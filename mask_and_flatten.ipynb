{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9o7Zk0y8MCZ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook was tokenizes (based on a Python tokenizer), flattens, and masks the target if statement with the token <MASK>\n",
    "for the training, validation, and test datasets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zd9miFmU-5o8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxjVbGZK_B_U"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('ft_train.csv')\n",
    "df_valid = pd.read_csv('ft_valid.csv')\n",
    "df_test = pd.read_csv('ft_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqdxnJBXqPuL"
   },
   "outputs": [],
   "source": [
    "from pygments.lexers import PythonLexer\n",
    "from pygments.token import Token\n",
    "from pygments import lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lLnLa6cqmQ8"
   },
   "outputs": [],
   "source": [
    "def tokenize_code_with_tab(code):\n",
    "    tokens = []\n",
    "    for ttype, value in lex(code, PythonLexer()):\n",
    "        # take care of tabs\n",
    "        if ttype in Token.Text and len(value)%4 == 0:\n",
    "            num_tabs = len(value)//4 # I consider each tab to be 4 spaces\n",
    "            assert(value == len(value)*\" \") # make sure it's actually all spaces\n",
    "            tokens.append(\"<TAB>\"*num_tabs)\n",
    "            continue\n",
    "        # ignore regular spaces and new lines\n",
    "        elif ttype in Token.Text:\n",
    "            continue\n",
    "        tokens.append(value)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDJOBs-BvJ9k"
   },
   "outputs": [],
   "source": [
    "def tokenize_code_no_tab(code):\n",
    "    tokens = []\n",
    "    for ttype, value in lex(code, PythonLexer()):\n",
    "        # ignore regular spaces and new lines\n",
    "        if ttype in Token.Text:\n",
    "            continue\n",
    "        tokens.append(value)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xojQltopxdK"
   },
   "outputs": [],
   "source": [
    "def mask_if_statement(method, target, with_tab):\n",
    "    # flatten cleaned method\n",
    "    if with_tab:\n",
    "        tokenized_method = tokenize_code_with_tab(method)\n",
    "    else:\n",
    "        tokenized_method = tokenize_code_no_tab(method)\n",
    "    joined_tokens = \" \".join(tokenized_method) # join tokens into a string separate by a space\n",
    "\n",
    "    tokenized_target = \" \".join(tokenize_code_no_tab(target))\n",
    "    assert(tokenized_target in joined_tokens) # make sure the target if statement is found in the cleaned method\n",
    "    return joined_tokens.replace(tokenized_target, \"<MASK>\") # replace if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfFmBYWolw7h"
   },
   "outputs": [],
   "source": [
    "masked_method_with_tab_list = []\n",
    "masked_method_no_tab_list = []\n",
    "for i in range(len(df_train)):\n",
    "    try:\n",
    "      method = df_train.iloc[i][\"cleaned_method\"]\n",
    "      target = df_train.iloc[i][\"target_block\"]\n",
    "\n",
    "      # mask and flatten with tab token\n",
    "      masked_method_with_tab = mask_if_statement(method, target, True)\n",
    "      masked_method_with_tab_list.append(masked_method_with_tab)\n",
    "\n",
    "      # mask and flatten without tab token\n",
    "      masked_method_no_tab = mask_if_statement(method, target, False)\n",
    "      masked_method_no_tab_list.append(masked_method_no_tab)\n",
    "    except Exception as e:\n",
    "      print(i)\n",
    "      raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MglmTDN16P2i"
   },
   "outputs": [],
   "source": [
    "# add masked and flattenen methods as columns in the df\n",
    "df_train[\"masked_with_tab\"] = masked_method_with_tab_list\n",
    "df_train[\"masked_no_tab\"] = masked_method_no_tab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TaGoFu2v6Ybk"
   },
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df_train.to_csv(\"ft_train_masked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRZz-exJxSDD"
   },
   "outputs": [],
   "source": [
    "masked_method_with_tab_list = []\n",
    "masked_method_no_tab_list = []\n",
    "for i in range(len(df_valid)):\n",
    "    method = df_valid.iloc[i][\"cleaned_method\"]\n",
    "    target = df_valid.iloc[i][\"target_block\"]\n",
    "    masked_method_with_tab = mask_if_statement(method, target, True)\n",
    "    masked_method_with_tab_list.append(masked_method_with_tab)\n",
    "    masked_method_no_tab = mask_if_statement(method, target, False)\n",
    "    masked_method_no_tab_list.append(masked_method_no_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNS5Jwlj7MLd"
   },
   "outputs": [],
   "source": [
    "df_valid[\"masked_with_tab\"] = masked_method_with_tab_list\n",
    "df_valid[\"masked_no_tab\"] = masked_method_no_tab_list\n",
    "df_valid.to_csv(\"ft_valid_masked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDNS7gUlxT7P"
   },
   "outputs": [],
   "source": [
    "masked_method_with_tab_list = []\n",
    "masked_method_no_tab_list = []\n",
    "for i in range(len(df_test)):\n",
    "    method = df_test.iloc[i][\"cleaned_method\"]\n",
    "    target = df_test.iloc[i][\"target_block\"]\n",
    "    masked_method_with_tab = mask_if_statement(method, target, True)\n",
    "    masked_method_with_tab_list.append(masked_method_with_tab)\n",
    "    masked_method_no_tab = mask_if_statement(method, target, False)\n",
    "    masked_method_no_tab_list.append(masked_method_no_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f3_fMy2uqJy"
   },
   "outputs": [],
   "source": [
    "df_test[\"masked_with_tab\"] = masked_method_with_tab_list\n",
    "df_test[\"masked_no_tab\"] = masked_method_no_tab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCUKXxSkw3zy"
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"ft_test_masked.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZpU5W9tSiVk3n08orgAQJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
