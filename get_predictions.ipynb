{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQ9YdNEGT4rCGj+/RgS/Vi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","This notebook gets the predictions on the methods in the test set from the fine-tuned model.\n","\"\"\""],"metadata":{"id":"3QadREKfUc18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers datasets evaluate -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZLG3vN2N8FI","executionInfo":{"status":"ok","timestamp":1744261037177,"user_tz":240,"elapsed":11274,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}},"outputId":"ff2fc206-6f71-49fa-f067-00152039da35"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m81.9/84.0 kB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import sys\n","def print_progress(percent):\n","    width = 50  # Width of the progress bar\n","    filled = int(width * percent / 100)\n","    bar = \"#\" * filled + \"-\" * (width - filled)\n","    sys.stdout.write(f\"\\r[{bar}] {percent}%\")\n","    sys.stdout.flush()"],"metadata":{"id":"yJIMZmZGE29l","executionInfo":{"status":"ok","timestamp":1744261342645,"user_tz":240,"elapsed":44,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------------------\n","# Load Test Dataset and Create DatasetDict\n","# ------------------------------------------------------------------------\n","import pandas as pd\n","from datasets import Dataset\n","from datasets import DatasetDict\n","\n","test_df = pd.read_csv(\"ft_test_masked.csv\")\n","test_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","dataset = DatasetDict({\n","    \"test\": test_dataset\n","})"],"metadata":{"id":"M87Kdx1ZN7A3","executionInfo":{"status":"ok","timestamp":1744261043456,"user_tz":240,"elapsed":6256,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!unzip final_model.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfLoYlgoNxF5","executionInfo":{"status":"ok","timestamp":1744264878913,"user_tz":240,"elapsed":14577,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}},"outputId":"b15776a6-18d5-4b3f-95c2-bbaf0afb9d3c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  final_model.zip\n","replace final_model/added_tokens.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: final_model/added_tokens.json  \n","  inflating: final_model/config.json  \n","  inflating: final_model/generation_config.json  \n","  inflating: final_model/merges.txt  \n","  inflating: final_model/model.safetensors  \n","  inflating: final_model/special_tokens_map.json  \n","  inflating: final_model/tokenizer_config.json  \n","  inflating: final_model/training_args.bin  \n","  inflating: final_model/vocab.json  \n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"3OvPdtJ2NqJF","executionInfo":{"status":"ok","timestamp":1744264882999,"user_tz":240,"elapsed":402,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}}},"outputs":[],"source":["# -----------------------------------\n","# Load fine-tuned model and tokenizer\n","# -----------------------------------\n","\n","from transformers import T5ForConditionalGeneration, RobertaTokenizer\n","\n","# Load model\n","model = T5ForConditionalGeneration.from_pretrained(\"final_model\")\n","\n","# Load tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(\"final_model\")"]},{"cell_type":"code","source":["import pandas as pd\n","\n","masked_functions = []\n","expected_if_statements = []\n","predicted_if_statements = []\n","predicted_full_methods = []\n","target_full_methods = []\n","\n","for i in range(5000):\n","    # get model prediction\n","    input_text = dataset[\"test\"][i][\"masked_with_tab\"]\n","    # input_text = dataset[\"test\"][i][\"masked_no_tab\"]\n","    masked_functions.append(input_text)\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n","    output = model.generate(**inputs)\n","    predicted_if_statement = tokenizer.decode(output[0], skip_special_tokens=True)\n","    predicted_if_statements.append(predicted_if_statement)\n","\n","    # get expected if statement\n","    expected_if_statement = dataset[\"test\"][i][\"target_block\"]\n","    expected_if_statements.append(expected_if_statement)\n","\n","    try:\n","      # attach expected if statement back into the function\n","      assert(\"<MASK>\" in input_text)\n","      predicted_method = input_text.replace(\"<MASK>\", predicted_if_statement)\n","      predicted_full_methods.append(predicted_method)\n","      target_method = input_text.replace(\"<MASK>\", expected_if_statement)\n","      target_full_methods.append(target_method)\n","      if i % 100 == 0:\n","        print_progress(((i+1)/5000)*100)\n","      # print(i)\n","\n","    except AssertionError as e:\n","      print(i)\n","      raise e\n","print_progress(100)"],"metadata":{"id":"u9ZBafaiRA5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744267788668,"user_tz":240,"elapsed":2305028,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}},"outputId":"dd1c9e10-4c4d-4be9-e05b-8b63f29c5030"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[##################################################] 100%"]}]},{"cell_type":"code","source":["# save predictions and other relevant data to df\n","df = pd.DataFrame({\n","    \"input_function\": masked_functions,\n","    \"expected_if_statement\": expected_if_statements,\n","    \"predicted_if_statement\": predicted_if_statements,\n","    \"predicted_full_method\": predicted_full_methods,\n","    \"target_full_method\": target_full_methods\n","})\n","\n","# save df to csv\n","# df.to_csv(\"predictions_no_tab.csv\")\n","df.to_csv(\"predictions_with_tab.csv\")"],"metadata":{"id":"vBtBF12Kx_SG","executionInfo":{"status":"ok","timestamp":1744268862391,"user_tz":240,"elapsed":382,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"nmnbDrtEOSRi","executionInfo":{"status":"ok","timestamp":1744268867810,"user_tz":240,"elapsed":124,"user":{"displayName":"Rachel Zheng","userId":"05341545600733692037"}},"outputId":"ad2c0b1e-c151-4aa2-d296-b746139cad95"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      input_function  \\\n","0  def read ( self , count = True , timeout = Non...   \n","1  def _cache_mem ( curr_out , prev_mem , mem_len...   \n","2  def filtered ( gen ) : <TAB> for example in ge...   \n","3  def search ( self , query ) : <TAB> # \"Search....   \n","4  def _check_script ( self , script , directive ...   \n","\n","                        expected_if_statement  \\\n","0   if ignore_timeouts and is_timeout ( e ) :   \n","1                       if prev_mem is None :   \n","2               if example_len > max_length :   \n","3  if item . get ( \"type\" , \"\" ) == \"audio\" :   \n","4             if var . must_contain ( \"/\" ) :   \n","\n","                      predicted_if_statement  \\\n","0    if ignore_timeouts and is_noerr ( e ) :   \n","1            if mem_len < len ( curr_out ) :   \n","2              if example_len > max_length :   \n","3                    if \"guide_id\" in item :   \n","4  if var . name in self . _untrusted_vars :   \n","\n","                               predicted_full_method  \\\n","0  def read ( self , count = True , timeout = Non...   \n","1  def _cache_mem ( curr_out , prev_mem , mem_len...   \n","2  def filtered ( gen ) : <TAB> for example in ge...   \n","3  def search ( self , query ) : <TAB> # \"Search....   \n","4  def _check_script ( self , script , directive ...   \n","\n","                                  target_full_method  \n","0  def read ( self , count = True , timeout = Non...  \n","1  def _cache_mem ( curr_out , prev_mem , mem_len...  \n","2  def filtered ( gen ) : <TAB> for example in ge...  \n","3  def search ( self , query ) : <TAB> # \"Search....  \n","4  def _check_script ( self , script , directive ...  "],"text/html":["\n","  <div id=\"df-6f5af597-8eff-4a75-a1fc-0a65ad238066\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_function</th>\n","      <th>expected_if_statement</th>\n","      <th>predicted_if_statement</th>\n","      <th>predicted_full_method</th>\n","      <th>target_full_method</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>def read ( self , count = True , timeout = Non...</td>\n","      <td>if ignore_timeouts and is_timeout ( e ) :</td>\n","      <td>if ignore_timeouts and is_noerr ( e ) :</td>\n","      <td>def read ( self , count = True , timeout = Non...</td>\n","      <td>def read ( self , count = True , timeout = Non...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>def _cache_mem ( curr_out , prev_mem , mem_len...</td>\n","      <td>if prev_mem is None :</td>\n","      <td>if mem_len &lt; len ( curr_out ) :</td>\n","      <td>def _cache_mem ( curr_out , prev_mem , mem_len...</td>\n","      <td>def _cache_mem ( curr_out , prev_mem , mem_len...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>def filtered ( gen ) : &lt;TAB&gt; for example in ge...</td>\n","      <td>if example_len &gt; max_length :</td>\n","      <td>if example_len &gt; max_length :</td>\n","      <td>def filtered ( gen ) : &lt;TAB&gt; for example in ge...</td>\n","      <td>def filtered ( gen ) : &lt;TAB&gt; for example in ge...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>def search ( self , query ) : &lt;TAB&gt; # \"Search....</td>\n","      <td>if item . get ( \"type\" , \"\" ) == \"audio\" :</td>\n","      <td>if \"guide_id\" in item :</td>\n","      <td>def search ( self , query ) : &lt;TAB&gt; # \"Search....</td>\n","      <td>def search ( self , query ) : &lt;TAB&gt; # \"Search....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>def _check_script ( self , script , directive ...</td>\n","      <td>if var . must_contain ( \"/\" ) :</td>\n","      <td>if var . name in self . _untrusted_vars :</td>\n","      <td>def _check_script ( self , script , directive ...</td>\n","      <td>def _check_script ( self , script , directive ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f5af597-8eff-4a75-a1fc-0a65ad238066')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6f5af597-8eff-4a75-a1fc-0a65ad238066 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6f5af597-8eff-4a75-a1fc-0a65ad238066');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bd436b87-7865-4320-b356-4214e13fedb0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd436b87-7865-4320-b356-4214e13fedb0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bd436b87-7865-4320-b356-4214e13fedb0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"input_function\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"def readMemory ( self , va , size ) : <TAB> for mva , mmaxva , mmap , mbytes in self . _map_defs : <TAB><TAB> if mva < = va < mmaxva : <TAB><TAB><TAB> mva , msize , mperms , mfname = mmap <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise envi . SegmentationViolation ( va ) <TAB><TAB><TAB> offset = va - mva <TAB><TAB><TAB> return mbytes [ offset : offset + size ] <TAB> raise envi . SegmentationViolation ( va )\",\n          \"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB><TAB> module_directory = join ( directory , module ) <TAB><TAB> has_module_directory = isdir ( module_directory ) <TAB><TAB> if not version : <TAB><TAB><TAB> has_module = has_module_directory or exists ( <TAB><TAB><TAB><TAB> module_directory <TAB><TAB><TAB> ) # could be a bare modulefile <TAB><TAB> else : <TAB><TAB><TAB> modulefile = join ( module_directory , version ) <TAB><TAB><TAB> has_modulefile = exists ( modulefile ) <TAB><TAB><TAB> has_module = has_module_directory and has_modulefile <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return has_module\",\n          \"def feature_reddit ( layer_data , graph ) : <TAB> feature = { } <TAB> times = { } <TAB> indxs = { } <TAB> for _type in layer_data : <TAB><TAB> if len ( layer_data [ _type ] ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> idxs = np . array ( list ( layer_data [ _type ] . keys ( ) ) ) <TAB><TAB> tims = np . array ( list ( layer_data [ _type ] . values ( ) ) ) [ : , 1 ] <TAB><TAB> feature [ _type ] = np . array ( <TAB><TAB><TAB> list ( graph . node_feature [ _type ] . loc [ idxs , \\\" emb \\\" ] ) , dtype = np . float <TAB><TAB> ) <TAB><TAB> times [ _type ] = tims <TAB><TAB> indxs [ _type ] = idxs <TAB><TAB> <MASK> <TAB><TAB><TAB> attr = feature [ _type ] <TAB> return feature , times , indxs , attr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_if_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4738,\n        \"samples\": [\n          \"if not FLAGS . ceph_monitors :\",\n          \"if key in self . clean_args :\",\n          \"if c == \\\"\\\\0\\\" :\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_if_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4598,\n        \"samples\": [\n          \"if marker :\",\n          \"if isinstance ( nick , bytes ) :\",\n          \"if cls . _clock . is_running ( next_iteration ) :\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_full_method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4875,\n        \"samples\": [\n          \"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB><TAB> for name , var in new_subst . items ( ) : <TAB><TAB><TAB> if name not in subst : <TAB><TAB><TAB><TAB> subst [ name ] = var <TAB><TAB><TAB> elif subst [ name ] is not var : <TAB><TAB><TAB><TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst\",\n          \"def addOutput ( self , data , isAsync = None , * * kwargs ) : <TAB> isAsync = _get_async_param ( isAsync , * * kwargs ) <TAB> if isAsync : <TAB><TAB> self . terminal . eraseLine ( ) <TAB><TAB> self . terminal . cursorBackward ( len ( self . lineBuffer ) + len ( self . ps [ self . pn ] ) ) <TAB> self . terminal . write ( data ) <TAB> if isAsync : <TAB><TAB> if self . lineBufferIndex == len ( self . ps [ self . pn ] ) : <TAB><TAB><TAB> self . terminal . nextLine ( ) <TAB><TAB> self . terminal . write ( self . ps [ self . pn ] ) <TAB><TAB> if self . lineBuffer : <TAB><TAB><TAB> oldBuffer = self . lineBuffer <TAB><TAB><TAB> self . lineBuffer = [ ] <TAB><TAB><TAB> self . lineBufferIndex = 0 <TAB><TAB><TAB> self . _deliverBuffer ( oldBuffer )\",\n          \"def test_create_repository ( repo_name , expected_status , client ) : <TAB> with client_with_identity ( \\\" devtable \\\" , client ) as cl : <TAB><TAB> body = { <TAB><TAB><TAB> \\\" namespace \\\" : \\\" devtable \\\" , <TAB><TAB><TAB> \\\" repository \\\" : repo_name , <TAB><TAB><TAB> \\\" visibility \\\" : \\\" public \\\" , <TAB><TAB><TAB> \\\" description \\\" : \\\" foo \\\" , <TAB><TAB> } <TAB><TAB> result = conduct_api_call ( <TAB><TAB><TAB> client , RepositoryList , \\\" post \\\" , None , body , expected_code = expected_status <TAB><TAB> ) . json <TAB><TAB> if result : <TAB><TAB><TAB> assert result [ \\\" name \\\" ] == repo_name <TAB><TAB><TAB> assert ( <TAB><TAB><TAB><TAB> model . repository . get_repository ( \\\" devtable \\\" , repo_name ) . name == repo_name <TAB><TAB><TAB> )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_full_method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4292,\n        \"samples\": [\n          \"def visit ( stmt ) : <TAB> \\\"\\\"\\\"Collect information about VTCM buffers and their alignments.\\\"\\\"\\\" <TAB> if isinstance ( stmt , tvm . tir . AttrStmt ) : <TAB><TAB> if stmt . attr_key == \\\" storage_scope \\\" and stmt . value == \\\" local.vtcm \\\" : <TAB><TAB><TAB> vtcm_buffers . append ( stmt . node ) <TAB><TAB> elif stmt . attr_key == \\\"storage_alignment\\\" : <TAB><TAB><TAB> if not stmt . node in alignments : <TAB><TAB><TAB><TAB> alignments [ stmt . node ] = [ ] <TAB><TAB><TAB> alignments [ stmt . node ] . append ( stmt . value )\",\n          \"def iterparent ( self , node ) : <TAB> \\\"\\\"\\\"Iterator wrapper to get allowed parent and child all at once.\\\"\\\"\\\" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node : <TAB><TAB> if not self . header_rgx . match ( child . tag ) and child . tag not in [ \\\"pre\\\" , \\\"code\\\" ] : <TAB><TAB><TAB> yield node , child <TAB><TAB><TAB> yield from self . iterparent ( child )\",\n          \"def function ( self , inputs , outputs , ignore_empty = False ) : <TAB> f = function ( inputs , outputs , mode = self . mode ) <TAB> if self . mode is not None or theano . config . mode != \\\" FAST_COMPILE \\\" : <TAB><TAB> topo = f . maker . fgraph . toposort ( ) <TAB><TAB> topo_ = [ node for node in topo if not isinstance ( node . op , self . ignore_topo ) ] <TAB><TAB> if ignore_empty : <TAB><TAB><TAB> assert len ( topo_ ) < = 1 , topo_ <TAB><TAB> else : <TAB><TAB><TAB> assert len ( topo_ ) == 1 , topo_ <TAB><TAB> if len ( topo_ ) > 0 : <TAB><TAB><TAB> assert type ( topo_ [ 0 ] . op ) is self . op <TAB> return f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":23}]}]}