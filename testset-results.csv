,input_function,expected_if_statement,predicted_if_statement,code_bleu,bleu_4,exact_match
0,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB><TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB><TAB> if DEBUG_COMM : <TAB><TAB><TAB> log . info ( <TAB><TAB><TAB><TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ ] <TAB><TAB> if ignore_non_errors and is_noerr ( e ) : <TAB><TAB><TAB> return [ ] <TAB><TAB> raise",if ignore_timeouts and is_timeout ( e ) :,if ignore_timeouts and is_noerr ( e ) :,98.90137729082613,98.91,False
1,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB><TAB> return None <TAB> else : <TAB><TAB> if reuse_len is not None and reuse_len > 0 : <TAB><TAB><TAB> curr_out = curr_out [ : reuse_len ] <TAB><TAB> <MASK> <TAB><TAB><TAB> new_mem = curr_out [ - mem_len : ] <TAB><TAB> else : <TAB><TAB><TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem",if prev_mem is None :,if mem_len < len ( curr_out ) :,73.00838888954597,94.86,False
2,def filtered ( gen ) : <TAB> for example in gen : <TAB><TAB> example_len = length_fn ( example ) <TAB><TAB> # Checking max length boundary. <TAB><TAB> if max_length is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> # Checking min length boundary. <TAB><TAB> if min_length is not None : <TAB><TAB><TAB> if example_len < min_length : <TAB><TAB><TAB><TAB> continue <TAB><TAB> # Within bounds. <TAB><TAB> yield example,if example_len > max_length :,if example_len > max_length :,100.0,100.00,True
3,"def search ( self , query ) : <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query : <TAB><TAB> logger . debug ( "" Empty search query "" ) <TAB><TAB> return [ ] <TAB> logger . debug ( ' Searching TuneIn for  "" %s "" ' % query ) <TAB> args = "" &query= "" + query <TAB> search_results = self . _tunein ( "" Search.ashx "" , args ) <TAB> results = [ ] <TAB> for item in self . _flatten ( search_results ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Only return stations <TAB><TAB><TAB> self . _stations [ item [ "" guide_id "" ] ] = item <TAB><TAB><TAB> results . append ( item ) <TAB> return results","if item . get ( ""type"" , """" ) == ""audio"" :","if ""guide_id"" in item :",70.69205051032309,91.97,False
4,"def _check_script ( self , script , directive ) : <TAB> for var in compile_script ( script ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Skip variable checks <TAB><TAB><TAB> return False <TAB><TAB> if var . can_contain ( "" . "" ) : <TAB><TAB><TAB> # Yay! Our variable can contain any symbols! <TAB><TAB><TAB> reason = ( <TAB><TAB><TAB><TAB> ' At least variable  "" $ {var} ""  can contain untrusted user input ' . format ( <TAB><TAB><TAB><TAB><TAB> var = var . name <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . add_issue ( directive = [ directive ] + var . providers , reason = reason ) <TAB><TAB><TAB> return True <TAB> return False","if var . must_contain ( ""/"" ) :",if var . name in self . _untrusted_vars :,82.7917274533819,96.05,False
5,"def getAllDataLinkIDs ( ) : <TAB> linkDataIDs = set ( ) <TAB> dataType = _forestData . dataTypeBySocket <TAB> for socketID , linkedIDs in _forestData . linkedSockets . items ( ) : <TAB><TAB> for linkedID in linkedIDs : <TAB><TAB><TAB> <MASK> # check which one is origin/target <TAB><TAB><TAB><TAB> linkDataIDs . add ( <TAB><TAB><TAB><TAB><TAB> ( socketID , linkedID , dataType [ socketID ] , dataType [ linkedID ] ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> linkDataIDs . add ( <TAB><TAB><TAB><TAB><TAB> ( linkedID , socketID , dataType [ linkedID ] , dataType [ socketID ] ) <TAB><TAB><TAB><TAB> ) <TAB> return linkDataIDs",if socketID [ 1 ] :,if linkedID in dataType :,94.75442090007202,97.32,False
6,"def _stderr_supports_color ( ) : <TAB> try : <TAB><TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB> if curses : <TAB><TAB><TAB><TAB> curses . setupterm ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> elif colorama : <TAB><TAB><TAB><TAB> if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB> except Exception : <TAB><TAB> # Very broad exception handling because it's always better to <TAB><TAB> # fall back to non-colored logs than to break at startup. <TAB><TAB> pass <TAB> return False","if curses . tigetnum ( ""colors"" ) > 0 :",if curses . is_running ( ) :,95.01534522938819,96.42,False
7,"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB><TAB> if isinstance ( ty , SimTypeBottom ) : <TAB><TAB><TAB> l . warning ( <TAB><TAB><TAB><TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB><TAB><TAB><TAB> "" element size. "" , <TAB><TAB><TAB><TAB> self . name , <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> if not self . _pack : <TAB><TAB><TAB> align = ty . alignment <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> offset_so_far + = align - offset_so_far % align <TAB><TAB> offsets [ name ] = offset_so_far <TAB><TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets",if offset_so_far % align != 0 :,if align :,92.44557405456233,95.83,False
8,"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB><TAB> if issubclass ( picker . __class__ , wx . FileDialog ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value [ - 1 ] <TAB><TAB> picker . SetPath ( value ) <TAB><TAB> return True <TAB> return False",if type ( value ) == list :,if value [ - 1 ] == PERSIST_FILEDIRPICKER_PATH :,90.58847358658535,90.60,False
9,"def dt_s_tup_to_string ( dt_s_tup ) : <TAB> dt_string = dt_s_tup [ 0 ] # string for identifying the file to parse. <TAB> if dt_s_tup [ 1 ] > 0 : # if there are seasons in the model <TAB><TAB> <MASK> <TAB><TAB><TAB> dt_string = dt_string [ : 2 ] + "" s "" + dt_string [ 2 : ] <TAB><TAB> else : <TAB><TAB><TAB> dt_string = "" s "" + dt_string <TAB> return dt_string","if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",if len ( dt_string ) > 2 :,91.89333402711523,85.40,False
10,"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB><TAB> stream . write ( sep ) <TAB><TAB> sep = ""   "" <TAB><TAB> <MASK> <TAB><TAB><TAB> item = str ( item ) <TAB><TAB> if not PY3K : <TAB><TAB><TAB> if not isinstance ( item , unicode ) : <TAB><TAB><TAB><TAB> item = str ( item ) <TAB><TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" )","if not isinstance ( item , str ) :","if not isinstance ( item , unicode ) :",80.57921260285353,98.25,False
11,"def _get_result_keys ( self , config ) : <TAB> result_key = config . get ( "" result_key "" ) <TAB> if result_key is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> result_key = [ result_key ] <TAB><TAB> result_key = [ jmespath . compile ( rk ) for rk in result_key ] <TAB><TAB> return result_key","if not isinstance ( result_key , list ) :","if not isinstance ( result_key , list ) :",100.0,100.00,True
12,"def _download_build_artifacts ( self , build : Dict [ str , Any ] ) - > None : <TAB> arch = build [ "" arch_tag "" ] <TAB> snap_build = self . _lp_load_url ( build [ "" self_link "" ] ) <TAB> urls = snap_build . getFileUrls ( ) <TAB> if not urls : <TAB><TAB> logger . error ( f "" Snap file not available for arch  { arch !r} . "" ) <TAB><TAB> return <TAB> for url in urls : <TAB><TAB> file_name = _get_url_basename ( url ) <TAB><TAB> self . _download_file ( url = url , dst = file_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . info ( f "" Snapped  { file_name } "" ) <TAB><TAB> else : <TAB><TAB><TAB> logger . info ( f "" Fetched  { file_name } "" )","if file_name . endswith ( "".snap"" ) :","if arch == ""snap"" :",68.21725629354117,95.08,False
13,"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB><TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB><TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB><TAB> if not isinstance ( custom_statements , list ) : <TAB><TAB><TAB> custom_statements = [ custom_statements ] <TAB><TAB> statement = self . resource_policy [ "" Statement "" ] <TAB><TAB> if not isinstance ( statement , list ) : <TAB><TAB><TAB> statement = [ statement ] <TAB><TAB> for s in custom_statements : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> statement . append ( s ) <TAB><TAB> self . resource_policy [ "" Statement "" ] = statement",if s not in statement :,if s not in statement :,100.0,100.00,True
14,"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB><TAB> message : Optional [ str ] <TAB><TAB> <MASK> <TAB><TAB><TAB> message = f "" { idx } .  { check . message } "" <TAB><TAB> else : <TAB><TAB><TAB> message = None <TAB><TAB> example = cast ( Case , check . example ) # filtered in `_get_unique_failures` <TAB><TAB> display_example ( example , check . name , message , result . seed ) <TAB><TAB> # Display every time except the last check <TAB><TAB> if idx != len ( checks ) : <TAB><TAB><TAB> click . echo ( "" \n "" )",if check . message :,if check . message :,100.0,100.00,True
15,"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" qangaroo "" ) <TAB> version = "" v1.1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB><TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # An older version exists, so remove these outdated files. <TAB><TAB><TAB> build_data . remove_dir ( dpath ) <TAB><TAB> build_data . make_dir ( dpath ) <TAB><TAB> # Download the data. <TAB><TAB> for downloadable_file in RESOURCES : <TAB><TAB><TAB> downloadable_file . download_file ( dpath ) <TAB><TAB> # Mark the data as built. <TAB><TAB> build_data . mark_done ( dpath , version_string = version )",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,100.0,100.00,True
16,"def call ( self , step_input , states ) : <TAB> new_states = [ ] <TAB> for i in range ( self . num_layers ) : <TAB><TAB> out , new_state = self . lstm_cells [ i ] ( step_input , states [ i ] ) <TAB><TAB> step_input = ( <TAB><TAB><TAB> layers . dropout ( <TAB><TAB><TAB><TAB> out , self . dropout_prob , dropout_implementation = "" upscale_in_train "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else out <TAB><TAB> ) <TAB><TAB> new_states . append ( new_state ) <TAB> return step_input , new_states",if self . dropout_prob > 0.0,if self . dropout_prob,85.66881588114599,98.17,False
17,"def jupyter_progress_bar ( min = 0 , max = 1.0 ) : <TAB> """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB> widgets = wandb . util . get_module ( "" ipywidgets "" ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB><TAB><TAB> from IPython . html import widgets # type: ignore <TAB><TAB> assert hasattr ( widgets , "" VBox "" ) <TAB><TAB> assert hasattr ( widgets , "" Label "" ) <TAB><TAB> assert hasattr ( widgets , "" FloatProgress "" ) <TAB><TAB> return ProgressWidget ( widgets , min = min , max = max ) <TAB> except ( ImportError , AssertionError ) : <TAB><TAB> return None",if widgets is None :,if widgets :,94.91892235019964,98.17,False
18,"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB><TAB> self . events [ path ] . append ( events ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not os . path . exists ( path ) : <TAB><TAB><TAB><TAB> self . watches . pop ( path ) . close ( )",if events | pyuv . fs . UV_RENAME :,if self . watches :,66.05327008614337,90.18,False
19,"def _get_v1_id_from_tags ( self , tags_obj , tag ) : <TAB> """"""Get image id from array of tags"""""" <TAB> if isinstance ( tags_obj , dict ) : <TAB><TAB> try : <TAB><TAB><TAB> return tags_obj [ tag ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> pass <TAB> elif isinstance ( tags_obj , [ ] ) : <TAB><TAB> try : <TAB><TAB><TAB> for tag_dict in tags_obj : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return tag_dict [ "" layer "" ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> pass <TAB> return "" ""","if tag_dict [ ""name"" ] == tag :","if ""layer"" in tag_dict :",69.19672729248609,94.87,False
20,"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB><TAB> rs = domain . connection . query_with_attributes ( <TAB><TAB><TAB> domain , query , attr_names , next_token = next_token <TAB><TAB> ) <TAB><TAB> for item in rs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if num_results == max_items : <TAB><TAB><TAB><TAB><TAB> raise StopIteration <TAB><TAB><TAB> yield item <TAB><TAB><TAB> num_results + = 1 <TAB><TAB> next_token = rs . next_token <TAB><TAB> more_results = next_token != None",if max_items :,if max_items is not None :,82.3082823450733,98.03,False
21,"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB><TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB><TAB> <MASK> <TAB><TAB><TAB> kValue = array . get ( unicode ( k ) ) <TAB><TAB><TAB> if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) : <TAB><TAB><TAB><TAB> res . append ( kValue ) <TAB><TAB> k + = 1 <TAB> return args . space . ConstructArray ( res )",if array . has_property ( unicode ( k ) ) :,if array . has_property ( unicode ( k ) ) :,100.0,100.00,True
22,"def every_one_is ( self , dst ) : <TAB> msg = "" all members of  %r  should be  %r , but the  %d th is  %r "" <TAB> for index , item in enumerate ( self . _src ) : <TAB><TAB> if self . _range : <TAB><TAB><TAB> if index < self . _range [ 0 ] or index > self . _range [ 1 ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB> error = msg % ( self . _src , dst , index , item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AssertionError ( error ) <TAB> return True",if item != dst :,if error :,75.28585461396791,96.54,False
23,"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB><TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB><TAB> if delete : <TAB><TAB><TAB> with LoggerFactory . lock : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB><TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> return True <TAB><TAB> key = job_id + "" schedule "" <TAB><TAB> if key in LoggerFactory . schedule_logger_dict : <TAB><TAB><TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB> return LoggerFactory . get_schedule_logger ( job_id )",if job_id in key :,"if key == job_id + ""schedule"" :",96.21322235086974,96.59,False
24,"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB><TAB> # The type checker can't know the true type of item! <TAB><TAB> item = cast ( TupleStr4 , item ) <TAB><TAB> if item [ 0 ] : <TAB><TAB><TAB> typ = "" number "" <TAB><TAB><TAB> val = item [ 0 ] <TAB><TAB> elif item [ 1 ] : <TAB><TAB><TAB> typ = "" name "" <TAB><TAB><TAB> val = item [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> typ = item [ 2 ] <TAB><TAB><TAB> val = item [ 2 ] <TAB><TAB> elif item [ 3 ] : <TAB><TAB><TAB> typ = item [ 3 ] <TAB><TAB><TAB> val = item [ 3 ] <TAB><TAB> yield Token ( typ , val )",elif item [ 2 ] :,elif item [ 2 ] :,75.0,100.00,True
25,"def _read_data_from_all_categories ( self , directory , config , categories ) : <TAB> lines = [ ] <TAB> for category in categories : <TAB><TAB> data_file = os . path . join ( directory , _DATASET_VERSION , category , config ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with open ( data_file ) as f : <TAB><TAB><TAB><TAB> ls = f . read ( ) . split ( "" \n "" ) <TAB><TAB><TAB><TAB> for l in ls [ : : - 1 ] : <TAB><TAB><TAB><TAB><TAB> if not l : <TAB><TAB><TAB><TAB><TAB><TAB> ls . remove ( l ) <TAB><TAB><TAB><TAB> lines . extend ( ls ) <TAB> return lines",if os . path . exists ( data_file ) :,if os . path . exists ( data_file ) :,100.0,100.00,True
26,"def find_handlers ( self , forms ) : <TAB> handlers = { } <TAB> for form in forms . itervalues ( ) : <TAB><TAB> for action_name , _action_label in form . actions : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> handlers [ action_name ] = form <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise HandlerError ( <TAB><TAB><TAB><TAB><TAB> "" More than one form defines the handler  %s "" % action_name <TAB><TAB><TAB><TAB> ) <TAB> return handlers",if action_name not in handlers :,if action_name in self . _handlers :,89.00224160766506,96.72,False
27,"def get_story_task_completed_body ( payload : Dict [ str , Any ] ) - > Optional [ str ] : <TAB> action = get_action_with_primary_id ( payload ) <TAB> kwargs = { <TAB><TAB> "" task_description "" : action [ "" description "" ] , <TAB> } <TAB> story_id = action [ "" story_id "" ] <TAB> for ref in payload [ "" references "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs [ "" name_template "" ] = STORY_NAME_TEMPLATE . format ( <TAB><TAB><TAB><TAB> name = ref [ "" name "" ] , <TAB><TAB><TAB><TAB> app_url = ref [ "" app_url "" ] , <TAB><TAB><TAB> ) <TAB> if action [ "" changes "" ] [ "" complete "" ] [ "" new "" ] : <TAB><TAB> return STORY_TASK_COMPLETED_TEMPLATE . format ( * * kwargs ) <TAB> else : <TAB><TAB> return None","if ref [ ""id"" ] == story_id :","if ref [ ""story_id"" ] == story_id :",99.11422688952808,98.64,False
28,"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB><TAB> for j in range ( len ( nodes ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB><TAB><TAB> if graph . has_edge ( edge ) : <TAB><TAB><TAB><TAB> graph . del_edge ( edge ) <TAB><TAB><TAB> graph . add_edge ( edge , 1 )",if i == j :,if i == j :,100.0,100.00,True
29,"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB><TAB> lift_stmt [ - 1 ] . append ( op ) <TAB><TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> lift_stmt [ - 1 ] . append ( op ) <TAB><TAB><TAB> return op . body <TAB><TAB> if op . attr_key == "" virtual_thread "" : <TAB><TAB><TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB><TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB><TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" )","if op . attr_key == ""storage_scope"" :","if op . attr_key == ""virtual_thread"" :",74.12330506678605,98.17,False
30,"def format_lazy_import ( names ) : <TAB> """"""Formats lazy import lines"""""" <TAB> lines = "" "" <TAB> for _ , name , asname in names : <TAB><TAB> pkg , _ , _ = name . partition ( "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line = "" {pkg}  = _LazyModule.load( {pkg!r} ,  {mod!r} ) \n "" <TAB><TAB> else : <TAB><TAB><TAB> line = "" {asname}  = _LazyModule.load( {pkg!r} ,  {mod!r} ,  {asname!r} ) \n "" <TAB><TAB> lines + = line . format ( pkg = pkg , mod = name , asname = asname ) <TAB> return lines",if asname is None :,if asname is None :,100.0,100.00,True
31,"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB><TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB><TAB><TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB><TAB> if wildcard_count == 1 and argument [ 0 ] . endswith ( "" * "" ) : <TAB><TAB><TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB><TAB> else : <TAB><TAB><TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB><TAB><TAB> matched = False <TAB><TAB><TAB> for w in self . words : <TAB><TAB><TAB><TAB> matched = bool ( re . search ( _regex , w ) ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] )",if matched :,if matched :,100.0,100.00,True
32,"def setup ( self , ir : "" IR "" , aconf : Config ) - > bool : <TAB> if self . kind == "" ConsulResolver "" : <TAB><TAB> self . resolve_with = "" consul "" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . post_error ( "" ConsulResolver is required to have a datacenter "" ) <TAB><TAB><TAB> return False <TAB> elif self . kind == "" KubernetesServiceResolver "" : <TAB><TAB> self . resolve_with = "" k8s "" <TAB> elif self . kind == "" KubernetesEndpointResolver "" : <TAB><TAB> self . resolve_with = "" k8s "" <TAB> else : <TAB><TAB> self . post_error ( f "" Resolver kind  { self . kind }  unknown "" ) <TAB><TAB> return False <TAB> return True","if not self . get ( ""datacenter"" ) :",if self . datacenter is None :,93.7913787977621,95.15,False
33,"def get_success_url ( self ) : <TAB> """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB> if "" back "" in self . request . GET : <TAB><TAB> back_url = self . request . GET [ "" back "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> back_url = "" / "" <TAB><TAB> return back_url <TAB> return reverse ( self . success_url )","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",if not back_url :,58.58029883370164,78.63,False
34,"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB><TAB> if url . startswith ( "" https:// "" ) : <TAB><TAB><TAB> url = url [ 8 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> url = "" http:// "" + url <TAB><TAB> if playlist : <TAB><TAB><TAB> download_playlist ( <TAB><TAB><TAB><TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only )","if not url . startswith ( ""http://"" ) :","elif not url . startswith ( ""http://"" ) :",73.61537545822999,98.84,False
35,"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB><TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> buf . append ( "" line  "" ) <TAB><TAB> buf . append ( str ( self . line ) ) <TAB><TAB> if self . column != - 1 : <TAB><TAB><TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB><TAB> buf . append ( "" : "" ) <TAB> buf . append ( ""   "" ) <TAB> return str ( "" "" ) . join ( buf )",if not self . fileName :,if self . line != - 1 :,95.71192146447683,95.72,False
36,"def parse_bash_set_output ( output ) : <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB><TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB><TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB><TAB> # line does not imply a continuation. <TAB><TAB> output = output . replace ( "" \\ \n "" , "" "" ) <TAB> environ = { } <TAB> for line in output . splitlines ( 0 ) : <TAB><TAB> line = line . rstrip ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> continue # skip black lines <TAB><TAB> item = _ParseBashEnvStr ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> environ [ item [ 0 ] ] = item [ 1 ] <TAB> return environ",if item :,if item :,100.0,100.00,True
37,"def remove_selected ( self ) : <TAB> """"""Removes selected items from list."""""" <TAB> to_delete = [ ] <TAB> for i in range ( len ( self ) ) : <TAB><TAB> if self [ i ] . selected : <TAB><TAB><TAB> to_delete . append ( i ) <TAB> to_delete . reverse ( ) <TAB> for i in to_delete : <TAB><TAB> self . pop ( i ) <TAB> if len ( to_delete ) > 0 : <TAB><TAB> first_to_delete = to_delete [ - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self [ 0 ] . selected = True <TAB><TAB> elif first_to_delete > 0 : <TAB><TAB><TAB> self [ first_to_delete - 1 ] . selected = True",if first_to_delete == 0 and len ( self ) > 0 :,if first_to_delete == 1 :,86.96355554734794,95.60,False
38,"def update ( self , update_tracks = True ) : <TAB> self . enable_update_metadata_images ( False ) <TAB> old_album_title = self . metadata [ "" album "" ] <TAB> self . metadata [ "" album "" ] = config . setting [ "" nat_name "" ] <TAB> for track in self . tracks : <TAB><TAB> <MASK> <TAB><TAB><TAB> track . metadata [ "" album "" ] = self . metadata [ "" album "" ] <TAB><TAB> for file in track . linked_files : <TAB><TAB><TAB> track . update_file_metadata ( file ) <TAB> self . enable_update_metadata_images ( True ) <TAB> super ( ) . update ( update_tracks )","if old_album_title == track . metadata [ ""album"" ] :","if track . metadata [ ""album"" ] != old_album_title :",96.13969842262429,96.60,False
39,"def on_input ( self , target , message ) : <TAB> if message . strip ( ) == "" "" : <TAB><TAB> self . panel ( "" No commit message provided "" ) <TAB><TAB> return <TAB> if target : <TAB><TAB> command = [ "" git "" , "" add "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> command . append ( "" --all "" ) <TAB><TAB> else : <TAB><TAB><TAB> command . extend ( ( "" -- "" , target ) ) <TAB><TAB> self . run_command ( command , functools . partial ( self . add_done , message ) ) <TAB> else : <TAB><TAB> self . add_done ( message , "" "" )","if target == ""*"" :","if target == ""all"" :",98.88191737224705,98.61,False
40,"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB><TAB> filename , position = self . last_edit_cursor_pos <TAB><TAB> <MASK> <TAB><TAB><TAB> self . last_edit_cursor_pos = None <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> self . load ( filename ) <TAB><TAB><TAB> editor = self . get_current_editor ( ) <TAB><TAB><TAB> if position < editor . document ( ) . characterCount ( ) : <TAB><TAB><TAB><TAB> editor . set_cursor_position ( position )",if not osp . isfile ( filename ) :,if filename is None :,65.98970659598412,95.41,False
41,"def returnByType ( self , results ) : <TAB> new_results = { } <TAB> for r in results : <TAB><TAB> type_name = r . get ( "" type "" , "" movie "" ) + "" s "" <TAB><TAB> <MASK> <TAB><TAB><TAB> new_results [ type_name ] = [ ] <TAB><TAB> new_results [ type_name ] . append ( r ) <TAB> # Combine movies, needs a cleaner way.. <TAB> if "" movies "" in new_results : <TAB><TAB> new_results [ "" movies "" ] = self . combineOnIMDB ( new_results [ "" movies "" ] ) <TAB> return new_results",if type_name not in new_results :,if type_name not in new_results :,100.0,100.00,True
42,"def cache_sns_topics_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> for account_id in accounts_d . keys ( ) : <TAB><TAB> if config . get ( "" environment "" ) == "" prod "" : <TAB><TAB><TAB> cache_sns_topics_for_account . delay ( account_id ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cache_sns_topics_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if config . get ( ""environment"" ) == ""test"" :",95.81094826577149,92.30,False
43,"def get ( self , subject , topic ) : <TAB> """"""Handles GET requests."""""" <TAB> if subject in feconf . AVAILABLE_LANDING_PAGES : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . render_template ( "" topic-landing-page.mainpage.html "" ) <TAB><TAB> else : <TAB><TAB><TAB> raise self . PageNotFoundException <TAB> else : <TAB><TAB> raise self . PageNotFoundException",if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,if topic in feconf . AVAILABLE_LANDING_PAGES :,67.69499810292281,96.05,False
44,"def callback ( compiled ) : <TAB> <MASK> <TAB><TAB> logger . show_tabulated ( <TAB><TAB><TAB> "" Compiled "" , showpath ( codepath ) , "" without writing to file. "" <TAB><TAB> ) <TAB> else : <TAB><TAB> with univ_open ( destpath , "" w "" ) as opened : <TAB><TAB><TAB> writefile ( opened , compiled ) <TAB><TAB> logger . show_tabulated ( "" Compiled to "" , showpath ( destpath ) , "" . "" ) <TAB> if self . show : <TAB><TAB> print ( compiled ) <TAB> if run : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . execute ( compiled , path = codepath , allow_show = False ) <TAB><TAB> else : <TAB><TAB><TAB> self . execute_file ( destpath )",if destpath is None :,if not os . path . exists ( codepath ) :,63.66974601308697,90.42,False
45,"def _find_start_index ( self , string , start , end ) : <TAB> while True : <TAB><TAB> index = string . find ( "" { "" , start , end ) - 1 <TAB><TAB> if index < 0 : <TAB><TAB><TAB> return - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> return index <TAB><TAB> start = index + 2","if self . _start_index_is_ok ( string , index ) :","if string . find ( ""}"" , start , index + 1 ) == - 1 :",84.84966854256423,84.61,False
46,"def _get_nlu_target_format ( export_path : Text ) - > Text : <TAB> guessed_format = loading . guess_format ( export_path ) <TAB> if guessed_format not in { MARKDOWN , RASA , RASA_YAML } : <TAB><TAB> if rasa . shared . data . is_likely_json_file ( export_path ) : <TAB><TAB><TAB> guessed_format = RASA <TAB><TAB> elif rasa . shared . data . is_likely_markdown_file ( export_path ) : <TAB><TAB><TAB> guessed_format = MARKDOWN <TAB><TAB> <MASK> <TAB><TAB><TAB> guessed_format = RASA_YAML <TAB> return guessed_format",elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,"elif guessed_format in { MARKDOWN , RASA , RASA",76.49673346887266,88.88,False
47,"def moveToThreadNext ( self ) : <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p . v : <TAB><TAB> if p . v . children : <TAB><TAB><TAB> p . moveToFirstChild ( ) <TAB><TAB> el<MASK> <TAB><TAB><TAB> p . moveToNext ( ) <TAB><TAB> else : <TAB><TAB><TAB> p . moveToParent ( ) <TAB><TAB><TAB> while p : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> p . moveToNext ( ) <TAB><TAB><TAB><TAB><TAB> break # found <TAB><TAB><TAB><TAB> p . moveToParent ( ) <TAB><TAB><TAB> # not found. <TAB> return p",if p . hasNext ( ) :,if p . v . next :,92.99394820256323,95.79,False
48,"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB><TAB> value = getattr ( obj , attr , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> name = name_fmt % attr <TAB><TAB> if formatter is not None : <TAB><TAB><TAB> value = formatter ( attr , value ) <TAB><TAB> info_add ( name , value )",if value is None :,if value is None :,100.0,100.00,True
49,"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB><TAB><TAB> if attr != None : <TAB><TAB><TAB><TAB> yield attr <TAB><TAB><TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB><TAB><TAB><TAB> yield element","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :","if desc . getAttributeNodeNS ( namespace , name ) != None :",71.81764257981091,90.13,False
50,def run ( self ) : <TAB> while not self . completed : <TAB><TAB> if self . block : <TAB><TAB><TAB> time . sleep ( self . period ) <TAB><TAB> else : <TAB><TAB><TAB> self . _completed . wait ( self . period ) <TAB><TAB> self . counter + = 1 <TAB><TAB> try : <TAB><TAB><TAB> self . callback ( self . counter ) <TAB><TAB> except Exception : <TAB><TAB><TAB> self . stop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> dt = time . time ( ) - self . _start_time <TAB><TAB><TAB> if dt > self . timeout : <TAB><TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . counter == self . count : <TAB><TAB><TAB> self . stop ( ),if self . timeout is not None :,if self . counter == self . count :,90.91551896168193,96.76,False
51,"def _parse_fixits ( message , titer , line ) : <TAB> """"""Parses fixit messages."""""" <TAB> while ( <TAB><TAB> OutputParser . message_line_re . match ( line ) is None <TAB><TAB> and OutputParser . note_line_re . match ( line ) is None <TAB> ) : <TAB><TAB> message_text = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> message . fixits . append ( <TAB><TAB><TAB><TAB> Note ( <TAB><TAB><TAB><TAB><TAB> message . path , <TAB><TAB><TAB><TAB><TAB> message . line , <TAB><TAB><TAB><TAB><TAB> line . find ( message_text ) + 1 , <TAB><TAB><TAB><TAB><TAB> message_text , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> line = next ( titer ) <TAB> return line","if message_text != """" :",if message_text :,74.59228814222381,97.86,False
52,"def _connect_db ( self , force_reconnect = False ) : <TAB> thread_id = thread . get_ident ( ) <TAB> if force_reconnect and thread_id in ENGINES : <TAB><TAB> del ENGINES [ thread_id ] <TAB> conn = None <TAB> try : <TAB><TAB> engine = ENGINES [ thread_id ] <TAB><TAB> conn = engine . connect ( ) <TAB><TAB> _test = conn . execute ( "" SELECT 1 "" ) <TAB><TAB> _test . fetchall ( ) <TAB> except ( KeyError , MySQLdb . OperationalError ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> conn . close ( ) <TAB><TAB> engine = sqla . create_engine ( self . db_url , pool_recycle = 3600 ) <TAB><TAB> ENGINES [ thread_id ] = engine <TAB><TAB> conn = engine . connect ( ) <TAB> return conn",if conn :,if conn :,100.0,100.00,True
53,"def read ( self , n ) : <TAB> if self . current_frame : <TAB><TAB> data = self . current_frame . read ( n ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current_frame = None <TAB><TAB><TAB> return self . file_read ( n ) <TAB><TAB> if len ( data ) < n : <TAB><TAB><TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB><TAB> return data <TAB> else : <TAB><TAB> return self . file_read ( n )",if not data and n != 0 :,if not data :,66.94916998831721,95.53,False
54,"def __setLoadCmd ( self ) : <TAB> base = self . __rawLoadCmd <TAB> for _ in range ( self . __machHeader . ncmds ) : <TAB><TAB> command = LOAD_COMMAND . from_buffer_copy ( base ) <TAB><TAB> <MASK> <TAB><TAB><TAB> segment = SEGMENT_COMMAND . from_buffer_copy ( base ) <TAB><TAB><TAB> self . __setSections ( segment , base [ 56 : ] , 32 ) <TAB><TAB> elif command . cmd == MACHOFlags . LC_SEGMENT_64 : <TAB><TAB><TAB> segment = SEGMENT_COMMAND64 . from_buffer_copy ( base ) <TAB><TAB><TAB> self . __setSections ( segment , base [ 72 : ] , 64 ) <TAB><TAB> base = base [ command . cmdsize : ]",if command . cmd == MACHOFlags . LC_SEGMENT :,if command . cmd == MACHOFlags . LC_SEGMENT_128 :,98.8691352232095,98.28,False
55,"def emit_post_sync_signal ( created_models , verbosity , interactive , db ) : <TAB> # Emit the post_sync signal for every application. <TAB> for app in models . get_apps ( ) : <TAB><TAB> app_name = app . __name__ . split ( "" . "" ) [ - 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Running post-sync handlers for application  %s "" % app_name ) <TAB><TAB> models . signals . post_syncdb . send ( <TAB><TAB><TAB> sender = app , <TAB><TAB><TAB> app = app , <TAB><TAB><TAB> created_models = created_models , <TAB><TAB><TAB> verbosity = verbosity , <TAB><TAB><TAB> interactive = interactive , <TAB><TAB><TAB> db = db , <TAB><TAB> )",if verbosity >= 2 :,if verbosity >= 2 :,75.0,100.00,True
56,"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB><TAB> repo = _get_repo ( ) <TAB><TAB> _confirm_dangerous ( ) <TAB><TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB><TAB> if url in repo . remotes : <TAB><TAB><TAB> origin = url <TAB><TAB><TAB> url = repo . remotes . get ( origin ) <TAB><TAB> <MASK> <TAB><TAB><TAB> repo . pull ( origin_uri = url ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB><TAB> print ( command_help [ "" git pull "" ] )",if url :,if url :,75.0,100.00,True
57,"def version ( self ) : <TAB> try : <TAB><TAB> return self . _version <TAB> except AttributeError : <TAB><TAB> for line in self . _get_metadata ( self . PKG_INFO ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _version = safe_version ( line . split ( "" : "" , 1 ) [ 1 ] . strip ( ) ) <TAB><TAB><TAB><TAB> return self . _version <TAB><TAB> else : <TAB><TAB><TAB> tmpl = "" Missing  ' Version: '  header and/or  %s  file "" <TAB><TAB><TAB> raise ValueError ( tmpl % self . PKG_INFO , self )","if line . lower ( ) . startswith ( ""version:"" ) :","if line . startswith ( ""version:"" ) :",94.77823388481069,97.42,False
58,"def increment ( self , metric , labels , delta ) : <TAB> """"""Increment a value by |delta|."""""" <TAB> with self . _lock : <TAB><TAB> key = self . _get_key ( metric . name , labels ) <TAB><TAB> <MASK> <TAB><TAB><TAB> start_time = self . _store [ key ] . start_time <TAB><TAB><TAB> value = self . _store [ key ] . value + delta <TAB><TAB> else : <TAB><TAB><TAB> start_time = time . time ( ) <TAB><TAB><TAB> value = metric . default_value + delta <TAB><TAB> self . _store [ key ] = _StoreValue ( metric , labels , start_time , value )",if key in self . _store :,if key in self . _store :,100.0,100.00,True
59,"def get_current_connections ( session ) : <TAB> """"""Retrieves open connections using the the given session"""""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session . sql ( "" SHOW PROCESSLIST "" ) . execute ( ) <TAB> rows = res . fetch_all ( ) <TAB> connections = { } <TAB> for row in rows : <TAB><TAB> <MASK> <TAB><TAB><TAB> connections [ row . get_string ( "" User "" ) ] = [ row . get_string ( "" Host "" ) ] <TAB><TAB> else : <TAB><TAB><TAB> connections [ row . get_string ( "" User "" ) ] . append ( row . get_string ( "" Host "" ) ) <TAB> return connections","if row . get_string ( ""User"" ) not in connections :","if row . get_string ( ""User"" ) not in connections :",100.0,100.00,True
60,"def asset ( * paths ) : <TAB> for path in paths : <TAB><TAB> fspath = www_root + "" /assets/ "" + path <TAB><TAB> etag = "" "" <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> etag = asset_etag ( fspath ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . stat ( fspath ) <TAB><TAB> except FileNotFoundError as e : <TAB><TAB><TAB> if path == paths [ - 1 ] : <TAB><TAB><TAB><TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB><TAB><TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> continue <TAB><TAB> except Exception as e : <TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )",if env . cache_static :,"if os . name == ""nt"" :",96.92679738602492,96.66,False
61,def thread_loop ( self ) - > None : <TAB> while not self . stop_event . is_set ( ) : <TAB><TAB> time . sleep ( 1 ) <TAB><TAB> new_trials = self . study . trials <TAB><TAB> with self . lock : <TAB><TAB><TAB> need_to_add_callback = self . new_trials is None <TAB><TAB><TAB> self . new_trials = new_trials <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . doc . add_next_tick_callback ( self . update_callback ),if need_to_add_callback :,if need_to_add_callback :,100.0,100.00,True
62,"def _cache_db_tables_iterator ( tables , cache_alias , db_alias ) : <TAB> no_tables = not tables <TAB> cache_aliases = settings . CACHES if cache_alias is None else ( cache_alias , ) <TAB> db_aliases = settings . DATABASES if db_alias is None else ( db_alias , ) <TAB> for db_alias in db_aliases : <TAB><TAB> if no_tables : <TAB><TAB><TAB> tables = connections [ db_alias ] . introspection . table_names ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for cache_alias in cache_aliases : <TAB><TAB><TAB><TAB> yield cache_alias , db_alias , tables",if tables :,if tables :,100.0,100.00,True
63,"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB><TAB> if hasattr ( subscriber , "" _pyroRelease "" ) : <TAB><TAB><TAB> subscriber . _pyroRelease ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB><TAB> proxy . _pyroRelease ( ) <TAB><TAB><TAB><TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> pass <TAB><TAB> self . subscribers [ topic ] . discard ( subscriber )","if hasattr ( subscriber , ""_pyroUri"" ) :",if self . proxy_cache :,70.06944660915522,94.66,False
64,"def test_constructor ( job_id ) : <TAB> with patch ( "" apscheduler.job.Job._modify "" ) as _modify : <TAB><TAB> scheduler_mock = MagicMock ( BaseScheduler ) <TAB><TAB> job = Job ( scheduler_mock , id = job_id ) <TAB><TAB> assert job . _scheduler is scheduler_mock <TAB><TAB> assert job . _jobstore_alias is None <TAB><TAB> modify_kwargs = _modify . call_args [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> assert len ( modify_kwargs [ "" id "" ] ) == 32 <TAB><TAB> else : <TAB><TAB><TAB> assert modify_kwargs [ "" id "" ] == job_id",if job_id is None :,"if isinstance ( modify_kwargs [ ""id"" ] , ( list , tuple ) ) :",65.46352525748627,90.64,False
65,"def get_connection ( self ) : <TAB> if self . config . proxy_host != "" "" : <TAB><TAB> return httplib . HTTPConnection ( self . config . proxy_host , self . config . proxy_port ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return httplib . HTTPSConnection ( self . config . simpledb_host ) <TAB><TAB> else : <TAB><TAB><TAB> return httplib . HTTPConnection ( self . config . simpledb_host )",if self . config . use_https :,if self . config . use_https :,75.0,100.00,True
66,"def notify_login ( self , ipaddress = "" "" ) : <TAB> if app . NOTIFY_ON_LOGIN : <TAB><TAB> update_text = common . notifyStrings [ common . NOTIFY_LOGIN_TEXT ] <TAB><TAB> title = common . notifyStrings [ common . NOTIFY_LOGIN ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _notify_pht ( title , update_text . format ( ipaddress ) )",if update_text and title and ipaddress :,if title :,67.34422103283694,92.07,False
67,"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB><TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB><TAB> # Set radio button layout <TAB><TAB> if item [ "" layout "" ] == "" horiz "" : <TAB><TAB><TAB> return 0.03 + ctrl . labelHeight * 3 <TAB><TAB> <MASK> <TAB><TAB><TAB> # for vertical take into account the nOptions <TAB><TAB><TAB> return ctrl . labelHeight * len ( item [ "" options "" ] )","elif item [ ""layout"" ] == ""vert"" :","elif item [ ""layout"" ] == ""horizontal"" :",98.96076013483109,98.64,False
68,"def _get_errors_lines ( self ) : <TAB> """"""Return the number of lines that contains errors to highlight."""""" <TAB> errors_lines = [ ] <TAB> block = self . document ( ) . begin ( ) <TAB> while block . isValid ( ) : <TAB><TAB> user_data = get_user_data ( block ) <TAB><TAB> <MASK> <TAB><TAB><TAB> errors_lines . append ( block . blockNumber ( ) ) <TAB><TAB> block = block . next ( ) <TAB> return errors_lines",if user_data . error :,if user_data . errors :,98.34064158234985,98.13,False
69,"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB><TAB> self . is_pulsing = False <TAB><TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB><TAB> self . pbar . set_text ( progress ) <TAB><TAB> if frac > 1 : <TAB><TAB><TAB> frac = 1.0 <TAB><TAB> <MASK> <TAB><TAB><TAB> frac = 0 <TAB><TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB><TAB> gtk . gdk . threads_leave ( )",if frac < 0 :,elif frac == 0 :,70.6297740573608,96.93,False
70,"def list_files ( basedir ) : <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os . path . isdir ( basedir ) : <TAB><TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB><TAB> d = directories . pop ( ) <TAB><TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB><TAB><TAB> filename = os . path . join ( d , basename ) <TAB><TAB><TAB> if os . path . isdir ( os . path . join ( basedir , filename ) ) : <TAB><TAB><TAB><TAB> directories . append ( filename ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield filename","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",elif os . path . isfile ( filename ) :,69.33457147674187,93.96,False
71,"def assistive ( self ) : <TAB> """"""Detects if item can be used as assistance"""""" <TAB> # Make sure we cache results <TAB> if self . __assistive is None : <TAB><TAB> assistive = False <TAB><TAB> # Go through all effects and find first assistive <TAB><TAB> for effect in self . effects . values ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # If we find one, stop and mark item as assistive <TAB><TAB><TAB><TAB> assistive = True <TAB><TAB><TAB><TAB> break <TAB><TAB> self . __assistive = assistive <TAB> return self . __assistive",if effect . isAssistance is True :,if effect . assistive is None :,97.56931764884094,97.54,False
72,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB><TAB> for col in range ( self . width ) : <TAB><TAB><TAB> if filter is None or ( row , col ) not in filter : <TAB><TAB><TAB><TAB> if self . map [ row ] [ col ] == UNSEEN : <TAB><TAB><TAB><TAB><TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen",if dist < min_dist :,if dist < min_dist :,100.0,100.00,True
73,"def _maybe_has_default_route ( self ) : <TAB> for route in self . iter_routes ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> for iface in self . iter_interfaces ( ) : <TAB><TAB> for subnet in iface . get ( "" subnets "" , [ ] ) : <TAB><TAB><TAB> for route in subnet . get ( "" routes "" , [ ] ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if self . _is_default_route ( route ) :,"if route . get ( ""name"" , """" ) == route . get ( ""name""",52.696555579186196,77.08,False
74,"def data ( self , data ) : <TAB> if data is None : <TAB><TAB> raise Exception ( "" Data cannot be None "" ) <TAB> val = [ ] <TAB> for d in data : <TAB><TAB> if isinstance ( d , str ) : <TAB><TAB><TAB> val . append ( bytes ( d , "" utf-8 "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> val . append ( d ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Invalid type, data can only be an str or a bytes not  {} :  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> type ( data ) , d <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> self . __data = val","elif isinstance ( d , bytes ) :","elif isinstance ( d , bytes ) :",100.0,100.00,True
75,"def get_one_segment_function ( data , context , echoerr ) : <TAB> ext = data [ "" ext "" ] <TAB> function_name = context [ - 2 ] [ 1 ] . get ( "" function "" ) <TAB> if function_name : <TAB><TAB> module , function_name = get_function_strings ( function_name , context , ext ) <TAB><TAB> func = import_segment ( function_name , data , context , echoerr , module = module ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield func",if func :,if func :,100.0,100.00,True
76,"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB><TAB> if isinstance ( value , list ) : <TAB><TAB><TAB> for item in value : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . visit ( item , parents ) <TAB><TAB> elif isinstance ( value , AST ) : <TAB><TAB><TAB> self . visit ( value , parents )","if isinstance ( item , AST ) :","if isinstance ( item , AST ) :",100.0,100.00,True
77,"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB><TAB> v = f . features [ name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB> if name . startswith ( "" SCE_ "" ) : <TAB><TAB><TAB><TAB><TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB><TAB><TAB><TAB><TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","if v [ ""Category"" ] != ""Deprecated"" :","if v [ ""FeatureType"" ] == ""constant"" :",97.7305293424143,96.53,False
78,"def things ( self , query ) : <TAB> limit = query . pop ( "" limit "" , 100 ) <TAB> offset = query . pop ( "" offset "" , 0 ) <TAB> keys = set ( self . docs ) <TAB> for k , v in query . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # query keys need to be flattened properly, <TAB><TAB><TAB> # this corrects any nested keys that have been included <TAB><TAB><TAB> # in values. <TAB><TAB><TAB> flat = common . flatten_dict ( v ) [ 0 ] <TAB><TAB><TAB> k + = "" . "" + web . rstrips ( flat [ 0 ] , "" .key "" ) <TAB><TAB><TAB> v = flat [ 1 ] <TAB><TAB> keys = set ( k for k in self . filter_index ( self . index , k , v ) if k in keys ) <TAB> keys = sorted ( keys ) <TAB> return keys [ offset : offset + limit ]","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",100.0,100.00,True
79,"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB><TAB> if self . _keys [ hash_ ] is self . _empty : <TAB><TAB><TAB> # That key was never assigned <TAB><TAB><TAB> return None <TAB><TAB> <MASK> <TAB><TAB><TAB> # key found, assign with deleted sentinel <TAB><TAB><TAB> self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _len - = 1 <TAB><TAB><TAB> return <TAB><TAB> hash_ = self . _rehash ( hash_ ) <TAB><TAB> if initial_hash == hash_ : <TAB><TAB><TAB> # table is full and wrapped around <TAB><TAB><TAB> return None",elif self . _keys [ hash_ ] == key :,if self . _keys [ hash_ ] is self . _empty :,97.01942329512784,96.30,False
80,"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB><TAB> response = self . fetch ( "" /?error=1 "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" requires HTTP/1.x "" ) <TAB><TAB> if self . http_client . configured_class != SimpleAsyncHTTPClient : <TAB><TAB><TAB> self . skipTest ( "" curl client accepts invalid headers "" ) <TAB><TAB> self . assertEqual ( response . code , 599 )",if not self . http1 :,if response . code == 204 :,71.82480316294372,95.50,False
81,"def __str__ ( self ) - > str : <TAB> text = "" \n "" <TAB> for k , r in self . result . items ( ) : <TAB><TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text + = "" #  {}  (failed) \n "" . format ( k ) <TAB><TAB> else : <TAB><TAB><TAB> text + = "" #  {}  (succeeded) \n "" . format ( k ) <TAB><TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB><TAB> for sub_r in r : <TAB><TAB><TAB> text + = "" ****  {} \n "" . format ( sub_r . name ) <TAB><TAB><TAB> text + = "" {} \n "" . format ( sub_r ) <TAB> return text",if r . failed :,if r is None :,96.05959932939471,98.48,False
82,"def DeleteTask ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB><TAB> result = Mongo . coll [ "" Task "" ] . delete_one ( { "" _id "" : ObjectId ( oid ) } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = Mongo . coll [ "" Result "" ] . delete_many ( { "" task_id "" : ObjectId ( oid ) } ) <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> return "" success "" <TAB> return "" fail """,if result . deleted_count > 0 :,if not result :,67.77573235316507,94.37,False
83,"def _replace_vars ( self , line , extracted , env_variables ) : <TAB> for e in extracted : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = env_variables . get ( e ) <TAB><TAB><TAB> if isinstance ( value , dict ) or isinstance ( value , list ) : <TAB><TAB><TAB><TAB> value = pprint . pformat ( value ) <TAB><TAB><TAB> decorated = self . _decorate_var ( e ) <TAB><TAB><TAB> line = line . replace ( decorated , str ( value ) ) <TAB> return line",if e in env_variables :,if e in self . _vars :,95.30572918108965,96.43,False
84,"def should_include ( service ) : <TAB> for f in filt : <TAB><TAB> if f == "" status "" : <TAB><TAB><TAB> state = filt [ f ] <TAB><TAB><TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB><TAB><TAB> if not has_container_with_state ( containers , state ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif f == "" source "" : <TAB><TAB><TAB> source = filt [ f ] <TAB><TAB><TAB> if source == "" image "" or source == "" build "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB><TAB> else : <TAB><TAB><TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True",if source not in service . options :,if not has_source_filter ( source ) :,89.56832416506887,96.34,False
85,def state_callback_loop ( ) : <TAB> if usercallback : <TAB><TAB> when = 1 <TAB><TAB> while ( <TAB><TAB><TAB> when <TAB><TAB><TAB> and not self . future_removed . done ( ) <TAB><TAB><TAB> and not self . session . shutdownstarttime <TAB><TAB> ) : <TAB><TAB><TAB> result = usercallback ( self . get_state ( ) ) <TAB><TAB><TAB> when = ( await result ) if iscoroutine ( result ) else result <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> await sleep ( when ),if when > 0.0 and not self . session . shutdownstarttime :,if when :,62.80056339450598,93.55,False
86,"def __get_new_timeout ( self , timeout ) : <TAB> """"""When using --timeout_multiplier=#.#"""""" <TAB> self . __check_scope ( ) <TAB> try : <TAB><TAB> timeout_multiplier = float ( self . timeout_multiplier ) <TAB><TAB> <MASK> <TAB><TAB><TAB> timeout_multiplier = 0.5 <TAB><TAB> timeout = int ( math . ceil ( timeout_multiplier * timeout ) ) <TAB><TAB> return timeout <TAB> except Exception : <TAB><TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB><TAB> return timeout",if timeout_multiplier <= 0.5 :,if timeout_multiplier < 0.5 :,98.30529300357543,98.40,False
87,"def readexactly ( self , n ) : <TAB> buf = b "" "" <TAB> while n : <TAB><TAB> yield IORead ( self . s ) <TAB><TAB> res = self . s . read ( n ) <TAB><TAB> assert res is not None <TAB><TAB> <MASK> <TAB><TAB><TAB> yield IOReadDone ( self . s ) <TAB><TAB><TAB> break <TAB><TAB> buf + = res <TAB><TAB> n - = len ( res ) <TAB> return buf",if not res :,if len ( res ) == 0 :,66.12643729605637,93.61,False
88,"def contract_rendering_pane ( event ) : <TAB> """"""Expand the rendering pane."""""" <TAB> c = event . get ( "" c "" ) <TAB> if c : <TAB><TAB> vr = c . frame . top . findChild ( QtWidgets . QWidget , "" viewrendered_pane "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> vr . contract ( ) <TAB><TAB> else : <TAB><TAB><TAB> # Just open the pane. <TAB><TAB><TAB> viewrendered ( event )",if vr :,if vr :,100.0,100.00,True
89,"def translate_headers ( self , environ ) : <TAB> """"""Translate CGI-environ header names to HTTP header names."""""" <TAB> for cgiName in environ : <TAB><TAB> # We assume all incoming header keys are uppercase already. <TAB><TAB> <MASK> <TAB><TAB><TAB> yield self . headerNames [ cgiName ] , environ [ cgiName ] <TAB><TAB> elif cgiName [ : 5 ] == "" HTTP_ "" : <TAB><TAB><TAB> # Hackish attempt at recovering original header names. <TAB><TAB><TAB> translatedHeader = cgiName [ 5 : ] . replace ( "" _ "" , "" - "" ) <TAB><TAB><TAB> yield translatedHeader , environ [ cgiName ]",if cgiName in self . headerNames :,if cgiName in self . headerNames :,100.0,100.00,True
90,"def get_value_from_string ( self , string_value ) : <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> string_value = str ( string_value ) . strip ( ) <TAB><TAB><TAB> if string_value != "" NONE "" : <TAB><TAB><TAB><TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB><TAB> self . pcluster_config . warn ( <TAB><TAB><TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB><TAB><TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB><TAB> ) <TAB> return param_value",if string_value is not None :,if string_value :,94.02144009834493,97.98,False
91,"def monitor_filter ( self ) : <TAB> """"""Return filtered service objects list"""""" <TAB> services = self . client . services . list ( filters = { "" label "" : "" com.ouroboros.enable "" } ) <TAB> monitored_services = [ ] <TAB> for service in services : <TAB><TAB> ouro_label = service . attrs [ "" Spec "" ] [ "" Labels "" ] . get ( "" com.ouroboros.enable "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> monitored_services . append ( service ) <TAB> self . data_manager . monitored_containers [ self . socket ] = len ( monitored_services ) <TAB> self . data_manager . set ( self . socket ) <TAB> return monitored_services","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",if ouro_label :,65.9390351805973,86.23,False
92,"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB><TAB> if len ( self . _editableChildren ) : <TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB><TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB> if ref in self . _editableChildren : <TAB><TAB><TAB><TAB> cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB> nei = cei + 1 <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> nei = 0 <TAB><TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if nei >= len ( self . _editableChildren ) :,if nei == cei :,85.19284809402792,95.37,False
93,"def linkify_cm_by_tp ( self , timeperiods ) : <TAB> for rm in self : <TAB><TAB> mtp_name = rm . modulation_period . strip ( ) <TAB><TAB> # The new member list, in id <TAB><TAB> mtp = timeperiods . find_by_name ( mtp_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> err = ( <TAB><TAB><TAB><TAB> "" Error: the business impact modulation  ' %s '  got an unknown  "" <TAB><TAB><TAB><TAB> "" modulation_period  ' %s ' "" % ( rm . get_name ( ) , mtp_name ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> rm . configuration_errors . append ( err ) <TAB><TAB> rm . modulation_period = mtp","if mtp_name != """" and mtp is None :",if mtp is None :,97.14952544518958,95.75,False
94,def close_open_fds ( keep = None ) : # noqa <TAB> keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB> for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> os . close ( fd ) <TAB><TAB><TAB> except OSError as exc : <TAB><TAB><TAB><TAB> if exc . errno != errno . EBADF : <TAB><TAB><TAB><TAB><TAB> raise,if fd not in keep :,if fd not in keep :,100.0,100.00,True
95,"def _append_child_from_unparsed_xml ( father_node , unparsed_xml ) : <TAB> """"""Append child xml nodes to a node."""""" <TAB> dom_tree = parseString ( unparsed_xml ) <TAB> if dom_tree . hasChildNodes ( ) : <TAB><TAB> first_child = dom_tree . childNodes [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> child_nodes = first_child . childNodes <TAB><TAB><TAB> for _ in range ( len ( child_nodes ) ) : <TAB><TAB><TAB><TAB> childNode = child_nodes . item ( 0 ) <TAB><TAB><TAB><TAB> father_node . appendChild ( childNode ) <TAB><TAB><TAB> return <TAB> raise DistutilsInternalError ( <TAB><TAB> "" Could not Append append elements to  "" "" the Windows msi descriptor. "" <TAB> )",if first_child . hasChildNodes ( ) :,if first_child . nodeType == dom_tree . ELEMENT_NODE :,94.15384699107037,94.87,False
96,"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB><TAB> request . uri = request . uri . replace ( old , new ) <TAB><TAB> <MASK> <TAB><TAB><TAB> body = six . ensure_str ( request . body ) <TAB><TAB><TAB> if old in body : <TAB><TAB><TAB><TAB> request . body = body . replace ( old , new ) <TAB> return request",if is_text_payload ( request ) and request . body :,if request . body :,69.71385187387456,91.52,False
97,"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB><TAB> from pygments . lexers . _luabuiltins import MODULES <TAB><TAB> for mod , func in MODULES . iteritems ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options )",if mod not in self . disabled_modules :,if mod in self . func_name_highlighting :,72.42544920509305,95.69,False
98,"def GetBestSizeForParentSize ( self , parentSize ) : <TAB> """"""Finds the best width and height given the parent's width and height."""""" <TAB> if len ( self . GetChildren ( ) ) == 1 : <TAB><TAB> win = self . GetChildren ( ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> temp_dc = wx . ClientDC ( self ) <TAB><TAB><TAB> childSize = win . GetBestSizeForParentSize ( parentSize ) <TAB><TAB><TAB> clientParentSize = self . _art . GetPanelClientSize ( <TAB><TAB><TAB><TAB> temp_dc , self , wx . Size ( * parentSize ) , None <TAB><TAB><TAB> ) <TAB><TAB><TAB> overallSize = self . _art . GetPanelSize ( <TAB><TAB><TAB><TAB> temp_dc , self , wx . Size ( * clientParentSize ) , None <TAB><TAB><TAB> ) <TAB><TAB><TAB> return overallSize <TAB> return self . GetSize ( )","if isinstance ( win , RibbonControl ) :",if win . GetWidth ( ) == parentSize :,77.16626568021843,96.38,False
99,"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB><TAB> try : <TAB><TAB><TAB> pid = int ( pid ) <TAB><TAB><TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return pid <TAB><TAB><TAB> if name in cmdline . split ( ""   "" , 1 ) [ 0 ] : <TAB><TAB><TAB><TAB> return pid <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name )",if name in pname :,"if pname == ""pid"" :",68.94774525473562,96.04,False
100,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB><TAB> if idx == num : <TAB><TAB><TAB> return element <TAB><TAB> <MASK> <TAB><TAB><TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB> if not isinstance ( i , int ) : <TAB><TAB><TAB><TAB> return i <TAB><TAB><TAB> idx = i <TAB><TAB> else : <TAB><TAB><TAB> idx + = 1 <TAB> return idx",if element [ 3 ] and element [ 4 ] :,if element [ 3 ] :,92.13123854695223,96.72,False
101,"def scan_block_scalar_indentation ( self ) : <TAB> # See the specification for details. <TAB> chunks = [ ] <TAB> max_indent = 0 <TAB> end_mark = self . get_mark ( ) <TAB> while self . peek ( ) in ""   \r \n \x85 \u2028 \u2029 "" : <TAB><TAB> if self . peek ( ) != ""   "" : <TAB><TAB><TAB> chunks . append ( self . scan_line_break ( ) ) <TAB><TAB><TAB> end_mark = self . get_mark ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . forward ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> max_indent = self . column <TAB> return chunks , max_indent , end_mark",if self . column > max_indent :,if self . column > max_indent :,75.0,100.00,True
102,"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB><TAB> tmp + = "" m  "" <TAB><TAB> for col in row : <TAB><TAB><TAB> if col == LAND : <TAB><TAB><TAB><TAB> tmp + = "" . "" <TAB><TAB><TAB> elif col == BARRIER : <TAB><TAB><TAB><TAB> tmp + = "" % "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp + = "" * "" <TAB><TAB><TAB> elif col == UNSEEN : <TAB><TAB><TAB><TAB> tmp + = "" ? "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> players [ col ] = True <TAB><TAB><TAB><TAB> tmp + = chr ( col + 97 ) <TAB><TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == FOOD :,elif col == LEGAL :,99.19101256226242,99.16,False
103,"def prepare_data ( entry ) : <TAB> branch_wise_entries = { } <TAB> gross_pay = 0 <TAB> for d in entry : <TAB><TAB> gross_pay + = d . gross_pay <TAB><TAB> <MASK> <TAB><TAB><TAB> branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB><TAB> else : <TAB><TAB><TAB> branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB><TAB><TAB><TAB> d . mode_of_payment , d . net_pay <TAB><TAB><TAB> ) <TAB> return branch_wise_entries , gross_pay",if branch_wise_entries . get ( d . branch ) :,if d . branch in branch_wise_entries :,65.986544508957,95.41,False
104,"def __init__ ( self , uuid = None , cluster_state = None , children = None , * * kwargs ) : <TAB> self . uuid = uuid <TAB> self . cluster_state = cluster_state <TAB> if self . cluster_state is not None : <TAB><TAB> self . children = WeakSet ( <TAB><TAB><TAB> self . cluster_state . tasks . get ( task_id ) <TAB><TAB><TAB> for task_id in children or ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB> ) <TAB> else : <TAB><TAB> self . children = WeakSet ( ) <TAB> self . _serializer_handlers = { <TAB><TAB> "" children "" : self . _serializable_children , <TAB><TAB> "" root "" : self . _serializable_root , <TAB><TAB> "" parent "" : self . _serializable_parent , <TAB> } <TAB> if kwargs : <TAB><TAB> self . __dict__ . update ( kwargs )",if task_id in self . cluster_state . tasks,if task_id not in self . cluster_state . tasks,99.2709649799814,98.99,False
105,"def listdir ( self , d ) : <TAB> try : <TAB><TAB> return [ <TAB><TAB><TAB> p <TAB><TAB><TAB> for p in os . listdir ( d ) <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB> except OSError : <TAB><TAB> return [ ]","if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",if p . startswith ( self . prefix ) and p . endswith ( self . prefix ),45.73545648857834,73.01,False
106,"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB><TAB> self . connect ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> command = [ command ] <TAB><TAB> for item in command : <TAB><TAB><TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB><TAB> self . disconnect ( ) <TAB><TAB> if len ( e . args ) == 1 : <TAB><TAB><TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> _errno , errmsg = e . args <TAB><TAB> raise ConnectionError ( <TAB><TAB><TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB><TAB> ) <TAB> except Exception : <TAB><TAB> self . disconnect ( ) <TAB><TAB> raise","if isinstance ( command , str ) :","if not isinstance ( command , list ) :",73.39460172421006,98.04,False
107,"def run ( self ) : <TAB> """"""Start the scanner"""""" <TAB> logging . info ( "" Dirscanner starting up "" ) <TAB> self . shutdown = False <TAB> while not self . shutdown : <TAB><TAB> # Wait to be woken up or triggered <TAB><TAB> with self . loop_condition : <TAB><TAB><TAB> self . loop_condition . wait ( self . dirscan_speed ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . scan ( )",if self . dirscan_speed and not self . shutdown :,if self . loop_condition . is_set ( ) :,94.86652491752533,92.25,False
108,"def __aexit__ ( <TAB> self , exc_type : type , exc_value : BaseException , tb : TracebackType ) - > None : <TAB> if exc_type is not None : <TAB><TAB> await self . close ( ) <TAB> await self . _task <TAB> while not self . _receive_queue . empty ( ) : <TAB><TAB> data = await self . _receive_queue . get ( ) <TAB><TAB> if isinstance ( data , bytes ) : <TAB><TAB><TAB> self . response_data . extend ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise data","elif not isinstance ( data , HTTPDisconnect ) :",if exc_type is not None :,66.3639301164322,94.04,False
109,"def f ( msg ) : <TAB> text = extractor ( msg ) <TAB> for px in prefix : <TAB><TAB> <MASK> <TAB><TAB><TAB> chunks = text [ len ( px ) : ] . split ( separator ) <TAB><TAB><TAB> return chunks [ 0 ] , ( chunks [ 1 : ] , ) if pass_args else ( ) <TAB> return ( ( None , ) , ) # to distinguish with `None`",if text . startswith ( px ) :,if text . startswith ( px ) :,100.0,100.00,True
110,"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB><TAB> for item in args : <TAB><TAB><TAB> if type ( item ) is ActionHandle : <TAB><TAB><TAB><TAB> ahs . add ( item ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for ah in item : <TAB><TAB><TAB><TAB><TAB> if type ( ah ) is not ActionHandle : # pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB> ahs . add ( ah ) <TAB><TAB><TAB> else : # pragma:nocover <TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs","elif type ( item ) in ( list , tuple , dict , set ) :","elif isinstance ( item , ( list , tuple ) ) :",93.42635058299874,95.58,False
111,"def find_class ( self , module , name ) : <TAB> # Subclasses may override this. <TAB> sys . audit ( "" pickle.find_class "" , module , name ) <TAB> if self . proto < 3 and self . fix_imports : <TAB><TAB> if ( module , name ) in _compat_pickle . NAME_MAPPING : <TAB><TAB><TAB> module , name = _compat_pickle . NAME_MAPPING [ ( module , name ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> module = _compat_pickle . IMPORT_MAPPING [ module ] <TAB> __import__ ( module , level = 0 ) <TAB> if self . proto > = 4 : <TAB><TAB> return _getattribute ( sys . modules [ module ] , name ) [ 0 ] <TAB> else : <TAB><TAB> return getattr ( sys . modules [ module ] , name )",elif module in _compat_pickle . IMPORT_MAPPING :,elif module in _compat_pickle . IMPORT_MAPPING :,75.0,100.00,True
112,"def _send_until_done ( self , data ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> return self . connection . send ( data ) <TAB><TAB> except OpenSSL . SSL . WantWriteError : <TAB><TAB><TAB> wr = util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise timeout ( ) <TAB><TAB><TAB> continue <TAB><TAB> except OpenSSL . SSL . SysCallError as e : <TAB><TAB><TAB> raise SocketError ( str ( e ) )",if not wr :,if wr is None :,70.30170956979134,97.32,False
113,"def __new__ ( cls , * args , * * kwargs ) : <TAB> """"""Hack to ensure method defined as async are implemented as such."""""" <TAB> coroutines = inspect . getmembers ( BaseManager , predicate = inspect . iscoroutinefunction ) <TAB> for coroutine in coroutines : <TAB><TAB> implemented_method = getattr ( cls , coroutine [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" The method  %s  must be a coroutine "" % implemented_method ) <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )",if not inspect . iscoroutinefunction ( implemented_method ) :,"if not implemented_method . __contains__ ( ""coroutine"" ) :",67.52574946115475,91.82,False
114,"def add_directive ( self , name , obj , content = None , arguments = None , * * options ) : <TAB> if isinstance ( obj , clstypes ) and issubclass ( obj , Directive ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ExtensionError ( <TAB><TAB><TAB><TAB> "" when adding directive classes, no  "" "" additional arguments may be given "" <TAB><TAB><TAB> ) <TAB><TAB> directives . register_directive ( name , directive_dwim ( obj ) ) <TAB> else : <TAB><TAB> obj . content = content <TAB><TAB> obj . arguments = arguments <TAB><TAB> obj . options = options <TAB><TAB> directives . register_directive ( name , obj )",if content or arguments or options :,if arguments is None :,92.75213790918926,96.47,False
115,"def create ( self , w ) : <TAB> if w . use_eventloop : <TAB><TAB> # does not use dedicated timer thread. <TAB><TAB> w . timer = _Timer ( max_interval = 10.0 ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Default Timer is set by the pool, as for example, the <TAB><TAB><TAB> # eventlet pool needs a custom timer implementation. <TAB><TAB><TAB> w . timer_cls = w . pool_cls . Timer <TAB><TAB> w . timer = self . instantiate ( <TAB><TAB><TAB> w . timer_cls , <TAB><TAB><TAB> max_interval = w . timer_precision , <TAB><TAB><TAB> on_error = self . on_timer_error , <TAB><TAB><TAB> on_tick = self . on_timer_tick , <TAB><TAB> )",if not w . timer_cls :,if w . timer_cls is None :,97.80012928016639,97.81,False
116,"def _config ( _molecule_file , request ) : <TAB> with open ( _molecule_file ) as f : <TAB><TAB> d = util . safe_load ( f ) <TAB> if hasattr ( request , "" param "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> d2 = util . safe_load ( request . getfixturevalue ( request . param ) ) <TAB><TAB> else : <TAB><TAB><TAB> d2 = request . getfixturevalue ( request . param ) <TAB><TAB> # print(100, d) <TAB><TAB> # print(200, d2) <TAB><TAB> d = util . merge_dicts ( d , d2 ) <TAB><TAB> # print(300, d) <TAB> return d","if isinstance ( request . getfixturevalue ( request . param ) , str ) :","if isinstance ( request . param , dict ) :",92.49197455740213,95.62,False
117,"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB><TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB><TAB> <MASK> <TAB><TAB><TAB> new_layer = self . _instrument ( value ) <TAB><TAB><TAB> if new_layer is not value : <TAB><TAB><TAB><TAB> setattr ( model , key , new_layer ) <TAB><TAB> elif isinstance ( value , list ) : <TAB><TAB><TAB> for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB> if isinstance ( item , tf . keras . layers . Layer ) : <TAB><TAB><TAB><TAB><TAB> value [ i ] = self . _instrument ( item ) <TAB> return model","if isinstance ( value , tf . keras . layers . Layer ) :","if isinstance ( value , ( dict , list ) ) :",96.62170299666512,96.14,False
118,"def is_accepted_drag_event ( self , event ) : <TAB> if event . source ( ) == self . table : <TAB><TAB> return True <TAB> mime = event . mimeData ( ) <TAB> if mime . hasUrls ( ) : <TAB><TAB> for url in mime . urls ( ) : <TAB><TAB><TAB> # Only support local files. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> # And only allow supported extensions. <TAB><TAB><TAB> filename = url . toLocalFile ( ) <TAB><TAB><TAB> extension = os . path . splitext ( filename ) [ 1 ] . lower ( ) [ 1 : ] <TAB><TAB><TAB> if extension not in _dictionary_formats ( ) : <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> return True <TAB> return False",if not url . isLocalFile ( ) :,if not url . isLocalFile ( ) :,100.0,100.00,True
119,"def explain ( self , other , depth = 0 ) : <TAB> exp = super ( UnionType , self ) . explain ( other , depth ) <TAB> for ndx , subtype in enumerate ( self . params [ "" allowed_types "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> exp + = "" \n {} and "" . format ( "" "" . join ( [ "" \t "" ] * depth ) ) <TAB><TAB> exp + = "" \n "" + subtype . explain ( other , depth = depth + 1 ) <TAB> return exp",if ndx > 0 :,if ndx == 0 :,98.74552779795805,97.31,False
120,"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB> seen = [ False , False ] <TAB> for i in sm . xrange ( 100 ) : <TAB><TAB> observed = aug . augment_image ( self . base_img ) <TAB><TAB> if np . array_equal ( observed , self . blur3x3 ) : <TAB><TAB><TAB> seen [ 0 ] + = True <TAB><TAB> <MASK> <TAB><TAB><TAB> seen [ 1 ] + = True <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB><TAB> if all ( seen ) : <TAB><TAB><TAB> break <TAB> assert np . all ( seen )","elif np . array_equal ( observed , self . blur5x5 ) :","elif np . array_equal ( observed , self . blur5x5 ) :",75.0,100.00,True
121,"def test_get_message ( self ) : <TAB> async with self . chat_client : <TAB><TAB> await self . _create_thread ( ) <TAB><TAB> async with self . chat_thread_client : <TAB><TAB><TAB> message_id = await self . _send_message ( ) <TAB><TAB><TAB> message = await self . chat_thread_client . get_message ( message_id ) <TAB><TAB><TAB> assert message . id == message_id <TAB><TAB><TAB> assert message . type == ChatMessageType . TEXT <TAB><TAB><TAB> assert message . content . message == "" hello world "" <TAB><TAB> # delete chat threads <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . chat_client . delete_chat_thread ( self . thread_id )",if not self . is_playback ( ) :,if self . thread_id :,96.55096491665603,95.97,False
122,"def do_write_property ( self , device , callback = None ) : <TAB> try : <TAB><TAB> iocb = ( <TAB><TAB><TAB> device <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else self . form_iocb ( device , request_type = "" writeProperty "" ) <TAB><TAB> ) <TAB><TAB> deferred ( self . request_io , iocb ) <TAB><TAB> self . requests_in_progress . update ( { iocb : { "" callback "" : callback } } ) <TAB><TAB> iocb . add_callback ( self . __general_cb ) <TAB> except Exception as error : <TAB><TAB> log . exception ( "" exception:  %r "" , error )","if isinstance ( device , IOCB )",if device is None,79.18326061432901,95.93,False
123,"def fit ( self , dataset , force_retrain ) : <TAB> if force_retrain : <TAB><TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB><TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB><TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB><TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> else : <TAB><TAB> if not self . sub_unit_1 [ "" fitted "" ] : <TAB><TAB><TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB><TAB><TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB><TAB><TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> return self","if not self . sub_unit_2 [ ""fitted"" ] :","if not self . sub_unit_2 [ ""fitted"" ] :",100.0,100.00,True
124,"def _insert_with_loop ( self ) : <TAB> id_list = [ ] <TAB> last_id = None <TAB> return_id_list = self . _return_id_list <TAB> for row in self . _rows : <TAB><TAB> last_id = InsertQuery ( self . model_class , row ) . upsert ( self . _upsert ) . execute ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> id_list . append ( last_id ) <TAB> <MASK> <TAB><TAB> return id_list <TAB> else : <TAB><TAB> return last_id",if return_id_list :,if id_list :,71.59961669843705,95.41,False
125,"def merge_block ( self ) : <TAB> """"""merges a block in the map"""""" <TAB> for i in range ( self . block . x ) : <TAB><TAB> for j in range ( self . block . x ) : <TAB><TAB><TAB> c = self . block . get ( i , j ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . map [ ( i + self . block . pos . x , j + self . block . pos . y ) ] = c",if c :,if c is not None :,87.27164031575445,96.54,False
126,"def configure_plex ( config ) : <TAB> core . PLEX_SSL = int ( config [ "" Plex "" ] [ "" plex_ssl "" ] ) <TAB> core . PLEX_HOST = config [ "" Plex "" ] [ "" plex_host "" ] <TAB> core . PLEX_PORT = config [ "" Plex "" ] [ "" plex_port "" ] <TAB> core . PLEX_TOKEN = config [ "" Plex "" ] [ "" plex_token "" ] <TAB> plex_section = config [ "" Plex "" ] [ "" plex_sections "" ] or [ ] <TAB> if plex_section : <TAB><TAB> <MASK> <TAB><TAB><TAB> plex_section = "" , "" . join ( plex_section ) # fix in case this imported as list. <TAB><TAB> plex_section = [ tuple ( item . split ( "" , "" ) ) for item in plex_section . split ( "" | "" ) ] <TAB> core . PLEX_SECTION = plex_section","if isinstance ( plex_section , list ) :","if not isinstance ( plex_section , list ) :",94.4963831209019,98.89,False
127,"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB><TAB> xlib . XNextEvent ( self . _display , e ) <TAB><TAB> # Key events are filtered by the xlib window event <TAB><TAB> # handler so they get a shot at the prefiltered event. <TAB><TAB> <MASK> <TAB><TAB><TAB> if xlib . XFilterEvent ( e , e . xany . window ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> dispatch = self . _window_map [ e . xany . window ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> continue <TAB><TAB> dispatch ( e )","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :",if e . xany . window in self . _window_map :,94.54121779352909,93.50,False
128,"def format_message ( self ) : <TAB> bits = [ self . message ] <TAB> if self . possibilities : <TAB><TAB> <MASK> <TAB><TAB><TAB> bits . append ( "" Did you mean  %s ? "" % self . possibilities [ 0 ] ) <TAB><TAB> else : <TAB><TAB><TAB> possibilities = sorted ( self . possibilities ) <TAB><TAB><TAB> bits . append ( "" (Possible options:  %s ) "" % "" ,  "" . join ( possibilities ) ) <TAB> return ""    "" . join ( bits )",if len ( self . possibilities ) == 1 :,if len ( self . possibilities ) == 1 :,100.0,100.00,True
129,"def _collect_logs ( model ) : <TAB> page_token = None <TAB> all_logs = [ ] <TAB> while True : <TAB><TAB> paginated_logs = model . lookup_logs ( now , later , page_token = page_token ) <TAB><TAB> page_token = paginated_logs . next_page_token <TAB><TAB> all_logs . extend ( paginated_logs . logs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return all_logs",if page_token is None :,if paginated_logs . next_page_token is None :,65.96968064182485,94.28,False
130,"def run ( self ) : <TAB> while True : <TAB><TAB> context_id_list_tuple = self . _inflated_addresses . get ( block = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> c_id , inflated_address_list = context_id_list_tuple <TAB><TAB> inflated_value_map = dict ( inflated_address_list ) <TAB><TAB> if c_id in self . _contexts : <TAB><TAB><TAB> self . _contexts [ c_id ] . set_from_tree ( inflated_value_map )",if context_id_list_tuple is _SHUTDOWN_SENTINEL :,if not context_id_list_tuple :,65.89321045496557,94.89,False
131,"def _setup_prefix ( self ) : <TAB> # we assume here that our metadata may be nested inside a ""basket"" <TAB> # of multiple eggs; that's why we use module_path instead of .archive <TAB> path = self . module_path <TAB> old = None <TAB> while path != old : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . egg_name = os . path . basename ( path ) <TAB><TAB><TAB> self . egg_info = os . path . join ( path , "" EGG-INFO "" ) <TAB><TAB><TAB> self . egg_root = path <TAB><TAB><TAB> break <TAB><TAB> old = path <TAB><TAB> path , base = os . path . split ( path )","if path . lower ( ) . endswith ( "".egg"" ) :",if os . path . isdir ( path ) :,71.00837834796887,93.64,False
132,"def get_filename ( self , prompt ) : <TAB> okay = False <TAB> val = "" "" <TAB> while not okay : <TAB><TAB> val = raw_input ( "" %s :  %s "" % ( prompt , val ) ) <TAB><TAB> val = os . path . expanduser ( val ) <TAB><TAB> if os . path . isfile ( val ) : <TAB><TAB><TAB> okay = True <TAB><TAB> <MASK> <TAB><TAB><TAB> path = val <TAB><TAB><TAB> val = self . choose_from_list ( os . listdir ( path ) ) <TAB><TAB><TAB> if val : <TAB><TAB><TAB><TAB> val = os . path . join ( path , val ) <TAB><TAB><TAB><TAB> okay = True <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> val = "" "" <TAB><TAB> else : <TAB><TAB><TAB> print ( "" Invalid value:  %s "" % val ) <TAB><TAB><TAB> val = "" "" <TAB> return val",elif os . path . isdir ( val ) :,elif os . path . isdir ( val ) :,100.0,100.00,True
133,"def versions ( self , sitename , data ) : <TAB> # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB> if "" query "" in data : <TAB><TAB> q = json . loads ( data [ "" query "" ] ) <TAB><TAB> itemid = self . _get_itemid ( q . get ( "" key "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> key = q [ "" key "" ] <TAB><TAB><TAB> return json . dumps ( [ self . dummy_edit ( key ) ] ) <TAB> # if not just go the default way <TAB> return ConnectionMiddleware . versions ( self , sitename , data )",if itemid :,if itemid is None :,73.83300004639474,97.98,False
134,"def read_stanza ( self ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> stanza_end = self . _buffer . index ( b "" \n "" ) <TAB><TAB><TAB> stanza = self . decoder . decode ( self . _buffer [ : stanza_end ] ) <TAB><TAB><TAB> self . _buffer = self . _buffer [ stanza_end + 1 : ] <TAB><TAB><TAB> colon = stanza . index ( "" : "" ) <TAB><TAB><TAB> return stanza [ : colon ] , stanza [ colon + 1 : ] <TAB><TAB> except ValueError : <TAB><TAB><TAB> bytes = self . read_bytes ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _buffer + = bytes",if not bytes :,if not bytes :,100.0,100.00,True
135,def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB><TAB> mask = 1 << bit <TAB><TAB> <MASK> <TAB><TAB><TAB> if attrnames . has_key ( mask ) : <TAB><TAB><TAB><TAB> names . append ( attrnames [ mask ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> names . append ( hex ( mask ) ) <TAB> return names,if attrs & mask :,if ( 0x80 >> bit ) in attrs :,65.88357871136633,92.73,False
136,"def _set_http_cookie ( ) : <TAB> if conf . cookie : <TAB><TAB> <MASK> <TAB><TAB><TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = "" ;  "" . join ( <TAB><TAB><TAB><TAB> map ( lambda x : "" = "" . join ( x ) , conf . cookie . items ( ) ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = conf . cookie","if isinstance ( conf . cookie , dict ) :","if isinstance ( conf . cookie , dict ) :",100.0,100.00,True
137,"def __ne__ ( self , other ) : <TAB> if isinstance ( other , WeakMethod ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self is not other <TAB><TAB> return weakref . ref . __ne__ ( self , other ) or self . _func_ref != other . _func_ref <TAB> return True",if not self . _alive or not other . _alive :,if self . _func_ref is None :,58.39235659019026,88.67,False
138,"def update_unread ( self , order_id , reset = False ) : <TAB> conn = Database . connect_database ( self . PATH ) <TAB> with conn : <TAB><TAB> cursor = conn . cursor ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cursor . execute ( <TAB><TAB><TAB><TAB> """"""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""" , ( order_id , ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> cursor . execute ( """""" UPDATE sales SET unread=0 WHERE id=?; """""" , ( order_id , ) ) <TAB><TAB> conn . commit ( ) <TAB> conn . close ( )",if reset is False :,if reset :,74.0576308572758,98.11,False
139,"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB> members = inspect . getmembers ( match ) <TAB><TAB> for member in members : <TAB><TAB><TAB> if member [ 0 ] == key : <TAB><TAB><TAB><TAB> field_value = member [ 1 ] <TAB><TAB><TAB> elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB> wildcards = member [ 1 ] <TAB><TAB> if key == "" nw_src "" : <TAB><TAB><TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB><TAB> field_value = match [ key ] <TAB> return field_value","elif key == ""nw_dst"" :","elif key == ""nw_dst"" :",100.0,100.00,True
140,"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB><TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if keep_nested is not None : <TAB><TAB><TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB><TAB><TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield k , v",if k in keep_current :,if k != keep_current :,98.49079152154178,98.13,False
141,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB><TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> elif p : <TAB><TAB><TAB> p . moveToThreadBack ( ) <TAB><TAB> elif wrapped : <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> wrapped = True <TAB><TAB><TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB><TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",if p and p . isMarked ( ) :,if p . isMarked ( ) :,83.59857408926314,98.68,False
142,"def sample ( self , * * config ) : <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( v , NestedSpace ) : <TAB><TAB><TAB><TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB><TAB><TAB><TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret [ k ] = v <TAB> return ret",if k in striped_keys :,if k not in striped_keys :,99.23175345981777,98.87,False
143,"def update_gradients_full ( self , dL_dK , X , X2 = None ) : <TAB> if self . ARD : <TAB><TAB> phi1 = self . phi ( X ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi1 ) <TAB><TAB> else : <TAB><TAB><TAB> phi2 = self . phi ( X2 ) <TAB><TAB><TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi2 ) <TAB> else : <TAB><TAB> self . variance . gradient = np . einsum ( "" ij,ij "" , dL_dK , self . _K ( X , X2 ) ) * self . beta",if X2 is None or X is X2 :,if self . ARD_AND_CANDARROW :,73.70945357472354,95.73,False
144,"def post ( self ) : <TAB> host_json = json . loads ( request . data ) <TAB> host_os = host_json . get ( "" os "" ) <TAB> if host_os : <TAB><TAB> result = get_monkey_executable ( host_os . get ( "" type "" ) , host_os . get ( "" machine "" ) ) <TAB><TAB> if result : <TAB><TAB><TAB> # change resulting from new base path <TAB><TAB><TAB> executable_filename = result [ "" filename "" ] <TAB><TAB><TAB> real_path = MonkeyDownload . get_executable_full_path ( executable_filename ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ "" size "" ] = os . path . getsize ( real_path ) <TAB><TAB><TAB><TAB> return result <TAB> return { }",if os . path . isfile ( real_path ) :,if real_path :,96.09638966532943,95.45,False
145,"def _encode_data ( <TAB> self , <TAB> data , <TAB> content_type , ) : <TAB> if content_type is MULTIPART_CONTENT : <TAB><TAB> return encode_multipart ( BOUNDARY , data ) <TAB> else : <TAB><TAB> # Encode the content so that the byte representation is correct. <TAB><TAB> match = CONTENT_TYPE_RE . match ( content_type ) <TAB><TAB> <MASK> <TAB><TAB><TAB> charset = match . group ( 1 ) <TAB><TAB> else : <TAB><TAB><TAB> charset = settings . DEFAULT_CHARSET <TAB><TAB> return force_bytes ( data , encoding = charset )",if match :,if match :,100.0,100.00,True
146,"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB><TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB><TAB> s = i - 1 <TAB><TAB> e = i + 1 <TAB><TAB> if not re . match ( "" [0-9] "" , str ( tokens [ s ] ) ) : <TAB><TAB><TAB> continue <TAB><TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB> e + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> e + = 1 <TAB><TAB><TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB><TAB><TAB> i - = 1 <TAB> return tokens","if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :","if re . match ( ""[+-]"" , str ( tokens [ e ] ) ) :",99.24777545515107,98.38,False
147,"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result : <TAB><TAB> <MASK> <TAB><TAB><TAB> self [ key ] = result <TAB><TAB> if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) : <TAB><TAB><TAB> result . parent = self <TAB><TAB><TAB> result . key = key <TAB> return result",if replace :,if replace :,100.0,100.00,True
148,"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB><TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB><TAB> for bp in bplist : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if text . strip ( ) . lower ( ) == "" none "" : <TAB><TAB><TAB><TAB><TAB> text = None <TAB><TAB><TAB><TAB> bp . cond = text <TAB><TAB><TAB><TAB> break <TAB> self . RespondDebuggerData ( )",if id ( bp ) == item_id :,if bp . id == item_id :,95.7462304681423,97.45,False
149,"def add ( self , url : str , future_nzo : NzbObject , when : Optional [ int ] = None ) : <TAB> """"""Add an URL to the URLGrabber queue, 'when' is seconds from now"""""" <TAB> if future_nzo and when : <TAB><TAB> # Always increase counter <TAB><TAB> future_nzo . url_tries + = 1 <TAB><TAB> # Too many tries? Cancel <TAB><TAB> <MASK> <TAB><TAB><TAB> self . fail_to_history ( future_nzo , url , T ( "" Maximum retries "" ) ) <TAB><TAB><TAB> return <TAB><TAB> future_nzo . url_wait = time . time ( ) + when <TAB> self . queue . put ( ( url , future_nzo ) )",if future_nzo . url_tries > cfg . max_url_retries ( ) :,if future_nzo . url_tries > self . max_retries :,97.30691774918279,95.67,False
150,def _is_datetime_string ( series ) : <TAB> if series . dtype == object : <TAB><TAB> not_numeric = False <TAB><TAB> try : <TAB><TAB><TAB> pd . to_numeric ( series ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> not_numeric = True <TAB><TAB> datetime_col = None <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> datetime_col = pd . to_datetime ( series ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> return False <TAB><TAB> if datetime_col is not None : <TAB><TAB><TAB> return True <TAB> return False,if not_numeric :,if not_numeric :,100.0,100.00,True
151,"def _getEventAndObservers ( self , event ) : <TAB> if isinstance ( event , xpath . XPathQuery ) : <TAB><TAB> # Treat as xpath <TAB><TAB> observers = self . _xpathObservers <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Treat as event <TAB><TAB><TAB> observers = self . _eventObservers <TAB><TAB> else : <TAB><TAB><TAB> # Treat as xpath <TAB><TAB><TAB> event = xpath . internQuery ( event ) <TAB><TAB><TAB> observers = self . _xpathObservers <TAB> return event , observers",if self . prefix == event [ : len ( self . prefix ) ] :,"if isinstance ( event , xpath . Event ) :",91.82556122629319,90.14,False
152,"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB><TAB> # ignore attributes starting by underscores <TAB><TAB> if name . startswith ( "" _ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> attr = getattr ( bonobo , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> assert name in bonobo . __all__",if inspect . ismodule ( attr ) :,"if not hasattr ( attr , ""__all__"" ) :",95.82169762041734,91.09,False
153,"def relint_views ( wid = None ) : <TAB> windows = [ sublime . Window ( wid ) ] if wid else sublime . windows ( ) <TAB> for window in windows : <TAB><TAB> for view in window . views ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> hit ( view , "" relint_views "" )",if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,if view . is_linked and view . is_linked :,87.7839447891233,83.92,False
154,def _check_for_unknown_gender ( self ) : <TAB> if self . obj . get_gender ( ) == Person . UNKNOWN : <TAB><TAB> d = GenderDialog ( parent = self . window ) <TAB><TAB> gender = d . run ( ) <TAB><TAB> d . destroy ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . obj . set_gender ( gender ),if gender >= 0 :,if gender :,67.23211989845845,95.55,False
155,"def add_to_path ( self , fnames ) : <TAB> """"""Add fnames to path"""""" <TAB> indexes = [ ] <TAB> for path in fnames : <TAB><TAB> project = self . get_source_project ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . parent_widget . emit ( SIGNAL ( "" pythonpath_changed() "" ) ) <TAB><TAB><TAB> indexes . append ( self . get_index ( path ) ) <TAB> if indexes : <TAB><TAB> self . reset_icon_provider ( ) <TAB><TAB> for index in indexes : <TAB><TAB><TAB> self . update ( index )",if project . add_to_pythonpath ( path ) :,if project and project . is_dir ( ) :,68.92061636155292,95.03,False
156,"def validate ( self , value ) : <TAB> if value . grid_id is not None : <TAB><TAB> if not isinstance ( value , self . proxy_class ) : <TAB><TAB><TAB> self . error ( "" FileField only accepts GridFSProxy values "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . error ( "" Invalid GridFSProxy value "" )","if not isinstance ( value . grid_id , ObjectId ) :",if value . grid_id not in self . proxy_class . _grid_fs_,60.966797705849274,84.71,False
157,"def shortcut ( self , input , ch_out , stride , name , if_first = False ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB><TAB> else : <TAB><TAB><TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB><TAB> return input",if if_first :,if if_first :,100.0,100.00,True
158,"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB><TAB> if code == Path . MOVETO : <TAB><TAB><TAB> ctx . move_to ( * points ) <TAB><TAB> elif code == Path . LINETO : <TAB><TAB><TAB> ctx . line_to ( * points ) <TAB><TAB> elif code == Path . CURVE3 : <TAB><TAB><TAB> ctx . curve_to ( <TAB><TAB><TAB><TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ctx . curve_to ( * points ) <TAB><TAB> elif code == Path . CLOSEPOLY : <TAB><TAB><TAB> ctx . close_path ( )",elif code == Path . CURVE4 :,elif code == Path . CURVE4 :,75.0,100.00,True
159,"def _get_build_status ( self , job_name , build_number ) : <TAB> try : <TAB><TAB> build_info = self . server . get_build_info ( job_name , build_number ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" building "" <TAB><TAB> else : <TAB><TAB><TAB> return "" built "" <TAB> except jenkins . NotFoundException : <TAB><TAB> return "" not found ""","if build_info [ ""building"" ] :","if build_info [ ""status"" ] == ""built"" :",66.86784799155095,92.94,False
160,"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB><TAB> if default . lower ( ) == "" true "" : <TAB><TAB><TAB> return True <TAB><TAB> elif default . lower ( ) == "" false "" : <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB><TAB> if type ( default ) == int : <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return float ( default ) <TAB> else : <TAB><TAB> return str ( default )",if type ( default ) == float :,if type ( default ) == float :,100.0,100.00,True
161,"def get_fills ( self , exchange_order_id ) : <TAB> async with aiohttp . ClientSession ( ) as client : <TAB><TAB> response : aiohttp . ClientResponse = await client . get ( <TAB><TAB><TAB> f "" { BASE_URL } { FILLS_ROUTE } "" , <TAB><TAB><TAB> params = { "" orderId "" : exchange_order_id , "" limit "" : 100 } , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> msg = await response . json ( ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> msg = await response . text ( ) <TAB><TAB><TAB> raise DydxAsyncAPIError ( response . status , msg ) <TAB><TAB> return await response . json ( )",if response . status >= 300 :,if response . status != 200 :,98.44300157589598,97.96,False
162,"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB><TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key , value in list ( semanticTags . items ( ) ) : <TAB><TAB> if not isinstance ( key , int ) : <TAB><TAB><TAB> raise TypeError ( "" At least one key is not a valid int position "" ) <TAB><TAB> if not isinstance ( value , list ) : <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB> ) <TAB><TAB> for x in value : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB><TAB> "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB><TAB> ) <TAB> self . __semanticTags = semanticTags","if not isinstance ( x , str ) :","if not isinstance ( x , str ) :",100.0,100.00,True
163,"def start_cutting_tool ( self , event , axis , direction ) : <TAB> toggle = event . EventObject <TAB> self . cutting = toggle . Value <TAB> if toggle . Value : <TAB><TAB> # Disable the other toggles <TAB><TAB> for child in self . cutsizer . Children : <TAB><TAB><TAB> child = child . Window <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> child . Value = False <TAB><TAB> self . cutting_axis = axis <TAB><TAB> self . cutting_direction = direction <TAB> else : <TAB><TAB> self . cutting_axis = None <TAB><TAB> self . cutting_direction = None <TAB> self . cutting_dist = None",if child != toggle :,if child . Name == toggle . Name :,97.38390102388553,95.76,False
164,"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB><TAB> for patching in patched . patchings : <TAB><TAB><TAB> arg = exit_stack . enter_context ( patching ) <TAB><TAB><TAB> if patching . attribute_name is not None : <TAB><TAB><TAB><TAB> keywargs . update ( arg ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> extra_args . append ( arg ) <TAB><TAB> args + = tuple ( extra_args ) <TAB><TAB> yield ( args , keywargs )",elif patching . new is DEFAULT :,elif arg is not None :,94.73455397901425,96.31,False
165,def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB><TAB> mask = 1 << bit <TAB><TAB> if attrs & mask : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> names . append ( attrnames [ mask ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> names . append ( hex ( mask ) ) <TAB> return names,if attrnames . has_key ( mask ) :,if mask in attrnames :,92.4380427236573,92.59,False
166,"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB><TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB><TAB><TAB> if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",75.0,100.00,True
167,"def handle_socket ( self , request ) : <TAB> conn = request . connection <TAB> while True : <TAB><TAB> chunk = conn . recv ( 4 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> slen = struct . unpack ( "" >L "" , chunk ) [ 0 ] <TAB><TAB> chunk = conn . recv ( slen ) <TAB><TAB> while len ( chunk ) < slen : <TAB><TAB><TAB> chunk = chunk + conn . recv ( slen - len ( chunk ) ) <TAB><TAB> obj = pickle . loads ( chunk ) <TAB><TAB> record = logging . makeLogRecord ( obj ) <TAB><TAB> self . log_output + = record . msg + "" \n "" <TAB><TAB> self . handled . release ( )",if len ( chunk ) < 4 :,if not chunk :,80.62344049177788,96.30,False
168,"def on_source_foreach ( self , model , path , iter , id ) : <TAB> m_id = model . get_value ( iter , self . COLUMN_ID ) <TAB> if m_id == id : <TAB><TAB> if self . _foreach_mode == "" get "" : <TAB><TAB><TAB> self . _foreach_take = model . get_value ( iter , self . COLUMN_ENABLED ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _foreach_take = iter","elif self . _foreach_mode == ""set"" :","elif self . _foreach_mode == ""set"" :",100.0,100.00,True
169,"def parts ( ) : <TAB> for l in lists . leaves : <TAB><TAB> head_name = l . get_head_name ( ) <TAB><TAB> if head_name == "" System`List "" : <TAB><TAB><TAB> yield l . leaves <TAB><TAB> <MASK> <TAB><TAB><TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l )","elif head_name != ""System`Missing"" :","elif head_name == ""System`List"" :",96.70476785549403,95.12,False
170,"def __fill_counter_values ( self , command : str ) : <TAB> result = [ ] <TAB> regex = r "" (item[0-9]+ \ .counter_value) "" <TAB> for token in re . split ( regex , command ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> result . append ( str ( self . simulator_config . item_dict [ token ] . value ) ) <TAB><TAB><TAB> except ( KeyError , ValueError , AttributeError ) : <TAB><TAB><TAB><TAB> logger . error ( "" Could not get counter value for  "" + token ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( token ) <TAB> return "" "" . join ( result )","if re . match ( regex , token ) is not None :",if token in self . simulator_config . item_dict :,92.80224251853708,94.03,False
171,"def IMPORTFROM ( self , node ) : <TAB> <MASK> <TAB><TAB> if not self . futuresAllowed : <TAB><TAB><TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB><TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB><TAB> if alias . name == "" * "" : <TAB><TAB><TAB> self . scope . importStarred = True <TAB><TAB><TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB> continue <TAB><TAB> name = alias . asname or alias . name <TAB><TAB> importation = Importation ( name , node ) <TAB><TAB> <MASK> <TAB><TAB><TAB> importation . used = ( self . scope , node ) <TAB><TAB> self . addBinding ( node , importation )","if node . module == ""__future__"" :",if self . scope :,70.35013028096007,88.74,False
172,"def _split_batch_list ( args , batch_list ) : <TAB> new_list = [ ] <TAB> for batch in batch_list . batches : <TAB><TAB> new_list . append ( batch ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield batch_pb2 . BatchList ( batches = new_list ) <TAB><TAB><TAB> new_list = [ ] <TAB> if new_list : <TAB><TAB> yield batch_pb2 . BatchList ( batches = new_list )",if len ( new_list ) == args . batch_size_limit :,if len ( new_list ) == 1 :,90.23705421231585,93.67,False
173,"def get_branch_or_use_upstream ( branch_name , arg , repo ) : <TAB> if not branch_name : # use upstream branch <TAB><TAB> current_b = repo . current_branch <TAB><TAB> upstream_b = current_b . upstream <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" No  {0}  branch specified and the current branch has no upstream  "" <TAB><TAB><TAB><TAB> "" branch set "" . format ( arg ) <TAB><TAB><TAB> ) <TAB><TAB> ret = current_b . upstream <TAB> else : <TAB><TAB> ret = get_branch ( branch_name , repo ) <TAB> return ret",if not upstream_b :,if not upstream_b :,100.0,100.00,True
174,"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB><TAB> if name not in default_settings : <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> name , <TAB><TAB><TAB><TAB><TAB> self . __class__ . __name__ , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> setattr ( self , name , value )","if not hasattr ( self , name ) :",if name in settings :,68.05700911671762,96.33,False
175,"def _declare ( self , name , obj , included = False , quals = 0 ) : <TAB> if name in self . _declarations : <TAB><TAB> prevobj , prevquals = self . _declarations [ name ] <TAB><TAB> if prevobj is obj and prevquals == quals : <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> raise api . FFIError ( <TAB><TAB><TAB><TAB> "" multiple declarations of  %s  (for interactive usage,  "" <TAB><TAB><TAB><TAB> "" try cdef(xx, override=True)) "" % ( name , ) <TAB><TAB><TAB> ) <TAB> assert "" __dotdotdot__ "" not in name . split ( ) <TAB> self . _declarations [ name ] = ( obj , quals ) <TAB> if included : <TAB><TAB> self . _included_declarations . add ( obj )",if not self . _override :,if len ( self . _declarations ) > 1 :,74.21735598938966,95.94,False
176,"def include_file ( name , fdir = tmp_dir , b64 = False ) : <TAB> try : <TAB><TAB> if fdir is None : <TAB><TAB><TAB> fdir = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> with io . open ( os . path . join ( fdir , name ) , "" rb "" ) as f : <TAB><TAB><TAB><TAB> return base64 . b64encode ( f . read ( ) ) . decode ( "" utf-8 "" ) <TAB><TAB> else : <TAB><TAB><TAB> with io . open ( os . path . join ( fdir , name ) , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB><TAB> return f . read ( ) <TAB> except ( OSError , IOError ) as e : <TAB><TAB> logger . error ( "" Could not include file  ' {} ' :  {} "" . format ( name , e ) )",if b64 :,if b64 :,100.0,100.00,True
177,"def to_raw_json ( self ) : <TAB> parts = { } <TAB> for p in self . parts : <TAB><TAB> <MASK> <TAB><TAB><TAB> parts [ p [ 0 ] ] = [ ] <TAB><TAB> parts [ p [ 0 ] ] . append ( { "" value "" : p [ 2 ] , "" parameters "" : p [ 1 ] } ) <TAB> children = [ x . to_raw_json ( ) for x in self . children ] <TAB> return { <TAB><TAB> "" type "" : self . __class__ . __name__ , <TAB><TAB> "" children "" : children , <TAB><TAB> "" parts "" : parts , <TAB> }",if p [ 0 ] not in parts :,if not parts . has_key ( p [ 0 ] ) :,86.24521217436639,94.13,False
178,"def process_output ( <TAB> output : str , filename : str , start_line : int ) - > Tuple [ Optional [ str ] , bool ] : <TAB> error_found = False <TAB> for line in output . splitlines ( ) : <TAB><TAB> t = get_revealed_type ( line , filename , start_line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return t , error_found <TAB><TAB> elif "" error: "" in line : <TAB><TAB><TAB> error_found = True <TAB> return None , True # finding no reveal_type is an error",if t :,if t is not None :,75.45110068110351,96.90,False
179,"def __init__ ( <TAB> self , resize_keyboard = None , one_time_keyboard = None , selective = None , row_width = 3 ) : <TAB> if row_width > self . max_row_keys : <TAB><TAB> # Todo: Will be replaced with Exception in future releases <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . error ( <TAB><TAB><TAB><TAB> "" Telegram does not support reply keyboard row width over  %d . "" <TAB><TAB><TAB><TAB> % self . max_row_keys <TAB><TAB><TAB> ) <TAB><TAB> row_width = self . max_row_keys <TAB> self . resize_keyboard = resize_keyboard <TAB> self . one_time_keyboard = one_time_keyboard <TAB> self . selective = selective <TAB> self . row_width = row_width <TAB> self . keyboard = [ ]",if not DISABLE_KEYLEN_ERROR :,if self . verbose :,98.02224015906461,96.67,False
180,"def realizeElementExpressions ( innerElement ) : <TAB> elementHasBeenRealized = False <TAB> for exp in innerElement . expressions : <TAB><TAB> if not hasattr ( exp , "" realize "" ) : <TAB><TAB><TAB> continue <TAB><TAB> # else: <TAB><TAB> before , during , after = exp . realize ( innerElement ) <TAB><TAB> elementHasBeenRealized = True <TAB><TAB> for n in before : <TAB><TAB><TAB> newStream . append ( n ) <TAB><TAB> <MASK> <TAB><TAB><TAB> newStream . append ( during ) <TAB><TAB> for n in after : <TAB><TAB><TAB> newStream . append ( n ) <TAB> if elementHasBeenRealized is False : <TAB><TAB> newStream . append ( innerElement )",if during is not None :,if during is not None :,100.0,100.00,True
181,"def lex_number ( self , pos ) : <TAB> # numeric literal <TAB> start = pos <TAB> found_dot = False <TAB> while pos < len ( self . string ) and ( <TAB><TAB> self . string [ pos ] . isdigit ( ) or self . string [ pos ] == "" . "" <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if found_dot is True : <TAB><TAB><TAB><TAB> raise ValueError ( "" Invalid number. Found multiple  ' . ' "" ) <TAB><TAB><TAB> found_dot = True <TAB><TAB> # technically we allow more than one ""."" and let float()'s parsing <TAB><TAB> # complain later <TAB><TAB> pos + = 1 <TAB> val = self . string [ start : pos ] <TAB> return Token ( TokenType . LNUM , val , len ( val ) )","if self . string [ pos ] == ""."" :",if self . string [ pos ] . isalpha ( ) :,73.40837337629098,97.19,False
182,"def rename ( src , dst ) : <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename ( src , dst ) : <TAB><TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try : <TAB><TAB> os . rename ( src , dst ) <TAB> except OSError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> old = "" %s - %08x "" % ( dst , random . randint ( 0 , sys . maxsize ) ) <TAB><TAB> os . rename ( dst , old ) <TAB><TAB> os . rename ( src , dst ) <TAB><TAB> try : <TAB><TAB><TAB> os . unlink ( old ) <TAB><TAB> except Exception : <TAB><TAB><TAB> pass",if e . errno != errno . EEXIST :,if e . errno != errno . EEXIST :,75.0,100.00,True
183,"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB><TAB> if num > 1 : <TAB><TAB><TAB> args = [ point , index ] <TAB><TAB> else : <TAB><TAB><TAB> args = [ point ] <TAB><TAB> <MASK> <TAB><TAB><TAB> args . append ( widget ) <TAB><TAB> try_callback ( callback , * args ) <TAB> return",if pass_widget :,if event_id == widget . WIDGET_EVENT_ID :,80.79943290273641,91.40,False
184,"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB><TAB> error = True <TAB><TAB> try : <TAB><TAB><TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB><TAB><TAB> error = False <TAB><TAB> except : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB> if self . expect_exception : <TAB><TAB><TAB> assert error",if not self . expect_exception :,if self . expect_exception :,68.32141109839608,98.15,False
185,"def handle ( self , * args : Any , * * options : Any ) - > None : <TAB> realm = self . get_realm ( options ) <TAB> if options [ "" all "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CommandError ( <TAB><TAB><TAB><TAB> "" You must specify a realm if you choose the --all option. "" <TAB><TAB><TAB> ) <TAB><TAB> self . fix_all_users ( realm ) <TAB><TAB> return <TAB> self . fix_emails ( realm , options [ "" emails "" ] )",if realm is None :,if not realm :,78.49511830439384,97.01,False
186,"def recv_tdi ( self , nbits , pos ) : <TAB> bits = 0 <TAB> for n in range ( nbits * 2 ) : <TAB><TAB> yield from self . _wait_for_tck ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> bits = ( bits << 1 ) | ( yield self . tdi . o ) <TAB> return bits",if ( yield self . tck . o ) == pos :,if self . tdi . o . read ( ) == pos :,87.04929050091617,92.04,False
187,"def _split_head ( self ) : <TAB> if not hasattr ( self , "" _severed_head "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tree = self . _tree . copy ( ) <TAB><TAB><TAB> head = tree . get_heading_text ( ) <TAB><TAB><TAB> tree . remove_heading ( ) <TAB><TAB><TAB> self . _severed_head = ( head , tree ) <TAB><TAB> else : <TAB><TAB><TAB> self . _severed_head = ( None , None ) <TAB> return self . _severed_head",if self . _tree :,if self . _tree :,100.0,100.00,True
188,"def buildSearchTrie ( self , choices ) : <TAB> searchtrie = trie . Trie ( ) <TAB> for choice in choices : <TAB><TAB> for token in self . tokenizeChoice ( choice ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> searchtrie [ token ] = [ ] <TAB><TAB><TAB> searchtrie [ token ] . append ( choice ) <TAB> return searchtrie",if not searchtrie . has_key ( token ) :,if token not in searchtrie :,86.98661066839341,90.39,False
189,"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB><TAB> # convert sql with named parameters to sql with unnamed parameters <TAB><TAB> conv = _FormatConverter ( params ) <TAB><TAB> if params : <TAB><TAB><TAB> sql = sql_to_string ( sql ) <TAB><TAB><TAB> sql = sql % conv <TAB><TAB><TAB> params = conv . params <TAB><TAB> else : <TAB><TAB><TAB> params = ( ) <TAB> for param in params or ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rv . append ( "" NULL "" ) <TAB><TAB> param = safe_repr ( param ) <TAB><TAB> rv . append ( param ) <TAB> return sql , rv",if param is None :,if param is None :,100.0,100.00,True
190,def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB><TAB> if len ( ql ) > 0 : <TAB><TAB><TAB> observer . on_next ( False ) <TAB><TAB><TAB> observer . on_completed ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> observer . on_next ( True ) <TAB><TAB><TAB> observer . on_completed ( ),elif donel [ 0 ] :,elif len ( ql ) == 1 :,92.43983513718761,92.69,False
191,"def notify_digest ( self , frequency , changes ) : <TAB> notifications = defaultdict ( list ) <TAB> users = { } <TAB> for change in changes : <TAB><TAB> for user in self . get_users ( frequency , change ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> notifications [ user . pk ] . append ( change ) <TAB><TAB><TAB><TAB> users [ user . pk ] = user <TAB> for user in users . values ( ) : <TAB><TAB> self . send_digest ( <TAB><TAB><TAB> user . profile . language , <TAB><TAB><TAB> user . email , <TAB><TAB><TAB> notifications [ user . pk ] , <TAB><TAB><TAB> subscription = user . current_subscription , <TAB><TAB> )",if change . project is None or user . can_access_project ( change . project ) :,if user . pk not in notifications :,86.44479004142515,91.30,False
192,"def _any_listener_using ( self , target_group_arn ) : <TAB> for load_balancer in self . load_balancers . values ( ) : <TAB><TAB> for listener in load_balancer . listeners . values ( ) : <TAB><TAB><TAB> for rule in listener . rules : <TAB><TAB><TAB><TAB> for action in rule . actions : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if action . data . get ( ""target_group_arn"" ) == target_group_arn :",if action . arn == target_group_arn :,66.29053232117468,90.99,False
193,"def train_dict ( self , triples ) : <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter ( ) <TAB> ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB> # find the most frequent mappings <TAB> for p , _ in ctr . most_common ( ) : <TAB><TAB> w , pos , l = p <TAB><TAB> if ( w , pos ) not in self . composite_dict : <TAB><TAB><TAB> self . composite_dict [ ( w , pos ) ] = l <TAB><TAB> <MASK> <TAB><TAB><TAB> self . word_dict [ w ] = l <TAB> return",if w not in self . word_dict :,"if ( w , pos ) not in self . word_dict :",98.37467023907132,96.88,False
194,"def parse_git_config ( path ) : <TAB> """"""Parse git config file."""""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB><TAB> for line in f : <TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB><TAB><TAB><TAB> config [ section ] = dict ( ) <TAB><TAB><TAB> elif section : <TAB><TAB><TAB><TAB> key , value = line . replace ( ""   "" , "" "" ) . split ( "" = "" ) <TAB><TAB><TAB><TAB> config [ section ] [ key ] = value <TAB> return config","if line . startswith ( ""["" ) :","if line . startswith ( ""git "" ) :",98.84238033902261,98.88,False
195,"def send_signal ( self , pid , signum ) : <TAB> if pid in self . processes : <TAB><TAB> process = self . processes [ pid ] <TAB><TAB> hook_result = self . call_hook ( "" before_signal "" , pid = pid , signum = signum ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( <TAB><TAB><TAB><TAB> "" before_signal hook didn ' t return True  "" <TAB><TAB><TAB><TAB> "" => signal  %i  is not sent to  %i "" % ( signum , pid ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> process . send_signal ( signum ) <TAB><TAB> self . call_hook ( "" after_signal "" , pid = pid , signum = signum ) <TAB> else : <TAB><TAB> logger . debug ( "" process  %s  does not exist "" % pid )",if signum != signal . SIGKILL and not hook_result :,if hook_result :,67.92240930298874,95.96,False
196,"def validate_pos_return ( self ) : <TAB> if self . is_pos and self . is_return : <TAB><TAB> total_amount_in_payments = 0 <TAB><TAB> for payment in self . payments : <TAB><TAB><TAB> total_amount_in_payments + = payment . amount <TAB><TAB> invoice_total = self . rounded_total or self . grand_total <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( <TAB><TAB><TAB><TAB> _ ( "" Total payments amount can ' t be greater than  {} "" ) . format ( <TAB><TAB><TAB><TAB><TAB> - invoice_total <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",if total_amount_in_payments < invoice_total :,if total_amount_in_payments > invoice_total :,98.4509621535763,98.74,False
197,"def delete ( key , inner_key = None ) : <TAB> if inner_key is not None : <TAB><TAB> try : <TAB><TAB><TAB> del cache [ key ] [ inner_key ] <TAB><TAB><TAB> del use_count [ key ] [ inner_key ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del cache [ key ] <TAB><TAB><TAB><TAB> del use_count [ key ] <TAB><TAB><TAB> wrapper . cache_size - = 1 <TAB><TAB> except KeyError : <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> return True <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> wrapper . cache_size - = len ( cache [ key ] ) <TAB><TAB><TAB> del cache [ key ] <TAB><TAB><TAB> del use_count [ key ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> return True",if not cache [ key ] :,if not cache [ key ] :,100.0,100.00,True
198,"def insertionsort ( array ) : <TAB> size = array . getsize ( ) <TAB> array . reset ( "" Insertion sort "" ) <TAB> for i in range ( 1 , size ) : <TAB><TAB> j = i - 1 <TAB><TAB> while j > = 0 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> array . swap ( j , j + 1 ) <TAB><TAB><TAB> j = j - 1 <TAB> array . message ( "" Sorted "" )","if array . compare ( j , j + 1 ) <= 0 :","if array . compare ( j , size - 1 ) < 0 :",95.99585439667572,95.80,False
199,"def publish_state ( cls , payload , state ) : <TAB> try : <TAB><TAB> if isinstance ( payload , LiveActionDB ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cls . process ( payload ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB><TAB> traceback . print_exc ( ) <TAB><TAB> print ( payload )",if state == action_constants . LIVEACTION_STATUS_REQUESTED :,if state == LiveActionDB . STATE_ACTIVE :,71.71813192449585,92.53,False
200,"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB><TAB> if type ( submob ) == AnnularSector : <TAB><TAB><TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # it's the shadow, don't dim it <TAB><TAB><TAB> continue <TAB><TAB> alpha = self . opacity_function ( r ) <TAB><TAB> submob . set_fill ( opacity = alpha )",if type ( submob ) != AnnularSector :,if submob . get_shape ( ) == 1 :,92.83215630916185,94.47,False
201,"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None : <TAB><TAB> return False <TAB> for warning_type in suppress_warnings : <TAB><TAB> <MASK> <TAB><TAB><TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB><TAB> else : <TAB><TAB><TAB> target , subtarget = warning_type , None <TAB><TAB> if target == type : <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> subtype is None <TAB><TAB><TAB><TAB> or subtarget is None <TAB><TAB><TAB><TAB> or subtarget == subtype <TAB><TAB><TAB><TAB> or subtarget == "" * "" <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> return True <TAB> return False","if ""."" in warning_type :","if ""."" in warning_type :",100.0,100.00,True
202,"def set_many ( self , mapping , timeout = None ) : <TAB> timeout = self . _normalize_timeout ( timeout ) <TAB> # Use transaction=False to batch without calling redis MULTI <TAB> # which is not supported by twemproxy <TAB> pipe = self . _client . pipeline ( transaction = False ) <TAB> for key , value in _items ( mapping ) : <TAB><TAB> dump = self . dump_object ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pipe . set ( name = self . key_prefix + key , value = dump ) <TAB><TAB> else : <TAB><TAB><TAB> pipe . setex ( name = self . key_prefix + key , value = dump , time = timeout ) <TAB> return pipe . execute ( )",if timeout == - 1 :,if timeout is None :,98.23723669659657,97.02,False
203,"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB><TAB> return path # already relative <TAB> dir = path <TAB> names = [ ] <TAB> while True : <TAB><TAB> prevdir = dir <TAB><TAB> dir , name = os . path . split ( prevdir ) <TAB><TAB> if dir == prevdir or not dir : <TAB><TAB><TAB> return path # failed to make it relative <TAB><TAB> names . append ( name ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> names . reverse ( ) <TAB><TAB><TAB><TAB> return os . path . join ( * names ) <TAB><TAB> except OSError : <TAB><TAB><TAB> pass","if samefile ( dir , os . curdir ) :",if not names :,95.97027909787185,95.42,False
204,"def word_range ( word ) : <TAB> for ind in range ( len ( word ) ) : <TAB><TAB> temp = word [ ind ] <TAB><TAB> for c in [ chr ( x ) for x in range ( ord ( "" a "" ) , ord ( "" z "" ) + 1 ) ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield word [ : ind ] + c + word [ ind + 1 : ]",if c != temp :,if c in temp :,98.41531739632069,96.88,False
205,"def validate ( self ) : <TAB> self . update_soil_edit ( "" sand_composition "" ) <TAB> for soil_type in self . soil_types : <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( _ ( "" {0}  should be a value between 0 and 100 "" ) . format ( soil_type ) ) <TAB> if sum ( self . get ( soil_type ) for soil_type in self . soil_types ) != 100 : <TAB><TAB> frappe . throw ( _ ( "" Soil compositions do not add up to 100 "" ) )",if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,if not random . random ( ) < 0.0 and not random . random ( ) <,60.968775975160995,85.99,False
206,"def on_click ( self , event ) : <TAB> run = self . _is_running ( ) <TAB> if event [ "" button "" ] == self . button_activate : <TAB><TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -activate "" ] ) <TAB> if event [ "" button "" ] == self . button_toggle : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -exit "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> # Because we want xscreensaver to continue running after <TAB><TAB><TAB> # exit, we instead use preexec_fn=setpgrp here. <TAB><TAB><TAB> Popen ( <TAB><TAB><TAB><TAB> [ "" xscreensaver "" , "" -no-splash "" , "" -no-capture-stderr "" ] , <TAB><TAB><TAB><TAB> stdout = PIPE , <TAB><TAB><TAB><TAB> stderr = PIPE , <TAB><TAB><TAB><TAB> preexec_fn = setpgrp , <TAB><TAB><TAB> )",if run :,if run :,100.0,100.00,True
207,"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB><TAB> return path # already relative <TAB> dir = path <TAB> names = [ ] <TAB> while True : <TAB><TAB> prevdir = dir <TAB><TAB> dir , name = os . path . split ( prevdir ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return path # failed to make it relative <TAB><TAB> names . append ( name ) <TAB><TAB> try : <TAB><TAB><TAB> if samefile ( dir , os . curdir ) : <TAB><TAB><TAB><TAB> names . reverse ( ) <TAB><TAB><TAB><TAB> return os . path . join ( * names ) <TAB><TAB> except OSError : <TAB><TAB><TAB> pass",if dir == prevdir or not dir :,if not os . path . isabs ( dir ) :,96.26175118760261,95.24,False
208,"def _format_micros ( self , datestring ) : <TAB> parts = datestring [ : - 1 ] . split ( "" . "" ) <TAB> if len ( parts ) == 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return datestring [ : - 1 ] + "" .000000Z "" <TAB><TAB> else : <TAB><TAB><TAB> return datestring + "" .000000Z "" <TAB> else : <TAB><TAB> micros = parts [ - 1 ] [ : 6 ] if len ( parts [ - 1 ] ) > 6 else parts [ - 1 ] <TAB><TAB> return "" . "" . join ( parts [ : - 1 ] + [ "" {:06d} "" . format ( int ( micros ) ) ] ) + "" Z ""","if datestring . endswith ( ""Z"" ) :",if len ( parts [ - 1 ] ) > 1 :,94.88321183588127,93.96,False
209,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB><TAB> with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> line = f1 . readline ( ) <TAB><TAB><TAB><TAB> if not line : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if line [ 0 ] == ""   "" : <TAB><TAB><TAB><TAB><TAB><TAB> line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB> f2 . writelines ( line + "" \n "" )","if line != "" "" and line != """" :",if line :,75.09068409834425,95.25,False
210,"def set ( self , item , data ) : <TAB> if not type ( item ) is slice : <TAB><TAB> item = slice ( item , item + len ( data ) , None ) <TAB> virt_item = self . item2virtitem ( item ) <TAB> if not virt_item : <TAB><TAB> return <TAB> off = 0 <TAB> for s , n_item in virt_item : <TAB><TAB> <MASK> <TAB><TAB><TAB> i = slice ( off , n_item . stop + off - n_item . start , n_item . step ) <TAB><TAB><TAB> data_slice = data . __getitem__ ( i ) <TAB><TAB><TAB> s . content . __setitem__ ( n_item , data_slice ) <TAB><TAB><TAB> off = i . stop <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" TODO XXX "" ) <TAB> return","if isinstance ( s , ProgBits ) :",if n_item . stop :,94.40948820695499,96.77,False
211,"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB><TAB> # multipart/* are just containers <TAB><TAB> if part . get_content_maintype ( ) == "" multipart "" : <TAB><TAB><TAB> continue <TAB><TAB> ctype = part . get_content_type ( ) <TAB><TAB> if ctype is None : <TAB><TAB><TAB> ctype = OCTET_TYPE <TAB><TAB> filename = part . get_filename ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = PART_FN_TPL % ( partnum ) <TAB><TAB> headers = dict ( part ) <TAB><TAB> LOG . debug ( headers ) <TAB><TAB> headers [ "" Content-Type "" ] = ctype <TAB><TAB> payload = util . fully_decoded_payload ( part ) <TAB><TAB> callback ( data , filename , payload , headers ) <TAB><TAB> partnum = partnum + 1",if not filename :,if not filename :,100.0,100.00,True
212,"def _run_wes ( args ) : <TAB> """"""Run CWL using a Workflow Execution Service (WES) endpoint"""""" <TAB> main_file , json_file , project_name = _get_main_and_json ( args . directory ) <TAB> main_file = _pack_cwl ( main_file ) <TAB> if args . host and "" stratus "" in args . host : <TAB><TAB> _run_wes_stratus ( args , main_file , json_file ) <TAB> else : <TAB><TAB> opts = [ "" --no-wait "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> opts + = [ "" --host "" , args . host ] <TAB><TAB> if args . auth : <TAB><TAB><TAB> opts + = [ "" --auth "" , args . auth ] <TAB><TAB> cmd = [ "" wes-client "" ] + opts + [ main_file , json_file ] <TAB><TAB> _run_tool ( cmd )",if args . host :,if args . host :,100.0,100.00,True
213,"def insertTestData ( self , rows ) : <TAB> for row in rows : <TAB><TAB> if isinstance ( row , Worker ) : <TAB><TAB><TAB> self . workers [ row . id ] = dict ( <TAB><TAB><TAB><TAB> id = row . id , name = row . name , paused = 0 , graceful = 0 , info = row . info <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> row . id = row . buildermasterid * 10000 + row . workerid <TAB><TAB><TAB> self . configured [ row . id ] = dict ( <TAB><TAB><TAB><TAB> buildermasterid = row . buildermasterid , workerid = row . workerid <TAB><TAB><TAB> ) <TAB><TAB> elif isinstance ( row , ConnectedWorker ) : <TAB><TAB><TAB> self . connected [ row . id ] = dict ( masterid = row . masterid , workerid = row . workerid )","elif isinstance ( row , ConfiguredWorker ) :","elif isinstance ( row , ConfiguredWorker ) :",100.0,100.00,True
214,"def local_shape_to_shape_i ( node ) : <TAB> if node . op == T . shape : <TAB><TAB> # This optimization needs ShapeOpt and fgraph.shape_feature <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> shape_feature = node . fgraph . shape_feature <TAB><TAB> ret = shape_feature . make_vector_shape ( node . inputs [ 0 ] ) <TAB><TAB> # We need to copy over stack trace from input to output <TAB><TAB> copy_stack_trace ( node . outputs [ 0 ] , ret ) <TAB><TAB> return [ ret ]","if not hasattr ( node . fgraph , ""shape_feature"" ) :","if not hasattr ( node . fgraph , ""shape_feature"" ) :",100.0,100.00,True
215,"def get_config ( ) : <TAB> """"""Get INI parser with version.ini data."""""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os . path . join ( THIS_DIRECTORY , "" version.ini "" ) <TAB> <MASK> <TAB><TAB> ini_path = os . path . join ( THIS_DIRECTORY , "" ../../version.ini "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" Couldn ' t find version.ini "" ) <TAB> config = configparser . ConfigParser ( ) <TAB> config . read ( ini_path ) <TAB> return config",if not os . path . exists ( ini_path ) :,if not os . path . exists ( ini_path ) :,100.0,100.00,True
216,"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB><TAB> logger = logging . getLogger ( ) <TAB><TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB><TAB> for m in self . modules ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> kaiming_init ( m ) <TAB><TAB><TAB> elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) : <TAB><TAB><TAB><TAB> constant_init ( m , 1 ) <TAB> else : <TAB><TAB> raise TypeError ( "" pretrained must be a str or None "" )","if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Conv2d ) :",100.0,100.00,True
217,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return value <TAB><TAB> day , month , year = value . split ( "" - "" ) <TAB><TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> return value <TAB> except Exception : <TAB><TAB> raise DateStringValueError ( config_param_name , value )","if value == ""DD-MM-YYYY"" :",if not valid_value :,82.25144433576088,96.68,False
218,"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB><TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> box_keys = [ ] <TAB><TAB> if hasattr ( py_obj , "" masks "" ) and py_obj . masks : <TAB><TAB><TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> mask_keys = [ ] <TAB><TAB> return cls ( box_keys , mask_keys )","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :",100.0,100.00,True
219,"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB><TAB> if stat . S_ISREG ( st . st_mode ) : <TAB><TAB><TAB> parts . append ( "" file "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> parts . append ( "" dir "" ) <TAB><TAB> else : <TAB><TAB><TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB><TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB><TAB><TAB> parts . append ( "" link "" ) <TAB> return ""   "" . join ( parts )",elif stat . S_ISDIR ( st . st_mode ) :,elif stat . S_ISDIR ( st . st_mode ) :,100.0,100.00,True
220,"def is_destructive ( queries ) : <TAB> """"""Returns if any of the queries in *queries* is destructive."""""" <TAB> keywords = ( "" drop "" , "" shutdown "" , "" delete "" , "" truncate "" , "" alter "" ) <TAB> for query in sqlparse . split ( queries ) : <TAB><TAB> if query : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> elif query_starts_with ( <TAB><TAB><TAB><TAB> query , [ "" update "" ] <TAB><TAB><TAB> ) is True and not query_has_where_clause ( query ) : <TAB><TAB><TAB><TAB> return True <TAB> return False","if query_starts_with ( query , keywords ) is True :","if query_starts_with ( query , keywords ) is True and not query_has_",94.0798659099836,96.20,False
221,"def _store_gsuite_membership_post ( self ) : <TAB> """"""Flush storing gsuite memberships."""""" <TAB> if not self . member_cache : <TAB><TAB> return <TAB> self . session . flush ( ) <TAB> # session.execute automatically flushes <TAB> if self . membership_items : <TAB><TAB> <MASK> <TAB><TAB><TAB> # SQLite doesn't support bulk insert <TAB><TAB><TAB> for item in self . membership_items : <TAB><TAB><TAB><TAB> stmt = self . dao . TBL_MEMBERSHIP . insert ( item ) <TAB><TAB><TAB><TAB> self . session . execute ( stmt ) <TAB><TAB> else : <TAB><TAB><TAB> stmt = self . dao . TBL_MEMBERSHIP . insert ( self . membership_items ) <TAB><TAB><TAB> self . session . execute ( stmt )","if get_sql_dialect ( self . session ) == ""sqlite"" :",if self . _bulk_insert :,96.16089226183325,93.20,False
222,"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB><TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB><TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB><TAB> outputs . append ( block_out ) <TAB><TAB> if i < 2 : <TAB><TAB><TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB><TAB><TAB> route = self . upsample ( route ) <TAB> return outputs",if i > 0 :,if route is not None :,76.44463806517835,97.21,False
223,"def deep_dict ( self , root = None ) : <TAB> if root is None : <TAB><TAB> root = self <TAB> result = { } <TAB> for key , value in root . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ key ] = self . deep_dict ( root = self . __class__ . _get_next ( key , root ) ) <TAB><TAB> else : <TAB><TAB><TAB> result [ key ] = value <TAB> return result","if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",100.0,100.00,True
224,"def _parse_param_list ( self , content ) : <TAB> r = Reader ( content ) <TAB> params = [ ] <TAB> while not r . eof ( ) : <TAB><TAB> header = r . read ( ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> arg_name , arg_type = header . split ( ""  :  "" ) [ : 2 ] <TAB><TAB> else : <TAB><TAB><TAB> arg_name , arg_type = header , "" "" <TAB><TAB> desc = r . read_to_next_unindented_line ( ) <TAB><TAB> desc = dedent_lines ( desc ) <TAB><TAB> params . append ( ( arg_name , arg_type , desc ) ) <TAB> return params","if "" : "" in header :","if "":"" in header :",97.93499720900262,100.00,False
225,"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB><TAB> <MASK> <TAB><TAB><TAB> if groups is not None : <TAB><TAB><TAB><TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB><TAB><TAB> for v in _ungroup ( v , groups ) : <TAB><TAB><TAB><TAB> yield v <TAB><TAB> else : <TAB><TAB><TAB> yield v","if isinstance ( v , ( list , tuple ) ) :","if isinstance ( v , ( list , tuple ) ) :",100.0,100.00,True
226,"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB><TAB> for array_item in obj : <TAB><TAB><TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB><TAB> try : <TAB><TAB><TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB><TAB><TAB><TAB> if obj [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB> except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB> pass <TAB><TAB> for item_key in obj : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _add_resource_group ( obj [ item_key ] )","if item_key != ""sourceVault"" :","if item_key in ( ""resourceGroup"" , ""resourceGroup"" ) :",96.61856701457054,95.60,False
227,"def haslayer ( self , cls ) : <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB><TAB> return 1 <TAB> for f in self . packetfields : <TAB><TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB><TAB> if fvalue_gen is None : <TAB><TAB><TAB> continue <TAB><TAB> if not f . islist : <TAB><TAB><TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB><TAB> for fvalue in fvalue_gen : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret = fvalue . haslayer ( cls ) <TAB><TAB><TAB><TAB> if ret : <TAB><TAB><TAB><TAB><TAB> return ret <TAB> return self . payload . haslayer ( cls )","if isinstance ( fvalue , Packet ) :","if hasattr ( fvalue , ""haslayer"" ) :",96.40019879166735,97.31,False
228,"def _post_attachment ( self , message , channel , color , sub_fields = None ) : <TAB> if channel is None : <TAB><TAB> message_channels = self . channels <TAB> else : <TAB><TAB> message_channels = [ channel ] <TAB> for message_channel in message_channels : <TAB><TAB> attachment = { <TAB><TAB><TAB> "" fallback "" : message , <TAB><TAB><TAB> "" text "" : message , <TAB><TAB><TAB> "" color "" : color , <TAB><TAB> } <TAB><TAB> <MASK> <TAB><TAB><TAB> attachment [ "" fields "" ] = sub_fields <TAB><TAB> self . slack_client . api_call ( <TAB><TAB><TAB> "" chat.postMessage "" , <TAB><TAB><TAB> channel = message_channel , <TAB><TAB><TAB> attachments = [ attachment ] , <TAB><TAB><TAB> as_user = True , <TAB><TAB> )",if sub_fields is not None :,if sub_fields :,96.04313240574761,98.18,False
229,"def create ( cls , repository , args ) : <TAB> key = cls ( ) <TAB> passphrase = os . environ . get ( "" ATTIC_PASSPHRASE "" ) <TAB> if passphrase is not None : <TAB><TAB> passphrase2 = passphrase <TAB> else : <TAB><TAB> passphrase , passphrase2 = 1 , 2 <TAB> while passphrase != passphrase2 : <TAB><TAB> passphrase = getpass ( "" Enter passphrase:  "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Passphrase must not be blank "" ) <TAB><TAB><TAB> continue <TAB><TAB> passphrase2 = getpass ( "" Enter same passphrase again:  "" ) <TAB><TAB> if passphrase != passphrase2 : <TAB><TAB><TAB> print ( "" Passphrases do not match "" ) <TAB> key . init ( repository , passphrase ) <TAB> if passphrase : <TAB><TAB> print ( "" Remember your passphrase. Your data will be inaccessible without it. "" ) <TAB> return key",if not passphrase :,if not passphrase :,100.0,100.00,True
230,"def _generate_create_date ( self ) : <TAB> if self . timezone is not None : <TAB><TAB> # First, assume correct capitalization <TAB><TAB> tzinfo = tz . gettz ( self . timezone ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Fall back to uppercase <TAB><TAB><TAB> tzinfo = tz . gettz ( self . timezone . upper ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise util . CommandError ( "" Can ' t locate timezone:  %s "" % self . timezone ) <TAB><TAB> create_date = ( <TAB><TAB><TAB> datetime . datetime . utcnow ( ) . replace ( tzinfo = tz . tzutc ( ) ) . astimezone ( tzinfo ) <TAB><TAB> ) <TAB> else : <TAB><TAB> create_date = datetime . datetime . now ( ) <TAB> return create_date",if tzinfo is None :,if not tzinfo :,96.192889044504,96.04,False
231,"def _read_header_lines ( fp ) : <TAB> """"""Read lines with headers until the start of body"""""" <TAB> lines = deque ( ) <TAB> for line in fp : <TAB><TAB> if is_empty ( line ) : <TAB><TAB><TAB> break <TAB><TAB> # tricky case if it's not a header and not an empty line <TAB><TAB> # usually means that user forgot to separate the body and newlines <TAB><TAB> # so ""unread"" this line here, what means to treat it like a body <TAB><TAB> <MASK> <TAB><TAB><TAB> fp . seek ( fp . tell ( ) - len ( line ) ) <TAB><TAB><TAB> break <TAB><TAB> lines . append ( line ) <TAB> return lines",if not _RE_HEADER . match ( line ) :,if not line . strip ( ) :,97.52794966805192,95.53,False
232,"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB><TAB> try : <TAB><TAB><TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB><TAB> except : <TAB><TAB><TAB> continue <TAB><TAB> uri , unused = uri_tuple <TAB><TAB> <MASK> <TAB><TAB><TAB> if utils . is_media_file ( uri ) == True : <TAB><TAB><TAB><TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB><TAB> return <TAB> open_dropped_files ( files )",if os . path . exists ( uri ) == True :,if uri :,64.7454682938707,93.89,False
233,"def remove_importlib ( frame , options ) : <TAB> if frame is None : <TAB><TAB> return None <TAB> for child in frame . children : <TAB><TAB> remove_importlib ( child , options = options ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # remove this node, moving the self_time and children up to the parent <TAB><TAB><TAB> frame . self_time + = child . self_time <TAB><TAB><TAB> frame . add_children ( child . children , after = child ) <TAB><TAB><TAB> child . remove_from_parent ( ) <TAB> return frame","if ""<frozen importlib._bootstrap"" in child . file_path :",if child . is_imported ( ) :,92.41956751217934,91.12,False
234,"def __call__ ( self , graph ) : <TAB> for layer_name , data in self . params : <TAB><TAB> <MASK> <TAB><TAB><TAB> node = graph . get_node ( layer_name ) <TAB><TAB><TAB> node . data = self . adjust_parameters ( node , data ) <TAB><TAB> else : <TAB><TAB><TAB> print_stderr ( "" Ignoring parameters for non-existent layer:  %s "" % layer_name ) <TAB> return graph",if layer_name in graph :,if self . is_existing ( layer_name ) :,90.39296279559595,92.12,False
235,"def test_with_three_points ( self ) : <TAB> cba = ia . Polygon ( [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 5 ) ] ) <TAB> for i , xy in enumerate ( cba ) : <TAB><TAB> assert i in [ 0 , 1 , 2 ] <TAB><TAB> if i == 0 : <TAB><TAB><TAB> assert np . allclose ( xy , ( 1 , 2 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert np . allclose ( xy , ( 3 , 4 ) ) <TAB><TAB> elif i == 2 : <TAB><TAB><TAB> assert np . allclose ( xy , ( 5 , 5 ) ) <TAB> assert i == 2",elif i == 1 :,elif i == 1 :,100.0,100.00,True
236,"def _serve ( self ) : <TAB> self . _conn = self . manager . request ( REQUEST_DNS_LISTENER , self . domain ) <TAB> conn = MsgPackMessages ( self . _conn ) <TAB> while self . active : <TAB><TAB> request = conn . recv ( ) <TAB><TAB> if not request : <TAB><TAB><TAB> logger . warning ( "" DNS: Recieved empty request. Shutdown "" ) <TAB><TAB><TAB> self . stop ( ) <TAB><TAB><TAB> break <TAB><TAB> now = time . time ( ) <TAB><TAB> response = self . handler . process ( request ) <TAB><TAB> if not response : <TAB><TAB><TAB> response = [ ] <TAB><TAB> used = time . time ( ) - now <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( "" DNS: Slow processing speed ( %s )s "" , used ) <TAB><TAB> conn . send ( response )",if used > 1 :,if used > self . speed :,70.11423847145609,98.12,False
237,"def read ( cls , fp , * * kwargs ) : <TAB> major_version , minor_version , count = read_fmt ( "" 2HI "" , fp ) <TAB> items = [ ] <TAB> for _ in range ( count ) : <TAB><TAB> length = read_fmt ( "" I "" , fp ) [ 0 ] - 4 <TAB><TAB> <MASK> <TAB><TAB><TAB> with io . BytesIO ( fp . read ( length ) ) as f : <TAB><TAB><TAB><TAB> items . append ( Annotation . read ( f ) ) <TAB> return cls ( major_version = major_version , minor_version = minor_version , items = items )",if length > 0 :,if length > 0 :,100.0,100.00,True
238,"def save_uploaded_files ( ) : <TAB> files = [ ] <TAB> unzip = bool ( request . form . get ( "" unzip "" ) in [ "" true "" , "" on "" ] ) <TAB> for uploaded_file in request . files . getlist ( "" files "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> with zipfile . ZipFile ( uploaded_file , "" r "" ) as zf : <TAB><TAB><TAB><TAB> for info in zf . infolist ( ) : <TAB><TAB><TAB><TAB><TAB> name = info . filename <TAB><TAB><TAB><TAB><TAB> size = info . file_size <TAB><TAB><TAB><TAB><TAB> data = zf . read ( name ) <TAB><TAB><TAB><TAB><TAB> if size > 0 : <TAB><TAB><TAB><TAB><TAB><TAB> files . append ( save_file ( data , filename = name . split ( "" / "" ) [ - 1 ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> files . append ( save_file ( uploaded_file ) ) <TAB> return files",if unzip and zipfile . is_zipfile ( uploaded_file ) :,if unzip :,96.10347382529362,95.66,False
239,"def analyze_string_content ( self , string , line_num , filename ) : <TAB> output = { } <TAB> if self . keyword_exclude and self . keyword_exclude . search ( string ) : <TAB><TAB> return output <TAB> for identifier in self . secret_generator ( <TAB><TAB> string , <TAB><TAB> filetype = determine_file_type ( filename ) , <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> secret = PotentialSecret ( <TAB><TAB><TAB> self . secret_type , <TAB><TAB><TAB> filename , <TAB><TAB><TAB> identifier , <TAB><TAB><TAB> line_num , <TAB><TAB> ) <TAB><TAB> output [ secret ] = secret <TAB> return output",if self . is_secret_false_positive ( identifier ) :,if not identifier :,82.35485208679385,93.56,False
240,"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name , definition in self . hyperparameter_definitions . items ( ) : <TAB><TAB> if name not in self . hyperparam_dict : <TAB><TAB><TAB> spec = definition [ "" spec "" ] <TAB><TAB><TAB> if "" DefaultValue "" in spec : <TAB><TAB><TAB><TAB> self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name )","elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",if self . hyperparam_dict [ name ] is None :,95.15057432734477,92.94,False
241,"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB><TAB> mod_type = self . etc [ 2 ] <TAB><TAB> if mod_type == imp . PY_SOURCE : <TAB><TAB><TAB> source = self . get_source ( fullname ) <TAB><TAB><TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB> elif mod_type == imp . PY_COMPILED : <TAB><TAB><TAB> self . _reopen ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . code = read_code ( self . file ) <TAB><TAB><TAB> finally : <TAB><TAB><TAB><TAB> self . file . close ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",elif mod_type == imp . PKG_DIRECTORY :,elif mod_type == imp . PY_DELEGATE :,99.07638315339523,98.38,False
242,"def eigh_abstract_eval ( operand , lower ) : <TAB> if isinstance ( operand , ShapedArray ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Argument to symmetric eigendecomposition must have shape [..., n, n], "" <TAB><TAB><TAB><TAB> "" got shape  {} "" . format ( operand . shape ) <TAB><TAB><TAB> ) <TAB><TAB> batch_dims = operand . shape [ : - 2 ] <TAB><TAB> n = operand . shape [ - 1 ] <TAB><TAB> v = ShapedArray ( batch_dims + ( n , n ) , operand . dtype ) <TAB><TAB> w = ShapedArray ( batch_dims + ( n , ) , lax . lax . _complex_basetype ( operand . dtype ) ) <TAB> else : <TAB><TAB> v , w = operand , operand <TAB> return v , w",if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,"if operand . shape [ - 2 ] != ( n , ) :",89.88926558400496,93.92,False
243,"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB><TAB> if dsn [ i ] . isspace ( ) : <TAB><TAB><TAB> i + = 1 <TAB><TAB><TAB> continue <TAB><TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> param = param_match . group ( 1 ) <TAB><TAB> i + = param_match . end ( ) <TAB><TAB> if i > = length : <TAB><TAB><TAB> return <TAB><TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB> if value is None : <TAB><TAB><TAB> return <TAB><TAB> i + = end <TAB><TAB> ret [ param ] = value <TAB> return ret",if not param_match :,if param_match is None :,71.08454949262291,97.95,False
244,"def load_weights_from_unsupervised ( self , unsupervised_model ) : <TAB> update_state_dict = copy . deepcopy ( self . network . state_dict ( ) ) <TAB> for param , weights in unsupervised_model . network . state_dict ( ) . items ( ) : <TAB><TAB> if param . startswith ( "" encoder "" ) : <TAB><TAB><TAB> # Convert encoder's layers name to match <TAB><TAB><TAB> new_param = "" tabnet. "" + param <TAB><TAB> else : <TAB><TAB><TAB> new_param = param <TAB><TAB> <MASK> <TAB><TAB><TAB> # update only common layers <TAB><TAB><TAB> update_state_dict [ new_param ] = weights <TAB> self . network . load_state_dict ( update_state_dict )",if self . network . state_dict ( ) . get ( new_param ) is not None :,if new_param in self . network . state_dict ( ) :,94.819099467782,94.62,False
245,"def viewer_setup ( self ) : <TAB> for key , value in DEFAULT_CAMERA_CONFIG . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> getattr ( self . viewer . cam , key ) [ : ] = value <TAB><TAB> else : <TAB><TAB><TAB> setattr ( self . viewer . cam , key , value )","if isinstance ( value , np . ndarray ) :","if isinstance ( value , ( list , tuple ) ) :",92.24964265457677,93.17,False
246,"def colormap_changed ( change ) : <TAB> if change [ "" new "" ] : <TAB><TAB> cmap_colors = [ <TAB><TAB><TAB> color [ 1 : ] for color in cmap . step . __dict__ [ "" _schemes "" ] [ colormap . value ] <TAB><TAB> ] <TAB><TAB> palette . value = "" ,  "" . join ( cmap_colors ) <TAB><TAB> colorbar = getattr ( cmap . step , colormap . value ) <TAB><TAB> colorbar_output = self . colorbar_widget <TAB><TAB> with colorbar_output : <TAB><TAB><TAB> colorbar_output . clear_output ( ) <TAB><TAB><TAB> display ( colorbar ) <TAB><TAB> <MASK> <TAB><TAB><TAB> labels = [ f "" Class  { i + 1 } "" for i in range ( len ( palette . value . split ( "" , "" ) ) ) ] <TAB><TAB><TAB> legend_labels . value = "" ,  "" . join ( labels )","if len ( palette . value ) > 0 and "","" in palette . value :","if change [ ""new"" ] :",67.11311480248396,93.29,False
247,"def invalidate ( self , layers = None ) : <TAB> if layers is None : <TAB><TAB> layers = Layer . AllLayers <TAB> if layers : <TAB><TAB> layers = set ( layers ) <TAB><TAB> self . invalidLayers . update ( layers ) <TAB><TAB> blockRenderers = [ <TAB><TAB><TAB> br <TAB><TAB><TAB> for br in self . blockRenderers <TAB><TAB><TAB> if br . layer is Layer . Blocks or br . layer not in layers <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . forgetDisplayLists ( ) <TAB><TAB> self . blockRenderers = blockRenderers <TAB><TAB> if self . renderer . showRedraw and Layer . Blocks in layers : <TAB><TAB><TAB> self . needsRedisplay = True",if len ( blockRenderers ) < len ( self . blockRenderers ) :,if len ( blockRenderers ) == 0 :,68.86225434351479,95.77,False
248,"def fromstring ( cls , input ) : <TAB> productions = [ ] <TAB> for linenum , line in enumerate ( input . split ( "" \n "" ) ) : <TAB><TAB> line = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> productions + = _read_dependency_production ( line ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise ValueError ( "" Unable to parse line  %s :  %s "" % ( linenum , line ) ) <TAB> if len ( productions ) == 0 : <TAB><TAB> raise ValueError ( "" No productions found! "" ) <TAB> return DependencyGrammar ( productions )","if line . startswith ( ""#"" ) or line == """" :",if not line :,65.6732127141211,91.52,False
249,"def repl ( m , base_path , rel_path = None ) : <TAB> if m . group ( "" comments "" ) : <TAB><TAB> tag = m . group ( "" comments "" ) <TAB> else : <TAB><TAB> tag = m . group ( "" open "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB><TAB><TAB><TAB> lambda m2 : repl_absolute ( m2 , base_path ) , m . group ( "" attr "" ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB><TAB><TAB><TAB> lambda m2 : repl_relative ( m2 , base_path , rel_path ) , m . group ( "" attr "" ) <TAB><TAB><TAB> ) <TAB><TAB> tag + = m . group ( "" close "" ) <TAB> return tag",if rel_path is None :,if rel_path is None :,100.0,100.00,True
250,"def encode ( path ) : <TAB> if isinstance ( path , str_cls ) : <TAB><TAB> try : <TAB><TAB><TAB> path = path . encode ( fs_encoding , "" strict "" ) <TAB><TAB> except UnicodeEncodeError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> path = path . encode ( fs_fallback_encoding , "" strict "" ) <TAB> return path",if not platform . is_linux ( ) :,if fs_fallback_encoding is None :,70.4168523853145,92.45,False
251,"def __iter__ ( self ) : <TAB> base_iterator = super ( ProcessIterable , self ) . __iter__ ( ) <TAB> if getattr ( self . queryset , "" _coerced "" , False ) : <TAB><TAB> for process in base_iterator : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> process = coerce_to_related_instance ( <TAB><TAB><TAB><TAB><TAB> process , process . flow_class . process_class <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> yield process <TAB> else : <TAB><TAB> for process in base_iterator : <TAB><TAB><TAB> yield process","if isinstance ( process , self . queryset . model ) :","if isinstance ( process , Process ) :",86.88973824498729,96.43,False
252,"def footnotes_under ( n : Element ) - > Iterator [ nodes . footnote ] : <TAB> if isinstance ( n , nodes . footnote ) : <TAB><TAB> yield n <TAB> else : <TAB><TAB> for c in n . children : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> elif isinstance ( c , nodes . Element ) : <TAB><TAB><TAB><TAB> yield from footnotes_under ( c )","if isinstance ( c , addnodes . start_of_file ) :","if c . tag != ""a"" :",92.6046599868944,90.00,False
253,"def _process_submissions ( self ) - > None : <TAB> """"""Process all submissions which have not been processed yet."""""" <TAB> while self . _to_be_processed : <TAB><TAB> job = self . _to_be_processed [ 0 ] <TAB><TAB> job . process ( ) # trigger computation <TAB><TAB> <MASK> <TAB><TAB><TAB> heapq . heappush ( <TAB><TAB><TAB><TAB> self . _steady_priority_queue , <TAB><TAB><TAB><TAB> OrderedJobs ( job . release_time , self . _order , job ) , <TAB><TAB><TAB> ) <TAB><TAB> self . _to_be_processed . popleft ( ) # remove right after it is added to the heap queue <TAB><TAB> self . _order + = 1",if not self . batch_mode :,if job . release_time :,97.22546616423593,96.55,False
254,"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB> # strip line, skip over empty lines <TAB><TAB> line = line . strip ( ) <TAB><TAB> if line == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> # skip over comments or empty lines <TAB><TAB> match = COMMENT . match ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # skip over localparts with delimiters <TAB><TAB> if strip_delimiters : <TAB><TAB><TAB> if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield line",if match :,if not match :,98.97076335136356,98.72,False
255,"def _get_payload_hash ( self , method , data = None ) : <TAB> if method in ( "" POST "" , "" PUT "" ) : <TAB><TAB> if data : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # File upload; don't try to read the entire payload <TAB><TAB><TAB><TAB> return UNSIGNED_PAYLOAD <TAB><TAB><TAB> return _hash ( data ) <TAB><TAB> else : <TAB><TAB><TAB> return UNSIGNED_PAYLOAD <TAB> else : <TAB><TAB> return _hash ( "" "" )","if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :","if data [ ""file"" ] :",73.15049984545696,86.52,False
256,"def get_download_info ( self ) : <TAB> try : <TAB><TAB> download_info = self . api . get_download_info ( self . game ) <TAB><TAB> result = True <TAB> except NoDownloadLinkFound as e : <TAB><TAB> print ( e ) <TAB><TAB> <MASK> <TAB><TAB><TAB> Config . unset ( "" current_download "" ) <TAB><TAB> GLib . idle_add ( <TAB><TAB><TAB> self . parent . parent . show_error , <TAB><TAB><TAB> _ ( "" Download error "" ) , <TAB><TAB><TAB> _ ( <TAB><TAB><TAB><TAB> "" There was an error when trying to fetch the download link! \n {} "" . format ( <TAB><TAB><TAB><TAB><TAB> e <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) , <TAB><TAB> ) <TAB><TAB> download_info = False <TAB><TAB> result = False <TAB> return result , download_info","if Config . get ( ""current_download"" ) == self . game . id :",if not download_info :,64.94223881135656,93.40,False
257,"def find_id ( self , doc_id ) : <TAB> self . _lock . acquire ( ) <TAB> try : <TAB><TAB> doc = self . _docs . get ( doc_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> doc = copy . deepcopy ( doc ) <TAB><TAB><TAB> doc [ "" id "" ] = doc_id <TAB><TAB><TAB> return doc <TAB> finally : <TAB><TAB> self . _lock . release ( )",if doc :,if doc :,100.0,100.00,True
258,"def assign_art ( self , session , task ) : <TAB> """"""Place the discovered art in the filesystem."""""" <TAB> if task in self . art_candidates : <TAB><TAB> candidate = self . art_candidates . pop ( task ) <TAB><TAB> self . _set_art ( task . album , candidate , not self . src_removed ) <TAB><TAB> <MASK> <TAB><TAB><TAB> task . prune ( candidate . path )",if self . src_removed :,if candidate . path :,71.81704550785739,94.48,False
259,"def _replace_named ( self , named , replace_scalar ) : <TAB> for item in named : <TAB><TAB> for name , value in self . _get_replaced_named ( item , replace_scalar ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise DataError ( "" Argument names must be strings. "" ) <TAB><TAB><TAB> yield name , value",if not is_string ( name ) :,"if not isinstance ( value , ( list , tuple ) ) :",64.56294065212043,90.44,False
260,"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB><TAB> # DataType doesn't have len function then convert it to string <TAB><TAB> if not hasattr ( val , "" __len__ "" ) : <TAB><TAB><TAB> val = str ( val ) <TAB><TAB> if len ( val ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> value = val <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB> value = ' "" ' + value + ' "" ' <TAB><TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res","if Driver . needsQuoting ( val , True ) :",if value :,71.95723710593032,96.04,False
261,"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> tiled_n = get_tiled ( n ) <TAB><TAB> if has_unknown_shape ( tiled_n ) : <TAB><TAB><TAB> if any ( c . key not in chunk_result for c in tiled_n . chunks ) : <TAB><TAB><TAB><TAB> # some of the chunks has been fused <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB><TAB><TAB> for node in ( n , tiled_n ) : <TAB><TAB><TAB><TAB> node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB><TAB><TAB> tiled_n . _nsplits = new_nsplits",if n . op in failed_ops :,if n . key not in failed_ops :,98.71987514511146,98.66,False
262,"def _read_filter ( self , data ) : <TAB> if data : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . inner_sha . update ( data ) <TAB><TAB> if self . expected_inner_md5sum : <TAB><TAB><TAB> self . inner_md5 . update ( data ) <TAB> return data",if self . expected_inner_sha256 :,if self . expected_inner_sha :,72.11282328646425,97.15,False
263,"def find_previous_editable ( self , * args ) : <TAB> if self . editw == 0 : <TAB><TAB> if self . _active_page > 0 : <TAB><TAB><TAB> self . switch_page ( self . _active_page - 1 ) <TAB> if not self . editw == 0 : <TAB><TAB> # remember that xrange does not return the 'last' value, <TAB><TAB> # so go to -1, not 0! (fence post error in reverse) <TAB><TAB> for n in range ( self . editw - 1 , - 1 , - 1 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . editw = n <TAB><TAB><TAB><TAB> break",if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,if self . _active_page == self . editw :,92.62419105443986,89.22,False
264,"def _get_event_for_message ( self , message_id ) : <TAB> with self . event_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" Event for message[ {} ] should have been created before accessing "" . format ( <TAB><TAB><TAB><TAB><TAB> message_id <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> return self . _events [ message_id ]",if message_id not in self . _events :,if message_id not in self . _events :,75.0,100.00,True
265,"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB><TAB> if len ( t ) == 1 : <TAB><TAB><TAB> return t [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> for part in t : <TAB><TAB><TAB><TAB> res = self . _get_deepest ( part ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return res <TAB><TAB><TAB> return None <TAB> return None",if res :,if res is not None :,70.03425863661317,96.90,False
266,"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB><TAB> <MASK> <TAB><TAB><TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB><TAB><TAB> return task_notify <TAB><TAB> elif self . _chain_notify : <TAB><TAB><TAB> return self . _chain_notify <TAB> return None",if action_node . notify :,if action_node . notify :,100.0,100.00,True
267,"def __init__ ( self , centered = None , shape_params = ( ) ) : <TAB> assert centered is None or isinstance ( centered , ( float , torch . Tensor ) ) <TAB> assert isinstance ( shape_params , ( tuple , list ) ) <TAB> assert all ( isinstance ( name , str ) for name in shape_params ) <TAB> if is_validation_enabled ( ) : <TAB><TAB> if isinstance ( centered , float ) : <TAB><TAB><TAB> assert 0 < = centered and centered < = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> assert ( 0 < = centered ) . all ( ) <TAB><TAB><TAB> assert ( centered < = 1 ) . all ( ) <TAB><TAB> else : <TAB><TAB><TAB> assert centered is None <TAB> self . centered = centered <TAB> self . shape_params = shape_params","elif isinstance ( centered , torch . Tensor ) :","elif isinstance ( centered , torch . Tensor ) :",100.0,100.00,True
268,"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB><TAB> squid_host = self . squid_hosts [ nickname ] <TAB><TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB><TAB> if fulldata is not None : <TAB><TAB><TAB> fulldata = fulldata . splitlines ( ) <TAB><TAB><TAB> for data in fulldata : <TAB><TAB><TAB><TAB> matches = self . stat_pattern . match ( data ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . publish_counter ( <TAB><TAB><TAB><TAB><TAB><TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB><TAB><TAB><TAB><TAB> )",if matches :,if matches is not None :,97.80373728237747,98.09,False
269,"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB><TAB> if size == 0 : <TAB><TAB><TAB> bsize = 0 <TAB><TAB> elif size < = 3 : <TAB><TAB><TAB> bsize = 4 <TAB><TAB> elif size < = 6 : <TAB><TAB><TAB> bsize = 8 <TAB><TAB> <MASK> <TAB><TAB><TAB> bsize = 12 <TAB><TAB> elif size < = 12 : <TAB><TAB><TAB> bsize = 16 <TAB><TAB> else : <TAB><TAB><TAB> bsize = 20 <TAB><TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 9 :,elif size <= 7 :,99.00060752674547,98.87,False
270,"def wait_for_initial_conf ( self , timeout = 1.0 ) : <TAB> logger . info ( "" Waiting for initial configuration "" ) <TAB> cur_timeout = timeout <TAB> # Arbiter do not already set our have_conf param <TAB> while not self . new_conf and not self . interrupted : <TAB><TAB> elapsed , _ , _ = self . handleRequests ( cur_timeout ) <TAB><TAB> if elapsed : <TAB><TAB><TAB> cur_timeout - = elapsed <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> cur_timeout = timeout <TAB><TAB> sys . stdout . write ( "" . "" ) <TAB><TAB> sys . stdout . flush ( )",if cur_timeout > 0 :,if cur_timeout <= 0 :,98.75110323748866,98.09,False
271,"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB><TAB> self . querylist = [ ] <TAB> else : <TAB><TAB> self . querylist = querylist <TAB><TAB> for query in self . querylist : <TAB><TAB><TAB> if self . query_id == - 1 : <TAB><TAB><TAB><TAB> self . query_id = query . query_id <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise ValueError ( "" query in list must be same query_id "" )",if self . query_id != query . query_id :,if self . query_id != query . query_id :,100.0,100.00,True
272,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB><TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB><TAB> if matchSelf : <TAB><TAB><TAB> yield s <TAB><TAB> <MASK> <TAB><TAB><TAB> yield from s . children_recurse_anon <TAB><TAB> else : <TAB><TAB><TAB> yield from s . _children <TAB><TAB> if s . siblingAbove is None : <TAB><TAB><TAB> break <TAB><TAB> s = s . siblingAbove <TAB><TAB> if Symbol . debug_lookup : <TAB><TAB><TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",if recurseInAnon :,elif matchAncestor :,98.64438018965559,98.62,False
273,"def get_default_params ( problem_type : str , penalty : str ) : <TAB> # TODO: get seed from seeds provider <TAB> if problem_type == REGRESSION : <TAB><TAB> default_params = { "" C "" : None , "" random_state "" : 0 , "" fit_intercept "" : True } <TAB><TAB> <MASK> <TAB><TAB><TAB> default_params [ "" solver "" ] = "" auto "" <TAB> else : <TAB><TAB> default_params = { <TAB><TAB><TAB> "" C "" : None , <TAB><TAB><TAB> "" random_state "" : 0 , <TAB><TAB><TAB> "" solver "" : _get_solver ( problem_type ) , <TAB><TAB><TAB> "" n_jobs "" : - 1 , <TAB><TAB><TAB> "" fit_intercept "" : True , <TAB><TAB> } <TAB> model_params = list ( default_params . keys ( ) ) <TAB> return model_params , default_params",if penalty == L2 :,"if penalty == ""auto"" :",99.02496889383579,98.18,False
274,"def _UploadDirectory ( local_dir : str , gcs_bucket : storage . Bucket , gcs_dir : str ) : <TAB> """"""Upload the contents of a local directory to a GCS Bucket."""""" <TAB> for file_name in os . listdir ( local_dir ) : <TAB><TAB> path = os . path . join ( local_dir , file_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . info ( "" Skipping  %s  as it ' s not a file. "" , path ) <TAB><TAB><TAB> continue <TAB><TAB> logging . info ( "" Uploading:  %s "" , path ) <TAB><TAB> gcs_blob = gcs_bucket . blob ( f "" { gcs_dir } / { file_name } "" ) <TAB><TAB> gcs_blob . upload_from_filename ( path )",if not os . path . isfile ( path ) :,if not os . path . isfile ( path ) :,100.0,100.00,True
275,"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB><TAB> self . decode_query_ids ( trans , conditional . left ) <TAB><TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB><TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB><TAB> if left_base in self . FIELDS : <TAB><TAB><TAB> field = self . FIELDS [ left_base ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> conditional . right = trans . security . decode_id ( conditional . right )",if field . id_decode :,"if field . get ( ""id"" ) :",74.11033771340999,95.84,False
276,"def data_dir ( self ) - > Path : <TAB> try : <TAB><TAB> from appdirs import user_data_dir <TAB> except ImportError : <TAB><TAB> # linux <TAB><TAB> path = Path . home ( ) / "" .local "" / "" share "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return path / "" dephell "" <TAB><TAB> # mac os <TAB><TAB> path = Path . home ( ) / "" Library "" / "" Application Support "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return path / "" dephell "" <TAB><TAB> self . pip_main ( [ "" install "" , "" appdirs "" ] ) <TAB><TAB> from appdirs import user_data_dir <TAB> return Path ( user_data_dir ( "" dephell "" ) )",if path . exists ( ) :,if path . exists ( ) :,100.0,100.00,True
277,"def setGameCard ( self , isGameCard = False ) : <TAB> if isGameCard : <TAB><TAB> targetValue = 1 <TAB> else : <TAB><TAB> targetValue = 0 <TAB> for nca in self : <TAB><TAB> if isinstance ( nca , Nca ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> Print . info ( "" writing isGameCard for  %s ,  %d "" % ( str ( nca . _path ) , targetValue ) ) <TAB><TAB><TAB> nca . header . setIsGameCard ( targetValue )",if nca . header . getIsGameCard ( ) == targetValue :,if nca . header . setIsGameCard ( targetValue ) :,94.1126387791783,95.37,False
278,"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB><TAB> if mode == "" start "" : <TAB><TAB><TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" key "" <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" end "" <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB> "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB> ) <TAB> if mode != "" end "" : <TAB><TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","elif mode == ""key"" :","elif mode == ""end"" :",99.16306039733045,99.08,False
279,"def register_aggregate_groups ( conn , * groups ) : <TAB> seen = set ( ) <TAB> for group in groups : <TAB><TAB> klasses = AGGREGATE_COLLECTION [ group ] <TAB><TAB> for klass in klasses : <TAB><TAB><TAB> name = getattr ( klass , "" name "" , klass . __name__ ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> seen . add ( name ) <TAB><TAB><TAB><TAB> conn . create_aggregate ( name , - 1 , klass )",if name not in seen :,if name not in seen :,100.0,100.00,True
280,"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 : # default, torch have only data, axis=None, keepdims=False <TAB><TAB> if isinstance ( inputs [ 1 ] , int ) : <TAB><TAB><TAB> axis = int ( inputs [ 1 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> axis = inputs [ 1 ] <TAB><TAB> else : <TAB><TAB><TAB> axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB><TAB> keepdims = bool ( inputs [ 2 ] ) <TAB> return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims )",elif _is_int_seq ( inputs [ 1 ] ) :,"elif isinstance ( inputs [ 1 ] , list ) :",97.93815048070213,95.41,False
281,"def walks_generator ( ) : <TAB> if filelist is not None : <TAB><TAB> bucket = [ ] <TAB><TAB> for filename in filelist : <TAB><TAB><TAB> with io . open ( filename ) as inf : <TAB><TAB><TAB><TAB> for line in inf : <TAB><TAB><TAB><TAB><TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( ""   "" ) ] <TAB><TAB><TAB><TAB><TAB> bucket . append ( walk ) <TAB><TAB><TAB><TAB><TAB> if len ( bucket ) == batch_size : <TAB><TAB><TAB><TAB><TAB><TAB> yield bucket <TAB><TAB><TAB><TAB><TAB><TAB> bucket = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> yield bucket <TAB> else : <TAB><TAB> for _ in range ( epoch ) : <TAB><TAB><TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB><TAB><TAB><TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB><TAB><TAB><TAB> yield walks",if len ( bucket ) :,if len ( bucket ) == batch_size :,82.73554123676861,97.92,False
282,"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Count the pass vs failures <TAB><TAB><TAB> if resultset [ "" result "" ] : <TAB><TAB><TAB><TAB> results [ "" num_passed_states "" ] + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results [ "" num_failed_states "" ] + = 1 <TAB><TAB><TAB> # Count durations <TAB><TAB><TAB> results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB> log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB> return results","if isinstance ( resultset , dict ) and ""duration"" in resultset :","if state == ""pass"" :",83.48033637414896,94.26,False
283,"def _replicator_primary_device ( ) - > snt_replicator . Replicator : <TAB> # NOTE: The explicit device list is required since currently Replicator <TAB> # only considers CPU and GPU devices. This means on TPU by default we only <TAB> # mirror on the local CPU. <TAB> for device_type in ( "" TPU "" , "" GPU "" , "" CPU "" ) : <TAB><TAB> devices = tf . config . experimental . list_logical_devices ( device_type = device_type ) <TAB><TAB> <MASK> <TAB><TAB><TAB> devices = [ d . name for d in devices ] <TAB><TAB><TAB> logging . info ( "" Replicating over  %s "" , devices ) <TAB><TAB><TAB> return snt_replicator . Replicator ( devices = devices ) <TAB> assert False , "" No TPU/GPU or CPU found """,if devices :,if len ( devices ) > 1 :,73.16841935884997,96.38,False
284,"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB><TAB> return [ ] <TAB> if not http . headers : <TAB><TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance ( headers , dict ) : <TAB><TAB> headers = headers . items ( ) <TAB> output = [ ] <TAB> for key , value in headers : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> ua = Parse ( value ) <TAB><TAB> if not ua : <TAB><TAB><TAB> continue <TAB><TAB> result = self . get_tag_from_ua ( ua ) <TAB><TAB> if result : <TAB><TAB><TAB> output . append ( result ) <TAB> return output","if key != ""User-Agent"" :","if key . startswith ( ""HTTP_"" ) :",98.0967166319582,96.09,False
285,"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB><TAB> <MASK> <TAB><TAB><TAB> v = quote ( value ) <TAB><TAB> else : <TAB><TAB><TAB> v = value <TAB><TAB> return u "" {0}   {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB><TAB> if not value : <TAB><TAB><TAB> return None <TAB><TAB> el<MASK> <TAB><TAB><TAB> return quote ( value ) <TAB><TAB> else : <TAB><TAB><TAB> return value","if not metadata . get ( ""nargs"" ) :","if isinstance ( value , str ) :",62.168218596224975,89.70,False
286,"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB><TAB> # take action <TAB><TAB> if self . action_input . selected_index == 0 : # Cancel <TAB><TAB><TAB> self . back_to_parent ( ) <TAB><TAB> elif self . action_input . selected_index == 1 : # Apply <TAB><TAB><TAB> self . _apply_prefs ( ) <TAB><TAB><TAB> client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB><TAB> <MASK> # OK <TAB><TAB><TAB> self . _apply_prefs ( ) <TAB><TAB><TAB> self . back_to_parent ( )",elif self . action_input . selected_index == 2 :,"elif c in [ curses . KEY_OK , util . KEY_OK2 ] :",95.52199825319046,92.96,False
287,def logic ( ) : <TAB> if reset == 1 : <TAB><TAB> lfsr . next = 1 <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> # lfsr.next[24:1] = lfsr[23:0] <TAB><TAB><TAB> lfsr . next = lfsr << 1 <TAB><TAB><TAB> lfsr . next [ 0 ] = lfsr [ 23 ] ^ lfsr [ 22 ] ^ lfsr [ 21 ] ^ lfsr [ 16 ],if enable :,if reset == 0 :,94.36470191205244,95.30,False
288,"def action_delete ( self , request , attachments ) : <TAB> deleted_attachments = [ ] <TAB> desynced_posts = [ ] <TAB> for attachment in attachments : <TAB><TAB> <MASK> <TAB><TAB><TAB> deleted_attachments . append ( attachment . pk ) <TAB><TAB><TAB> desynced_posts . append ( attachment . post_id ) <TAB> if desynced_posts : <TAB><TAB> with transaction . atomic ( ) : <TAB><TAB><TAB> for post in Post . objects . filter ( id__in = desynced_posts ) : <TAB><TAB><TAB><TAB> self . delete_from_cache ( post , deleted_attachments ) <TAB> for attachment in attachments : <TAB><TAB> attachment . delete ( ) <TAB> message = _ ( "" Selected attachments have been deleted. "" ) <TAB> messages . success ( request , message )",if attachment . post :,if attachment . pk :,98.95107179152033,98.80,False
289,"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB><TAB> if isinstance ( index , int ) : <TAB><TAB><TAB> if index < 0 or index > = len ( self . features ) : <TAB><TAB><TAB><TAB> raise IndexError ( index ) <TAB><TAB><TAB> if self . features [ index ] is None : <TAB><TAB><TAB><TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB> if feature : <TAB><TAB><TAB><TAB><TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB> self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB> return self . features [ index ] <TAB><TAB> <MASK> <TAB><TAB><TAB> indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]","elif isinstance ( index , slice ) :","if isinstance ( index , Index ) :",80.331587330552,98.24,False
290,"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB><TAB> self . _pos + = len ( chunk ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> elif self . _pos == start : <TAB><TAB><TAB> return b "" "" <TAB><TAB> else : <TAB><TAB><TAB> chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB> if stop is not None and self . _pos > stop : <TAB><TAB><TAB><TAB> chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB> assert len ( chunk ) == stop - start <TAB><TAB><TAB> return chunk <TAB> else : <TAB><TAB> raise StopIteration ( )",if self . _pos < start :,if self . _pos >= self . _max_pos :,70.65062635004016,95.87,False
291,"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB><TAB> for name in files : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB><TAB><TAB><TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if ""meta-environment"" in root or ""cross-canadian"" in root :","if ""build"" in root or ""build_sdk"" in root :",97.35646994703939,96.02,False
292,"def _load_windows_store_certs ( self , storename , purpose ) : <TAB> certs = bytearray ( ) <TAB> try : <TAB><TAB> for cert , encoding , trust in enum_certificates ( storename ) : <TAB><TAB><TAB> # CA certs are never PKCS#7 encoded <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if trust is True or purpose . oid in trust : <TAB><TAB><TAB><TAB><TAB> certs . extend ( cert ) <TAB> except PermissionError : <TAB><TAB> warnings . warn ( "" unable to enumerate Windows certificate store "" ) <TAB> if certs : <TAB><TAB> self . load_verify_locations ( cadata = certs ) <TAB> return certs","if encoding == ""x509_asn"" :","if encoding == ""PKCS#7"" :",98.72901839120273,97.54,False
293,"def test_tokenizer_identifier_with_correct_config ( self ) : <TAB> for tokenizer_class in [ BertTokenizer , BertTokenizerFast , AutoTokenizer ] : <TAB><TAB> tokenizer = tokenizer_class . from_pretrained ( "" wietsedv/bert-base-dutch-cased "" ) <TAB><TAB> self . assertIsInstance ( tokenizer , ( BertTokenizer , BertTokenizerFast ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( tokenizer . basic_tokenizer . do_lower_case , False ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( tokenizer . do_lower_case , False ) <TAB><TAB> self . assertEqual ( tokenizer . model_max_length , 512 )","if isinstance ( tokenizer , BertTokenizer ) :","if hasattr ( tokenizer , ""basic_tokenizer"" ) :",67.33234180284965,94.58,False
294,"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB><TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB><TAB> if path_id is None : <TAB><TAB><TAB> continue <TAB><TAB> self . lock . acquire ( ) <TAB><TAB> self . modules [ path_id ] = module <TAB><TAB> self . lock . release ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB><TAB><TAB> self . _relations [ path_id ] = [ ] <TAB><TAB><TAB> for package in resolution : <TAB><TAB><TAB><TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB><TAB><TAB> self . queue_send . put ( ( path_id , module , False , resolution ) )",if resolve :,if resolve :,100.0,100.00,True
295,"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB><TAB> for base in bases : <TAB><TAB><TAB> if hasattr ( base , "" trace "" ) : <TAB><TAB><TAB><TAB> include_trace = False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> include_garbage = False <TAB> if include_profile : <TAB><TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB><TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB><TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs )","if hasattr ( base , ""garbage"" ) :","if hasattr ( base , ""garbage"" ) :",100.0,100.00,True
296,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_owner_ : <TAB><TAB> res + = prefix + ( "" owner:  %s \n "" % self . DebugFormatString ( self . owner_ ) ) <TAB> cnt = 0 <TAB> for e in self . entries_ : <TAB><TAB> elm = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> elm = "" ( %d ) "" % cnt <TAB><TAB> res + = prefix + ( "" entries %s  < \n "" % elm ) <TAB><TAB> res + = e . __str__ ( prefix + ""    "" , printElemNumber ) <TAB><TAB> res + = prefix + "" > \n "" <TAB><TAB> cnt + = 1 <TAB> return res",if printElemNumber :,if printElemNumber :,100.0,100.00,True
297,"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB><TAB> if escaped : <TAB><TAB><TAB> buf . append ( c ) <TAB><TAB> elif c == "" \\ "" : <TAB><TAB><TAB> escaped = True <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" "" . join ( buf ) <TAB><TAB> else : <TAB><TAB><TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) )","elif c == "">"" :","elif c == ""\\"" :",96.570360985191,97.81,False
298,"def get_batches ( train_nodes , train_labels , batch_size = 64 , shuffle = True ) : <TAB> if shuffle : <TAB><TAB> random . shuffle ( train_nodes ) <TAB> total = train_nodes . shape [ 0 ] <TAB> for i in range ( 0 , total , batch_size ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> cur_nodes = train_nodes [ i : i + batch_size ] <TAB><TAB><TAB> cur_labels = train_labels [ cur_nodes ] <TAB><TAB><TAB> yield cur_nodes , cur_labels",if i + batch_size <= total :,if i + batch_size < total :,98.41141636975831,98.35,False
299,"def _get_all_info_lines ( data ) : <TAB> infos = [ ] <TAB> for row in data : <TAB><TAB> splitrow = row . split ( ) <TAB><TAB> if len ( splitrow ) > 0 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> infos . append ( ""   "" . join ( splitrow [ 1 : ] ) ) <TAB> return infos","if splitrow [ 0 ] == ""INFO:"" :","if splitrow [ 0 ] == ""info"" :",97.96754454765386,96.74,False
300,"def _validate_client_public_key ( self , username , key_data ) : <TAB> """"""Validate a client public key for the specified user"""""" <TAB> try : <TAB><TAB> key = decode_ssh_public_key ( key_data ) <TAB> except KeyImportError : <TAB><TAB> return None <TAB> options = None <TAB> if self . _client_keys : <TAB><TAB> options = self . _client_keys . validate ( key , self . _peer_addr ) <TAB> if options is None : <TAB><TAB> result = self . _owner . validate_public_key ( username , key ) <TAB><TAB> if asyncio . iscoroutine ( result ) : <TAB><TAB><TAB> result = yield from result <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> options = { } <TAB> self . _key_options = options <TAB> return key",if not result :,if not result :,100.0,100.00,True
301,"def attach_related_versions ( addons , addon_dict = None ) : <TAB> if addon_dict is None : <TAB><TAB> addon_dict = { addon . id : addon for addon in addons } <TAB> all_ids = set ( filter ( None , ( addon . _current_version_id for addon in addons ) ) ) <TAB> versions = list ( Version . objects . filter ( id__in = all_ids ) . order_by ( ) ) <TAB> for version in versions : <TAB><TAB> try : <TAB><TAB><TAB> addon = addon_dict [ version . addon_id ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> log . info ( "" Version  %s  has an invalid add-on id. "" % version . id ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> addon . _current_version = version <TAB><TAB> version . addon = addon",if addon . _current_version_id == version . id :,if not addon . _current_version :,76.53101738555057,95.76,False
302,"def move_view ( obj , evt ) : <TAB> position = obj . GetCurrentCursorPosition ( ) <TAB> for other_axis , axis_number in self . _axis_names . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> ipw3d = getattr ( self , "" ipw_3d_ %s "" % other_axis ) <TAB><TAB> ipw3d . ipw . slice_position = position [ axis_number ]",if other_axis == axis_name :,if other_axis not in position :,95.12978504458174,94.21,False
303,"def func_wrapper ( * args , * * kwargs ) : <TAB> warnings . simplefilter ( "" always "" , DeprecationWarning ) # turn off filter <TAB> for old , new in arg_mapping . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> f "" Keyword argument  ' { old } '  has been  "" <TAB><TAB><TAB><TAB> f "" deprecated in favour of  ' { new } ' .  "" <TAB><TAB><TAB><TAB> f "" ' { old } '  will be removed in a future version. "" , <TAB><TAB><TAB><TAB> category = DeprecationWarning , <TAB><TAB><TAB><TAB> stacklevel = 2 , <TAB><TAB><TAB> ) <TAB><TAB><TAB> val = kwargs . pop ( old ) <TAB><TAB><TAB> kwargs [ new ] = val <TAB> # reset filter <TAB> warnings . simplefilter ( "" default "" , DeprecationWarning ) <TAB> return func ( * args , * * kwargs )",if old in kwargs :,if old in kwargs :,75.0,100.00,True
304,"def inner_connection_checker ( self , * args , * * kwargs ) : <TAB> LOG . debug ( "" in _connection_checker "" ) <TAB> for attempts in range ( 5 ) : <TAB><TAB> try : <TAB><TAB><TAB> return func ( self , * args , * * kwargs ) <TAB><TAB> except exception . VolumeBackendAPIException as e : <TAB><TAB><TAB> pattern = re . compile ( r "" .*Session id expired$ "" ) <TAB><TAB><TAB> matches = pattern . match ( six . text_type ( e ) ) <TAB><TAB><TAB> if matches : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> LOG . debug ( "" Session might have expired. "" ""  Trying to relogin "" ) <TAB><TAB><TAB><TAB><TAB> self . _login ( ) <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> LOG . error ( "" Re-throwing Exception  %s "" , e ) <TAB><TAB><TAB> raise",if attempts < 4 :,if attempts == 0 :,98.69793989861431,98.29,False
305,"def set ( self , pcount ) : <TAB> """"""Set channel prefetch_count setting."""""" <TAB> if pcount != self . prev : <TAB><TAB> new_value = pcount <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" QoS: Disabled: prefetch_count exceeds  %r "" , PREFETCH_COUNT_MAX <TAB><TAB><TAB> ) <TAB><TAB><TAB> new_value = 0 <TAB><TAB> logger . debug ( "" basic.qos: prefetch_count-> %s "" , new_value ) <TAB><TAB> self . callback ( prefetch_count = new_value ) <TAB><TAB> self . prev = pcount <TAB> return pcount",if pcount > PREFETCH_COUNT_MAX :,if new_value > PREFETCH_COUNT_MAX :,87.03475038026039,97.62,False
306,"def _build_gcs_object_key ( self , key ) : <TAB> if self . platform_specific_separator : <TAB><TAB> <MASK> <TAB><TAB><TAB> gcs_object_key = os . path . join ( <TAB><TAB><TAB><TAB> self . prefix , self . _convert_key_to_filepath ( key ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> gcs_object_key = "" / "" . join ( ( self . prefix , self . _convert_key_to_filepath ( key ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> return gcs_object_key",if self . prefix :,if self . prefix :,100.0,100.00,True
307,"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = "" __ %s __ "" % name <TAB><TAB><TAB> if hasattr ( a , name ) : <TAB><TAB><TAB><TAB> res = eval ( expr , dict ) <TAB><TAB><TAB><TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = "" __ %s __ "" % name <TAB><TAB><TAB> if hasattr ( a , name ) : <TAB><TAB><TAB><TAB> res = eval ( expr , dict ) <TAB><TAB><TAB><TAB> self . unop_test ( a , res , expr , name )",if name not in skip :,if name not in skip :,100.0,100.00,True
308,def isCurveMonotonic ( set_ ) : <TAB> for i in range ( len ( set_ ) - 1 ) : <TAB><TAB> # ==== added by zli ======= <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> # ==== added by zli ======= <TAB><TAB> # ==== added by zli ======= <TAB><TAB> # if set_[i][1] > set_[i + 1][1]: <TAB><TAB> if set_ [ i ] [ 1 ] > = set_ [ i + 1 ] [ 1 ] : <TAB><TAB><TAB> # ==== added by zli ======= <TAB><TAB><TAB> return False <TAB> return True,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,if set_ [ i ] [ 0 ] <= set_ [ i + 1 ] [ 0,97.16006899122047,97.27,False
309,"def show_topics ( ) : <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> content = os . listdir ( pp ) <TAB><TAB> for pn in content : <TAB><TAB><TAB> if "" . "" in pn : <TAB><TAB><TAB><TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> name = pn <TAB><TAB><TAB> print ( name )",if not os . path . isdir ( pp ) :,if not os . path . isdir ( pp ) :,100.0,100.00,True
310,"def test_send_error ( self ) : <TAB> allow_transfer_encoding_codes = ( 205 , 304 ) <TAB> for code in ( 101 , 102 , 204 , 205 , 304 ) : <TAB><TAB> self . con . request ( "" SEND_ERROR "" , "" / {} "" . format ( code ) ) <TAB><TAB> res = self . con . getresponse ( ) <TAB><TAB> self . assertEqual ( code , res . status ) <TAB><TAB> self . assertEqual ( None , res . getheader ( "" Content-Length "" ) ) <TAB><TAB> self . assertEqual ( None , res . getheader ( "" Content-Type "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( None , res . getheader ( "" Transfer-Encoding "" ) ) <TAB><TAB> data = res . read ( ) <TAB><TAB> self . assertEqual ( b "" "" , data )",if code not in allow_transfer_encoding_codes :,if code in allow_transfer_encoding_codes :,99.002981588684,98.84,False
311,"def _length_hint ( obj ) : <TAB> """"""Returns the length hint of an object."""""" <TAB> try : <TAB><TAB> return len ( obj ) <TAB> except ( AttributeError , TypeError ) : <TAB><TAB> try : <TAB><TAB><TAB> get_hint = type ( obj ) . __length_hint__ <TAB><TAB> except AttributeError : <TAB><TAB><TAB> return None <TAB><TAB> try : <TAB><TAB><TAB> hint = get_hint ( obj ) <TAB><TAB> except TypeError : <TAB><TAB><TAB> return None <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> return hint","if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",if not hint :,60.408483711255954,90.40,False
312,"def _rmtree ( self , path ) : <TAB> # Essentially a stripped down version of shutil.rmtree.  We can't <TAB> # use globals because they may be None'ed out at shutdown. <TAB> for name in self . _listdir ( path ) : <TAB><TAB> fullname = self . _path_join ( path , name ) <TAB><TAB> try : <TAB><TAB><TAB> isdir = self . _isdir ( fullname ) <TAB><TAB> except self . _os_error : <TAB><TAB><TAB> isdir = False <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _rmtree ( fullname ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . _remove ( fullname ) <TAB><TAB><TAB> except self . _os_error : <TAB><TAB><TAB><TAB> pass <TAB> try : <TAB><TAB> self . _rmdir ( path ) <TAB> except self . _os_error : <TAB><TAB> pass",if isdir :,if isdir :,75.0,100.00,True
313,"def get_sources ( self , sources = None ) : <TAB> """"""Returns all sources from this provider."""""" <TAB> self . _load ( ) <TAB> if sources is None : <TAB><TAB> sources = list ( self . data . keys ( ) ) <TAB> elif not isinstance ( sources , ( list , tuple ) ) : <TAB><TAB> sources = [ sources ] <TAB> for source in sources : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise KeyError ( <TAB><TAB><TAB><TAB> "" Invalid data key:  {} . Valid keys are:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> source , "" ,  "" . join ( str ( k ) for k in self . data ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return { k : self . data [ k ] for k in sources }",if source not in self . data :,if source not in self . data :,100.0,100.00,True
314,"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB><TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB><TAB> if short_has_arg ( opt , shortopts ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not args : <TAB><TAB><TAB><TAB><TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB><TAB><TAB><TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB><TAB><TAB> optarg , optstring = optstring , "" "" <TAB><TAB> else : <TAB><TAB><TAB> optarg = "" "" <TAB><TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args","if optstring == """" :","if optstring == """" :",100.0,100.00,True
315,"def _sanitize_dict ( self , config_dict , allow_val_change = None , ignore_keys : set = None ) : <TAB> sanitized = { } <TAB> for k , v in six . iteritems ( config_dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> k , v = self . _sanitize ( k , v , allow_val_change ) <TAB><TAB> sanitized [ k ] = v <TAB> return sanitized",if ignore_keys and k in ignore_keys :,if k in ignore_keys :,93.3391312284347,95.41,False
316,def x ( data ) : <TAB> count = 0 <TAB> while count < 10 : <TAB><TAB> data . start_example ( SOME_LABEL ) <TAB><TAB> b = data . draw_bits ( 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> count + = 1 <TAB><TAB> data . stop_example ( discard = not b ) <TAB> data . mark_interesting ( ),if b :,if b :,100.0,100.00,True
317,"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB><TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB><TAB> prompt = "" (R/F)>  "" <TAB><TAB> answer = "" "" <TAB><TAB> try : <TAB><TAB><TAB> answer = raw_input ( prompt ) <TAB><TAB> except NameError : <TAB><TAB><TAB> answer = input ( prompt ) <TAB><TAB> if answer . upper ( ) == "" F "" : <TAB><TAB><TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( "" Resuming previous scan "" ) <TAB><TAB><TAB> config . resume = True <TAB> return config . resume","elif answer . upper ( ) == ""R"" :","elif answer . upper ( ) == ""R"" :",100.0,100.00,True
318,"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB><TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB> with function . no_backprop_mode ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB> elif isinstance ( in_arrays , dict ) : <TAB><TAB><TAB><TAB> results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results = self . calc_local ( in_arrays ) <TAB><TAB> if self . _progress_hook : <TAB><TAB><TAB> self . _progress_hook ( batch ) <TAB><TAB> yield results","if isinstance ( in_arrays , tuple ) :","if isinstance ( in_arrays , list ) :",98.80960373695471,98.90,False
319,"def _send_until_done ( self , data ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> return self . connection . send ( data ) <TAB><TAB> except OpenSSL . SSL . WantWriteError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise timeout ( ) <TAB><TAB><TAB> continue <TAB><TAB> except OpenSSL . SSL . SysCallError as e : <TAB><TAB><TAB> raise SocketError ( str ( e ) )","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",if self . timeout :,59.50928696069661,84.51,False
320,"def _read_jtl_chunk ( self , jtl ) : <TAB> data = jtl . read ( 1024 * 1024 * 10 ) <TAB> if data : <TAB><TAB> parts = data . rsplit ( "" \n "" , 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ready_chunk = self . buffer + parts [ 0 ] + "" \n "" <TAB><TAB><TAB> self . buffer = parts [ 1 ] <TAB><TAB><TAB> df = string_to_df ( ready_chunk ) <TAB><TAB><TAB> self . stat_queue . put ( df ) <TAB><TAB><TAB> return df <TAB><TAB> else : <TAB><TAB><TAB> self . buffer + = parts [ 0 ] <TAB> else : <TAB><TAB> if self . jmeter_finished : <TAB><TAB><TAB> self . agg_finished = True <TAB><TAB> jtl . readline ( ) <TAB> return None",if len ( parts ) > 1 :,if len ( parts ) == 2 :,76.27410355176512,98.09,False
321,"def __new__ ( mcl , classname , bases , dictionary ) : <TAB> slots = list ( dictionary . get ( "" __slots__ "" , [ ] ) ) <TAB> for getter_name in [ key for key in dictionary if key . startswith ( "" get_ "" ) ] : <TAB><TAB> name = getter_name <TAB><TAB> slots . append ( "" __ "" + name ) <TAB><TAB> getter = dictionary . pop ( getter_name ) <TAB><TAB> setter = dictionary . get ( setter_name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> del dictionary [ setter_name ] <TAB><TAB> dictionary [ name ] = property ( getter . setter ) <TAB><TAB> dictionary [ "" __slots__ "" ] = tuple ( slots ) <TAB><TAB> return super ( ) . __new__ ( mcl , classname , bases , dictionary )","if setter is not None and isinstance ( setter , collections . Callable ) :",if setter is None :,71.81357044441478,94.49,False
322,"def tex_coords ( self ) : <TAB> """"""Array of texture coordinate data."""""" <TAB> if "" multi_tex_coords "" not in self . domain . attribute_names : <TAB><TAB> <MASK> <TAB><TAB><TAB> domain = self . domain <TAB><TAB><TAB> attribute = domain . attribute_names [ "" tex_coords "" ] <TAB><TAB><TAB> self . _tex_coords_cache = attribute . get_region ( <TAB><TAB><TAB><TAB> attribute . buffer , self . start , self . count <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . _tex_coords_cache_version = domain . _version <TAB><TAB> region = self . _tex_coords_cache <TAB><TAB> region . invalidate ( ) <TAB><TAB> return region . array <TAB> else : <TAB><TAB> return None",if self . _tex_coords_cache_version != self . domain . _version :,if self . _tex_coords_cache is None :,92.25968099705804,95.10,False
323,"def index ( self , sub , start = 0 ) : <TAB> """"""Returns the index of the closing bracket"""""" <TAB> br = "" ([ { < "" [ "" )]}> "" . index ( sub ) ] <TAB> count = 0 <TAB> for i in range ( start , len ( self . string ) ) : <TAB><TAB> char = self . string [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> count + = 1 <TAB><TAB> elif char == sub : <TAB><TAB><TAB> if count > 0 : <TAB><TAB><TAB><TAB> count - = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return i <TAB> err = "" Closing bracket  {!r}  missing in string  {!r} "" . format ( <TAB><TAB> sub , "" "" . join ( self . original ) <TAB> ) <TAB> raise ParseError ( err )",if char == br :,if char == br :,100.0,100.00,True
324,"def test_createFile ( self ) : <TAB> text = "" This is a test! "" <TAB> path = tempfile . mktemp ( ) <TAB> try : <TAB><TAB> koDoc = self . _koDocFromPath ( path , load = False ) <TAB><TAB> koDoc . buffer = text <TAB><TAB> koDoc . save ( 0 ) <TAB><TAB> del koDoc <TAB><TAB> koDoc2 = self . _koDocFromPath ( path ) <TAB><TAB> assert koDoc2 . buffer == text <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . unlink ( path ) # clean up",if os . path . exists ( path ) :,if os . path . exists ( path ) :,100.0,100.00,True
325,"def __editScopeHasEdit ( self , attributeHistory ) : <TAB> with attributeHistory . context : <TAB><TAB> tweak = GafferScene . EditScopeAlgo . acquireParameterEdit ( <TAB><TAB><TAB> attributeHistory . scene . node ( ) , <TAB><TAB><TAB> attributeHistory . context [ "" scene:path "" ] , <TAB><TAB><TAB> attributeHistory . attributeName , <TAB><TAB><TAB> IECoreScene . ShaderNetwork . Parameter ( "" "" , self . __parameter ) , <TAB><TAB><TAB> createIfNecessary = False , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> return tweak [ "" enabled "" ] . getValue ( )",if tweak is None :,if not tweak :,68.12347825224533,97.41,False
326,"def mail_migrator ( app , schema_editor ) : <TAB> Event_SettingsStore = app . get_model ( "" pretixbase "" , "" Event_SettingsStore "" ) <TAB> for ss in Event_SettingsStore . objects . filter ( <TAB><TAB> key__in = [ <TAB><TAB><TAB> "" mail_text_order_approved "" , <TAB><TAB><TAB> "" mail_text_order_placed "" , <TAB><TAB><TAB> "" mail_text_order_placed_require_approval "" , <TAB><TAB> ] <TAB> ) : <TAB><TAB> chgd = ss . value . replace ( "" {date} "" , "" {expire_date} "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ss . value = chgd <TAB><TAB><TAB> ss . save ( ) <TAB><TAB><TAB> cache . delete ( "" hierarkey_ {} _ {} "" . format ( "" event "" , ss . object_id ) )",if chgd != ss . value :,if chgd :,79.88530684171654,97.26,False
327,"def __get_limits ( self ) : <TAB> dimension = len ( self . __tree . get_root ( ) . data ) <TAB> nodes = self . __get_all_nodes ( ) <TAB> max , min = [ float ( "" -inf "" ) ] * dimension , [ float ( "" +inf "" ) ] * dimension <TAB> for node in nodes : <TAB><TAB> for d in range ( dimension ) : <TAB><TAB><TAB> if max [ d ] < node . data [ d ] : <TAB><TAB><TAB><TAB> max [ d ] = node . data [ d ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> min [ d ] = node . data [ d ] <TAB> return min , max",if min [ d ] > node . data [ d ] :,if min [ d ] > node . data [ d ] :,100.0,100.00,True
328,"def get_complete_position ( self , context : UserContext ) - > int : <TAB> # Check member prefix pattern. <TAB> for prefix_pattern in convert2list ( <TAB><TAB> self . get_filetype_var ( context [ "" filetype "" ] , "" prefix_patterns "" ) <TAB> ) : <TAB><TAB> m = re . search ( self . _object_pattern + prefix_pattern + r "" \ w*$ "" , context [ "" input "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . _prefix = re . sub ( r "" \ w*$ "" , "" "" , m . group ( 0 ) ) <TAB><TAB> m = re . search ( r "" \ w*$ "" , context [ "" input "" ] ) <TAB><TAB> if m : <TAB><TAB><TAB> return m . start ( ) <TAB> return - 1","if m is None or prefix_pattern == """" :",if not m :,71.7082654147176,94.46,False
329,"def _stderr_supports_color ( ) : <TAB> try : <TAB><TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB> if curses : <TAB><TAB><TAB><TAB> curses . setupterm ( ) <TAB><TAB><TAB><TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB> except Exception : <TAB><TAB> # Very broad exception handling because it's always better to <TAB><TAB> # fall back to non-colored logs than to break at startup. <TAB><TAB> pass <TAB> return False",elif colorama :,if colorama :,98.7992749579786,99.00,False
330,"def setLabelColumnWidth ( self , panel , width ) : <TAB> for child in panel . GetChildren ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> size = child . GetSize ( ) <TAB><TAB><TAB> size [ 0 ] = width <TAB><TAB><TAB> child . SetBestSize ( size )","if isinstance ( child , wx . lib . stattext . GenStaticText ) :","if child . GetKind ( ) == ""column"" :",80.72670171061601,85.46,False
331,"def update ( self , other ) : <TAB> if other . M is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . items . update ( other . items ) <TAB><TAB> else : <TAB><TAB><TAB> for i in other . items : <TAB><TAB><TAB><TAB> self . add ( i ) <TAB><TAB> return <TAB> <MASK> <TAB><TAB> self . convert ( ) <TAB> self . M = array . array ( "" B "" , list ( map ( max , list ( zip ( self . M , other . M ) ) ) ) )",if self . M is None :,if self . M is None :,100.0,100.00,True
332,"def on_end_epoch ( self , state ) : <TAB> if self . write_epoch_metrics : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . writer . add_text ( <TAB><TAB><TAB><TAB> "" epoch "" , <TAB><TAB><TAB><TAB> "" <h4>Epoch  {} </h4> "" . format ( state [ torchbearer . EPOCH ] ) <TAB><TAB><TAB><TAB> + self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB><TAB><TAB><TAB> 1 , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . writer . add_text ( <TAB><TAB><TAB><TAB> "" epoch "" , <TAB><TAB><TAB><TAB> self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB><TAB><TAB><TAB> state [ torchbearer . EPOCH ] , <TAB><TAB><TAB> )",if self . visdom :,if state [ torchbearer . METRICS ] :,81.94099076230223,97.17,False
333,"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> elif e . get ( "" event "" ) == ActionExecuted . type_name : <TAB><TAB><TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False","if e . get ( ""event"" ) == UserUttered . type_name :","if e . get ( ""event"" ) == ActionExecuted . type_name :",98.86977716895323,98.57,False
334,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB><TAB> nw_id_ = port . network_id <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if nw_id_ == nw_id : <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB><TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB> return ret",if port . port_no == in_port :,if in_port is not None and in_port != nw_id_unknown :,70.74299038852295,92.15,False
335,"def next_month ( billing_cycle_anchor : datetime , dt : datetime ) - > datetime : <TAB> estimated_months = round ( ( dt - billing_cycle_anchor ) . days * 12.0 / 365 ) <TAB> for months in range ( max ( estimated_months - 1 , 0 ) , estimated_months + 2 ) : <TAB><TAB> proposed_next_month = add_months ( billing_cycle_anchor , months ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return proposed_next_month <TAB> raise AssertionError ( <TAB><TAB> "" Something wrong in next_month calculation with  "" <TAB><TAB> f "" billing_cycle_anchor:  { billing_cycle_anchor } , dt:  { dt } "" <TAB> )",if 20 < ( proposed_next_month - dt ) . days < 40 :,if proposed_next_month :,88.73631966545098,92.91,False
336,"def wait_complete ( self ) : <TAB> """"""Wait for futures complete done."""""" <TAB> for future in concurrent . futures . as_completed ( self . _futures . keys ( ) ) : <TAB><TAB> try : <TAB><TAB><TAB> error = future . exception ( ) <TAB><TAB> except concurrent . futures . CancelledError : <TAB><TAB><TAB> break <TAB><TAB> name = self . _futures [ future ] <TAB><TAB> <MASK> <TAB><TAB><TAB> err_msg = ' Extracting  "" {0} "" , got:  {1} ' . format ( name , error ) <TAB><TAB><TAB> logger . error ( err_msg )",if error is not None :,if error :,74.52174223803128,97.35,False
337,"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB><TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB><TAB> if issubclass ( target , mapperlib . Mapper ) : <TAB><TAB><TAB> return target <TAB><TAB> else : <TAB><TAB><TAB> mapper = _mapper_or_none ( target ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return mapper <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB><TAB> return target",if mapper is not None :,if mapper :,69.54837678488795,97.32,False
338,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> gvariant + = ""   {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB> elif isinstance ( arg , ( int , float ) ) : <TAB><TAB><TAB> gvariant + = f ""   { arg } "" <TAB><TAB> elif isinstance ( arg , str ) : <TAB><TAB><TAB> gvariant + = f '   "" { arg } "" ' <TAB><TAB> else : <TAB><TAB><TAB> gvariant + = f ""   { arg !s} "" <TAB> return gvariant . lstrip ( )","if isinstance ( arg , bool ) :","if isinstance ( arg , ( str , unicode ) ) :",97.04360286811021,96.69,False
339,"def _list_cases ( suite ) : <TAB> for test in suite : <TAB><TAB> if isinstance ( test , unittest . TestSuite ) : <TAB><TAB><TAB> _list_cases ( test ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if support . match_test ( test ) : <TAB><TAB><TAB><TAB> print ( test . id ( ) )","elif isinstance ( test , unittest . TestCase ) :","elif isinstance ( test , unittest . TestCase ) :",75.0,100.00,True
340,def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB><TAB> <MASK> <TAB><TAB><TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB><TAB> if page . relations . disambiguation_links is not None : <TAB><TAB><TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ),if page . relations . disambiguation_links_norm is not None :,if page . relations . disambiguation_links_norm is not None :,100.0,100.00,True
341,"def test_decode_invalid ( self ) : <TAB> testcases = [ <TAB><TAB> ( b "" xn--w& "" , "" strict "" , UnicodeError ( ) ) , <TAB><TAB> ( b "" xn--w& "" , "" ignore "" , "" xn- "" ) , <TAB> ] <TAB> for puny , errors , expected in testcases : <TAB><TAB> with self . subTest ( puny = puny , errors = errors ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertRaises ( UnicodeError , puny . decode , "" punycode "" , errors ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertEqual ( puny . decode ( "" punycode "" , errors ) , expected )","if isinstance ( expected , Exception ) :","if not isinstance ( puny , UnicodeError ) :",94.38952088950518,96.38,False
342,"def find_globs ( walker , patterns , matches ) : <TAB> for root , dirs , files in walker : <TAB><TAB> for d in dirs : <TAB><TAB><TAB> d = join ( root , d ) <TAB><TAB><TAB> for pattern in patterns : <TAB><TAB><TAB><TAB> for p in Path ( d ) . glob ( pattern ) : <TAB><TAB><TAB><TAB><TAB> matches . add ( str ( p ) ) <TAB><TAB> sub_files = set ( ) <TAB><TAB> for p in matches : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for f in files : <TAB><TAB><TAB><TAB><TAB> sub_files . add ( join ( root , f ) ) <TAB><TAB> matches . update ( sub_files )",if root . startswith ( p ) :,if p . is_file ( ) :,96.30394493227364,96.84,False
343,"def parse_stack_trace ( self , it , line ) : <TAB> """"""Iterate over lines and parse stack traces."""""" <TAB> events = [ ] <TAB> stack_traces = [ ] <TAB> while self . stack_trace_re . match ( line ) : <TAB><TAB> event = self . parse_stack_trace_line ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> events . append ( event ) <TAB><TAB> stack_traces . append ( line ) <TAB><TAB> line = get_next ( it ) <TAB> events . reverse ( ) <TAB> return stack_traces , events , line",if event :,if event :,100.0,100.00,True
344,"def process ( self ) : <TAB> """"""Do processing necessary, storing result in feature."""""" <TAB> summation = 0 # count of all <TAB> histo = self . data [ "" flat.notes.quarterLengthHistogram "" ] <TAB> if not histo : <TAB><TAB> raise NativeFeatureException ( "" input lacks notes "" ) <TAB> maxKey = 0 # max found for any one key <TAB> for key in histo : <TAB><TAB> # all defined keys should be greater than zero, but just in case <TAB><TAB> if histo [ key ] > 0 : <TAB><TAB><TAB> summation + = histo [ key ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> maxKey = histo [ key ] <TAB> self . feature . vector [ 0 ] = maxKey / summation",if histo [ key ] >= maxKey :,if histo [ key ] > maxKey :,98.99434032962894,98.71,False
345,"def load_resource ( name ) : <TAB> """"""return file contents for files within the package root folder"""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return sublime . load_resource ( "" Packages/Markdown Preview/ {0} "" . format ( name ) ) <TAB><TAB> else : <TAB><TAB><TAB> filename = os . path . join ( <TAB><TAB><TAB><TAB> sublime . packages_path ( ) , INSTALLED_DIRECTORY , os . path . normpath ( name ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> return load_utf8 ( filename ) <TAB> except : <TAB><TAB> print ( "" Error while load_resource( ' %s ' ) "" % name ) <TAB><TAB> traceback . print_exc ( ) <TAB><TAB> return "" """,if is_ST3 ( ) :,"if name . endswith ( "".html"" ) :",96.05249497561194,95.66,False
346,"def get_password ( self , service , repo_url ) : <TAB> if self . is_unlocked : <TAB><TAB> asyncio . set_event_loop ( asyncio . new_event_loop ( ) ) <TAB><TAB> collection = secretstorage . get_default_collection ( self . connection ) <TAB><TAB> attributes = { "" application "" : "" Vorta "" , "" service "" : service , "" repo_url "" : repo_url } <TAB><TAB> items = list ( collection . search_items ( attributes ) ) <TAB><TAB> logger . debug ( "" Found  %i  passwords matching repo URL. "" , len ( items ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return items [ 0 ] . get_secret ( ) . decode ( "" utf-8 "" ) <TAB> return None",if len ( items ) > 0 :,if len ( items ) == 1 :,73.55754582828617,97.64,False
347,"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB> if not p : <TAB><TAB><TAB> continue <TAB><TAB> ( pth , fname ) = os . path . split ( p ) <TAB><TAB> if fname == "" output "" : <TAB><TAB><TAB> continue <TAB><TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB><TAB><TAB> continue <TAB><TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> get_dir ( p ) <TAB><TAB> else : <TAB><TAB><TAB> res . append ( p ) <TAB> return res",if os . path . isdir ( p ) :,if os . path . isdir ( p ) :,100.0,100.00,True
348,"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB><TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if nic not in out : <TAB><TAB><TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic )","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",if not nic :,63.12567668101288,88.47,False
349,"def vexop_to_simop ( op , extended = True , fp = True ) : <TAB> res = operations . get ( op ) <TAB> if res is None and extended : <TAB><TAB> attrs = op_attrs ( op ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB><TAB> res = SimIROp ( op , * * attrs ) <TAB> if res is None : <TAB><TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB> if res . _float and not fp : <TAB><TAB> raise UnsupportedIROpError ( "" Floating point support disabled "" ) <TAB> return res",if attrs is None :,if attrs is None :,100.0,100.00,True
350,"def rule_builder_add_value ( self , value , screenshot_name = None ) : <TAB> rule_builder = self . components . rule_builder <TAB> rule_builder . menu_button_column . wait_for_and_click ( ) <TAB> with self . rule_builder_rule_editor ( "" add-column-value "" ) as editor_element : <TAB><TAB> filter_input = editor_element . find_element_by_css_selector ( "" input[type= ' text ' ] "" ) <TAB><TAB> filter_input . clear ( ) <TAB><TAB> filter_input . send_keys ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . screenshot ( screenshot_name )",if screenshot_name :,if screenshot_name :,100.0,100.00,True
351,"def make_open_socket ( self ) : <TAB> s = socket . socket ( ) <TAB> try : <TAB><TAB> s . bind ( DEFAULT_BIND_ADDR_TUPLE ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Windows and linux (with psutil) doesn't show as open until <TAB><TAB><TAB> # we call listen (linux with lsof accepts either) <TAB><TAB><TAB> s . listen ( 1 ) <TAB><TAB> self . assert_open ( s , s . fileno ( ) ) <TAB> except : <TAB><TAB> s . close ( ) <TAB><TAB> s = None <TAB><TAB> raise <TAB> return s",if WIN or greentest . LINUX :,"if sys . platform == ""win32"" :",92.98653299763906,94.60,False
352,"def handle_ray_task_error ( e ) : <TAB> for s in e . traceback_str . split ( "" \n "" ) [ : : - 1 ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> raise getattr ( builtins , s . split ( "" : "" ) [ 0 ] ) ( "" "" . join ( s . split ( "" : "" ) [ 1 : ] ) ) <TAB><TAB><TAB> except AttributeError as att_err : <TAB><TAB><TAB><TAB> if "" module "" in str ( att_err ) and builtins . __name__ in str ( att_err ) : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> raise att_err <TAB> raise e","if ""Error"" in s or ""Exception"" in s :","if s . startswith ( ""ray:"" ) :",69.01087286611892,94.76,False
353,"def compare_multiple_events ( i , expected_results , actual_results ) : <TAB> events_in_a_row = [ ] <TAB> j = i <TAB> while j < len ( expected_results ) and isinstance ( <TAB><TAB> actual_results [ j ] , actual_results [ i ] . __class__ <TAB> ) : <TAB><TAB> events_in_a_row . append ( actual_results [ j ] ) <TAB><TAB> j + = 1 <TAB> message = "" "" <TAB> for event in events_in_a_row : <TAB><TAB> for k in range ( i , j ) : <TAB><TAB><TAB> passed , message = compare_events ( expected_results [ k ] , event ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> expected_results [ k ] = None <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> return i , False , message <TAB> return j , True , "" """,if passed :,if not passed :,94.45422367538848,99.02,False
354,"def ListSubscriptions ( self , params ) : <TAB> queryreturn = sqlQuery ( """""" SELECT label, address, enabled FROM subscriptions """""" ) <TAB> data = ' { "" subscriptions "" :[ ' <TAB> for row in queryreturn : <TAB><TAB> label , address , enabled = row <TAB><TAB> label = shared . fixPotentiallyInvalidUTF8Data ( label ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data + = "" , "" <TAB><TAB> data + = json . dumps ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" label "" : label . encode ( "" base64 "" ) , <TAB><TAB><TAB><TAB> "" address "" : address , <TAB><TAB><TAB><TAB> "" enabled "" : enabled == 1 , <TAB><TAB><TAB> } , <TAB><TAB><TAB> indent = 4 , <TAB><TAB><TAB> separators = ( "" , "" , "" :  "" ) , <TAB><TAB> ) <TAB> data + = "" ]} "" <TAB> return data",if len ( data ) > 20 :,if len ( data ) > 0 :,99.12328663086033,99.03,False
355,"def compile ( self , args ) : <TAB> compiled_args = { } <TAB> for key , value in six . iteritems ( args ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> compiled_args [ key ] = str ( value ) <TAB><TAB> else : <TAB><TAB><TAB> compiled_args [ key ] = sjson_dumps ( value ) <TAB> return self . _minified_code % compiled_args",if key in self . clean_args :,"if isinstance ( value , ( list , tuple ) ) :",87.71439614707809,89.76,False
356,"def insert ( self , pack_id , data ) : <TAB> if ( pack_id not in self . queue ) and pack_id > self . begin_id : <TAB><TAB> self . queue [ pack_id ] = PacketInfo ( data ) <TAB><TAB> if self . end_id == pack_id : <TAB><TAB><TAB> self . end_id = pack_id + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> eid = self . end_id <TAB><TAB><TAB> while eid < pack_id : <TAB><TAB><TAB><TAB> self . miss_queue . add ( eid ) <TAB><TAB><TAB><TAB> eid + = 1 <TAB><TAB><TAB> self . end_id = pack_id + 1 <TAB><TAB> else : <TAB><TAB><TAB> self . miss_queue . remove ( pack_id )",elif self . end_id < pack_id :,elif self . end_id != self . begin_id :,70.27123748221588,97.19,False
357,"def _target_generator ( self ) : <TAB> # since we do not have predictions yet, so we ignore sampling here <TAB> if self . _internal_target_generator is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> from . . . . model_zoo . ssd . target import SSDTargetGenerator <TAB><TAB> self . _internal_target_generator = SSDTargetGenerator ( <TAB><TAB><TAB> iou_thresh = self . _iou_thresh , <TAB><TAB><TAB> stds = self . _box_norm , <TAB><TAB><TAB> negative_mining_ratio = - 1 , <TAB><TAB><TAB> * * self . _kwargs <TAB><TAB> ) <TAB><TAB> return self . _internal_target_generator <TAB> else : <TAB><TAB> return self . _internal_target_generator",if self . _anchors_none :,if self . _iou_thresh == 0 :,73.22145010640378,96.66,False
358,"def test_heapsort ( self ) : <TAB> # Exercise everything with repeated heapsort checks <TAB> for trial in range ( 100 ) : <TAB><TAB> size = random . randrange ( 50 ) <TAB><TAB> data = [ random . randrange ( 25 ) for i in range ( size ) ] <TAB><TAB> <MASK> # Half of the time, use heapify <TAB><TAB><TAB> heap = data [ : ] <TAB><TAB><TAB> self . module . heapify ( heap ) <TAB><TAB> else : # The rest of the time, use heappush <TAB><TAB><TAB> heap = [ ] <TAB><TAB><TAB> for item in data : <TAB><TAB><TAB><TAB> self . module . heappush ( heap , item ) <TAB><TAB> heap_sorted = [ self . module . heappop ( heap ) for i in range ( size ) ] <TAB><TAB> self . assertEqual ( heap_sorted , sorted ( data ) )",if trial & 1 :,if trial == 0 :,73.7885553108459,98.03,False
359,"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB><TAB> if timeout is None : <TAB><TAB><TAB> msecs = _subprocess . INFINITE <TAB><TAB> else : <TAB><TAB><TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB> if code == TERMINATE : <TAB><TAB><TAB><TAB> code = - signal . SIGTERM <TAB><TAB><TAB> self . returncode = code <TAB> return self . returncode",if res == _subprocess . WAIT_OBJECT_0 :,if res == _subprocess . WAIT_OBJECT_0 :,100.0,100.00,True
360,"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB><TAB> if isinstance ( value , bool ) : <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB> if value != 1 : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> elif len ( value ) != 0 : <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> break <TAB> self . _reset_button . disabled = not changed",elif value is None :,if value is None :,95.85930078623797,98.86,False
361,"def isnotsurplus ( self , item : T ) - > bool : <TAB> if not self . matchers : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . mismatch_description . append_text ( <TAB><TAB><TAB><TAB> "" not matched:  "" <TAB><TAB><TAB> ) . append_description_of ( item ) <TAB><TAB> return False <TAB> return True",if self . mismatch_description :,if self . mismatch_description :,75.0,100.00,True
362,"def resolve_env_secrets ( config , environ ) : <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance ( config , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB><TAB> elif list ( config . keys ( ) ) == [ "" $file "" ] : <TAB><TAB><TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB><TAB> else : <TAB><TAB><TAB> return { <TAB><TAB><TAB><TAB> key : resolve_env_secrets ( value , environ ) <TAB><TAB><TAB><TAB> for key , value in config . items ( ) <TAB><TAB><TAB> } <TAB> elif isinstance ( config , list ) : <TAB><TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB><TAB> return config","if list ( config . keys ( ) ) == [ ""$env"" ] :","if list ( config . keys ( ) ) == [ ""$env"" ] :",75.0,100.00,True
363,"def __open__ ( filename , * args , * * kwargs ) : <TAB> if os . path . isfile ( filename ) : <TAB><TAB> return __realopen__ ( filename , * args , * * kwargs ) <TAB> if not os . path . isabs ( filename ) : <TAB><TAB> datafilename = __papplet__ . dataPath ( filename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return __realopen__ ( datafilename , * args , * * kwargs ) <TAB><TAB> sketchfilename = __papplet__ . sketchPath ( filename ) <TAB> if os . path . isfile ( sketchfilename ) : <TAB><TAB> return __realopen__ ( sketchfilename , * args , * * kwargs ) <TAB> # Fail naturally <TAB> return __realopen__ ( filename , * args , * * kwargs )",if os . path . isfile ( datafilename ) :,if os . path . isfile ( datafilename ) :,100.0,100.00,True
364,def run ( self ) : <TAB> while not self . completed : <TAB><TAB> <MASK> <TAB><TAB><TAB> time . sleep ( self . period ) <TAB><TAB> else : <TAB><TAB><TAB> self . _completed . wait ( self . period ) <TAB><TAB> self . counter + = 1 <TAB><TAB> try : <TAB><TAB><TAB> self . callback ( self . counter ) <TAB><TAB> except Exception : <TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . timeout is not None : <TAB><TAB><TAB> dt = time . time ( ) - self . _start_time <TAB><TAB><TAB> if dt > self . timeout : <TAB><TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . counter == self . count : <TAB><TAB><TAB> self . stop ( ),if self . block :,if self . _completed . is_set ( ) :,82.4492703868481,95.98,False
365,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> return <TAB> if config is not None or defaults is not None : <TAB><TAB> if config is None : <TAB><TAB><TAB> config = self . _config <TAB><TAB> if defaults is None : <TAB><TAB><TAB> defaults = dict ( self . _map . parents ) <TAB><TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB><TAB> chain = self . _map <TAB> try : <TAB><TAB> chain . del_by_path ( path ) <TAB><TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> pass",if error_on_path :,if error_on_path :,100.0,100.00,True
366,"def structured_dot_grad ( sparse_A , dense_B , ga ) : <TAB> if sparse_A . type . format in ( "" csc "" , "" csr "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> sdgcsx = sdg_csc <TAB><TAB><TAB> CSx = CSC <TAB><TAB> else : <TAB><TAB><TAB> sdgcsx = sdg_csr <TAB><TAB><TAB> CSx = CSR <TAB><TAB> g_A_data = sdgcsx ( csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , dense_B , ga ) <TAB><TAB> return CSx ( <TAB><TAB><TAB> g_A_data , csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , csm_shape ( sparse_A ) <TAB><TAB> ) <TAB> else : <TAB><TAB> raise NotImplementedError ( )","if sparse_A . type . format == ""csc"" :","if sparse_B . type . format == ""csr"" :",96.49615041769535,97.80,False
367,"def step_async ( self , actions ) : <TAB> listify = True <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> listify = False <TAB> except TypeError : <TAB><TAB> pass <TAB> if not listify : <TAB><TAB> self . actions = actions <TAB> else : <TAB><TAB> assert ( <TAB><TAB><TAB> self . num_envs == 1 <TAB><TAB> ) , f "" actions  { actions }  is either not a list or has a wrong size - cannot match to  { self . num_envs }  environments "" <TAB><TAB> self . actions = [ actions ]",if len ( actions ) == self . num_envs :,"if not isinstance ( actions , ( list , tuple ) ) :",70.35428270812925,92.86,False
368,"def tempFailureRetry ( func , * args , * * kwargs ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> return func ( * args , * * kwargs ) <TAB><TAB> except ( os . error , IOError ) as ex : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise",if ex . errno == errno . EINTR :,"if ex . errno in ( errno . EINTR , errno . EINTR ) :",66.71974635382803,91.80,False
369,"def test_learning_always_changes_generation ( chars , order ) : <TAB> learner = LStar ( lambda s : len ( s ) == 1 and s [ 0 ] in chars ) <TAB> for c in order : <TAB><TAB> prev = learner . generation <TAB><TAB> s = bytes ( [ c ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> learner . learn ( s ) <TAB><TAB><TAB> assert learner . generation > prev",if learner . dfa . matches ( s ) != learner . member ( s ) :,if s [ 0 ] in chars :,60.01588280471738,86.14,False
370,"def test_costs_5D_noisy_names ( signal_bkps_5D_noisy , cost_name ) : <TAB> signal , bkps = signal_bkps_5D_noisy <TAB> cost = cost_factory ( cost_name ) <TAB> cost . fit ( signal ) <TAB> cost . error ( 0 , 100 ) <TAB> cost . error ( 100 , signal . shape [ 0 ] ) <TAB> cost . error ( 10 , 50 ) <TAB> cost . sum_of_costs ( bkps ) <TAB> with pytest . raises ( NotEnoughPoints ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> cost . min_size = 4 <TAB><TAB><TAB> cost . error ( 1 , 2 ) <TAB><TAB> else : <TAB><TAB><TAB> cost . error ( 1 , 2 )","if cost_name == ""cosine"" :","if cost_name == ""cosine"" :",100.0,100.00,True
371,"def remove_empty_dirs ( dirname ) : <TAB> logger . debug ( "" remove_empty_dirs  ' %s ' "" % ( dirname ) ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> dirname = dirname . encode ( "" utf-8 "" ) <TAB><TAB> os . removedirs ( dirname ) <TAB><TAB> logger . debug ( "" remove_empty_dirs  ' %s '  done "" % ( dirname ) ) <TAB> except OSError as exc : # Python >2.5 <TAB><TAB> if exc . errno == errno . ENOTEMPTY : <TAB><TAB><TAB> logger . debug ( "" remove_empty_dirs  ' %s '  not empty "" % ( dirname ) ) <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> raise <TAB> except Exception as e : <TAB><TAB> logger . exception ( e ) <TAB><TAB> logger . error ( "" remove_empty_dirs exception:  "" + dirname ) <TAB><TAB> raise e","if not isinstance ( dirname , str ) :","if not isinstance ( dirname , str ) :",100.0,100.00,True
372,"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB><TAB> <MASK> <TAB><TAB><TAB> if feat is not None : <TAB><TAB><TAB><TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB><TAB><TAB> feat = f <TAB> if feat is None : <TAB><TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name )","if self . _return_feature ( f ) and hasattr ( f , name ) :",if f . unique :,89.03397022974143,87.37,False
373,"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB><TAB> occupied = False <TAB><TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB><TAB><TAB> if strategy == self : <TAB><TAB><TAB><TAB> occupied = True <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> return addr <TAB> raise NoIdleSlot ( <TAB><TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> )",if not occupied :,if occupied :,98.0449427064971,98.70,False
374,"def __deepcopy__ ( self , memo ) : <TAB> cls = self . __class__ <TAB> result = cls . __new__ ( cls ) <TAB> memo [ id ( self ) ] = result <TAB> for key , value in self . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( result , key , copy . copy ( value ) ) <TAB><TAB> else : <TAB><TAB><TAB> setattr ( result , key , copy . deepcopy ( value , memo ) ) <TAB> return result",if key in cls . dynamic_methods :,"if isinstance ( value , dict ) :",66.25448795426924,94.07,False
375,def restore_forward ( model ) : <TAB> for child in model . children ( ) : <TAB><TAB> # leaf node <TAB><TAB> <MASK> <TAB><TAB><TAB> child . forward = child . old_forward <TAB><TAB><TAB> child . old_forward = None <TAB><TAB> else : <TAB><TAB><TAB> restore_forward ( child ),"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :","if hasattr ( child , ""old_forward"" ) :",93.85064790556166,92.11,False
376,"def add ( self , obj , allow_duplicates = False ) : <TAB> if allow_duplicates or obj not in self . _constants : <TAB><TAB> self . _constant_pool . append ( obj ) <TAB><TAB> self . _constants [ obj ] = len ( self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _constant_pool . append ( None )","if obj . __class__ in ( Double , Long ) :",if self . _constants [ obj ] == 0 :,67.96002102654471,87.03,False
377,"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] : # hmmm, assume copyright to be in first 80 lines <TAB><TAB> idx = l . lower ( ) . find ( "" copyright "" ) <TAB><TAB> if idx < 0 : <TAB><TAB><TAB> continue <TAB><TAB> copyright = l [ idx + 9 : ] . strip ( ) <TAB><TAB> if not copyright : <TAB><TAB><TAB> continue <TAB><TAB> copyright = sanitise ( copyright ) <TAB><TAB> # hmm, do a quick check to see if there's a year, <TAB><TAB> # if not, skip it <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> ret . add ( copyright ) <TAB> return ret","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :","if copyright == ""hmmm"" :",92.99552417182389,89.41,False
378,"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB><TAB> context . next_indent = len ( text ) <TAB><TAB> if context . next_indent < context . indent : <TAB><TAB><TAB> while context . next_indent < context . indent : <TAB><TAB><TAB><TAB> context . indent = context . indent_stack . pop ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> extra = text [ context . indent : ] <TAB><TAB><TAB><TAB> text = text [ : context . indent ] <TAB> else : <TAB><TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB><TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB><TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( )",if context . next_indent > context . indent :,if context . next_indent < context . indent :,99.20525558097776,99.02,False
379,"def queries ( self ) : <TAB> if DEV : <TAB><TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB><TAB><TAB> if not cmd . stdout . strip ( ) : <TAB><TAB><TAB><TAB> log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> print ( cmd . stdout ) <TAB><TAB><TAB><TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",if not log_cmd . run ( ) :,82.9059829602216,92.79,False
380,"def nodes ( self ) : <TAB> if not self . _nodes : <TAB><TAB> nodes = self . cluster_group . instances ( ) <TAB><TAB> self . _nodes = [ ] <TAB><TAB> master = self . master_node <TAB><TAB> nodeid = 1 <TAB><TAB> for node in nodes : <TAB><TAB><TAB> if node . state not in [ "" pending "" , "" running "" ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _nodes . insert ( 0 , master ) <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . _nodes . append ( Node ( node , self . key_location , "" node %.3d "" % nodeid ) ) <TAB><TAB><TAB> nodeid + = 1 <TAB> else : <TAB><TAB> for node in self . _nodes : <TAB><TAB><TAB> log . debug ( "" refreshing instance  %s "" % node . id ) <TAB><TAB><TAB> node . update ( ) <TAB> return self . _nodes",if node . id == master . id :,if node . id == master :,77.63622152015827,98.77,False
381,"def match ( cls , agent_name , guid , uri , media = None ) : <TAB> # Retrieve `Agent` for provided `guid` <TAB> agent = Agents . get ( agent_name ) <TAB> if agent is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> # First occurrence of unsupported agent <TAB><TAB><TAB> log . warn ( "" Unsupported metadata agent:  %s "" % agent_name ) <TAB><TAB><TAB> # Mark unsupported agent as ""seen"" <TAB><TAB><TAB> unsupported_agents [ agent_name ] = True <TAB><TAB><TAB> return False <TAB><TAB> # Duplicate occurrence of unsupported agent <TAB><TAB> log . warn ( <TAB><TAB><TAB> "" Unsupported metadata agent:  %s "" % agent_name , extra = { "" duplicate "" : True } <TAB><TAB> ) <TAB><TAB> return False <TAB> # Fill `guid` with details from agent <TAB> return agent . fill ( guid , uri , media )",if agent_name not in unsupported_agents :,if agent_name in unsupported_agents :,98.98723623560637,98.99,False
382,"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB><TAB> randomNode = Gaffer . Random ( ) <TAB><TAB> parentNode . addChild ( randomNode ) <TAB><TAB> if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) : <TAB><TAB><TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode )","elif isinstance ( plug , Gaffer . Color3fPlug ) :","elif isinstance ( plug , Gaffer . ColorPlug ) :",98.88785183498896,98.42,False
383,"def post_arrow ( self , arr : pa . Table , graph_type : str , opts : str = "" "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> sub_path = f "" api/v2/upload/datasets/ { dataset_id } / { graph_type } /arrow "" <TAB> try : <TAB><TAB> resp = self . post_arrow_generic ( sub_path , tok , arr , opts ) <TAB><TAB> out = resp . json ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" No success indicator in server response "" ) <TAB><TAB> return out <TAB> except Exception as e : <TAB><TAB> logger . error ( "" Failed to post arrow to  %s "" , sub_path , exc_info = True ) <TAB><TAB> raise e","if not ( ""success"" in out ) or not out [ ""success"" ] :",if resp . status_code != 200 :,66.60891627013807,91.98,False
384,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB> elif isinstance ( val , MutableMapping ) : <TAB><TAB><TAB> child = dict_to_XML ( key , val ) <TAB><TAB> else : <TAB><TAB><TAB> if tag == "" config "" : <TAB><TAB><TAB><TAB> child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> child = Element ( key ) <TAB><TAB><TAB> child . text = str ( val ) <TAB><TAB> elem . append ( child ) <TAB> return elem","if tag == ""layers"" :","if isinstance ( val , MutableMapping ) :",85.68456645921937,96.94,False
385,"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB><TAB> node = self . path . find_dir ( dir ) <TAB><TAB> <MASK> <TAB><TAB><TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB><TAB><TAB> continue <TAB><TAB> if not node in lst : <TAB><TAB><TAB> lst . append ( node ) <TAB><TAB> self . bld_incpaths_lst . append ( node )",if not node :,if not node :,100.0,100.00,True
386,"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB> if isinstance ( val , compat . string_types ) : <TAB><TAB><TAB> return ""    %s "" % val <TAB><TAB> elif val < 1024 * * 2 : <TAB><TAB><TAB> return ""    %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ""    %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB> else : <TAB><TAB><TAB> return ""    %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB><TAB> return str ( val ) <TAB> else : <TAB><TAB> return ""    %s "" % val",elif val < 1024 ** 3 :,elif val > 1024 * * 3 :,70.47586209994189,98.88,False
387,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB><TAB> return None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> curr_out = curr_out [ : reuse_len ] <TAB><TAB> if prev_mem is None : <TAB><TAB><TAB> new_mem = curr_out [ - mem_len : ] <TAB><TAB> else : <TAB><TAB><TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem",if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,93.87065905006853,96.40,False
388,"def GROUP_CONCAT ( builder , distinct , expr , sep = None ) : <TAB> assert distinct in ( None , True , False ) <TAB> result = distinct and "" GROUP_CONCAT(DISTINCT  "" or "" GROUP_CONCAT( "" , builder ( expr ) <TAB> if sep is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = result , ""  SEPARATOR  "" , builder ( sep ) <TAB><TAB> else : <TAB><TAB><TAB> result = result , "" ,  "" , builder ( sep ) <TAB> return result , "" ) ""","if builder . provider . dialect == ""MySQL"" :","if sep == "","" :",90.03665368796162,93.51,False
389,"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> self . custom_fields = [ ] <TAB> self . obj_type = ContentType . objects . get_for_model ( self . model ) <TAB> # Add all applicable CustomFields to the form <TAB> custom_fields = CustomField . objects . filter ( content_types = self . obj_type ) <TAB> for cf in custom_fields : <TAB><TAB> # Annotate non-required custom fields as nullable <TAB><TAB> <MASK> <TAB><TAB><TAB> self . nullable_fields . append ( cf . name ) <TAB><TAB> self . fields [ cf . name ] = cf . to_form_field ( <TAB><TAB><TAB> set_initial = False , enforce_required = False <TAB><TAB> ) <TAB><TAB> # Annotate this as a custom field <TAB><TAB> self . custom_fields . append ( cf . name )",if not cf . required :,if cf . required :,99.01616156116233,98.96,False
390,"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB><TAB> return None <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> if possible_child_hash not in self . items : <TAB><TAB><TAB> return False <TAB><TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash",if possible_child_hash == item_hash :,if self . get_first ( item_hash ) != self . get_first ( possible,77.03885028069098,88.22,False
391,"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB><TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB><TAB> else : <TAB><TAB><TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB><TAB><TAB><TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB><TAB><TAB><TAB> if not self . use_parallel_executor : <TAB><TAB><TAB><TAB><TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) )",if self . use_parallel_executor and not self . use_double_buffer :,if self . use_unordered_batch :,70.02002119571858,94.49,False
392,"def add_cells ( self , cells ) : <TAB> for cell in cells : <TAB><TAB> <MASK> <TAB><TAB><TAB> id = len ( self . cell_id_map ) <TAB><TAB><TAB> self . cell_id_map [ cell ] = id <TAB><TAB><TAB> self . id_cell_map [ id ] = cell",if cell not in self . cell_id_map :,if cell not in self . cell_id_map :,100.0,100.00,True
393,"def _verify_out ( marker = "" >> "" ) : <TAB> if shared : <TAB><TAB> self . assertIn ( "" libapp_lib.dylib "" , self . client . out ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIn ( "" libapp_lib.a "" , self . client . out ) <TAB><TAB> else : # Incremental build not the same msg <TAB><TAB><TAB> self . assertIn ( "" Built target app_lib "" , self . client . out ) <TAB> out = str ( self . client . out ) . splitlines ( ) <TAB> for k , v in vals . items ( ) : <TAB><TAB> self . assertIn ( "" %s   %s :  %s "" % ( marker , k , v ) , out )","if marker == "">>"" :","if build == ""a"" :",98.3434707102889,96.87,False
394,"def Visit_expr ( self , node ) : # pylint: disable=invalid-name <TAB> # expr ::= xor_expr ('|' xor_expr)* <TAB> for child in node . children : <TAB><TAB> self . Visit ( child ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR )","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :",75.0,100.00,True
395,"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB><TAB> after = self . after . id if self . after else None <TAB><TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB><TAB> if not data : <TAB><TAB><TAB> # no data, terminate <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> self . limit = 0 # terminate loop <TAB><TAB> self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB><TAB> for element in reversed ( data ) : <TAB><TAB><TAB> await self . members . put ( self . create_member ( element ) )",if len ( data ) < 1000 :,if len ( data ) == 1 :,98.65928279968581,97.78,False
396,"def assert_warns ( expected ) : <TAB> with warnings . catch_warnings ( record = True ) as w : <TAB><TAB> warnings . simplefilter ( "" always "" ) <TAB><TAB> yield <TAB> # Python 2 does not raise warnings multiple times from the same stack <TAB> # frame. <TAB> if sys . version_info > = ( 3 , 0 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> exc_name = expected . __name__ <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> exc_name = str ( expected ) <TAB><TAB><TAB> raise AssertionError ( "" %s  not triggerred "" % exc_name )","if not any ( isinstance ( m . message , expected ) for m in w ) :",if expected is not None :,92.12972220203389,91.20,False
397,"def __init__ ( self , measures ) : <TAB> """"""Constructs a ContingencyMeasures given a NgramAssocMeasures class"""""" <TAB> self . __class__ . __name__ = "" Contingency "" + measures . __class__ . __name__ <TAB> for k in dir ( measures ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> v = getattr ( measures , k ) <TAB><TAB> if not k . startswith ( "" _ "" ) : <TAB><TAB><TAB> v = self . _make_contingency_fn ( measures , v ) <TAB><TAB> setattr ( self , k , v )","if k . startswith ( ""__"" ) :","if k . startswith ( ""__"" ) :",100.0,100.00,True
398,"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB><TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB><TAB> omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB><TAB> start = event == "" start "" <TAB><TAB> <MASK> <TAB><TAB><TAB> omitted_kws + = 1 <TAB><TAB> if not omitted_kws : <TAB><TAB><TAB> yield event , elem <TAB><TAB> elif not start : <TAB><TAB><TAB> elem . clear ( ) <TAB><TAB> if omit and not start : <TAB><TAB><TAB> omitted_kws - = 1",if omit and start :,if omit and start :,100.0,100.00,True
399,"def read_block ( buffer , i ) : <TAB> offset = i * BLOCK_LENGTH % config . CAPTURE_BUFFER <TAB> while True : <TAB><TAB> if buffer [ offset ] == BLOCK_MARKER . END : <TAB><TAB><TAB> return None <TAB><TAB> while buffer [ offset ] == BLOCK_MARKER . WRITE : <TAB><TAB><TAB> time . sleep ( SHORT_SENSOR_SLEEP_TIME ) <TAB><TAB> buffer [ offset ] = BLOCK_MARKER . READ <TAB><TAB> buffer . seek ( offset + 1 ) <TAB><TAB> length = struct . unpack ( "" =H "" , buffer . read ( 2 ) ) [ 0 ] <TAB><TAB> retval = buffer . read ( length ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> buffer [ offset ] = BLOCK_MARKER . NOP <TAB> return retval",if buffer [ offset ] == BLOCK_MARKER . READ :,if retval == BLOCK_MARKER . NOP :,73.15150993105628,96.33,False
400,def _start ( self ) : <TAB> try : <TAB><TAB> instance_info = self . _get_instance_info ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _multipass_cmd . start ( instance_name = self . instance_name ) <TAB> except errors . ProviderInfoError as instance_error : <TAB><TAB> # Until we have proper multipass error codes to know if this <TAB><TAB> # was a communication error we should keep this error tracking <TAB><TAB> # and generation here. <TAB><TAB> raise errors . ProviderInstanceNotFoundError ( <TAB><TAB><TAB> instance_name = self . instance_name <TAB><TAB> ) from instance_error,if not instance_info . is_running ( ) :,if instance_info . name == self . instance_name :,91.62052442494762,93.89,False
401,"def _river_driver ( self ) : <TAB> if self . _cached_river_driver : <TAB><TAB> return self . _cached_river_driver <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _cached_river_driver = MsSqlDriver ( <TAB><TAB><TAB><TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . _cached_river_driver = OrmDriver ( <TAB><TAB><TAB><TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB><TAB><TAB> ) <TAB><TAB> return self . _cached_river_driver",if app_config . IS_MSSQL :,if self . is_mysql :,96.52289526709816,95.92,False
402,"def __LazyMap__ ( self , attr ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> debug_attr_print ( <TAB><TAB><TAB><TAB> "" %s .__LazyMap__( %s ) added something "" % ( self . _username_ , attr ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> return 1 <TAB> except AttributeError : <TAB><TAB> return 0",if self . _LazyAddAttr_ ( attr ) :,if self . _username_ and attr . lower ( ) . startswith ( self . _username,55.68778872524847,87.89,False
403,"def prepare ( self , data = None , user = None ) : <TAB> """"""Prepare activation for execution."""""" <TAB> super ( ManagedStartViewActivation , self ) . prepare . original ( ) <TAB> self . task . owner = user <TAB> management_form_class = self . get_management_form_class ( ) <TAB> self . management_form = management_form_class ( data = data , instance = self . task ) <TAB> if data : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise FlowRuntimeError ( <TAB><TAB><TAB><TAB> "" Activation metadata is broken  {} "" . format ( self . management_form . errors ) <TAB><TAB><TAB> ) <TAB><TAB> self . task = self . management_form . save ( commit = False )",if not self . management_form . is_valid ( ) :,if self . management_form . errors :,72.9998982938309,95.42,False
404,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB><TAB> if self . __Token : <TAB><TAB><TAB> x = 1 <TAB><TAB> elif not IfList : <TAB><TAB><TAB> if self < = 2 : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionSizeGuid = 3 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> RegionLayoutLine = 5 <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",if not RegionSizeGuid :,if self <= 3 :,81.65460698244671,96.36,False
405,"def _get_completion ( self , document ) : <TAB> try : <TAB><TAB> completion_header = document . xpath ( "" //div[@id= ' complete_day ' ] "" ) [ 0 ] <TAB><TAB> completion_message = completion_header . getchildren ( ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> elif "" day_complete_message "" in completion_message . classes : <TAB><TAB><TAB> return True <TAB> except IndexError : <TAB><TAB> return False # Who knows, probably not my diary.","if ""day_incomplete_message"" in completion_message . classes :",if completion_message is None :,66.96276656164706,91.48,False
406,"def run ( self ) : <TAB> DISPATCH_SYNC = components . interfaces . nsIEventTarget . DISPATCH_SYNC <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> for match in findlib2 . find_all_matches ( self . regex , self . text ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> self . target . dispatch ( lambda : self . callback ( match ) , DISPATCH_SYNC ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> self . target . dispatch ( lambda : self . callback ( None ) , DISPATCH_SYNC ) <TAB> finally : <TAB><TAB> self . callback = None <TAB><TAB> self . target = None",if self . _stopped :,if self . callback is None :,92.50949023694564,93.62,False
407,"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB> k = literal_or_identifier [ "" value "" ] <TAB><TAB> if isinstance ( k , float ) : <TAB><TAB><TAB> return unicode ( float_repr ( k ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return compose_regex ( k ) <TAB><TAB> elif isinstance ( k , bool ) : <TAB><TAB><TAB> return "" true "" if k else "" false "" <TAB><TAB> elif k is None : <TAB><TAB><TAB> return "" null "" <TAB><TAB> else : <TAB><TAB><TAB> return unicode ( k )","elif ""regex"" in literal_or_identifier :","elif isinstance ( k , str ) :",96.23642404327923,95.72,False
408,"def process_image_pre_creation ( sender , instance : Image , * * kwargs ) : <TAB> # FIXME(winkidney): May have issue on determining if it <TAB> #  is created or not <TAB> if instance . pk is not None : <TAB><TAB> return <TAB> for plugin in _plugin_instances : <TAB><TAB> process_fn = getattr ( plugin , "" process_image_pre_creation "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> process_fn ( <TAB><TAB><TAB><TAB> django_settings = settings , <TAB><TAB><TAB><TAB> image_instance = instance , <TAB><TAB><TAB> ) <TAB><TAB> except Exception : <TAB><TAB><TAB> logging . exception ( <TAB><TAB><TAB><TAB> "" Error occurs while trying to access plugin ' s pin_pre_save  "" <TAB><TAB><TAB><TAB> "" for plugin  %s "" % plugin <TAB><TAB><TAB> )",if process_fn is None :,if process_fn is None :,75.0,100.00,True
409,"def check_screenshots ( self ) : <TAB> # If we arrive here, there have not been any failures yet <TAB> if self . interactive : <TAB><TAB> self . _commit_screenshots ( ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _validate_screenshots ( ) <TAB><TAB><TAB> # Always commit the screenshots here. They can be used for the next test run. <TAB><TAB><TAB> # If reference screenshots were already present and there was a mismatch, it should <TAB><TAB><TAB> # have failed above. <TAB><TAB><TAB> self . _commit_screenshots ( ) <TAB><TAB> elif self . allow_missing_screenshots : <TAB><TAB><TAB> warnings . warn ( "" No committed reference screenshots available. Ignoring. "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( <TAB><TAB><TAB><TAB> "" No committed reference screenshots available. Run interactive first. "" <TAB><TAB><TAB> )",if self . _has_reference_screenshots ( ) :,if self . allow_valid_screenshots :,73.28853387379105,96.72,False
410,"def on_task_abort ( self , task , config ) : <TAB> if "" abort "" in config : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> log . debug ( "" sending abort notification "" ) <TAB><TAB> self . send_notification ( <TAB><TAB><TAB> config [ "" abort "" ] [ "" title "" ] , <TAB><TAB><TAB> config [ "" abort "" ] [ "" message "" ] , <TAB><TAB><TAB> config [ "" abort "" ] [ "" via "" ] , <TAB><TAB><TAB> template_renderer = task . render , <TAB><TAB> )",if task . silent_abort :,"if config [ ""abort"" ] [ ""status"" ] == ""completed"" :",93.72686398666224,89.93,False
411,"def block_users ( self , user_ids ) : <TAB> broken_items = [ ] <TAB> self . logger . info ( "" Going to block  %d  users. "" % len ( user_ids ) ) <TAB> for user_id in tqdm ( user_ids ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . error_delay ( ) <TAB><TAB><TAB> broken_items = user_ids [ user_ids . index ( user_id ) : ] <TAB><TAB><TAB> break <TAB> self . logger . info ( "" DONE: Total blocked  %d  users. "" % self . total [ "" blocks "" ] ) <TAB> return broken_items",if not self . block ( user_id ) :,"if self . total [ ""blocks"" ] > self . total [ ""blocks"" ] :",77.9901746225777,89.93,False
412,"def find_widget_by_id ( self , id , parent = None ) : <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None : <TAB><TAB> if id in self : <TAB><TAB><TAB> return self [ id ] # Do things fast if possible <TAB><TAB> parent = self [ "" editor "" ] <TAB> for c in parent . get_children ( ) : <TAB><TAB> if hasattr ( c , "" get_id "" ) : <TAB><TAB><TAB> if c . get_id ( ) == id : <TAB><TAB><TAB><TAB> return c <TAB><TAB> if isinstance ( c , Gtk . Container ) : <TAB><TAB><TAB> r = self . find_widget_by_id ( id , c ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return r <TAB> return None",if not r is None :,if r :,97.52790285032789,97.70,False
413,"def addClasses ( self , name ) : <TAB> # Result: void - None <TAB> # In: name: string <TAB> for n in name . split ( ) : <TAB><TAB> try : <TAB><TAB><TAB> k , method = n . split ( "" . "" ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> k = n <TAB><TAB><TAB> method = None <TAB><TAB> self . classes [ k ] = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . methods . setdefault ( k , { } ) [ method ] = 1",if method is not None :,if method :,71.94710336258669,96.98,False
414,"def Read ( self , lex_mode ) : <TAB> while True : <TAB><TAB> t = self . _Read ( lex_mode ) <TAB><TAB> self . was_line_cont = t . id == Id . Ignored_LineCont <TAB><TAB> # TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means <TAB><TAB> # we don't have to handle them in the VS_1/VS_2/etc. states. <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> # log('Read() Returning %s', t) <TAB> return t",if t . id != Id . Ignored_LineCont :,if self . was_line_cont :,94.82901567501933,92.86,False
415,"def _dir_guildfile ( dir , ctx ) : <TAB> from guild import guildfile <TAB> try : <TAB><TAB> return guildfile . for_dir ( dir ) <TAB> except guildfile . NoModels : <TAB><TAB> <MASK> <TAB><TAB><TAB> help_suffix = ""  or  ' %s '  for help "" % click_util . cmd_help ( ctx ) <TAB><TAB> else : <TAB><TAB><TAB> help_suffix = "" "" <TAB><TAB> cli . error ( <TAB><TAB><TAB> "" %s  does not contain a Guild file (guild.yml) \n "" <TAB><TAB><TAB> "" Try specifying a project path or package name %s . "" <TAB><TAB><TAB> % ( cwd_desc ( dir ) , help_suffix ) <TAB><TAB> ) <TAB> except guildfile . GuildfileError as e : <TAB><TAB> cli . error ( str ( e ) )",if ctx :,if ctx :,100.0,100.00,True
416,"def check_response ( self , response ) : <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response : <TAB><TAB> # Skip blank lines: <TAB><TAB> if not line . strip ( ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB><TAB><TAB> raise BadLogin ( line ) <TAB><TAB> else : <TAB><TAB><TAB> raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) )","if line . startswith ( b""OK"" ) :","elif line . startswith ( b""User"" ) :",96.90893763586531,97.01,False
417,"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB><TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB><TAB><TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB> <MASK> <TAB><TAB><TAB> homedir = response . pathspec . path <TAB><TAB><TAB> username = os . path . basename ( homedir ) <TAB><TAB><TAB> if username not in self . _ignore_users : <TAB><TAB><TAB><TAB> yield rdf_client . User ( username = username , homedir = homedir )",if stat . S_ISDIR ( int ( response . st_mode ) ) :,if response . st_mode == rdf_client . ST_MODE_NONE :,96.0920391174219,94.20,False
418,"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB><TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB><TAB> spk = uttid <TAB> if not self . reverse : <TAB><TAB> <MASK> <TAB><TAB><TAB> x = np . add ( x , self . bias [ spk ] ) <TAB><TAB> if self . norm_vars : <TAB><TAB><TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB><TAB> if self . norm_vars : <TAB><TAB><TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x",if self . norm_means :,if self . bias is not None :,73.19912283821756,95.05,False
419,"def hasFixtures ( self , ctx_callback = None ) : <TAB> context = self . context <TAB> if context is None : <TAB><TAB> return False <TAB> if self . implementsAnyFixture ( context , ctx_callback = ctx_callback ) : <TAB><TAB> return True <TAB> # My context doesn't have any, but its ancestors might <TAB> factory = self . factory <TAB> if factory : <TAB><TAB> ancestors = factory . context . get ( self , [ ] ) <TAB><TAB> for ancestor in ancestors : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",100.0,100.00,True
420,def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self . radioButtons : <TAB><TAB> btn = self . radioButtons [ moduleID ] <TAB><TAB> if moduleID == active : <TAB><TAB><TAB> btn . SetValue ( True ) <TAB><TAB> else : <TAB><TAB><TAB> btn . SetValue ( False ) <TAB><TAB> if self . demoModules . Exists ( moduleID ) : <TAB><TAB><TAB> btn . Enable ( True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . btnRestore . Enable ( True ) <TAB><TAB> else : <TAB><TAB><TAB> btn . Enable ( False ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . btnRestore . Enable ( False ),if moduleID == modModified :,if self . demoModules . Restore ( moduleID ) :,94.64552392217942,92.03,False
421,"def ignore_proxy_host ( self ) : <TAB> """"""Check if self.host is in the $no_proxy ignore list."""""" <TAB> if urllib . proxy_bypass ( self . host ) : <TAB><TAB> return True <TAB> no_proxy = os . environ . get ( "" no_proxy "" ) <TAB> if no_proxy : <TAB><TAB> entries = [ parse_host_port ( x ) for x in no_proxy . split ( "" , "" ) ] <TAB><TAB> for host , port in entries : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False",if host . lower ( ) == self . host and port == self . port :,if self . host . startswith ( host ) and self . port . startswith ( port ) :,90.21504174103697,92.00,False
422,"def run ( self , _ ) : <TAB> view = self . view <TAB> if not view . settings ( ) . get ( "" terminus_view "" ) : <TAB><TAB> return <TAB> terminal = Terminal . from_id ( view . id ( ) ) <TAB> if terminal : <TAB><TAB> terminal . close ( ) <TAB><TAB> panel_name = terminal . panel_name <TAB><TAB> <MASK> <TAB><TAB><TAB> window = panel_window ( view ) <TAB><TAB><TAB> if window : <TAB><TAB><TAB><TAB> window . destroy_output_panel ( panel_name ) <TAB><TAB> else : <TAB><TAB><TAB> view . close ( )",if panel_name :,if panel_name :,100.0,100.00,True
423,"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB><TAB> elif isinstance ( node , addnodes . start_of_file ) : <TAB><TAB><TAB> return node [ "" docname "" ] <TAB><TAB> else : <TAB><TAB><TAB> node = node . parent <TAB> return None # never reached here. only for type hinting","if isinstance ( node , nodes . document ) :","if isinstance ( node , addnodes . start_of_file ) :",97.38606131702734,94.03,False
424,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
425,"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB><TAB> if self . has_gender_differences : <TAB><TAB><TAB> elements = path_elements + [ "" female "" ] <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise <TAB><TAB> el<MASK> <TAB><TAB><TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict )",if strict :,if self . species_id not in self . _female_differences :,92.772215772398,87.18,False
426,"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB><TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB><TAB><TAB> self . _cancel_editing ( ) <TAB><TAB> elif event . GetKeyCode ( ) == wx . WXK_RETURN : <TAB><TAB><TAB> self . _update_value ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB><TAB> # Don't send skip event if enter key is pressed <TAB><TAB> # On some platforms this event is sent too late and causes crash <TAB><TAB> event . Skip ( )",elif event . GetKeyCode ( ) == wx . WXK_DELETE :,elif event . GetKeyCode ( ) == wx . WXK_ALT :,98.90494922554146,98.68,False
427,"def sync_up_to_new_location ( self , worker_ip ) : <TAB> if worker_ip != self . worker_ip : <TAB><TAB> logger . debug ( "" Setting new worker IP to  %s "" , worker_ip ) <TAB><TAB> self . set_worker_ip ( worker_ip ) <TAB><TAB> self . reset ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( "" Sync up to new location skipped. This should not occur. "" ) <TAB> else : <TAB><TAB> logger . warning ( "" Sync attempted to same IP  %s . "" , worker_ip )",if not self . sync_up ( ) :,if self . is_sync_up ( ) :,67.29116114691998,97.01,False
428,"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB><TAB> "" torrent "" : "" "" , <TAB><TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB><TAB> data = self . session . get ( url ) . text <TAB><TAB> with bs4_parser ( data ) as html : <TAB><TAB><TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for download in downloads . findAll ( "" a "" ) : <TAB><TAB><TAB><TAB><TAB> link = download [ "" href "" ] <TAB><TAB><TAB><TAB><TAB> if link . startswith ( "" magnet "" ) : <TAB><TAB><TAB><TAB><TAB><TAB> links [ "" magnet "" ] = link <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB><TAB> pass <TAB> return links [ download_type ]",if downloads :,if downloads :,100.0,100.00,True
429,"def force_ipv4 ( self , * args ) : <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB> lines = [ ] <TAB> for line in open ( self . etc_hosts ( ) ) : <TAB><TAB> if "" ::1 "" in line : <TAB><TAB><TAB> newline = re . sub ( "" \\ slocalhost \\ s "" , ""   "" , line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB><TAB><TAB><TAB> line = newline <TAB><TAB> lines . append ( line ) <TAB> f = open ( self . etc_hosts ( ) , "" w "" ) <TAB> for line in lines : <TAB><TAB> f . write ( line ) <TAB> f . close ( )",if line != newline :,if newline :,94.66679139033283,98.21,False
430,"def prepare ( self ) : <TAB> # Maybe the brok is a old daemon one or was already prepared <TAB> # if so, the data is already ok <TAB> if hasattr ( self , "" prepared "" ) and not self . prepared : <TAB><TAB> self . data = SafeUnpickler . loads ( self . data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . data [ "" instance_id "" ] = self . instance_id <TAB> self . prepared = True","if hasattr ( self , ""instance_id"" ) :",if self . instance_id :,70.799910944815,91.76,False
431,"def _test_compute_q0 ( self ) : <TAB> # Stub code to search a logq space and figure out logq0 by eyeballing <TAB> # results. This code does not run with the tests. Remove underscore to run. <TAB> sigma = 15 <TAB> order = 250 <TAB> logqs = np . arange ( - 290 , - 270 , 1 ) <TAB> count = 0 <TAB> for logq in logqs : <TAB><TAB> count + = 1 <TAB><TAB> sys . stdout . write ( <TAB><TAB><TAB> "" \t %0.5g :  %0.10g "" % ( logq , pate . rdp_gaussian ( logq , sigma , order ) ) <TAB><TAB> ) <TAB><TAB> sys . stdout . flush ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" "" )",if count % 5 == 0 :,if count % 100 == 0 :,74.00660551861131,98.71,False
432,"def valid_fieldnames ( fieldnames ) : <TAB> """"""check if fieldnames are valid"""""" <TAB> for fieldname in fieldnames : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> elif fieldname in fieldname_map and fieldname_map [ fieldname ] == "" source "" : <TAB><TAB><TAB> return True <TAB> return False","if fieldname in canonical_field_names and fieldname == ""source"" :","if fieldname == ""name"" :",64.90921357389422,88.80,False
433,"def ns_provide ( self , id_ ) : <TAB> global controllers , layouts <TAB> if id_ == "" _leo_viewrendered "" : <TAB><TAB> c = self . c <TAB><TAB> vr = controllers . get ( c . hash ( ) ) or ViewRenderedController ( c ) <TAB><TAB> h = c . hash ( ) <TAB><TAB> controllers [ h ] = vr <TAB><TAB> <MASK> <TAB><TAB><TAB> layouts [ h ] = c . db . get ( "" viewrendered_default_layouts "" , ( None , None ) ) <TAB><TAB> # return ViewRenderedController(self.c) <TAB><TAB> return vr",if not layouts . get ( h ) :,if h in layouts :,93.24083492591268,95.02,False
434,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB><TAB> if error_on_path : <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> return <TAB> if config is not None or defaults is not None : <TAB><TAB> if config is None : <TAB><TAB><TAB> config = self . _config <TAB><TAB> <MASK> <TAB><TAB><TAB> defaults = dict ( self . _map . parents ) <TAB><TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB><TAB> chain = self . _map <TAB> try : <TAB><TAB> chain . del_by_path ( path ) <TAB><TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB><TAB> if error_on_path : <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> pass",if defaults is None :,"if isinstance ( self . _map , HierarchicalChainMap ) :",76.11441292403246,95.70,False
435,"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB><TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB><TAB> for k , v in q . items ( ) : <TAB><TAB><TAB> if k not in query : <TAB><TAB><TAB><TAB> query [ k ] = { } <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # TODO check exists of k in query, may be it should be update <TAB><TAB><TAB><TAB> query [ k ] = v <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> query [ k ] . update ( v ) <TAB> return query","if isinstance ( v , list ) :","elif isinstance ( query [ k ] , dict ) :",92.32178237756001,95.30,False
436,"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB><TAB> self . data . append ( data ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB><TAB> else : <TAB><TAB><TAB> passon = b "" "" <TAB><TAB> if data : <TAB><TAB><TAB> self . data . append ( data ) <TAB> return passon",if self . size :,if self . size > 0 :,97.23441783720044,97.62,False
437,"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB><TAB> if mode == "" append "" : <TAB><TAB><TAB> core . config . globalVariables [ name ] . append ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB><TAB> core . config . globalVariables [ name ] = data","elif mode == ""add"" :","elif mode == ""add"" :",100.0,100.00,True
438,"def vi_pos_back_short ( line , index = 0 , count = 1 ) : <TAB> line = vi_list ( line ) <TAB> try : <TAB><TAB> for i in range ( count ) : <TAB><TAB><TAB> index - = 1 <TAB><TAB><TAB> while vi_is_space ( line [ index ] ) : <TAB><TAB><TAB><TAB> index - = 1 <TAB><TAB><TAB> in_word = vi_is_word ( line [ index ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> while vi_is_word ( line [ index ] ) : <TAB><TAB><TAB><TAB><TAB> index - = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> while not vi_is_word_or_space ( line [ index ] ) : <TAB><TAB><TAB><TAB><TAB> index - = 1 <TAB><TAB> return index + 1 <TAB> except IndexError : <TAB><TAB> return 0",if in_word :,if in_word :,100.0,100.00,True
439,"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB><TAB> example = list ( example ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for key , max_len in len_map . items ( ) : <TAB><TAB><TAB><TAB> example_len = example [ key ] . shape <TAB><TAB><TAB><TAB> if example_len > max_len : <TAB><TAB><TAB><TAB><TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB><TAB> yield tuple ( example )",if len_map is not None :,if len_map :,90.00176607779574,97.19,False
440,"def decorate ( f ) : <TAB> # call-signature of f is exposed via __wrapped__. <TAB> # we want it to mimic Obj.__init__ <TAB> f . __wrapped__ = Obj . __init__ <TAB> f . _uses_signature = Obj <TAB> # Supplement the docstring of f with information from Obj <TAB> if Obj . __doc__ : <TAB><TAB> doclines = Obj . __doc__ . splitlines ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> doc = f . __doc__ + "" \n "" . join ( doclines [ 1 : ] ) <TAB><TAB> else : <TAB><TAB><TAB> doc = "" \n "" . join ( doclines ) <TAB><TAB> try : <TAB><TAB><TAB> f . __doc__ = doc <TAB><TAB> except AttributeError : <TAB><TAB><TAB> # __doc__ is not modifiable for classes in Python < 3.3 <TAB><TAB><TAB> pass <TAB> return f",if f . __doc__ :,if f . __doc__ :,75.0,100.00,True
441,"def IncrementErrorCount ( self , category ) : <TAB> """"""Bumps the module's error statistic."""""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB><TAB> if self . counting != "" detailed "" : <TAB><TAB><TAB> category = category . split ( "" / "" ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . errors_by_category [ category ] = 0 <TAB><TAB> self . errors_by_category [ category ] + = 1",if category not in self . errors_by_category :,if category not in self . errors_by_category :,100.0,100.00,True
442,"def _delete_fields ( self , data ) : <TAB> data = self . _del ( <TAB><TAB> data , [ "" speaker_ids "" , "" track_id "" , "" microlocation_id "" , "" session_type_id "" ] <TAB> ) <TAB> # convert datetime fields <TAB> for _ in [ "" start_time_tz "" , "" end_time_tz "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> data [ _ ] = SESSION_POST [ _ [ 0 : - 3 ] ] . from_str ( data [ _ ] ) <TAB><TAB><TAB> data [ _ [ 0 : - 3 ] ] = data . pop ( _ ) <TAB> return data",if _ in data :,if _ [ - 3 ] in SESSION_POST :,97.57248477079837,94.66,False
443,"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB><TAB> if char in char_set : <TAB><TAB><TAB> letters + = char <TAB><TAB><TAB> count + = 1 <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> strings . append ( letters ) <TAB><TAB><TAB> letters = "" "" <TAB><TAB><TAB> count = 0 <TAB> <MASK> <TAB><TAB> strings . append ( letters ) <TAB> return strings",if count > threshold :,if count >= threshold :,97.14659448430805,97.17,False
444,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB><TAB> while token : <TAB><TAB><TAB> if token . value == "" { "" : <TAB><TAB><TAB><TAB> length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if token . OpensScope ( ) : <TAB><TAB><TAB><TAB> token = token . matching_bracket <TAB><TAB><TAB> token = token . next_token <TAB> return False",if token . ClosesScope ( ) :,"elif token . value == ""}"" :",76.04305997640273,95.45,False
445,"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB><TAB> if mode == "" start "" : <TAB><TAB><TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" key "" <TAB><TAB> elif mode == "" key "" : <TAB><TAB><TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" end "" <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB> "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB> ) <TAB> if mode != "" end "" : <TAB><TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :","elif mode == ""end"" :",83.93877314377275,94.44,False
446,"def main ( self ) : <TAB> self . model . clear ( ) <TAB> self . callman . unregister_all ( ) <TAB> active_handle = self . get_active ( "" Person "" ) <TAB> if active_handle : <TAB><TAB> active = self . dbstate . db . get_person_from_handle ( active_handle ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . callman . register_obj ( active ) <TAB><TAB><TAB> self . display_citations ( active ) <TAB><TAB> else : <TAB><TAB><TAB> self . set_has_data ( False ) <TAB> else : <TAB><TAB> self . set_has_data ( False )",if active :,if active :,100.0,100.00,True
447,"def _validate ( self ) - > None : <TAB> # Paren validation and such <TAB> super ( Tuple , self ) . _validate ( ) <TAB> if len ( self . elements ) == 0 : <TAB><TAB> <MASK> # assumes len(lpar) == len(rpar), via superclass <TAB><TAB><TAB> raise CSTValidationError ( <TAB><TAB><TAB><TAB> "" A zero-length tuple must be wrapped in parentheses. "" <TAB><TAB><TAB> )",if len ( self . lpar ) == 0 :,if self . elements [ 0 ] == 0 :,70.26000215139055,94.42,False
448,"def _session_from_arg ( self , session_obj , lock_type = None ) : <TAB> if not isinstance ( session_obj , self . ISession ) : <TAB><TAB> vm = self . _machine_from_arg ( session_obj ) <TAB><TAB> lock_type = lock_type or self . LockType . null <TAB><TAB> <MASK> <TAB><TAB><TAB> return vm . create_session ( lock_type ) <TAB><TAB> return None <TAB> return session_obj",if vm :,if vm :,100.0,100.00,True
449,"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB> if name not in cls . __dict__ : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> if not private and name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB> if name in butnot : <TAB><TAB><TAB> continue <TAB><TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls","if name != ""__init__"" :",if not inspect . isfunction ( meth ) :,66.36628543632543,92.25,False
450,"def pdb ( message = "" "" ) : <TAB> """"""Fall into pdb."""""" <TAB> import pdb # Required: we have just defined pdb as a function! <TAB> if app and not app . useIpython : <TAB><TAB> # from leo.core.leoQt import QtCore <TAB><TAB> # This is more portable. <TAB><TAB> try : <TAB><TAB><TAB> import PyQt5 . QtCore as QtCore <TAB><TAB> except ImportError : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> import PyQt4 . QtCore as QtCore <TAB><TAB><TAB> except ImportError : <TAB><TAB><TAB><TAB> QtCore = None <TAB><TAB> <MASK> <TAB><TAB><TAB> # pylint: disable=no-member <TAB><TAB><TAB> QtCore . pyqtRemoveInputHook ( ) <TAB> if message : <TAB><TAB> print ( message ) <TAB> pdb . set_trace ( )",if QtCore :,if QtCore :,100.0,100.00,True
451,"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets : <TAB><TAB> if b . get ( "" Logging "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB><TAB> if not self_log and b [ "" Name "" ] . startswith ( "" cf-templates- "" ) : <TAB><TAB><TAB> yield ( b [ "" Name "" ] , "" "" )",if self_log :,"if ""TargetPrefix"" in b [ ""Logging"" ] :",96.6807786056235,94.63,False
452,"def prepare_fields ( self ) : <TAB> # See clean() <TAB> for k , v in self . fields . items ( ) : <TAB><TAB> v . _required = v . required <TAB><TAB> v . required = False <TAB><TAB> v . widget . is_required = False <TAB><TAB> <MASK> <TAB><TAB><TAB> v . _required = v . one_required <TAB><TAB><TAB> v . one_required = False <TAB><TAB><TAB> v . widget . enabled_locales = self . locales","if isinstance ( v , I18nFormField ) :",if v . one_required :,70.39651025168993,94.79,False
453,"def __pack__ ( self ) : <TAB> new_values = [ ] <TAB> for i in xrange ( len ( self . __unpacked_data_elms__ ) ) : <TAB><TAB> for key in self . __keys__ [ i ] : <TAB><TAB><TAB> new_val = getattr ( self , key ) <TAB><TAB><TAB> old_val = self . __unpacked_data_elms__ [ i ] <TAB><TAB><TAB> # In the case of Unions, when the first changed value <TAB><TAB><TAB> # is picked the loop is exited <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> new_values . append ( new_val ) <TAB> return struct . pack ( self . __format__ , * new_values )",if new_val != old_val :,if new_val != old_val :,100.0,100.00,True
454,"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB><TAB> main_vault_directory = os . path . join ( <TAB><TAB><TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB><TAB><TAB><TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB><TAB><TAB><TAB><TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> if cred : <TAB><TAB><TAB><TAB><TAB> pwd_found . append ( cred ) <TAB> return pwd_found",if os . path . exists ( main_vault_directory ) :,if os . path . isdir ( main_vault_directory ) :,98.95783192280525,99.01,False
455,"def on_revision_plugin_revision_pre_save ( * * kwargs ) : <TAB> instance = kwargs [ "" instance "" ] <TAB> if kwargs . get ( "" created "" , False ) : <TAB><TAB> update_previous_revision = ( <TAB><TAB><TAB> not instance . previous_revision <TAB><TAB><TAB> and instance . plugin <TAB><TAB><TAB> and instance . plugin . current_revision <TAB><TAB><TAB> and instance . plugin . current_revision != instance <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> instance . previous_revision = instance . plugin . current_revision <TAB> if not instance . revision_number : <TAB><TAB> try : <TAB><TAB><TAB> previous_revision = instance . plugin . revision_set . latest ( ) <TAB><TAB><TAB> instance . revision_number = previous_revision . revision_number + 1 <TAB><TAB> except RevisionPluginRevision . DoesNotExist : <TAB><TAB><TAB> instance . revision_number = 1",if update_previous_revision :,if update_previous_revision :,100.0,100.00,True
456,"def __setattr__ ( self , name , value ) : <TAB> super ( ) . __setattr__ ( name , value ) <TAB> field = self . _fields . get ( name ) <TAB> if field : <TAB><TAB> self . check_field_type ( field , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( f "" cannot set immutable  { name }  on  { self !r} "" )",if name in self . __ast_frozen_fields__ :,if self . immutable :,92.77160861126238,87.91,False
457,"def _check_for_req_data ( data ) : <TAB> required_args = [ "" columns "" ] <TAB> for arg in required_args : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True , make_json_response ( <TAB><TAB><TAB><TAB> status = 400 , <TAB><TAB><TAB><TAB> success = 0 , <TAB><TAB><TAB><TAB> errormsg = gettext ( "" Could not find required parameter ( {} ). "" ) . format ( arg ) , <TAB><TAB><TAB> ) <TAB> return False , "" ""","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",if data . get ( arg ) == arg :,79.98128045938383,84.18,False
458,"def train_dict ( self , triples ) : <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter ( ) <TAB> ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB> # find the most frequent mappings <TAB> for p , _ in ctr . most_common ( ) : <TAB><TAB> w , pos , l = p <TAB><TAB> <MASK> <TAB><TAB><TAB> self . composite_dict [ ( w , pos ) ] = l <TAB><TAB> if w not in self . word_dict : <TAB><TAB><TAB> self . word_dict [ w ] = l <TAB> return","if ( w , pos ) not in self . composite_dict :","if ( w , pos ) not in self . composite_dict :",100.0,100.00,True
459,"def render ( type_ , obj , context ) : <TAB> if type_ == "" foreign_key "" : <TAB><TAB> return None <TAB> if type_ == "" column "" : <TAB><TAB> if obj . name == "" y "" : <TAB><TAB><TAB> return None <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> return "" col( %s ) "" % obj . name <TAB> if type_ == "" type "" and isinstance ( obj , MySpecialType ) : <TAB><TAB> context . imports . add ( "" from mypackage import MySpecialType "" ) <TAB><TAB> return "" MySpecialType() "" <TAB> return "" render: %s "" % type_","elif obj . name == ""q"" :","elif obj . name == ""n"" :",73.85195706484502,98.68,False
460,"def test_knows_when_stepping_back_possible ( self ) : <TAB> iterator = bidirectional_iterator . BidirectionalIterator ( [ 0 , 1 , 2 , 3 ] ) <TAB> commands = [ 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ] <TAB> command_count = 0 <TAB> results = [ ] <TAB> for _ in iterator : <TAB><TAB> <MASK> <TAB><TAB><TAB> iterator . step_back_on_next_iteration ( ) <TAB><TAB> results . append ( iterator . can_step_back ( ) ) <TAB><TAB> command_count + = 1 <TAB> assert results == [ False , True , False , True , True , True , False , True , True , True ]",if commands [ command_count ] :,if command_count == 2 :,66.86964520716845,96.66,False
461,"def flask_debug_true ( context ) : <TAB> if context . is_module_imported_like ( "" flask "" ) : <TAB><TAB> if context . call_function_name_qual . endswith ( "" .run "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return bandit . Issue ( <TAB><TAB><TAB><TAB><TAB> severity = bandit . HIGH , <TAB><TAB><TAB><TAB><TAB> confidence = bandit . MEDIUM , <TAB><TAB><TAB><TAB><TAB> text = "" A Flask app appears to be run with debug=True,  "" <TAB><TAB><TAB><TAB><TAB> "" which exposes the Werkzeug debugger and allows  "" <TAB><TAB><TAB><TAB><TAB> "" the execution of arbitrary code. "" , <TAB><TAB><TAB><TAB><TAB> lineno = context . get_lineno_for_call_arg ( "" debug "" ) , <TAB><TAB><TAB><TAB> )","if context . check_call_arg_value ( ""debug"" , ""True"" ) :","if context . get_lineno_for_call_arg ( ""debug"" ) :",75.30155973131212,96.05,False
462,"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . _should_meta_profile : <TAB><TAB> end_time = timezone . now ( ) <TAB><TAB> exception_raised = exc_type is not None <TAB><TAB> if exception_raised : <TAB><TAB><TAB> Logger . error ( <TAB><TAB><TAB><TAB> "" Exception when performing meta profiling, dumping trace below "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> traceback . print_exception ( exc_type , exc_val , exc_tb ) <TAB><TAB> request = getattr ( DataCollector ( ) . local , "" request "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> curr = request . meta_time or 0 <TAB><TAB><TAB> request . meta_time = curr + _time_taken ( self . start_time , end_time )",if request :,if request :,100.0,100.00,True
463,"def get_job_offer ( ja_list ) : <TAB> ja_joff_map = { } <TAB> offers = frappe . get_all ( <TAB><TAB> "" Job Offer "" , <TAB><TAB> filters = [ [ "" job_applicant "" , "" IN "" , ja_list ] ] , <TAB><TAB> fields = [ "" name "" , "" job_applicant "" , "" status "" , "" offer_date "" , "" designation "" ] , <TAB> ) <TAB> for offer in offers : <TAB><TAB> <MASK> <TAB><TAB><TAB> ja_joff_map [ offer . job_applicant ] = [ offer ] <TAB><TAB> else : <TAB><TAB><TAB> ja_joff_map [ offer . job_applicant ] . append ( offer ) <TAB> return ja_joff_map",if offer . job_applicant not in ja_joff_map . keys ( ) :,if offer . job_applicant not in ja_joff_map :,78.40006731108184,97.34,False
464,"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return t [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> for part in t : <TAB><TAB><TAB><TAB> res = self . _get_deepest ( part ) <TAB><TAB><TAB><TAB> if res : <TAB><TAB><TAB><TAB><TAB> return res <TAB><TAB><TAB> return None <TAB> return None",if len ( t ) == 1 :,if len ( t ) == 1 :,100.0,100.00,True
465,"def test_main ( self ) : <TAB> root = os . path . dirname ( mutagen . __path__ [ 0 ] ) <TAB> skip = [ os . path . join ( root , "" docs "" ) , os . path . join ( root , "" venv "" ) ] <TAB> for dirpath , dirnames , filenames in os . walk ( root ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> if filename . endswith ( "" .py "" ) : <TAB><TAB><TAB><TAB> path = os . path . join ( dirpath , filename ) <TAB><TAB><TAB><TAB> self . _check_encoding ( path )",if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,if dirpath in skip :,87.15029842567306,86.96,False
466,"def xview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB><TAB> value = float ( value ) <TAB> if mode is None : <TAB><TAB> return self . hsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB><TAB> frameWidth = self . innerframe . winfo_reqwidth ( ) <TAB><TAB> self . _startX = value * float ( frameWidth ) <TAB> else : # mode == 'scroll' <TAB><TAB> clipperWidth = self . _clipper . winfo_width ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> jump = int ( clipperWidth * self . _jfraction ) <TAB><TAB> else : <TAB><TAB><TAB> jump = clipperWidth <TAB><TAB> self . _startX = self . _startX + value * jump <TAB> self . reposition ( )","if units == ""units"" :",if self . _jfraction is not None :,97.84770687072681,96.09,False
467,"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB><TAB> DEFAULT_DOMAIN_PATH , <TAB><TAB> DEFAULT_STORIES_FILE , <TAB><TAB> tmpdir . strpath , <TAB><TAB> interpreter = RegexInterpreter ( ) , <TAB><TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB><TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB><TAB> <MASK> <TAB><TAB><TAB> if type ( policy ) == FormPolicy : <TAB><TAB><TAB><TAB> assert policy . featurizer . max_history == 2 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> assert policy . featurizer . max_history == 5","if hasattr ( policy . featurizer , ""max_history"" ) :",if policy . featurizer . max_history_limit is not None :,71.67075481769615,95.50,False
468,"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB><TAB> compare_entry = entry <TAB><TAB> compare_base = base <TAB><TAB> <MASK> <TAB><TAB><TAB> compare_entry = compare_entry . lower ( ) <TAB><TAB><TAB> compare_base = compare_base . lower ( ) <TAB><TAB> if self . compare_entries ( compare_entry , compare_base ) : <TAB><TAB><TAB> if entry not in sugg : <TAB><TAB><TAB><TAB> sugg . append ( entry ) <TAB> return sugg",if self . settings . get ( IGNORE_CASE_SETTING ) :,if self . lower_compare :,65.93584777518234,93.46,False
469,"def marker_expr ( remaining ) : <TAB> if remaining and remaining [ 0 ] == "" ( "" : <TAB><TAB> result , remaining = marker ( remaining [ 1 : ] . lstrip ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise SyntaxError ( "" unterminated parenthesis:  %s "" % remaining ) <TAB><TAB> remaining = remaining [ 1 : ] . lstrip ( ) <TAB> else : <TAB><TAB> lhs , remaining = marker_var ( remaining ) <TAB><TAB> while remaining : <TAB><TAB><TAB> m = MARKER_OP . match ( remaining ) <TAB><TAB><TAB> if not m : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> op = m . groups ( ) [ 0 ] <TAB><TAB><TAB> remaining = remaining [ m . end ( ) : ] <TAB><TAB><TAB> rhs , remaining = marker_var ( remaining ) <TAB><TAB><TAB> lhs = { "" op "" : op , "" lhs "" : lhs , "" rhs "" : rhs } <TAB><TAB> result = lhs <TAB> return result , remaining","if remaining [ 0 ] != "")"" :",if not remaining :,71.95072834315843,96.31,False
470,"def __repr__ ( self ) : <TAB> """"""Dump the class data in the format of a .netrc file."""""" <TAB> rep = "" "" <TAB> for host in self . hosts . keys ( ) : <TAB><TAB> attrs = self . hosts [ host ] <TAB><TAB> rep = rep + "" machine  "" + host + "" \n \t login  "" + repr ( attrs [ 0 ] ) + "" \n "" <TAB><TAB> <MASK> <TAB><TAB><TAB> rep = rep + "" account  "" + repr ( attrs [ 1 ] ) <TAB><TAB> rep = rep + "" \t password  "" + repr ( attrs [ 2 ] ) + "" \n "" <TAB> for macro in self . macros . keys ( ) : <TAB><TAB> rep = rep + "" macdef  "" + macro + "" \n "" <TAB><TAB> for line in self . macros [ macro ] : <TAB><TAB><TAB> rep = rep + line <TAB><TAB> rep = rep + "" \n "" <TAB> return rep",if attrs [ 1 ] :,if attrs [ 1 ] :,100.0,100.00,True
471,"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB><TAB> id_ = required_key ( item , "" id "" ) <TAB><TAB> controls_ids = required_key ( item , "" controls "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if controls_ids != "" all "" : <TAB><TAB><TAB><TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB><TAB><TAB><TAB><TAB> id_ = id_ , controls = str ( controls_ids ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> raise ValueError ( msg ) <TAB><TAB> self . policies [ id_ ] = controls_ids","if not isinstance ( controls_ids , list ) :",if id_ not in self . policies :,77.69271125225622,95.10,False
472,"def __set__ ( self , obj , value ) : # noqa <TAB> if ( <TAB><TAB> value is not None <TAB><TAB> and self . field . _currency_field . null <TAB><TAB> and not isinstance ( value , MONEY_CLASSES + ( Decimal , ) ) <TAB> ) : <TAB><TAB> # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB><TAB> raise ValueError ( "" Missing currency value "" ) <TAB> if isinstance ( value , BaseExpression ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = self . prepare_value ( obj , value . value ) <TAB><TAB> elif not isinstance ( value , Func ) : <TAB><TAB><TAB> validate_money_expression ( obj , value ) <TAB><TAB><TAB> prepare_expression ( value ) <TAB> else : <TAB><TAB> value = self . prepare_value ( obj , value ) <TAB> obj . __dict__ [ self . field . name ] = value","if isinstance ( value , Value ) :",if value . value is not None :,72.6599935053219,97.08,False
473,"def Children ( self ) : <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB><TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if not is_list : <TAB><TAB><TAB><TAB> children . append ( self . _properties [ property ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> children . extend ( self . _properties [ property ] ) <TAB> return children",if is_strong and property in self . _properties :,if is_strong :,66.4757240092595,95.08,False
474,"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB><TAB> start = self . items . index ( self . _selected ) <TAB><TAB> i = start + direction <TAB> except : <TAB><TAB> pass <TAB> while True : <TAB><TAB> if i == start : <TAB><TAB><TAB> # Cannot find valid menu item <TAB><TAB><TAB> self . select ( start ) <TAB><TAB><TAB> break <TAB><TAB> if i > = len ( self . items ) : <TAB><TAB><TAB> i = 0 <TAB><TAB><TAB> continue <TAB><TAB> if i < 0 : <TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> continue <TAB><TAB> if self . select ( i ) : <TAB><TAB><TAB> break <TAB><TAB> i + = direction <TAB><TAB> <MASK> <TAB><TAB><TAB> start = 0",if start < 0 :,if i == start :,98.49540424919117,98.13,False
475,"def setup_displace ( self ) : <TAB> self . displace_mod = None <TAB> self . displace_strength = 0.020 <TAB> for mod in self . obj . modifiers : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . displace_mod = mod <TAB><TAB><TAB> self . displace_strength = mod . strength <TAB> if not self . displace_mod : <TAB><TAB> bpy . ops . object . modifier_add ( type = "" DISPLACE "" ) <TAB><TAB> self . displace_mod = self . obj . modifiers [ - 1 ] <TAB><TAB> self . displace_mod . show_expanded = False <TAB><TAB> self . displace_mod . strength = self . displace_strength <TAB><TAB> self . displace_mod . show_render = False <TAB><TAB> self . displace_mod . show_viewport = False","if mod . type == ""DISPLACE"" :","if isinstance ( mod , bpy . ops . object . modifier_add ) :",94.31826332967555,93.13,False
476,"def set_json_body ( cls , request_builder ) : <TAB> old_body = request_builder . info . pop ( "" data "" , { } ) <TAB> if isinstance ( old_body , abc . Mapping ) : <TAB><TAB> body = request_builder . info . setdefault ( "" json "" , { } ) <TAB><TAB> for path in old_body : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cls . _sequence_path_resolver ( path , old_body [ path ] , body ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> body [ path ] = old_body [ path ] <TAB> else : <TAB><TAB> request_builder . info . setdefault ( "" json "" , old_body )","if isinstance ( path , tuple ) :","if isinstance ( old_body [ path ] , abc . Mapping ) :",93.31450467312715,94.56,False
477,"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" DBLL "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB><TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # An older version exists, so remove these outdated files. <TAB><TAB><TAB> build_data . remove_dir ( dpath ) <TAB><TAB> build_data . make_dir ( dpath ) <TAB><TAB> # Download the data. <TAB><TAB> for downloadable_file in RESOURCES : <TAB><TAB><TAB> downloadable_file . download_file ( dpath ) <TAB><TAB> # Mark the data as built. <TAB><TAB> build_data . mark_done ( dpath , version_string = version )",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,100.0,100.00,True
478,"def test_prefix_lm ( self ) : <TAB> num_tries = 100 <TAB> original = "" This is a long test with lots of words to see if it works ok. "" <TAB> dataset = tf . data . Dataset . from_tensor_slices ( { "" text "" : [ original ] * num_tries } ) <TAB> dataset = prep . prefix_lm ( dataset ) <TAB> for data in test_utils . dataset_as_text ( dataset ) : <TAB><TAB> inputs = data [ "" inputs "" ] . replace ( "" prefix:  "" , "" "" ) <TAB><TAB> targets = data [ "" targets "" ] <TAB><TAB> reconstructed = "" "" . join ( inputs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> reconstructed + = ""   "" <TAB><TAB> reconstructed + = "" "" . join ( targets ) <TAB><TAB> self . assertEqual ( reconstructed , original )",if inputs :,if len ( targets ) > 1 :,69.23373442937529,96.50,False
479,"def leading_whitespace ( self , inputstring ) : <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB><TAB> if c in legal_indent_chars : <TAB><TAB><TAB> leading_ws . append ( c ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> self . indchar = c <TAB><TAB> elif c != self . indchar : <TAB><TAB><TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws )",if self . indchar is None :,if i == 0 :,87.25510483464517,96.38,False
480,"def __init__ ( self , text ) : <TAB> self . mappings = { } <TAB> self . attributes = collections . defaultdict ( set ) <TAB> for stanza in _ParseTextProperties ( text ) : <TAB><TAB> processor_id , single_values , multiple_values = self . _ParseStanza ( stanza ) <TAB><TAB> if processor_id is None : # can be 0 <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . warn ( "" Processor id  %s  seen twice in  %s "" , processor_id , text ) <TAB><TAB><TAB> continue <TAB><TAB> self . mappings [ processor_id ] = single_values <TAB><TAB> for key , value in multiple_values . items ( ) : <TAB><TAB><TAB> self . attributes [ key ] . add ( value )",if processor_id in self . mappings :,if processor_id in self . mappings :,100.0,100.00,True
481,"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . wait_counter = 0 <TAB><TAB><TAB> yield chunk <TAB><TAB> elif self . wait_counter < self . wait_cntr_max : <TAB><TAB><TAB> self . wait_counter + = 1 <TAB><TAB> else : <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB><TAB><TAB><TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( self . poll_period )",if chunk is not None :,if self . wait_counter == self . wait_cntr_max :,91.00977348214539,93.09,False
482,"def download ( self , prefetch = False ) : <TAB> while self . running : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ( path , start , end ) = self . prefetch_queue . get ( <TAB><TAB><TAB><TAB><TAB> True , 1 <TAB><TAB><TAB><TAB> ) # 1 second time-out <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ( path , start , end ) = self . download_queue . get ( <TAB><TAB><TAB><TAB><TAB> True , 1 <TAB><TAB><TAB><TAB> ) # 1 second time-out <TAB><TAB><TAB> self . download_data ( path , start , end ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . prefetch_queue . task_done ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . download_queue . task_done ( ) <TAB><TAB> except Queue . Empty : <TAB><TAB><TAB> pass",if prefetch :,if prefetch :,100.0,100.00,True
483,"def process_messages ( self , found_files , messages ) : <TAB> for message in messages : <TAB><TAB> <MASK> <TAB><TAB><TAB> message . to_absolute_path ( self . config . workdir ) <TAB><TAB> else : <TAB><TAB><TAB> message . to_relative_path ( self . config . workdir ) <TAB> if self . config . blending : <TAB><TAB> messages = blender . blend ( messages ) <TAB> filepaths = found_files . iter_module_paths ( abspath = False ) <TAB> return postfilter . filter_messages ( filepaths , self . config . workdir , messages )",if self . config . absolute_paths :,if self . config . absolute :,98.6390490442835,97.70,False
484,"def set_indentation_params ( self , ispythonsource , guess = 1 ) : <TAB> if guess and ispythonsource : <TAB><TAB> i = self . guess_indent ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . indentwidth = i <TAB><TAB> if self . indentwidth != self . tabwidth : <TAB><TAB><TAB> self . usetabs = 0 <TAB> self . editwin . set_tabwidth ( self . tabwidth )",if 2 <= i <= 8 :,if i :,72.24355959418045,92.51,False
485,"def to_tree ( self , tagname = None , value = None , namespace = None ) : <TAB> namespace = getattr ( self , "" namespace "" , namespace ) <TAB> if value is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> tagname = "" { %s } %s "" % ( namespace , tagname ) <TAB><TAB> el = Element ( tagname ) <TAB><TAB> el . text = safe_string ( value ) <TAB><TAB> return el",if namespace is not None :,if namespace is not None :,100.0,100.00,True
486,"def execute ( self , argv : List ) - > bool : <TAB> if not argv : <TAB><TAB> print ( "" ERROR: You must give at least one module to download. "" ) <TAB><TAB> return False <TAB> for _arg in argv : <TAB><TAB> result = module_server . search_module ( _arg ) <TAB><TAB> CacheUpdater ( "" hub_download "" , _arg ) . start ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> url = result [ 0 ] [ "" url "" ] <TAB><TAB><TAB> with log . ProgressBar ( "" Download  {} "" . format ( url ) ) as bar : <TAB><TAB><TAB><TAB> for file , ds , ts in utils . download_with_progress ( url ) : <TAB><TAB><TAB><TAB><TAB> bar . update ( float ( ds ) / ts ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" ERROR: Could not find a HubModule named  {} "" . format ( _arg ) ) <TAB> return True",if result :,if result :,100.0,100.00,True
487,"def visit_type_type ( self , t : TypeType ) - > ProperType : <TAB> if isinstance ( self . s , TypeType ) : <TAB><TAB> typ = self . meet ( t . item , self . s . item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> typ = TypeType . make_normalized ( typ , line = t . line ) <TAB><TAB> return typ <TAB> elif isinstance ( self . s , Instance ) and self . s . type . fullname == "" builtins.type "" : <TAB><TAB> return t <TAB> elif isinstance ( self . s , CallableType ) : <TAB><TAB> return self . meet ( t , self . s ) <TAB> else : <TAB><TAB> return self . default ( self . s )","if not isinstance ( typ , NoneType ) :","if self . s . type . fullname == ""builtins.type"" :",68.75022706479128,91.90,False
488,"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB> items . append ( item . name ( ) ) <TAB> if len ( items ) > 0 : <TAB><TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sublime . status_message ( "" Items copied "" ) <TAB><TAB> else : <TAB><TAB><TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,100.0,100.00,True
489,"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB><TAB> # Load it from an absolute filename <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB><TAB><TAB> except GObject . GError as ge : <TAB><TAB><TAB><TAB> pass <TAB><TAB> # Load it from the current icon theme <TAB><TAB> ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB><TAB> theme = Gtk . IconTheme ( ) <TAB><TAB> if theme . has_icon ( icon_name ) : <TAB><TAB><TAB> return theme . load_icon ( icon_name , 24 , 0 )",if os . path . exists ( self . icon ) :,if os . path . isabs ( self . icon ) :,99.01341084821884,98.88,False
490,"def setup_logger ( ) : <TAB> """"""Set up logger and add stdout handler"""""" <TAB> logging . setLoggerClass ( IPDLogger ) <TAB> logger = logging . getLogger ( "" icloudpd "" ) <TAB> has_stdout_handler = False <TAB> for handler in logger . handlers : <TAB><TAB> <MASK> <TAB><TAB><TAB> has_stdout_handler = True <TAB> if not has_stdout_handler : <TAB><TAB> formatter = logging . Formatter ( <TAB><TAB><TAB> fmt = "" %(asctime)s   %(levelname)-8s   %(message)s "" , datefmt = "" % Y- % m- %d   % H: % M: % S "" <TAB><TAB> ) <TAB><TAB> stdout_handler = logging . StreamHandler ( stream = sys . stdout ) <TAB><TAB> stdout_handler . setFormatter ( formatter ) <TAB><TAB> stdout_handler . name = "" stdoutLogger "" <TAB><TAB> logger . addHandler ( stdout_handler ) <TAB> return logger","if handler . name == ""stdoutLogger"" :","if hasattr ( handler , ""name"" ) :",95.47971795529497,96.45,False
491,"def process_extra_fields ( self ) : <TAB> if self . instance . pk is not None : <TAB><TAB> if self . cleaned_data . get ( "" initialize "" , None ) : <TAB><TAB><TAB> self . instance . initialize ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . instance . update_from_templates ( )","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :","if self . cleaned_data . get ( ""update_from_templates"" , None )",57.07518506086495,86.47,False
492,"def testFunctions ( self ) : <TAB> from zim . formats . wiki import match_url , is_url <TAB> for input , input_is_url , tail in self . examples : <TAB><TAB> if input_is_url : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( match_url ( input ) , input [ : - len ( tail ) ] ) <TAB><TAB><TAB><TAB> self . assertFalse ( is_url ( input ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertEqual ( match_url ( input ) , input ) <TAB><TAB><TAB><TAB> self . assertTrue ( is_url ( input ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( match_url ( input ) , None ) <TAB><TAB><TAB> self . assertFalse ( is_url ( input ) )",if tail :,if input . endswith ( tail ) :,87.18083926992146,96.90,False
493,"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB><TAB> username = user [ 0 ] <TAB><TAB> settings = user [ 1 ] <TAB><TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB><TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" joined "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB><TAB><TAB> elif "" left "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB> self . _client . removeUser ( username ) <TAB><TAB> else : <TAB><TAB><TAB> self . _client . userlist . modUser ( username , room , file_ )","if ""event"" in settings :",if room :,69.78521742318603,97.17,False
494,"def restoreTerminals ( self , state ) : <TAB> for name in list ( self . terminals . keys ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . removeTerminal ( name ) <TAB> for name , opts in state . items ( ) : <TAB><TAB> if name in self . terminals : <TAB><TAB><TAB> term = self [ name ] <TAB><TAB><TAB> term . setOpts ( * * opts ) <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> opts = strDict ( opts ) <TAB><TAB><TAB> self . addTerminal ( name , * * opts ) <TAB><TAB> except : <TAB><TAB><TAB> printExc ( "" Error restoring terminal  %s  ( %s ): "" % ( str ( name ) , str ( opts ) ) )",if name not in state :,if name in state :,98.84824426088926,98.78,False
495,"def htmlify ( path , text ) : <TAB> fname = os . path . basename ( path ) <TAB> if any ( ( fnmatch . fnmatchcase ( fname , p ) for p in _patterns ) ) : <TAB><TAB> # Get file_id, skip if not in database <TAB><TAB> sql = "" SELECT files.id FROM files WHERE path = ? LIMIT 1 "" <TAB><TAB> row = _conn . execute ( sql , ( path , ) ) . fetchone ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ClangHtmlifier ( _tree , _conn , path , text , row [ 0 ] ) <TAB> return None",if row :,if row :,100.0,100.00,True
496,"def autoformat_filter_conv2d ( fsize , in_depth , out_depth ) : <TAB> if isinstance ( fsize , int ) : <TAB><TAB> return [ fsize , fsize , in_depth , out_depth ] <TAB> elif isinstance ( fsize , ( tuple , list , tf . TensorShape ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ fsize [ 0 ] , fsize [ 1 ] , in_depth , out_depth ] <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" filter length error:  "" <TAB><TAB><TAB><TAB> + str ( len ( fsize ) ) <TAB><TAB><TAB><TAB> + "" , only a length of 2 is supported. "" <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise Exception ( "" filter format error:  "" + str ( type ( fsize ) ) )",if len ( fsize ) == 2 :,if len ( fsize ) == 2 :,75.0,100.00,True
497,"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB><TAB> <MASK> <TAB><TAB><TAB> count + = 1 <TAB><TAB> else : <TAB><TAB><TAB> if count : <TAB><TAB><TAB><TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB><TAB><TAB><TAB> count = 0 <TAB><TAB><TAB> new + = bytes ( [ cur ] ) <TAB> return new",if not cur :,"if cur == b""\0"" :",67.76021816386668,93.54,False
498,"def is_clean ( self ) : <TAB> acceptable_statuses = { "" external "" , "" unversioned "" } <TAB> root = self . _capture_output ( "" status "" , "" --quiet "" ) <TAB> for elem in root . findall ( "" ./target/entry "" ) : <TAB><TAB> status = elem . find ( "" ./wc-status "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> log . debug ( "" Path  %s  is  %s "" , elem . get ( "" path "" ) , status . get ( "" item "" ) ) <TAB><TAB> return False <TAB> return True","if status . get ( ""item"" , None ) in acceptable_statuses :","if status . get ( ""status"" ) in acceptable_statuses :",68.1593446523503,96.74,False
499,"def process ( self , body , message ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> ' Received an unexpected type  "" %s ""  for payload. ' % type ( body ) <TAB><TAB><TAB> ) <TAB><TAB> response = self . _handler . pre_ack_process ( body ) <TAB><TAB> self . _dispatcher . dispatch ( self . _process_message , response ) <TAB> except : <TAB><TAB> LOG . exception ( "" %s  failed to process message:  %s "" , self . __class__ . __name__ , body ) <TAB> finally : <TAB><TAB> # At this point we will always ack a message. <TAB><TAB> message . ack ( )","if not isinstance ( body , self . _handler . message_type ) :","if not isinstance ( body , ( dict , list ) ) :",93.26677353588532,95.39,False
500,"def page_file ( self , page ) : <TAB> try : <TAB><TAB> page = self . notebook . get_page ( page ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return page . source <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> except PageNotFoundError : <TAB><TAB> return None","if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",if page . source :,54.049447652239145,82.64,False
501,"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> elif silhouette < = best_silhouette : <TAB><TAB><TAB> break <TAB><TAB> best_silhouette = silhouette <TAB><TAB> best_a = a <TAB><TAB> best_k = k <TAB> return best_a , best_silhouette , best_k",if best_silhouette is None :,if a is None :,86.4698331111111,96.79,False
502,"def _cancel_tasks_for_partitions ( self , to_cancel_partitions ) : <TAB> # type: (Iterable[str]) -> None <TAB> with self . _lock : <TAB><TAB> _LOGGER . debug ( <TAB><TAB><TAB> "" EventProcessor  %r  tries to cancel partitions  %r "" , <TAB><TAB><TAB> self . _id , <TAB><TAB><TAB> to_cancel_partitions , <TAB><TAB> ) <TAB><TAB> for partition_id in to_cancel_partitions : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _consumers [ partition_id ] . stop = True <TAB><TAB><TAB><TAB> _LOGGER . info ( <TAB><TAB><TAB><TAB><TAB> "" EventProcessor  %r  has cancelled partition  %r "" , <TAB><TAB><TAB><TAB><TAB> self . _id , <TAB><TAB><TAB><TAB><TAB> partition_id , <TAB><TAB><TAB><TAB> )",if partition_id in self . _consumers :,if partition_id in self . _consumers :,75.0,100.00,True
503,"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = parts <TAB><TAB> else : <TAB><TAB><TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB><TAB> return None <TAB> elif len ( result ) == 1 : <TAB><TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB><TAB> solids = [ p . item for p in result ] <TAB><TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB><TAB> if refine : <TAB><TAB><TAB> solid = solid . removeSplitter ( ) <TAB><TAB> return solid",if result is None :,"if source == ""result"" :",76.79796175226478,96.50,False
504,"def geli_detach ( self , pool , clear = False ) : <TAB> failed = 0 <TAB> for ed in self . middleware . call_sync ( <TAB><TAB> "" datastore.query "" , <TAB><TAB> "" storage.encrypteddisk "" , <TAB><TAB> [ ( "" encrypted_volume "" , "" = "" , pool [ "" id "" ] ) ] , <TAB> ) : <TAB><TAB> dev = ed [ "" encrypted_provider "" ] <TAB><TAB> try : <TAB><TAB><TAB> self . geli_detach_single ( dev ) <TAB><TAB> except Exception as ee : <TAB><TAB><TAB> self . logger . warn ( str ( ee ) ) <TAB><TAB><TAB> failed + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . geli_clear ( dev ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> self . logger . warn ( "" Failed to clear  %s :  %s "" , dev , e ) <TAB> return failed",if clear :,if clear :,100.0,100.00,True
505,def compute_lengths ( batch_sizes ) : <TAB> tmp_batch_sizes = np . copy ( batch_sizes ) <TAB> lengths = [ ] <TAB> while True : <TAB><TAB> c = np . count_nonzero ( tmp_batch_sizes > 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> lengths . append ( c ) <TAB><TAB> tmp_batch_sizes = np . array ( [ b - 1 for b in tmp_batch_sizes ] ) <TAB> return np . array ( lengths ),if c == 0 :,if c == 0 :,100.0,100.00,True
506,"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB><TAB> <MASK> <TAB><TAB><TAB> flatten_items . append ( b "" "" ) <TAB><TAB> elif isinstance ( item , bytes ) : <TAB><TAB><TAB> flatten_items . append ( item ) <TAB><TAB> elif isinstance ( item , int ) : <TAB><TAB><TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB><TAB> elif isinstance ( item , list ) : <TAB><TAB><TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items )",if item is None :,"if isinstance ( item , str ) :",93.4978830610418,96.13,False
507,"def update ( self , new_config ) : <TAB> jsonschema . validate ( new_config , self . schema ) <TAB> config = { } <TAB> for k , v in new_config . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> config [ k ] = self [ k ] <TAB><TAB> else : <TAB><TAB><TAB> config [ k ] = v <TAB> self . _config = config <TAB> self . changed ( )","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",if k in self :,81.89086398075507,83.89,False
508,"def _encode_numpy ( values , uniques = None , encode = False , check_unknown = True ) : <TAB> # only used in _encode below, see docstring there for details <TAB> if uniques is None : <TAB><TAB> if encode : <TAB><TAB><TAB> uniques , encoded = np . unique ( values , return_inverse = True ) <TAB><TAB><TAB> return uniques , encoded <TAB><TAB> else : <TAB><TAB><TAB> # unique sorts <TAB><TAB><TAB> return np . unique ( values ) <TAB> if encode : <TAB><TAB> <MASK> <TAB><TAB><TAB> diff = _encode_check_unknown ( values , uniques ) <TAB><TAB><TAB> if diff : <TAB><TAB><TAB><TAB> raise ValueError ( "" y contains previously unseen labels:  %s "" % str ( diff ) ) <TAB><TAB> encoded = np . searchsorted ( uniques , values ) <TAB><TAB> return uniques , encoded <TAB> else : <TAB><TAB> return uniques",if check_unknown :,if check_unknown :,100.0,100.00,True
509,"def restore_dtype_and_merge ( arr , input_dtype ) : <TAB> if isinstance ( arr , list ) : <TAB><TAB> arr = [ restore_dtype_and_merge ( arr_i , input_dtype ) for arr_i in arr ] <TAB><TAB> shapes = [ arr_i . shape for arr_i in arr ] <TAB><TAB> <MASK> <TAB><TAB><TAB> arr = np . array ( arr ) <TAB> if ia . is_np_array ( arr ) : <TAB><TAB> arr = iadt . restore_dtypes_ ( arr , input_dtype ) <TAB> return arr",if len ( set ( shapes ) ) == 1 :,if not ia . is_array_like ( arr ) :,67.95417922124962,92.27,False
510,"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB><TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB><TAB> if diff_min is not None and diff_min != 0 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB><TAB><TAB> return True , d <TAB> return False , d",if is_prev :,"if expanded [ 0 ] [ 0 ] == ""*"" :",95.11826030570138,92.47,False
511,"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _populate_dict ( element , k , v ) <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> self . _populate_list ( element , k , v ) <TAB><TAB> elif isinstance ( v , bool ) : <TAB><TAB><TAB> self . _populate_bool ( element , k , v ) <TAB><TAB> elif isinstance ( v , basestring ) : <TAB><TAB><TAB> self . _populate_str ( element , k , v ) <TAB><TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB> self . _populate_number ( element , k , v )","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",75.0,100.00,True
512,"def __createItemAttribute ( self , item , function , preload ) : <TAB> """"""Create the new widget, add it, and remove the old one"""""" <TAB> try : <TAB><TAB> self . __stack . addWidget ( function ( item , preload ) ) <TAB><TAB> # Remove the widget <TAB><TAB> <MASK> <TAB><TAB><TAB> oldWidget = self . __stack . widget ( 0 ) <TAB><TAB><TAB> self . __stack . removeWidget ( oldWidget ) <TAB><TAB><TAB> oldWidget . setParent ( QtWidgets . QWidget ( ) ) <TAB> except Exception as e : <TAB><TAB> list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) )",if self . __stack . count ( ) > 1 :,if self . __stack . widget ( 0 ) . isVisible ( ) :,96.83953371687765,95.22,False
513,"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB><TAB> <MASK> <TAB><TAB><TAB> url = url [ 8 : ] <TAB><TAB> if not url . startswith ( "" http:// "" ) : <TAB><TAB><TAB> url = "" http:// "" + url <TAB><TAB> if playlist : <TAB><TAB><TAB> download_playlist ( <TAB><TAB><TAB><TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only )","if url . startswith ( ""https://"" ) :","if url . startswith ( ""http://"" ) :",98.79683980563735,98.84,False
514,"def add_enc_zero ( obj , enc_zero ) : <TAB> if isinstance ( obj , np . ndarray ) : <TAB><TAB> return obj + enc_zero <TAB> elif isinstance ( obj , Iterable ) : <TAB><TAB> return type ( obj ) ( <TAB><TAB><TAB> EncryptModeCalculator . add_enc_zero ( o , enc_zero ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else o + enc_zero <TAB><TAB><TAB> for o in obj <TAB><TAB> ) <TAB> else : <TAB><TAB> return obj + enc_zero","if isinstance ( o , Iterable )",if not o,68.03205406924435,95.19,False
515,"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB><TAB> w , pos = p <TAB><TAB> if ( w , pos ) in self . composite_dict : <TAB><TAB><TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB> elif w in self . word_dict : <TAB><TAB><TAB> lemma = self . word_dict [ w ] <TAB><TAB> else : <TAB><TAB><TAB> lemma = pred <TAB><TAB> <MASK> <TAB><TAB><TAB> lemma = w <TAB><TAB> lemmas . append ( lemma ) <TAB> return lemmas",if lemma is None :,elif self . _is_label :,74.2581821299884,96.20,False
516,"def replace_to_6hex ( color ) : <TAB> """"""Validate and replace 3hex colors to 6hex ones."""""" <TAB> if match ( r "" ^#(?:[0-9a-fA-F] {3} ) { 1,2}$ "" , color ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> color = "" # {0} {0} {1} {1} {2} {2} "" . format ( color [ 1 ] , color [ 2 ] , color [ 3 ] ) <TAB><TAB> return color <TAB> else : <TAB><TAB> exit ( _ ( "" Invalid color  {} "" ) . format ( color ) )",if len ( color ) == 4 :,if color [ 1 ] != color [ 2 ] :,91.10094888293976,93.17,False
517,"def computeMachineName ( self ) : <TAB> """"""Return the name of the current machine, i.e, HOSTNAME."""""" <TAB> # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB> # to give the machine-specific setting name. <TAB> # How can this be worth doing?? <TAB> try : <TAB><TAB> import os <TAB><TAB> name = os . getenv ( "" HOSTNAME "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> name = os . getenv ( "" COMPUTERNAME "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> import socket <TAB><TAB><TAB> name = socket . gethostname ( ) <TAB> except Exception : <TAB><TAB> name = "" "" <TAB> return name",if not name :,if not name :,100.0,100.00,True
518,"def _git_dirty_working_directory ( q , include_untracked ) : <TAB> try : <TAB><TAB> cmd = [ "" git "" , "" status "" , "" --porcelain "" ] <TAB><TAB> if include_untracked : <TAB><TAB><TAB> cmd + = [ "" --untracked-files=normal "" ] <TAB><TAB> else : <TAB><TAB><TAB> cmd + = [ "" --untracked-files=no "" ] <TAB><TAB> status = _run_git_cmd ( cmd ) <TAB><TAB> <MASK> <TAB><TAB><TAB> q . put ( bool ( status ) ) <TAB><TAB> else : <TAB><TAB><TAB> q . put ( None ) <TAB> except ( subprocess . CalledProcessError , OSError , FileNotFoundError ) : <TAB><TAB> q . put ( None )",if status is not None :,if status :,68.66120101627915,97.68,False
519,"def runAndWaitWork ( server , work ) : <TAB> work . touch ( ) <TAB> thr = threading . Thread ( target = workThread , args = ( server , work ) ) <TAB> thr . setDaemon ( True ) <TAB> thr . start ( ) <TAB> # Wait around for done or timeout <TAB> while True : <TAB><TAB> if work . isTimedOut ( ) : <TAB><TAB><TAB> break <TAB><TAB> # If the thread is done, lets get out. <TAB><TAB> if not thr . isAlive ( ) : <TAB><TAB><TAB> break <TAB><TAB> # If our parent, or some thread closes stdin, <TAB><TAB> # time to pack up and go. <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( 2 )",if sys . stdin . closed :,if thr . isAlive ( ) :,97.50625946897262,96.84,False
520,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB><TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB><TAB> if DEBUG_COMM : <TAB><TAB><TAB> log . info ( <TAB><TAB><TAB><TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB> ) <TAB><TAB> if ignore_timeouts and is_timeout ( e ) : <TAB><TAB><TAB> return [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ ] <TAB><TAB> raise",if ignore_non_errors and is_noerr ( e ) :,if ignore_non_errors and is_non_errors ( e ) :,98.90137729082613,98.05,False
521,"def PrintHeader ( self ) : # print the header array <TAB> if self . draw == False : <TAB><TAB> return <TAB> for val in self . parent . header : <TAB><TAB> self . SetPrintFont ( val [ "" Font "" ] ) <TAB><TAB> header_indent = val [ "" Indent "" ] * self . pwidth <TAB><TAB> text = val [ "" Text "" ] <TAB><TAB> htype = val [ "" Type "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> addtext = self . GetDate ( ) <TAB><TAB> elif htype == "" Date & Time "" : <TAB><TAB><TAB> addtext = self . GetDateTime ( ) <TAB><TAB> else : <TAB><TAB><TAB> addtext = "" "" <TAB><TAB> self . OutTextPageWidth ( <TAB><TAB><TAB> text + addtext , self . pheader_margin , val [ "" Align "" ] , header_indent , True <TAB><TAB> )","if htype == ""Date"" :","if htype == ""Date & Time"" :",73.75280539597475,98.52,False
522,"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB><TAB> if result is None : <TAB><TAB><TAB> result = parts <TAB><TAB> else : <TAB><TAB><TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB><TAB> return None <TAB> elif len ( result ) == 1 : <TAB><TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB><TAB> solids = [ p . item for p in result ] <TAB><TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> solid = solid . removeSplitter ( ) <TAB><TAB> return solid",if refine :,if refine :,100.0,100.00,True
523,"def captured_updateNode ( self , context ) : <TAB> if not self . updating_name_from_pointer : <TAB><TAB> font_datablock = self . get_bpy_data_from_name ( self . fontname , bpy . data . fonts ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . font_pointer = font_datablock <TAB><TAB><TAB> updateNode ( self , context )",if font_datablock :,if font_datablock :,100.0,100.00,True
524,"def __add__ ( self , other ) : <TAB> if isinstance ( other , Vector2 ) : <TAB><TAB> # Vector + Vector -> Vector <TAB><TAB> # Vector + Point -> Point <TAB><TAB> # Point + Point -> Vector <TAB><TAB> <MASK> <TAB><TAB><TAB> _class = Vector2 <TAB><TAB> else : <TAB><TAB><TAB> _class = Point2 <TAB><TAB> return _class ( self . x + other . x , self . y + other . y ) <TAB> else : <TAB><TAB> assert hasattr ( other , "" __len__ "" ) and len ( other ) == 2 <TAB><TAB> return Vector2 ( self . x + other [ 0 ] , self . y + other [ 1 ] )",if self . __class__ is other . __class__ :,if self . __len__ == 1 :,97.184490651071,94.18,False
525,"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB><TAB> <MASK> <TAB><TAB><TAB> setting_values . update ( <TAB><TAB><TAB><TAB> self . _flatten_settings_from_form ( <TAB><TAB><TAB><TAB><TAB> settings , field , form_values [ field . _name ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> elif field . _name in settings : <TAB><TAB><TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values","if isinstance ( field , _ContainerMixin ) :",if field . _name in form_values :,94.03582971444673,95.80,False
526,"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB><TAB> # FIXME same hack, forcibly unpack from holder. <TAB><TAB> if hasattr ( a , "" includedirs "" ) : <TAB><TAB><TAB> a = a . includedirs <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidArguments ( <TAB><TAB><TAB><TAB> "" Include directory to be added is not an include directory object. "" <TAB><TAB><TAB> ) <TAB><TAB> ids . append ( a ) <TAB> self . include_dirs + = ids","if not isinstance ( a , IncludeDirs ) :","if not isinstance ( a , ( Directory , File ) ) :",97.5183871736649,95.97,False
527,"def _clip_array ( array , config ) : <TAB> if "" threshold "" in config . keys ( ) : <TAB><TAB> threshold = config [ "" threshold "" ] <TAB> else : <TAB><TAB> abs_array = np . max ( np . abs ( array ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return array <TAB><TAB> threshold = np . percentile ( np . abs ( array ) , 99.99 ) <TAB> return np . clip ( array , - threshold , threshold )",if abs_array < 1.0 :,if abs_array < 0.5 :,98.48858082333533,97.96,False
528,def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield from dfs ( w ) <TAB><TAB> elif w not in identified : <TAB><TAB><TAB> while index [ w ] < boundaries [ - 1 ] : <TAB><TAB><TAB><TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB><TAB> boundaries . pop ( ) <TAB><TAB> scc = set ( stack [ index [ v ] : ] ) <TAB><TAB> del stack [ index [ v ] : ] <TAB><TAB> identified . update ( scc ) <TAB><TAB> yield scc,if w not in index :,"if isinstance ( w , ( list , tuple ) ) :",95.74897037166495,94.96,False
529,"def create_balancer ( <TAB> self , name , members , protocol = "" http "" , port = 80 , algorithm = DEFAULT_ALGORITHM ) : <TAB> balancer = self . ex_create_balancer_nowait ( name , members , protocol , port , algorithm ) <TAB> timeout = 60 * 20 <TAB> waittime = 0 <TAB> interval = 2 * 15 <TAB> if balancer . id is not None : <TAB><TAB> return balancer <TAB> else : <TAB><TAB> while waittime < timeout : <TAB><TAB><TAB> balancers = self . list_balancers ( ) <TAB><TAB><TAB> for i in balancers : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return i <TAB><TAB><TAB> waittime + = interval <TAB><TAB><TAB> time . sleep ( interval ) <TAB> raise Exception ( "" Failed to get id "" )",if i . name == balancer . name and i . id is not None :,if i . id is not None :,72.25548212749173,95.94,False
530,"def handle ( self , scope : Scope , receive : Receive , send : Send ) - > None : <TAB> if self . methods and scope [ "" method "" ] not in self . methods : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise HTTPException ( status_code = 405 ) <TAB><TAB> else : <TAB><TAB><TAB> response = PlainTextResponse ( "" Method Not Allowed "" , status_code = 405 ) <TAB><TAB> await response ( scope , receive , send ) <TAB> else : <TAB><TAB> await self . app ( scope , receive , send )","if ""app"" in scope :","if scope [ ""method"" ] not in self . methods :",94.43867420760604,92.12,False
531,"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB><TAB> # noinspection PyCompatibility <TAB><TAB> if isinstance ( d , tuple ) and len ( d ) == 2 : <TAB><TAB><TAB> result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( d ) <TAB> return result","elif isinstance ( d , basestring ) :","elif isinstance ( d , ( list , tuple ) ) :",97.0590668216569,94.36,False
532,"def register_adapters ( ) : <TAB> global adapters_registered <TAB> if adapters_registered is True : <TAB><TAB> return <TAB> try : <TAB><TAB> import pkg_resources <TAB><TAB> packageDir = pkg_resources . resource_filename ( "" pyamf "" , "" adapters "" ) <TAB> except : <TAB><TAB> packageDir = os . path . dirname ( __file__ ) <TAB> for f in glob . glob ( os . path . join ( packageDir , "" *.py "" ) ) : <TAB><TAB> mod = os . path . basename ( f ) . split ( os . path . extsep , 1 ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> register_adapter ( mod [ 1 : ] . replace ( "" _ "" , "" . "" ) , PackageImporter ( mod ) ) <TAB><TAB> except ImportError : <TAB><TAB><TAB> pass <TAB> adapters_registered = True","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :","if mod [ 0 ] == ""."" :",67.50982319639061,92.74,False
533,"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB><TAB> print ( loading_message ) <TAB> for name in to_load : <TAB><TAB> module = load ( name ) <TAB><TAB> if module is None or not hasattr ( module , attr ) : <TAB><TAB><TAB> continue <TAB><TAB> cls = getattr ( module , attr ) <TAB><TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB> continue <TAB><TAB> if hasattr ( module , "" aliases "" ) : <TAB><TAB><TAB> for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> modules_dict [ alias ] = module <TAB><TAB> else : <TAB><TAB><TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB><TAB> print ( )",if alias not in excluded_aliases :,if alias in excluded_aliases :,98.99730753025956,99.06,False
534,"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB><TAB> if item . has_variations : <TAB><TAB><TAB> if not any ( var . item == item for var in variations ) : <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( <TAB><TAB><TAB><TAB><TAB><TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> )",if event != item . event :,"if not isinstance ( item , Event ) :",91.88572482884527,95.82,False
535,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> return element <TAB><TAB> if element [ 3 ] and element [ 4 ] : <TAB><TAB><TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB> if not isinstance ( i , int ) : <TAB><TAB><TAB><TAB> return i <TAB><TAB><TAB> idx = i <TAB><TAB> else : <TAB><TAB><TAB> idx + = 1 <TAB> return idx",if idx == num :,"if not isinstance ( element , str ) :",92.1400859817374,95.26,False
536,"def check ( chip , xeddb , chipdb ) : <TAB> all_inst = [ ] <TAB> undoc = [ ] <TAB> for inst in xeddb . recs : <TAB><TAB> <MASK> <TAB><TAB><TAB> if inst . undocumented : <TAB><TAB><TAB><TAB> undoc . append ( inst ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> all_inst . append ( inst ) <TAB> return ( all_inst , undoc )",if inst . isa_set in chipdb [ chip ] :,if inst . name == chipdb . name :,91.6689684178554,92.67,False
537,"def get_all_topic_src_files ( self ) : <TAB> """"""Retrieves the file paths of all the topics in directory"""""" <TAB> topic_full_paths = [ ] <TAB> topic_names = os . listdir ( self . topic_dir ) <TAB> for topic_name in topic_names : <TAB><TAB> # Do not try to load hidden files. <TAB><TAB> <MASK> <TAB><TAB><TAB> topic_full_path = os . path . join ( self . topic_dir , topic_name ) <TAB><TAB><TAB> # Ignore the JSON Index as it is stored with topic files. <TAB><TAB><TAB> if topic_full_path != self . index_file : <TAB><TAB><TAB><TAB> topic_full_paths . append ( topic_full_path ) <TAB> return topic_full_paths","if not topic_name . startswith ( ""."" ) :",if not os . path . isdir ( self . topic_dir ) :,96.22831432023537,94.95,False
538,"def _get_element ( dom_msi , tag_name , name = None , id_ = None ) : <TAB> """"""Get a xml element defined on Product."""""" <TAB> product = dom_msi . getElementsByTagName ( "" Product "" ) [ 0 ] <TAB> elements = product . getElementsByTagName ( tag_name ) <TAB> for element in elements : <TAB><TAB> <MASK> <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> element . getAttribute ( "" Name "" ) == name <TAB><TAB><TAB><TAB> and element . getAttribute ( "" Id "" ) == id_ <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> return element <TAB><TAB> elif id_ : <TAB><TAB><TAB> if element . getAttribute ( "" Id "" ) == id_ : <TAB><TAB><TAB><TAB> return element",if name and id_ :,if name :,96.77305786750874,97.96,False
539,"def __init__ ( self , * models ) : <TAB> super ( ) . __init__ ( ) <TAB> self . models = ModuleList ( models ) <TAB> for m in models : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs) "" <TAB><TAB><TAB> ) <TAB> self . likelihood = LikelihoodList ( * [ m . likelihood for m in models ] )","if not hasattr ( m , ""likelihood"" ) :","if not isinstance ( m , LikelihoodList ) :",74.0708853669882,94.73,False
540,"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB><TAB> with open ( filename , "" rb "" ) as fileobj : <TAB><TAB><TAB> header = fileobj . read ( 4 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> fileobj . read ( 1 ) # skip the version number <TAB><TAB><TAB><TAB> ftype = fileobj . read ( 1 ) <TAB><TAB><TAB><TAB> if binascii . hexlify ( ftype ) == oxlitype : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB> return False <TAB> except OSError : <TAB><TAB> return False","if header == b""OXLI"" :","if header == ""version"" :",98.49821474968905,97.50,False
541,"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB><TAB> key = str ( k ) <TAB><TAB> if "" / "" not in key : <TAB><TAB><TAB> key + = "" /tcp "" <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB><TAB> else : <TAB><TAB><TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result","if isinstance ( v , list ) :","if isinstance ( v , list ) :",100.0,100.00,True
542,"def input_data ( self ) : <TAB> gen = self . config . generator <TAB> # don't try running the generator if we specify an output file explicitly, <TAB> # otherwise generator may segfault and we end up returning the output file anyway <TAB> if gen and ( not self . config [ "" out "" ] or not self . config [ "" in "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _run_generator ( gen , args = self . config . generator_args ) <TAB><TAB> if self . _generated [ 0 ] : <TAB><TAB><TAB> return self . _generated [ 0 ] <TAB> # in file is optional <TAB> return ( <TAB><TAB> self . _normalize ( self . problem . problem_data [ self . config [ "" in "" ] ] ) <TAB><TAB> if self . config [ "" in "" ] <TAB><TAB> else b "" "" <TAB> )",if self . _generated is None :,"if self . config [ ""out"" ] :",98.22195022827209,96.67,False
543,"def __new__ ( cls , * tasks , * * kwargs ) : <TAB> # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB> if not kwargs and tasks : <TAB><TAB> <MASK> <TAB><TAB><TAB> tasks = tasks [ 0 ] if len ( tasks ) == 1 else tasks <TAB><TAB><TAB> return reduce ( operator . or_ , tasks ) <TAB> return super ( chain , cls ) . __new__ ( cls , * tasks , * * kwargs )",if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,"if isinstance ( tasks , tuple ) :",68.05214154000639,88.51,False
544,"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB><TAB> from galaxy . files import ConfiguredFileSources <TAB><TAB> file_sources = None <TAB><TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB><TAB><TAB> file_sources_as_dict = None <TAB><TAB><TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB> if file_sources_as_dict is not None : <TAB><TAB><TAB><TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources is None :,if file_sources is None :,100.0,100.00,True
545,"def InitializeColours ( self ) : <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB><TAB> c = self . _colourData . GetCustomColour ( i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB><TAB> else : <TAB><TAB><TAB> self . _customColours [ i ] = wx . WHITE <TAB><TAB> if c == curr : <TAB><TAB><TAB> self . _colourSelection = i",if c . IsOk ( ) :,if c == curr :,72.54636579120097,96.79,False
546,"def convert_obj_into_marshallable ( self , obj ) : <TAB> if isinstance ( obj , self . marshalable_types ) : <TAB><TAB> return obj <TAB> if isinstance ( obj , array . array ) : <TAB><TAB> if obj . typecode == "" c "" : <TAB><TAB><TAB> return obj . tostring ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return obj . tounicode ( ) <TAB><TAB> return obj . tolist ( ) <TAB> return self . class_to_dict ( obj )","if obj . typecode == ""u"" :","if obj . typecode == ""b"" :",73.41707224345947,98.16,False
547,"def run ( self ) : <TAB> self . run_command ( "" egg_info "" ) <TAB> from glob import glob <TAB> for pattern in self . match : <TAB><TAB> pattern = self . distribution . get_name ( ) + "" * "" + pattern <TAB><TAB> files = glob ( os . path . join ( self . dist_dir , pattern ) ) <TAB><TAB> files = [ ( os . path . getmtime ( f ) , f ) for f in files ] <TAB><TAB> files . sort ( ) <TAB><TAB> files . reverse ( ) <TAB><TAB> log . info ( "" %d  file(s) matching  %s "" , len ( files ) , pattern ) <TAB><TAB> files = files [ self . keep : ] <TAB><TAB> for ( t , f ) in files : <TAB><TAB><TAB> log . info ( "" Deleting  %s "" , f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . unlink ( f )",if not self . dry_run :,if os . path . exists ( f ) :,75.79176859064219,96.29,False
548,"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB><TAB> if token . token_type == TOKEN_TEXT : <TAB><TAB><TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars",elif token . token_type == TOKEN_VAR :,elif token . token_type == TOKEN_VAR :,100.0,100.00,True
549,"def _handle_raise ( self , values , is_NAs , origins ) : <TAB> for is_NA , origin in zip ( is_NAs , origins ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = ( <TAB><TAB><TAB><TAB> "" Missing values detected. If you want rows with missing  "" <TAB><TAB><TAB><TAB> "" values to be automatically deleted in a list-wise  "" <TAB><TAB><TAB><TAB> "" manner (not recommended), please set dropna=True in  "" <TAB><TAB><TAB><TAB> "" the Bambi Model initialization. "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> raise PatsyError ( msg , origin ) <TAB> return values",if np . any ( is_NA ) :,if not is_NA and not values :,90.5731017422502,95.65,False
550,"def add_node_data ( node_array , ntwk ) : <TAB> node_ntwk = nx . Graph ( ) <TAB> newdata = { } <TAB> for idx , data in ntwk . nodes ( data = True ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> newdata [ "" value "" ] = node_array [ int ( idx ) - 1 ] <TAB><TAB><TAB> data . update ( newdata ) <TAB><TAB><TAB> node_ntwk . add_node ( int ( idx ) , * * data ) <TAB> return node_ntwk",if not int ( idx ) == 0 :,if idx > 0 and node_array [ int ( idx ) - 1 ] == 0 :,76.59217164527018,90.61,False
551,"def safe_parse_date ( date_hdr ) : <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try : <TAB><TAB> if "" ; "" in date_hdr : <TAB><TAB><TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB><TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> else : <TAB><TAB><TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB><TAB> return None",if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,if msg_ts < 0 :,58.537686150496825,87.46,False
552,"def _route_db ( self , model , * * hints ) : <TAB> chosen_db = None <TAB> for router in self . routers : <TAB><TAB> try : <TAB><TAB><TAB> method = getattr ( router , action ) <TAB><TAB> except AttributeError : <TAB><TAB><TAB> # If the router doesn't have a method, skip to the next one. <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> chosen_db = method ( model , * * hints ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return chosen_db <TAB> try : <TAB><TAB> return hints [ "" instance "" ] . _state . db or DEFAULT_DB_ALIAS <TAB> except KeyError : <TAB><TAB> return DEFAULT_DB_ALIAS",if chosen_db :,if chosen_db :,100.0,100.00,True
553,"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB><TAB> if not ignore_first_level : <TAB><TAB><TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB><TAB><TAB> res . extend ( keys ) <TAB><TAB> for key in struct : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB><TAB> for item in struct : <TAB><TAB><TAB> res . extend ( get_keys ( item ) ) <TAB> return res",if key in IGNORED_KEYS :,if key in IGNORED_FIRST_LEVEL :,99.09382887217242,98.17,False
554,"def launch_app ( self , fs_id ) : <TAB> if fs_id in self . app_infos : <TAB><TAB> row = self . get_row_by_fsid ( fs_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> app_info = self . app_infos [ fs_id ] <TAB><TAB> filepath = os . path . join ( row [ SAVEDIR_COL ] , row [ SAVENAME_COL ] ) <TAB><TAB> gfile = Gio . File . new_for_path ( filepath ) <TAB><TAB> app_info . launch ( <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> gfile , <TAB><TAB><TAB> ] , <TAB><TAB><TAB> None , <TAB><TAB> ) <TAB><TAB> self . app_infos . pop ( fs_id , None )",if not row :,if not row :,100.0,100.00,True
555,"def create_skipfile ( files_changed , skipfile ) : <TAB> # File is likely to contain some garbage values at start, <TAB> # only the corresponding json should be parsed. <TAB> json_pattern = re . compile ( r "" ^ \ { .* \ } "" ) <TAB> for line in files_changed . readlines ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for filename in json . loads ( line ) : <TAB><TAB><TAB><TAB> if "" /COMMIT_MSG "" in filename : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> skipfile . write ( "" +*/ %s \n "" % filename ) <TAB> skipfile . write ( "" -* \n "" )","if re . match ( json_pattern , line ) :",if json_pattern . search ( line ) :,71.94074479066784,96.04,False
556,"def zscore ( self , client , request , N ) : <TAB> check_input ( request , N != 2 ) <TAB> key = request [ 1 ] <TAB> db = client . db <TAB> value = db . get ( key ) <TAB> if value is None : <TAB><TAB> client . reply_bulk ( None ) <TAB> elif not isinstance ( value , self . zset_type ) : <TAB><TAB> client . reply_wrongtype ( ) <TAB> else : <TAB><TAB> score = value . score ( request [ 2 ] , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> score = str ( score ) . encode ( "" utf-8 "" ) <TAB><TAB> client . reply_bulk ( score )",if score is not None :,"if not isinstance ( score , str ) :",79.2699957190427,95.51,False
557,"def _list_cases ( suite ) : <TAB> for test in suite : <TAB><TAB> if isinstance ( test , unittest . TestSuite ) : <TAB><TAB><TAB> _list_cases ( test ) <TAB><TAB> elif isinstance ( test , unittest . TestCase ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> print ( test . id ( ) )",if support . match_test ( test ) :,if test . id ( ) :,67.39351527525054,92.39,False
558,"def Run ( self ) : <TAB> """"""The main run method of the client."""""" <TAB> for thread in self . _threads . values ( ) : <TAB><TAB> thread . start ( ) <TAB> logging . info ( START_STRING ) <TAB> while True : <TAB><TAB> dead_threads = [ tn for ( tn , t ) in self . _threads . items ( ) if not t . isAlive ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise FatalError ( <TAB><TAB><TAB><TAB> "" These threads are dead:  %r . Shutting down... "" % dead_threads <TAB><TAB><TAB> ) <TAB><TAB> time . sleep ( 10 )",if dead_threads :,if dead_threads :,100.0,100.00,True
559,"def _slice_queryset ( queryset , order_by , per_page , start ) : <TAB> page_len = int ( per_page ) + 1 <TAB> if start : <TAB><TAB> <MASK> <TAB><TAB><TAB> filter_name = "" %s __lte "" % order_by [ 1 : ] <TAB><TAB> else : <TAB><TAB><TAB> filter_name = "" %s __gte "" % order_by <TAB><TAB> return queryset . filter ( * * { filter_name : start } ) [ : page_len ] <TAB> return queryset [ : page_len ]","if order_by . startswith ( ""-"" ) :","if order_by [ 0 ] == ""lte"" :",93.66639968291787,94.20,False
560,"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB><TAB> for _ in XRANGE ( 10 ) : <TAB><TAB><TAB> t1 = timer ( ) <TAB><TAB><TAB> t2 = timer ( ) <TAB><TAB><TAB> dt = t2 - t1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> dt = t2 - previous <TAB><TAB><TAB> if dt < = 0.0 : <TAB><TAB><TAB><TAB> continue <TAB><TAB> if precision is not None : <TAB><TAB><TAB> precision = min ( precision , dt ) <TAB><TAB> else : <TAB><TAB><TAB> precision = dt <TAB><TAB> points + = 1 <TAB><TAB> previous = timer ( ) <TAB> return precision",if 0 < dt :,if dt <= 0.0 :,77.00823713785769,98.11,False
561,"def findWorkingDir ( ) : <TAB> frozen = getattr ( sys , "" frozen "" , "" "" ) <TAB> if not frozen : <TAB><TAB> path = os . path . dirname ( __file__ ) <TAB> elif frozen in ( "" dll "" , "" console_exe "" , "" windows_exe "" , "" macosx_app "" ) : <TAB><TAB> path = os . path . dirname ( <TAB><TAB><TAB> os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) ) <TAB><TAB> ) <TAB> elif frozen : # needed for PyInstaller <TAB><TAB> <MASK> <TAB><TAB><TAB> path = getattr ( sys , "" _MEIPASS "" , "" "" ) # --onefile <TAB><TAB> else : <TAB><TAB><TAB> path = os . path . dirname ( sys . executable ) # --onedir <TAB> else : <TAB><TAB> path = "" "" <TAB> return path","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :","if hasattr ( sys , ""_MEIPASS"" ) :",96.58026601054944,95.63,False
562,"def CreateDataType ( vmodlName , wsdlName , parent , version , props ) : <TAB> with _lazyLock : <TAB><TAB> dic = [ vmodlName , wsdlName , parent , version , props ] <TAB><TAB> names = vmodlName . split ( "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> vmodlName = "" . "" . join ( name [ 0 ] . lower ( ) + name [ 1 : ] for name in names ) <TAB><TAB> _AddToDependencyMap ( names ) <TAB><TAB> typeNs = GetWsdlNamespace ( version ) <TAB><TAB> _dataDefMap [ vmodlName ] = dic <TAB><TAB> _wsdlDefMap [ ( typeNs , wsdlName ) ] = dic <TAB><TAB> _wsdlTypeMapNSs . add ( typeNs )",if _allowCapitalizedNames :,if len ( names ) > 1 :,85.0270420372902,95.59,False
563,"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB><TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB><TAB><TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB> if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB><TAB><TAB> homedir = response . pathspec . path <TAB><TAB><TAB> username = os . path . basename ( homedir ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield rdf_client . User ( username = username , homedir = homedir )",if username not in self . _ignore_users :,if username :,97.37798789284328,95.87,False
564,"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB><TAB> if letter == "" < "" : <TAB><TAB><TAB> skip = True <TAB><TAB> if letter == "" > "" : <TAB><TAB><TAB> skip = False <TAB><TAB> if skip : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> if letter == ""   "" : <TAB><TAB><TAB><TAB> letter = "" _ "" <TAB><TAB><TAB> question + = letter . lower ( ) <TAB> return question","if letter . isalnum ( ) or letter == "" "" :",if not skip :,82.21188813080674,92.66,False
565,"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB><TAB> for line in lines : <TAB><TAB><TAB> if gap : <TAB><TAB><TAB><TAB> self . write ( "" "" ) <TAB><TAB><TAB> self . process ( line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> gap = True <TAB> return 0",if not is_command ( line ) :,if len ( line ) > times :,90.35597047823433,94.35,False
566,"def _get ( self , domain ) : <TAB> with self . lock : <TAB><TAB> try : <TAB><TAB><TAB> record = self . cache [ domain ] <TAB><TAB><TAB> time_now = time . time ( ) <TAB><TAB><TAB> if time_now - record [ "" update "" ] > self . ttl : <TAB><TAB><TAB><TAB> record = None <TAB><TAB> except KeyError : <TAB><TAB><TAB> record = None <TAB><TAB> <MASK> <TAB><TAB><TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB><TAB> # self.cache[domain] = record <TAB><TAB> return record",if not record :,if record is None :,96.8015618537272,97.81,False
567,"def gen_constant_folding ( cw ) : <TAB> types = [ "" Int32 "" , "" Double "" , "" BigInteger "" , "" Complex "" ] <TAB> for cur_type in types : <TAB><TAB> cw . enter_block ( "" if (constLeft.Value.GetType() == typeof( %s )) "" % ( cur_type , ) ) <TAB><TAB> cw . enter_block ( "" switch (_op) "" ) <TAB><TAB> for op in ops : <TAB><TAB><TAB> gen = getattr ( op , "" genConstantFolding "" , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> gen ( cw , cur_type ) <TAB><TAB> cw . exit_block ( ) <TAB><TAB> cw . exit_block ( )",if gen is not None :,if gen is not None :,100.0,100.00,True
568,"def unreferenced_dummy ( self ) : <TAB> for g , base in zip ( self . evgroups , self . evbases ) : <TAB><TAB> for ind , j in enumerate ( g ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> debug_print ( <TAB><TAB><TAB><TAB><TAB> "" replacing unreferenced  %d   %s  with dummy "" % ( ( base + ind ) , g [ ind ] ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> g [ ind ] = "" dummy "" <TAB><TAB><TAB><TAB> self . evnum [ base + ind ] = "" dummy """,if not self . indexobj [ base + ind ] :,if j . dummy :,88.10793735651858,94.02,False
569,"def handle_signature ( self , sig : str , signode : desc_signature ) - > Tuple [ str , str ] : <TAB> for cls in self . __class__ . __mro__ : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" PyDecoratorMixin is deprecated.  "" <TAB><TAB><TAB><TAB> "" Please check the implementation of  %s "" % cls , <TAB><TAB><TAB><TAB> RemovedInSphinx50Warning , <TAB><TAB><TAB><TAB> stacklevel = 2 , <TAB><TAB><TAB> ) <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> warnings . warn ( <TAB><TAB><TAB> "" PyDecoratorMixin is deprecated "" , RemovedInSphinx50Warning , stacklevel = 2 <TAB><TAB> ) <TAB> ret = super ( ) . handle_signature ( sig , signode ) # type: ignore <TAB> signode . insert ( 0 , addnodes . desc_addname ( "" @ "" , "" @ "" ) ) <TAB> return ret","if cls . __name__ != ""DirectiveAdapter"" :","if cls . __name__ == ""PyDecoratorMixin"" :",98.71246359525743,98.18,False
570,"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB><TAB> path . responses . append ( response ) <TAB><TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB><TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> n + = 1 <TAB><TAB> if n > max_next : <TAB><TAB><TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB><TAB><TAB> break <TAB><TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB><TAB> response = requests . get ( src , stream = True )",if not src :,if not src :,100.0,100.00,True
571,"def ordered_indices ( self ) : <TAB> with data_utils . numpy_seed ( self . seed , self . epoch ) : <TAB><TAB> # Used to store the order of indices of each dataset to use <TAB><TAB> indices = [ <TAB><TAB><TAB> np . random . permutation ( len ( dataset ) ) for dataset in self . datasets . values ( ) <TAB><TAB> ] <TAB><TAB> # Keep track of which samples we've  used for each dataset <TAB><TAB> counters = [ 0 for _ in self . datasets ] <TAB><TAB> sampled_indices = [ <TAB><TAB><TAB> self . _sample ( indices , counters ) for _ in range ( self . total_num_instances ) <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> sampled_indices . sort ( key = lambda i : self . num_tokens ( i ) ) <TAB><TAB> return np . array ( sampled_indices , dtype = np . int64 )",if self . sort_indices :,if self . num_tokens :,99.1524900051899,98.21,False
572,"def _build_columns ( self ) : <TAB> self . columns = [ Column ( ) for col in self . keys ] <TAB> for row in self : <TAB><TAB> for ( col_idx , col_val ) in enumerate ( row ) : <TAB><TAB><TAB> col = self . columns [ col_idx ] <TAB><TAB><TAB> col . append ( col_val ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> col . is_quantity = False <TAB> for ( idx , key_name ) in enumerate ( self . keys ) : <TAB><TAB> self . columns [ idx ] . name = key_name <TAB> self . x = Column ( ) <TAB> self . ys = [ ]",if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,if col . is_quantity :,65.21783325765178,89.75,False
573,"def tearDown ( self ) : <TAB> subprocess_list = self . subprocess_list <TAB> processes = subprocess_list . processes <TAB> self . schedule . reset ( ) <TAB> del self . schedule <TAB> for proc in processes : <TAB><TAB> <MASK> <TAB><TAB><TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = True ) <TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB><TAB> for proc in processes : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = False ) <TAB><TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB><TAB> log . warning ( "" Processes left running:  %s "" , processes )",if proc . is_alive ( ) :,if proc . pid :,94.84827012664587,94.36,False
574,"def colorNetwork ( cls , network , nodesInNetwork , nodeByID = None ) : <TAB> for node in nodesInNetwork : <TAB><TAB> node . use_custom_color = True <TAB><TAB> neededCopies = sum ( socket . execution . neededCopies for socket in node . outputs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> color = ( 0.7 , 0.9 , 0.7 ) <TAB><TAB> else : <TAB><TAB><TAB> color = ( 1.0 , 0.3 , 0.3 ) <TAB><TAB> node . color = color",if neededCopies == 0 :,if neededCopies == 0 :,100.0,100.00,True
575,"def _init_warmup_scheduler ( self , optimizer , states ) : <TAB> updates_so_far = states . get ( "" number_training_updates "" , 0 ) <TAB> if self . warmup_updates > 0 and ( <TAB><TAB> updates_so_far < = self . warmup_updates or self . hard_reset <TAB> ) : <TAB><TAB> self . warmup_scheduler = optim . lr_scheduler . LambdaLR ( optimizer , self . _warmup_lr ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . warmup_scheduler . load_state_dict ( states [ "" warmup_scheduler "" ] ) <TAB> else : <TAB><TAB> self . warmup_scheduler = None","if states . get ( ""warmup_scheduler"" ) :","if ""warmup_scheduler"" in states :",76.23049639936065,95.51,False
576,"def inner ( self , * iargs , * * ikwargs ) : <TAB> try : <TAB><TAB> return getattr ( super ( VEXResilienceMixin , self ) , func ) ( * iargs , * * ikwargs ) <TAB> except excs as e : <TAB><TAB> for exc , handler in zip ( excs , handlers ) : <TAB><TAB><TAB> if isinstance ( e , exc ) : <TAB><TAB><TAB><TAB> v = getattr ( self , handler ) ( * iargs , * * ikwargs ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB><TAB> return v <TAB><TAB> assert False , "" this should be unreachable if Python is working correctly """,if v is raiseme :,if v is None :,96.75555216707177,98.61,False
577,"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB><TAB> if data [ "" items "" ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . context [ "" total "" ] = len ( data ) <TAB><TAB><TAB><TAB> return data <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB><TAB> else : <TAB><TAB><TAB> self . context [ "" total "" ] = 0 <TAB><TAB><TAB> data = { "" items "" : [ ] } <TAB><TAB> return data [ "" items "" ] <TAB> return data","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :","if data [ ""total"" ] == 0 :",88.18698013122828,92.70,False
578,"def __subclasscheck__ ( self , cls ) : <TAB> if self . __origin__ is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> "" Parameterized generics cannot be used with class  "" "" or instance checks "" <TAB><TAB><TAB> ) <TAB><TAB> return False <TAB> if self is Generic : <TAB><TAB> raise TypeError ( <TAB><TAB><TAB> "" Class  %r  cannot be used with class  "" "" or instance checks "" % self <TAB><TAB> ) <TAB> return super ( ) . __subclasscheck__ ( cls )","if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",if self . __origin__ is not Generic :,61.97329130479792,83.22,False
579,"def __init__ ( self , pyversions , coverage_service ) : <TAB> build_matrix = "" "" <TAB> for version in pyversions : <TAB><TAB> build_matrix + = "" \n      {} , "" . format ( <TAB><TAB><TAB> version <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else "" py {} "" . format ( "" "" . join ( version . split ( "" . "" ) ) ) <TAB><TAB> ) <TAB> coverage_package = "" "" <TAB> if coverage_service : <TAB><TAB> coverage_package + = "" \n      {} "" . format ( coverage_service . package ) <TAB> coverage_package + = "" \n "" <TAB> super ( Tox , self ) . __init__ ( <TAB><TAB> "" tox.ini "" , <TAB><TAB> TEMPLATE . format ( build_matrix = build_matrix , coverage_package = coverage_package ) , <TAB> )","if version . startswith ( ""pypy"" )","if not version . startswith ( ""py"" )",97.27485017196659,97.87,False
580,"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB><TAB> try : <TAB><TAB><TAB> tasks = self . tasks . tasks # is a group <TAB><TAB> except AttributeError : <TAB><TAB><TAB> tasks = self . tasks <TAB><TAB> if len ( tasks ) : <TAB><TAB><TAB> app = tasks [ 0 ] . _app <TAB><TAB> <MASK> <TAB><TAB><TAB> app = body . _app <TAB> return app if app is not None else current_app",if app is None and body is not None :,elif body is not None :,95.91579072423941,95.78,False
581,"def logic ( ) : <TAB> for v in [ True , False , None , 0 , True , None , None , 1 ] : <TAB><TAB> yield clk . posedge <TAB><TAB> xd . next = v <TAB><TAB> <MASK> <TAB><TAB><TAB> yd . next = zd . next = None <TAB><TAB> elif v : <TAB><TAB><TAB> yd . next = zd . next = 11 <TAB><TAB> else : <TAB><TAB><TAB> yd . next = zd . next = 0",if v is None :,if v is None :,100.0,100.00,True
582,"def run ( self ) : <TAB> eid = self . start_episode ( ) <TAB> obs = self . env . reset ( ) <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> action = self . env . action_space . sample ( ) <TAB><TAB><TAB> self . log_action ( eid , obs , action ) <TAB><TAB> else : <TAB><TAB><TAB> action = self . get_action ( eid , obs ) <TAB><TAB> obs , reward , done , info = self . env . step ( action ) <TAB><TAB> self . log_returns ( eid , reward , info = info ) <TAB><TAB> if done : <TAB><TAB><TAB> self . end_episode ( eid , obs ) <TAB><TAB><TAB> obs = self . env . reset ( ) <TAB><TAB><TAB> eid = self . start_episode ( )",if random . random ( ) < self . off_pol_frac :,if self . env . action_space :,94.04178323701342,94.30,False
583,"def tearDown ( self ) : <TAB> os . chdir ( self . orig_working_dir ) <TAB> sys . argv = self . orig_argv <TAB> sys . stdout = self . orig_stdout <TAB> sys . stderr = self . orig_stderr <TAB> for dirname in [ "" lv_LV "" , "" ja_JP "" ] : <TAB><TAB> locale_dir = os . path . join ( self . datadir , "" project "" , "" i18n "" , dirname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shutil . rmtree ( locale_dir )",if os . path . isdir ( locale_dir ) :,if os . path . exists ( locale_dir ) :,98.64668455895446,98.21,False
584,"def sentry_set_scope ( process_context , entity , project , email = None , url = None ) : <TAB> # Using GLOBAL_HUB means these tags will persist between threads. <TAB> # Normally there is one hub per thread. <TAB> with sentry_sdk . hub . GLOBAL_HUB . configure_scope ( ) as scope : <TAB><TAB> scope . set_tag ( "" process_context "" , process_context ) <TAB><TAB> scope . set_tag ( "" entity "" , entity ) <TAB><TAB> scope . set_tag ( "" project "" , project ) <TAB><TAB> <MASK> <TAB><TAB><TAB> scope . user = { "" email "" : email } <TAB><TAB> if url : <TAB><TAB><TAB> scope . set_tag ( "" url "" , url )",if email :,if email :,100.0,100.00,True
585,"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB><TAB> c = self . getSystemCurve ( i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if c . getYAxis ( ) == Y_AXIS : <TAB><TAB><TAB> nPoints = c . getNPoints ( ) <TAB><TAB><TAB> for j in range ( nPoints ) : <TAB><TAB><TAB><TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB><TAB> return Double . NaN <TAB> return result",if not c . isVisible ( ) :,if not c . isVisible ( ) :,100.0,100.00,True
586,"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" link "" and ( "" rel "" , "" icon "" ) in attrs or ( "" rel "" , "" shortcut icon "" ) in attrs : <TAB><TAB> href = None <TAB><TAB> icon_type = None <TAB><TAB> for attr , value in attrs : <TAB><TAB><TAB> if attr == "" href "" : <TAB><TAB><TAB><TAB> href = value <TAB><TAB><TAB> elif attr == "" type "" : <TAB><TAB><TAB><TAB> icon_type = value <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> mimetype = extension_to_mimetype ( href . rpartition ( "" . "" ) [ 2 ] ) <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> icon_type = mimetype <TAB><TAB><TAB> if icon_type : <TAB><TAB><TAB><TAB> self . icons . append ( ( href , icon_type ) )",if href :,"elif attr == ""type"" :",80.82086747696054,97.12,False
587,"def get_version ( version_file = STATIC_VERSION_FILE ) : <TAB> version_info = get_static_version_info ( version_file ) <TAB> version = version_info [ "" version "" ] <TAB> if version == "" __use_git__ "" : <TAB><TAB> version = get_version_from_git ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> version = get_version_from_git_archive ( version_info ) <TAB><TAB> <MASK> <TAB><TAB><TAB> version = Version ( "" unknown "" , None , None ) <TAB><TAB> return pep440_format ( version ) <TAB> else : <TAB><TAB> return version",if not version :,"if version == ""__version_unknown"" :",65.89605191925816,88.04,False
588,"def _Sleep ( self , seconds ) : <TAB> if threading . current_thread ( ) is not self . _worker_thread : <TAB><TAB> return self . _original_sleep ( seconds ) <TAB> self . _time + = seconds <TAB> self . _budget - = seconds <TAB> while self . _budget < 0 : <TAB><TAB> self . _worker_thread_turn . clear ( ) <TAB><TAB> self . _owner_thread_turn . set ( ) <TAB><TAB> self . _worker_thread_turn . wait ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise FakeTimeline . _WorkerThreadExit ( )",if self . _worker_thread_done :,if self . _owner_thread_turn . isSet ( ) :,95.90011991854442,94.51,False
589,"def validate_attributes ( self ) : <TAB> if not ( self . has_variants or self . variant_of ) : <TAB><TAB> return <TAB> if not self . variant_based_on : <TAB><TAB> self . variant_based_on = "" Item Attribute "" <TAB> if self . variant_based_on == "" Item Attribute "" : <TAB><TAB> attributes = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( _ ( "" Attribute table is mandatory "" ) ) <TAB><TAB> for d in self . attributes : <TAB><TAB><TAB> if d . attribute in attributes : <TAB><TAB><TAB><TAB> frappe . throw ( <TAB><TAB><TAB><TAB><TAB> _ ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Attribute  {0}  selected multiple times in Attributes Table "" <TAB><TAB><TAB><TAB><TAB> ) . format ( d . attribute ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> attributes . append ( d . attribute )",if not self . attributes :,if not self . attributes :,100.0,100.00,True
590,"def check_digest_auth ( user , passwd ) : <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB><TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB><TAB> if not credentails : <TAB><TAB><TAB> return <TAB><TAB> response_hash = response ( <TAB><TAB><TAB> credentails , <TAB><TAB><TAB> passwd , <TAB><TAB><TAB> dict ( <TAB><TAB><TAB><TAB> uri = request . script_root + request . path , <TAB><TAB><TAB><TAB> body = request . data , <TAB><TAB><TAB><TAB> method = request . method , <TAB><TAB><TAB> ) , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False","if credentails . get ( ""response"" ) == response_hash :",if response_hash == user . digest_hash :,71.99622399377391,95.63,False
591,"def _get_index_type ( return_index_type , ctx ) : <TAB> if return_index_type is None : # pragma: no cover <TAB><TAB> if ctx . running_mode == RunningMode . local : <TAB><TAB><TAB> return_index_type = "" object "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return_index_type = "" filename "" <TAB><TAB> else : <TAB><TAB><TAB> return_index_type = "" bytes "" <TAB> return return_index_type",elif ctx . running_mode == RunningMode . local_cluster :,elif ctx . running_mode == RunningMode . file :,97.93976264046455,96.81,False
592,"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB><TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB><TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB><TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB><TAB> if not isinstance ( handler , handlers . ResourceWatchingHandler ) : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> yield handler","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",if not cause . is_watching_cause ( event ) :,75.02869568191272,90.20,False
593,"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB><TAB> if completed_process . stderr is not None : <TAB><TAB><TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB><TAB> if raise_error : <TAB><TAB><TAB> raise PipxError ( <TAB><TAB><TAB><TAB> f "" { '   ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> logger . info ( f "" { '   ' . join ( completed_process . args ) !r}  failed "" )",if completed_process . stdout is not None :,if completed_process . stdout is not None :,75.0,100.00,True
594,"def __pow__ ( self , power ) : <TAB> if power == 1 : <TAB><TAB> return self <TAB> if power == - 1 : <TAB><TAB> # HACK: break cycle <TAB><TAB> from cirq . devices import line_qubit <TAB><TAB> decomposed = protocols . decompose_once_with_qubits ( <TAB><TAB><TAB> self , qubits = line_qubit . LineQid . for_gate ( self ) , default = None <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return NotImplemented <TAB><TAB> inverse_decomposed = protocols . inverse ( decomposed , None ) <TAB><TAB> if inverse_decomposed is None : <TAB><TAB><TAB> return NotImplemented <TAB><TAB> return _InverseCompositeGate ( self ) <TAB> return NotImplemented",if decomposed is None :,if decomposed is None :,100.0,100.00,True
595,"def tearDown ( self ) : <TAB> """"""Close the application after tests"""""" <TAB> # set it back to it's old position so not to annoy users :-) <TAB> self . old_pos = self . dlg . rectangle <TAB> # close the application <TAB> self . dlg . menu_select ( "" File->Exit "" ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . app . UntitledNotepad [ "" Do&n ' t Save "" ] . click ( ) <TAB><TAB><TAB> self . app . UntitledNotepad . wait_not ( "" visible "" ) <TAB> except Exception : <TAB><TAB> pass <TAB> finally : <TAB><TAB> self . app . kill ( )","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :","if self . app . UntitledNotepad [ ""Do&n't"" ]",96.1380848738136,95.30,False
596,"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> <MASK> <TAB><TAB> if log : <TAB><TAB><TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB><TAB> proc . terminate ( ) <TAB><TAB> timeout_time = time . time ( ) + timeout <TAB><TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB><TAB><TAB> time . sleep ( 0.02 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if log : <TAB><TAB><TAB><TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB><TAB><TAB> proc . kill ( ) <TAB> return proc . returncode",if proc . poll ( ) is None :,if proc . is_alive ( ) :,91.65231155262478,94.47,False
597,"def validate ( self , detection , expectation ) : <TAB> config = SigmaConfiguration ( ) <TAB> self . basic_rule [ "" detection "" ] = detection <TAB> with patch ( "" yaml.safe_load_all "" , return_value = [ self . basic_rule ] ) : <TAB><TAB> parser = SigmaCollectionParser ( "" any sigma io "" , config , None ) <TAB><TAB> backend = SQLiteBackend ( config , self . table ) <TAB><TAB> assert len ( parser . parsers ) == 1 <TAB><TAB> for p in parser . parsers : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( expectation , backend . generate ( p ) ) <TAB><TAB><TAB> elif isinstance ( expectation , Exception ) : <TAB><TAB><TAB><TAB> self . assertRaises ( type ( expectation ) , backend . generate , p )","if isinstance ( expectation , str ) :","if isinstance ( expectation , str ) :",100.0,100.00,True
598,"def makelist ( d ) : <TAB> """"""Convert d into a list if all the keys of d are integers."""""" <TAB> if isinstance ( d , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ makelist ( d [ k ] ) for k in sorted ( d , key = int ) ] <TAB><TAB> else : <TAB><TAB><TAB> return web . storage ( ( k , makelist ( v ) ) for k , v in d . items ( ) ) <TAB> else : <TAB><TAB> return d",if all ( isint ( k ) for k in d ) :,"if isinstance ( d [ k ] , list ) :",66.09144873402019,92.38,False
599,"def __share_local_dir ( self , lpath , rpath , fast ) : <TAB> result = const . ENoError <TAB> for walk in self . __walk_normal_file ( lpath ) : <TAB><TAB> ( dirpath , dirnames , filenames ) = walk <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> rpart = os . path . relpath ( dirpath , lpath ) <TAB><TAB><TAB> if rpart == "" . "" : <TAB><TAB><TAB><TAB> rpart = "" "" <TAB><TAB><TAB> subr = self . __share_local_file ( <TAB><TAB><TAB><TAB> joinpath ( dirpath , filename ) , <TAB><TAB><TAB><TAB> posixpath . join ( rpath , rpart , filename ) , <TAB><TAB><TAB><TAB> fast , <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = subr <TAB> return result",if subr != const . ENoError :,if subr :,81.73967012746228,97.36,False
600,"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set ( ) <TAB> for condfield in self . conditions : <TAB><TAB> <MASK> <TAB><TAB><TAB> rulefieldvalues = sigmaparser . values [ condfield ] <TAB><TAB><TAB> for condvalue in self . conditions [ condfield ] : <TAB><TAB><TAB><TAB> if condvalue in rulefieldvalues : <TAB><TAB><TAB><TAB><TAB> targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB> return targets",if condfield in sigmaparser . values :,if condfield in sigmaparser . values :,75.0,100.00,True
601,"def _wrapped_view ( request , * args , * * kwargs ) : <TAB> # based on authority/decorators.py <TAB> user = request . user <TAB> if user . is_authenticated ( ) : <TAB><TAB> obj = _resolve_lookup ( obj_lookup , kwargs ) <TAB><TAB> perm_obj = _resolve_lookup ( perm_obj_lookup , kwargs ) <TAB><TAB> granted = access . has_perm_or_owns ( user , perm , obj , perm_obj , owner_attr ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return view_func ( request , * args , * * kwargs ) <TAB> # In all other cases, permission denied <TAB> return HttpResponseForbidden ( )",if granted or user . has_perm ( perm ) :,if granted :,70.69556888531437,94.03,False
602,"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB><TAB> earlier_part = earlier [ "" part "" ] <TAB><TAB> earlier_step = earlier [ "" step "" ] <TAB><TAB> found = False <TAB><TAB> for current in current_parts : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> found = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if not found : <TAB><TAB><TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB><TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint )","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",if current == earlier_part :,65.74970395063622,91.05,False
603,"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB><TAB> if self . named_windows [ wnd_name ] == 0 : <TAB><TAB><TAB> self . named_windows [ wnd_name ] = 1 <TAB><TAB><TAB> self . on_create_window ( wnd_name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . capture_mouse ( wnd_name ) <TAB><TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB><TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" )",if wnd_name in self . capture_mouse_windows :,if self . named_windows [ wnd_name ] == 1 :,68.10913536907792,93.86,False
604,"def readlines ( self , hint = None ) : <TAB> # Again, allow hint but ignore <TAB> body = self . _get_body ( ) <TAB> rest = body [ self . position : ] <TAB> self . position = len ( body ) <TAB> result = [ ] <TAB> while 1 : <TAB><TAB> next = rest . find ( "" \r \n "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( rest ) <TAB><TAB><TAB> break <TAB><TAB> result . append ( rest [ : next + 2 ] ) <TAB><TAB> rest = rest [ next + 2 : ] <TAB> return result",if next == - 1 :,if next == - 1 :,100.0,100.00,True
605,"def __lt__ ( self , other ) : <TAB> olen = len ( other ) <TAB> for i in range ( olen ) : <TAB><TAB> try : <TAB><TAB><TAB> c = self [ i ] < other [ i ] <TAB><TAB> except IndexError : <TAB><TAB><TAB> # self must be shorter <TAB><TAB><TAB> return True <TAB><TAB> if c : <TAB><TAB><TAB> return c <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return len ( self ) < olen",elif other [ i ] < self [ i ] :,if not c :,92.89442318155233,92.29,False
606,"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB><TAB> if user and social . user != user : <TAB><TAB><TAB> msg = "" This account is already in use. "" <TAB><TAB><TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> user = social . user <TAB> return { <TAB><TAB> "" social "" : social , <TAB><TAB> "" user "" : user , <TAB><TAB> "" is_new "" : user is None , <TAB><TAB> "" new_association "" : social is None , <TAB> }",elif not user :,if not user :,98.84531926022603,98.73,False
607,"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB><TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB><TAB> self . utexc = True <TAB> else : <TAB><TAB> if self . utexc is False : <TAB><TAB><TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . utexc [ indices ] = True",if self . utexc is not True :,if indices is not None :,89.37414560464634,94.93,False
608,"def destination ( self , type , name , arglist ) : <TAB> classname = "" ResFunction "" <TAB> listname = "" functions "" <TAB> if arglist : <TAB><TAB> t , n , m = arglist [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> classname = "" ResMethod "" <TAB><TAB><TAB> listname = "" resmethods "" <TAB> return classname , listname","if t == ""Handle"" and m == ""InMode"" :","if t == ""ResFunction"" and m == ""resmethods"" :",96.09925966926822,95.17,False
609,"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB><TAB> self . view . sel ( ) . add ( r ) <TAB><TAB> if register : <TAB><TAB><TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> if register : <TAB><TAB> text = "" "" . join ( to_store ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = text + "" \n "" <TAB><TAB> state = State ( self . view ) <TAB><TAB> state . registers [ register ] = [ text ]","if not text . endswith ( ""\n"" ) :",if self . view . full_line ( r ) :,74.96055105340227,94.66,False
610,"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB><TAB> self . _pos + = len ( chunk ) <TAB><TAB> if self . _pos < start : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> return b "" "" <TAB><TAB> else : <TAB><TAB><TAB> chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB> if stop is not None and self . _pos > stop : <TAB><TAB><TAB><TAB> chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB> assert len ( chunk ) == stop - start <TAB><TAB><TAB> return chunk <TAB> else : <TAB><TAB> raise StopIteration ( )",elif self . _pos == start :,if self . _pos == start :,73.82478896799716,98.88,False
611,"def start ( self ) : <TAB> self . on_config_change ( ) <TAB> self . start_config_watch ( ) <TAB> try : <TAB><TAB> if self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" tcp "" ] . lower ( ) == "" on "" : <TAB><TAB><TAB> self . startTCP ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . startUDP ( ) <TAB> except socket . error as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> shutdown ( <TAB><TAB><TAB><TAB> "" \n [DNS] Unable to start DNS server on port  {} : port already in use "" . format ( <TAB><TAB><TAB><TAB><TAB> self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" port "" ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )","if ""Address already in use"" in e :",if e . errno == errno . EEXIST :,75.25412364454426,96.03,False
612,"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB><TAB> if other not in self . ignoreExprs : <TAB><TAB><TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB><TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self",if self . expr is not None :,if self . expr :,66.68224777372721,94.27,False
613,"def test_relative_deploy_path_override ( ) : <TAB> s = Site ( TEST_SITE_ROOT ) <TAB> s . load ( ) <TAB> res = s . content . resource_from_relative_path ( <TAB><TAB> "" blog/2010/december/merry-christmas.html "" <TAB> ) <TAB> res . relative_deploy_path = "" blog/2010/december/happy-holidays.html "" <TAB> for page in s . content . walk_resources ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert page . relative_deploy_path == "" blog/2010/december/happy-holidays.html "" <TAB><TAB> else : <TAB><TAB><TAB> assert page . relative_deploy_path == Folder ( page . relative_path )",if res . source_file == page . source_file :,"if isinstance ( page , Site ) :",65.71290570407234,93.12,False
614,"def _parser ( cls , buf ) : <TAB> tlvs = [ ] <TAB> while buf : <TAB><TAB> tlv_type = LLDPBasicTLV . get_type ( buf ) <TAB><TAB> tlv = cls . _tlv_parsers [ tlv_type ] ( buf ) <TAB><TAB> tlvs . append ( tlv ) <TAB><TAB> offset = LLDP_TLV_SIZE + tlv . len <TAB><TAB> buf = buf [ offset : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> assert len ( buf ) > 0 <TAB> lldp_pkt = cls ( tlvs ) <TAB> assert lldp_pkt . _tlvs_len_valid ( ) <TAB> assert lldp_pkt . _tlvs_valid ( ) <TAB> return lldp_pkt , None , buf",if tlv . tlv_type == LLDP_TLV_END :,if not tlv_type :,72.88129956725902,93.86,False
615,"def _do_pull ( self , repo , pull_kwargs , silent , ignore_pull_failures ) : <TAB> try : <TAB><TAB> output = self . client . pull ( repo , * * pull_kwargs ) <TAB><TAB> if silent : <TAB><TAB><TAB> with open ( os . devnull , "" w "" ) as devnull : <TAB><TAB><TAB><TAB> yield from stream_output ( output , devnull ) <TAB><TAB> else : <TAB><TAB><TAB> yield from stream_output ( output , sys . stdout ) <TAB> except ( StreamOutputError , NotFound ) as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> log . error ( str ( e ) )",if not ignore_pull_failures :,if ignore_pull_failures :,96.91246042298843,98.71,False
616,def _collect_bytecode ( ordered_code ) : <TAB> bytecode_blocks = [ ] <TAB> stack = [ ordered_code ] <TAB> while stack : <TAB><TAB> code = stack . pop ( ) <TAB><TAB> bytecode_blocks . append ( code . co_code ) <TAB><TAB> for const in code . co_consts : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> stack . append ( const ) <TAB> return bytecode_blocks,"if isinstance ( const , blocks . OrderedCode ) :","if not const . co_name . startswith ( ""bytecode"" ) :",62.77843212269244,90.12,False
617,"def displayhook ( value ) : <TAB> if value is None : <TAB><TAB> return <TAB> builtins = modules [ "" builtins "" ] <TAB> # Set '_' to None to avoid recursion <TAB> builtins . _ = None <TAB> text = repr ( value ) <TAB> try : <TAB><TAB> local_stdout = stdout <TAB> except NameError as e : <TAB><TAB> raise RuntimeError ( "" lost sys.stdout "" ) from e <TAB> try : <TAB><TAB> local_stdout . write ( text ) <TAB> except UnicodeEncodeError : <TAB><TAB> bytes = text . encode ( local_stdout . encoding , "" backslashreplace "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> local_stdout . buffer . write ( bytes ) <TAB><TAB> else : <TAB><TAB><TAB> text = bytes . decode ( local_stdout . encoding , "" strict "" ) <TAB><TAB><TAB> local_stdout . write ( text ) <TAB> local_stdout . write ( "" \n "" ) <TAB> builtins . _ = value","if hasattr ( local_stdout , ""buffer"" ) :",if PY3 :,97.63237940882436,95.51,False
618,"def _analyze ( self ) : <TAB> lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB> prev_line = None <TAB> for line in lines : <TAB><TAB> if line . startswith ( "" ERROR: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB><TAB><TAB> self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB><TAB> prev_line = line","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :","elif line . startswith ( ""FAIL:"" ) and prev_line . startswith ( ""="" )",95.32988137968304,96.36,False
619,"def _flush ( self ) : <TAB> if self . _data : <TAB><TAB> if self . _last is not None : <TAB><TAB><TAB> text = "" "" . join ( self . _data ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> assert self . _last . tail is None , "" internal error (tail) "" <TAB><TAB><TAB><TAB> self . _last . tail = text <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> assert self . _last . text is None , "" internal error (text) "" <TAB><TAB><TAB><TAB> self . _last . text = text <TAB><TAB> self . _data = [ ]",if self . _tail :,if self . _last . tail is not None :,81.5490908381434,96.23,False
620,"def write ( self , chunk ) : <TAB> consumer = self . _current_consumer <TAB> server_side = consumer . server_side <TAB> if server_side : <TAB><TAB> server_side . data_received ( chunk ) <TAB> else : <TAB><TAB> consumer . message + = chunk <TAB><TAB> assert consumer . in_parser . execute ( chunk , len ( chunk ) ) == len ( chunk ) <TAB><TAB> <MASK> <TAB><TAB><TAB> consumer . finished ( )",if consumer . in_parser . is_message_complete ( ) :,if consumer . finished :,65.74976389880791,90.43,False
621,"def _api_change_cat ( name , output , kwargs ) : <TAB> """"""API: accepts output, value(=nzo_id), value2(=category)"""""" <TAB> value = kwargs . get ( "" value "" ) <TAB> value2 = kwargs . get ( "" value2 "" ) <TAB> if value and value2 : <TAB><TAB> nzo_id = value <TAB><TAB> cat = value2 <TAB><TAB> <MASK> <TAB><TAB><TAB> cat = None <TAB><TAB> result = sabnzbd . NzbQueue . change_cat ( nzo_id , cat ) <TAB><TAB> return report ( output , keyword = "" status "" , data = bool ( result > 0 ) ) <TAB> else : <TAB><TAB> return report ( output , _MSG_NO_VALUE )","if cat == ""None"" :","if cat == ""category"" :",98.8196395849797,98.69,False
622,"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB><TAB> occupied = False <TAB><TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> occupied = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if not occupied : <TAB><TAB><TAB> return addr <TAB> raise NoIdleSlot ( <TAB><TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> )",if strategy == self :,"if strategy == ""primary"" :",97.4495540838899,97.68,False
623,"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB><TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> with LoggerFactory . lock : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> if job_id in key : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> return True <TAB><TAB> key = job_id + "" schedule "" <TAB><TAB> if key in LoggerFactory . schedule_logger_dict : <TAB><TAB><TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB> return LoggerFactory . get_schedule_logger ( job_id )",if delete :,if delete :,100.0,100.00,True
624,"def quick_load ( tool_file , async_load = True ) : <TAB> try : <TAB><TAB> tool = self . load_tool ( tool_file , tool_cache_data_dir ) <TAB><TAB> self . __add_tool ( tool , load_panel_dict , elems ) <TAB><TAB> # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB><TAB> key = "" tool_ %s "" % str ( tool . id ) <TAB><TAB> integrated_elems [ key ] = tool <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _load_tool_panel ( ) <TAB><TAB><TAB> self . _save_integrated_tool_panel ( ) <TAB><TAB> return tool . id <TAB> except Exception : <TAB><TAB> log . exception ( "" Failed to load potential tool  %s . "" , tool_file ) <TAB><TAB> return None",if async_load :,if async_load :,100.0,100.00,True
625,"def _get_default_ordering ( self ) : <TAB> try : <TAB><TAB> ordering = super ( DocumentChangeList , self ) . _get_default_ordering ( ) <TAB> except AttributeError : <TAB><TAB> ordering = [ ] <TAB><TAB> if self . model_admin . ordering : <TAB><TAB><TAB> ordering = self . model_admin . ordering <TAB><TAB> <MASK> <TAB><TAB><TAB> ordering = self . lookup_opts . ordering <TAB> return ordering",elif self . lookup_opts . ordering :,elif self . lookup_opts . ordering :,100.0,100.00,True
626,"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB><TAB> self . __storage ( None ) , <TAB><TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB><TAB> for b in s : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if b . name . startswith ( "" __ "" ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if b . name not in u : <TAB><TAB><TAB><TAB> result . append ( b . name ) <TAB><TAB><TAB><TAB> u . add ( b . name ) <TAB> return result",if persistent is not None and b . persistent != persistent :,if b . persistent and b . name not in persistent :,94.4847879010816,95.75,False
627,"def common_check_get_messages_query ( <TAB> self , query_params : Dict [ str , object ] , expected : str ) - > None : <TAB> user_profile = self . example_user ( "" hamlet "" ) <TAB> request = POSTRequestMock ( query_params , user_profile ) <TAB> with queries_captured ( ) as queries : <TAB><TAB> get_messages_backend ( request , user_profile ) <TAB> for query in queries : <TAB><TAB> <MASK> <TAB><TAB><TAB> sql = str ( query [ "" sql "" ] ) . replace ( ""  /* get_messages */ "" , "" "" ) <TAB><TAB><TAB> self . assertEqual ( sql , expected ) <TAB><TAB><TAB> return <TAB> raise AssertionError ( "" get_messages query not found "" )","if ""/* get_messages */"" in query [ ""sql"" ] :","if query [ ""sql"" ] :",95.25479340697038,94.32,False
628,"def _activate_only_current_top_active ( ) : <TAB> for i in range ( 0 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> current_sequence ( ) . tracks [ i ] . active = True <TAB><TAB> else : <TAB><TAB><TAB> current_sequence ( ) . tracks [ i ] . active = False <TAB> gui . tline_column . widget . queue_draw ( )",if i == current_sequence ( ) . get_first_active_track ( ) . id :,if current_sequence ( ) . tracks [ i ] . active :,87.37759716493301,87.76,False
629,"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB><TAB> if postdata != { } : <TAB><TAB><TAB> f = urllib . urlopen ( url , postdata ) <TAB><TAB> else : <TAB><TAB><TAB> f = urllib . urlopen ( url ) <TAB><TAB> response = f . read ( ) <TAB> except : <TAB><TAB> import traceback <TAB><TAB> import logging , sys <TAB><TAB> cla , exc , tb = sys . exc_info ( ) <TAB><TAB> logging . error ( url ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . error ( "" with post data "" ) <TAB><TAB> else : <TAB><TAB><TAB> logging . error ( "" without post data "" ) <TAB><TAB> logging . error ( exc . args ) <TAB><TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB><TAB> response = "" "" <TAB> return response",if postdata :,"if cla . __name__ == ""post"" :",72.72344643706235,94.73,False
630,"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> <MASK> <TAB><TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB><TAB><TAB> interval = sys . getswitchinterval ( ) <TAB><TAB><TAB> sys . setswitchinterval ( 1e-6 ) <TAB><TAB> else : <TAB><TAB><TAB> interval = sys . getcheckinterval ( ) <TAB><TAB><TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB><TAB> yield <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB><TAB><TAB><TAB> sys . setswitchinterval ( interval ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sys . setcheckinterval ( interval )","if not sys . platform . startswith ( ""java"" ) :",if interval is not None :,60.52325571253567,89.40,False
631,"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB><TAB> f = queue . popleft ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if block_end : <TAB><TAB><TAB><TAB> queue . appendleft ( None ) <TAB><TAB><TAB> for gf in f . filters : <TAB><TAB><TAB><TAB> queue . appendleft ( gf ) <TAB><TAB> yield f","if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :","if isinstance ( f , FilterList ) :",63.64317554526456,84.44,False
632,"def smartsplit ( code ) : <TAB> """"""Split `code` at "" symbol, only if it is not escaped."""""" <TAB> strings = [ ] <TAB> pos = 0 <TAB> while pos < len ( code ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> word = "" "" # new word <TAB><TAB><TAB> pos + = 1 <TAB><TAB><TAB> while pos < len ( code ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> if code [ pos ] == "" \\ "" : <TAB><TAB><TAB><TAB><TAB> word + = "" \\ "" <TAB><TAB><TAB><TAB><TAB> pos + = 1 <TAB><TAB><TAB><TAB> word + = code [ pos ] <TAB><TAB><TAB><TAB> pos + = 1 <TAB><TAB><TAB> strings . append ( ' "" %s "" ' % word ) <TAB><TAB> pos + = 1 <TAB> return strings","if code [ pos ] == '""' :","if code [ pos ] == ""\\"" :",94.66260430215915,96.41,False
633,"def get_folder_content ( cls , name ) : <TAB> """"""Return (folders, files) for the given folder in the root dir."""""" <TAB> folders = set ( ) <TAB> files = set ( ) <TAB> for path in cls . LAYOUT : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> parts = path . split ( "" / "" ) <TAB><TAB> if len ( parts ) == 2 : <TAB><TAB><TAB> files . add ( parts [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> folders . add ( parts [ 1 ] ) <TAB> folders = list ( folders ) <TAB> folders . sort ( ) <TAB> files = list ( files ) <TAB> files . sort ( ) <TAB> return ( folders , files )","if not path . startswith ( name + ""/"" ) :",if not path . startswith ( name ) :,75.30243724496692,97.34,False
634,"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _tail <TAB><TAB> node = self . _root <TAB><TAB> level = self . _shift <TAB><TAB> while level > 0 : <TAB><TAB><TAB> assert isinstance ( node , Node ) <TAB><TAB><TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB><TAB><TAB> level - = 5 <TAB><TAB> assert isinstance ( node , Node ) <TAB><TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" )",if i >= self . tailoff ( ) :,if i >= self . _tail_offset :,95.58135495861623,96.96,False
635,"def __or__ ( self , other ) - > "" MultiVector "" : <TAB> r """"""``self | other``, the inner product :math:`M \cdot N`"""""" <TAB> other , mv = self . _checkOther ( other ) <TAB> if mv : <TAB><TAB> newValue = self . layout . imt_func ( self . value , other . value ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> obj = self . __array__ ( ) <TAB><TAB><TAB> return obj | other <TAB><TAB> # l * M = M * l = 0 for scalar l <TAB><TAB> return self . _newMV ( dtype = np . result_type ( self . value . dtype , other ) ) <TAB> return self . _newMV ( newValue )","if isinstance ( other , np . ndarray ) :",if self . value . dtype == np . float32 :,92.97685962861154,94.73,False
636,"def parse_bzr_stats ( status ) : <TAB> stats = RepoStats ( ) <TAB> statustype = "" changed "" <TAB> for statusline in status : <TAB><TAB> if statusline [ : 2 ] == ""    "" : <TAB><TAB><TAB> setattr ( stats , statustype , getattr ( stats , statustype ) + 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> statustype = "" staged "" <TAB><TAB> elif statusline == "" unknown: "" : <TAB><TAB><TAB> statustype = "" new "" <TAB><TAB> else : # removed, missing, renamed, modified or kind changed <TAB><TAB><TAB> statustype = "" changed "" <TAB> return stats","elif statusline == ""added:"" :","elif statusline == ""staged:"" :",98.69749587468785,98.52,False
637,"def write ( self , timestamps , actualValues , predictedValues , predictionStep = 1 ) : <TAB> assert len ( timestamps ) == len ( actualValues ) == len ( predictedValues ) <TAB> for index in range ( len ( self . names ) ) : <TAB><TAB> timestamp = timestamps [ index ] <TAB><TAB> actual = actualValues [ index ] <TAB><TAB> prediction = predictedValues [ index ] <TAB><TAB> writer = self . outputWriters [ index ] <TAB><TAB> <MASK> <TAB><TAB><TAB> outputRow = [ timestamp , actual , prediction ] <TAB><TAB><TAB> writer . writerow ( outputRow ) <TAB><TAB><TAB> self . lineCounts [ index ] + = 1",if timestamp is not None :,if self . outputWriters [ index ] > predictionStep :,74.91885965635645,94.32,False
638,"def clean ( self ) : <TAB> """"""Delete old files in ""tmp""."""""" <TAB> now = time . time ( ) <TAB> for entry in os . listdir ( os . path . join ( self . _path , "" tmp "" ) ) : <TAB><TAB> path = os . path . join ( self . _path , "" tmp "" , entry ) <TAB><TAB> <MASK> # 60 * 60 * 36 <TAB><TAB><TAB> os . remove ( path )",if now - os . path . getatime ( path ) > 129600 :,if now - os . time ( ) > 60 * 60 * 36 :,89.03230687399552,92.39,False
639,"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB><TAB> stdout = None <TAB><TAB> try : <TAB><TAB><TAB> stdout , stderr = Popen ( <TAB><TAB><TAB><TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB><TAB><TAB><TAB> stdout = PIPE , <TAB><TAB><TAB><TAB> stderr = PIPE , <TAB><TAB><TAB> ) . communicate ( ) <TAB><TAB> except OSError : <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for line in stdout . splitlines ( ) : <TAB><TAB><TAB><TAB><TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB><TAB><TAB><TAB><TAB> if len ( line ) == 2 : <TAB><TAB><TAB><TAB><TAB><TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info",if stdout :,if stdout :,100.0,100.00,True
640,"def add ( meta_list , info_list = None ) : <TAB> if not info_list : <TAB><TAB> info_list = meta_list <TAB> if not isinstance ( meta_list , ( list , tuple ) ) : <TAB><TAB> meta_list = ( meta_list , ) <TAB> if not isinstance ( info_list , ( list , tuple ) ) : <TAB><TAB> info_list = ( info_list , ) <TAB> for info_f in info_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> for meta_f in meta_list : <TAB><TAB><TAB><TAB> metadata [ meta_f ] = info [ info_f ] <TAB><TAB><TAB> break",if info . get ( info_f ) is not None :,if info_f not in metadata :,70.04550201237367,94.61,False
641,"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> log_r_term = model_site [ "" log_prob "" ] <TAB><TAB><TAB> if not model_site [ "" is_observed "" ] : <TAB><TAB><TAB><TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB><TAB><TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r","if model_site [ ""type"" ] == ""sample"" :","if ""log_prob"" in model_site :",93.91814077040483,93.92,False
642,"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB><TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB><TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB><TAB> line = f . readline ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> break <TAB><TAB> if prog . match ( line ) : <TAB><TAB><TAB> text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB> while 1 : <TAB><TAB><TAB><TAB> line = f . readline ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> text = text + line <TAB><TAB><TAB> return text . strip ( ) <TAB> return None",if not line or not line [ 0 ] . isspace ( ) :,if not line :,70.61257774155641,95.55,False
643,"def build_iterator ( data , infinite = True ) : <TAB> """"""Build the iterator for inputs."""""" <TAB> index = 0 <TAB> size = len ( data [ 0 ] ) <TAB> while True : <TAB><TAB> if index + batch_size > size : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> index = 0 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return <TAB><TAB> yield data [ 0 ] [ index : index + batch_size ] , data [ 1 ] [ index : index + batch_size ] <TAB><TAB> index + = batch_size",if infinite :,if infinite :,100.0,100.00,True
644,"def checkall ( g , bg , dst_nodes , include_dst_in_src = True ) : <TAB> for etype in g . etypes : <TAB><TAB> ntype = g . to_canonical_etype ( etype ) [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> check ( g , bg , ntype , etype , dst_nodes [ ntype ] , include_dst_in_src ) <TAB><TAB> else : <TAB><TAB><TAB> check ( g , bg , ntype , etype , None , include_dst_in_src )",if dst_nodes is not None and ntype in dst_nodes :,if ntype in dst_nodes :,70.96420104244382,93.96,False
645,"def minimalBases ( classes ) : <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3 : # pragma: no cover <TAB><TAB> classes = [ c for c in classes if c is not ClassType ] <TAB> candidates = [ ] <TAB> for m in classes : <TAB><TAB> for n in classes : <TAB><TAB><TAB> if issubclass ( n , m ) and m is not n : <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> # m has no subclasses in 'classes' <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> candidates . remove ( m ) # ensure that we're later in the list <TAB><TAB><TAB> candidates . append ( m ) <TAB> return candidates",if m in candidates :,if m in candidates :,100.0,100.00,True
646,"def __keep_songs_enable ( self , enabled ) : <TAB> config . set ( "" memory "" , "" queue_keep_songs "" , enabled ) <TAB> if enabled : <TAB><TAB> self . queue . set_first_column_type ( CurrentColumn ) <TAB> else : <TAB><TAB> for col in self . queue . get_columns ( ) : <TAB><TAB><TAB> # Remove the CurrentColum if it exists <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . queue . set_first_column_type ( None ) <TAB><TAB><TAB><TAB> break","if isinstance ( col , CurrentColumn ) :",if col . name == CurrentColum . name :,95.12699533462894,94.12,False
647,"def outlineView_heightOfRowByItem_ ( self , tree , item ) - > float : <TAB> default_row_height = self . rowHeight <TAB> if item is self : <TAB><TAB> return default_row_height <TAB> heights = [ default_row_height ] <TAB> for column in self . tableColumns : <TAB><TAB> value = getattr ( item . attrs [ "" node "" ] , str ( column . identifier ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # if the cell value is a widget, use its height <TAB><TAB><TAB> heights . append ( value . _impl . native . intrinsicContentSize ( ) . height ) <TAB> return max ( heights )","if isinstance ( value , toga . Widget ) :","if isinstance ( value , _impl . native . intrinsicContentSize ) :",94.55362102180419,95.69,False
648,"def condition ( self ) : <TAB> if self . __condition is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Avoid an extra indirection in the common case of only one condition. <TAB><TAB><TAB> self . __condition = self . flat_conditions [ 0 ] <TAB><TAB> elif len ( self . flat_conditions ) == 0 : <TAB><TAB><TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB><TAB><TAB> self . __condition = lambda _ : True <TAB><TAB> else : <TAB><TAB><TAB> self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB> return self . __condition",if len ( self . flat_conditions ) == 1 :,if len ( self . flat_conditions ) == 1 :,100.0,100.00,True
649,"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB><TAB> return 0 <TAB> while True : <TAB><TAB> b = f . read ( block_size ) <TAB><TAB> if not b : <TAB><TAB><TAB> return f . tell ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1",elif delimiter in b :,if b [ - 1 ] == delimiter :,89.09722386689201,92.81,False
650,"def serialize ( self , name = None ) : <TAB> data = super ( SimpleText , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> data [ "" content "" ] = self . content <TAB> if self . width : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidWidthException ( self . width ) <TAB><TAB> data [ "" inputOptions "" ] = { } <TAB><TAB> data [ "" width "" ] = self . width <TAB> return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",if not self . width . is_valid ( ) :,68.63726704198827,89.57,False
651,"def inference ( self ) : <TAB> self . attention_weight_dim = self . input_dims [ 0 ] [ - 1 ] <TAB> if self . keep_dim : <TAB><TAB> self . output_dim = copy . deepcopy ( self . input_dims [ 0 ] ) <TAB> else : <TAB><TAB> self . output_dim = [ ] <TAB><TAB> for idx , dim in enumerate ( self . input_dims [ 0 ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . output_dim . append ( dim ) <TAB> super ( <TAB><TAB> LinearAttentionConf , self <TAB> ) . inference ( ) # PUT THIS LINE AT THE END OF inference()",if idx != len ( self . input_dims [ 0 ] ) - 2 :,if dim is not None :,91.72757807414047,90.46,False
652,"def __delete_hook ( self , rpc ) : <TAB> try : <TAB><TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB><TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB><TAB> if status == MemcacheDeleteResponse . DELETED : <TAB><TAB><TAB> result . append ( DELETE_SUCCESSFUL ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( DELETE_ITEM_MISSING ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result",elif status == MemcacheDeleteResponse . NOT_FOUND :,elif status == MemcacheDeleteResponse . NOT_FOUND :,100.0,100.00,True
653,def identify_page_at_cursor ( self ) : <TAB> for region in self . view . sel ( ) : <TAB><TAB> text_on_cursor = None <TAB><TAB> pos = region . begin ( ) <TAB><TAB> scope_region = self . view . extract_scope ( pos ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text_on_cursor = self . view . substr ( scope_region ) <TAB><TAB><TAB> return text_on_cursor . strip ( string . punctuation ) <TAB> return None,if not scope_region . empty ( ) :,if scope_region :,72.72357350139234,94.17,False
654,"def from_elem ( cls , parent , when_elem ) : <TAB> """"""Loads the proper when by attributes of elem"""""" <TAB> when_value = when_elem . get ( "" value "" , None ) <TAB> <MASK> <TAB><TAB> return ValueToolOutputActionConditionalWhen ( parent , when_elem , when_value ) <TAB> else : <TAB><TAB> when_value = when_elem . get ( "" datatype_isinstance "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return DatatypeIsInstanceToolOutputActionConditionalWhen ( <TAB><TAB><TAB><TAB> parent , when_elem , when_value <TAB><TAB><TAB> ) <TAB> raise TypeError ( "" When type not implemented "" )",if when_value is not None :,if when_value is not None :,100.0,100.00,True
655,"def test_insert_entity_empty_string_rk ( <TAB> self , tables_cosmos_account_name , tables_primary_cosmos_account_key ) : <TAB> # Arrange <TAB> await self . _set_up ( tables_cosmos_account_name , tables_primary_cosmos_account_key ) <TAB> try : <TAB><TAB> entity = { "" PartitionKey "" : "" pk "" , "" RowKey "" : "" "" } <TAB><TAB> # Act <TAB><TAB> with pytest . raises ( HttpResponseError ) : <TAB><TAB><TAB> await self . table . create_entity ( entity = entity ) <TAB><TAB><TAB> # Assert <TAB><TAB> #  assert resp is None <TAB> finally : <TAB><TAB> await self . _tear_down ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sleep ( SLEEP_DELAY )",if self . is_live :,if self . is_live :,100.0,100.00,True
656,"def provider_uris ( self ) : <TAB> login_urls = { } <TAB> continue_url = self . request . get ( "" continue_url "" ) <TAB> for provider in self . provider_info : <TAB><TAB> <MASK> <TAB><TAB><TAB> login_url = self . uri_for ( <TAB><TAB><TAB><TAB> "" social-login "" , provider_name = provider , continue_url = continue_url <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> login_url = self . uri_for ( "" social-login "" , provider_name = provider ) <TAB><TAB> login_urls [ provider ] = login_url <TAB> return login_urls",if continue_url :,if continue_url :,100.0,100.00,True
657,"def expand_extensions ( existing ) : <TAB> for name in extension_names : <TAB><TAB> ext = ( <TAB><TAB><TAB> im ( "" lizard_ext.lizard "" + name . lower ( ) ) . LizardExtension ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else name <TAB><TAB> ) <TAB><TAB> existing . insert ( <TAB><TAB><TAB> len ( existing ) if not hasattr ( ext , "" ordering_index "" ) else ext . ordering_index , <TAB><TAB><TAB> ext , <TAB><TAB> ) <TAB> return existing","if isinstance ( name , str )","if not hasattr ( ext , ""ordering_index"" )",86.95396300742529,93.04,False
658,"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB><TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB> uri = self . request . path + "" / "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> uri + = "" ? "" + self . request . query <TAB><TAB><TAB> self . redirect ( uri , permanent = True ) <TAB><TAB><TAB> return <TAB><TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )",if self . request . query :,if self . request . query :,100.0,100.00,True
659,"def subword_map_by_joiner ( subwords , marker = SubwordMarker . JOINER ) : <TAB> """"""Return word id for each subword token (annotate by joiner)."""""" <TAB> flags = [ 0 ] * len ( subwords ) <TAB> for i , tok in enumerate ( subwords ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> flags [ i ] = 1 <TAB><TAB> if tok . startswith ( marker ) : <TAB><TAB><TAB> assert i > = 1 and flags [ i - 1 ] != 1 , "" Sentence ` {} ` not correct! "" . format ( <TAB><TAB><TAB><TAB> ""   "" . join ( subwords ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> flags [ i - 1 ] = 1 <TAB> marker_acc = list ( accumulate ( [ 0 ] + flags [ : - 1 ] ) ) <TAB> word_group = [ ( i - maker_sofar ) for i , maker_sofar in enumerate ( marker_acc ) ] <TAB> return word_group",if tok . endswith ( marker ) :,"if tok . startswith ( ( SubwordMarker . JOINER , SubwordMarker . LEFTMARKER",67.43346576273464,95.59,False
660,"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB><TAB> start = self . items . index ( self . _selected ) <TAB><TAB> i = start + direction <TAB> except : <TAB><TAB> pass <TAB> while True : <TAB><TAB> if i == start : <TAB><TAB><TAB> # Cannot find valid menu item <TAB><TAB><TAB> self . select ( start ) <TAB><TAB><TAB> break <TAB><TAB> if i > = len ( self . items ) : <TAB><TAB><TAB> i = 0 <TAB><TAB><TAB> continue <TAB><TAB> if i < 0 : <TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> i + = direction <TAB><TAB> if start < 0 : <TAB><TAB><TAB> start = 0",if self . select ( i ) :,if self . items [ i ] . selected :,97.80982672622484,97.43,False
661,"def get_config ( cls ) : <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = { } <TAB> # Try to get iflytek_yuyin config from config <TAB> profile_path = dingdangpath . config ( "" profile.yml "" ) <TAB> if os . path . exists ( profile_path ) : <TAB><TAB> with open ( profile_path , "" r "" ) as f : <TAB><TAB><TAB> profile = yaml . safe_load ( f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if "" vid "" in profile [ "" iflytek_yuyin "" ] : <TAB><TAB><TAB><TAB><TAB> config [ "" vid "" ] = profile [ "" iflytek_yuyin "" ] [ "" vid "" ] <TAB> return config","if ""iflytek_yuyin"" in profile :","if ""iflytek_yuyin"" in profile :",75.0,100.00,True
662,"def get_signed_in_user ( test_case ) : <TAB> playback = not ( test_case . is_live or test_case . in_recording ) <TAB> if playback : <TAB><TAB> return MOCKED_USER_NAME <TAB> else : <TAB><TAB> account_info = test_case . cmd ( "" account show "" ) . get_output_in_json ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return account_info [ "" user "" ] [ "" name "" ] <TAB> return None","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :","if account_info [ ""user"" ] :",77.9249619294032,91.81,False
663,"def rename_project ( self , project , new_name ) : <TAB> """"""Rename project, update the related projects if necessary"""""" <TAB> old_name = project . name <TAB> for proj in self . projects : <TAB><TAB> relproj = proj . get_related_projects ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> relproj [ relproj . index ( old_name ) ] = new_name <TAB><TAB><TAB> proj . set_related_projects ( relproj ) <TAB> project . rename ( new_name ) <TAB> self . save ( )",if old_name in relproj :,if old_name in relproj :,100.0,100.00,True
664,"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB><TAB> "" memcmp "" , <TAB><TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB><TAB> if a . is_null != b . is_null : <TAB><TAB><TAB> return False <TAB><TAB> if a is None : <TAB><TAB><TAB> return True <TAB><TAB> if len ( a ) != b . len : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if a . ptr == b . ptr :,"if memcmp ( a . ptr , b . ptr ) != 0 :",96.23892594868563,95.34,False
665,"def parse_variable ( self ) : <TAB> begin = self . _pos <TAB> while True : <TAB><TAB> ch = self . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ScriptVariable ( self . _text [ begin : self . _pos - 1 ] ) <TAB><TAB> elif ch is None : <TAB><TAB><TAB> self . __raise_eof ( ) <TAB><TAB> elif not isidentif ( ch ) and ch != "" : "" : <TAB><TAB><TAB> self . __raise_char ( ch )","if ch == ""%"" :",if begin < self . _pos :,67.92406900142413,94.76,False
666,"def h_file ( self ) : <TAB> filename = self . abspath ( ) <TAB> st = os . stat ( filename ) <TAB> cache = self . ctx . hashes_md5_tstamp <TAB> if filename in cache and cache [ filename ] [ 0 ] == st . st_mtime : <TAB><TAB> return cache [ filename ] [ 1 ] <TAB> if STRONGEST : <TAB><TAB> ret = Utils . h_file ( filename ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IOError ( "" Not a file "" ) <TAB><TAB> ret = Utils . md5 ( str ( ( st . st_mtime , st . st_size ) ) . encode ( ) ) . digest ( ) <TAB> cache [ filename ] = ( st . st_mtime , ret ) <TAB> return ret",if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,if not os . path . isfile ( filename ) :,79.75005472822849,92.79,False
667,"def add_widgets ( self , * widgets_or_spacings ) : <TAB> """"""Add widgets/spacing to dialog vertical layout"""""" <TAB> layout = self . layout ( ) <TAB> for widget_or_spacing in widgets_or_spacings : <TAB><TAB> <MASK> <TAB><TAB><TAB> layout . addSpacing ( widget_or_spacing ) <TAB><TAB> else : <TAB><TAB><TAB> layout . addWidget ( widget_or_spacing )","if isinstance ( widget_or_spacing , int ) :","if isinstance ( widget_or_spacing , ( list , tuple ) ) :",92.32032308631351,94.77,False
668,"def _str_index ( self ) : <TAB> idx = self [ "" index "" ] <TAB> out = [ ] <TAB> if len ( idx ) == 0 : <TAB><TAB> return out <TAB> out + = [ "" .. index::  %s "" % idx . get ( "" default "" , "" "" ) ] <TAB> for section , references in idx . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> elif section == "" refguide "" : <TAB><TAB><TAB> out + = [ ""    single:  %s "" % ( "" ,  "" . join ( references ) ) ] <TAB><TAB> else : <TAB><TAB><TAB> out + = [ ""     %s :  %s "" % ( section , "" , "" . join ( references ) ) ] <TAB> return out","if section == ""default"" :","if section == ""default"" :",100.0,100.00,True
669,"def dictify_CPPDEFINES ( env ) : <TAB> cppdefines = env . get ( "" CPPDEFINES "" , { } ) <TAB> if cppdefines is None : <TAB><TAB> return { } <TAB> if SCons . Util . is_Sequence ( cppdefines ) : <TAB><TAB> result = { } <TAB><TAB> for c in cppdefines : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ c [ 0 ] ] = c [ 1 ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> result [ c ] = None <TAB><TAB> return result <TAB> if not SCons . Util . is_Dict ( cppdefines ) : <TAB><TAB> return { cppdefines : None } <TAB> return cppdefines",if SCons . Util . is_Sequence ( c ) :,if SCons . Util . is_Dict ( c ) :,98.15709790923913,98.68,False
670,"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB><TAB> if c == "" & "" and not decode : <TAB><TAB><TAB> decode . append ( "" & "" ) <TAB><TAB> elif c == "" - "" and decode : <TAB><TAB><TAB> if len ( decode ) == 1 : <TAB><TAB><TAB><TAB> r . append ( "" & "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB> decode = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> decode . append ( c ) <TAB><TAB> else : <TAB><TAB><TAB> r . append ( c ) <TAB> if decode : <TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )",elif decode :,"elif c in ( ""+"" , ""-"" ) :",86.86579578095682,95.68,False
671,"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> height , width = TextureShape . get ( v ) <TAB><TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB><TAB><TAB> continue <TAB><TAB> if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB> flag_changed = True <TAB><TAB><TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed",if not Placeholder . check_resolved ( v . size ) :,"if not isinstance ( v , Graph ) :",75.12207074933825,94.81,False
672,"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB><TAB> if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ "" v "" ] ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> r + = 1 <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> return n == 1 and r == 1",elif op_gprv ( op ) :,elif op_reg ( op ) or ( op_mem ( op ) and op .,68.64472830436576,90.20,False
673,"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir : <TAB><TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB><TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB><TAB> if seq_file and os . path . exists ( seq_file ) : <TAB><TAB><TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB><TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return gdirs [ 0 ]",if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,if gdirs :,80.15836031388012,90.66,False
674,"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB><TAB> line = line and line . strip ( ) <TAB><TAB> if not line or line . startswith ( "" - "" ) : <TAB><TAB><TAB> continue <TAB><TAB> line_modules = line . split ( ) <TAB><TAB> for module in line_modules : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB><TAB><TAB> module_parts = module . split ( "" / "" ) <TAB><TAB><TAB> module_version = None <TAB><TAB><TAB> if len ( module_parts ) == 2 : <TAB><TAB><TAB><TAB> module_version = module_parts [ 1 ] <TAB><TAB><TAB> module_name = module_parts [ 0 ] <TAB><TAB><TAB> yield module_name , module_version",if module . endswith ( self . default_indicator ) :,if module . endswith ( self . default_indicator ) :,100.0,100.00,True
675,"def save ( self ) : <TAB> updates = self . cinder_obj_get_changes ( ) <TAB> if updates : <TAB><TAB> <MASK> <TAB><TAB><TAB> metadata = updates . pop ( "" metadata "" , None ) <TAB><TAB><TAB> self . metadata = db . backup_metadata_update ( <TAB><TAB><TAB><TAB> self . _context , self . id , metadata , True <TAB><TAB><TAB> ) <TAB><TAB> updates . pop ( "" parent "" , None ) <TAB><TAB> db . backup_update ( self . _context , self . id , updates ) <TAB> self . obj_reset_changes ( )","if ""metadata"" in updates :","if ""metadata"" in updates :",100.0,100.00,True
676,"def test_set_tag ( association_obj , sagemaker_session ) : <TAB> tag = { "" Key "" : "" foo "" , "" Value "" : "" bar "" } <TAB> association_obj . set_tag ( tag ) <TAB> while True : <TAB><TAB> actual_tags = sagemaker_session . sagemaker_client . list_tags ( <TAB><TAB><TAB> ResourceArn = association_obj . source_arn <TAB><TAB> ) [ "" Tags "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( 5 ) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len ( actual_tags ) > 0 <TAB> assert actual_tags [ 0 ] == tag",if actual_tags :,if actual_tags :,100.0,100.00,True
677,"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB><TAB> "" flush "" , <TAB><TAB> "" write "" , <TAB><TAB> "" writelines "" , <TAB> ] : <TAB><TAB> if not hasattr ( wsgi_errors , method ) : <TAB><TAB><TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB><TAB> <MASK> <TAB><TAB><TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB><TAB> if error_msg : <TAB><TAB><TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ]","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :",elif not callable ( wsgi_errors [ method ] ) :,77.15736445246156,93.93,False
678,"def current_dict ( cursor_offset , line ) : <TAB> """"""If in dictionary completion, return the dict that should be used"""""" <TAB> for m in current_dict_re . finditer ( line ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return LinePart ( m . start ( 1 ) , m . end ( 1 ) , m . group ( 1 ) ) <TAB> return None",if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,if m . start ( 1 ) <= cursor_offset and m . end ( 1 ) >=,61.72678883442846,90.98,False
679,"def show_file_browser ( self ) : <TAB> """"""Show/hide the file browser."""""" <TAB> if self . show_file_browser_action . isChecked ( ) : <TAB><TAB> sizes = self . panel . sizes ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sizes [ 0 ] = sum ( sizes ) / / 4 <TAB><TAB><TAB> self . panel . setSizes ( sizes ) <TAB><TAB> self . file_browser . show ( ) <TAB> else : <TAB><TAB> self . file_browser . hide ( )",if sizes [ 0 ] == 0 :,if sizes :,78.54234908462999,94.79,False
680,"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB> items . append ( item . nameEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB><TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sublime . status_message ( "" Items copied "" ) <TAB><TAB> else : <TAB><TAB><TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,100.0,100.00,True
681,"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tag . text = "" "" <TAB><TAB> if len ( root ) > 0 : <TAB><TAB><TAB> root [ - 1 ] . tail = tag . text <TAB><TAB><TAB> tag . text = root_text <TAB><TAB> else : <TAB><TAB><TAB> tag . text = root_text + tag . text <TAB><TAB> if i > 0 : <TAB><TAB><TAB> root = deepcopy ( list ( root ) ) <TAB><TAB> tag [ : 0 ] = root <TAB><TAB> root = tag [ : len ( root ) ] <TAB> return self",if not tag . text :,"if tag . text == """" :",71.85144129667319,96.83,False
682,"def getLabel ( self , address = None ) : <TAB> if address is None : <TAB><TAB> address = self . address <TAB> label = address <TAB> if shared . config . has_section ( address ) : <TAB><TAB> label = shared . config . get ( address , "" label "" ) <TAB> queryreturn = sqlQuery ( """""" select label from addressbook where address=? """""" , address ) <TAB> <MASK> <TAB><TAB> for row in queryreturn : <TAB><TAB><TAB> ( label , ) = row <TAB> else : <TAB><TAB> queryreturn = sqlQuery ( <TAB><TAB><TAB> """"""select label from subscriptions where address=?"""""" , address <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for row in queryreturn : <TAB><TAB><TAB><TAB> ( label , ) = row <TAB> return label",if queryreturn != [ ] :,if queryreturn :,91.501025607917,95.07,False
683,"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB><TAB> if "" axis "" in self . args : <TAB><TAB><TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if ""momentum"" in self . args :","if ""momentum"" in self . args :",100.0,100.00,True
684,"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB><TAB> new_kwargs = dict ( kwargs ) <TAB><TAB> if "" encoding "" in new_kwargs : <TAB><TAB><TAB> del new_kwargs [ "" encoding "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs )","if ""errors"" in kwargs :","if ""errors"" in new_kwargs :",98.21175747296871,97.13,False
685,"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB><TAB> if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] : <TAB><TAB><TAB> self . _FORM_VISIT_LIST . pop ( ) # Remove the current form. if it is at the end of the list <TAB><TAB> <MASK> <TAB><TAB><TAB> # take no action if it looks as if someone has already set the next form. <TAB><TAB><TAB> self . setNextForm ( <TAB><TAB><TAB><TAB> self . _FORM_VISIT_LIST . pop ( ) <TAB><TAB><TAB> ) # Switch to the previous form if one exists <TAB> except IndexError : <TAB><TAB> self . setNextForm ( backup )",if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT,98.48199787802727,96.84,False
686,"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB><TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB><TAB><TAB> if current_word : <TAB><TAB><TAB><TAB> yield current_word <TAB><TAB><TAB><TAB> current_word = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> yield current_word <TAB><TAB><TAB> current_word = [ char ] <TAB><TAB> else : <TAB><TAB><TAB> current_word . append ( char ) <TAB> if current_word : <TAB><TAB> yield current_word","elif current_word and self . char_begins_new_word ( current_word , char ) :","elif isinstance ( char , six . string_types ) :",70.93541156215036,90.49,False
687,"def get ( self ) : <TAB> """"""return a secret by name"""""" <TAB> results = self . _get ( "" secrets "" , self . name ) <TAB> results [ "" decoded "" ] = { } <TAB> results [ "" exists "" ] = False <TAB> if results [ "" returncode "" ] == 0 and results [ "" results "" ] [ 0 ] : <TAB><TAB> results [ "" exists "" ] = True <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" data "" in results [ "" results "" ] [ 0 ] : <TAB><TAB><TAB><TAB> for sname , value in results [ "" results "" ] [ 0 ] [ "" data "" ] . items ( ) : <TAB><TAB><TAB><TAB><TAB> results [ "" decoded "" ] [ sname ] = base64 . b64decode ( value ) <TAB> if results [ "" returncode "" ] != 0 and ' "" %s ""  not found ' % self . name in results [ "" stderr "" ] : <TAB><TAB> results [ "" returncode "" ] = 0 <TAB> return results",if self . decode :,"if results [ ""exists"" ] :",82.56579099909199,97.06,False
688,"def insert_use ( self , edit ) : <TAB> if self . is_first_use ( ) : <TAB><TAB> for location in [ r "" ^ \ s*namespace \ s+[ \ w \\ ]+[; { ] "" , r "" < \ ?php "" ] : <TAB><TAB><TAB> inserted = self . insert_first_use ( location , edit ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> else : <TAB><TAB> self . insert_use_among_others ( edit )",if inserted :,if not inserted :,92.1584755170346,98.16,False
689,"def _new_rsa_key ( spec ) : <TAB> if "" name "" not in spec : <TAB><TAB> <MASK> <TAB><TAB><TAB> ( head , tail ) = os . path . split ( spec [ "" key "" ] ) <TAB><TAB><TAB> spec [ "" path "" ] = head <TAB><TAB><TAB> spec [ "" name "" ] = tail <TAB><TAB> else : <TAB><TAB><TAB> spec [ "" name "" ] = spec [ "" key "" ] <TAB> return rsa_init ( spec )","if ""/"" in spec [ ""key"" ] :","if spec [ ""key"" ] :",94.93495733831878,96.07,False
690,"def mimeData ( self , indexes ) : <TAB> if len ( indexes ) == 1 : <TAB><TAB> index = indexes [ 0 ] <TAB><TAB> model = song = index . data ( Qt . UserRole ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> model = song . album <TAB><TAB><TAB> except ( ProviderIOError , Exception ) : <TAB><TAB><TAB><TAB> model = None <TAB><TAB> return ModelMimeData ( model )",if index . column ( ) == Column . album :,if model is None :,65.8638323819733,91.49,False
691,"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB><TAB> if url . endswith ( "" ping "" ) and self . _first_ping : <TAB><TAB><TAB> self . _first_ping = False <TAB><TAB><TAB> return EmptyCapabilitiesResponse ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ErrorApiResponse ( ) <TAB><TAB> else : <TAB><TAB><TAB> response = app . get ( url , * * kwargs ) <TAB><TAB><TAB> return TestingResponse ( response ) <TAB> else : <TAB><TAB> return requests . get ( url , * * kwargs )","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :","elif url . endswith ( ""error"" ) :",69.24889894173664,90.60,False
692,"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB><TAB> if hasattr ( model , "" _create_content_base "" ) : <TAB><TAB><TAB> self . validate_base_model ( model ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . validate_content_type ( model )","if hasattr ( model , ""_feincms_content_models"" ) :","if hasattr ( model , ""_create_content_type"" ) :",98.46794334110184,96.56,False
693,"def test_rules_widget ( self ) : <TAB> subreddit = self . reddit . subreddit ( pytest . placeholders . test_subreddit ) <TAB> widgets = subreddit . widgets <TAB> with self . use_cassette ( "" TestSubredditWidgets.fetch_widgets "" ) : <TAB><TAB> rules = None <TAB><TAB> for widget in widgets . sidebar : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> rules = widget <TAB><TAB><TAB><TAB> break <TAB><TAB> assert isinstance ( rules , RulesWidget ) <TAB><TAB> assert rules == rules <TAB><TAB> assert rules . id == rules <TAB><TAB> assert rules . display <TAB><TAB> assert len ( rules ) > 0 <TAB><TAB> assert subreddit == rules . subreddit","if isinstance ( widget , RulesWidget ) :","if isinstance ( widget , RulesWidget ) :",100.0,100.00,True
694,"def __init__ ( self , exception ) : <TAB> message = str ( exception ) <TAB> with contextlib . suppress ( IndexError ) : <TAB><TAB> underlying_exception = exception . args [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> message = ( <TAB><TAB><TAB><TAB> "" maximum retries exceeded trying to reach the store. \n "" <TAB><TAB><TAB><TAB> "" Check your network connection, and check the store  "" <TAB><TAB><TAB><TAB> "" status at  {} "" . format ( _STORE_STATUS_URL ) <TAB><TAB><TAB> ) <TAB> super ( ) . __init__ ( message = message )","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",if underlying_exception . args [ 0 ] == _STORE_MAX_RETRIES :,76.55859426150614,91.49,False
695,"def wrapped ( self , request ) : <TAB> try : <TAB><TAB> return self . _finished <TAB> except AttributeError : <TAB><TAB> if self . node_ids : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> log . debug ( <TAB><TAB><TAB><TAB><TAB> "" %s  is still going to be used, not terminating it.  "" <TAB><TAB><TAB><TAB><TAB> "" Still in use on: \n %s "" , <TAB><TAB><TAB><TAB><TAB> self , <TAB><TAB><TAB><TAB><TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return <TAB><TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB><TAB> try : <TAB><TAB><TAB> return func ( request ) <TAB><TAB> finally : <TAB><TAB><TAB> self . _finished = True",if not request . session . shouldfail and not request . session . shouldstop :,if self . _finished :,90.75858228987472,94.79,False
696,"def get_min_vertical_scroll ( ) - > int : <TAB> # Make sure that the cursor line is not below the bottom. <TAB> # (Calculate how many lines can be shown between the cursor and the .) <TAB> used_height = 0 <TAB> prev_lineno = ui_content . cursor_position . y <TAB> for lineno in range ( ui_content . cursor_position . y , - 1 , - 1 ) : <TAB><TAB> used_height + = get_line_height ( lineno ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return prev_lineno <TAB><TAB> else : <TAB><TAB><TAB> prev_lineno = lineno <TAB> return 0",if used_height > height - scroll_offsets_bottom :,if used_height < ui_content . cursor_position . y :,71.66534445305327,93.75,False
697,"def cookies ( self ) : <TAB> # strip cookie_suffix from all cookies in the request, return result <TAB> cookies = flask . Request . cookies . __get__ ( self ) <TAB> result = { } <TAB> desuffixed = { } <TAB> for key , value in cookies . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> desuffixed [ key [ : - len ( self . cookie_suffix ) ] ] = value <TAB><TAB> else : <TAB><TAB><TAB> result [ key ] = value <TAB> result . update ( desuffixed ) <TAB> return result",if key . endswith ( self . cookie_suffix ) :,if key . endswith ( self . cookie_suffix ) :,75.0,100.00,True
698,"def update_vars ( state1 , state2 ) : <TAB> ops = [ ] <TAB> for name in state1 . _fields : <TAB><TAB> state1_vs = getattr ( state1 , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ops + = [ <TAB><TAB><TAB><TAB> tf . assign ( _v1 , _v2 ) <TAB><TAB><TAB><TAB> for _v1 , _v2 in zip ( state1_vs , getattr ( state2 , name ) ) <TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> ops + = [ tf . assign ( state1_vs , getattr ( state2 , name ) ) ] <TAB> return tf . group ( * ops )","if isinstance ( state1_vs , list ) :","if isinstance ( state1_vs , ( list , tuple ) ) :",69.86916213208664,96.66,False
699,"def manifest ( self ) : <TAB> """"""The current manifest dictionary."""""" <TAB> if self . reload : <TAB><TAB> <MASK> <TAB><TAB><TAB> return { } <TAB><TAB> mtime = self . getmtime ( self . manifest_path ) <TAB><TAB> if self . _mtime is None or mtime > self . _mtime : <TAB><TAB><TAB> self . _manifest = self . get_manifest ( ) <TAB><TAB><TAB> self . _mtime = mtime <TAB> return self . _manifest",if not self . exists ( self . manifest_path ) :,if self . manifest_path is None :,86.09223229121208,93.56,False
700,"def csvtitle ( self ) : <TAB> if isinstance ( self . name , six . string_types ) : <TAB><TAB> return ' "" ' + self . name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB> else : <TAB><TAB> ret = "" "" <TAB><TAB> for i , name in enumerate ( self . name ) : <TAB><TAB><TAB> ret = ret + ' "" ' + name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret = ret + char [ "" sep "" ] <TAB><TAB> return ret",if i + 1 != len ( self . name ) :,if i == 0 :,71.91558599544629,93.79,False
701,"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB><TAB> for dst , src in viewitems ( assignblk ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if final_dst is not None : <TAB><TAB><TAB><TAB><TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB><TAB><TAB><TAB> final_dst = src <TAB><TAB><TAB><TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst","if dst . is_id ( ""IRDst"" ) :",if dst in self . destinations :,94.6632449986305,94.33,False
702,"def _ProcessName ( self , name , dependencies ) : <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB><TAB> <MASK> <TAB><TAB><TAB> if module_name in dependencies : <TAB><TAB><TAB><TAB> dependencies [ module_name ] . add ( base_name ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> dependencies [ module_name ] = { base_name } <TAB><TAB> else : <TAB><TAB><TAB> # If we have a relative import that did not get qualified (usually due <TAB><TAB><TAB> # to an empty package_name), don't insert module_name='' into the <TAB><TAB><TAB> # dependencies; we get a better error message if we filter it out here <TAB><TAB><TAB> # and fail later on. <TAB><TAB><TAB> logging . warning ( "" Empty package name:  %s "" , name )",if module_name :,if base_name :,99.06324132062528,99.05,False
703,"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB><TAB> if i == "" [ "" : <TAB><TAB><TAB> m = - 1 <TAB><TAB><TAB> aas . append ( "" "" ) <TAB><TAB> elif i == "" ] "" : <TAB><TAB><TAB> m = 0 <TAB><TAB><TAB> continue <TAB><TAB> elif m == - 1 : <TAB><TAB><TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB><TAB> <MASK> <TAB><TAB><TAB> aas . append ( i ) <TAB> return aas",elif m == 0 :,elif m == 1 :,77.21199835156818,98.62,False
704,"def logic ( ) : <TAB> count = intbv ( 0 , min = 0 , max = MAXVAL + 1 ) <TAB> while True : <TAB><TAB> yield clock . posedge , reset . posedge <TAB><TAB> if reset == 1 : <TAB><TAB><TAB> count [ : ] = 0 <TAB><TAB> else : <TAB><TAB><TAB> flag . next = 0 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> flag . next = 1 <TAB><TAB><TAB><TAB> count [ : ] = 0 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> count + = 1",if count == MAXVAL :,if reset == 0 :,81.71639672501591,97.17,False
705,"def _history_define_metric ( <TAB> self , hkey : str ) - > Optional [ wandb_internal_pb2 . MetricRecord ] : <TAB> """"""check for hkey match in glob metrics, return defined metric."""""" <TAB> # Dont define metric for internal metrics <TAB> if hkey . startswith ( "" _ "" ) : <TAB><TAB> return None <TAB> for k , mglob in six . iteritems ( self . _metric_globs ) : <TAB><TAB> if k . endswith ( "" * "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> m = wandb_internal_pb2 . MetricRecord ( ) <TAB><TAB><TAB><TAB> m . CopyFrom ( mglob ) <TAB><TAB><TAB><TAB> m . ClearField ( "" glob_name "" ) <TAB><TAB><TAB><TAB> m . name = hkey <TAB><TAB><TAB><TAB> return m <TAB> return None",if hkey . startswith ( k [ : - 1 ] ) :,if hkey in mglob :,95.56959728158374,95.12,False
706,"def optimize_models ( args , use_cuda , models ) : <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models : <TAB><TAB> model . make_generation_fast_ ( <TAB><TAB><TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB><TAB><TAB> need_attn = args . print_alignment , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> model . half ( ) <TAB><TAB> if use_cuda : <TAB><TAB><TAB> model . cuda ( )",if args . fp16 :,if args . half :,73.1835032006277,98.38,False
707,"def _Dynamic_Rollback ( self , transaction , transaction_response ) : <TAB> txid = transaction . handle ( ) <TAB> self . __local_tx_lock . acquire ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise apiproxy_errors . ApplicationError ( <TAB><TAB><TAB><TAB> datastore_pb . Error . BAD_REQUEST , "" Transaction  %d  not found. "" % ( txid , ) <TAB><TAB><TAB> ) <TAB><TAB> txdata = self . __transactions [ txid ] <TAB><TAB> assert ( <TAB><TAB><TAB> txdata . thread_id == thread . get_ident ( ) <TAB><TAB> ) , "" Transactions are single-threaded. "" <TAB><TAB> del self . __transactions [ txid ] <TAB> finally : <TAB><TAB> self . __local_tx_lock . release ( )",if txid not in self . __transactions :,if txid not in self . __transactions :,100.0,100.00,True
708,"def get_job_dirs ( path ) : <TAB> regex = re . compile ( "" [1-9][0-9]*- "" ) <TAB> jobdirs = [ ] <TAB> for d in os . listdir ( path ) : <TAB><TAB> # skip directories not matching the job result dir pattern <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> d = os . path . join ( options . resultsdir , d ) <TAB><TAB> if os . path . isdir ( d ) and not os . path . exists ( os . path . join ( d , PUBLISH_FLAGFILE ) ) : <TAB><TAB><TAB> jobdirs . append ( d ) <TAB> return jobdirs",if not regex . match ( d ) :,if not regex . search ( d ) :,98.8660655660742,98.53,False
709,"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB><TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB><TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB><TAB> if node : <TAB><TAB><TAB> node . functions = list ( functions ) <TAB><TAB><TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB><TAB> functions . append ( type ( node ) . __name__ ) <TAB><TAB> for f in node . next_functions : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB><TAB><TAB><TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB><TAB> for t in node . saved_tensors : <TAB><TAB><TAB> traverse ( t )",if f [ 0 ] :,"if hasattr ( f [ 0 ] , ""functions"" ) :",70.70968832029064,96.45,False
710,"def get_all_snap_points ( self , forts ) : <TAB> points = [ ] <TAB> radius = Constants . MAX_DISTANCE_FORT_IS_REACHABLE <TAB> for i in range ( 0 , len ( forts ) ) : <TAB><TAB> for j in range ( i + 1 , len ( forts ) ) : <TAB><TAB><TAB> c1 , c2 = self . get_enclosing_circles ( forts [ i ] , forts [ j ] , radius ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> points . append ( ( c1 , c2 , forts [ i ] , forts [ j ] ) ) <TAB> return points",if c1 and c2 :,if c1 != c2 :,95.72495805968192,97.77,False
711,"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB><TAB> if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB> continue <TAB><TAB> if child . tagName == "" Directory "" : <TAB><TAB><TAB> doDir ( child ) <TAB><TAB> elif child . tagName == "" Component "" : <TAB><TAB><TAB> for grandchild in child . childNodes : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if not isinstance ( grandchild , minidom . Element ) :","if not isinstance ( grandchild , minidom . Element ) :",75.0,100.00,True
712,"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB><TAB> if ch == ""   "" : <TAB><TAB><TAB> w + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return w","elif ch == ""\t"" :","elif ch == ""\t"" :",100.0,100.00,True
713,"def test_avg_group_by ( self ) : <TAB> ret = ( <TAB><TAB> await Book . annotate ( avg = Avg ( "" rating "" ) ) <TAB><TAB> . group_by ( "" author_id "" ) <TAB><TAB> . values ( "" author_id "" , "" avg "" ) <TAB> ) <TAB> for item in ret : <TAB><TAB> author_id = item . get ( "" author_id "" ) <TAB><TAB> avg = item . get ( "" avg "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( avg , 4.5 ) <TAB><TAB> elif author_id == self . a2 . pk : <TAB><TAB><TAB> self . assertEqual ( avg , 2.0 )",if author_id == self . a1 . pk :,if author_id == self . a1 . pk :,100.0,100.00,True
714,"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB><TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> expiration = stored_session . expiration <TAB><TAB><TAB> if not expiration . tzinfo : <TAB><TAB><TAB><TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB><TAB><TAB><TAB> return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB> initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )",if stored_session :,if stored_session :,100.0,100.00,True
715,"def one_line_description ( self ) : <TAB> MAX_LINE_LENGTH = 120 <TAB> desc = util . remove_html_tags ( self . description or "" "" ) <TAB> desc = re . sub ( "" \ s+ "" , ""   "" , desc ) . strip ( ) <TAB> if not desc : <TAB><TAB> return _ ( "" No description available "" ) <TAB> else : <TAB><TAB> # Decode the description to avoid gPodder bug 1277 <TAB><TAB> desc = util . convert_bytes ( desc ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return desc [ : MAX_LINE_LENGTH ] + "" ... "" <TAB><TAB> else : <TAB><TAB><TAB> return desc",if len ( desc ) > MAX_LINE_LENGTH :,if len ( desc ) > MAX_LINE_LENGTH :,100.0,100.00,True
716,"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB><TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB><TAB> self . tag . append ( node ) <TAB><TAB> name = getattr ( node , "" name "" , None ) <TAB><TAB> if name is None : <TAB><TAB><TAB> continue <TAB><TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> handler ( node )",if handler :,if handler is not None :,70.53654396368778,97.51,False
717,def get_supported_period_type_map ( cls ) : <TAB> if cls . supported_period_map is None : <TAB><TAB> cls . supported_period_map = { } <TAB><TAB> cls . supported_period_map . update ( cls . period_type_map ) <TAB><TAB> try : <TAB><TAB><TAB> from dateutil import relativedelta <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cls . supported_period_map . update ( cls . optional_period_type_map ) <TAB><TAB> except Exception : <TAB><TAB><TAB> pass <TAB> return cls . supported_period_map,if relativedelta is not None :,if relativedelta ( cls . period_type_map ) :,91.9027048026275,93.83,False
718,"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB><TAB> compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB> ) <TAB> except Empty : <TAB><TAB> pass <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> if redo : <TAB><TAB><TAB><TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB> compares_done . add ( compare_id ) <TAB><TAB><TAB> self . _process_compare ( compare_id ) <TAB><TAB><TAB> if self . callback : <TAB><TAB><TAB><TAB> self . callback ( )","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",if compare_id not in compares_done :,92.872961101759,91.51,False
719,"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB><TAB> for field_name in field_names : <TAB><TAB><TAB> field_name = field_name . lower ( ) <TAB><TAB><TAB> if "" : "" in line : <TAB><TAB><TAB><TAB> left , right = line . split ( "" : "" , 1 ) <TAB><TAB><TAB><TAB> left = left . strip ( ) . lower ( ) <TAB><TAB><TAB><TAB> right = right . strip ( ) <TAB><TAB><TAB><TAB> if left == field_name and len ( right ) > 0 : <TAB><TAB><TAB><TAB><TAB> if cant_be_number : <TAB><TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB><TAB> return right <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> return right <TAB> return None",if not right . isdigit ( ) :,if len ( right ) == cant_be_number :,68.99097961689152,96.07,False
720,"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB><TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB><TAB> if not s . consume ( "" \\ "" ) : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB><TAB><TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> s . expect_re ( _escapes_re ) <TAB><TAB><TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res )",if s . consume_re ( _newline_esc_re ) :,if s . consume_re ( _basicstr_re ) :,99.09720145857136,98.18,False
721,"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB><TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB><TAB> try : <TAB><TAB><TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB> except error_perm as error : <TAB><TAB><TAB> code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB> if code == "" 550 "" : <TAB><TAB><TAB><TAB> if self . isfile ( path ) : <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB> raise # pragma: no cover",if not self . isempty ( path ) :,elif self . isdir ( path ) :,72.57191698654762,97.74,False
722,"def _normalize_store_path ( self , resource_store ) : <TAB> if resource_store [ "" type "" ] == "" filesystem "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> resource_store [ "" base_directory "" ] = os . path . join ( <TAB><TAB><TAB><TAB> self . root_directory , resource_store [ "" base_directory "" ] <TAB><TAB><TAB> ) <TAB> return resource_store","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",if self . root_directory :,77.87007029955019,85.19,False
723,"def _apply_nested ( name , val , nested ) : <TAB> parts = name . split ( "" . "" ) <TAB> cur = nested <TAB> for i in range ( 0 , len ( parts ) - 1 ) : <TAB><TAB> cur = cur . setdefault ( parts [ i ] , { } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> conflicts_with = "" . "" . join ( parts [ 0 : i + 1 ] ) <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" %r  cannot be nested: conflicts with  { %r :  %s } "" <TAB><TAB><TAB><TAB> % ( name , conflicts_with , cur ) <TAB><TAB><TAB> ) <TAB> cur [ parts [ - 1 ] ] = val","if not isinstance ( cur , dict ) :",if cur . get ( parts [ i ] ) != val :,68.08576844393579,93.69,False
724,"def build_packages ( targeted_packages , distribution_directory , is_dev_build = False ) : <TAB> # run the build and distribution <TAB> for package_root in targeted_packages : <TAB><TAB> service_hierarchy = os . path . join ( os . path . basename ( package_root ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> verify_update_package_requirement ( package_root ) <TAB><TAB> print ( "" Generating Package Using Python  {} "" . format ( sys . version ) ) <TAB><TAB> run_check_call ( <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> sys . executable , <TAB><TAB><TAB><TAB> build_packing_script_location , <TAB><TAB><TAB><TAB> "" --dest "" , <TAB><TAB><TAB><TAB> os . path . join ( distribution_directory , service_hierarchy ) , <TAB><TAB><TAB><TAB> package_root , <TAB><TAB><TAB> ] , <TAB><TAB><TAB> root_dir , <TAB><TAB> )",if is_dev_build :,if is_dev_build :,100.0,100.00,True
725,"def resolve_root_node_address ( self , root_node ) : <TAB> if "" [ "" in root_node : <TAB><TAB> name , numbers = root_node . split ( "" [ "" , maxsplit = 1 ) <TAB><TAB> number = numbers . split ( "" , "" , maxsplit = 1 ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> number = number . split ( "" - "" ) [ 0 ] <TAB><TAB> number = re . sub ( "" [^0-9] "" , "" "" , number ) <TAB><TAB> root_node = name + number <TAB> return root_node","if ""-"" in number :","if ""-"" in number :",100.0,100.00,True
726,"def _map_args ( maps : dict , * * kwargs ) : <TAB> # maps: key=old name, value= new name <TAB> output = { } <TAB> for name , val in kwargs . items ( ) : <TAB><TAB> if name in maps : <TAB><TAB><TAB> assert isinstance ( maps [ name ] , str ) <TAB><TAB><TAB> output . update ( { maps [ name ] : val } ) <TAB><TAB> else : <TAB><TAB><TAB> output . update ( { name : val } ) <TAB> for keys in maps . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB> return output",if keys not in output . keys ( ) :,if keys in output :,71.2795160422687,95.45,False
727,"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB><TAB> start = self . items . index ( self . _selected ) <TAB><TAB> i = start + direction <TAB> except : <TAB><TAB> pass <TAB> while True : <TAB><TAB> if i == start : <TAB><TAB><TAB> # Cannot find valid menu item <TAB><TAB><TAB> self . select ( start ) <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> i = 0 <TAB><TAB><TAB> continue <TAB><TAB> if i < 0 : <TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> continue <TAB><TAB> if self . select ( i ) : <TAB><TAB><TAB> break <TAB><TAB> i + = direction <TAB><TAB> if start < 0 : <TAB><TAB><TAB> start = 0",if i >= len ( self . items ) :,if i > len ( self . items ) - 1 :,98.21000056398906,98.22,False
728,"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . KEY in function . context : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . _explore ( function . entry_point , [ ] ) <TAB><TAB><TAB> function . context [ self . KEY ] = True",if function . is_implemented :,if self . _is_function_name ( function . name ) :,92.49058388450771,88.97,False
729,"def load_model ( self ) : <TAB> if not os . path . exists ( self . get_filename ( absolute = True ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return { } , { } <TAB><TAB> error ( <TAB><TAB><TAB> "" Model file with pre-trained convolution layers not found. Download it here... "" , <TAB><TAB><TAB> "" https://github.com/alexjc/neural-enhance/releases/download/v %s / %s "" <TAB><TAB><TAB> % ( __version__ , self . get_filename ( ) ) , <TAB><TAB> ) <TAB> print ( ""   - Loaded file ` {} ` with trained model. "" . format ( self . get_filename ( ) ) ) <TAB> return pickle . load ( bz2 . open ( self . get_filename ( ) , "" rb "" ) )",if args . train :,"if self . get_version ( ) == ""0.0.0"" :",96.08778630105424,93.98,False
730,"def get_nonexisting_check_definition_extends ( definition , indexed_oval_defs ) : <TAB> # TODO: handle multiple levels of referrals. <TAB> # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB> for extdefinition in definition . findall ( "" .// { %s }extend_definition "" % oval_ns ) : <TAB><TAB> # Verify each extend_definition in the definition <TAB><TAB> extdefinitionref = extdefinition . get ( "" definition_ref "" ) <TAB><TAB> # Search the OVAL tree for a definition with the referred ID <TAB><TAB> referreddefinition = indexed_oval_defs . get ( extdefinitionref ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # There is no oval satisfying the extend_definition referal <TAB><TAB><TAB> return extdefinitionref <TAB> return None",if referreddefinition is None :,if referreddefinition is not None :,74.0922519161754,98.71,False
731,"def pause ( self ) : <TAB> if self . is_playing : <TAB><TAB> self . state = MusicPlayerState . PAUSED <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _current_player . pause ( ) <TAB><TAB> self . emit ( "" pause "" , player = self , entry = self . current_entry ) <TAB><TAB> return <TAB> elif self . is_paused : <TAB><TAB> return <TAB> raise ValueError ( "" Cannot pause a MusicPlayer in state  %s "" % self . state )",if self . _current_player :,if self . _current_player :,100.0,100.00,True
732,"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _FORM_VISIT_LIST . pop ( ) # Remove the current form. if it is at the end of the list <TAB><TAB> if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM : <TAB><TAB><TAB> # take no action if it looks as if someone has already set the next form. <TAB><TAB><TAB> self . setNextForm ( <TAB><TAB><TAB><TAB> self . _FORM_VISIT_LIST . pop ( ) <TAB><TAB><TAB> ) # Switch to the previous form if one exists <TAB> except IndexError : <TAB><TAB> self . setNextForm ( backup )",if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,if self . _THISFORM .FORM_NAME in self . _FORM_VISIT,82.82350392533895,94.13,False
733,"def get_expr_referrers ( schema : s_schema . Schema , obj : so . Object ) - > Dict [ so . Object , str ] : <TAB> """"""Return schema referrers with refs in expressions."""""" <TAB> refs = schema . get_referrers_ex ( obj ) <TAB> result = { } <TAB> for ( mcls , fn ) , referrers in refs . items ( ) : <TAB><TAB> field = mcls . get_field ( fn ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . update ( { ref : fn for ref in referrers } ) <TAB> return result","if issubclass ( field . type , ( Expression , ExpressionList ) ) :",if field . is_expr :,64.52670357801368,91.51,False
734,"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> requires_index = any ( <TAB><TAB><TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB><TAB> ) <TAB><TAB> if requires_index : <TAB><TAB><TAB> fields . append ( field ) <TAB> return fields",if field . primary_key :,if field . index is None or field . unique is None :,93.47847648491815,92.24,False
735,"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB><TAB> value = None <TAB><TAB> # XXX: how will this interact with orig_prefix ? <TAB><TAB> #      not exposing attrs for now if orig_prefix is set. <TAB><TAB> if not self . orig_prefix : <TAB><TAB><TAB> wrapped = self . wrapped <TAB><TAB><TAB> idents = getattr ( wrapped , "" ident_values "" , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB><TAB><TAB> ##else: <TAB><TAB><TAB> ##    ident = self.ident <TAB><TAB><TAB> ##    if ident is not None: <TAB><TAB><TAB> ##        value = [ident] <TAB><TAB> self . _ident_values = value <TAB> return value",if idents :,if idents is not None :,98.70776676385137,98.18,False
736,"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB><TAB> node = self . path . find_dir ( dir ) <TAB><TAB> if not node : <TAB><TAB><TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> lst . append ( node ) <TAB><TAB> self . bld_incpaths_lst . append ( node )",if not node in lst :,if node not in lst :,93.81984335745935,97.96,False
737,"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames : <TAB><TAB> logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB><TAB> if os . path . exists ( filename ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sabnzbd . add_nzbfile ( filename , keep = True )",if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,"if os . name == ""nt"" and os . name == ""nt"" :",66.88789097375124,86.03,False
738,"def check ( self , xp , nout ) : <TAB> input = xp . asarray ( self . x ) . astype ( numpy . float32 ) <TAB> with warnings . catch_warnings ( ) : <TAB><TAB> if self . ignore_warning : <TAB><TAB><TAB> warnings . simplefilter ( "" ignore "" , self . ignore_warning ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . check_positive ( xp , self . func , input , self . eps , nout ) <TAB><TAB> else : <TAB><TAB><TAB> self . check_negative ( xp , self . func , input , self . eps , nout )",if self . result :,if self . ignore_negative :,98.7564242548323,97.10,False
739,"def _set_scheme ( url , newscheme ) : <TAB> scheme = _get_scheme ( url ) <TAB> newscheme = newscheme or "" "" <TAB> newseparator = "" : "" if newscheme in COLON_SEPARATED_SCHEMES else "" :// "" <TAB> if scheme == "" "" : # Protocol relative URL. <TAB><TAB> url = "" %s : %s "" % ( newscheme , url ) <TAB> elif scheme is None and url : # No scheme. <TAB><TAB> url = "" "" . join ( [ newscheme , newseparator , url ] ) <TAB> elif scheme : # Existing scheme. <TAB><TAB> remainder = url [ len ( scheme ) : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> remainder = remainder [ 3 : ] <TAB><TAB> elif remainder . startswith ( "" : "" ) : <TAB><TAB><TAB> remainder = remainder [ 1 : ] <TAB><TAB> url = "" "" . join ( [ newscheme , newseparator , remainder ] ) <TAB> return url","if remainder . startswith ( ""://"" ) :","if remainder . startswith ( ""://"" ) :",100.0,100.00,True
740,"def parquet ( tables , data_directory , ignore_missing_dependency , * * params ) : <TAB> try : <TAB><TAB> import pyarrow as pa # noqa: F401 <TAB><TAB> import pyarrow . parquet as pq # noqa: F401 <TAB> except ImportError : <TAB><TAB> msg = "" PyArrow dependency is missing "" <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( "" Ignored:  %s "" , msg ) <TAB><TAB><TAB> return 0 <TAB><TAB> else : <TAB><TAB><TAB> raise click . ClickException ( msg ) <TAB> data_directory = Path ( data_directory ) <TAB> for table , df in read_tables ( tables , data_directory ) : <TAB><TAB> arrow_table = pa . Table . from_pandas ( df ) <TAB><TAB> target_path = data_directory / "" {} .parquet "" . format ( table ) <TAB><TAB> pq . write_table ( arrow_table , str ( target_path ) )",if ignore_missing_dependency :,if ignore_missing_dependency :,75.0,100.00,True
741,"def h2i ( self , pkt , s ) : <TAB> t = ( ) <TAB> if type ( s ) is str : <TAB><TAB> t = time . strptime ( s ) <TAB><TAB> t = t [ : 2 ] + t [ 2 : - 3 ] <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> y , m , d , h , min , sec , rest , rest , rest = time . gmtime ( time . time ( ) ) <TAB><TAB><TAB> t = ( y , m , d , h , min , sec ) <TAB><TAB> else : <TAB><TAB><TAB> t = s <TAB> return t",if not s :,if pkt . h2i_magic == 2 :,69.4276890794927,94.35,False
742,"def filter_episodes ( self , batch , cross_entropy ) : <TAB> """"""Filter the episodes for the cross_entropy method"""""" <TAB> accumulated_reward = [ sum ( rewards ) for rewards in batch [ "" rewards "" ] ] <TAB> percentile = cross_entropy * 100 <TAB> reward_bound = np . percentile ( accumulated_reward , percentile ) <TAB> # we save the batch with reward above the bound <TAB> result = { k : [ ] for k in self . data_keys } <TAB> episode_kept = 0 <TAB> for i in range ( len ( accumulated_reward ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for k in self . data_keys : <TAB><TAB><TAB><TAB> result [ k ] . append ( batch [ k ] [ i ] ) <TAB><TAB><TAB> episode_kept + = 1 <TAB> return result",if accumulated_reward [ i ] >= reward_bound :,if episode_kept < reward_bound :,97.64062433543428,95.78,False
743,"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB><TAB> envvar = match . groups ( ) [ 0 ] <TAB><TAB> if envvar in os . environ : <TAB><TAB><TAB> value = os . environ [ envvar ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value . decode ( "" utf8 "" ) <TAB><TAB><TAB> return value <TAB><TAB> else : <TAB><TAB><TAB> raise InvalidConfigException ( <TAB><TAB><TAB><TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise InvalidConfigException ( <TAB><TAB><TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB><TAB><TAB><TAB> msg , var , _ENV_VAR_PAT_STR <TAB><TAB><TAB> ) <TAB><TAB> )",if six . PY2 :,"if isinstance ( value , bytes ) :",97.02568843339292,97.32,False
744,"def _allocate_nbd ( self ) : <TAB> if not os . path . exists ( "" /sys/block/nbd0 "" ) : <TAB><TAB> self . error = _ ( "" nbd unavailable: module not loaded "" ) <TAB><TAB> return None <TAB> while True : <TAB><TAB> if not self . _DEVICES : <TAB><TAB><TAB> # really want to log this info, not raise <TAB><TAB><TAB> self . error = _ ( "" No free nbd devices "" ) <TAB><TAB><TAB> return None <TAB><TAB> device = self . _DEVICES . pop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return device","if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",if not device :,91.84764457042817,84.75,False
745,"def _expand_deps_java_generation ( self ) : <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB><TAB> k = queue . popleft ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> keys . add ( k ) <TAB><TAB><TAB> dep = self . target_database [ k ] <TAB><TAB><TAB> if "" generate_java "" in dep . attr : # Has this attribute <TAB><TAB><TAB><TAB> dep . attr [ "" generate_java "" ] = True <TAB><TAB><TAB><TAB> queue . extend ( dep . deps )",if k not in keys :,if k not in keys :,100.0,100.00,True
746,"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB><TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB><TAB> if isinstance ( fstyle , basestring ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> key = fstyle [ 2 : - 2 ] <TAB><TAB><TAB><TAB> fstyle = context [ key ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> fstyle = fstyle % context <TAB><TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats","if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :","if fstyle . startswith ( ""file:"" ) :",74.1452623284523,94.96,False
747,"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> values . remove ( ) <TAB><TAB> elif operation == "" update "" : <TAB><TAB><TAB> old_value , new_value = values <TAB><TAB><TAB> if new_value . full_filename != old_value . full_filename : <TAB><TAB><TAB><TAB> os . unlink ( new_value . full_filename ) <TAB><TAB><TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( )","if operation == ""insert"" :","if operation == ""delete"" :",98.38865646849847,98.49,False
748,"def _buildOffsets ( offsetDict , localeData , indexStart ) : <TAB> o = indexStart <TAB> for key in localeData : <TAB><TAB> <MASK> <TAB><TAB><TAB> for k in key . split ( "" | "" ) : <TAB><TAB><TAB><TAB> offsetDict [ k ] = o <TAB><TAB> else : <TAB><TAB><TAB> offsetDict [ key ] = o <TAB><TAB> o + = 1","if ""|"" in key :","if ""|"" in key :",100.0,100.00,True
749,"def _check_start_pipeline_execution_errors ( <TAB> graphene_info , execution_params , execution_plan ) : <TAB> if execution_params . step_keys : <TAB><TAB> for step_key in execution_params . step_keys : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise UserFacingGraphQLError ( <TAB><TAB><TAB><TAB><TAB> graphene_info . schema . type_named ( "" InvalidStepError "" ) ( <TAB><TAB><TAB><TAB><TAB><TAB> invalid_step_key = step_key <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> )",if not execution_plan . has_step ( step_key ) :,if step_key not in execution_plan . steps :,87.2711842553311,94.35,False
750,"def __setattr__ ( self , option_name , option_value ) : <TAB> if option_name in self . _options : <TAB><TAB> # type checking <TAB><TAB> sort = self . OPTIONS [ self . arch . name ] [ option_name ] [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _options [ option_name ] = option_value <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> ' Value for option  "" %s ""  must be of type  %s ' % ( option_name , sort ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> super ( CFGArchOptions , self ) . __setattr__ ( option_name , option_value )","if sort is None or isinstance ( option_value , sort ) :","if sort == ""all"" :",94.73385622570127,93.83,False
751,"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB><TAB> quote = True <TAB> else : <TAB><TAB> for x in self : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> quote = True <TAB> if quote : <TAB><TAB> pre = post = "" "" <TAB><TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB><TAB><TAB> pre = ""   "" <TAB><TAB> if self [ - 1 ] . token_type == "" cfws "" or self [ - 1 ] [ - 1 ] . token_type == "" cfws "" : <TAB><TAB><TAB> post = ""   "" <TAB><TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB><TAB> return super ( DisplayName , self ) . value","if x . token_type == ""quoted-string"" :","if x . token_type == ""quoted-string"" :",100.0,100.00,True
752,"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB><TAB> <MASK> <TAB><TAB><TAB> filename , data = filename_data <TAB><TAB> else : <TAB><TAB><TAB> filename = filename_data <TAB><TAB><TAB> data = None <TAB><TAB> if not filename . startswith ( os . sep ) : <TAB><TAB><TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB> files . append ( filename ) <TAB><TAB> if data : <TAB><TAB><TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories","if isinstance ( filename_data , list ) :","if isinstance ( filename_data , tuple ) :",98.91345792692078,98.89,False
753,"def _evaluateStack ( s ) : <TAB> op = s . pop ( ) <TAB> if op in "" +-*/@^ "" : <TAB><TAB> op2 = _evaluateStack ( s ) <TAB><TAB> op1 = _evaluateStack ( s ) <TAB><TAB> result = opn [ op ] ( op1 , op2 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( result ) <TAB><TAB> return result <TAB> else : <TAB><TAB> return op",if debug_flag :,if result :,73.06542301133025,96.20,False
754,"def reconnect_user ( self , user_id , host_id , server_id ) : <TAB> if host_id == settings . local . host_id : <TAB><TAB> return <TAB> if server_id and self . server . id != server_id : <TAB><TAB> return <TAB> for client in self . clients . find ( { "" user_id "" : user_id } ) : <TAB><TAB> self . clients . update_id ( <TAB><TAB><TAB> client [ "" id "" ] , <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" ignore_routes "" : True , <TAB><TAB><TAB> } , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . instance . disconnect_wg ( client [ "" id "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . instance_com . client_kill ( client [ "" id "" ] )","if len ( client [ ""id"" ] ) > 32 :",if self . instance :,93.87332231963437,94.93,False
755,"def _get_library ( self , name , args ) : <TAB> library_database = self . _library_manager . get_new_connection_to_library_database ( ) <TAB> try : <TAB><TAB> last_updated = library_database . get_library_last_updated ( name , args ) <TAB><TAB> if last_updated : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _library_manager . fetch_keywords ( <TAB><TAB><TAB><TAB><TAB> name , args , self . _libraries_need_refresh_listener <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return library_database . fetch_library_keywords ( name , args ) <TAB><TAB> return self . _library_manager . get_and_insert_keywords ( name , args ) <TAB> finally : <TAB><TAB> library_database . close ( )",if time . time ( ) - last_updated > 10.0 :,if last_updated < self . _libraries_need_refresh_listener :,92.987300517135,94.22,False
756,"def get_paths ( self , path , commit ) : <TAB> """"""Return a generator of all filepaths under path at commit."""""" <TAB> _check_path_is_repo_relative ( path ) <TAB> git_path = _get_git_path ( path ) <TAB> tree = self . gl_repo . git_repo [ commit . tree [ git_path ] . id ] <TAB> assert tree . type == pygit2 . GIT_OBJ_TREE <TAB> for tree_entry in tree : <TAB><TAB> tree_entry_path = os . path . join ( path , tree_entry . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for fp in self . get_paths ( tree_entry_path , commit ) : <TAB><TAB><TAB><TAB> yield fp <TAB><TAB> else : <TAB><TAB><TAB> yield tree_entry_path","if tree_entry . type == ""tree"" :",if os . path . isdir ( tree_entry_path ) :,67.46509715026475,94.75,False
757,"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB><TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB><TAB><TAB><TAB><TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",75.0,100.00,True
758,"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self . _wb_parse_context : <TAB><TAB> if tag == "" style "" : <TAB><TAB><TAB> self . _wb_parse_context = "" style "" <TAB><TAB> elif tag == "" script "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _wb_parse_context = "" script """,if self . _allow_js_type ( tag_attrs ) :,"if self . _wb_parse_context == ""script"" :",70.88814761195539,92.04,False
759,"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB><TAB> if not isinstance ( op_list , list ) : <TAB><TAB><TAB> op_list = ( op_list , ) <TAB><TAB> for item in chain ( * op_list ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> dictionary = item . dictionary <TAB><TAB><TAB> if dictionary . path in paths : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> paths . add ( dictionary . path ) <TAB><TAB><TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list",if item is None :,"if item . type != ""dictionary"" :",68.71821964053551,95.82,False
760,def preorder ( root ) : <TAB> res = [ ] <TAB> if not root : <TAB><TAB> return res <TAB> stack = [ ] <TAB> stack . append ( root ) <TAB> while stack : <TAB><TAB> root = stack . pop ( ) <TAB><TAB> res . append ( root . val ) <TAB><TAB> <MASK> <TAB><TAB><TAB> stack . append ( root . right ) <TAB><TAB> if root . left : <TAB><TAB><TAB> stack . append ( root . left ) <TAB> return res,if root . right :,if root . right :,100.0,100.00,True
761,"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB><TAB> self . context . log . info ( <TAB><TAB><TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB><TAB> ) <TAB><TAB> subject = self . derived_by_original . get ( <TAB><TAB><TAB> exported_python_target , exported_python_target <TAB><TAB> ) <TAB><TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB><TAB> created [ exported_python_target ] = setup_dir <TAB><TAB> if self . _recursive : <TAB><TAB><TAB> for dep in dependencies : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> create ( dep )",if is_exported_python_target ( dep ) :,if dep not in created :,95.90617746478088,95.05,False
762,"def test_array_interface ( self , data ) : <TAB> result = np . array ( data ) <TAB> np . testing . assert_array_equal ( result [ 0 ] , data [ 0 ] ) <TAB> result = np . array ( data , dtype = object ) <TAB> expected = np . array ( list ( data ) , dtype = object ) <TAB> for a1 , a2 in zip ( result , expected ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert np . isnan ( a1 ) and np . isnan ( a2 ) <TAB><TAB> else : <TAB><TAB><TAB> tm . assert_numpy_array_equal ( a2 , a1 )",if np . isscalar ( a1 ) :,"if isinstance ( a1 , np . ndarray ) :",68.50729953078041,95.67,False
763,"def valueChanged ( plug ) : <TAB> changed = plug . getInput ( ) is not None <TAB> if not changed and isinstance ( plug , Gaffer . ValuePlug ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> changed = not Gaffer . NodeAlgo . isSetToUserDefault ( plug ) <TAB><TAB> else : <TAB><TAB><TAB> changed = not plug . isSetToDefault ( ) <TAB> return changed",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,if Gaffer . NodeAlgo . isUserDefault ( plug ) :,98.16245406308424,97.47,False
764,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB> <MASK> # if failed to get version bail <TAB><TAB><TAB> major , minor , _ = version <TAB><TAB><TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB> if arch is not None : <TAB><TAB><TAB><TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB> if exe_data is not None : <TAB><TAB><TAB><TAB><TAB> exe , args = exe_data <TAB><TAB><TAB><TAB><TAB> return company , major , minor , arch , exe , args",if version is not None :,if version is not None :,100.0,100.00,True
765,"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB><TAB> if isinstance ( value , alias_flag_value ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( name , self . _has_flag ( value . flag ) )","if isinstance ( value , flag_value ) :",if value . flag :,66.80220271949966,91.22,False
766,"def connect ( self ) : <TAB> self . sock = sockssocket ( ) <TAB> self . sock . setproxy ( * proxy_args ) <TAB> if type ( self . timeout ) in ( int , float ) : <TAB><TAB> self . sock . settimeout ( self . timeout ) <TAB> self . sock . connect ( ( self . host , self . port ) ) <TAB> if isinstance ( self , compat_http_client . HTTPSConnection ) : <TAB><TAB> <MASK> # Python > 2.6 <TAB><TAB><TAB> self . sock = self . _context . wrap_socket ( self . sock , server_hostname = self . host ) <TAB><TAB> else : <TAB><TAB><TAB> self . sock = ssl . wrap_socket ( self . sock )","if hasattr ( self , ""_context"" ) :","if sys . version_info >= ( 2 , 6 ) :",88.15843660006992,93.68,False
767,"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB><TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB><TAB><TAB> interval = sys . getswitchinterval ( ) <TAB><TAB><TAB> sys . setswitchinterval ( 1e-6 ) <TAB><TAB> else : <TAB><TAB><TAB> interval = sys . getcheckinterval ( ) <TAB><TAB><TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB><TAB> yield <TAB> finally : <TAB><TAB> if not sys . platform . startswith ( "" java "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sys . setswitchinterval ( interval ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sys . setcheckinterval ( interval )","if hasattr ( sys , ""setswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",100.0,100.00,True
768,"def vars ( self ) : <TAB> ret = [ ] <TAB> if op . intlist : <TAB><TAB> varlist = op . intlist <TAB> else : <TAB><TAB> varlist = self . discover <TAB><TAB> for name in varlist : <TAB><TAB><TAB> if name in ( "" 0 "" , "" 1 "" , "" 2 "" , "" 8 "" , "" CPU0 "" , "" ERR "" , "" LOC "" , "" MIS "" , "" NMI "" ) : <TAB><TAB><TAB><TAB> varlist . remove ( name ) <TAB><TAB> if not op . full and len ( varlist ) > 3 : <TAB><TAB><TAB> varlist = varlist [ - 3 : ] <TAB> for name in varlist : <TAB><TAB> if name in self . discover : <TAB><TAB><TAB> ret . append ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( self . intmap [ name . lower ( ) ] ) <TAB> return ret",elif name . lower ( ) in self . intmap :,elif name . lower ( ) in self . intmap :,100.0,100.00,True
769,"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB><TAB> inst . add ( gadget . _gadget ) <TAB><TAB> <MASK> <TAB><TAB><TAB> count = len ( inst ) <TAB><TAB><TAB> toReturn . append ( gadget ) <TAB><TAB><TAB> added = True <TAB><TAB> if callback : <TAB><TAB><TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB><TAB><TAB> added = False <TAB> return toReturn",if len ( inst ) > count :,if count == len_gadgets :,85.68875574226861,96.19,False
770,"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB><TAB> value = None <TAB><TAB> # XXX: how will this interact with orig_prefix ? <TAB><TAB> #      not exposing attrs for now if orig_prefix is set. <TAB><TAB> if not self . orig_prefix : <TAB><TAB><TAB> wrapped = self . wrapped <TAB><TAB><TAB> ident = getattr ( wrapped , "" ident "" , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = self . _wrap_hash ( ident ) <TAB><TAB> self . _ident = value <TAB> return value",if ident is not None :,if ident is not None :,100.0,100.00,True
771,"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB><TAB> if isinstance ( field , _ContainerMixin ) : <TAB><TAB><TAB> setting_values . update ( <TAB><TAB><TAB><TAB> self . _flatten_settings_from_form ( <TAB><TAB><TAB><TAB><TAB> settings , field , form_values [ field . _name ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values",elif field . _name in settings :,"elif isinstance ( field , _FormField ) :",92.70192548802234,96.26,False
772,"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB> if name not in cls . __dict__ : <TAB><TAB><TAB> continue <TAB><TAB> if name != "" __init__ "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> if name in butnot : <TAB><TAB><TAB> continue <TAB><TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls","if not private and name . startswith ( ""_"" ) :","if not hasattr ( meth , ""__call__"" ) :",66.72519259035813,93.50,False
773,"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB><TAB> while True : <TAB><TAB><TAB> b1 = fp1 . read ( bufsize ) <TAB><TAB><TAB> b2 = fp2 . read ( bufsize ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> if not b1 : <TAB><TAB><TAB><TAB> return True",if b1 != b2 :,if not b1 and b2 :,94.55810284707411,96.96,False
774,"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB><TAB> value , last_update = self . cache [ args ] <TAB><TAB> age = now - last_update <TAB><TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB><TAB><TAB> self . _call_count = 0 <TAB><TAB><TAB> raise AttributeError <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _call_count + = 1 <TAB><TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB><TAB> value = func ( * args ) <TAB><TAB> if value : <TAB><TAB><TAB> self . cache [ args ] = ( value , now ) <TAB><TAB> return value <TAB> except TypeError : <TAB><TAB> return func ( * args )",if self . ctl :,if self . _call_count < self . ctl :,84.26524301182593,96.81,False
775,"def check ( self , hyperlinks : Dict [ str , Hyperlink ] ) - > Generator [ CheckResult , None , None ] : <TAB> self . invoke_threads ( ) <TAB> total_links = 0 <TAB> for hyperlink in hyperlinks . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield CheckResult ( <TAB><TAB><TAB><TAB> hyperlink . uri , hyperlink . docname , hyperlink . lineno , "" ignored "" , "" "" , 0 <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . wqueue . put ( CheckRequest ( CHECK_IMMEDIATELY , hyperlink ) , False ) <TAB><TAB><TAB> total_links + = 1 <TAB> done = 0 <TAB> while done < total_links : <TAB><TAB> yield self . rqueue . get ( ) <TAB><TAB> done + = 1 <TAB> self . shutdown_threads ( )",if self . is_ignored_uri ( hyperlink . uri ) :,if hyperlink . is_immediate :,92.59364921454866,94.88,False
776,"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> subscriber . _pyroRelease ( ) <TAB><TAB> if hasattr ( subscriber , "" _pyroUri "" ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB><TAB> proxy . _pyroRelease ( ) <TAB><TAB><TAB><TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> pass <TAB><TAB> self . subscribers [ topic ] . discard ( subscriber )","if hasattr ( subscriber , ""_pyroRelease"" ) :","if hasattr ( subscriber , ""_pyroRelease"" ) :",100.0,100.00,True
777,"def delete_arc ( collection , document , origin , target , type ) : <TAB> directory = collection <TAB> real_dir = real_directory ( directory ) <TAB> mods = ModificationTracker ( ) <TAB> projectconf = ProjectConfiguration ( real_dir ) <TAB> document = path_join ( real_dir , document ) <TAB> with TextAnnotations ( document ) as ann_obj : <TAB><TAB> # bail as quick as possible if read-only <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AnnotationsIsReadOnlyError ( ann_obj . get_document ( ) ) <TAB><TAB> _delete_arc_with_ann ( origin , target , type , mods , ann_obj , projectconf ) <TAB><TAB> mods_json = mods . json_response ( ) <TAB><TAB> mods_json [ "" annotations "" ] = _json_from_ann ( ann_obj ) <TAB><TAB> return mods_json",if ann_obj . _read_only :,if ann_obj . get_document ( ) . read_only :,98.13567489509099,96.69,False
778,"def _select_from ( self , parent_path , is_dir , exists , listdir ) : <TAB> if not is_dir ( parent_path ) : <TAB><TAB> return <TAB> with _cached ( listdir ) as listdir : <TAB><TAB> yielded = set ( ) <TAB><TAB> try : <TAB><TAB><TAB> successor_select = self . successor . _select_from <TAB><TAB><TAB> for starting_point in self . _iterate_directories ( <TAB><TAB><TAB><TAB> parent_path , is_dir , listdir <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> for p in successor_select ( starting_point , is_dir , exists , listdir ) : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> yield p <TAB><TAB><TAB><TAB><TAB><TAB> yielded . add ( p ) <TAB><TAB> finally : <TAB><TAB><TAB> yielded . clear ( )",if p not in yielded :,if p not in yielded :,100.0,100.00,True
779,"def _fractional_part ( self , n , expr , evaluation ) : <TAB> n_sympy = n . to_sympy ( ) <TAB> if n_sympy . is_constant ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> positive_integer_part = ( <TAB><TAB><TAB><TAB> Expression ( "" Floor "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> result = n - positive_integer_part <TAB><TAB> else : <TAB><TAB><TAB> negative_integer_part = ( <TAB><TAB><TAB><TAB> Expression ( "" Ceiling "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> result = n - negative_integer_part <TAB> else : <TAB><TAB> return expr <TAB> return from_python ( result )",if n_sympy >= 0 :,if n_sympy . is_integer ( ) :,96.61507712324432,96.87,False
780,"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB><TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB><TAB> if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB> )",if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,if geometry [ 0 ] < - 180 or geometry [ 0 ] < - 180 :,94.40418916360375,94.00,False
781,"def get_absolute_path ( self , root , path ) : <TAB> # find the first absolute path that exists <TAB> self . root = self . roots [ 0 ] <TAB> for root in self . roots : <TAB><TAB> abspath = os . path . abspath ( os . path . join ( root , path ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . root = root # make sure all the other methods in the base class know how to find the file <TAB><TAB><TAB> break <TAB> return abspath",if os . path . exists ( abspath ) :,if abspath . startswith ( self . root ) :,71.08098608608151,94.34,False
782,"def do_setflow ( self , l = "" "" ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> l = str ( self . flow_slider . GetValue ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> l = l . lower ( ) <TAB><TAB> flow = int ( l ) <TAB><TAB> if self . p . online : <TAB><TAB><TAB> self . p . send_now ( "" M221 S "" + l ) <TAB><TAB><TAB> self . log ( _ ( "" Setting print flow factor to  %d %% . "" ) % flow ) <TAB><TAB> else : <TAB><TAB><TAB> self . logError ( _ ( "" Printer is not online. "" ) ) <TAB> except Exception as x : <TAB><TAB> self . logError ( _ ( "" You must enter a flow. ( %s ) "" ) % ( repr ( x ) , ) )","if not isinstance ( l , str ) or not len ( l ) :",if self . flow_slider . HasField ( ) :,90.89820718630155,94.44,False
783,"def sources ( ) : <TAB> for d in os . listdir ( base ) : <TAB><TAB> #        if d.startswith('talis'): <TAB><TAB> #            continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if d == "" indcat "" : <TAB><TAB><TAB> continue <TAB><TAB> if not os . path . isdir ( base + d ) : <TAB><TAB><TAB> continue <TAB><TAB> yield d","if d . endswith ( ""old"" ) :","if d . startswith ( ""source"" ) :",96.59091360267398,96.22,False
784,"def create_accumulator ( self ) - > tf_metric_accumulators . TFCompilableMetricsAccumulator : <TAB> configs = zip ( self . _metric_configs , self . _loss_configs ) <TAB> padding_options = None <TAB> if self . _eval_config is not None : <TAB><TAB> model_spec = model_util . get_model_spec ( self . _eval_config , self . _model_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> padding_options = model_spec . padding_options <TAB> return tf_metric_accumulators . TFCompilableMetricsAccumulator ( <TAB><TAB> padding_options , <TAB><TAB> [ len ( m ) + len ( l ) for m , l in configs ] , <TAB><TAB> desired_batch_size = self . _desired_batch_size , <TAB> )","if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",if model_spec :,90.77158547490798,91.45,False
785,"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB><TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . expr . resultsName : <TAB><TAB><TAB><TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB><TAB><TAB><TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tokens = [ self . defaultValue ] <TAB><TAB> else : <TAB><TAB><TAB> tokens = [ ] <TAB> return loc , tokens",if self . defaultValue is not self . __optionalNotMatched :,if self . expr . is_list :,95.02254615409615,95.44,False
786,"def handleConnection ( self ) : <TAB> # connection handshake <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> self . csock . close ( ) <TAB> except : <TAB><TAB> ex_t , ex_v , ex_tb = sys . exc_info ( ) <TAB><TAB> tb = util . formatTraceback ( ex_t , ex_v , ex_tb ) <TAB><TAB> log . warning ( "" error during connect/handshake:  %s ;  %s "" , ex_v , "" \n "" . join ( tb ) ) <TAB><TAB> self . csock . close ( ) <TAB> return False",if self . daemon . _handshake ( self . csock ) :,if self . csock . connect ( ) :,71.38811313795408,95.08,False
787,"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 : # have a one element wedge <TAB><TAB> proc = ( "" first "" , "" last "" ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> proc = ( "" first "" , "" last "" ) # same element can be first and last <TAB><TAB> elif su . isFirst ( innerTarget ) : <TAB><TAB><TAB> proc = ( "" first "" , ) <TAB><TAB> elif su . isLast ( innerTarget ) : <TAB><TAB><TAB> proc = ( "" last "" , ) <TAB><TAB> else : <TAB><TAB><TAB> proc = ( ) <TAB> return proc",if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,if su . equals ( innerTarget ) :,95.94178214203579,94.78,False
788,"def get_color_dtype ( data , column_names ) : <TAB> has_color = all ( column in data [ "" points "" ] for column in column_names ) <TAB> if has_color : <TAB><TAB> color_data_types = [ <TAB><TAB><TAB> data [ "" points "" ] [ column_name ] . dtype for column_name in column_names <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> f "" Data types of color values are inconsistent: got  { color_data_types } "" <TAB><TAB><TAB> ) <TAB><TAB> color_data_type = color_data_types [ 0 ] <TAB> else : <TAB><TAB> color_data_type = None <TAB> return color_data_type",if len ( set ( color_data_types ) ) > 1 :,"if not isinstance ( color_data_types [ 0 ] , ColorDataType ) :",67.6477428237023,95.02,False
789,"def close ( self ) : <TAB> children = [ ] <TAB> for children_part , line_offset , last_line_offset_leaf in self . children_groups : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> _update_positions ( children_part , line_offset , last_line_offset_leaf ) <TAB><TAB><TAB> except _PositionUpdatingFinished : <TAB><TAB><TAB><TAB> pass <TAB><TAB> children + = children_part <TAB> self . tree_node . children = children <TAB> # Reset the parents <TAB> for node in children : <TAB><TAB> node . parent = self . tree_node",if line_offset != 0 :,if children_part :,94.37833840480248,95.86,False
790,"def get_multi ( self , keys , index = None ) : <TAB> with self . _lmdb . begin ( ) as txn : <TAB><TAB> result = [ ] <TAB><TAB> for key in keys : <TAB><TAB><TAB> packed = txn . get ( key . encode ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result . append ( ( key , cbor . loads ( packed ) ) ) <TAB> return result",if packed is not None :,if packed :,70.93037497965123,96.12,False
791,"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB><TAB> if p [ 0 ] != "" . "" : <TAB><TAB><TAB> subp = os . path . join ( pth , p ) <TAB><TAB><TAB> p = os . path . join ( prefix , p ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> res . append ( [ p , None ] ) <TAB> return res",if recursive and os . path . isdir ( subp ) :,if recursive :,74.25038378722643,94.61,False
792,"def __schedule ( self , workflow_scheduler_id , workflow_scheduler ) : <TAB> invocation_ids = self . __active_invocation_ids ( workflow_scheduler_id ) <TAB> for invocation_id in invocation_ids : <TAB><TAB> log . debug ( "" Attempting to schedule workflow invocation [ %s ] "" , invocation_id ) <TAB><TAB> self . __attempt_schedule ( invocation_id , workflow_scheduler ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return",if not self . monitor_running :,if self . __is_running ( invocation_id ) :,62.93994759539914,90.69,False
793,"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB><TAB> self . data . append ( data ) <TAB> else : <TAB><TAB> if self . size : <TAB><TAB><TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB><TAB> else : <TAB><TAB><TAB> passon = b "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . data . append ( data ) <TAB> return passon",if data :,if data :,100.0,100.00,True
794,"def __getstate__ ( self ) : <TAB> try : <TAB><TAB> store_func , load_func = self . store_function , self . load_function <TAB><TAB> self . store_function , self . load_function = None , None <TAB><TAB> # ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly <TAB><TAB> # added analyses classes <TAB><TAB> d = dict ( <TAB><TAB><TAB> ( k , v ) <TAB><TAB><TAB> for k , v in self . __dict__ . items ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> not in { <TAB><TAB><TAB><TAB> "" analyses "" , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB><TAB> return d <TAB> finally : <TAB><TAB> self . store_function , self . load_function = store_func , load_func",if k,"if k . startswith ( ""analyses"" )",98.29091587736526,96.52,False
795,"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB><TAB> if self . scrolling : <TAB><TAB><TAB> p = event . local <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . scroll_up ( ) <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB> self . scroll_down ( ) <TAB><TAB><TAB><TAB> return <TAB> if event . button == 4 : <TAB><TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB><TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",if self . scroll_up_rect ( ) . collidepoint ( p ) :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,100.0,100.00,True
796,"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB><TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB><TAB><TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB><TAB> if self . _prompt is None : <TAB><TAB><TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB><TAB> choice = data [ "" choice "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return flask . abort ( <TAB><TAB><TAB><TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB><TAB><TAB> ) <TAB><TAB> self . _answer_prompt ( choice )","if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",if not choice :,63.37441787320597,90.40,False
797,"def register_predictors ( self , model_data_arr ) : <TAB> for integration in self . _get_integrations ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> integration . register_predictors ( model_data_arr ) <TAB><TAB> else : <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> f "" There is no connection to  { integration . name } . predictor wouldn ' t be registred. "" <TAB><TAB><TAB> )",if integration . check_connection ( ) :,if integration . name in model_data_arr :,94.52719296317717,93.61,False
798,"def _pack_shears ( shearData ) : <TAB> shears = list ( ) <TAB> vidxs = list ( ) <TAB> for e_idx , entry in enumerate ( shearData ) : <TAB><TAB> # Should be 3 entries <TAB><TAB> <MASK> <TAB><TAB><TAB> shears . extend ( [ float ( "" nan "" ) , float ( "" nan "" ) ] ) <TAB><TAB><TAB> vidxs . extend ( [ 0 , 0 ] ) <TAB><TAB> else : <TAB><TAB><TAB> vidx1 , vidx2 , shear1 , shear2 = entry <TAB><TAB><TAB> shears . extend ( [ shear1 , shear2 ] ) <TAB><TAB><TAB> vidxs . extend ( [ vidx1 , vidx2 ] ) <TAB> return ( np . asarray ( shears , dtype = np . float32 ) , np . asarray ( vidxs , dtype = np . uint32 ) )",if entry is None :,if len ( entry ) == 3 :,97.62095890957814,96.02,False
799,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB> fpath = _dir / "" settings.json "" <TAB><TAB> if not fpath . exists ( ) : <TAB><TAB><TAB> continue <TAB><TAB> with fpath . open ( ) as f : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> data = json . load ( f ) <TAB><TAB><TAB> except json . JSONDecodeError : <TAB><TAB><TAB><TAB> continue <TAB><TAB> if not isinstance ( data , dict ) : <TAB><TAB><TAB> continue <TAB><TAB> cog_name = _dir . stem <TAB><TAB> for cog_id , inner in data . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield cog_name , cog_id","if not isinstance ( inner , dict ) :",if not inner :,69.50219070961067,97.31,False
800,"def subFeaName ( m , newNames , state ) : <TAB> try : <TAB><TAB> int ( m [ 3 ] , 16 ) <TAB> except : <TAB><TAB> return m [ 0 ] <TAB> name = m [ 2 ] <TAB> if name in newNames : <TAB><TAB> # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" sub  %r  =>  %r "" % ( m [ 0 ] , m [ 1 ] + newNames [ name ] + m [ 4 ] ) ) <TAB><TAB> state [ "" didChange "" ] = True <TAB><TAB> return m [ 1 ] + newNames [ name ] + m [ 4 ] <TAB> return m [ 0 ]","if name == ""uni0402"" :","if state [ ""didChange"" ] :",98.04515786537462,96.50,False
801,"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB><TAB> if input_array is None : <TAB><TAB><TAB> input_array = model . example_input_array <TAB><TAB> <MASK> <TAB><TAB><TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB><TAB><TAB> self . experiment . add_graph ( model , input_array ) <TAB><TAB> else : <TAB><TAB><TAB> rank_zero_warn ( <TAB><TAB><TAB><TAB> "" Could not log computational graph since the "" <TAB><TAB><TAB><TAB> ""  `model.example_input_array` attribute is not set "" <TAB><TAB><TAB><TAB> ""  or `input_array` was not given "" , <TAB><TAB><TAB><TAB> UserWarning , <TAB><TAB><TAB> )",if input_array is not None :,"elif isinstance ( input_array , ( list , tuple ) ) :",93.26947149908302,94.80,False
802,"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> if family : <TAB><TAB><TAB> for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB> if event_ref : <TAB><TAB><TAB><TAB><TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB><TAB> if not event . get_date_object ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if not event . get_place_handle ( ) :,if not event . get_date_object ( ) :,97.43390084958297,98.18,False
803,"def format ( m ) : <TAB> if m > 1000 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( str ( int ( m / 1000 ) ) , "" km "" ) <TAB><TAB> else : <TAB><TAB><TAB> return ( str ( round ( m / 1000 , 1 ) ) , "" km "" ) <TAB> return ( str ( m ) , "" m "" )",if m % 1000 == 0 :,if m % 1000 == 0 :,75.0,100.00,True
804,"def previous ( self ) : <TAB> try : <TAB><TAB> idx = _jump_list_index <TAB><TAB> next_index = idx + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> next_index = 100 <TAB><TAB> next_index = min ( len ( _jump_list ) - 1 , next_index ) <TAB><TAB> _jump_list_index = next_index <TAB><TAB> return _jump_list [ next_index ] <TAB> except ( IndexError , KeyError ) as e : <TAB><TAB> return None",if next_index > 100 :,if next_index > 100 :,100.0,100.00,True
805,"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name , definition in self . hyperparameter_definitions . items ( ) : <TAB><TAB> if name not in self . hyperparam_dict : <TAB><TAB><TAB> spec = definition [ "" spec "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB><TAB><TAB> elif "" IsRequired "" in spec and spec [ "" IsRequired "" ] : <TAB><TAB><TAB><TAB> raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name )","if ""DefaultValue"" in spec :","if ""DefaultValue"" in spec and spec [ ""DefaultValue"" ] :",98.2611787736506,95.86,False
806,"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB><TAB> # take action <TAB><TAB> if self . action_input . selected_index == 0 : # Cancel <TAB><TAB><TAB> self . back_to_parent ( ) <TAB><TAB> <MASK> # Apply <TAB><TAB><TAB> self . _apply_prefs ( ) <TAB><TAB><TAB> client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB><TAB> elif self . action_input . selected_index == 2 : # OK <TAB><TAB><TAB> self . _apply_prefs ( ) <TAB><TAB><TAB> self . back_to_parent ( )",elif self . action_input . selected_index == 1 :,"elif c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] :",95.52199825319046,92.96,False
807,"def _split_anonymous_function ( s ) : <TAB> # Regex is not sufficient to handle differences between anonymous <TAB> # functions and YAML encoded lists. We perform a sniff test to see <TAB> # if it might be an anonymous function and then confirm by <TAB> # decoding it as YAML and testing the result. <TAB> if s [ : 1 ] == "" [ "" and s [ - 1 : ] == "" ] "" and "" : "" in s : <TAB><TAB> try : <TAB><TAB><TAB> l = yaml_util . decode_yaml ( s ) <TAB><TAB> except Exception : <TAB><TAB><TAB> return None , s [ 1 : - 1 ] <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None , s [ 1 : - 1 ] <TAB> return None","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :","if l [ : 1 ] == ""anonymous"" :",67.72771220795887,89.09,False
808,"def test_source_address ( self ) : <TAB> for addr , is_ipv6 in VALID_SOURCE_ADDRESSES : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( "" No IPv6 support: skipping. "" , NoIPv6Warning ) <TAB><TAB><TAB> continue <TAB><TAB> pool = HTTPConnectionPool ( <TAB><TAB><TAB> self . host , self . port , source_address = addr , retries = False <TAB><TAB> ) <TAB><TAB> self . addCleanup ( pool . close ) <TAB><TAB> r = pool . request ( "" GET "" , "" /source_address "" ) <TAB><TAB> self . assertEqual ( r . data , b ( addr [ 0 ] ) )",if is_ipv6 and not HAS_IPV6_AND_DNS :,if not is_ipv6 :,91.9305428385577,93.41,False
809,"def vim_G ( self ) : <TAB> """"""Put the cursor on the last character of the file."""""" <TAB> if self . is_text_wrapper ( self . w ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . do ( "" end-of-buffer-extend-selection "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . do ( "" end-of-buffer "" ) <TAB><TAB> self . done ( ) <TAB> else : <TAB><TAB> self . quit ( )","if self . state == ""visual"" :",if self . is_extend_selection ( ) :,69.29157592910622,93.42,False
810,"def backend_supported ( module , manager , * * kwargs ) : <TAB> if CollectionNodeModule . backend_supported ( module , manager , * * kwargs ) : <TAB><TAB> if "" tid "" not in kwargs : <TAB><TAB><TAB> return True <TAB><TAB> conn = manager . connection ( did = kwargs [ "" did "" ] ) <TAB><TAB> template_path = "" partitions/sql/ {0} /# {0} # {1} # "" . format ( <TAB><TAB><TAB> manager . server_type , manager . version <TAB><TAB> ) <TAB><TAB> SQL = render_template ( <TAB><TAB><TAB> "" / "" . join ( [ template_path , "" backend_support.sql "" ] ) , tid = kwargs [ "" tid "" ] <TAB><TAB> ) <TAB><TAB> status , res = conn . execute_scalar ( SQL ) <TAB><TAB> # check if any errors <TAB><TAB> <MASK> <TAB><TAB><TAB> return internal_server_error ( errormsg = res ) <TAB><TAB> return res",if not status :,if status != 200 :,98.56423096508222,97.98,False
811,"def _get_regex_config ( self , data_asset_name : Optional [ str ] = None ) - > dict : <TAB> regex_config : dict = copy . deepcopy ( self . _default_regex ) <TAB> asset : Optional [ Asset ] = None <TAB> if data_asset_name : <TAB><TAB> asset = self . _get_asset ( data_asset_name = data_asset_name ) <TAB> if asset is not None : <TAB><TAB> # Override the defaults <TAB><TAB> <MASK> <TAB><TAB><TAB> regex_config [ "" pattern "" ] = asset . pattern <TAB><TAB> if asset . group_names : <TAB><TAB><TAB> regex_config [ "" group_names "" ] = asset . group_names <TAB> return regex_config",if asset . pattern :,if asset . pattern :,100.0,100.00,True
812,"def resolve ( self , other ) : <TAB> if other == ANY_TYPE : <TAB><TAB> return self <TAB> elif isinstance ( other , ComplexType ) : <TAB><TAB> f = self . first . resolve ( other . first ) <TAB><TAB> s = self . second . resolve ( other . second ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ComplexType ( f , s ) <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> elif self == ANY_TYPE : <TAB><TAB> return other <TAB> else : <TAB><TAB> return None",if f and s :,if f is not None and s is not None :,69.34711474378223,94.39,False
813,"def collect_pages ( app ) : <TAB> new_images = { } <TAB> for full_path , basename in app . builder . images . iteritems ( ) : <TAB><TAB> base , ext = os . path . splitext ( full_path ) <TAB><TAB> retina_path = base + "" @2x "" + ext <TAB><TAB> <MASK> <TAB><TAB><TAB> new_images [ retina_path ] = app . env . images [ retina_path ] [ 1 ] <TAB> app . builder . images . update ( new_images ) <TAB> return [ ]",if retina_path in app . env . images :,if retina_path in app . env . images :,100.0,100.00,True
814,"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB><TAB> if _has_newline ( header ) : <TAB><TAB><TAB> return True <TAB> if self . subject : <TAB><TAB> if _has_newline ( self . subject ) : <TAB><TAB><TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if linenum > 0 and line [ 0 ] not in "" \t   "" : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if len ( line . strip ( ) ) == 0 : <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if not line :,"if linenum == 0 and line [ 0 ] in ""\r\n"" :",96.15958514559347,94.16,False
815,"def reader ( ) : <TAB> try : <TAB><TAB> imgs = mp4_loader ( video_path , seg_num , seglen , mode ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . error ( <TAB><TAB><TAB><TAB> "" {}  frame length  {}  less than 1. "" . format ( video_path , len ( imgs ) ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> yield None , None <TAB> except : <TAB><TAB> logger . error ( "" Error when loading  {} "" . format ( mp4_path ) ) <TAB><TAB> yield None , None <TAB> imgs_ret = imgs_transform ( <TAB><TAB> imgs , mode , seg_num , seglen , short_size , target_size , img_mean , img_std <TAB> ) <TAB> label_ret = video_path <TAB> yield imgs_ret , label_ret",if len ( imgs ) < 1 :,if len ( imgs ) < 1 :,100.0,100.00,True
816,"def translate_from_sortname ( name , sortname ) : <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name : <TAB><TAB> ctg = unicodedata . category ( c ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB><TAB><TAB><TAB> if separator in sortname : <TAB><TAB><TAB><TAB><TAB> parts = sortname . split ( separator ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> parts = [ sortname ] <TAB><TAB><TAB><TAB> separator = "" "" <TAB><TAB><TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name","if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :","if ctg == ""all"" :",67.36839677587811,89.54,False
817,"def _to_local_path ( path ) : <TAB> """"""Convert local path to SFTP path"""""" <TAB> if sys . platform == "" win32 "" : # pragma: no cover <TAB><TAB> path = os . fsdecode ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> path = path [ 1 : ] <TAB><TAB> path = path . replace ( "" / "" , "" \\ "" ) <TAB> return path","if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :","if path [ 0 ] == ""/"" :",90.93794697178966,86.94,False
818,"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB><TAB> if t == "" tacotron "" : <TAB><TAB><TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = jaconv . normalize ( text ) <TAB><TAB> elif t == "" vietnamese "" : <TAB><TAB><TAB> if vietnamese_cleaners is None : <TAB><TAB><TAB><TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB><TAB><TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB><TAB> else : <TAB><TAB><TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text","elif t == ""jaconv"" :","elif t == ""jaconv"" :",100.0,100.00,True
819,"def cb_syncthing_system_data ( self , daemon , mem , cpu , d_failed , d_total ) : <TAB> if self . daemon . get_my_id ( ) in self . devices : <TAB><TAB> # Update my device display <TAB><TAB> device = self . devices [ self . daemon . get_my_id ( ) ] <TAB><TAB> device [ "" ram "" ] = sizeof_fmt ( mem ) <TAB><TAB> device [ "" cpu "" ] = "" %3.2f %% "" % ( cpu ) <TAB><TAB> <MASK> <TAB><TAB><TAB> device [ "" announce "" ] = _ ( "" disabled "" ) <TAB><TAB> else : <TAB><TAB><TAB> device [ "" announce "" ] = "" %s / %s "" % ( d_total - d_failed , d_total )",if d_total == 0 :,if d_failed == 0 :,98.9716329743721,98.76,False
820,"def update_kls ( self , sampled_kls ) : <TAB> for i , kl in enumerate ( sampled_kls ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . kl_coeff_val [ i ] * = 0.5 <TAB><TAB> elif kl > 1.5 * self . kl_target : <TAB><TAB><TAB> self . kl_coeff_val [ i ] * = 2.0 <TAB> return self . kl_coeff_val",if kl < self . kl_target / 1.5 :,if kl < 0.5 * self . kl_target :,86.53778997970879,95.59,False
821,"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB><TAB> f = True <TAB><TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB><TAB><TAB> if self . FindItemAtPosition ( ( r , c ) ) is not None : <TAB><TAB><TAB><TAB> f = False <TAB><TAB> <MASK> <TAB><TAB><TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB><TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB><TAB> cols2delete = [ x - 1 for x in cols2delete ]",if f :,if f :,100.0,100.00,True
822,"def get_session ( self ) : <TAB> if self . _session is None : <TAB><TAB> session = super ( ChildResourceManager , self ) . get_session ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> session = session . get_session_for_resource ( self . resource_type . resource ) <TAB><TAB> self . _session = session <TAB> return self . _session",if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,if self . resource_type :,67.75039557101915,88.31,False
823,"def _get_master_authorized_networks_config ( self , raw_cluster ) : <TAB> if raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) : <TAB><TAB> config = raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) <TAB><TAB> config [ "" includes_public_cidr "" ] = False <TAB><TAB> for block in config [ "" cidrBlocks "" ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> config [ "" includes_public_cidr "" ] = True <TAB><TAB> return config <TAB> else : <TAB><TAB> return { "" enabled "" : False , "" cidrBlocks "" : [ ] , "" includes_public_cidr "" : False }","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :","if block [ ""enabled"" ] :",93.81937726471912,93.85,False
824,"def scan_folder ( folder ) : <TAB> scanned_files = [ ] <TAB> for root , dirs , files in os . walk ( folder ) : <TAB><TAB> dirs [ : ] = [ d for d in dirs if d != "" __pycache__ "" ] <TAB><TAB> relative_path = os . path . relpath ( root , folder ) <TAB><TAB> for f in files : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> relative_name = os . path . normpath ( os . path . join ( relative_path , f ) ) . replace ( <TAB><TAB><TAB><TAB> "" \\ "" , "" / "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> scanned_files . append ( relative_name ) <TAB> return sorted ( scanned_files )","if f . endswith ( "".pyc"" ) :","if f == ""__pycache__"" :",95.08647148174877,95.46,False
825,"def read_progress ( self ) : <TAB> while True : <TAB><TAB> processed_file = self . queue . get ( ) <TAB><TAB> self . threading_completed . append ( processed_file ) <TAB><TAB> total_number = len ( self . file_list ) <TAB><TAB> completed_number = len ( self . threading_completed ) <TAB><TAB> # Just for the record, this slows down book searching by about 20% <TAB><TAB> if _progress_emitter : # Skip update in reading mode <TAB><TAB><TAB> _progress_emitter . update_progress ( completed_number * 100 / / total_number ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if total_number == completed_number :,if completed_number == total_number :,97.87283034853718,98.00,False
826,"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> if parser . is_quoted ( ) : <TAB><TAB><TAB> parser . read_line ( line ) <TAB><TAB><TAB> continue <TAB><TAB> parser . read_line ( line ) <TAB><TAB> if not line . strip ( ) : # empty line <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB> return True <TAB><TAB> if line . startswith ( ( "" # "" , "" @ "" , ""   "" , "" ) "" ) ) : <TAB><TAB><TAB> continue <TAB><TAB> return False <TAB> return False",if i > 0 and not lines [ i - 1 ] . strip ( ) :,if i == 0 :,95.0181661831241,94.40,False
827,def __next__ ( self ) : <TAB> try : <TAB><TAB> data = next ( self . iter_loader ) <TAB> except StopIteration : <TAB><TAB> self . _epoch + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _dataloader . sampler . set_epoch ( self . _epoch ) <TAB><TAB> self . iter_loader = iter ( self . _dataloader ) <TAB><TAB> data = next ( self . iter_loader ) <TAB> return data,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",if self . _epoch % self . _dataloader . sampler . get_num,68.42319588500187,90.98,False
828,"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB><TAB> data = zip ( * data ) <TAB><TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB><TAB> if dt is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB><TAB><TAB> elif isinstance ( dt , nd . NDArray ) : <TAB><TAB><TAB><TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB><TAB><TAB><TAB> data_list = [ dt for dt in data if dt is not None ] <TAB><TAB><TAB><TAB> return pad ( data_list )","if isinstance ( dt , dgl . DGLGraph ) :","if isinstance ( dt , dgl . DGLGraph ) :",100.0,100.00,True
829,"def f ( self , info ) : <TAB> for k in keys : <TAB><TAB> <MASK> <TAB><TAB><TAB> for k2 in list ( info . keys ( ) ) : <TAB><TAB><TAB><TAB> if k ( k2 ) : <TAB><TAB><TAB><TAB><TAB> info . pop ( k2 ) <TAB><TAB> else : <TAB><TAB><TAB> info . pop ( k , None )",if callable ( k ) :,if callable ( k ) :,75.0,100.00,True
830,"def create ( path , binary = False ) : <TAB> for i in range ( 10 ) : <TAB><TAB> try : <TAB><TAB><TAB> os . makedirs ( os . path . dirname ( path ) , exist_ok = True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return open ( path , "" wb "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return open ( path , "" w "" , encoding = "" utf-8 "" ) <TAB><TAB><TAB> if i > 0 : <TAB><TAB><TAB><TAB> log ( True , f "" Created  { path }  at attempt  { i + 1 } "" ) <TAB><TAB> except : <TAB><TAB><TAB> time . sleep ( 0.5 ) <TAB> else : <TAB><TAB> raise Error ( f "" Failed to create  { path } "" )",if binary :,if binary :,100.0,100.00,True
831,"def validate_update ( self , update_query ) : <TAB> structure = DotCollapsedDict ( self . doc_class . structure ) <TAB> for op , fields in update_query . iteritems ( ) : <TAB><TAB> for field in fields : <TAB><TAB><TAB> if op != "" $unset "" and op != "" $rename "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise UpdateQueryError ( <TAB><TAB><TAB><TAB><TAB><TAB> "" ' %s '  not found in  %s ' s structure "" <TAB><TAB><TAB><TAB><TAB><TAB> % ( field , self . doc_class . __name__ ) <TAB><TAB><TAB><TAB><TAB> )",if field not in structure :,if field not in structure :,100.0,100.00,True
832,"def check_enums_ATLAS_ISAEXT ( lines ) : <TAB> for i , isaext in enumerate ( ATLAS_ISAEXT ) : <TAB><TAB> got = lines . pop ( 0 ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> expect = "" none: 1 "" <TAB><TAB> else : <TAB><TAB><TAB> expect = "" {0} :  {1} "" . format ( isaext , 1 << i ) <TAB><TAB> if got != expect : <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" ATLAS_ISAEXT mismatch at position  "" <TAB><TAB><TAB><TAB> + str ( i ) <TAB><TAB><TAB><TAB> + "" : got >> "" <TAB><TAB><TAB><TAB> + got <TAB><TAB><TAB><TAB> + "" <<, expected >> "" <TAB><TAB><TAB><TAB> + expect <TAB><TAB><TAB><TAB> + "" << "" <TAB><TAB><TAB> )",if i == 0 :,if not got :,96.72595712832486,97.93,False
833,"def _test_export_session_csv ( self , test_session = None ) : <TAB> with self . app . test_request_context ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> test_session = SessionFactory ( ) <TAB><TAB> field_data = export_sessions_csv ( [ test_session ] ) <TAB><TAB> session_row = field_data [ 1 ] <TAB><TAB> self . assertEqual ( session_row [ 0 ] , "" example (accepted) "" ) <TAB><TAB> self . assertEqual ( session_row [ 9 ] , "" accepted "" )",if not test_session :,if not test_session :,100.0,100.00,True
834,"def get_report_to_platform ( self , args , scan_reports ) : <TAB> if self . bc_api_key : <TAB><TAB> <MASK> <TAB><TAB><TAB> repo_id = self . get_repository ( args ) <TAB><TAB><TAB> self . setup_bridgecrew_credentials ( <TAB><TAB><TAB><TAB> bc_api_key = self . bc_api_key , repo_id = repo_id <TAB><TAB><TAB> ) <TAB><TAB> if self . is_integration_configured ( ) : <TAB><TAB><TAB> self . _upload_run ( args , scan_reports )",if args . directory :,if self . is_bridgecrew_enabled ( ) :,92.79786258371392,93.80,False
835,"def test_fvalue ( self ) : <TAB> if not getattr ( self , "" skip_f "" , False ) : <TAB><TAB> rtol = getattr ( self , "" rtol "" , 1e-10 ) <TAB><TAB> assert_allclose ( self . res1 . fvalue , self . res2 . F , rtol = rtol ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # only available with ivreg2 <TAB><TAB><TAB> assert_allclose ( self . res1 . f_pvalue , self . res2 . Fp , rtol = rtol ) <TAB> else : <TAB><TAB> raise pytest . skip ( "" TODO: document why this test is skipped "" )","if hasattr ( self . res2 , ""Fp"" ) :","if hasattr ( self , ""ivreg2"" ) :",90.99854374436273,96.36,False
836,"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB><TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB> if e . value is None : <TAB><TAB><TAB><TAB><TAB> e . value = [ ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> e . value = e . value . split ( ) <TAB><TAB><TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB> e . value = 0 <TAB> return self",elif type ( e . value ) is not list :,if type ( e . value ) is str :,89.0454673571645,97.62,False
837,"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB><TAB> try : <TAB><TAB><TAB> self . parent ( ) . touch ( ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> pass <TAB><TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB><TAB> if not node . isdir : <TAB><TAB><TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . watcher . emit ( "" created "" , self )",if self . watcher :,if self . _fs . create ( node ) :,69.94504907821883,94.59,False
838,"def __init__ ( self , _inf = None , _tzinfos = None ) : <TAB> if _inf : <TAB><TAB> self . _tzinfos = _tzinfos <TAB><TAB> self . _utcoffset , self . _dst , self . _tzname = _inf <TAB> else : <TAB><TAB> _tzinfos = { } <TAB><TAB> self . _tzinfos = _tzinfos <TAB><TAB> self . _utcoffset , self . _dst , self . _tzname = self . _transition_info [ 0 ] <TAB><TAB> _tzinfos [ self . _transition_info [ 0 ] ] = self <TAB><TAB> for inf in self . _transition_info [ 1 : ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _tzinfos [ inf ] = self . __class__ ( inf , _tzinfos )",if not _tzinfos . has_key ( inf ) :,if inf not in _tzinfos :,78.11126356349615,95.17,False
839,"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> with _file . open ( ) as f : <TAB><TAB><TAB><TAB> if comment not in f . read ( ) : <TAB><TAB><TAB><TAB><TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB><TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB><TAB> for error in errors : <TAB><TAB><TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB><TAB> print ( line [ : - 1 ] ) <TAB><TAB> assert False","if _file . suffix == "".py"" and _file . name not in skip_files :","if _file . suffix == "".py"" and _file . suffix == "".py"" and",69.26355069680376,96.22,False
840,"def http_get ( url , target ) : <TAB> req = requests . get ( url , stream = True ) <TAB> content_length = req . headers . get ( "" Content-Length "" ) <TAB> total = int ( content_length ) if content_length is not None else None <TAB> progress = tqdm ( unit = "" B "" , total = total ) <TAB> with open ( target , "" wb "" ) as target_file : <TAB><TAB> for chunk in req . iter_content ( chunk_size = 1024 ) : <TAB><TAB><TAB> <MASK> # filter out keep-alive new chunks <TAB><TAB><TAB><TAB> progress . update ( len ( chunk ) ) <TAB><TAB><TAB><TAB> target_file . write ( chunk ) <TAB> progress . close ( )",if chunk :,if chunk :,100.0,100.00,True
841,"def _elements_to_datasets ( self , elements , level = 0 ) : <TAB> for element in elements : <TAB><TAB> extra_kwds = { "" identifier_ %d "" % level : element [ "" name "" ] } <TAB><TAB> <MASK> <TAB><TAB><TAB> for inner_element in self . _elements_to_datasets ( <TAB><TAB><TAB><TAB> element [ "" elements "" ] , level = level + 1 <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> dataset = extra_kwds . copy ( ) <TAB><TAB><TAB><TAB> dataset . update ( inner_element ) <TAB><TAB><TAB><TAB> yield dataset <TAB><TAB> else : <TAB><TAB><TAB> dataset = extra_kwds <TAB><TAB><TAB> extra_kwds . update ( element ) <TAB><TAB><TAB> yield extra_kwds","if ""elements"" in element :","if ""elements"" in element :",100.0,100.00,True
842,"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB><TAB> if value is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> a [ key ] = value <TAB><TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB><TAB><TAB> update_dict ( a [ key ] , value ) <TAB><TAB> elif isinstance ( a [ key ] , list ) : <TAB><TAB><TAB> a [ key ] . append ( value ) <TAB><TAB> else : <TAB><TAB><TAB> a [ key ] = [ a [ key ] , value ]",if key not in a :,"if isinstance ( a [ key ] , list ) :",95.05344561224499,94.57,False
843,"def scan ( self , targets ) : <TAB> for target in targets : <TAB><TAB> target . print_infos ( ) <TAB><TAB> if self . is_interesting ( target ) : <TAB><TAB><TAB> self . target [ "" other "" ] . append ( target ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return target <TAB> return None",if self . match ( target ) :,"if self . target [ ""other"" ] :",68.85204206510404,92.97,False
844,"def printConnections ( switches ) : <TAB> "" Compactly print connected nodes to each switch "" <TAB> for sw in switches : <TAB><TAB> output ( "" %s :  "" % sw ) <TAB><TAB> for intf in sw . intfList ( ) : <TAB><TAB><TAB> link = intf . link <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> intf1 , intf2 = link . intf1 , link . intf2 <TAB><TAB><TAB><TAB> remote = intf1 if intf1 . node != sw else intf2 <TAB><TAB><TAB><TAB> output ( "" %s ( %s )  "" % ( remote . node , sw . ports [ intf ] ) ) <TAB><TAB> output ( "" \n "" )",if link :,if link :,100.0,100.00,True
845,"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i , char in enumerate ( sentence ) : <TAB><TAB> pos = pos_list [ i ] <TAB><TAB> if pos == "" B "" : <TAB><TAB><TAB> begin = i <TAB><TAB> <MASK> <TAB><TAB><TAB> yield sentence [ begin : i + 1 ] <TAB><TAB><TAB> nexti = i + 1 <TAB><TAB> elif pos == "" S "" : <TAB><TAB><TAB> yield char <TAB><TAB><TAB> nexti = i + 1 <TAB> if nexti < len ( sentence ) : <TAB><TAB> yield sentence [ nexti : ]","elif pos == ""E"" :","elif pos == ""C"" :",99.00239803152061,98.88,False
846,"def check_files ( self , paths = None ) : <TAB> """"""Run all checks on the paths."""""" <TAB> if paths is None : <TAB><TAB> paths = self . paths <TAB> report = self . options . report <TAB> runner = self . runner <TAB> report . start ( ) <TAB> try : <TAB><TAB> for path in paths : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . input_dir ( path ) <TAB><TAB><TAB> elif not self . excluded ( path ) : <TAB><TAB><TAB><TAB> runner ( path ) <TAB> except KeyboardInterrupt : <TAB><TAB> print ( "" ... stopped "" ) <TAB> report . stop ( ) <TAB> return report",if os . path . isdir ( path ) :,if self . is_dir ( path ) :,95.66833889018633,96.78,False
847,"def verts_of_loop ( edge_loop ) : <TAB> verts = [ ] <TAB> for e0 , e1 in iter_pairs ( edge_loop , False ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> v0 = e0 . shared_vert ( e1 ) <TAB><TAB><TAB> verts + = [ e0 . other_vert ( v0 ) , v0 ] <TAB><TAB> verts + = [ e1 . other_vert ( verts [ - 1 ] ) ] <TAB> if len ( verts ) > 1 and verts [ 0 ] == verts [ - 1 ] : <TAB><TAB> return verts [ : - 1 ] <TAB> return verts",if not verts :,if e0 . shared_vert ( e1 ) :,68.97743791135684,94.04,False
848,"def generator ( self , data ) : <TAB> for task in data : <TAB><TAB> # Do we scan everything or just /bin/bash instances? <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for bucket in task . bash_hash_entries ( ) : <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> int ( task . p_pid ) , <TAB><TAB><TAB><TAB><TAB> str ( task . p_comm ) , <TAB><TAB><TAB><TAB><TAB> int ( bucket . times_found ) , <TAB><TAB><TAB><TAB><TAB> str ( bucket . key ) , <TAB><TAB><TAB><TAB><TAB> str ( bucket . data . path ) , <TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB> )","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",if not task . is_active ( ) :,92.838003350768,91.40,False
849,"def __get_ratio ( self ) : <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB><TAB> w = free_layout . get_main_splitter ( ) <TAB><TAB> if w : <TAB><TAB><TAB> aList = w . sizes ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> n1 , n2 = aList <TAB><TAB><TAB><TAB> # 2017/06/07: guard against division by zero. <TAB><TAB><TAB><TAB> ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB><TAB><TAB><TAB> return ratio <TAB> return 0.5",if len ( aList ) == 2 :,if len ( aList ) == 3 :,98.74848367649116,98.81,False
850,"def geterrors ( self ) : <TAB> """"""Get all error messages."""""" <TAB> notes = self . getnotes ( origin = "" translator "" ) . split ( "" \n "" ) <TAB> errordict = { } <TAB> for note in notes : <TAB><TAB> <MASK> <TAB><TAB><TAB> error = note . replace ( "" (pofilter)  "" , "" "" ) <TAB><TAB><TAB> errorname , errortext = error . split ( "" :  "" , 1 ) <TAB><TAB><TAB> errordict [ errorname ] = errortext <TAB> return errordict","if ""(pofilter) "" in note :","if note . startswith ( ""pofilter"" ) :",94.25635779870196,94.21,False
851,"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB><TAB> if d in [ "" . "" , "" .. "" ] : <TAB><TAB><TAB> continue <TAB><TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB><TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB><TAB> attr = self . getattr ( d_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . rename_path ( d_path , d_new_path ) <TAB><TAB> else : <TAB><TAB><TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True )","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :","if isinstance ( attr , dict ) :",76.44952501989587,94.34,False
852,"def index ( self , url_id : int ) - > FlaskResponse : # pylint: disable=no-self-use <TAB> url = db . session . query ( models . Url ) . get ( url_id ) <TAB> if url and url . url : <TAB><TAB> explore_url = "" //superset/explore/? "" <TAB><TAB> <MASK> <TAB><TAB><TAB> explore_url + = f "" r= { url_id } "" <TAB><TAB><TAB> return redirect ( explore_url [ 1 : ] ) <TAB><TAB> return redirect ( url . url [ 1 : ] ) <TAB> flash ( "" URL to nowhere... "" , "" danger "" ) <TAB> return redirect ( "" / "" )",if url . url . startswith ( explore_url ) :,if url_id :,70.78995015817236,94.17,False
853,"def testShortCircuit ( self ) : <TAB> """"""Test that creation short-circuits to reuse existing references"""""" <TAB> sd = { } <TAB> for s in self . ss : <TAB><TAB> sd [ s ] = 1 <TAB> for t in self . ts : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertTrue ( sd . has_key ( safeRef ( t . x ) ) ) <TAB><TAB><TAB> self . assertTrue ( safeRef ( t . x ) in sd ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertTrue ( sd . has_key ( safeRef ( t ) ) ) <TAB><TAB><TAB> self . assertTrue ( safeRef ( t ) in sd )","if hasattr ( t , ""x"" ) :","if isinstance ( t , Reference ) :",95.81443186253686,96.07,False
854,"def wrapped ( request , * args , * * kwargs ) : <TAB> if not request . user . is_authenticated ( ) : <TAB><TAB> request . session [ "" _next "" ] = request . get_full_path ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> redirect_uri = reverse ( <TAB><TAB><TAB><TAB> "" sentry-auth-organization "" , args = [ kwargs [ "" organization_slug "" ] ] <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> redirect_uri = get_login_url ( ) <TAB><TAB> return HttpResponseRedirect ( redirect_uri ) <TAB> return func ( request , * args , * * kwargs )","if ""organization_slug"" in kwargs :","if kwargs . get ( ""organization_slug"" ) :",76.90416840894008,95.64,False
855,"def read_info ( reader , dump = None ) : <TAB> line_number_table_length = reader . read_u2 ( ) <TAB> <MASK> <TAB><TAB> reader . debug ( <TAB><TAB><TAB> ""      "" * dump , "" Line numbers ( %s  total): "" % line_number_table_length <TAB><TAB> ) <TAB> line_numbers = [ ] <TAB> for i in range ( 0 , line_number_table_length ) : <TAB><TAB> start_pc = reader . read_u2 ( ) <TAB><TAB> line_number = reader . read_u2 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> reader . debug ( ""      "" * ( dump + 1 ) , "" %s :  %s "" % ( start_pc , line_number ) ) <TAB><TAB> line_numbers . append ( ( start_pc , line_number ) ) <TAB> return LineNumberTable ( line_numbers )",if dump is not None :,if dump :,68.99595902783277,96.10,False
856,"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB><TAB> for _ in XRANGE ( 10 ) : <TAB><TAB><TAB> t1 = timer ( ) <TAB><TAB><TAB> t2 = timer ( ) <TAB><TAB><TAB> dt = t2 - t1 <TAB><TAB><TAB> if 0 < dt : <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> dt = t2 - previous <TAB><TAB><TAB> if dt < = 0.0 : <TAB><TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> precision = min ( precision , dt ) <TAB><TAB> else : <TAB><TAB><TAB> precision = dt <TAB><TAB> points + = 1 <TAB><TAB> previous = timer ( ) <TAB> return precision",if precision is not None :,if precision :,77.10928862294266,98.30,False
857,def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB><TAB> pass <TAB> else : <TAB><TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB><TAB><TAB> if self . expr3 is None : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno,if self . expr2 is None :,if self . expr2 is None :,100.0,100.00,True
858,"def validate_cluster_resource_group ( cmd , namespace ) : <TAB> if namespace . cluster_resource_group is not None : <TAB><TAB> client = get_mgmt_service_client ( <TAB><TAB><TAB> cmd . cli_ctx , ResourceType . MGMT_RESOURCE_RESOURCES <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidArgumentValueError ( <TAB><TAB><TAB><TAB> "" Invalid --cluster-resource-group  ' %s ' : resource group must not exist. "" <TAB><TAB><TAB><TAB> % namespace . cluster_resource_group <TAB><TAB><TAB> )",if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,if not client . has_permission ( namespace . cluster_resource_group ) :,91.67406208983067,94.31,False
859,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB><TAB> <MASK> <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB> left - = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> done = False <TAB> while not done : <TAB><TAB> if right == len ( text ) : <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB> right + = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> return left , right",if left == 0 :,if left == 0 and self . word_boundary_char ( text [ left ] ) in,71.31143022675481,92.96,False
860,"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB><TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB><TAB> if len ( set ( lengths ) ) > 1 : <TAB><TAB><TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB><TAB> x_len = lengths [ 0 ] <TAB> else : <TAB><TAB> x_len = len ( X ) <TAB> if y is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB><TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y",if len ( y ) != x_len :,if x_len != len ( X ) :,81.22573548207014,96.64,False
861,"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB><TAB> if isinstance ( node , HtmlTag ) : <TAB><TAB><TAB> if node . tag_type == OPEN_TAG : <TAB><TAB><TAB><TAB> open_tags + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> open_tags - = 1 <TAB><TAB> elif ( <TAB><TAB><TAB> isinstance ( node , HtmlDataFragment ) <TAB><TAB><TAB> and node . is_text_content <TAB><TAB><TAB> and open_tags == 0 <TAB><TAB> ) : <TAB><TAB><TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text",elif node . tag_type == CLOSE_TAG :,elif node . tag_type == CLOSE_TAG :,100.0,100.00,True
862,"def _get_spyne_type ( cls_name , k , v ) : <TAB> try : <TAB><TAB> v = NATIVE_MAP . get ( v , v ) <TAB> except TypeError : <TAB><TAB> return <TAB> try : <TAB><TAB> subc = issubclass ( v , ModelBase ) or issubclass ( v , SelfReference ) <TAB> except : <TAB><TAB> subc = False <TAB> if subc : <TAB><TAB> if issubclass ( v , Array ) and len ( v . _type_info ) != 1 : <TAB><TAB><TAB> raise Exception ( "" Invalid Array definition in  %s . %s . "" % ( cls_name , k ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Please specify the number of dimensions "" ) <TAB><TAB> return v","elif issubclass ( v , Point ) and v . Attributes . dim is None :",if len ( v . _type_info ) != len ( v . _type_info,63.92146567520673,90.80,False
863,"def customize ( cls , * * kwargs ) : <TAB> """"""return a class with some existing attributes customized"""""" <TAB> for name , value in kwargs . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TransportError ( <TAB><TAB><TAB><TAB> "" you cannot customize the protected attribute  %s "" % name <TAB><TAB><TAB> ) <TAB><TAB> if not hasattr ( cls , name ) : <TAB><TAB><TAB> raise TransportError ( "" Transport has no attribute  %s "" % name ) <TAB> NewSubClass = type ( "" Customized_ {} "" . format ( cls . __name__ ) , ( cls , ) , kwargs ) <TAB> return NewSubClass","if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :","if name . startswith ( ""_"" ) :",87.63294552007585,87.74,False
864,"def test_UNrelativize ( self ) : <TAB> import URIlib <TAB> relative = self . relative + self . full_relativize <TAB> for base , rel , fullpath , common in relative : <TAB><TAB> URI = uriparse . UnRelativizeURL ( base , rel ) <TAB><TAB> fullURI = URIlib . URIParser ( URI ) <TAB><TAB> # We need to canonicalize the result from unrelativize <TAB><TAB> # compared to the original full path we expect to see. <TAB><TAB> <MASK> <TAB><TAB><TAB> fullpath = fullpath [ : - 1 ] <TAB><TAB> self . failUnlessSamePath ( <TAB><TAB><TAB> os . path . normcase ( fullURI . path ) , os . path . normcase ( fullpath ) <TAB><TAB> )","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :","if common == ""same"" :",94.75474356967777,90.87,False
865,"def get_release_info ( file_path = RELEASE_FILE ) : <TAB> RELEASE_TYPE_REGEX = re . compile ( r "" ^[Rr]elease [Tt]ype: (major|minor|patch)$ "" ) <TAB> with open ( file_path , "" r "" ) as f : <TAB><TAB> line = f . readline ( ) <TAB><TAB> match = RELEASE_TYPE_REGEX . match ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" The file RELEASE.md should start with `Release type`  "" <TAB><TAB><TAB><TAB> "" and specify one of the following values: major, minor or patch. "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> sys . exit ( 1 ) <TAB><TAB> type_ = match . group ( 1 ) <TAB><TAB> changelog = "" "" . join ( [ line for line in f . readlines ( ) ] ) . strip ( ) <TAB> return type_ , changelog",if not match :,if not match :,100.0,100.00,True
866,"def _get_next_history_entry ( self ) : <TAB> if self . _history : <TAB><TAB> hist_len = len ( self . _history ) - 1 <TAB><TAB> self . history_index = min ( hist_len , self . history_index + 1 ) <TAB><TAB> index = self . history_index <TAB><TAB> <MASK> <TAB><TAB><TAB> self . history_index + = 1 <TAB><TAB> return self . _history [ index ] <TAB> return "" """,if self . history_index == hist_len :,if self . _history [ index ] :,66.65812378458382,93.42,False
867,"def star_op ( self ) : <TAB> """"""Put a '*' op, with special cases for *args."""""" <TAB> val = "" * "" <TAB> if self . paren_level : <TAB><TAB> i = len ( self . code_list ) - 1 <TAB><TAB> if self . code_list [ i ] . kind == "" blank "" : <TAB><TAB><TAB> i - = 1 <TAB><TAB> token = self . code_list [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . op_no_blanks ( val ) <TAB><TAB> elif token . value == "" , "" : <TAB><TAB><TAB> self . blank ( ) <TAB><TAB><TAB> self . add_token ( "" op-no-blanks "" , val ) <TAB><TAB> else : <TAB><TAB><TAB> self . op ( val ) <TAB> else : <TAB><TAB> self . op ( val )","if token . kind == ""lt"" :","if token . value == ""*"" :",73.35814284643124,97.94,False
868,"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if HIDDEN_SETTINGS . search ( k ) : <TAB><TAB><TAB><TAB> settings_dict [ k ] = "" ******************** "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict",if k . isupper ( ) :,"if k . startswith ( ""_"" ) :",94.97881758515875,96.21,False
869,"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB><TAB> if len ( self . _editableChildren ) : <TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB><TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB> nei = cei + 1 <TAB><TAB><TAB><TAB> if nei > = len ( self . _editableChildren ) : <TAB><TAB><TAB><TAB><TAB> nei = 0 <TAB><TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if ref in self . _editableChildren :,if ref in self . _editableChildren :,100.0,100.00,True
870,"def _handle_dependents_type ( types , type_str , type_name , rel_name , row ) : <TAB> if types [ type_str [ 0 ] ] is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> type_name = "" index "" <TAB><TAB><TAB> rel_name = row [ "" indname "" ] + ""  ON  "" + rel_name <TAB><TAB> elif type_str [ 0 ] == "" o "" : <TAB><TAB><TAB> type_name = "" operator "" <TAB><TAB><TAB> rel_name = row [ "" relname "" ] <TAB> else : <TAB><TAB> type_name = types [ type_str [ 0 ] ] <TAB> return type_name , rel_name","if type_str [ 0 ] == ""i"" :","if type_str [ 0 ] == ""i"" :",100.0,100.00,True
871,"def streamErrorHandler ( self , conn , error ) : <TAB> name , text = "" error "" , error . getData ( ) <TAB> for tag in error . getChildren ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if tag . getName ( ) == "" text "" : <TAB><TAB><TAB><TAB> text = tag . getData ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> name = tag . getName ( ) <TAB> if name in stream_exceptions . keys ( ) : <TAB><TAB> exc = stream_exceptions [ name ] <TAB> else : <TAB><TAB> exc = StreamError <TAB> raise exc ( ( name , text ) )",if tag . getNamespace ( ) == NS_XMPP_STREAMS :,"if isinstance ( tag , StreamError ) :",94.9963958203889,92.89,False
872,"def _validate_names ( self , settings : _SettingsType ) - > None : <TAB> """"""Make sure all settings exist."""""" <TAB> unknown = [ ] <TAB> for name in settings : <TAB><TAB> <MASK> <TAB><TAB><TAB> unknown . append ( name ) <TAB> if unknown : <TAB><TAB> errors = [ <TAB><TAB><TAB> configexc . ConfigErrorDesc ( <TAB><TAB><TAB><TAB> "" While loading options "" , "" Unknown option  {} "" . format ( e ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> for e in sorted ( unknown ) <TAB><TAB> ] <TAB><TAB> raise configexc . ConfigFileErrors ( "" autoconfig.yml "" , errors )",if name not in configdata . DATA :,"if not name . startswith ( ""_"" ) :",86.10959636473281,94.76,False
873,"def can_haz ( self , target , credentials ) : <TAB> """"""Check whether key-values in target are present in credentials."""""" <TAB> # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB> #               string <TAB> for requirement in target : <TAB><TAB> key , match = requirement . split ( "" : "" , 1 ) <TAB><TAB> check = credentials . get ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> check = [ check ] <TAB><TAB> if match in check : <TAB><TAB><TAB> return True","if check is None or isinstance ( check , basestring ) :","if not isinstance ( check , list ) :",95.25212029011944,94.66,False
874,"def _recursive_fx_apply ( input : dict , fx ) : <TAB> for k , v in input . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> v = torch . tensor ( v ) <TAB><TAB> if isinstance ( v , torch . Tensor ) : <TAB><TAB><TAB> v = fx ( v . float ( ) ) <TAB><TAB><TAB> input [ k ] = v <TAB><TAB> else : <TAB><TAB><TAB> _recursive_fx_apply ( v , fx )","if isinstance ( v , list ) :","if isinstance ( v , ( list , tuple ) ) :",95.79542184759875,95.54,False
875,"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _first_ping = False <TAB><TAB><TAB> return EmptyCapabilitiesResponse ( ) <TAB><TAB> elif "" Hello0 "" in url and "" 1.2.1 "" in url and "" v1 "" in url : <TAB><TAB><TAB> return ErrorApiResponse ( ) <TAB><TAB> else : <TAB><TAB><TAB> response = app . get ( url , * * kwargs ) <TAB><TAB><TAB> return TestingResponse ( response ) <TAB> else : <TAB><TAB> return requests . get ( url , * * kwargs )","if url . endswith ( ""ping"" ) and self . _first_ping :","if ""first_ping"" in url and ""v0"" in url :",91.08416364084671,92.75,False
876,"def server_thread_fn ( ) : <TAB> server_ctx = ssl . create_default_context ( ssl . Purpose . CLIENT_AUTH ) <TAB> server_ctx . load_cert_chain ( "" trio-test-1.pem "" ) <TAB> server = server_ctx . wrap_socket ( <TAB><TAB> server_sock , <TAB><TAB> server_side = True , <TAB><TAB> suppress_ragged_eofs = False , <TAB> ) <TAB> while True : <TAB><TAB> data = server . recv ( 4096 ) <TAB><TAB> print ( "" server got: "" , data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" server waiting for client to finish everything "" ) <TAB><TAB><TAB> client_done . wait ( ) <TAB><TAB><TAB> print ( "" server attempting to send back close-notify "" ) <TAB><TAB><TAB> server . unwrap ( ) <TAB><TAB><TAB> print ( "" server ok "" ) <TAB><TAB><TAB> break <TAB><TAB> server . sendall ( data )",if not data :,if not client_done . is_set ( ) :,88.1068876896861,96.04,False
877,"def find_hostnames ( data ) : <TAB> # sends back an array of hostnames <TAB> hostnames = [ ] <TAB> for i in re . finditer ( hostname_regex , data ) : <TAB><TAB> h = string . lower ( i . group ( 1 ) ) <TAB><TAB> tld = h . split ( "" . "" ) [ - 1 : ] [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> hostnames . append ( h ) <TAB> return hostnames",if tld in tlds :,if tld in hostnames :,73.42930274946293,97.80,False
878,"def Validate ( self , win ) : <TAB> textCtrl = self . GetWindow ( ) <TAB> text = textCtrl . GetValue ( ) . strip ( ) <TAB> sChar = Character . getInstance ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( _t ( "" You must supply a name for the Character! "" ) ) <TAB><TAB> elif text in [ x . name for x in sChar . getCharacterList ( ) ] : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> _t ( "" Character name already in use, please choose another. "" ) <TAB><TAB><TAB> ) <TAB><TAB> return True <TAB> except ValueError as e : <TAB><TAB> pyfalog . error ( e ) <TAB><TAB> wx . MessageBox ( "" {} "" . format ( e ) , _t ( "" Error "" ) ) <TAB><TAB> textCtrl . SetFocus ( ) <TAB><TAB> return False",if len ( text ) == 0 :,if not sChar . isValid ( ) :,69.6956894511943,96.61,False
879,def get_random_user_agent ( agent_list = UA_CACHE ) : <TAB> if not len ( agent_list ) : <TAB><TAB> ua_file = file ( UA_FILE ) <TAB><TAB> for line in ua_file : <TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> agent_list . append ( line ) <TAB> ua = random . choice ( UA_CACHE ) <TAB> return ua,if line :,if line :,100.0,100.00,True
880,"def _validate_action_like_for_prefixes ( self , key ) : <TAB> for statement in self . _statements : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( statement [ key ] , string_types ) : <TAB><TAB><TAB><TAB> self . _validate_action_prefix ( statement [ key ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> for action in statement [ key ] : <TAB><TAB><TAB><TAB><TAB> self . _validate_action_prefix ( action )",if key in statement :,if key in statement :,75.0,100.00,True
881,"def predict ( self , X ) : <TAB> if self . regression : <TAB><TAB> return self . predict_proba ( X ) <TAB> else : <TAB><TAB> y_pred = np . argmax ( self . predict_proba ( X ) , axis = 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> y_pred = self . enc_ . inverse_transform ( y_pred ) <TAB><TAB> return y_pred",if self . use_label_encoder :,if self . enc_ :,80.65985223996155,94.42,False
882,"def _threaded_request_tracker ( self , builder ) : <TAB> while True : <TAB><TAB> event_type = self . _read_q . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> payload = { "" body "" : b "" "" } <TAB><TAB> request_id = builder . build_record ( event_type , payload , "" "" ) <TAB><TAB> self . _write_q . put_nowait ( request_id )",if event_type is False :,if event_type is None :,94.82806447452057,97.96,False
883,"def __call__ ( self , value ) : <TAB> try : <TAB><TAB> super ( EmailValidator , self ) . __call__ ( value ) <TAB> except ValidationError as e : <TAB><TAB> # Trivial case failed. Try for possible IDN domain-part <TAB><TAB> <MASK> <TAB><TAB><TAB> parts = value . split ( "" @ "" ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> parts [ - 1 ] = parts [ - 1 ] . encode ( "" idna "" ) . decode ( "" ascii "" ) <TAB><TAB><TAB> except UnicodeError : <TAB><TAB><TAB><TAB> raise e <TAB><TAB><TAB> super ( EmailValidator , self ) . __call__ ( "" @ "" . join ( parts ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise","if value and ""@"" in value :","if ""@"" in value :",98.3785371520818,98.39,False
884,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB><TAB> if self . __Token : <TAB><TAB><TAB> x = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> if self < = 2 : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionSizeGuid = 3 <TAB><TAB><TAB> if not RegionSizeGuid : <TAB><TAB><TAB><TAB> RegionLayoutLine = 5 <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",elif not IfList :,if x == IfList [ 0 ] :,70.16308881277604,94.00,False
885,"def _arg_with_type ( self ) : <TAB> for t in self . d [ "" Args "" ] : <TAB><TAB> m = re . search ( "" ([A-Za-z0-9_-]+) \ s { 0,4}( \ (.+ \ )) \ s { 0,4}: "" , t ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . args [ m . group ( 1 ) ] = m . group ( 2 ) <TAB> return self . args",if m :,if m :,100.0,100.00,True
886,"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB><TAB> # return subset of palette <TAB><TAB> palette = [ ] <TAB><TAB> for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB><TAB><TAB> if new_id != - 1 : <TAB><TAB><TAB><TAB> palette . append ( self . PALETTE [ old_id ] ) <TAB><TAB> palette = type ( self . PALETTE ) ( palette ) <TAB> elif palette is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB><TAB> else : <TAB><TAB><TAB> palette = self . PALETTE <TAB> return palette",if self . PALETTE is None :,if len ( class_names ) > 3 :,97.32474351870076,96.00,False
887,"def Visit_star_expr ( self , node ) : # pylint: disable=invalid-name <TAB> # star_expr ::= '*' expr <TAB> for child in node . children : <TAB><TAB> self . Visit ( child ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _AppendTokenSubtype ( child , format_token . Subtype . UNARY_OPERATOR ) <TAB><TAB><TAB> _AppendTokenSubtype ( child , format_token . Subtype . VARARGS_STAR )","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",75.0,100.00,True
888,"def create_if_compatible ( cls , typ : Type , * , root : "" RootNode "" ) - > Optional [ "" Node "" ] : <TAB> if cls . compatible_types : <TAB><TAB> target_type : Type = typ <TAB><TAB> <MASK> <TAB><TAB><TAB> target_type = getattr ( typ , "" __origin__ "" , None ) or typ <TAB><TAB> if cls . _issubclass ( target_type , cls . compatible_types ) : <TAB><TAB><TAB> return cls ( typ , root = root ) <TAB> return None",if cls . use_origin :,if not target_type :,68.78677234889851,95.51,False
889,"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB><TAB> tokentype , token = tokens [ i ] <TAB><TAB> i + = 1 <TAB><TAB> if tokentype != "" id "" : <TAB><TAB><TAB> continue <TAB><TAB> while ( <TAB><TAB><TAB> i + 1 < len ( tokens ) <TAB><TAB><TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB><TAB><TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB><TAB> ) : <TAB><TAB><TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB><TAB><TAB> i + = 2 <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if token in pykeywords : <TAB><TAB><TAB> continue <TAB><TAB> if token [ 0 ] in "" .0123456789 "" : <TAB><TAB><TAB> continue <TAB><TAB> yield token","if token == """" :","if token == ""op"" :",99.18315084605547,99.13,False
890,"def create_config_filepath ( cls , visibility = None ) : <TAB> if cls . is_local ( visibility ) : <TAB><TAB> # Local to this directory <TAB><TAB> base_path = os . path . join ( "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Add it to the current ""./.polyaxon"" <TAB><TAB><TAB> base_path = os . path . join ( base_path , "" .polyaxon "" ) <TAB><TAB><TAB> cls . _create_dir ( base_path ) <TAB> elif cls . CONFIG_PATH : # Custom path <TAB><TAB> pass <TAB> else : # Handle both global and all cases <TAB><TAB> base_path = polyaxon_user_path ( ) <TAB><TAB> cls . _create_dir ( base_path )",if cls . IS_POLYAXON_DIR :,if os . path . exists ( base_path ) :,96.94412545450626,94.74,False
891,"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB><TAB> if size == 0 : <TAB><TAB><TAB> bsize = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> bsize = 4 <TAB><TAB> elif size < = 6 : <TAB><TAB><TAB> bsize = 8 <TAB><TAB> elif size < = 9 : <TAB><TAB><TAB> bsize = 12 <TAB><TAB> elif size < = 12 : <TAB><TAB><TAB> bsize = 16 <TAB><TAB> else : <TAB><TAB><TAB> bsize = 20 <TAB><TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 3 :,elif size <= 5 :,99.00060752674547,98.87,False
892,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB><TAB> return None <TAB> for item in dirs : <TAB><TAB> <MASK> <TAB><TAB><TAB> records = as_dict ( path + item , version , section ) <TAB><TAB><TAB> if records : <TAB><TAB><TAB><TAB> result [ item [ : - 1 ] ] = records <TAB><TAB> elif is_dict . match ( item ) : <TAB><TAB><TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB> if records : <TAB><TAB><TAB><TAB> result [ name ] = records <TAB><TAB> else : <TAB><TAB><TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result","if item . endswith ( ""/"" ) :",if is_dict . is_string ( item ) :,96.56396101470719,96.49,False
893,"def api_read ( self ) : <TAB> result = { } <TAB> files = [ "" my.cnf "" , "" debian.cnf "" ] <TAB> directory_list = self . exec_payload ( "" mysql_config_directory "" ) [ "" directory "" ] <TAB> for _file in files : <TAB><TAB> for directory in directory_list : <TAB><TAB><TAB> mysql_conf = directory + _file <TAB><TAB><TAB> content = self . shell . read ( mysql_conf ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ mysql_conf ] = content <TAB> return result",if content :,if content :,100.0,100.00,True
894,"def generate ( self , count = 100 ) : <TAB> self . pre_generate ( ) <TAB> counter = iter ( range ( count ) ) <TAB> created = 0 <TAB> while True : <TAB><TAB> batch = list ( islice ( counter , self . batch_size ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> self . do_generate ( batch , self . batch_size ) <TAB><TAB> from_size = created <TAB><TAB> created + = len ( batch ) <TAB><TAB> print ( "" Generate  %s :  %s - %s "" % ( self . resource , from_size , created ) ) <TAB> self . after_generate ( )",if not batch :,if len ( batch ) == 0 :,73.89746192538237,95.26,False
895,"def _normalize_fields ( self , document , loader ) : <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list ( document . keys ( ) ) : <TAB><TAB> d2 = loader . expand_url ( d , u "" "" , scoped_id = False , vocab_term = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> document [ d2 ] = document [ d ] <TAB><TAB><TAB> del document [ d ]",if d != d2 :,if d2 not in document :,72.26092160283213,96.14,False
896,"def load_cache ( filename , get_key = mangle_key ) : <TAB> cache = { } <TAB> if not os . path . exists ( filename ) : <TAB><TAB> return cache <TAB> f = open ( filename , "" rb "" ) <TAB> l = 0 <TAB> for line in f . readlines ( ) : <TAB><TAB> l + = 1 <TAB><TAB> fields = line . split ( b ""   "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sys . stderr . write ( "" Invalid file format in [ %s ], line  %d \n "" % ( filename , l ) ) <TAB><TAB><TAB> continue <TAB><TAB> # put key:value in cache, key without ^: <TAB><TAB> cache [ get_key ( fields [ 0 ] [ 1 : ] ) ] = fields [ 1 ] . split ( b "" \n "" ) [ 0 ] <TAB> f . close ( ) <TAB> return cache","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",if len ( fields ) != 2 :,62.77836941043523,89.19,False
897,"def __lshift__ ( self , other ) : <TAB> if not self . symbolic and type ( other ) is int : <TAB><TAB> return RegisterOffset ( <TAB><TAB><TAB> self . _bits , self . reg , self . _to_signed ( self . offset << other ) <TAB><TAB> ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return RegisterOffset ( self . _bits , self . reg , self . offset << other ) <TAB><TAB> else : <TAB><TAB><TAB> return RegisterOffset ( <TAB><TAB><TAB><TAB> self . _bits , <TAB><TAB><TAB><TAB> self . reg , <TAB><TAB><TAB><TAB> ArithmeticExpression ( <TAB><TAB><TAB><TAB><TAB> ArithmeticExpression . LShift , <TAB><TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB><TAB> self . offset , <TAB><TAB><TAB><TAB><TAB><TAB> other , <TAB><TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB> )",if self . symbolic :,if self . symbolic :,75.0,100.00,True
898,"def SaveSettings ( self , force = False ) : <TAB> if self . config is not None : <TAB><TAB> frame . ShellFrameMixin . SaveSettings ( self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> frame . Frame . SaveSettings ( self , self . config ) <TAB><TAB><TAB> self . shell . SaveSettings ( self . config )",if self . autoSaveSettings or force :,if force :,92.15383856978247,93.59,False
899,"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB><TAB> if "" type "" in genename_element . attrib : <TAB><TAB><TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB><TAB><TAB><TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB><TAB><TAB><TAB> genename_element . attrib [ "" type "" ] , <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> append_to_annotations ( ann_key , genename_element . text )","if genename_element . attrib [ ""type"" ] == ""primary"" :",if genename_element . text :,69.00891530973303,93.98,False
900,"def _write_pkg_file ( self , file ) : <TAB> with TemporaryFile ( mode = "" w+ "" ) as tmpfd : <TAB><TAB> _write_pkg_file_orig ( self , tmpfd ) <TAB><TAB> tmpfd . seek ( 0 ) <TAB><TAB> for line in tmpfd : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> file . write ( "" Metadata-Version: 2.1 \n "" ) <TAB><TAB><TAB> elif line . startswith ( "" Description:  "" ) : <TAB><TAB><TAB><TAB> file . write ( <TAB><TAB><TAB><TAB><TAB> "" Description-Content-Type:  %s ; charset=UTF-8 \n "" <TAB><TAB><TAB><TAB><TAB> % long_description_content_type <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> file . write ( line ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> file . write ( line )","if line . startswith ( ""Metadata-Version: "" ) :","if line . startswith ( ""Metadata: "" ) :",73.83071764932147,99.03,False
901,"def get ( self ) : <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self . _exception is not _NONE : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . value <TAB><TAB> getcurrent ( ) . throw ( * self . _exception ) # pylint:disable=undefined-variable <TAB> else : <TAB><TAB> if self . greenlet is not None : <TAB><TAB><TAB> raise ConcurrentObjectUseError ( <TAB><TAB><TAB><TAB> "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB><TAB><TAB> ) <TAB><TAB> self . greenlet = getcurrent ( ) # pylint:disable=undefined-variable <TAB><TAB> try : <TAB><TAB><TAB> return self . hub . switch ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . greenlet = None",if self . _exception is None :,if self . value is not _NONE :,69.41402089344247,97.50,False
902,"def connect ( self , * args ) : <TAB> """"""connects to the dropbox. args[0] is the username."""""" <TAB> if len ( args ) != 1 : <TAB><TAB> return "" expected one argument! "" <TAB> try : <TAB><TAB> dbci = get_dropbox_client ( args [ 0 ] , False , None , None ) <TAB> except Exception as e : <TAB><TAB> return e . message <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" No Dropbox configured for  ' {u} ' . "" . format ( u = args [ 0 ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . client = dbci <TAB><TAB> return True",if dbci is None :,if not dbci :,89.54533367471305,97.64,False
903,"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB><TAB> if "" & "" in text : <TAB><TAB><TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB> if "" > "" in text : <TAB><TAB><TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB> if "" < "" in text : <TAB><TAB><TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB> if ' "" ' in text : <TAB><TAB><TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB> if "" ' "" in text : <TAB><TAB><TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB> if newline : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if ""\n"" in text :","if ""\n"" in text :",100.0,100.00,True
904,def t ( ret ) : <TAB> with IPDB ( ) as ipdb : <TAB><TAB> with ipdb . eventqueue ( ) as evq : <TAB><TAB><TAB> for msg in evq : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> ret . append ( msg ) <TAB><TAB><TAB><TAB><TAB> return,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",if msg not in ret :,62.00856879084402,83.78,False
905,"def check_stmt ( self , stmt ) : <TAB> if is_future ( stmt ) : <TAB><TAB> for name , asname in stmt . names : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . found [ name ] = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise SyntaxError ( "" future feature  %s  is not defined "" % name ) <TAB><TAB> stmt . valid_future = 1 <TAB><TAB> return 1 <TAB> return 0",if name in self . features :,"if asname == ""future"" :",92.02211205135988,94.45,False
906,"def process_pypi_option ( option , option_str , option_value , parser ) : <TAB> if option_str . startswith ( "" --no "" ) : <TAB><TAB> setattr ( parser . values , option . dest , [ ] ) <TAB> else : <TAB><TAB> indexes = getattr ( parser . values , option . dest , [ ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> indexes . append ( _PYPI ) <TAB><TAB> setattr ( parser . values , option . dest , indexes )",if _PYPI not in indexes :,"if option_str . startswith ( ""--p"" ) :",66.39457322301104,91.36,False
907,"def modify_address ( self , name , address , domain ) : <TAB> if not self . get_entries_by_name ( name , domain ) : <TAB><TAB> raise exception . NotFound <TAB> infile = open ( self . filename , "" r "" ) <TAB> outfile = tempfile . NamedTemporaryFile ( "" w "" , delete = False ) <TAB> for line in infile : <TAB><TAB> entry = self . parse_line ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> outfile . write ( <TAB><TAB><TAB><TAB> "" %s     %s     %s \n "" % ( address , self . qualify ( name , domain ) , entry [ "" type "" ] ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> outfile . write ( line ) <TAB> infile . close ( ) <TAB> outfile . close ( ) <TAB> shutil . move ( outfile . name , self . filename )","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :","if entry [ ""type"" ] :",63.792888336381345,89.98,False
908,"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google : <TAB><TAB> y = ( 2 * * z - 1 ) - y <TAB> for i in range ( z , 0 , - 1 ) : <TAB><TAB> digit = 0 <TAB><TAB> mask = 1 << ( i - 1 ) <TAB><TAB> if ( x & mask ) != 0 : <TAB><TAB><TAB> digit + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> digit + = 2 <TAB><TAB> quadKey + = str ( digit ) <TAB> return quadKey",if ( y & mask ) != 0 :,if ( y & mask ) != 0 :,100.0,100.00,True
909,"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB><TAB> for typ , key in keys : <TAB><TAB><TAB> flag = 1 <TAB><TAB><TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB><TAB><TAB><TAB> if _typ == typ and key is _key : <TAB><TAB><TAB><TAB><TAB> flag = 0 <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB><TAB> self . issuer_keys [ issuer ] [ use ] = keys",if flag :,if flag :,100.0,100.00,True
910,"def scan_error ( self ) : <TAB> "" A string describing why the last scan failed, or None if it didn ' t. "" <TAB> self . acquire_lock ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . _load_buf_data_once ( ) <TAB><TAB><TAB> except NotFoundInDatabase : <TAB><TAB><TAB><TAB> pass <TAB><TAB> return self . _scan_error_cache <TAB> finally : <TAB><TAB> self . release_lock ( )",if self . _scan_error_cache is None :,if self . _scan_error_cache is None :,75.0,100.00,True
911,"def _query ( self ) : <TAB> if self . _mongo_query is None : <TAB><TAB> self . _mongo_query = self . _query_obj . to_query ( self . _document ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" _cls "" in self . _mongo_query : <TAB><TAB><TAB><TAB> self . _mongo_query = { "" $and "" : [ self . _cls_query , self . _mongo_query ] } <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _mongo_query . update ( self . _cls_query ) <TAB> return self . _mongo_query",if self . _cls_query :,if self . _cls_query :,100.0,100.00,True
912,"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB> return 1 <TAB><TAB> if self . HasCloseButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasMaximizeButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasMinimizeButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> n + = 1 <TAB> return n",if self . HasPinButton ( ) :,if self . HasMinimizeButton ( ) :,79.40056519384144,98.66,False
913,"def testBind ( self ) : <TAB> try : <TAB><TAB> with socket . socket ( socket . PF_CAN , socket . SOCK_DGRAM , socket . CAN_J1939 ) as s : <TAB><TAB><TAB> addr = ( <TAB><TAB><TAB><TAB> self . interface , <TAB><TAB><TAB><TAB> socket . J1939_NO_NAME , <TAB><TAB><TAB><TAB> socket . J1939_NO_PGN , <TAB><TAB><TAB><TAB> socket . J1939_NO_ADDR , <TAB><TAB><TAB> ) <TAB><TAB><TAB> s . bind ( addr ) <TAB><TAB><TAB> self . assertEqual ( s . getsockname ( ) , addr ) <TAB> except OSError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" network interface ` %s ` does not exist "" % self . interface ) <TAB><TAB> else : <TAB><TAB><TAB> raise",if e . errno == errno . ENODEV :,if e . errno == errno . EEXIST :,98.92387798802096,98.98,False
914,"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB><TAB> pos = self . stream . searchBytes ( <TAB><TAB><TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB><TAB> ) # seek forward by at most 1MB <TAB><TAB> if pos is not None : <TAB><TAB><TAB> padsize = pos - self . current_size <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB><TAB> chunk = Chunk ( self , "" chunk[] "" ) <TAB><TAB> try : <TAB><TAB><TAB> # force chunk to be processed, so that CustomFragments are complete <TAB><TAB><TAB> chunk [ "" content/data "" ] <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> yield chunk",if padsize :,if padsize > 1 :,99.02434073181804,98.56,False
915,"def index_modulemd_files ( repo_path ) : <TAB> merger = Modulemd . ModuleIndexMerger ( ) <TAB> for fn in sorted ( os . listdir ( repo_path ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> yaml_path = os . path . join ( repo_path , fn ) <TAB><TAB> mmd = Modulemd . ModuleIndex ( ) <TAB><TAB> mmd . update_from_file ( yaml_path , strict = True ) <TAB><TAB> merger . associate_index ( mmd , 0 ) <TAB> return merger . resolve ( )","if not fn . endswith ( "".yaml"" ) :","if fn . startswith ( ""__"" ) :",75.2289111983257,94.58,False
916,"def set_visible ( self , visible = True ) : <TAB> self . _visible = visible <TAB> if self . _nswindow is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Not really sure why on_resize needs to be here, <TAB><TAB><TAB> # but it's what pyglet wants. <TAB><TAB><TAB> self . dispatch_event ( "" on_resize "" , self . _width , self . _height ) <TAB><TAB><TAB> self . dispatch_event ( "" on_show "" ) <TAB><TAB><TAB> self . dispatch_event ( "" on_expose "" ) <TAB><TAB><TAB> self . _nswindow . makeKeyAndOrderFront_ ( None ) <TAB><TAB> else : <TAB><TAB><TAB> self . _nswindow . orderOut_ ( None )",if visible :,if visible :,100.0,100.00,True
917,"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB><TAB> return "" <recursion> "" <TAB> try : <TAB><TAB> self . _in_repr = True <TAB><TAB> if self . is_computed ( ) : <TAB><TAB><TAB> status = "" computed,  "" <TAB><TAB><TAB> if self . error ( ) is None : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> status + = "" = self "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> status = "" isn ' t computed "" <TAB><TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB><TAB> self . _in_repr = False",if self . value ( ) is self :,if self . value ( ) is None :,99.13783441828264,99.14,False
918,"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB><TAB> for key , value in segment . items ( ) : <TAB><TAB><TAB> if key == index [ 0 ] : <TAB><TAB><TAB><TAB> return value <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if key . text == index [ 0 ] : <TAB><TAB><TAB><TAB><TAB> return value <TAB><TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB><TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB><TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB><TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB><TAB> raise Exception ( "" Invalid state "" )","if hasattr ( key , ""text"" ) :","elif index_type == ""val_text"" :",70.74158337922367,95.58,False
919,"def _makeSafeAbsoluteURI ( base , rel = None ) : <TAB> # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB> if not ACCEPTABLE_URI_SCHEMES : <TAB><TAB> return _urljoin ( base , rel or u "" "" ) <TAB> if not base : <TAB><TAB> return rel or u "" "" <TAB> if not rel : <TAB><TAB> try : <TAB><TAB><TAB> scheme = urlparse . urlparse ( base ) [ 0 ] <TAB><TAB> except ValueError : <TAB><TAB><TAB> return u "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return base <TAB><TAB> return u "" "" <TAB> uri = _urljoin ( base , rel ) <TAB> if uri . strip ( ) . split ( "" : "" , 1 ) [ 0 ] not in ACCEPTABLE_URI_SCHEMES : <TAB><TAB> return u "" "" <TAB> return uri",if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,if scheme . scheme == scheme . scheme :,96.90829419710357,95.05,False
920,"def _write_packet ( self , packet ) : <TAB> # Immediately writes the given packet to the network. The caller must <TAB> # have the write lock acquired before calling this method. <TAB> try : <TAB><TAB> for listener in self . early_outgoing_packet_listeners : <TAB><TAB><TAB> listener . call_packet ( packet ) <TAB><TAB> <MASK> <TAB><TAB><TAB> packet . write ( self . socket , self . options . compression_threshold ) <TAB><TAB> else : <TAB><TAB><TAB> packet . write ( self . socket ) <TAB><TAB> for listener in self . outgoing_packet_listeners : <TAB><TAB><TAB> listener . call_packet ( packet ) <TAB> except IgnorePacket : <TAB><TAB> pass",if self . options . compression_enabled :,if self . options . compression_threshold :,73.81078951272626,98.70,False
921,"def rangelist_to_set ( rangelist ) : <TAB> result = set ( ) <TAB> if not rangelist : <TAB><TAB> return result <TAB> for x in rangelist . split ( "" , "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result . add ( int ( x ) ) <TAB><TAB><TAB> continue <TAB><TAB> m = re . match ( r "" ^( \ d+)-( \ d+)$ "" , x ) <TAB><TAB> if m : <TAB><TAB><TAB> start = int ( m . group ( 1 ) ) <TAB><TAB><TAB> end = int ( m . group ( 2 ) ) <TAB><TAB><TAB> result . update ( set ( range ( start , end + 1 ) ) ) <TAB><TAB><TAB> continue <TAB><TAB> msg = "" Cannot understand data input:  %s   %s "" % ( x , rangelist ) <TAB><TAB> raise ValueError ( msg ) <TAB> return result","if re . match ( r""^(\d+)$"" , x ) :","if x . startswith ( ""0x"" ) :",94.95702680383909,93.59,False
922,"def test_device_property_logfile_isinstance ( self ) : <TAB> mock = MagicMock ( ) <TAB> with patch ( builtin_string + "" .open "" , mock ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> builtin_file = "" io.TextIOWrapper "" <TAB><TAB> else : <TAB><TAB><TAB> builtin_file = builtin_string + "" .file "" <TAB><TAB> with patch ( builtin_file , MagicMock ) : <TAB><TAB><TAB> handle = open ( "" filename "" , "" r "" ) <TAB><TAB><TAB> self . dev . logfile = handle <TAB><TAB><TAB> self . assertEqual ( self . dev . logfile , handle )","if sys . version > ""3"" :","if sys . platform == ""win32"" :",97.5637970274805,96.43,False
923,"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB><TAB> if lidx > = len ( lines ) : <TAB><TAB><TAB> break <TAB><TAB> if stmt == lines [ lidx ] : <TAB><TAB><TAB> lidx + = 1 <TAB><TAB><TAB> if not start : <TAB><TAB><TAB><TAB> start = stmt <TAB><TAB><TAB> end = stmt <TAB><TAB> <MASK> <TAB><TAB><TAB> pairs . append ( ( start , end ) ) <TAB><TAB><TAB> start = None <TAB> if start : <TAB><TAB> pairs . append ( ( start , end ) ) <TAB> return pairs",elif start :,if start and end :,69.13357813222567,97.78,False
924,"def reset_parameters ( self ) : <TAB> initialize = layers . get_initializer ( self . _hparams . initializer ) <TAB> if initialize is not None : <TAB><TAB> # Do not re-initialize LayerNorm modules. <TAB><TAB> for name , param in self . named_parameters ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> initialize ( param )","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :","if isinstance ( param , LayerNorm ) :",86.51082672598936,76.02,False
925,"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB><TAB> RequiredArgumentMissingError , <TAB><TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB><TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB><TAB> if namespace . by_subscription is not None : <TAB><TAB><TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> if namespace . by_subscription is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RequiredArgumentMissingError ( "" --name is also required "" )",if namespace . name is None :,if namespace . account_name not in valid_combs :,93.87443349625427,91.06,False
926,"def DeleteDocuments ( self , document_ids , response ) : <TAB> """"""Deletes documents for the given document_ids."""""" <TAB> for document_id in document_ids : <TAB><TAB> <MASK> <TAB><TAB><TAB> document = self . _documents [ document_id ] <TAB><TAB><TAB> self . _inverted_index . RemoveDocument ( document ) <TAB><TAB><TAB> del self . _documents [ document_id ] <TAB><TAB> delete_status = response . add_status ( ) <TAB><TAB> delete_status . set_code ( search_service_pb . SearchServiceError . OK )",if document_id in self . _documents :,if document_id in self . _documents :,100.0,100.00,True
927,"def generate_new_element ( items , prefix , numeric = False ) : <TAB> """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> candidate = prefix + generate_random_numeric ( 8 ) <TAB><TAB> else : <TAB><TAB><TAB> candidate = prefix + generate_random_alphanumeric ( 8 ) <TAB><TAB> if not candidate in items : <TAB><TAB><TAB> return candidate <TAB><TAB> LOG . debug ( "" Random collision on  %s "" % candidate )",if numeric :,if numeric :,100.0,100.00,True
928,"def generate_text_for_vocab ( self , data_dir , tmp_dir ) : <TAB> for i , sample in enumerate ( <TAB><TAB> self . generate_samples ( data_dir , tmp_dir , problem . DatasetSplit . TRAIN ) <TAB> ) : <TAB><TAB> if self . has_inputs : <TAB><TAB><TAB> yield sample [ "" inputs "" ] <TAB><TAB> yield sample [ "" targets "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,if i == self . num_samples :,61.58289069005778,82.15,False
929,"def _get_ccp ( config = None , config_path = None , saltenv = "" base "" ) : <TAB> """""" """""" <TAB> if config_path : <TAB><TAB> config = __salt__ [ "" cp.get_file_str "" ] ( config_path , saltenv = saltenv ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise SaltException ( "" {}  is not available "" . format ( config_path ) ) <TAB> if isinstance ( config , six . string_types ) : <TAB><TAB> config = config . splitlines ( ) <TAB> ccp = ciscoconfparse . CiscoConfParse ( config ) <TAB> return ccp",if config is False :,if not config :,77.14156344572203,97.22,False
930,"def rpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB><TAB> _client . rpush ( key , * vals ) <TAB> else : <TAB><TAB> pipe = _client . pipeline ( ) <TAB><TAB> pipe . rpush ( key , * vals ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pipe . ltrim ( key , 0 , cap ) <TAB><TAB> if ttl : <TAB><TAB><TAB> pipe . expire ( key , ttl ) <TAB><TAB> pipe . execute ( )",if cap :,if cap :,100.0,100.00,True
931,"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" key "" <TAB><TAB> elif mode == "" key "" : <TAB><TAB><TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" end "" <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB> "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB> ) <TAB> if mode != "" end "" : <TAB><TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","if mode == ""start"" :","if s . startswith ( ""APNS-Type"" ) and ""ENCRYPTED"" in",70.14929125000036,94.95,False
932,"def _add_communication_type ( apps , schema_editor , communication_type ) : <TAB> Worker = apps . get_model ( "" orchestra "" , "" Worker "" ) <TAB> CommunicationPreference = apps . get_model ( "" orchestra "" , "" CommunicationPreference "" ) <TAB> for worker in Worker . objects . all ( ) : <TAB><TAB> ( <TAB><TAB><TAB> communication_preference , <TAB><TAB><TAB> created , <TAB><TAB> ) = CommunicationPreference . objects . get_or_create ( <TAB><TAB><TAB> worker = worker , communication_type = communication_type <TAB><TAB> ) <TAB><TAB> # By default set both Slack and Email notifications to True <TAB><TAB> <MASK> <TAB><TAB><TAB> communication_preference . methods . slack = True <TAB><TAB><TAB> communication_preference . methods . email = True <TAB><TAB> communication_preference . save ( )",if created :,if created :,100.0,100.00,True
933,"def get_postgresql_driver_name ( ) : <TAB> # pylint: disable=unused-variable <TAB> try : <TAB><TAB> driver = os . getenv ( "" CODECHECKER_DB_DRIVER "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return driver <TAB><TAB> try : <TAB><TAB><TAB> # pylint: disable=W0611 <TAB><TAB><TAB> import psycopg2 <TAB><TAB><TAB> return "" psycopg2 "" <TAB><TAB> except Exception : <TAB><TAB><TAB> # pylint: disable=W0611 <TAB><TAB><TAB> import pg8000 <TAB><TAB><TAB> return "" pg8000 "" <TAB> except Exception as ex : <TAB><TAB> LOG . error ( str ( ex ) ) <TAB><TAB> LOG . error ( "" Failed to import psycopg2 or pg8000 module. "" ) <TAB><TAB> raise",if driver :,if driver :,75.0,100.00,True
934,"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB><TAB> if entry is False : <TAB><TAB><TAB> continue <TAB><TAB> code , tags , used , refname = entry <TAB><TAB> for fullname in list ( used ) : <TAB><TAB><TAB> if used [ fullname ] == docname : <TAB><TAB><TAB><TAB> used . pop ( fullname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> modules . pop ( modname )",if len ( used ) == 0 :,if modname in modules :,94.97969017470803,95.09,False
935,"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB><TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB><TAB> if len ( q ) == 1 : <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . append ( value ) <TAB><TAB><TAB> elif is_iterable ( value ) : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",if not is_iterable ( value ) :,if not q [ 0 ] :,96.94261570964109,97.18,False
936,"def _get_bucket_for_key ( self , key : bytes ) - > Optional [ _DBValueTuple ] : <TAB> dbs : Iterable [ PartitionDB ] <TAB> try : <TAB><TAB> partition = self . _key_index [ key ] <TAB><TAB> dbs = [ PartitionDB ( partition , self . _dbs [ partition ] ) ] <TAB> except KeyError : <TAB><TAB> dbs = cast ( Iterable [ PartitionDB ] , self . _dbs . items ( ) ) <TAB> for partition , db in dbs : <TAB><TAB> if db . key_may_exist ( key ) [ 0 ] : <TAB><TAB><TAB> value = db . get ( key ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _key_index [ key ] = partition <TAB><TAB><TAB><TAB> return _DBValueTuple ( db , value ) <TAB> return None",if value is not None :,if value is not None :,100.0,100.00,True
937,"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB><TAB> if self . _process . poll ( ) is None : <TAB><TAB><TAB> for _ in range ( 3 ) : <TAB><TAB><TAB><TAB> self . _process . terminate ( ) <TAB><TAB><TAB><TAB> time . sleep ( 0.5 ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _process . kill ( ) <TAB><TAB><TAB><TAB> self . _process . wait ( ) <TAB><TAB><TAB><TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB><TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" )",if self . _process . poll ( ) is not None :,if self . _process . poll ( ) is None :,99.04658639761593,99.11,False
938,"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB><TAB> if isinstance ( resultset , dict ) and "" duration "" in resultset : <TAB><TAB><TAB> # Count the pass vs failures <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> results [ "" num_passed_states "" ] + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results [ "" num_failed_states "" ] + = 1 <TAB><TAB><TAB> # Count durations <TAB><TAB><TAB> results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB> log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB> return results","if resultset [ ""result"" ] :","if resultset [ ""pass"" ] :",99.03999482429954,98.90,False
939,"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB><TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB><TAB> if max != - 1 and spaces > max : <TAB><TAB><TAB> return LintProblem ( <TAB><TAB><TAB><TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return LintProblem ( <TAB><TAB><TAB><TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB><TAB><TAB> )",elif min != - 1 and spaces < min :,if min != - 1 and spaces < min :,91.94931098484881,98.90,False
940,"def getfileinfo ( name ) : <TAB> finfo = FInfo ( ) <TAB> with io . open ( name , "" rb "" ) as fp : <TAB><TAB> # Quick check for textfile <TAB><TAB> data = fp . read ( 512 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> finfo . Type = "" TEXT "" <TAB><TAB> fp . seek ( 0 , 2 ) <TAB><TAB> dsize = fp . tell ( ) <TAB> dir , file = os . path . split ( name ) <TAB> file = file . replace ( "" : "" , "" - "" , 1 ) <TAB> return file , finfo , dsize , 0",if 0 not in data :,if not data :,97.93845458478435,97.24,False
941,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB><TAB> if tag == "" layers "" : <TAB><TAB><TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> child = dict_to_XML ( key , val ) <TAB><TAB> else : <TAB><TAB><TAB> if tag == "" config "" : <TAB><TAB><TAB><TAB> child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> child = Element ( key ) <TAB><TAB><TAB> child . text = str ( val ) <TAB><TAB> elem . append ( child ) <TAB> return elem","elif isinstance ( val , MutableMapping ) :","elif tag == ""variables"" :",77.59609805757015,96.94,False
942,"def _read_bytes ( self , length ) : <TAB> buffer = b "" "" <TAB> while length : <TAB><TAB> chunk = self . request . recv ( length ) <TAB><TAB> <MASK> <TAB><TAB><TAB> log . debug ( "" Connection closed "" ) <TAB><TAB><TAB> return False <TAB><TAB> length - = len ( chunk ) <TAB><TAB> buffer + = chunk <TAB> return buffer","if chunk == b"""" :",if not chunk :,65.49648329638369,93.40,False
943,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB><TAB> dep_cnts = services . get ( dep ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB> if dep_cnt : <TAB><TAB><TAB> # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB> if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB> deps . update ( new_deps ) <TAB> return deps",if not dep_cnts :,if not dep_cnts :,100.0,100.00,True
944,"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB><TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if e . value is None : <TAB><TAB><TAB><TAB><TAB> e . value = [ ] <TAB><TAB><TAB><TAB> elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB> e . value = e . value . split ( ) <TAB><TAB><TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB> e . value = 0 <TAB> return self",if type ( e ) is Argument or type ( e ) is Option and e . argcount :,if type ( e ) is Argument or type ( e ) is Option and e . argcount,96.49367295307664,99.01,False
945,"def do_cli ( manager , options ) : <TAB> header = [ "" Name "" , "" Description "" ] <TAB> table_data = [ header ] <TAB> for filter_name , filter in get_filters ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> filter_doc = inspect . getdoc ( filter ) or "" "" <TAB><TAB> table_data . append ( [ filter_name , filter_doc ] ) <TAB> try : <TAB><TAB> table = TerminalTable ( options . table_type , table_data ) <TAB> except TerminalTableError as e : <TAB><TAB> console ( "" ERROR:  %s "" % str ( e ) ) <TAB> else : <TAB><TAB> console ( table . output )",if options . name and not options . name in filter_name :,"if filter_name in ( ""name"" , ""description"" ) :",89.58497358361444,93.55,False
946,"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB><TAB> while True : <TAB><TAB><TAB> b1 = fp1 . read ( bufsize ) <TAB><TAB><TAB> b2 = fp2 . read ( bufsize ) <TAB><TAB><TAB> if b1 != b2 : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True",if not b1 :,if b1 != b2 :,74.36600551954005,96.30,False
947,"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB><TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> if family : <TAB><TAB><TAB> father_handle = family . get_father_handle ( ) <TAB><TAB><TAB> mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> if not mother_handle : <TAB><TAB><TAB><TAB> return True <TAB> return False",if not father_handle :,if father_handle :,80.9842317535012,98.78,False
948,"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB><TAB> n = ord ( char ) <TAB><TAB> if 64 < n < 91 : <TAB><TAB><TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB><TAB> <MASK> <TAB><TAB><TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB><TAB> result = result + chr ( n ) <TAB> return result",if 96 < n < 123 :,elif 32 < n < 122 :,73.73652246017134,95.30,False
949,"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB> if i == index : <TAB><TAB><TAB> rval = composite_name <TAB><TAB><TAB> if composite_file . description : <TAB><TAB><TAB><TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> rval = "" %s  [optional] "" % rval <TAB><TAB><TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB><TAB> return "" Extra primary file "" <TAB> return None",if composite_file . optional :,"if self . get_optional_file ( trans , context ) :",83.72773664031664,94.67,False
950,"def __str__ ( self ) : <TAB> t = ""      "" <TAB> if self . _name != "" root "" : <TAB><TAB> r = f "" { t * ( self . _level - 1 ) } { self . _name } : \n "" <TAB> else : <TAB><TAB> r = "" "" <TAB> level = self . _level <TAB> for i , ( k , v ) in enumerate ( self . _pointer . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> r + = f "" { t * ( self . _level ) } { v } \n "" <TAB><TAB><TAB> self . _level + = 1 <TAB><TAB> else : <TAB><TAB><TAB> r + = f "" { t * ( self . _level ) } { k } :  { v }  ( { type ( v ) . __name__ } ) \n "" <TAB><TAB> self . _level = level <TAB> return r [ : - 1 ]","if isinstance ( v , Config ) :",if i == level :,74.20406244285063,96.97,False
951,"def __get_securitygroups ( vm_ ) : <TAB> vm_securitygroups = config . get_cloud_config_value ( <TAB><TAB> "" securitygroups "" , vm_ , __opts__ , search_global = False <TAB> ) <TAB> if not vm_securitygroups : <TAB><TAB> return [ ] <TAB> securitygroups = list_securitygroups ( ) <TAB> for i in range ( len ( vm_securitygroups ) ) : <TAB><TAB> vm_securitygroups [ i ] = six . text_type ( vm_securitygroups [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise SaltCloudNotFound ( <TAB><TAB><TAB><TAB> "" The specified securitygroups  ' {0} '  could not be found. "" . format ( <TAB><TAB><TAB><TAB><TAB> vm_securitygroups [ i ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return vm_securitygroups",if vm_securitygroups [ i ] not in securitygroups :,if not securitygroups :,67.09081170506387,96.03,False
952,"def assert_walk_snapshot ( <TAB> self , field , filespecs_or_globs , paths , ignore_patterns = None , prepare = None ) : <TAB> with self . mk_project_tree ( ignore_patterns = ignore_patterns ) as project_tree : <TAB><TAB> scheduler = self . mk_scheduler ( <TAB><TAB><TAB> rules = create_fs_rules ( ) , project_tree = project_tree <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> prepare ( project_tree ) <TAB><TAB> result = self . execute ( scheduler , Snapshot , self . specs ( filespecs_or_globs ) ) [ 0 ] <TAB><TAB> self . assertEqual ( sorted ( getattr ( result , field ) ) , sorted ( paths ) )",if prepare :,if prepare is not None :,86.92339280156915,97.57,False
953,"def _parse_rowids ( self , rowids ) : <TAB> xploded = [ ] <TAB> rowids = [ x . strip ( ) for x in rowids . split ( "" , "" ) ] <TAB> for rowid in rowids : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> start = int ( rowid . split ( "" - "" ) [ 0 ] . strip ( ) ) <TAB><TAB><TAB><TAB> end = int ( rowid . split ( "" - "" ) [ - 1 ] . strip ( ) ) <TAB><TAB><TAB><TAB> xploded + = range ( start , end + 1 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> xploded . append ( int ( rowid ) ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> continue <TAB> return sorted ( list ( set ( xploded ) ) )","if ""-"" in rowid :","if ""-"" in rowid :",100.0,100.00,True
954,"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB><TAB> w , pos = p <TAB><TAB> <MASK> <TAB><TAB><TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB> elif w in self . word_dict : <TAB><TAB><TAB> lemma = self . word_dict [ w ] <TAB><TAB> else : <TAB><TAB><TAB> lemma = pred <TAB><TAB> if lemma is None : <TAB><TAB><TAB> lemma = w <TAB><TAB> lemmas . append ( lemma ) <TAB> return lemmas","if ( w , pos ) in self . composite_dict :","if ( w , pos ) in self . composite_dict :",100.0,100.00,True
955,"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB> return <TAB><TAB> selectedChunks = self . selectedChunks <TAB><TAB> boxedChunks = set ( box . chunkPositions ) <TAB><TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB><TAB><TAB> remove = True <TAB><TAB> if remove and not add : <TAB><TAB><TAB> selectedChunks . difference_update ( boxedChunks ) <TAB><TAB> else : <TAB><TAB><TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if box == self . level . bounds :,if self . selectedChunks is None :,93.6619575813606,95.35,False
956,"def _ensure_max_size ( cls , image , max_size , interpolation ) : <TAB> if max_size is not None : <TAB><TAB> size = max ( image . shape [ 0 ] , image . shape [ 1 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> resize_factor = max_size / size <TAB><TAB><TAB> new_height = int ( image . shape [ 0 ] * resize_factor ) <TAB><TAB><TAB> new_width = int ( image . shape [ 1 ] * resize_factor ) <TAB><TAB><TAB> image = ia . imresize_single_image ( <TAB><TAB><TAB><TAB> image , ( new_height , new_width ) , interpolation = interpolation <TAB><TAB><TAB> ) <TAB> return image",if size > max_size :,if size > 0 :,82.21512721329984,97.71,False
957,"def _1_0_cloud_ips ( self , method , url , body , headers ) : <TAB> if method == "" GET "" : <TAB><TAB> return self . test_response ( httplib . OK , self . fixtures . load ( "" list_cloud_ips.json "" ) ) <TAB> elif method == "" POST "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> body = json . loads ( body ) <TAB><TAB> node = json . loads ( self . fixtures . load ( "" create_cloud_ip.json "" ) ) <TAB><TAB> if "" reverse_dns "" in body : <TAB><TAB><TAB> node [ "" reverse_dns "" ] = body [ "" reverse_dns "" ] <TAB><TAB> return self . test_response ( httplib . ACCEPTED , json . dumps ( node ) )",if body :,"if ""create_cloud_ip"" in body :",97.72477470118083,95.33,False
958,"def get_formatted_stats ( self ) : <TAB> """"""Get percentage or number of rar's done"""""" <TAB> if self . cur_setname and self . cur_setname in self . total_volumes : <TAB><TAB> # This won't work on obfuscated posts <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" %02d / %02d "" % ( self . cur_volume , self . total_volumes [ self . cur_setname ] ) <TAB> return self . cur_volume",if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,if self . cur_volume < self . total_volumes [ self . cur_setname,93.49777074771741,90.33,False
959,"def wdayset ( self , year , month , day ) : <TAB> # We need to handle cross-year weeks here. <TAB> dset = [ None ] * ( self . yearlen + 7 ) <TAB> i = datetime . date ( year , month , day ) . toordinal ( ) - self . yearordinal <TAB> start = i <TAB> for j in range ( 7 ) : <TAB><TAB> dset [ i ] = i <TAB><TAB> i + = 1 <TAB><TAB> # if (not (0 <= i < self.yearlen) or <TAB><TAB> #    self.wdaymask[i] == self.rrule._wkst): <TAB><TAB> # This will cross the year boundary, if necessary. <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return dset , start , i",if self . wdaymask [ i ] == self . rrule . _wkst :,if self . wdaymask [ i ] == self . rule . _wkst :,74.03254034835052,98.76,False
960,"def do_acquire_read_lock ( self , wait = True ) : <TAB> self . condition . acquire ( ) <TAB> try : <TAB><TAB> # see if a synchronous operation is waiting to start <TAB><TAB> # or is already running, in which case we wait (or just <TAB><TAB> # give up and return) <TAB><TAB> <MASK> <TAB><TAB><TAB> while self . current_sync_operation is not None : <TAB><TAB><TAB><TAB> self . condition . wait ( ) <TAB><TAB> else : <TAB><TAB><TAB> if self . current_sync_operation is not None : <TAB><TAB><TAB><TAB> return False <TAB><TAB> self . asynch + = 1 <TAB> finally : <TAB><TAB> self . condition . release ( ) <TAB> if not wait : <TAB><TAB> return True",if wait :,if self . asynch == 0 :,98.0508586642015,96.58,False
961,"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return y <TAB><TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB><TAB> if not isinstance ( y , ( list , tuple ) ) : <TAB><TAB><TAB> return y <TAB><TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB> if len ( x ) > len ( y ) : <TAB><TAB><TAB> result + = x [ len ( y ) : ] <TAB><TAB> elif len ( x ) < len ( y ) : <TAB><TAB><TAB> result + = y [ len ( x ) : ] <TAB><TAB> return result <TAB> return y","if not isinstance ( y , ( dict , OrderedDict ) ) :","if not isinstance ( y , OrderedDict ) :",73.33363215437993,97.86,False
962,"def update_forum_nums_topic_post ( modeladmin , request , queryset ) : <TAB> for forum in queryset : <TAB><TAB> forum . num_topics = forum . count_nums_topic ( ) <TAB><TAB> forum . num_posts = forum . count_nums_post ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> forum . last_post = forum . topic_set . order_by ( "" -last_reply_on "" ) [ 0 ] . last_post <TAB><TAB> else : <TAB><TAB><TAB> forum . last_post = "" "" <TAB><TAB> forum . save ( )",if forum . num_topics :,if forum . last_post :,76.59089348043929,97.26,False
963,"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB><TAB> if isinstance ( node , nodes . document ) : <TAB><TAB><TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return node [ "" docname "" ] <TAB><TAB> else : <TAB><TAB><TAB> node = node . parent <TAB> return None # never reached here. only for type hinting","elif isinstance ( node , addnodes . start_of_file ) :","elif isinstance ( node , nodes . module ) :",97.38606131702734,93.84,False
964,"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB><TAB> if self . _args . host and self . _args . host == machine . name : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> <MASK> <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB> return selected_machines",if self . locations and machine . location in self . locations :,if self . _args . host and self . _args . host == machine . name :,92.04546996718612,90.56,False
965,"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB><TAB> if value is True : <TAB><TAB><TAB> return [ "" - %s "" % name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if split_single_char_options : <TAB><TAB><TAB><TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB><TAB> if value is True : <TAB><TAB><TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB><TAB> elif value is not False and value is not None : <TAB><TAB><TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ]","elif value not in ( False , None ) :",elif value is not None :,70.40523333649595,96.82,False
966,"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * ""    "" <TAB> if len ( elem ) : <TAB><TAB> if not elem . text or not elem . text . strip ( ) : <TAB><TAB><TAB> elem . text = i + ""    "" <TAB><TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB><TAB><TAB> elem . tail = i <TAB><TAB> for elem in elem : <TAB><TAB><TAB> indent ( elem , level + 1 ) <TAB><TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB><TAB><TAB> elem . tail = i <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> elem . tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,100.0,100.00,True
967,"def _run_instances_op ( self , op , instance_ids , * * kwargs ) : <TAB> while instance_ids : <TAB><TAB> try : <TAB><TAB><TAB> return self . manager . retry ( op , InstanceIds = instance_ids , * * kwargs ) <TAB><TAB> except ClientError as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> instance_ids . remove ( extract_instance_id ( e ) ) <TAB><TAB><TAB> raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""NoSuchEntity""",65.16620138503801,96.97,False
968,"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB><TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB><TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB><TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB><TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> bomb_count + = 1 <TAB><TAB><TAB> if bomb_count > 3 : <TAB><TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> fish . click ( ) <TAB><TAB> time . sleep ( 2.5 )",if fish is bomb :,if fish is not None :,70.76786920208544,98.51,False
969,"def lineWidth ( self , lw = None ) : <TAB> """"""Set/get width of mesh edges. Same as `lw()`."""""" <TAB> if lw is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . GetProperty ( ) . EdgeVisibilityOff ( ) <TAB><TAB><TAB> self . GetProperty ( ) . SetRepresentationToSurface ( ) <TAB><TAB><TAB> return self <TAB><TAB> self . GetProperty ( ) . EdgeVisibilityOn ( ) <TAB><TAB> self . GetProperty ( ) . SetLineWidth ( lw ) <TAB> else : <TAB><TAB> return self . GetProperty ( ) . GetLineWidth ( ) <TAB> return self",if lw == 0 :,if self . GetProperty ( ) . GetLineWidth ( ) == lw :,93.96821017077723,92.47,False
970,"def _current_date_updater ( doc , field_name , value ) : <TAB> if isinstance ( doc , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # TODO(juannyg): get_current_timestamp should also be using helpers utcnow, <TAB><TAB><TAB> # as it currently using time.time internally <TAB><TAB><TAB> doc [ field_name ] = helpers . get_current_timestamp ( ) <TAB><TAB> else : <TAB><TAB><TAB> doc [ field_name ] = mongomock . utcnow ( )","if value == { ""$type"" : ""timestamp"" } :",if value :,86.72460511115234,90.52,False
971,"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB><TAB> after = self . after . id if self . after else None <TAB><TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # no data, terminate <TAB><TAB><TAB> return <TAB><TAB> if len ( data ) < 1000 : <TAB><TAB><TAB> self . limit = 0 # terminate loop <TAB><TAB> self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB><TAB> for element in reversed ( data ) : <TAB><TAB><TAB> await self . members . put ( self . create_member ( element ) )",if not data :,if not data :,100.0,100.00,True
972,"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB><TAB> extracted = extractor . extract ( <TAB><TAB><TAB> page , start_index , end_index , self . template . ignored_regions <TAB><TAB> ) <TAB><TAB> for item in arg_to_iter ( extracted ) : <TAB><TAB><TAB> if item : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> item [ u "" _template "" ] = self . template . id <TAB><TAB><TAB><TAB> items . append ( item ) <TAB> return items","if isinstance ( item , ( ItemProcessor , dict ) ) :","if u""_template"" not in item :",90.10905383172766,93.96,False
973,"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB><TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB><TAB> if node_type not in self . available_node_types : <TAB><TAB><TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB><TAB> node_specific_config = self . available_node_types [ node_type ] <TAB><TAB> <MASK> <TAB><TAB><TAB> fields = node_specific_config [ fields_key ] <TAB> return fields",if fields_key in node_specific_config :,if fields_key in node_specific_config :,100.0,100.00,True
974,"def _write_all ( self , writer ) : <TAB> """"""Writes messages and insert comments here and there."""""" <TAB> # Note: we make no assumptions about the length of original_messages and original_comments <TAB> for msg , comment in zip_longest ( <TAB><TAB> self . original_messages , self . original_comments , fillvalue = None <TAB> ) : <TAB><TAB> # msg and comment might be None <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" writing comment:  "" , comment ) <TAB><TAB><TAB> writer . log_event ( comment ) # we already know that this method exists <TAB><TAB> if msg is not None : <TAB><TAB><TAB> print ( "" writing message:  "" , msg ) <TAB><TAB><TAB> writer ( msg )",if comment is not None :,if comment is not None :,100.0,100.00,True
975,"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB> elif case ( 1 , 2 ) : <TAB><TAB><TAB> print ( "" one or two "" ) <TAB><TAB> elif case ( 3 , 4 ) : <TAB><TAB><TAB> print ( "" three or four "" ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" default "" ) <TAB><TAB><TAB> print ( "" another "" )",if case ( 0 ) :,"if case ( 0 , 0 ) :",74.10104537460768,98.45,False
976,"def date_to_format ( value , target_format ) : <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str : <TAB><TAB> if isinstance ( value , datetime . date ) : <TAB><TAB><TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB> elif isinstance ( value , datetime . time ) : <TAB><TAB><TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB><TAB> ret = value <TAB> return ret","elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . datetime ) :",100.0,100.00,True
977,"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB><TAB> if not which ( "" initdb "" ) : <TAB><TAB><TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB><TAB> if not os . environ . get ( "" GALAXY_TEST_AMQP_INTERNAL_CONNECTION "" ) : <TAB><TAB><TAB> pytest . skip ( <TAB><TAB><TAB><TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB><TAB><TAB> ) <TAB> return request . getfixturevalue ( request . param )",if not psycopg2 :,"if not which ( ""psycopg2"" ) :",70.48574753840472,96.55,False
978,"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> <MASK> <TAB><TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB><TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB><TAB> if not os . check_error ( n ) : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB><TAB><TAB> if timeout < 0 : <TAB><TAB><TAB><TAB> n = 0 <TAB><TAB><TAB><TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB><TAB> vals = struct . unpack ( epoll_event , s ) <TAB><TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res",if timeout >= 0 :,if timeout > 0 :,98.28990929869475,98.01,False
979,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB><TAB> # None is a placeholder for any plugin not having a defined order <TAB><TAB> if name is None : <TAB><TAB><TAB> all_plugins + = [ <TAB><TAB><TAB><TAB> plugin <TAB><TAB><TAB><TAB> for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB> if name not in self . plugins_callback_order and plugin . is_activated <TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> plugin = self . plugins [ name ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> all_plugins . append ( plugin ) <TAB> return all_plugins",if plugin . is_activated :,if plugin . is_activated :,100.0,100.00,True
980,"def get_expected_sql ( self ) : <TAB> sql_base_path = path . join ( path . dirname ( path . realpath ( __file__ ) ) , "" sql "" ) <TAB> # Iterate the version mapping directories. <TAB> for version_mapping in get_version_mapping_directories ( self . server [ "" type "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> complete_path = path . join ( sql_base_path , version_mapping [ "" name "" ] ) <TAB><TAB> if not path . exists ( complete_path ) : <TAB><TAB><TAB> continue <TAB><TAB> break <TAB> data_sql = "" "" <TAB> with open ( path . join ( complete_path , "" test_sql_output.sql "" ) ) as fp : <TAB><TAB> data_sql = fp . read ( ) <TAB> return data_sql","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :","if version_mapping [ ""type"" ] != ""version"" :",96.15539719050244,93.35,False
981,"def _validate_headers ( self , headers ) : <TAB> if headers is None : <TAB><TAB> return headers <TAB> res = { } <TAB> for key , value in headers . items ( ) : <TAB><TAB> if isinstance ( value , ( int , float ) ) : <TAB><TAB><TAB> value = str ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ScriptError ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" message "" : "" headers must be a table "" <TAB><TAB><TAB><TAB><TAB> ""  with strings as keys and values. "" <TAB><TAB><TAB><TAB><TAB> "" Header: ` {!r} : {!r} ` is not valid "" . format ( key , value ) <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB><TAB> res [ key ] = value <TAB> return res","if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :","if not isinstance ( key , str ) :",73.69396609440379,93.26,False
982,"def _get_literal_value ( self , pyval ) : <TAB> if pyval == self . vm . lookup_builtin ( "" builtins.True "" ) : <TAB><TAB> return True <TAB> elif pyval == self . vm . lookup_builtin ( "" builtins.False "" ) : <TAB><TAB> return False <TAB> elif isinstance ( pyval , str ) : <TAB><TAB> prefix , value = parser_constants . STRING_RE . match ( pyval ) . groups ( ) [ : 2 ] <TAB><TAB> value = value [ 1 : - 1 ] # remove quotation marks <TAB><TAB> <MASK> <TAB><TAB><TAB> value = compat . bytestring ( value ) <TAB><TAB> elif "" u "" in prefix and self . vm . PY2 : <TAB><TAB><TAB> value = compat . UnicodeType ( value ) <TAB><TAB> return value <TAB> else : <TAB><TAB> return pyval","if ""b"" in prefix and not self . vm . PY2 :","if ""x"" in prefix and self . vm . PY1 :",97.23660706391726,96.66,False
983,"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB><TAB> self . decode_query_ids ( trans , conditional . left ) <TAB><TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB><TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> field = self . FIELDS [ left_base ] <TAB><TAB><TAB> if field . id_decode : <TAB><TAB><TAB><TAB> conditional . right = trans . security . decode_id ( conditional . right )",if left_base in self . FIELDS :,if left_base in self . FIELDS :,100.0,100.00,True
984,"def testLastPhrases ( self ) : <TAB> for day in ( 11 , 12 , 13 , 14 , 15 , 16 , 17 ) : <TAB><TAB> start = datetime . datetime ( 2012 , 11 , day , 9 , 0 , 0 ) <TAB><TAB> ( yr , mth , dy , _ , _ , _ , wd , yd , isdst ) = start . timetuple ( ) <TAB><TAB> n = 4 - wd <TAB><TAB> <MASK> <TAB><TAB><TAB> n - = 7 <TAB><TAB> target = start + datetime . timedelta ( days = n ) <TAB><TAB> self . assertExpectedResult ( <TAB><TAB><TAB> self . cal . parse ( "" last friday "" , start . timetuple ( ) ) , <TAB><TAB><TAB> ( target . timetuple ( ) , 1 ) , <TAB><TAB><TAB> dateOnly = True , <TAB><TAB> )",if n >= 0 :,if n > 7 :,98.76897116228007,98.34,False
985,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB><TAB> if isinstance ( nbChars , int ) : <TAB><TAB><TAB> nbMinBit = nbChars * 8 <TAB><TAB><TAB> nbMaxBit = nbMinBit <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB> if nbChars [ 1 ] is not None : <TAB><TAB><TAB><TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )",if nbChars [ 0 ] is not None :,if nbChars [ 0 ] is not None :,100.0,100.00,True
986,"def getpystone ( ) : <TAB> # Start calculation <TAB> maxpystone = 0 <TAB> # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB> for pyseed in [ 1000 , 2000 , 5000 , 10000 , 20000 , 50000 , 100000 , 200000 ] : <TAB><TAB> duration , pystonefloat = pystones ( pyseed ) <TAB><TAB> maxpystone = max ( maxpystone , int ( pystonefloat ) ) <TAB><TAB> # Stop when pystone() has been running for at least 0.1 second <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return maxpystone",if duration > 0.1 :,if duration < 0.1 :,73.73714740577498,98.21,False
987,"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB> for part in parts : <TAB><TAB> <MASK> # split may produce empty string in the beginning or start <TAB><TAB><TAB> # split the data so that very long lines separated <TAB><TAB><TAB> for block in re . split ( <TAB><TAB><TAB><TAB> "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> if block : <TAB><TAB><TAB><TAB><TAB> self . _queued_io_events . append ( ( block , stream_name ) )",if part :,if part :,75.0,100.00,True
988,"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB><TAB> # DataType doesn't have len function then convert it to string <TAB><TAB> <MASK> <TAB><TAB><TAB> val = str ( val ) <TAB><TAB> if len ( val ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> value = val <TAB><TAB> if Driver . needsQuoting ( val , True ) : <TAB><TAB><TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB> value = ' "" ' + value + ' "" ' <TAB><TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res","if not hasattr ( val , ""__len__"" ) :","if not isinstance ( val , ( int , float ) ) :",72.81019718918044,95.44,False
989,"def SetVerbose ( self , level ) : <TAB> """"""Sets the verbose level."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> level = int ( level ) <TAB><TAB> if ( level > = 0 ) and ( level < = 3 ) : <TAB><TAB><TAB> self . _verbose = level <TAB><TAB><TAB> return <TAB> except ValueError : <TAB><TAB> pass <TAB> self . Error ( "" Verbose level ( %s ) must be between 0 and 3 inclusive. "" % level )",if type ( level ) != types . IntType :,"if not isinstance ( level , int ) :",86.52762282215556,93.31,False
990,"def step ( self ) - > None : <TAB> """"""Performs a single optimization step."""""" <TAB> for group in self . param_groups : <TAB><TAB> for p in group [ "" params "" ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> p . add_ ( p . grad , alpha = ( - group [ "" lr "" ] * self . num_data ) ) <TAB> return None",if p . grad is None :,if p . grad is None :,75.0,100.00,True
991,"def fill ( self , values ) : <TAB> if lupa . lua_type ( values ) != "" table "" : <TAB><TAB> raise ScriptError ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" argument "" : "" values "" , <TAB><TAB><TAB><TAB> "" message "" : "" element:fill values is not a table "" , <TAB><TAB><TAB><TAB> "" splash_method "" : "" fill "" , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB> # marking all tables as arrays by default <TAB> for key , value in values . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> _mark_table_as_array ( self . lua , value ) <TAB> values = self . lua . lua2python ( values ) <TAB> return self . element . fill ( values )","if lupa . lua_type ( value ) == ""table"" :","if isinstance ( value , dict ) :",96.60062264826722,93.95,False
992,"def _gen_repr ( self , buf ) : <TAB> print >> buf , ""     def __repr__(self): "" <TAB> if self . argnames : <TAB><TAB> fmt = COMMA . join ( [ "" %s "" ] * self . nargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fmt = "" ( %s ) "" % fmt <TAB><TAB> vals = [ "" repr(self. %s ) "" % name for name in self . argnames ] <TAB><TAB> vals = COMMA . join ( vals ) <TAB><TAB> if self . nargs == 1 : <TAB><TAB><TAB> vals = vals + "" , "" <TAB><TAB> print >> buf , '         return  "" %s ( %s ) ""   %%  ( %s ) ' % ( self . name , fmt , vals ) <TAB> else : <TAB><TAB> print >> buf , '         return  "" %s () "" ' % self . name","if ""("" in self . args :",if self . nargs == 2 :,62.74282780037835,96.66,False
993,"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid    :  "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> x_str + = ""   "" * len ( label ) <TAB><TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB><TAB><TAB> if i == x [ 0 ] and j == x [ 1 ] : <TAB><TAB><TAB><TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB><TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str",if j != - 1 :,if j != self . rows - 1 :,91.86230805189454,98.28,False
994,"def get_module_comment ( self , attrname : str ) - > Optional [ List [ str ] ] : <TAB> try : <TAB><TAB> analyzer = ModuleAnalyzer . for_module ( self . modname ) <TAB><TAB> analyzer . analyze ( ) <TAB><TAB> key = ( "" "" , attrname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return list ( analyzer . attr_docs [ key ] ) <TAB> except PycodeError : <TAB><TAB> pass <TAB> return None",if key in analyzer . attr_docs :,if key in analyzer . attr_docs :,100.0,100.00,True
995,"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google : <TAB><TAB> y = ( 2 * * z - 1 ) - y <TAB> for i in range ( z , 0 , - 1 ) : <TAB><TAB> digit = 0 <TAB><TAB> mask = 1 << ( i - 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> digit + = 1 <TAB><TAB> if ( y & mask ) != 0 : <TAB><TAB><TAB> digit + = 2 <TAB><TAB> quadKey + = str ( digit ) <TAB> return quadKey",if ( x & mask ) != 0 :,if ( x & mask ) != 0 :,100.0,100.00,True
996,"def test_enumerate ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB><TAB> for i in range ( 100 ) : <TAB><TAB><TAB> await stream . channel . deliver ( message ( key = i , value = i * 4 ) ) <TAB><TAB> async for i , value in stream . enumerate ( ) : <TAB><TAB><TAB> current_event = stream . current_event <TAB><TAB><TAB> assert i == current_event . key <TAB><TAB><TAB> assert value == i * 4 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> assert await channel_empty ( stream . channel )",if i >= 99 :,if i == 100 :,89.09711446794859,97.60,False
997,"def print_messages ( self ) : <TAB> output_reports = self . config . get_output_report ( ) <TAB> for report in output_reports : <TAB><TAB> output_format , output_files = report <TAB><TAB> self . summary [ "" formatter "" ] = output_format <TAB><TAB> formatter = FORMATTERS [ output_format ] ( <TAB><TAB><TAB> self . summary , self . messages , self . config . profile <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . write_to ( formatter , sys . stdout ) <TAB><TAB> for output_file in output_files : <TAB><TAB><TAB> with open ( output_file , "" w+ "" ) as target : <TAB><TAB><TAB><TAB> self . write_to ( formatter , target )",if not output_files :,if sys . stdout :,68.48324365583368,97.32,False
998,"def eval_metrics ( self ) : <TAB> for task in self . task_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ <TAB><TAB><TAB><TAB> metrics . Metrics . ACC , <TAB><TAB><TAB><TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB><TAB><TAB><TAB> metrics . Metrics . ROUGE_2_F , <TAB><TAB><TAB><TAB> metrics . Metrics . ROUGE_L_F , <TAB><TAB><TAB> ] <TAB> return [ <TAB><TAB> metrics . Metrics . ACC , <TAB><TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB> ]","if ""summarize"" in task . name :","if task . name == ""test_metrics"" :",94.38430172365928,94.65,False
999,"def _getBuildRequestForBrdict ( self , brdict ) : <TAB> # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB> # for API like 'nextBuild', which operate on BuildRequest objects. <TAB> breq = self . breqCache . get ( brdict [ "" buildrequestid "" ] ) <TAB> if not breq : <TAB><TAB> breq = yield BuildRequest . fromBrdict ( self . master , brdict ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . breqCache [ brdict [ "" buildrequestid "" ] ] = breq <TAB> defer . returnValue ( breq )",if breq :,if breq :,75.0,100.00,True
1000,"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB><TAB> for s in states : <TAB><TAB><TAB> ns = state_func ( s ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> split . append ( ns ) <TAB><TAB><TAB> elif isinstance ( ns , ( list , tuple , set ) ) : <TAB><TAB><TAB><TAB> split . extend ( ns ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB><TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB><TAB> keep = states <TAB> return keep , split","if isinstance ( ns , SimState ) :","if isinstance ( ns , to_stash ) :",86.4021038305917,97.93,False
1001,"def sequence_to_text ( sequence ) : <TAB> """"""Converts a sequence of IDs back to a string"""""" <TAB> result = "" "" <TAB> for symbol_id in sequence : <TAB><TAB> <MASK> <TAB><TAB><TAB> s = _id_to_symbol [ symbol_id ] <TAB><TAB><TAB> # Enclose ARPAbet back in curly braces: <TAB><TAB><TAB> if len ( s ) > 1 and s [ 0 ] == "" @ "" : <TAB><TAB><TAB><TAB> s = "" { %s } "" % s [ 1 : ] <TAB><TAB><TAB> result + = s <TAB> return result . replace ( "" } { "" , ""   "" )",if symbol_id in _id_to_symbol :,if symbol_id in _id_to_symbol :,100.0,100.00,True
1002,"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB><TAB> mod_type = self . etc [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> source = self . get_source ( fullname ) <TAB><TAB><TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB> elif mod_type == imp . PY_COMPILED : <TAB><TAB><TAB> self . _reopen ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . code = read_code ( self . file ) <TAB><TAB><TAB> finally : <TAB><TAB><TAB><TAB> self . file . close ( ) <TAB><TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB><TAB><TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",if mod_type == imp . PY_SOURCE :,if mod_type == imp . PY_COMPILED :,78.54066886768094,99.04,False
1003,"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB><TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB><TAB> return detected <TAB> for wafvendor in self . checklist : <TAB><TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB><TAB> if self . wafdetections [ wafvendor ] ( self ) : <TAB><TAB><TAB> detected . append ( wafvendor ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected",if not findall :,if findall :,90.27497548886787,98.44,False
1004,"def SessionId ( self ) : <TAB> """"""Returns the Session ID of the process"""""" <TAB> if self . Session . is_valid ( ) : <TAB><TAB> process_space = self . get_process_address_space ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return obj . Object ( <TAB><TAB><TAB><TAB> "" _MM_SESSION_SPACE "" , offset = self . Session , vm = process_space <TAB><TAB><TAB> ) . SessionId <TAB> return obj . NoneObject ( "" Cannot find process session "" )",if process_space :,if process_space :,100.0,100.00,True
1005,"def _convert_java_pattern_to_python ( pattern ) : <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB><TAB> c = s [ i ] <TAB><TAB> if c == "" $ "" and s [ i + 1 ] in "" 0123456789 "" : <TAB><TAB><TAB> s [ i ] = "" \\ "" <TAB><TAB> <MASK> <TAB><TAB><TAB> s [ i ] = "" "" <TAB><TAB><TAB> i + = 1 <TAB><TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s )","elif c == ""\\"" and s [ i + 1 ] == ""$"" :","elif c == ""$"" and s [ i + 1 ] in ""0123456789"" :",93.85098550699654,96.58,False
1006,"def __init__ ( self , coverage ) : <TAB> self . coverage = coverage <TAB> self . config = self . coverage . config <TAB> self . source_paths = set ( ) <TAB> if self . config . source : <TAB><TAB> for src in self . config . source : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not self . config . relative_files : <TAB><TAB><TAB><TAB><TAB> src = files . canonical_filename ( src ) <TAB><TAB><TAB><TAB> self . source_paths . add ( src ) <TAB> self . packages = { } <TAB> self . xml_out = None",if os . path . exists ( src ) :,if src not in self . source_paths :,66.81309555942518,94.83,False
1007,"def populate_vol_format ( self ) : <TAB> rhel6_file_whitelist = [ "" raw "" , "" qcow2 "" , "" qed "" ] <TAB> model = self . widget ( "" vol-format "" ) . get_model ( ) <TAB> model . clear ( ) <TAB> formats = self . vol_class . formats <TAB> if hasattr ( self . vol_class , "" create_formats "" ) : <TAB><TAB> formats = getattr ( self . vol_class , "" create_formats "" ) <TAB> if self . vol_class == Storage . FileVolume and not self . conn . rhel6_defaults_caps ( ) : <TAB><TAB> newfmts = [ ] <TAB><TAB> for f in rhel6_file_whitelist : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> newfmts . append ( f ) <TAB><TAB> formats = newfmts <TAB> for f in formats : <TAB><TAB> model . append ( [ f , f ] )",if f in formats :,if f not in formats :,99.28144353965793,98.91,False
1008,"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB><TAB> from galaxy . files import ConfiguredFileSources <TAB><TAB> file_sources = None <TAB><TAB> <MASK> <TAB><TAB><TAB> file_sources_as_dict = None <TAB><TAB><TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB> if file_sources_as_dict is not None : <TAB><TAB><TAB><TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB> if file_sources is None : <TAB><TAB><TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB> _file_sources = file_sources <TAB> return _file_sources","if os . path . exists ( ""file_sources.json"" ) :","if os . path . exists ( ""file_sources.json"" ) :",100.0,100.00,True
1009,"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB> if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB><TAB><TAB> return y <TAB><TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB><TAB> if not isinstance ( y , ( list , tuple ) ) : <TAB><TAB><TAB> return y <TAB><TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> result + = x [ len ( y ) : ] <TAB><TAB> elif len ( x ) < len ( y ) : <TAB><TAB><TAB> result + = y [ len ( x ) : ] <TAB><TAB> return result <TAB> return y",if len ( x ) > len ( y ) :,if len ( x ) < len ( y ) :,74.23348999043088,99.03,False
1010,"def copy_dicts ( dct ) : <TAB> if "" _remote_data "" in dct : <TAB><TAB> dsindex = dct [ "" _remote_data "" ] [ "" _content "" ] . dsindex <TAB><TAB> newdct = dct . copy ( ) <TAB><TAB> newdct [ "" _remote_data "" ] = { "" _content "" : dsindex } <TAB><TAB> return list ( newdct . items ( ) ) <TAB> elif "" _data "" in dct : <TAB><TAB> newdct = dct . copy ( ) <TAB><TAB> newdata = copy_dicts ( dct [ "" _data "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> newdct [ "" _data "" ] = newdata <TAB><TAB> return list ( newdct . items ( ) ) <TAB> return None",if newdata :,if newdata :,100.0,100.00,True
1011,"def _import_epic_activity ( self , project_data , taiga_epic , epic , options ) : <TAB> offset = 0 <TAB> while True : <TAB><TAB> activities = self . _client . get ( <TAB><TAB><TAB> "" /projects/ {} /epics/ {} /activity "" . format ( <TAB><TAB><TAB><TAB> project_data [ "" id "" ] , <TAB><TAB><TAB><TAB> epic [ "" id "" ] , <TAB><TAB><TAB> ) , <TAB><TAB><TAB> { "" envelope "" : "" true "" , "" limit "" : 300 , "" offset "" : offset } , <TAB><TAB> ) <TAB><TAB> offset + = 300 <TAB><TAB> for activity in activities [ "" data "" ] : <TAB><TAB><TAB> self . _import_activity ( taiga_epic , activity , options ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break","if len ( activities [ ""data"" ] ) < 300 :","if not activities [ ""data"" ] :",65.89825908762505,96.69,False
1012,"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB><TAB> <MASK> <TAB><TAB><TAB> rel_obj = self . get_obj ( instance ) <TAB><TAB><TAB> if rel_obj : <TAB><TAB><TAB><TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB><TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self",if self . att_name not in instance . _obj_cache :,if instance_type :,86.28575008199225,89.38,False
1013,"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB><TAB> if url . startswith ( "" https:// "" ) : <TAB><TAB><TAB> url = url [ 8 : ] <TAB><TAB> if not url . startswith ( "" http:// "" ) : <TAB><TAB><TAB> url = "" http:// "" + url <TAB><TAB> <MASK> <TAB><TAB><TAB> download_playlist ( <TAB><TAB><TAB><TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only )",if playlist :,if playlist :,100.0,100.00,True
1014,"def _mksubs ( self ) : <TAB> self . _subs = { } <TAB> commit_dir = CommitDir ( self , "" .commit "" ) <TAB> self . _subs [ "" .commit "" ] = commit_dir <TAB> tag_dir = TagDir ( self , "" .tag "" ) <TAB> self . _subs [ "" .tag "" ] = tag_dir <TAB> for ( name , sha ) in git . list_refs ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = name [ 11 : ] <TAB><TAB><TAB> date = git . rev_get_date ( sha . encode ( "" hex "" ) ) <TAB><TAB><TAB> n1 = BranchList ( self , name , sha ) <TAB><TAB><TAB> n1 . ctime = n1 . mtime = date <TAB><TAB><TAB> self . _subs [ name ] = n1","if name . startswith ( ""refs/heads/"" ) :","if name . startswith ( ""git-"" ) :",99.05600786259082,97.47,False
1015,"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB><TAB> rlen = size - len ( ret ) <TAB><TAB> x = self . fd . read ( rlen ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not shortok : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> return ret <TAB><TAB> ret + = x <TAB> return ret","if x == b"""" :",if not x :,68.5274272587985,94.82,False
1016,"def remove_indent ( self ) : <TAB> """"""Remove one tab-width of blanks from the previous token."""""" <TAB> w = abs ( self . tab_width ) <TAB> if self . result : <TAB><TAB> s = self . result [ - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . result . pop ( ) <TAB><TAB><TAB> s = s . replace ( "" \t "" , ""   "" * w ) <TAB><TAB><TAB> if s . startswith ( "" \n "" ) : <TAB><TAB><TAB><TAB> s2 = s [ 1 : ] <TAB><TAB><TAB><TAB> self . result . append ( "" \n "" + s2 [ : - w ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . result . append ( s [ : - w ] )",if s . isspace ( ) :,"if s . startswith ( ""\t"" ) :",70.82326141283757,96.76,False
1017,"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB><TAB> self . _last_updated = time . time ( ) <TAB><TAB> try : <TAB><TAB><TAB> if kwargs . get ( "" in_place "" , False ) : <TAB><TAB><TAB><TAB> self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB><TAB> except OSError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise <TAB><TAB> self . _last_updated = time . time ( )","if ""_create_temporary"" in traceback . format_exc ( ) :","if kwargs . get ( ""in_place"" , False ) :",94.86088875301512,94.48,False
1018,"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB><TAB> elif act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_COMP_CODES : <TAB><TAB><TAB> manual_intervention_nodes . add ( act [ "" id "" ] )","if act [ ""type"" ] == ""SubProcess"" :","if act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION",63.44636995659272,90.57,False
1019,"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB><TAB> return <TAB> if authed ( ) : <TAB><TAB> user = get_current_user_attrs ( ) <TAB><TAB> team = get_current_team_attrs ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( <TAB><TAB><TAB><TAB> render_template ( <TAB><TAB><TAB><TAB><TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> 403 , <TAB><TAB><TAB> ) <TAB><TAB> if team and team . banned : <TAB><TAB><TAB> return ( <TAB><TAB><TAB><TAB> render_template ( <TAB><TAB><TAB><TAB><TAB> "" errors/403.html "" , <TAB><TAB><TAB><TAB><TAB> error = "" Your team has been banned from this CTF "" , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> 403 , <TAB><TAB><TAB> )",if user and user . banned :,if user and user . banned :,100.0,100.00,True
1020,"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB> values = [ values ] <TAB> for v in values : <TAB><TAB> v = str ( v ) <TAB><TAB> if isinstance ( self . _definition , dict ) : <TAB><TAB><TAB> self . _definition . pop ( v , None ) <TAB><TAB> elif self . _definition == "" ANY "" : <TAB><TAB><TAB> if v == "" ANY "" : <TAB><TAB><TAB><TAB> self . _definition = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _definition . remove ( v ) <TAB> if ( <TAB><TAB> self . _value is not None <TAB><TAB> and self . _value not in self . _definition <TAB><TAB> and self . _not_any ( ) <TAB> ) : <TAB><TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )",elif v in self . _definition :,elif v in self . _definition :,100.0,100.00,True
1021,"def save ( self , learner , file_name ) : <TAB> """"""Save the model to location specified in file_name."""""" <TAB> with open ( file_name , "" wb "" ) as f : <TAB><TAB> <MASK> <TAB><TAB><TAB> # don't store the large inference cache! <TAB><TAB><TAB> learner . inference_cache_ , tmp = ( None , learner . inference_cache_ ) <TAB><TAB><TAB> pickle . dump ( learner , f , - 1 ) <TAB><TAB><TAB> learner . inference_cache_ = tmp <TAB><TAB> else : <TAB><TAB><TAB> pickle . dump ( learner , f , - 1 )","if hasattr ( learner , ""inference_cache_"" ) :",if learner . inference_cache_ :,93.21847038873562,94.44,False
1022,"def __init__ ( self , exprs , savelist = False ) : <TAB> super ( ParseExpression , self ) . __init__ ( savelist ) <TAB> if isinstance ( exprs , _generatorType ) : <TAB><TAB> exprs = list ( exprs ) <TAB> if isinstance ( exprs , basestring ) : <TAB><TAB> self . exprs = [ ParserElement . _literalStringClass ( exprs ) ] <TAB> elif isinstance ( exprs , collections . Iterable ) : <TAB><TAB> exprs = list ( exprs ) <TAB><TAB> # if sequence of strings provided, wrap with Literal <TAB><TAB> <MASK> <TAB><TAB><TAB> exprs = map ( ParserElement . _literalStringClass , exprs ) <TAB><TAB> self . exprs = list ( exprs ) <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> self . exprs = list ( exprs ) <TAB><TAB> except TypeError : <TAB><TAB><TAB> self . exprs = [ exprs ] <TAB> self . callPreparse = False","if all ( isinstance ( expr , basestring ) for expr in exprs ) :","if isinstance ( exprs , ( list , tuple ) ) :",96.08253177054723,95.20,False
1023,"def find ( self , back = False ) : <TAB> flags = 0 <TAB> <MASK> <TAB><TAB> flags = QTextDocument . FindBackward <TAB> if self . csBox . isChecked ( ) : <TAB><TAB> flags = flags | QTextDocument . FindCaseSensitively <TAB> text = self . searchEdit . text ( ) <TAB> if not self . findMain ( text , flags ) : <TAB><TAB> if text in self . editBoxes [ self . ind ] . toPlainText ( ) : <TAB><TAB><TAB> cursor = self . editBoxes [ self . ind ] . textCursor ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cursor . movePosition ( QTextCursor . End ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> cursor . movePosition ( QTextCursor . Start ) <TAB><TAB><TAB> self . editBoxes [ self . ind ] . setTextCursor ( cursor ) <TAB><TAB><TAB> self . findMain ( text , flags )",if back :,if back :,100.0,100.00,True
1024,"def _load_storage ( self ) : <TAB> self . _storage = { } <TAB> for row in self ( "" SELECT object, resource, amount FROM storage "" ) : <TAB><TAB> ownerid = int ( row [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _storage [ ownerid ] . append ( row [ 1 : ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . _storage [ ownerid ] = [ row [ 1 : ] ]",if ownerid in self . _storage :,if ownerid in self . _storage :,100.0,100.00,True
1025,"def parse_chunked ( self , unreader ) : <TAB> ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB> while size > 0 : <TAB><TAB> while size > len ( rest ) : <TAB><TAB><TAB> size - = len ( rest ) <TAB><TAB><TAB> yield rest <TAB><TAB><TAB> rest = unreader . read ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise NoMoreData ( ) <TAB><TAB> yield rest [ : size ] <TAB><TAB> # Remove \r\n after chunk <TAB><TAB> rest = rest [ size : ] <TAB><TAB> while len ( rest ) < 2 : <TAB><TAB><TAB> rest + = unreader . read ( ) <TAB><TAB> if rest [ : 2 ] != b "" \r \n "" : <TAB><TAB><TAB> raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB><TAB> ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] )",if not rest :,if not rest :,100.0,100.00,True
1026,"def _augment_batch_ ( self , batch , random_state , parents , hooks ) : <TAB> for column in batch . columns : <TAB><TAB> <MASK> <TAB><TAB><TAB> for i , cbaoi in enumerate ( column . value ) : <TAB><TAB><TAB><TAB> column . value [ i ] = cbaoi . clip_out_of_image_ ( ) <TAB> return batch","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :","if column . name == ""clip_out_of_image"" :",88.0057298401869,80.67,False
1027,"def to_nim ( self ) : <TAB> if self . is_pointer == 2 : <TAB><TAB> s = "" cstringArray "" if self . type == "" GLchar "" else "" ptr pointer "" <TAB> else : <TAB><TAB> s = self . type <TAB><TAB> <MASK> <TAB><TAB><TAB> default = "" ptr  "" + s <TAB><TAB><TAB> s = self . NIM_POINTER_MAP . get ( s , default ) <TAB> return s",if self . is_pointer == 1 :,if s in self . NIM_POINTER_MAP :,71.09953051212024,92.27,False
1028,"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB> if self . match_function ( path ) : <TAB><TAB><TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB><TAB> for content in os . listdir ( path ) : <TAB><TAB><TAB> file = os . path . join ( path , content ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB> if self . match_function ( file ) : <TAB><TAB><TAB><TAB><TAB> self . files . append ( file ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . find ( file )",if os . path . isfile ( file ) or os . path . islink ( file ) :,if os . path . isfile ( file ) or os . path . islink ( file ),97.41957643505339,99.03,False
1029,"def remove ( self , event ) : <TAB> try : <TAB><TAB> self . _events_current_sweep . remove ( event ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert event . in_sweep == True <TAB><TAB><TAB> assert event . other . in_sweep == True <TAB><TAB><TAB> event . in_sweep = False <TAB><TAB><TAB> event . other . in_sweep = False <TAB><TAB> return True <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert event . in_sweep == False <TAB><TAB><TAB> assert event . other . in_sweep == False <TAB><TAB> return False",if USE_DEBUG :,if self . _assert_event_is_sweep :,93.33883969303915,88.64,False
1030,"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB><TAB> if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> attrvalue = getattr ( self , attrname , None ) <TAB><TAB> if attrvalue == 0 : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> attrname = "" version "" <TAB><TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB> elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass","if attrname == ""salt_version"" :","if attrname == ""version"" :",99.02812377326894,98.57,False
1031,"def _init_auxiliary_head ( self , auxiliary_head ) : <TAB> """"""Initialize ``auxiliary_head``"""""" <TAB> if auxiliary_head is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . auxiliary_head = nn . ModuleList ( ) <TAB><TAB><TAB> for head_cfg in auxiliary_head : <TAB><TAB><TAB><TAB> self . auxiliary_head . append ( builder . build_head ( head_cfg ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . auxiliary_head = builder . build_head ( auxiliary_head )","if isinstance ( auxiliary_head , list ) :","if isinstance ( auxiliary_head , list ) :",100.0,100.00,True
1032,"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB><TAB> out + = self . _str_header ( name ) <TAB><TAB> for param in self [ name ] : <TAB><TAB><TAB> parts = [ ] <TAB><TAB><TAB> if param . name : <TAB><TAB><TAB><TAB> parts . append ( param . name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> parts . append ( param . type ) <TAB><TAB><TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB><TAB><TAB><TAB> out + = self . _str_indent ( param . desc ) <TAB><TAB> out + = [ "" "" ] <TAB> return out",if param . type :,if param . type :,100.0,100.00,True
1033,"def _set_handler ( <TAB> self , name , handle = None , obj = None , constructor_args = ( ) , constructor_kwds = { } ) : <TAB> if handle is None : <TAB><TAB> handle = obj is not None <TAB> if handle : <TAB><TAB> handler_class = self . handler_classes [ name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> newhandler = handler_class ( obj ) <TAB><TAB> else : <TAB><TAB><TAB> newhandler = handler_class ( * constructor_args , * * constructor_kwds ) <TAB> else : <TAB><TAB> newhandler = None <TAB> self . _replace_handler ( name , newhandler )",if obj is not None :,if obj is not None :,100.0,100.00,True
1034,"def _extract_subtitles ( src ) : <TAB> subtitles = { } <TAB> for caption in try_get ( src , lambda x : x [ "" captions "" ] , list ) or [ ] : <TAB><TAB> subtitle_url = url_or_none ( caption . get ( "" uri "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> lang = caption . get ( "" language "" , "" deu "" ) <TAB><TAB><TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" url "" : subtitle_url , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB> return subtitles",if subtitle_url :,if subtitle_url :,100.0,100.00,True
1035,"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB><TAB><TAB> res . extend ( keys ) <TAB><TAB> for key in struct : <TAB><TAB><TAB> if key in IGNORED_KEYS : <TAB><TAB><TAB><TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB><TAB> for item in struct : <TAB><TAB><TAB> res . extend ( get_keys ( item ) ) <TAB> return res",if not ignore_first_level :,if ignore_first_level :,77.46819527083025,98.98,False
1036,"def create_dir ( path ) : <TAB> curr_path = None <TAB> for p in path : <TAB><TAB> if curr_path is None : <TAB><TAB><TAB> curr_path = os . path . abspath ( p ) <TAB><TAB> else : <TAB><TAB><TAB> curr_path = os . path . join ( curr_path , p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . mkdir ( curr_path )",if not os . path . exists ( curr_path ) :,if not os . path . exists ( curr_path ) :,100.0,100.00,True
1037,"def dataToDumpFile ( dumpFile , data ) : <TAB> try : <TAB><TAB> dumpFile . write ( data ) <TAB><TAB> dumpFile . flush ( ) <TAB> except IOError as ex : <TAB><TAB> if "" No space left "" in getUnicode ( ex ) : <TAB><TAB><TAB> errMsg = "" no space left on output device "" <TAB><TAB><TAB> logger . error ( errMsg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> errMsg = "" permission denied when flushing dump data "" <TAB><TAB><TAB> logger . error ( errMsg ) <TAB><TAB> else : <TAB><TAB><TAB> errMsg = ( <TAB><TAB><TAB><TAB> "" error occurred when writing dump data to file ( ' %s ' ) "" % getUnicode ( ex ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> logger . error ( errMsg )","elif ""Permission denied"" in getUnicode ( ex ) :","elif ""Permission denied"" in getUnicode ( ex ) :",100.0,100.00,True
1038,"def elements ( self , top ) : <TAB> res = [ ] <TAB> # try: <TAB> #     string = ""== %s (%s)"" % (self.name,self.__class__) <TAB> # except AttributeError: <TAB> #     string = ""== (%s)"" % (self.__class__,) <TAB> # print(string) <TAB> for part in self . parts : <TAB><TAB> <MASK> <TAB><TAB><TAB> res . append ( name_or_ref ( part , top ) ) <TAB><TAB> else : <TAB><TAB><TAB> if isinstance ( part , Extension ) : <TAB><TAB><TAB><TAB> res . append ( part . base ) <TAB><TAB><TAB> res . extend ( part . elements ( top ) ) <TAB> return res","if isinstance ( part , Element ) :","if isinstance ( part , NameOrRef ) :",98.79683980563735,98.79,False
1039,"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB><TAB> if default . lower ( ) == "" true "" : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB><TAB> if type ( default ) == int : <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB><TAB> if type ( default ) == float : <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return float ( default ) <TAB> else : <TAB><TAB> return str ( default )","elif default . lower ( ) == ""false"" :","elif default . lower ( ) == ""false"" :",100.0,100.00,True
1040,"def dvmethod ( c , dx , doAST = False ) : <TAB> for m in c . get_methods ( ) : <TAB><TAB> mx = dx . get_method ( m ) <TAB><TAB> ms = DvMethod ( mx ) <TAB><TAB> ms . process ( doAST = doAST ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert ms . get_ast ( ) is not None <TAB><TAB><TAB> assert isinstance ( ms . get_ast ( ) , dict ) <TAB><TAB><TAB> assert "" body "" in ms . get_ast ( ) <TAB><TAB> else : <TAB><TAB><TAB> assert ms . get_source ( ) is not None",if doAST :,if doAST :,100.0,100.00,True
1041,"def _repr_pretty_ ( self , p , cycle ) : <TAB> if cycle : <TAB><TAB> return "" {{ ...} "" <TAB> with p . group ( 2 , "" { "" , "" } "" ) : <TAB><TAB> p . breakable ( "" "" ) <TAB><TAB> for idx , key in enumerate ( self . _items ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> p . text ( "" , "" ) <TAB><TAB><TAB><TAB> p . breakable ( ) <TAB><TAB><TAB> value = self . _items [ key ] <TAB><TAB><TAB> p . pretty ( key ) <TAB><TAB><TAB> p . text ( "" :  "" ) <TAB><TAB><TAB> if isinstance ( value , bytes ) : <TAB><TAB><TAB><TAB> value = trimmed_repr ( value ) <TAB><TAB><TAB> p . pretty ( value ) <TAB><TAB> p . breakable ( "" "" )",if idx :,if idx == 0 :,98.07349437691325,98.21,False
1042,"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB><TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB><TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB><TAB> if "" ~#rating "" in song : <TAB><TAB><TAB> del song [ "" ~#rating "" ] <TAB><TAB><TAB> reset . append ( song ) <TAB> librarian . changed ( reset )",if dialog . run ( ) != Gtk . ResponseType . YES :,if not dialog . is_valid ( ) :,64.30784224182476,93.77,False
1043,"def get_or_create_place ( self , place_name ) : <TAB> "" Return the requested place object tuple-packed with a new indicator. "" <TAB> LOG . debug ( "" get_or_create_place: looking for:  %s "" , place_name ) <TAB> for place_handle in self . db . iter_place_handles ( ) : <TAB><TAB> place = self . db . get_place_from_handle ( place_handle ) <TAB><TAB> place_title = place_displayer . display ( self . db , place ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( 0 , place ) <TAB> place = Place ( ) <TAB> place . set_title ( place_name ) <TAB> place . name = PlaceName ( value = place_name ) <TAB> self . db . add_place ( place , self . trans ) <TAB> return ( 1 , place )",if place_title == place_name :,"if place_title == """" :",77.1377267822075,97.92,False
1044,def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB><TAB> <MASK> <TAB><TAB><TAB> if constraint_data . variables is None : <TAB><TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> if constraint_data . body . polynomial_degree ( ) == 0 : <TAB><TAB><TAB><TAB> return True <TAB> return False,"if isinstance ( constraint_data , LinearCanonicalRepn ) :","if isinstance ( constraint_data . body , Composite ) :",67.81099218404607,95.66,False
1045,"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB><TAB> data = list ( data ) <TAB><TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB><TAB> m_items = items . copy ( ) <TAB><TAB> for idx , item in enumerate ( items ) : <TAB><TAB><TAB> if item < 0 : <TAB><TAB><TAB><TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del data [ i ] <TAB><TAB> if is_tuple : <TAB><TAB><TAB> return tuple ( data ) <TAB><TAB> else : <TAB><TAB><TAB> return data <TAB> else : <TAB><TAB> return None",if i < len ( data ) and i > - 1 :,if i != idx :,67.03517923991723,95.51,False
1046,"def test_case_insensitivity ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB><TAB> env . set ( "" PYTHONCASEOK "" , "" 1 "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB><TAB> loader = self . find_module ( ) <TAB><TAB> self . assertTrue ( hasattr ( loader , "" load_module "" ) )","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :","if not hasattr ( _os . environ , ""PYTHONCASEOK"" ) :",88.79681507631263,91.70,False
1047,def field_spec ( self ) : <TAB> <MASK> <TAB><TAB> self . lazy_init_lock_ . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . field_spec_ = FieldSpec ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . field_spec_,if self . field_spec_ is None :,if self . field_spec_ is None :,100.0,100.00,True
1048,"def reduce ( self , f , init ) : <TAB> for x in range ( self . _idx , rt . count ( self . _w_array ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return rt . deref ( init ) <TAB><TAB> init = f . invoke ( [ init , rt . nth ( self . _w_array , rt . wrap ( x ) ) ] ) <TAB> return init",if rt . reduced_QMARK_ ( init ) :,if rt . reduced_QMARK_ ( init ) :,100.0,100.00,True
1049,"def _find ( event : E ) - > None : <TAB> # We first check values after the selected value, then all values. <TAB> values = list ( self . values ) <TAB> for value in values [ self . _selected_index + 1 : ] + values : <TAB><TAB> text = fragment_list_to_text ( to_formatted_text ( value [ 1 ] ) ) . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _selected_index = self . values . index ( value ) <TAB><TAB><TAB> return",if text . startswith ( event . data . lower ( ) ) :,if text in self . values :,68.58902853010692,91.50,False
1050,"def check_permissions ( ) : <TAB> if platform_os ( ) != "" Windows "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( localization . lang_check_permissions [ "" permissions_granted "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> print ( localization . lang_check_permissions [ "" permissions_denied "" ] ) <TAB><TAB><TAB> exit ( ) <TAB> else : <TAB><TAB> print ( localization . lang_check_permissions [ "" windows_warning "" ] ) <TAB><TAB> exit ( )",if getuid ( ) == 0 :,"if localization . lang_check_permissions [ ""permissions_granted"" ] :",67.89423958342273,89.76,False
1051,"def _ProcessName ( self , name , dependencies ) : <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB><TAB> if module_name : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dependencies [ module_name ] . add ( base_name ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> dependencies [ module_name ] = { base_name } <TAB><TAB> else : <TAB><TAB><TAB> # If we have a relative import that did not get qualified (usually due <TAB><TAB><TAB> # to an empty package_name), don't insert module_name='' into the <TAB><TAB><TAB> # dependencies; we get a better error message if we filter it out here <TAB><TAB><TAB> # and fail later on. <TAB><TAB><TAB> logging . warning ( "" Empty package name:  %s "" , name )",if module_name in dependencies :,if base_name in dependencies [ module_name ] :,96.16471266018866,96.92,False
1052,"def _load_db ( self ) : <TAB> try : <TAB><TAB> with open ( self . db ) as db : <TAB><TAB><TAB> content = db . read ( 8 ) <TAB><TAB><TAB> db . seek ( 0 ) <TAB><TAB><TAB> if content == ( "" Salted__ "" ) : <TAB><TAB><TAB><TAB> data = StringIO ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . encryptor . decrypt ( db , data ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> raise EncryptionError ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return json . loads ( data . getvalue ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return json . load ( db ) <TAB> except : <TAB><TAB> return { "" creds "" : [ ] }",if self . encryptor :,if self . encryptor :,100.0,100.00,True
1053,"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB><TAB> context_for_subcon = context <TAB><TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB><TAB><TAB> context_for_subcon = context . __copy__ ( ) <TAB><TAB> while True : <TAB><TAB><TAB> subobj = self . subcon . _parse ( stream , context_for_subcon ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> obj . append ( subobj ) <TAB> except ConstructError as ex : <TAB><TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj","if self . predicate ( subobj , context ) :",if not subobj :,65.48770129471467,95.11,False
1054,"def is_active_for_user ( self , user ) : <TAB> is_active = super ( AbstractUserFlag , self ) . is_active_for_user ( user ) <TAB> if is_active : <TAB><TAB> return is_active <TAB> user_ids = self . _get_user_ids ( ) <TAB> if hasattr ( user , "" pk "" ) and user . pk in user_ids : <TAB><TAB> return True <TAB> if hasattr ( user , "" groups "" ) : <TAB><TAB> group_ids = self . _get_group_ids ( ) <TAB><TAB> if group_ids : <TAB><TAB><TAB> user_groups = set ( user . groups . all ( ) . values_list ( "" pk "" , flat = True ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return None",if group_ids . intersection ( user_groups ) :,"if user_groups and user_groups . get ( ""id"" ) == group_ids",81.40374153014902,92.64,False
1055,"def lookup_member ( self , member_name ) : <TAB> document_choices = self . choices or [ ] <TAB> for document_choice in document_choices : <TAB><TAB> doc_and_subclasses = [ document_choice ] + document_choice . __subclasses__ ( ) <TAB><TAB> for doc_type in doc_and_subclasses : <TAB><TAB><TAB> field = doc_type . _fields . get ( member_name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return field",if field :,if field :,100.0,100.00,True
1056,"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB><TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> if family : <TAB><TAB><TAB> father_handle = family . get_father_handle ( ) <TAB><TAB><TAB> mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB> if not father_handle : <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False",if not mother_handle :,if not mother_handle :,100.0,100.00,True
1057,"def init_weights ( self ) : <TAB> for m in self . modules ( ) : <TAB><TAB> if isinstance ( m , nn . Linear ) : <TAB><TAB><TAB> normal_init ( m , std = 0.01 ) <TAB><TAB> if isinstance ( m , nn . Conv3d ) : <TAB><TAB><TAB> xavier_init ( m , distribution = "" uniform "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> constant_init ( m , 1 )","if isinstance ( m , nn . BatchNorm3d ) :","if isinstance ( m , nn . BatchNorm3d ) :",75.0,100.00,True
1058,"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn <TAB><TAB> elif step_num < 30000 : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 10 <TAB><TAB> elif step_num < 35000 : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 100 <TAB><TAB> else : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB><TAB> fd [ model . lrn_rate ] = lrn_rate",if step_num < hparams . lrn_step :,if step_num < 10 :,73.10558392991359,96.95,False
1059,"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB><TAB> if is_push_data_token ( token ) : <TAB><TAB><TAB> yield DataToken ( read_data ( token , source ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB><TAB> else : <TAB><TAB><TAB> yield Token ( token ) <TAB><TAB> token = source . read_uint8 ( )",elif is_small_integer ( token ) :,elif is_push_small_integer_token ( token ) :,98.23905109290143,95.65,False
1060,"def user_info ( oicsrv , userdb , sub , client_id = "" "" , user_info_claims = None ) : <TAB> identity = userdb [ sub ] <TAB> if user_info_claims : <TAB><TAB> result = { } <TAB><TAB> for key , restr in user_info_claims [ "" claims "" ] . items ( ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> result [ key ] = identity [ key ] <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise Exception ( "" Missing property  ' %s ' "" % key ) <TAB> else : <TAB><TAB> result = identity <TAB> return OpenIDSchema ( * * result )","if restr == { ""essential"" : True } :",if not restr :,72.08297923995136,94.36,False
1061,"def _helpSlot ( self , * args ) : <TAB> help_text = "" Filters are applied to packets in both direction. \n \n "" <TAB> filter_nb = 0 <TAB> for filter in self . _filters : <TAB><TAB> help_text + = "" {} :  {} "" . format ( filter [ "" name "" ] , filter [ "" description "" ] ) <TAB><TAB> filter_nb + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> help_text + = "" \n \n "" <TAB> QtWidgets . QMessageBox . information ( self , "" Help for filters "" , help_text )",if len ( self . _filters ) != filter_nb :,if filter_nb == len ( self . _filters ) :,83.35356998598184,95.99,False
1062,"def find_user_theme ( self , name : str ) - > Theme : <TAB> """"""Find a theme named as *name* from latex_theme_path."""""" <TAB> for theme_path in self . theme_paths : <TAB><TAB> config_path = path . join ( theme_path , name , "" theme.conf "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return UserTheme ( name , config_path ) <TAB><TAB><TAB> except ThemeError as exc : <TAB><TAB><TAB><TAB> logger . warning ( exc ) <TAB> return None",if path . isfile ( config_path ) :,if path . exists ( config_path ) :,98.44012880228077,98.47,False
1063,"def decompress ( self , value ) : <TAB> if value : <TAB><TAB> <MASK> <TAB><TAB><TAB> if value . country_code and value . national_number : <TAB><TAB><TAB><TAB> return [ <TAB><TAB><TAB><TAB><TAB> "" + %d "" % value . country_code , <TAB><TAB><TAB><TAB><TAB> national_significant_number ( value ) , <TAB><TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ]",if type ( value ) == PhoneNumber :,"if ""."" in value :",67.92579353015051,94.95,False
1064,"def update_prevdoc_status ( self , flag ) : <TAB> for quotation in list ( set ( [ d . prevdoc_docname for d in self . get ( "" items "" ) ] ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> doc = frappe . get_doc ( "" Quotation "" , quotation ) <TAB><TAB><TAB> if doc . docstatus == 2 : <TAB><TAB><TAB><TAB> frappe . throw ( _ ( "" Quotation  {0}  is cancelled "" ) . format ( quotation ) ) <TAB><TAB><TAB> doc . set_status ( update = True ) <TAB><TAB><TAB> doc . update_opportunity ( )",if quotation :,"if flag and not frappe . db . exists ( ""Questation"" , quotation",91.52059872589294,91.05,False
1065,"def map ( item ) : <TAB> if item . deleted : <TAB><TAB> return <TAB> exploration = exp_fetchers . get_exploration_from_model ( item ) <TAB> for state_name , state in exploration . states . items ( ) : <TAB><TAB> hints_length = len ( state . interaction . hints ) <TAB><TAB> <MASK> <TAB><TAB><TAB> exp_and_state_key = "" %s   %s "" % ( item . id , state_name . encode ( "" utf-8 "" ) ) <TAB><TAB><TAB> yield ( python_utils . UNICODE ( hints_length ) , exp_and_state_key )",if hints_length > 0 :,if hints_length > 0 :,100.0,100.00,True
1066,"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB><TAB> if self . _args . host and self . _args . host == machine . name : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> <MASK> <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> if self . locations and machine . location in self . locations : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB> return selected_machines","if self . tags and self . _tags_match ( machine . tags , self . tags ) :",if self . _args . port and self . _args . port == machine . port :,90.5677063116214,90.77,False
1067,"def _ripple_trim_compositors_move ( self , delta ) : <TAB> comp_ids = self . multi_data . moved_compositors_destroy_ids <TAB> tracks_compositors = _get_tracks_compositors_list ( ) <TAB> track_moved = self . multi_data . track_affected <TAB> for i in range ( 1 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB><TAB> if not track_moved [ i - 1 ] : <TAB><TAB><TAB> continue <TAB><TAB> track_comps = tracks_compositors [ i - 1 ] <TAB><TAB> for comp in track_comps : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> comp . move ( delta )",if comp . destroy_id in comp_ids :,if comp . id in comp_ids :,98.62700001990608,98.12,False
1068,"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB><TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB><TAB><TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB> elif "" error "" in line : <TAB><TAB><TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB> raise DockerBuildError","elif ""status"" in line :","elif ""status"" in line and line [ ""status"" ] . strip ( ) :",96.0981697949203,92.44,False
1069,"def create_keyfile ( self , keyfile , size = 64 , force = False ) : <TAB> if force or not os . path . exists ( keyfile ) : <TAB><TAB> keypath = os . path . dirname ( keyfile ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( keypath ) <TAB><TAB> subprocess . run ( <TAB><TAB><TAB> [ "" dd "" , "" if=/dev/random "" , f "" of= { keyfile } "" , f "" bs= { size } "" , "" count=1 "" ] , <TAB><TAB><TAB> check = True , <TAB><TAB><TAB> stdout = subprocess . DEVNULL , <TAB><TAB><TAB> stderr = subprocess . DEVNULL , <TAB><TAB> )",if not os . path . exists ( keypath ) :,if not os . path . exists ( keypath ) :,100.0,100.00,True
1070,"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB><TAB> self . clear ( ) <TAB><TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB><TAB> if self . op == "" + "" : <TAB><TAB><TAB> self . current + = num <TAB><TAB> elif self . op == "" - "" : <TAB><TAB><TAB> self . current - = num <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current * = num <TAB><TAB> elif self . op == "" / "" : <TAB><TAB><TAB> self . current / = num <TAB><TAB> self . op = op <TAB> else : <TAB><TAB> self . op = op <TAB><TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB><TAB> self . clear ( ) <TAB> return res","elif self . op == ""*"" :","elif self . op == ""*"" :",100.0,100.00,True
1071,"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB><TAB> if - delta < expr . get_float_value ( ) < delta : <TAB><TAB><TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB><TAB> real , imag = expr . real , expr . imag <TAB><TAB> <MASK> <TAB><TAB><TAB> real = Integer ( 0 ) <TAB><TAB> if - delta < imag . get_float_value ( ) < delta : <TAB><TAB><TAB> imag = Integer ( 0 ) <TAB><TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB><TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr",if - delta < real . get_float_value ( ) < delta :,if - delta < real . get_float_value ( ) < delta :,100.0,100.00,True
1072,"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB><TAB> from galaxy . files import ConfiguredFileSources <TAB><TAB> file_sources = None <TAB><TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB><TAB><TAB> file_sources_as_dict = None <TAB><TAB><TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> file_sources_as_dict = json . load ( f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB><TAB> if file_sources is None : <TAB><TAB><TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB><TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources_as_dict is not None :,if file_sources_as_dict is not None :,100.0,100.00,True
1073,"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if tag . user : <TAB><TAB><TAB><TAB> tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB> if tag . internal : <TAB><TAB><TAB><TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts",if tag . has_sort :,if name not in tts :,95.52817479952027,95.56,False
1074,"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB><TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB><TAB><TAB> ) <TAB><TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name , ( description , default ) in self . options . items ( ) : <TAB><TAB> if not name in self . option_values : <TAB><TAB><TAB> self . option_values [ name ] = default",if not key in self . options :,if not key in self . options :,100.0,100.00,True
1075,"def modify_bottle_params ( self , output_stride = None ) : <TAB> if output_stride is not None and output_stride % 2 != 0 : <TAB><TAB> raise Exception ( "" output stride must to be even number "" ) <TAB> if output_stride is None : <TAB><TAB> return <TAB> else : <TAB><TAB> stride = 2 <TAB><TAB> for i , _cfg in enumerate ( self . cfg ) : <TAB><TAB><TAB> stride = stride * _cfg [ - 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> s = 1 <TAB><TAB><TAB><TAB> self . cfg [ i ] [ - 1 ] = s",if stride > output_stride :,if stride == output_stride :,98.71889941374535,98.03,False
1076,"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB><TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB><TAB> if len ( q ) == 1 : <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . append ( value ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB><TAB> else : <TAB><TAB><TAB> if not is_iterable ( value ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",elif is_iterable ( value ) :,elif key == q [ 0 ] :,96.58376689435383,96.82,False
1077,"def make_shares ( self , plaintext ) : <TAB> share_arrays = [ ] <TAB> for i , p in enumerate ( plaintext ) : <TAB><TAB> share_array = self . make_byte_shares ( p ) <TAB><TAB> for sa in share_array : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> share_arrays . append ( array . array ( "" H "" ) ) <TAB><TAB><TAB> current_share_array = sa <TAB><TAB><TAB> current_share_array . append ( sa ) <TAB> return share_arrays",if i == 0 :,"if sa . dtype == ""uint8"" :",93.00011268108099,94.21,False
1078,"def populate ( self , item ) : <TAB> # log.message('populate: %s', item) <TAB> path = self . getItemPath ( item ) <TAB> # log.message('populate: path=%s', path) <TAB> value = self . getValue ( path ) <TAB> for name in sorted ( value . __dict__ . keys ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> child = getattr ( value , name , None ) <TAB><TAB> if hasattr ( child , "" __dict__ "" ) : <TAB><TAB><TAB> item . addChild ( name , True ) <TAB><TAB> else : <TAB><TAB><TAB> item . addChild ( name , False )","if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :","if name . startswith ( ""_"" ) :",67.72492753989042,88.20,False
1079,"def __repr__ ( self ) : <TAB> try : <TAB><TAB> if self . _semlock . _is_mine ( ) : <TAB><TAB><TAB> name = current_process ( ) . name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> name + = "" | "" + threading . current_thread ( ) . name <TAB><TAB> elif self . _semlock . _get_value ( ) == 1 : <TAB><TAB><TAB> name = "" None "" <TAB><TAB> elif self . _semlock . _count ( ) > 0 : <TAB><TAB><TAB> name = "" SomeOtherThread "" <TAB><TAB> else : <TAB><TAB><TAB> name = "" SomeOtherProcess "" <TAB> except Exception : <TAB><TAB> name = "" unknown "" <TAB> return "" <Lock(owner= %s )> "" % name","if threading . current_thread ( ) . name != ""MainThread"" :",if self . _semlock . _is_mine ( ) :,80.12553843113439,93.86,False
1080,"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB><TAB> elif scroll_if_editing : <TAB><TAB><TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets )",if not self . editing :,if self . _my_widgets :,85.68929669575735,95.37,False
1081,"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB><TAB> if dep . repo is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for repo in dep . repo . repos : <TAB><TAB><TAB> if repo . from_config : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) )","if not isinstance ( dep . repo , WarehouseBaseRepo ) :","if dep . repo . name in [ ""project"" , ""project_dir"" ] :",92.83601181241742,90.27,False
1082,"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef ( "" "" , { } , None ) <TAB> for name in dir ( src_flag ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> dest_val = getattr ( dest_flag , name , None ) <TAB><TAB> baseline_val = getattr ( baseline_flag , name , None ) <TAB><TAB> if dest_val == baseline_val : <TAB><TAB><TAB> setattr ( dest_flag , name , getattr ( src_flag , name ) )","if name [ : 1 ] == ""_"" :","if name . startswith ( ""_"" ) :",71.3254802985729,94.77,False
1083,"def out ( parent , attr , indent = 0 ) : <TAB> val = getattr ( parent , attr ) <TAB> prefix = "" %s %s : "" % ( ""   "" * indent , attr . replace ( "" _ "" , "" - "" ) ) <TAB> if val is None : <TAB><TAB> cli . out ( prefix ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> val = [ flag_util . encode_flag_val ( c . value ) for c in val ] <TAB><TAB> cli . out ( "" %s   %s "" % ( prefix , flag_util . encode_flag_val ( val ) ) )","if attr == ""choices"" :","if isinstance ( val , list ) :",94.46650426314852,95.23,False
1084,"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB><TAB> x = cand . creator <TAB><TAB> if x is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB><TAB><TAB> heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB><TAB> fan_out [ x ] + = 1",if x not in fan_out :,if x . rank != 0 :,92.81561911621444,95.33,False
1085,"def task_tree_lines ( task = None ) : <TAB> if task is None : <TAB><TAB> task = current_root_task ( ) <TAB> rendered_children = [ ] <TAB> nurseries = list ( task . child_nurseries ) <TAB> while nurseries : <TAB><TAB> nursery = nurseries . pop ( ) <TAB><TAB> nursery_children = _rendered_nursery_children ( nursery ) <TAB><TAB> <MASK> <TAB><TAB><TAB> nested = _render_subtree ( "" (nested nursery) "" , rendered_children ) <TAB><TAB><TAB> nursery_children . append ( nested ) <TAB><TAB> rendered_children = nursery_children <TAB> return _render_subtree ( task . name , rendered_children )",if rendered_children :,if nursery_children :,87.4226793832833,98.59,False
1086,"def lock_workspace ( build_dir ) : <TAB> _BUILDING_LOCK_FILE = "" .blade.building.lock "" <TAB> lock_file_fd , ret_code = lock_file ( os . path . join ( build_dir , _BUILDING_LOCK_FILE ) ) <TAB> if lock_file_fd == - 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> console . fatal ( "" There is already an active building in current workspace. "" ) <TAB><TAB> else : <TAB><TAB><TAB> console . fatal ( "" Lock exception, please try it later. "" ) <TAB> return lock_file_fd",if ret_code == errno . EAGAIN :,if ret_code == 0 :,94.70454466588038,97.16,False
1087,"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB><TAB> self . assertIn ( "" bbox "" , feature ) <TAB><TAB> fid = feature [ "" id "" ] <TAB><TAB> if fid == 1 : <TAB><TAB><TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( )",elif fid == 2 :,elif fid == 2 :,100.0,100.00,True
1088,"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R , V = rays , virtual_rays <TAB> if V is not None : <TAB><TAB> if normalize : <TAB><TAB><TAB> V = normalize_rays ( V , lattice ) <TAB><TAB> if check : <TAB><TAB><TAB> R = PointCollection ( V , lattice ) <TAB><TAB><TAB> V = PointCollection ( V , lattice ) <TAB><TAB><TAB> d = lattice . dimension ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB><TAB> "" virtual rays must be linearly  "" <TAB><TAB><TAB><TAB><TAB> "" independent and with other rays span the ambient space. "" <TAB><TAB><TAB><TAB> ) <TAB> return RationalPolyhedralFan ( cones , R , lattice , is_complete , V )",if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,if d != 1 :,65.66136064615378,89.39,False
1089,"def search_host ( self , search_string ) : <TAB> results = [ ] <TAB> for host_entry in self . config_data : <TAB><TAB> if host_entry . get ( "" type "" ) != "" entry "" : <TAB><TAB><TAB> continue <TAB><TAB> if host_entry . get ( "" host "" ) == "" * "" : <TAB><TAB><TAB> continue <TAB><TAB> searchable_information = host_entry . get ( "" host "" ) <TAB><TAB> for key , value in six . iteritems ( host_entry . get ( "" options "" ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = ""   "" . join ( value ) <TAB><TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB><TAB> value = str ( value ) <TAB><TAB><TAB> searchable_information + = ""   "" + value <TAB><TAB> if search_string in searchable_information : <TAB><TAB><TAB> results . append ( host_entry ) <TAB> return results","if isinstance ( value , list ) :","if isinstance ( value , list ) :",100.0,100.00,True
1090,"def test_async_iterator ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB><TAB> for i in range ( 100 ) : <TAB><TAB><TAB> await stream . channel . deliver ( message ( key = i , value = i ) ) <TAB><TAB> received = 0 <TAB><TAB> async for value in stream : <TAB><TAB><TAB> assert value == received <TAB><TAB><TAB> received + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> assert await channel_empty ( stream . channel )",if received >= 100 :,if received >= 100 :,100.0,100.00,True
1091,"def has_google_credentials ( ) : <TAB> global _HAS_GOOGLE_CREDENTIALS <TAB> if _HAS_GOOGLE_CREDENTIALS is None : <TAB><TAB> provider = Provider ( "" google "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _HAS_GOOGLE_CREDENTIALS = False <TAB><TAB> else : <TAB><TAB><TAB> _HAS_GOOGLE_CREDENTIALS = True <TAB> return _HAS_GOOGLE_CREDENTIALS",if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,if provider . is_google :,53.99196025689661,81.90,False
1092,"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB><TAB> a = self . _d . getTime ( ) <TAB><TAB> b = other . _d . getTime ( ) <TAB><TAB> if a < b : <TAB><TAB><TAB> return - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> return 0 <TAB> else : <TAB><TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1",elif a == b :,elif b > a :,97.47895827558033,96.24,False
1093,"def validate_weight ( self , weight ) : <TAB> try : <TAB><TAB> add_acl_to_obj ( self . context [ "" user_acl "" ] , self . category ) <TAB> except AttributeError : <TAB><TAB> return weight # don't validate weight further if category failed <TAB> if weight > self . category . acl . get ( "" can_pin_threads "" , 0 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> _ ( <TAB><TAB><TAB><TAB><TAB> "" You don ' t have permission to pin threads globally  "" <TAB><TAB><TAB><TAB><TAB> "" in this category. "" <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> _ ( "" You don ' t have permission to pin threads in this category. "" ) <TAB><TAB><TAB> ) <TAB> return weight",if weight == 2 :,"if self . category . acl . get ( ""can_pin_threads"" , False )",96.42622720126272,92.94,False
1094,"def effective ( line ) : <TAB> for b in line : <TAB><TAB> if not b . cond : <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> val = 5 <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if b . ignore : <TAB><TAB><TAB><TAB><TAB><TAB> b . ignore - = 1 <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> return ( b , True ) <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> return ( b , False ) <TAB> return",if val :,if val > 0 :,69.91210757329672,98.28,False
1095,"def wheelEvent ( self , event ) : <TAB> """"""Handle a wheel event."""""" <TAB> if QtCore . Qt . ControlModifier & event . modifiers ( ) : <TAB><TAB> d = { "" c "" : self . leo_c } <TAB><TAB> if isQt5 : <TAB><TAB><TAB> point = event . angleDelta ( ) <TAB><TAB><TAB> delta = point . y ( ) or point . x ( ) <TAB><TAB> else : <TAB><TAB><TAB> delta = event . delta ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> zoom_out ( d ) <TAB><TAB> else : <TAB><TAB><TAB> zoom_in ( d ) <TAB><TAB> event . accept ( ) <TAB><TAB> return <TAB> QtWidgets . QTextBrowser . wheelEvent ( self , event )",if delta < 0 :,if delta < 0 :,100.0,100.00,True
1096,"def test_evname_in_mp_events_testcases ( ) : <TAB> ok = True <TAB> for evname in ins . mp_events : <TAB><TAB> if evname == "" version "" : <TAB><TAB><TAB> continue <TAB><TAB> for i , args in enumerate ( ins . mp_events [ evname ] [ "" test_cases "" ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> msg = "" Error, for evname  %s  the testase # %d  does not match evname "" <TAB><TAB><TAB><TAB> print ( msg % ( evname , i ) ) <TAB><TAB><TAB><TAB> ok = False <TAB> if ok : <TAB><TAB> print ( "" test_evname_in_mp_events_testcases: passed "" )",if evname != args [ 0 ] :,"if args [ 0 ] != ""test_evname_in_mp_events_test",66.52757520196309,92.41,False
1097,"def check_database ( ) : <TAB> if len ( EmailAddress . objects . all ( ) ) > 0 : <TAB><TAB> print ( <TAB><TAB><TAB> "" Are you sure you want to wipe the existing development database and reseed it? (Y/N) "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> destroy_database ( ) <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> else : <TAB><TAB> return True","if raw_input ( ) . lower ( ) == ""y"" :","if EmailAddress . objects . filter ( name = ""y"" ) . exists ( ) :",64.20493243047378,90.36,False
1098,"def _get_requested_databases ( self ) : <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB><TAB> for requested_namespace in self . _requested_namespaces : <TAB><TAB><TAB> if requested_namespace [ 0 ] is "" * "" : <TAB><TAB><TAB><TAB> return [ ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases",elif requested_namespace [ 0 ] not in IGNORE_DBS :,"if requested_namespace [ 0 ] not in [ ""*"" , ""*"" ] :",93.94774464982262,92.82,False
1099,"def decorated ( self , * args , * * kwargs ) : <TAB> start_time = time . perf_counter ( ) <TAB> stderr = "" "" <TAB> saved_exception = None <TAB> try : <TAB><TAB> yield from fn ( self , * args , * * kwargs ) <TAB> except GitSavvyError as e : <TAB><TAB> stderr = e . stderr <TAB><TAB> saved_exception = e <TAB> finally : <TAB><TAB> end_time = time . perf_counter ( ) <TAB><TAB> util . debug . log_git ( args , None , "" <SNIP> "" , stderr , end_time - start_time ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise saved_exception from None",if saved_exception :,if saved_exception is not None :,80.2670319902727,97.49,False
1100,"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None : <TAB><TAB> return False <TAB> for warning_type in suppress_warnings : <TAB><TAB> if "" . "" in warning_type : <TAB><TAB><TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB><TAB> else : <TAB><TAB><TAB> target , subtarget = warning_type , None <TAB><TAB> <MASK> <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> subtype is None <TAB><TAB><TAB><TAB> or subtarget is None <TAB><TAB><TAB><TAB> or subtarget == subtype <TAB><TAB><TAB><TAB> or subtarget == "" * "" <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> return True <TAB> return False",if target == type :,if target is not None :,77.60934866998979,98.27,False
1101,"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB><TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB><TAB> i = self . readSentence ( ) <TAB><TAB> if len ( i ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> reply = i [ 0 ] <TAB><TAB> attrs = { } <TAB><TAB> for w in i [ 1 : ] : <TAB><TAB><TAB> j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB> if j == - 1 : <TAB><TAB><TAB><TAB> attrs [ w ] = "" "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB> r . append ( ( reply , attrs ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return r","if reply == ""!done"" :",if len ( r ) == self . max_words :,69.31782132614246,95.41,False
1102,"def encrypt ( self , plaintext ) : <TAB> encrypted = [ ] <TAB> for p in _string_to_bytes ( plaintext ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _remaining_block = self . _aes . encrypt ( self . _last_precipherblock ) <TAB><TAB><TAB> self . _last_precipherblock = [ ] <TAB><TAB> precipherbyte = self . _remaining_block . pop ( 0 ) <TAB><TAB> self . _last_precipherblock . append ( precipherbyte ) <TAB><TAB> cipherbyte = p ^ precipherbyte <TAB><TAB> encrypted . append ( cipherbyte ) <TAB> return _bytes_to_string ( encrypted )",if len ( self . _remaining_block ) == 0 :,if self . _last_precipherblock :,91.44092476446424,93.01,False
1103,"def find_symbol ( self , r , globally = False ) : <TAB> query = self . view . substr ( self . view . word ( r ) ) <TAB> fname = self . view . file_name ( ) . replace ( "" \\ "" , "" / "" ) <TAB> locations = self . view . window ( ) . lookup_symbol_in_index ( query ) <TAB> if not locations : <TAB><TAB> return <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> location = [ hit [ 2 ] for hit in locations if fname . endswith ( hit [ 1 ] ) ] [ 0 ] <TAB><TAB><TAB> return location [ 0 ] - 1 , location [ 1 ] - 1 <TAB><TAB> else : <TAB><TAB><TAB> # TODO: There might be many symbols with the same name. <TAB><TAB><TAB> return locations [ 0 ] <TAB> except IndexError : <TAB><TAB> return",if not globally :,if globally :,97.9446771086991,98.88,False
1104,"def __getslice__ ( self , i , j ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> # handle the case where the right bound is unspecified <TAB><TAB><TAB> j = len ( self ) <TAB><TAB> if i < 0 or j < 0 : <TAB><TAB><TAB> raise dns . exception . FormError <TAB><TAB> # If it's not an empty slice, access left and right bounds <TAB><TAB> # to make sure they're valid <TAB><TAB> if i != j : <TAB><TAB><TAB> super ( WireData , self ) . __getitem__ ( i ) <TAB><TAB><TAB> super ( WireData , self ) . __getitem__ ( j - 1 ) <TAB><TAB> return WireData ( super ( WireData , self ) . __getslice__ ( i , j ) ) <TAB> except IndexError : <TAB><TAB> raise dns . exception . FormError",if j == sys . maxint :,if i == 0 :,91.15740018134578,97.10,False
1105,"def main ( ) : <TAB> r = redis . StrictRedis ( ) <TAB> curr_memory = prev_memory = r . info ( ) [ "" used_memory "" ] <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" Delta Memory :  %d , Total Memory :  %d "" <TAB><TAB><TAB><TAB> % ( ( curr_memory - prev_memory ) , curr_memory ) <TAB><TAB><TAB> ) <TAB><TAB> time . sleep ( 1 ) <TAB><TAB> prev_memory = curr_memory <TAB><TAB> curr_memory = r . info ( ) [ "" used_memory "" ]",if prev_memory != curr_memory :,"if r . info ( ) [ ""used_memory"" ] > curr_memory - prev",81.19847812304819,90.95,False
1106,"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB><TAB> if self . _flags [ fname ] == 1 : <TAB><TAB><TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB> import sys <TAB><TAB><TAB> sys . exit ( - 1 ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _flags [ fname ] = 1 <TAB><TAB> for output in func [ 3 ] : <TAB><TAB><TAB> for f in self . _orig : <TAB><TAB><TAB><TAB> for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB> if output == input : <TAB><TAB><TAB><TAB><TAB><TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if fname not in self . _flags :,if fname in self . _orig :,91.48502321281394,98.18,False
1107,"def urls ( self , version = None ) : <TAB> """"""Returns all URLS that are mapped to this interface"""""" <TAB> urls = [ ] <TAB> for _base_url , routes in self . api . http . routes . items ( ) : <TAB><TAB> for url , methods in routes . items ( ) : <TAB><TAB><TAB> for _method , versions in methods . items ( ) : <TAB><TAB><TAB><TAB> for interface_version , interface in versions . items ( ) : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> if not url in urls : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> urls . append ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB><TAB> ( "" /v {0} "" . format ( version ) if version else "" "" ) + url <TAB><TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB> return urls",if interface_version == version and interface == self :,if interface_version == version :,96.43475505282164,97.57,False
1108,"def _handle_data ( self , text ) : <TAB> if self . _translate : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _data . append ( text ) <TAB><TAB> else : <TAB><TAB><TAB> self . _translate = False <TAB><TAB><TAB> self . _data = [ ] <TAB><TAB><TAB> self . _comments = [ ]","if not text . startswith ( ""gtk-"" ) :",if self . _translate :,82.52483740756922,90.49,False
1109,"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB><TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB><TAB> if not self . dry_run : <TAB><TAB><TAB> os . chmod ( dirpath , mode )",if os . path . islink ( dirpath ) :,if not self . is_chmod_supported ( dirpath ) :,66.1387416542834,93.21,False
1110,"def language ( self ) : <TAB> if self . lang_data : <TAB><TAB> lang_data = [ s if s != "" None "" else None for s in self . lang_data ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return Language ( lang_data [ 0 ] , country = lang_data [ 1 ] , script = lang_data [ 2 ] )",if lang_data [ 0 ] :,if lang_data :,66.36707085585488,95.27,False
1111,"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB><TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol : <TAB><TAB> for col in range ( 0 , nCol , 2 ) : <TAB><TAB><TAB> # FIND RIGHT COLUMN <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> if col + 2 == nCol : <TAB><TAB><TAB> # MAKE NEW ROW <TAB><TAB><TAB> col = 0 <TAB><TAB><TAB> row + = 1 <TAB> self . layout . addItem ( sample , row , col ) <TAB> self . layout . addItem ( label , row , col + 1 )","if not self . layout . itemAt ( row , col ) :",if col == nCol :,95.55763734294989,94.54,False
1112,"def align_comments ( tlist ) : <TAB> tidx , token = tlist . token_next_by ( i = sql . Comment ) <TAB> while token : <TAB><TAB> pidx , prev_ = tlist . token_prev ( tidx ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tlist . group_tokens ( sql . TokenList , pidx , tidx , extend = True ) <TAB><TAB><TAB> tidx = pidx <TAB><TAB> tidx , token = tlist . token_next_by ( i = sql . Comment , idx = tidx )","if isinstance ( prev_ , sql . TokenList ) :",if prev_ :,69.74533330906421,92.76,False
1113,"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB><TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB><TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB><TAB> if params [ "" Attributes "" ] != 0 : <TAB><TAB><TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB><TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return EFI_BUFFER_TOO_SMALL <TAB><TAB> if params [ "" Data "" ] != 0 : <TAB><TAB><TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB><TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND",if read_len < len ( var ) :,if read_len < 0 :,96.51095543560375,97.56,False
1114,"def _PromptMySQL ( self , config ) : <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True : <TAB><TAB> self . _PromptMySQLOnce ( config ) <TAB><TAB> if self . _CheckMySQLConnection ( ) : <TAB><TAB><TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB><TAB><TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ConfigInitError ( )",if not retry :,if not retry :,100.0,100.00,True
1115,"def split_long_line_with_indent ( line , max_per_line , indent ) : <TAB> """"""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines."""""" <TAB> words = line . split ( ""   "" ) <TAB> lines = [ ] <TAB> current_line = words [ 0 ] <TAB> for word in words [ 1 : ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> lines . append ( current_line ) <TAB><TAB><TAB> current_line = ""   "" * indent + word <TAB><TAB> else : <TAB><TAB><TAB> current_line = f "" { current_line }   { word } "" <TAB> lines . append ( current_line ) <TAB> return "" \n "" . join ( lines )","if len ( f""{current_line} {word}"" ) > max_per_line :",if max_per_line and len ( word ) > max_per_line :,73.11008847109318,94.14,False
1116,"def gen_cli ( docs_dir ) : <TAB> with open ( os . path . join ( docs_dir , "" CLI_template.md "" ) , "" r "" ) as cli_temp_file : <TAB><TAB> temp_lines = cli_temp_file . readlines ( ) <TAB> lines = [ ] <TAB> for line in temp_lines : <TAB><TAB> matched = re . match ( r "" { onnx-tf.*} "" , line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> command = matched . string . strip ( ) [ 1 : - 1 ] <TAB><TAB><TAB> output = subprocess . check_output ( command . split ( ""   "" ) ) . decode ( "" UTF-8 "" ) <TAB><TAB><TAB> lines . append ( output ) <TAB><TAB> else : <TAB><TAB><TAB> lines . append ( line ) <TAB> with open ( os . path . join ( docs_dir , "" CLI.md "" ) , "" w "" ) as cli_file : <TAB><TAB> cli_file . writelines ( lines )",if matched :,if matched :,100.0,100.00,True
1117,"def read ( self , size = None ) : <TAB> if size == 0 : <TAB><TAB> return "" "" <TAB> data = list ( ) <TAB> while size is None or size > 0 : <TAB><TAB> line = self . readline ( size or - 1 ) <TAB><TAB> if not line : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> size - = len ( line ) <TAB><TAB> data . append ( line ) <TAB> return "" "" . join ( data )",if size is not None :,if size is not None and len ( line ) > size :,72.73332268214638,93.98,False
1118,"def _get_format_and_pattern ( file_path ) : <TAB> file_path = Path ( file_path ) <TAB> with file_path . open ( ) as f : <TAB><TAB> first_line = f . readline ( ) . strip ( ) <TAB><TAB> match = re . match ( r "" format *: *(.+) "" , first_line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" gztar "" , first_line , 1 <TAB><TAB> return match . group ( 1 ) , f . readline ( ) . strip ( ) , 2",if match is None :,if match is None :,100.0,100.00,True
1119,"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB><TAB> try : <TAB><TAB><TAB> if os . path . isfile ( file ) : <TAB><TAB><TAB><TAB> os . unlink ( file ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> shutil . rmtree ( file ) <TAB><TAB> except Exception as error : <TAB><TAB><TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB><TAB><TAB> sys . exit ( 1 )",elif os . path . isdir ( file ) :,elif os . path . isdir ( file ) :,75.0,100.00,True
1120,"def _test_forever ( self , tests ) : <TAB> while True : <TAB><TAB> for test_name in tests : <TAB><TAB><TAB> yield test_name <TAB><TAB><TAB> if self . bad : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return",if self . ns . fail_env_changed and self . environment_changed :,if self . done :,61.51693506150825,86.03,False
1121,"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB><TAB> if line . startswith ( "" #include "" ) or line . startswith ( "" %i nclude "" ) : <TAB><TAB><TAB> line = line . split ( ""   "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ]","if not ( ""<"" in line or line in dep ) :","if line . startswith ( ""dependency"" ) :",73.33428978757678,92.82,False
1122,"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB><TAB> with db_transaction ( ) : <TAB><TAB><TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> key . name = name <TAB><TAB><TAB> if metadata is not None : <TAB><TAB><TAB><TAB> key . metadata . update ( metadata ) <TAB><TAB><TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB><TAB> raise ServiceKeyDoesNotExist",if name is not None :,if name is not None :,100.0,100.00,True
1123,"def range ( self , dimension , data_range = True , dimension_range = True ) : <TAB> if self . nodes and dimension in self . nodes . dimensions ( ) : <TAB><TAB> node_range = self . nodes . range ( dimension , data_range , dimension_range ) <TAB><TAB> <MASK> <TAB><TAB><TAB> path_range = self . _edgepaths . range ( dimension , data_range , dimension_range ) <TAB><TAB><TAB> return max_range ( [ node_range , path_range ] ) <TAB><TAB> return node_range <TAB> return super ( Graph , self ) . range ( dimension , data_range , dimension_range )",if self . _edgepaths :,if self . _edgepaths and dimension in self . _edgepaths . dimensions ( ) :,82.77388185598546,92.75,False
1124,"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB><TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB><TAB> if verbose == True : <TAB><TAB><TAB> print ( e ) <TAB><TAB> return <TAB> while True : <TAB><TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB><TAB> if sock in r : <TAB><TAB><TAB> data = sock . recv ( 1024 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> chan . send ( data ) <TAB><TAB> if chan in r : <TAB><TAB><TAB> data = chan . recv ( 1024 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( )",if len ( data ) == 0 :,if not data :,66.78662441724292,93.96,False
1125,"def output_layer ( self , features , * * kwargs ) : <TAB> """"""Project features to the vocabulary size."""""" <TAB> if self . adaptive_softmax is None : <TAB><TAB> # project back to size of vocabulary <TAB><TAB> <MASK> <TAB><TAB><TAB> return F . linear ( features , self . embed_tokens . weight ) <TAB><TAB> else : <TAB><TAB><TAB> return F . linear ( features , self . embed_out ) <TAB> else : <TAB><TAB> return features",if self . share_input_output_embed :,if self . embed_tokens . weight is not None :,96.81267192737987,93.48,False
1126,"def generate ( self , dest , vars ) : <TAB> util . ensure_dir ( dest ) <TAB> for relpath , src , template in self . _file_templates : <TAB><TAB> file_dest = os . path . join ( dest , relpath ) <TAB><TAB> util . ensure_dir ( os . path . dirname ( file_dest ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shutil . copyfile ( src , file_dest ) <TAB><TAB> else : <TAB><TAB><TAB> _render_template ( template , vars , file_dest )",if template is None :,if os . path . isfile ( file_dest ) :,66.29665382918091,92.14,False
1127,"def _py_matching_callback ( self , context , result , sender , device ) : <TAB> d = HIDDevice . get_device ( c_void_p ( device ) ) <TAB> if d not in self . devices : <TAB><TAB> self . devices . add ( d ) <TAB><TAB> for x in self . matching_observers : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> x . device_discovered ( d )","if hasattr ( x , ""device_discovered"" ) :","if hasattr ( x , ""device_discovered"" ) :",100.0,100.00,True
1128,"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB><TAB> new_kwargs = dict ( kwargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> del new_kwargs [ "" encoding "" ] <TAB><TAB> if "" errors "" in kwargs : <TAB><TAB><TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs )","if ""encoding"" in new_kwargs :","if ""encoding"" in kwargs :",73.21175747296871,97.09,False
1129,"def Set ( self , attr , value ) : <TAB> hook = getattr ( self , "" _set_ %s "" % attr , None ) <TAB> if hook : <TAB><TAB> # If there is a set hook we must use the context manager. <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Can only update attribute  %s  using the context manager. "" % attr <TAB><TAB><TAB> ) <TAB><TAB> if attr not in self . _pending_hooks : <TAB><TAB><TAB> self . _pending_hooks . append ( attr ) <TAB><TAB> self . _pending_parameters [ attr ] = value <TAB> else : <TAB><TAB> super ( Configuration , self ) . Set ( attr , value )",if self . _lock > 0 :,"if not self . _context_manager . Set ( attr , value ) :",96.33124515916246,93.14,False
1130,"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB><TAB> name = f . get_basename ( ) <TAB><TAB> if name . endswith ( "" .mod "" ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> name = name [ 0 : - 11 ] <TAB><TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 )","if name . endswith ( "".sccprofile"" ) :","if name . endswith ( "".py"" ) :",98.74705169905964,98.44,False
1131,"def get_eval_task ( self , worker_id ) : <TAB> """"""Return next evaluation (task_id, Task) tuple"""""" <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return - 1 , None <TAB><TAB> self . _task_id + = 1 <TAB><TAB> task = self . _eval_todo . pop ( ) <TAB><TAB> self . _doing [ self . _task_id ] = ( worker_id , task , time . time ( ) ) <TAB><TAB> return self . _task_id , task",if not self . _eval_todo :,if self . _task_id >= len ( self . _eval_todo ) :,87.98427107567046,91.26,False
1132,"def queries ( self ) : <TAB> if DEV : <TAB><TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not cmd . stdout . strip ( ) : <TAB><TAB><TAB><TAB> log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB><TAB><TAB><TAB><TAB> print ( cmd . stdout ) <TAB><TAB><TAB><TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )","if not cmd . check ( f""docker check for {self.path.k8s}"" ) :","if cmd . check ( f""docker logs for { self . path . k8s }",66.24661212254061,96.17,False
1133,"def disjoined ( data ) : <TAB> # create marginalized distributions and multiple them together <TAB> data_disjoined = None <TAB> dim = len ( data . shape ) <TAB> for d in range ( dim ) : <TAB><TAB> axes = list ( range ( dim ) ) <TAB><TAB> axes . remove ( d ) <TAB><TAB> data1d = multisum ( data , axes ) <TAB><TAB> shape = [ 1 for k in range ( dim ) ] <TAB><TAB> shape [ d ] = len ( data1d ) <TAB><TAB> data1d = data1d . reshape ( tuple ( shape ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data_disjoined = data1d <TAB><TAB> else : <TAB><TAB><TAB> data_disjoined = data_disjoined * data1d <TAB> return data_disjoined",if d == 0 :,if data_disjoined is None :,73.13259609937089,96.69,False
1134,"def safe_repr ( val ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> # We special case dicts to have a sorted repr. This makes testing <TAB><TAB><TAB> # significantly easier <TAB><TAB><TAB> val = _obj_with_safe_repr ( val ) <TAB><TAB> ret = repr ( val ) <TAB><TAB> if six . PY2 : <TAB><TAB><TAB> ret = ret . decode ( "" utf-8 "" ) <TAB> except UnicodeEncodeError : <TAB><TAB> ret = red ( "" a  %r  that cannot be represented "" % type ( val ) ) <TAB> else : <TAB><TAB> ret = green ( ret ) <TAB> return ret","if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",100.0,100.00,True
1135,"def wrapper ( * args , * * kwargs ) : <TAB> resp = view_func ( * args , * * kwargs ) <TAB> if isinstance ( resp , dict ) : <TAB><TAB> ctx_params = request . environ . get ( "" webrec.template_params "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> resp . update ( ctx_params ) <TAB><TAB> template = self . jinja_env . jinja_env . get_or_select_template ( template_name ) <TAB><TAB> return template . render ( * * resp ) <TAB> else : <TAB><TAB> return resp",if ctx_params :,if ctx_params :,100.0,100.00,True
1136,"def post ( self , request , * args , * * kwargs ) : <TAB> contact_id = kwargs . get ( "" pk "" ) <TAB> self . object = get_object_or_404 ( Contact , id = contact_id ) <TAB> if ( <TAB><TAB> self . request . user . role != "" ADMIN "" <TAB><TAB> and not self . request . user . is_superuser <TAB><TAB> and self . request . user != self . object . created_by <TAB> ) or self . object . company != self . request . company : <TAB><TAB> raise PermissionDenied <TAB> else : <TAB><TAB> if self . object . address_id : <TAB><TAB><TAB> self . object . address . delete ( ) <TAB><TAB> self . object . delete ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return JsonResponse ( { "" error "" : False } ) <TAB><TAB> return redirect ( "" contacts:list "" )",if self . request . is_ajax ( ) :,if not self . object . delete_success :,95.09500039657485,96.16,False
1137,"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB><TAB> if "" & "" in text : <TAB><TAB><TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB> if "" > "" in text : <TAB><TAB><TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB> if ' "" ' in text : <TAB><TAB><TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB> if "" ' "" in text : <TAB><TAB><TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB> if newline : <TAB><TAB><TAB> if "" \n "" in text : <TAB><TAB><TAB><TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if ""<"" in text :","if ""<"" in text :",100.0,100.00,True
1138,"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> for i in v : <TAB><TAB><TAB><TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB><TAB> elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , _bytes ) : <TAB><TAB><TAB> return False <TAB> return True",if not everythingIsUnicode ( v ) :,if not everythingIsUnicode ( v ) :,75.0,100.00,True
1139,"def fill ( self ) : <TAB> try : <TAB><TAB> while ( <TAB><TAB><TAB> not self . stopping . wait ( self . sample_wait ) <TAB><TAB><TAB> and len ( self . queue ) < self . queue . maxlen <TAB><TAB> ) : <TAB><TAB><TAB> self . queue . append ( self . parent . _read ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . parent . _fire_events ( ) <TAB><TAB> self . full . set ( ) <TAB><TAB> while not self . stopping . wait ( self . sample_wait ) : <TAB><TAB><TAB> self . queue . append ( self . parent . _read ( ) ) <TAB><TAB><TAB> if isinstance ( self . parent , EventsMixin ) : <TAB><TAB><TAB><TAB> self . parent . _fire_events ( ) <TAB> except ReferenceError : <TAB><TAB> # Parent is dead; time to die! <TAB><TAB> pass","if self . partial and isinstance ( self . parent , EventsMixin ) :","if isinstance ( self . parent , EventsMixin ) :",96.75964931385015,97.92,False
1140,"def _SetListviewTextItems ( self , items ) : <TAB> self . listview . DeleteAllItems ( ) <TAB> index = - 1 <TAB> for item in items : <TAB><TAB> index = self . listview . InsertItem ( index + 1 , item [ 0 ] ) <TAB><TAB> data = item [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> data = "" "" <TAB><TAB> self . listview . SetItemText ( index , 1 , data )",if data is None :,"if data == """" :",92.16876394020626,95.05,False
1141,"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB><TAB> request . uri = request . uri . replace ( old , new ) <TAB><TAB> if is_text_payload ( request ) and request . body : <TAB><TAB><TAB> body = six . ensure_str ( request . body ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> request . body = body . replace ( old , new ) <TAB> return request",if old in body :,if body :,80.20357721803201,97.23,False
1142,"def serialize ( cls , value , * args , * * kwargs ) : <TAB> if value is None : <TAB><TAB> return "" "" <TAB> value_as_string = six . text_type ( value ) <TAB> if SHOULD_NOT_USE_LOCALE : <TAB><TAB> return value_as_string <TAB> else : <TAB><TAB> grouping = kwargs . get ( "" grouping "" , None ) <TAB><TAB> has_decimal_places = value_as_string . find ( "" . "" ) != - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> string_format = "" %d "" <TAB><TAB> else : <TAB><TAB><TAB> decimal_places = len ( value_as_string . split ( "" . "" ) [ 1 ] ) <TAB><TAB><TAB> string_format = "" % . {} f "" . format ( decimal_places ) <TAB><TAB> return locale . format ( string_format , value , grouping = grouping )",if not has_decimal_places :,if has_decimal_places :,95.01593992133182,98.96,False
1143,"def review_link ( request , path_obj ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> if check_permission ( "" translate "" , request ) : <TAB><TAB><TAB><TAB> text = _ ( "" Review Suggestions "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> text = _ ( "" View Suggestions "" ) <TAB><TAB><TAB> return { <TAB><TAB><TAB><TAB> "" href "" : dispatch . translate ( <TAB><TAB><TAB><TAB><TAB> request , path_obj . pootle_path , matchnames = [ "" hassuggestion "" ] <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> "" text "" : text , <TAB><TAB><TAB> } <TAB> except IOError : <TAB><TAB> pass",if path_obj . has_suggestions ( ) :,if path_obj . review_path :,95.91789024509987,97.21,False
1144,"def _migrate_key ( self , key ) : <TAB> """"""migrate key from old .dat file"""""" <TAB> key_path = os . path . join ( self . home_path , "" keys.dat "" ) <TAB> if os . path . exists ( key_path ) : <TAB><TAB> try : <TAB><TAB><TAB> key_data = json . loads ( open ( key_path , "" rb "" ) . read ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . add_key ( key , key_data . get ( key ) ) <TAB><TAB> except : <TAB><TAB><TAB> self . error ( f "" Corrupt key file. Manual migration of  ' { key } '  required. "" )",if key_data . get ( key ) :,if key in key_data :,68.47327993892424,96.35,False
1145,"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB><TAB> backref = callback . backref <TAB><TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB><TAB> if root_objs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> root_objs = [ root_objs ] <TAB><TAB><TAB> with session . no_autoflush : <TAB><TAB><TAB><TAB> for root_obj in root_objs : <TAB><TAB><TAB><TAB><TAB> if root_obj : <TAB><TAB><TAB><TAB><TAB><TAB> args = self . get_callback_args ( root_obj , callback ) <TAB><TAB><TAB><TAB><TAB><TAB> if args : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> yield args","if not isinstance ( root_objs , Iterable ) :","if not isinstance ( root_objs , list ) :",98.74293278826612,99.01,False
1146,"def GetDefFile ( self , gyp_to_build_path ) : <TAB> """"""Returns the .def file from sources, if any.  Otherwise returns None."""""" <TAB> spec = self . spec <TAB> if spec [ "" type "" ] in ( "" shared_library "" , "" loadable_module "" , "" executable "" ) : <TAB><TAB> def_files = [ s for s in spec . get ( "" sources "" , [ ] ) if s . endswith ( "" .def "" ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return gyp_to_build_path ( def_files [ 0 ] ) <TAB><TAB> elif len ( def_files ) > 1 : <TAB><TAB><TAB> raise Exception ( "" Multiple .def files "" ) <TAB> return None",if len ( def_files ) == 1 :,if len ( def_files ) == 1 :,100.0,100.00,True
1147,"def _validate_gallery ( images ) : <TAB> for image in images : <TAB><TAB> image_path = image . get ( "" image_path "" , "" "" ) <TAB><TAB> if image_path : <TAB><TAB><TAB> if not isfile ( image_path ) : <TAB><TAB><TAB><TAB> raise TypeError ( f "" { image_path !r}  is not a valid image path. "" ) <TAB><TAB> else : <TAB><TAB><TAB> raise TypeError ( "" ' image_path '  is required. "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( "" Caption must be 180 characters or less. "" )","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",if len ( image_path ) < 180 :,63.39800885990289,90.87,False
1148,"def VType ( self ) : <TAB> if "" DW_AT_type "" in self . attributes : <TAB><TAB> target = self . types [ self . type_id ] <TAB><TAB> target_type = target . VType ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> target_type = [ target_type , None ] <TAB><TAB> return [ "" Pointer "" , dict ( target = target_type [ 0 ] , target_args = target_type [ 1 ] ) ] <TAB> return [ "" Pointer "" , dict ( target = "" Void "" ) ]","if not isinstance ( target_type , list ) :","if not isinstance ( target_type , list ) :",100.0,100.00,True
1149,"def addInPlace ( self , value1 , value2 ) : <TAB> for group in value2 : <TAB><TAB> for key in value2 [ group ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value1 [ group ] [ key ] = value2 [ group ] [ key ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> value1 [ group ] [ key ] + = value2 [ group ] [ key ] <TAB> return value1",if key not in value1 [ group ] :,if key not in value1 [ group ] :,100.0,100.00,True
1150,"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB><TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB><TAB> for k , v in q . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> query [ k ] = { } <TAB><TAB><TAB> if isinstance ( v , list ) : <TAB><TAB><TAB><TAB> # TODO check exists of k in query, may be it should be update <TAB><TAB><TAB><TAB> query [ k ] = v <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> query [ k ] . update ( v ) <TAB> return query",if k not in query :,if k not in query :,100.0,100.00,True
1151,"def _handled_eventtype ( self , eventtype , handler ) : <TAB> if eventtype not in known_events : <TAB><TAB> log . error ( ' The event  "" %s ""  is not known ' , eventtype ) <TAB><TAB> return False <TAB> if known_events [ eventtype ] . __module__ . startswith ( "" deluge.event "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> log . error ( <TAB><TAB><TAB> "" You cannot register custom notification providers  "" <TAB><TAB><TAB> "" for built-in event types. "" <TAB><TAB> ) <TAB><TAB> return False <TAB> return True",if handler . __self__ is self :,if handler ( known_events [ eventtype ] . event ) :,68.91209645126308,93.65,False
1152,"def get_ax_arg ( uri ) : <TAB> if not ax_ns : <TAB><TAB> return u "" "" <TAB> prefix = "" openid. "" + ax_ns + "" .type. "" <TAB> ax_name = None <TAB> for name , values in self . request . arguments . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> part = name [ len ( prefix ) : ] <TAB><TAB><TAB> ax_name = "" openid. "" + ax_ns + "" .value. "" + part <TAB><TAB><TAB> break <TAB> if not ax_name : <TAB><TAB> return u "" "" <TAB> return self . get_argument ( ax_name , u "" "" )",if values [ - 1 ] == uri and name . startswith ( prefix ) :,if name . startswith ( prefix ) :,74.36594891704893,94.41,False
1153,"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB><TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB><TAB> for attr , value in attrs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . strip : <TAB><TAB><TAB><TAB><TAB> value = strip_html5_whitespace ( value ) <TAB><TAB><TAB><TAB> url = self . process_attr ( value ) <TAB><TAB><TAB><TAB> link = Link ( url = url ) <TAB><TAB><TAB><TAB> self . links . append ( link ) <TAB><TAB><TAB><TAB> self . current_link = link",if self . scan_attr ( attr ) :,"if attr == ""href"" :",95.51359061766809,95.64,False
1154,"def test_long_steadystate_queue_popright ( self ) : <TAB> for size in ( 0 , 1 , 2 , 100 , 1000 ) : <TAB><TAB> d = deque ( reversed ( range ( size ) ) ) <TAB><TAB> append , pop = d . appendleft , d . pop <TAB><TAB> for i in range ( size , BIG ) : <TAB><TAB><TAB> append ( i ) <TAB><TAB><TAB> x = pop ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( x , i - size ) <TAB><TAB> self . assertEqual ( list ( reversed ( list ( d ) ) ) , list ( range ( BIG - size , BIG ) ) )",if x != i - size :,if i > size :,69.34698387592199,96.53,False
1155,"def _update_read ( self ) : <TAB> """"""Update state when there is read event"""""" <TAB> try : <TAB><TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . on_message ( msg ) <TAB><TAB><TAB> return True <TAB><TAB> # normal close, remote is closed <TAB><TAB> self . close ( ) <TAB> except socket . error as err : <TAB><TAB> if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) : <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> self . on_error ( err ) <TAB> return False",if msg :,if msg :,100.0,100.00,True
1156,"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB><TAB> if not tag . text : <TAB><TAB><TAB> tag . text = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> root [ - 1 ] . tail = tag . text <TAB><TAB><TAB> tag . text = root_text <TAB><TAB> else : <TAB><TAB><TAB> tag . text = root_text + tag . text <TAB><TAB> if i > 0 : <TAB><TAB><TAB> root = deepcopy ( list ( root ) ) <TAB><TAB> tag [ : 0 ] = root <TAB><TAB> root = tag [ : len ( root ) ] <TAB> return self",if len ( root ) > 0 :,if root :,72.23387974010427,96.67,False
1157,"def cmp ( self , other ) : <TAB> v_is_ptr = not isinstance ( self , CTypesGenericPrimitive ) <TAB> w_is_ptr = isinstance ( other , CTypesData ) and not isinstance ( <TAB><TAB> other , CTypesGenericPrimitive <TAB> ) <TAB> if v_is_ptr and w_is_ptr : <TAB><TAB> return cmpfunc ( self . _convert_to_address ( None ) , other . _convert_to_address ( None ) ) <TAB> elif v_is_ptr or w_is_ptr : <TAB><TAB> return NotImplemented <TAB> else : <TAB><TAB> if isinstance ( self , CTypesGenericPrimitive ) : <TAB><TAB><TAB> self = self . _value <TAB><TAB> <MASK> <TAB><TAB><TAB> other = other . _value <TAB><TAB> return cmpfunc ( self , other )","if isinstance ( other , CTypesGenericPrimitive ) :","elif isinstance ( other , CTypesGenericPrimitive ) :",95.02517643969011,98.77,False
1158,"def get_external_addresses ( self , label = None ) - > List [ str ] : <TAB> result = [ ] <TAB> for c in self . _conf [ "" pools "" ] . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if label == c [ "" label "" ] : <TAB><TAB><TAB><TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB> return result",if label is not None :,"if c [ ""type"" ] == ""external"" :",93.888777037679,91.68,False
1159,"def coerce_text ( v ) : <TAB> if not isinstance ( v , basestring_ ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> attr = "" __unicode__ "" <TAB><TAB> else : <TAB><TAB><TAB> attr = "" __str__ "" <TAB><TAB> if hasattr ( v , attr ) : <TAB><TAB><TAB> return unicode ( v ) <TAB><TAB> else : <TAB><TAB><TAB> return bytes ( v ) <TAB> return v",if sys . version_info [ 0 ] < 3 :,"if v . startswith ( ""__unicode__"" ) :",84.35948613697136,90.59,False
1160,"def check_localhost ( self ) : <TAB> """"""Warn if any socket_host is 'localhost'. See #711."""""" <TAB> for k , v in cherrypy . config . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" The use of  ' localhost '  as a socket host can  "" <TAB><TAB><TAB><TAB> "" cause problems on newer systems, since  "" <TAB><TAB><TAB><TAB> "" ' localhost '  can map to either an IPv4 or an  "" <TAB><TAB><TAB><TAB> "" IPv6 address. You should use  ' 127.0.0.1 '   "" <TAB><TAB><TAB><TAB> "" or  ' [::1] '  instead. "" <TAB><TAB><TAB> )","if k == ""server.socket_host"" and v == ""localhost"" :","if k == ""socket_host"" :",94.77568268185934,94.59,False
1161,"def add_songs ( self , filenames , library ) : <TAB> changed = [ ] <TAB> for i in range ( len ( self ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> song = library [ self . _list [ i ] ] <TAB><TAB><TAB> self . _list [ i ] = song <TAB><TAB><TAB> changed . append ( song ) <TAB> if changed : <TAB><TAB> self . _emit_changed ( changed , msg = "" add "" ) <TAB> return bool ( changed )","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",if self . _list [ i ] in filenames :,85.97860019731417,92.03,False
1162,"def _expand_deps_java_generation ( self ) : <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB><TAB> k = queue . popleft ( ) <TAB><TAB> if k not in keys : <TAB><TAB><TAB> keys . add ( k ) <TAB><TAB><TAB> dep = self . target_database [ k ] <TAB><TAB><TAB> <MASK> # Has this attribute <TAB><TAB><TAB><TAB> dep . attr [ "" generate_java "" ] = True <TAB><TAB><TAB><TAB> queue . extend ( dep . deps )","if ""generate_java"" in dep . attr :",if dep . attr :,96.47272892590615,95.99,False
1163,"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB><TAB> opts = dict ( ) <TAB><TAB> opts [ "" type "" ] = "" episode "" <TAB><TAB> result = guessit ( name , options = opts ) <TAB><TAB> res = dict ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB><TAB> else : <TAB><TAB><TAB> res [ "" episode "" ] = 0 <TAB><TAB> if "" season "" in result : <TAB><TAB><TAB> res [ "" season "" ] = result [ "" season "" ] <TAB><TAB> else : <TAB><TAB><TAB> res [ "" season "" ] = 0 <TAB><TAB> if "" subtitle_language "" in result : <TAB><TAB><TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB><TAB> return jsonify ( data = res ) <TAB> else : <TAB><TAB> return "" "" , 400","if ""episode"" in result :","if ""episode"" in result :",100.0,100.00,True
1164,def _get_error_file ( self ) - > Optional [ str ] : <TAB> error_file = None <TAB> min_timestamp = sys . maxsize <TAB> for replicas in self . role_replicas . values ( ) : <TAB><TAB> for replica in replicas : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> mtime = os . path . getmtime ( replica . error_file ) <TAB><TAB><TAB> if mtime < min_timestamp : <TAB><TAB><TAB><TAB> min_timestamp = mtime <TAB><TAB><TAB><TAB> error_file = replica . error_file <TAB> return error_file,if not os . path . exists ( replica . error_file ) :,if not replica . error_file :,92.05487441907627,94.43,False
1165,"def findChapterNameForPosition ( self , p ) : <TAB> """"""Return the name of a chapter containing p or None if p does not exist."""""" <TAB> cc , c = self , self . c <TAB> if not p or not c . positionExists ( p ) : <TAB><TAB> return None <TAB> for name in cc . chaptersDict : <TAB><TAB> <MASK> <TAB><TAB><TAB> theChapter = cc . chaptersDict . get ( name ) <TAB><TAB><TAB> if theChapter . positionIsInChapter ( p ) : <TAB><TAB><TAB><TAB> return name <TAB> return "" main ""","if name != ""main"" :","if name . startswith ( ""main"" ) :",95.45780355373472,95.29,False
1166,"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB><TAB> f_path = os . path . join ( folder , f ) <TAB><TAB> if os . path . isfile ( f_path ) : <TAB><TAB><TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . remove ( f_path )",if extension in file_extensions :,if extension in file_extensions :,100.0,100.00,True
1167,"def execute_uncomment ( self , event ) : <TAB> cursor = self . _editor . GetCurrentPos ( ) <TAB> line , pos = self . _editor . GetCurLine ( ) <TAB> spaces = ""   "" * self . _tab_size <TAB> comment = "" Comment "" + spaces <TAB> cpos = cursor - len ( comment ) <TAB> lenline = len ( line ) <TAB> if lenline > 0 : <TAB><TAB> idx = 0 <TAB><TAB> while idx < lenline and line [ idx ] == ""   "" : <TAB><TAB><TAB> idx + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _editor . DeleteRange ( cursor - pos + idx , len ( comment ) ) <TAB><TAB><TAB> self . _editor . SetCurrentPos ( cpos ) <TAB><TAB><TAB> self . _editor . SetSelection ( cpos , cpos ) <TAB><TAB><TAB> self . store_position ( )",if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,if idx < lenline :,62.36606787457395,89.31,False
1168,"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell ( <TAB> critical_suite_with_citations , empty_data_context ) : <TAB> obs = SuiteEditNotebookRenderer . from_data_context ( empty_data_context ) . render ( <TAB><TAB> critical_suite_with_citations , { "" path "" : "" ./foo/data "" } <TAB> ) <TAB> assert isinstance ( obs , dict ) <TAB> found_expected = False <TAB> for cell in obs [ "" cells "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> source_code = cell [ "" source "" ] <TAB><TAB><TAB> if ' batch_kwargs =  { "" path "" :  "" ../.././foo/data "" } ' in source_code : <TAB><TAB><TAB><TAB> found_expected = True <TAB><TAB><TAB><TAB> break <TAB> assert found_expected","if cell [ ""cell_type"" ] == ""code"" :","if cell [ ""type"" ] == ""code"" :",98.77685365590368,98.59,False
1169,"def _get_file ( self ) : <TAB> if self . _file is None : <TAB><TAB> self . _file = SpooledTemporaryFile ( <TAB><TAB><TAB> max_size = self . _storage . max_memory_size , <TAB><TAB><TAB> suffix = "" .S3Boto3StorageFile "" , <TAB><TAB><TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB><TAB> ) <TAB><TAB> if "" r "" in self . _mode : <TAB><TAB><TAB> self . _is_dirty = False <TAB><TAB><TAB> self . obj . download_fileobj ( self . _file ) <TAB><TAB><TAB> self . _file . seek ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file","if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :",if self . _is_dirty :,72.86082941967278,92.83,False
1170,"def _parse_filters ( f_strs ) : <TAB> filters = [ ] <TAB> if not f_strs : <TAB><TAB> return filters <TAB> for f_str in f_strs : <TAB><TAB> <MASK> <TAB><TAB><TAB> fname , fopts = f_str . split ( "" : "" , 1 ) <TAB><TAB><TAB> filters . append ( ( fname , _parse_options ( [ fopts ] ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> filters . append ( ( f_str , { } ) ) <TAB> return filters","if "":"" in f_str :","if "":"" in f_str :",100.0,100.00,True
1171,"def update_completion ( self ) : <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> if orig_text [ - 1 ] not in ( "" , "" , ""   "" ) : <TAB><TAB><TAB><TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB><TAB><TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB><TAB> else : <TAB><TAB><TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB><TAB> self . completer_model . setStringList ( tags )","if "","" in orig_text :",if tag in orig_text :,71.4019120381447,98.19,False
1172,"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB><TAB> name = path . name <TAB><TAB> if name == "" __pycache__ "" : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB><TAB> elif path . is_dir ( ) and "" . "" not in name : <TAB><TAB><TAB> names . add ( name ) <TAB> if packages : <TAB><TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB><TAB> if len ( names & packages ) == len ( packages ) : <TAB><TAB><TAB> return packages <TAB> return names","if name . endswith ( "".py"" ) :","elif path . is_file ( ) and ""."" in name :",70.87305391999486,94.29,False
1173,"def get_cloud_credential ( self ) : <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if cred . kind == self . source . replace ( "" ec2 "" , "" aws "" ) : <TAB><TAB><TAB><TAB> credential = cred <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> # these need to be returned in the API credential field <TAB><TAB><TAB> if cred . credential_type . kind != "" vault "" : <TAB><TAB><TAB><TAB> credential = cred <TAB><TAB><TAB><TAB> break <TAB> return credential",if self . source in CLOUD_PROVIDERS :,if self . source :,95.84747221162182,97.34,False
1174,"def newickize ( clade ) : <TAB> """"""Convert a node tree to a Newick tree string, recursively."""""" <TAB> label = clade . name or "" "" <TAB> if label : <TAB><TAB> unquoted_label = re . match ( token_dict [ "" unquoted node label "" ] , label ) <TAB><TAB> <MASK> <TAB><TAB><TAB> label = "" ' %s ' "" % label . replace ( "" \\ "" , "" \\ \\ "" ) . replace ( "" ' "" , "" \\ ' "" ) <TAB> if clade . is_terminal ( ) : # terminal <TAB><TAB> return label + make_info_string ( clade , terminal = True ) <TAB> else : <TAB><TAB> subtrees = ( newickize ( sub ) for sub in clade ) <TAB><TAB> return "" ( %s ) %s "" % ( "" , "" . join ( subtrees ) , label + make_info_string ( clade ) )",if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,if unquoted_label :,87.65580334610566,91.02,False
1175,"def __iter__ ( self ) : <TAB> for name , value in self . _vars . store . data . items ( ) : <TAB><TAB> source = self . _sources [ name ] <TAB><TAB> prefix = self . _get_prefix ( value ) <TAB><TAB> name = u "" {0} {{ {1} }} "" . format ( prefix , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ArgumentInfo ( name , value ) <TAB><TAB> else : <TAB><TAB><TAB> yield VariableInfo ( name , value , source )",if source == self . ARGUMENT_SOURCE :,if source is None :,67.56679129153198,94.21,False
1176,"def filepath_enumerate ( paths ) : <TAB> """"""Enumerate the file paths of all subfiles of the list of paths"""""" <TAB> out = [ ] <TAB> for path in paths : <TAB><TAB> <MASK> <TAB><TAB><TAB> out . append ( path ) <TAB><TAB> else : <TAB><TAB><TAB> for root , dirs , files in os . walk ( path ) : <TAB><TAB><TAB><TAB> for name in files : <TAB><TAB><TAB><TAB><TAB> out . append ( os . path . normpath ( os . path . join ( root , name ) ) ) <TAB> return out",if os . path . isfile ( path ) :,if os . path . isdir ( path ) :,98.71231510248136,98.46,False
1177,"def del_ ( self , key ) : <TAB> hash_ = self . hash ( key ) <TAB> node_ = self . _table [ hash_ ] <TAB> pre_node = None <TAB> while node_ is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> if pre_node is None : <TAB><TAB><TAB><TAB> self . _table [ hash_ ] = node_ . next <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> pre_node . next = node_ . next <TAB><TAB><TAB> self . _len - = 1 <TAB><TAB> pre_node = node_ <TAB><TAB> node_ = node_ . next",if node_ . key == key :,if self . _len == 0 :,68.36861671948174,95.99,False
1178,"def _recurse ( self , base_path , rel_source , rel_zip ) : <TAB> submodules_path = Path ( base_path ) / "" submodules "" <TAB> if not submodules_path . is_dir ( ) : <TAB><TAB> return <TAB> for submodule in submodules_path . iterdir ( ) : <TAB><TAB> source_path = submodule / rel_source <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> output_path = submodule / rel_zip <TAB><TAB> self . _build_lambdas ( source_path , output_path ) <TAB><TAB> self . _recurse ( submodule , rel_source , rel_zip )",if not source_path . is_dir ( ) :,if not source_path . is_file ( ) :,86.70305049153721,98.53,False
1179,"def find_test_functions ( collections ) : <TAB> if not isinstance ( collections , list ) : <TAB><TAB> collections = [ collections ] <TAB> functions = [ ] <TAB> for collection in collections : <TAB><TAB> if not isinstance ( collection , dict ) : <TAB><TAB><TAB> collection = vars ( collection ) <TAB><TAB> keys = collection . keys ( ) <TAB><TAB> keys . sort ( ) <TAB><TAB> for key in keys : <TAB><TAB><TAB> value = collection [ key ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> functions . append ( value ) <TAB> return functions","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :","if isinstance ( value , ( list , tuple ) ) :",63.65739449351364,92.76,False
1180,"def __init__ ( <TAB> self , <TAB> classifier , <TAB> layer_name = None , <TAB> transpose = None , <TAB> distance = None , <TAB> copy_weights = True , ) : <TAB> super ( ) . __init__ ( ) <TAB> self . copy_weights = copy_weights <TAB> ### set layer weights ### <TAB> if layer_name is not None : <TAB><TAB> self . set_weights ( getattr ( classifier , layer_name ) ) <TAB> else : <TAB><TAB> for x in self . possible_layer_names : <TAB><TAB><TAB> layer = getattr ( classifier , x , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . set_weights ( layer ) <TAB><TAB><TAB><TAB> break <TAB> ### set distance measure ### <TAB> self . distance = classifier . distance if distance is None else distance <TAB> self . transpose = transpose",if layer is not None :,if layer is not None :,100.0,100.00,True
1181,def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB><TAB> if len ( self . _tail_data ) < self . _base_number : <TAB><TAB><TAB> self . _tail_data + = data <TAB><TAB> <MASK> <TAB><TAB><TAB> yield self . _tail_data <TAB><TAB><TAB> self . _tail_data = [ ],if len ( self . _tail_data ) == self . _base_number :,if len ( self . _tail_data ) == self . _base_number :,100.0,100.00,True
1182,"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB><TAB> for setting , edge in self . Conflicts : <TAB><TAB><TAB> answer = self . AskUser ( self . Setting , setting ) <TAB><TAB><TAB> if answer == Gtk . ResponseType . YES : <TAB><TAB><TAB><TAB> value = setting . Value . split ( "" | "" ) <TAB><TAB><TAB><TAB> value . remove ( edge ) <TAB><TAB><TAB><TAB> setting . Value = "" | "" . join ( value ) <TAB><TAB><TAB><TAB> if updater : <TAB><TAB><TAB><TAB><TAB> updater . UpdateSetting ( setting ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB> return True",if answer == Gtk . ResponseType . NO :,elif answer == Gtk . ResponseType . NO :,75.11095561079915,98.83,False
1183,"def _post_process_ttl ( zone ) : <TAB> for name in zone : <TAB><TAB> for record_type in zone [ name ] : <TAB><TAB><TAB> records = zone [ name ] [ record_type ] <TAB><TAB><TAB> if isinstance ( records , list ) : <TAB><TAB><TAB><TAB> ttl = min ( [ x [ "" ttl "" ] for x in records ] ) <TAB><TAB><TAB><TAB> for record in records : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" Using lowest TTL  {}  for the record set. Ignoring value  {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB><TAB> ttl , record [ "" ttl "" ] <TAB><TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB><TAB> record [ "" ttl "" ] = ttl","if record [ ""ttl"" ] != ttl :","if record [ ""ttl"" ] < ttl :",98.92577898228728,98.83,False
1184,"def __init__ ( self , cmds , env , cleanup = [ ] ) : <TAB> self . handle = None <TAB> self . cmds = cmds <TAB> self . env = env <TAB> if cleanup : <TAB><TAB> <MASK> <TAB><TAB><TAB> cleanup = [ cleanup ] <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> cleanup = [ c for c in cleanup if callable ( c ) ] <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> cleanup = [ ] <TAB> self . cleanup = cleanup",if callable ( cleanup ) :,if not callable ( cleanup ) :,94.95126707935361,98.37,False
1185,"def _parse_data_of_birth ( cls , data_of_birth_string ) : <TAB> if data_of_birth_string : <TAB><TAB> format = "" % m/ %d / % Y "" <TAB><TAB> try : <TAB><TAB><TAB> parsed_date = datetime . datetime . strptime ( data_of_birth_string , format ) <TAB><TAB><TAB> return parsed_date <TAB><TAB> except ValueError : <TAB><TAB><TAB> # Facebook sometimes provides a partial date format <TAB><TAB><TAB> # ie 04/07 (ignore those) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise","if data_of_birth_string . count ( ""/"" ) != 1 :",if not parsed_date :,93.56480116044283,89.91,False
1186,"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB><TAB> var = d . upper ( ) <TAB><TAB> if var == "" QTCORE "" : <TAB><TAB><TAB> continue <TAB><TAB> value = env [ "" LIBPATH_ "" + var ] <TAB><TAB> if value : <TAB><TAB><TAB> core = env [ coreval ] <TAB><TAB><TAB> accu = [ ] <TAB><TAB><TAB> for lib in value : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> accu . append ( lib ) <TAB><TAB><TAB> env [ "" LIBPATH_ "" + var ] = accu",if lib in core :,if not core . startswith ( lib ) :,73.03917071839801,95.96,False
1187,"def throttle_status ( server = None ) : <TAB> result = AmonStruct ( ) <TAB> result . allow = False <TAB> last_check = server . get ( "" last_check "" ) <TAB> server_check_period = server . get ( "" check_every "" , 60 ) <TAB> if last_check : <TAB><TAB> period_since_last_check = unix_utc_now ( ) - last_check <TAB><TAB> # Add 15 seconds buffer, for statsd <TAB><TAB> period_since_last_check = period_since_last_check + 15 <TAB><TAB> <MASK> <TAB><TAB><TAB> result . allow = True <TAB> else : <TAB><TAB> result . allow = True # Never checked <TAB> return result",if period_since_last_check >= server_check_period :,if period_since_last_check < server_check_period :,98.69884266175568,98.18,False
1188,"def fetch_scatter_outputs ( self , task ) : <TAB> scatteroutputs = [ ] <TAB> for var in task [ "" body "" ] : <TAB><TAB> # TODO variable support <TAB><TAB> if var . startswith ( "" call "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for output in self . tasks_dictionary [ task [ "" body "" ] [ var ] [ "" task "" ] ] [ <TAB><TAB><TAB><TAB><TAB> "" outputs "" <TAB><TAB><TAB><TAB> ] : <TAB><TAB><TAB><TAB><TAB> scatteroutputs . append ( <TAB><TAB><TAB><TAB><TAB><TAB> { "" task "" : task [ "" body "" ] [ var ] [ "" alias "" ] , "" output "" : output [ 0 ] } <TAB><TAB><TAB><TAB><TAB> ) <TAB> return scatteroutputs","if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :","if task [ ""body"" ] [ var ] [ ""task"" ] in self . tasks",96.34817940089361,94.92,False
1189,"def _add_constant_node ( self , source_node ) : <TAB> parent_ids = range ( len ( source_node . in_edges ) ) <TAB> for idx in parent_ids : <TAB><TAB> parent_node = self . tf_graph . get_node ( source_node . in_edges [ idx ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _rename_Const ( parent_node )","if parent_node . type == ""Const"" :",if parent_node . is_constant :,65.0363446764565,93.32,False
1190,"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self . storySettingsData : <TAB><TAB> name = data [ "" name "" ] <TAB><TAB> if name in self . ctrls : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> set = self . getSetting ( data [ "" requires "" ] ) <TAB><TAB><TAB><TAB> for i in self . ctrls [ name ] : <TAB><TAB><TAB><TAB><TAB> i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] )","if ""requires"" in data :","if data [ ""requires"" ] :",72.69243066252439,96.61,False
1191,"def update_realtime ( self , stdout = "" "" , stderr = "" "" , delete = False ) : <TAB> wooey_cache = wooey_settings . WOOEY_REALTIME_CACHE <TAB> if delete == False and wooey_cache is None : <TAB><TAB> self . stdout = stdout <TAB><TAB> self . stderr = stderr <TAB><TAB> self . save ( ) <TAB> elif wooey_cache is not None : <TAB><TAB> cache = django_cache [ wooey_cache ] <TAB><TAB> <MASK> <TAB><TAB><TAB> cache . delete ( self . get_realtime_key ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> cache . set ( <TAB><TAB><TAB><TAB> self . get_realtime_key ( ) , <TAB><TAB><TAB><TAB> json . dumps ( { "" stdout "" : stdout , "" stderr "" : stderr } ) , <TAB><TAB><TAB> )",if delete :,if delete :,100.0,100.00,True
1192,"def _check_for_batch_clashes ( xs ) : <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB><TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB><TAB> if batches : <TAB><TAB><TAB> if not isinstance ( batches , ( list , tuple ) ) : <TAB><TAB><TAB><TAB> batches = [ batches ] <TAB><TAB><TAB> for batch in batches : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB><TAB><TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB><TAB> )",if batch in names :,if len ( names ) == len ( batch ) :,96.65836411114779,96.02,False
1193,"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB><TAB> if self . save == self . split : <TAB><TAB><TAB> self . save = 100 <TAB><TAB> if self . split > 20 : <TAB><TAB><TAB> self . save = self . split <TAB><TAB><TAB> self . split = 1 <TAB><TAB> else : <TAB><TAB><TAB> self . split = self . save <TAB> else : <TAB><TAB> if self . save == self . split : <TAB><TAB><TAB> self . save = 0.3 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . split = self . save <TAB><TAB> elif self . split < 0.5 : <TAB><TAB><TAB> self . split = self . min <TAB><TAB> else : <TAB><TAB><TAB> self . split = self . max <TAB> self . placeChilds ( )",if self . split <= self . min or self . split >= self . max :,elif self . save > 0.5 :,69.43251002765027,92.52,False
1194,"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB><TAB> iterator = iter ( self . file ) <TAB><TAB> head = next ( iterator , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . repaired = [ ] <TAB><TAB><TAB> return True <TAB><TAB> if isinstance ( head , str ) : <TAB><TAB><TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> # We may have mangled a generator at this point, so just abort <TAB><TAB><TAB> raise IOSourceError ( <TAB><TAB><TAB><TAB> "" Could not open source:  %r  (mode:  %r ) "" <TAB><TAB><TAB><TAB> % ( self . file , self . options [ "" mode "" ] ) <TAB><TAB><TAB> ) <TAB> return False",if head is None :,if head is None :,100.0,100.00,True
1195,"def _print_message_content ( self , peer , data ) : <TAB> inheaders = 1 <TAB> lines = data . splitlines ( ) <TAB> for line in lines : <TAB><TAB> # headers first <TAB><TAB> if inheaders and not line : <TAB><TAB><TAB> peerheader = "" X-Peer:  "" + peer [ 0 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # decoded_data=false; make header match other binary output <TAB><TAB><TAB><TAB> peerheader = repr ( peerheader . encode ( "" utf-8 "" ) ) <TAB><TAB><TAB> print ( peerheader ) <TAB><TAB><TAB> inheaders = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> # Avoid spurious 'str on bytes instance' warning. <TAB><TAB><TAB> line = repr ( line ) <TAB><TAB> print ( line )","if not isinstance ( data , str ) :",if not inheaders :,93.89428690206088,93.39,False
1196,"def connect ( self ) : <TAB> # Makes connection with MySQL server <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> connection = pymysql . connect ( read_default_file = "" /etc/mysql/conf.d/my.cnf "" ) <TAB><TAB> else : <TAB><TAB><TAB> connection = pymysql . connect ( read_default_file = "" ~/.my.cnf "" ) <TAB><TAB> return connection <TAB> except ValueError as e : <TAB><TAB> Log . debug ( self , str ( e ) ) <TAB><TAB> raise MySQLConnectionError <TAB> except pymysql . err . InternalError as e : <TAB><TAB> Log . debug ( self , str ( e ) ) <TAB><TAB> raise MySQLConnectionError","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :","if os . path . exists ( ""/etc/mysql/conf.d/my.cn",72.87397122184144,97.24,False
1197,"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB><TAB> src = src_unresolved . resolve ( ) <TAB><TAB> app = src . name <TAB><TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB> if not dest . parent . is_dir ( ) : <TAB><TAB><TAB> mkdir ( dest . parent ) <TAB><TAB> if dest . exists ( ) : <TAB><TAB><TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB> dest . unlink ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shutil . copy ( src , dest )",if src . exists ( ) :,if not src . is_dir ( ) :,72.08539784853522,97.04,False
1198,"def update ( self , x , who = None , metadata = None ) : <TAB> self . _retain_refs ( metadata ) <TAB> y = self . _get_key ( x ) <TAB> if self . keep == "" last "" : <TAB><TAB> # remove key if already present so that emitted value <TAB><TAB> # will reflect elements' actual relative ordering <TAB><TAB> self . _buffer . pop ( y , None ) <TAB><TAB> self . _metadata_buffer . pop ( y , None ) <TAB><TAB> self . _buffer [ y ] = x <TAB><TAB> self . _metadata_buffer [ y ] = metadata <TAB> else : # self.keep == ""first"" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _buffer [ y ] = x <TAB><TAB><TAB> self . _metadata_buffer [ y ] = metadata <TAB> return self . last",if y not in self . _buffer :,"if self . keep == ""first"" :",97.33468202136126,96.11,False
1199,"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB><TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB><TAB><TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB><TAB><TAB> for ak in keys : <TAB><TAB><TAB><TAB> if c_date == ak [ "" CreateDate "" ] : <TAB><TAB><TAB><TAB><TAB> ak = dict ( ak ) <TAB><TAB><TAB><TAB><TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> res . append ( ak ) <TAB><TAB> elif k not in res : <TAB><TAB><TAB> res . append ( k ) <TAB> return res",if ak not in res :,"if ak [ ""c7n:match-type"" ] == ""access"" :",77.71146494647627,94.59,False
1200,"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef ( "" "" , { } , None ) <TAB> for name in dir ( src_flag ) : <TAB><TAB> if name [ : 1 ] == "" _ "" : <TAB><TAB><TAB> continue <TAB><TAB> dest_val = getattr ( dest_flag , name , None ) <TAB><TAB> baseline_val = getattr ( baseline_flag , name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( dest_flag , name , getattr ( src_flag , name ) )",if dest_val == baseline_val :,if dest_val is None or baseline_val is None :,72.41099644289342,95.42,False
1201,"def _ws_keep_reading ( self ) : <TAB> import websockets . exceptions <TAB> while not self . _reader_stopped : <TAB><TAB> try : <TAB><TAB><TAB> data = await self . _ws . recv ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = data . encode ( "" UTF-8 "" ) <TAB><TAB><TAB> if len ( data ) == 0 : <TAB><TAB><TAB><TAB> self . _error = "" EOF "" <TAB><TAB><TAB><TAB> break <TAB><TAB> except websockets . exceptions . ConnectionClosedError : <TAB><TAB><TAB> # TODO: try to reconnect in case of Ctrl+D <TAB><TAB><TAB> self . _error = "" EOF "" <TAB><TAB><TAB> break <TAB><TAB> self . num_bytes_received + = len ( data ) <TAB><TAB> self . _make_output_available ( data , block = False )","if isinstance ( data , str ) :","if isinstance ( data , str ) :",100.0,100.00,True
1202,"def to_dict ( self ) - > Dict [ str , Any ] : <TAB> result = { } <TAB> for field_name in self . API_FIELDS : <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" stream_id "" ] = self . id <TAB><TAB><TAB> continue <TAB><TAB> elif field_name == "" date_created "" : <TAB><TAB><TAB> result [ "" date_created "" ] = datetime_to_timestamp ( self . date_created ) <TAB><TAB><TAB> continue <TAB><TAB> result [ field_name ] = getattr ( self , field_name ) <TAB> result [ "" is_announcement_only "" ] = ( <TAB><TAB> self . stream_post_policy == Stream . STREAM_POST_POLICY_ADMINS <TAB> ) <TAB> return result","if field_name == ""id"" :","if field_name == ""stream_id"" :",98.78510547571634,98.34,False
1203,"def all_masks ( <TAB> cls , <TAB> images , <TAB> run , <TAB> run_key , <TAB> step , ) : <TAB> all_mask_groups = [ ] <TAB> for image in images : <TAB><TAB> <MASK> <TAB><TAB><TAB> mask_group = { } <TAB><TAB><TAB> for k in image . _masks : <TAB><TAB><TAB><TAB> mask = image . _masks [ k ] <TAB><TAB><TAB><TAB> mask_group [ k ] = mask . to_json ( run ) <TAB><TAB><TAB> all_mask_groups . append ( mask_group ) <TAB><TAB> else : <TAB><TAB><TAB> all_mask_groups . append ( None ) <TAB> if all_mask_groups and not all ( x is None for x in all_mask_groups ) : <TAB><TAB> return all_mask_groups <TAB> else : <TAB><TAB> return False",if image . _masks :,if image . _masks :,100.0,100.00,True
1204,"def disconnect_all ( listener ) : <TAB> """"""Disconnect from all signals"""""" <TAB> for emitter in listener . _signal_data . emitters : <TAB><TAB> for signal in emitter . _signal_data . listeners : <TAB><TAB><TAB> emitter . _signal_data . listeners [ signal ] = [ <TAB><TAB><TAB><TAB> i <TAB><TAB><TAB><TAB> for i in emitter . _signal_data . listeners [ signal ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> ]","if getattr ( i , ""__self__"" , None ) != listener",if i . _signal_data . listeners [ signal ],71.4976734578196,88.38,False
1205,"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB><TAB> if timeout is None : <TAB><TAB><TAB> msecs = _subprocess . INFINITE <TAB><TAB> else : <TAB><TAB><TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB><TAB><TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> code = - signal . SIGTERM <TAB><TAB><TAB> self . returncode = code <TAB> return self . returncode",if code == TERMINATE :,if code == _subprocess . WAIT_SIG_0 :,82.53063457616231,95.26,False
1206,"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB><TAB> self . is_pulsing = False <TAB><TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB><TAB> self . pbar . set_text ( progress ) <TAB><TAB> <MASK> <TAB><TAB><TAB> frac = 1.0 <TAB><TAB> if frac < 0 : <TAB><TAB><TAB> frac = 0 <TAB><TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB><TAB> gtk . gdk . threads_leave ( )",if frac > 1 :,if frac > 1.0 :,72.13861545906879,98.53,False
1207,"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB><TAB> if i == "" [ "" : <TAB><TAB><TAB> m = - 1 <TAB><TAB><TAB> aas . append ( "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> m = 0 <TAB><TAB><TAB> continue <TAB><TAB> elif m == - 1 : <TAB><TAB><TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB><TAB> elif m == 0 : <TAB><TAB><TAB> aas . append ( i ) <TAB> return aas","elif i == ""]"" :","elif i == ""]"" :",100.0,100.00,True
1208,"def link ( token , base_url ) : <TAB> """"""Validation for ``link``."""""" <TAB> if get_keyword ( token ) == "" none "" : <TAB><TAB> return "" none "" <TAB> parsed_url = get_url ( token , base_url ) <TAB> if parsed_url : <TAB><TAB> return parsed_url <TAB> function = parse_function ( token ) <TAB> if function : <TAB><TAB> name , args = function <TAB><TAB> prototype = ( name , [ a . type for a in args ] ) <TAB><TAB> args = [ getattr ( a , "" value "" , a ) for a in args ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( "" attr() "" , args [ 0 ] )","if prototype == ( ""attr"" , [ ""ident"" ] ) :","if prototype in ( ""attr"" , ""attr_async"" ) :",92.54454111941685,95.31,False
1209,"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB><TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB><TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB><TAB><TAB> return self . current_provider . on_search ( query ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . current_provider . on_url ( query ) <TAB><TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB><TAB><TAB> return self . current_provider . on_file ( query )",elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,100.0,100.00,True
1210,"def test_handle_single ( self ) : <TAB> self . skipTest ( <TAB><TAB> "" Pops up windows and needs user input.. so disabled. "" <TAB><TAB> "" Still worth keeping whilst we don ' t have unit tests  "" <TAB><TAB> "" for all plugins. "" <TAB> ) <TAB> # Ignored... <TAB> for id_ , plugin in self . plugins . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . h . plugin_enable ( plugin , None ) <TAB><TAB><TAB> self . h . handle ( id_ , self . lib , self . parent , SONGS ) <TAB><TAB><TAB> self . h . plugin_disable ( plugin )",if self . h . plugin_handle ( plugin ) :,if self . h . plugin_supports_user_input ( plugin ) :,98.87179986195824,96.49,False
1211,"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . _keydata : <TAB><TAB> <MASK> <TAB><TAB><TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB><TAB> elif hasattr ( self , k ) : <TAB><TAB><TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB><TAB> attrs . append ( "" private "" ) <TAB> # PY3K: This is meant to be text, do not change to bytes (data) <TAB> return "" < %s  @0x %x   %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) )","if k == ""p"" :","if k == ""p"" :",100.0,100.00,True
1212,"def apply ( self , node , code , required ) : <TAB> yield "" try: "" <TAB> yield from self . iterIndented ( code ) <TAB> yield ""     pass "" <TAB> yield "" except  {} : "" . format ( self . exceptionString ) <TAB> outputVariables = node . getOutputSocketVariables ( ) <TAB> for i , s in enumerate ( node . outputs ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if hasattr ( s , "" getDefaultValueCode "" ) : <TAB><TAB><TAB><TAB> yield f ""      { outputVariables [ s . identifier ] }  =  { s . getDefaultValueCode ( ) } "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield f ""      { outputVariables [ s . identifier ] }  = self.outputs[ { i } ].getDefaultValue() "" <TAB> yield ""     pass """,if s . identifier in required :,if s . identifier in self . outputs :,96.79879287094691,97.74,False
1213,"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB><TAB> if "" * "" in fromlist : <TAB><TAB><TAB> fromlist = list ( fromlist ) <TAB><TAB><TAB> fromlist . remove ( "" * "" ) <TAB><TAB><TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB><TAB> for x in fromlist : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB><TAB><TAB><TAB> if from_name in modules : <TAB><TAB><TAB><TAB><TAB> importlib . import_module ( from_name ) <TAB> return module","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",if x is not None :,94.55879938499713,93.79,False
1214,"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> r = await ws . recv ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> r = r . decode ( "" utf-8 "" ) <TAB><TAB><TAB> msg = json . loads ( r ) <TAB><TAB><TAB> stream = msg . get ( "" stream "" ) <TAB><TAB><TAB> if stream is not None : <TAB><TAB><TAB><TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB><TAB> logging . warn ( wse ) <TAB><TAB> await self . close ( ) <TAB><TAB> asyncio . ensure_future ( self . _ensure_ws ( ) )","if isinstance ( r , bytes ) :","if isinstance ( r , bytes ) :",100.0,100.00,True
1215,"def add_source ( self , source , name = None ) : <TAB> """"""Adds a new data source to an existing provider."""""" <TAB> if self . randomize : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Cannot add a non-shuffleable source to an  "" <TAB><TAB><TAB><TAB> "" already shuffled provider. "" <TAB><TAB><TAB> ) <TAB> super ( ) . add_source ( source , name = name ) <TAB> if self . randomize is True : <TAB><TAB> self . _shuffle_len = self . entries",if not source . can_shuffle ( ) :,if source in self . entries :,91.48678466262248,94.34,False
1216,"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB><TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB><TAB> if not self . fileName : <TAB><TAB><TAB> buf . append ( "" line  "" ) <TAB><TAB> buf . append ( str ( self . line ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB><TAB> buf . append ( "" : "" ) <TAB> buf . append ( ""   "" ) <TAB> return str ( "" "" ) . join ( buf )",if self . column != - 1 :,if self . column != - 1 :,100.0,100.00,True
1217,"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB><TAB> if _has_newline ( header ) : <TAB><TAB><TAB> return True <TAB> if self . subject : <TAB><TAB> if _has_newline ( self . subject ) : <TAB><TAB><TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB> if not line : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if linenum > 0 and line [ 0 ] not in "" \t   "" : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if len ( line . strip ( ) ) == 0 :,"if line [ 0 ] in ""\r\n"" :",93.96910794109311,95.73,False
1218,"def scanHexEscape ( self , prefix ) : <TAB> code = 0 <TAB> leng = 4 if ( prefix == "" u "" ) else 2 <TAB> for i in xrange ( leng ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ch = self . source [ self . index ] <TAB><TAB><TAB> self . index + = 1 <TAB><TAB><TAB> code = code * 16 + HEX_CONV [ ch ] <TAB><TAB> else : <TAB><TAB><TAB> return "" "" <TAB> return unichr ( code )",if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,if self . index < leng :,82.34862191157171,88.69,False
1219,"def _get_table_info ( self , table_name ) : <TAB> table_addr = self . addr_space . profile . get_symbol ( table_name ) <TAB> table_size = self . _get_table_info_distorm ( ) <TAB> <MASK> <TAB><TAB> table_size = self . _get_table_info_other ( table_addr , table_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> debug . error ( "" Unable to get system call table size "" ) <TAB> return [ table_addr , table_size ]",if table_size == 0 :,if not table_size :,60.22653755865134,91.67,False
1220,"def format_file_path ( filepath ) : <TAB> """"""Formats a path as absolute and with the correct platform separator."""""" <TAB> try : <TAB><TAB> is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN . match ( filepath ) <TAB><TAB> filepath = os . path . realpath ( os . path . abspath ( filepath ) ) <TAB><TAB> filepath = re . sub ( BACKSLASH_REPLACE_PATTERN , "" / "" , filepath ) <TAB><TAB> is_windows_drive = WINDOWS_DRIVE_PATTERN . match ( filepath ) <TAB><TAB> <MASK> <TAB><TAB><TAB> filepath = filepath . capitalize ( ) <TAB><TAB> if is_windows_network_mount : <TAB><TAB><TAB> # Add back a / to the front, since the previous modifications <TAB><TAB><TAB> # will have replaced any double slashes with single <TAB><TAB><TAB> filepath = "" / "" + filepath <TAB> except : <TAB><TAB> pass <TAB> return filepath",if is_windows_drive :,if is_windows_drive :,100.0,100.00,True
1221,"def _match ( self , cre , s ) : <TAB> # Run compiled regular expression match method on 's'. <TAB> # Save result, return success. <TAB> self . mo = cre . match ( s ) <TAB> if __debug__ : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _mesg ( "" \t matched r ' %r '  =>  %r "" % ( cre . pattern , self . mo . groups ( ) ) ) <TAB> return self . mo is not None",if self . mo is not None and self . debug >= 5 :,if self . mo :,68.72435694138275,90.90,False
1222,"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB><TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB><TAB><TAB> for line in f . readlines ( ) : <TAB><TAB><TAB><TAB> if not line . startswith ( "" # "" ) : <TAB><TAB><TAB><TAB><TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . warning ( <TAB><TAB><TAB><TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB><TAB><TAB><TAB> self . sanitize_allowlist_file , <TAB><TAB><TAB> )",if explicit :,if explicit :,100.0,100.00,True
1223,"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB><TAB> if not self . flags . forc : <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> order = "" F "" <TAB><TAB> else : <TAB><TAB><TAB> order = "" C "" <TAB><TAB> result = self . _new_like_me ( order = order ) <TAB><TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB><TAB> func . prepared_async_call ( <TAB><TAB><TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB><TAB> ) <TAB><TAB> return result <TAB> else : <TAB><TAB> return self",if self . flags . f_contiguous :,if self . flags . f :,99.09720145857136,98.64,False
1224,"def scan_spec_conf ( self , conf ) : <TAB> if "" metadata "" in conf : <TAB><TAB> if "" annotations "" in conf [ "" metadata "" ] and conf [ "" metadata "" ] . get ( "" annotations "" ) : <TAB><TAB><TAB> for annotation in conf [ "" metadata "" ] [ "" annotations "" ] : <TAB><TAB><TAB><TAB> for key in annotation : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" docker/default "" in annotation [ key ] <TAB><TAB><TAB><TAB><TAB><TAB><TAB> or "" runtime/default "" in annotation [ key ] <TAB><TAB><TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :","if key in conf [ ""metadata"" ] :",71.11844979361206,94.02,False
1225,"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self . CloseFailureIO ( ) <TAB> with support . catch_unraisable_exception ( ) as cm : <TAB><TAB> with self . assertRaises ( AttributeError ) : <TAB><TAB><TAB> self . tp ( rawio ) . xyzzy <TAB><TAB> if not IOBASE_EMITS_UNRAISABLE : <TAB><TAB><TAB> self . assertIsNone ( cm . unraisable ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( cm . unraisable . exc_type , OSError )",elif cm . unraisable is not None :,if not PY3 :,70.29137244791397,94.90,False
1226,"def _dumpf ( frame ) : <TAB> if frame is None : <TAB><TAB> return "" <None> "" <TAB> else : <TAB><TAB> addn = "" (with trace!) "" <TAB><TAB> <MASK> <TAB><TAB><TAB> addn = ""  **No Trace Set ** "" <TAB><TAB> return "" Frame at  %d , file  %s , line:  %d %s "" % ( <TAB><TAB><TAB> id ( frame ) , <TAB><TAB><TAB> frame . f_code . co_filename , <TAB><TAB><TAB> frame . f_lineno , <TAB><TAB><TAB> addn , <TAB><TAB> )",if frame . f_trace is None :,if not frame . f_code . co_filename :,95.83040393922965,94.85,False
1227,"def containsBadbytes ( self , value , bytecount = 4 ) : <TAB> for b in self . badbytes : <TAB><TAB> tmp = value <TAB><TAB> <MASK> <TAB><TAB><TAB> b = ord ( b ) <TAB><TAB> for i in range ( bytecount ) : <TAB><TAB><TAB> if ( tmp & 0xFF ) == b : <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> tmp >> = 8 <TAB> return False",if type ( b ) == str :,"if not isinstance ( tmp , int ) :",69.30234460999975,93.60,False
1228,"def _set_peer_statuses ( self ) : <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB><TAB> <MASK> <TAB><TAB><TAB> peer . status = PEER_BAD <TAB><TAB> elif peer . last_good > cutoff : <TAB><TAB><TAB> peer . status = PEER_GOOD <TAB><TAB> elif peer . last_good : <TAB><TAB><TAB> peer . status = PEER_STALE <TAB><TAB> else : <TAB><TAB><TAB> peer . status = PEER_NEVER",if peer . bad :,if not peer . last_good :,67.81646375411165,95.78,False
1229,"def afterTest ( self , test ) : <TAB> try : <TAB><TAB> # If the browser window is still open, close it now. <TAB><TAB> self . driver . quit ( ) <TAB> except AttributeError : <TAB><TAB> pass <TAB> except Exception : <TAB><TAB> pass <TAB> if self . options . headless : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . display . stop ( ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> pass",if self . headless_active :,if self . display :,98.42305650024072,97.39,False
1230,"def _written_variables_in_proxy ( self , contract ) : <TAB> variables = [ ] <TAB> if contract . is_upgradeable : <TAB><TAB> variables_name_written_in_proxy = self . _variable_written_in_proxy ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> variables_in_contract = [ <TAB><TAB><TAB><TAB> contract . get_state_variable_from_name ( v ) <TAB><TAB><TAB><TAB> for v in variables_name_written_in_proxy <TAB><TAB><TAB> ] <TAB><TAB><TAB> variables_in_contract = [ v for v in variables_in_contract if v ] <TAB><TAB><TAB> variables + = variables_in_contract <TAB> return list ( set ( variables ) )",if variables_name_written_in_proxy :,if variables_name_written_in_proxy :,100.0,100.00,True
1231,"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB><TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB> for child in elem : <TAB><TAB><TAB> name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB> if name . startswith ( expr ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB> cplns . append ( ( ilk , name ) ) <TAB><TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB> if not scoperef : <TAB><TAB><TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )",if name not in found_names :,if name not in found_names :,100.0,100.00,True
1232,"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB><TAB> if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not name . startswith ( "" wait_until "" ) : <TAB><TAB><TAB><TAB><TAB> if is_resource_action ( member ) : <TAB><TAB><TAB><TAB><TAB><TAB> resource_methods [ name ] = member <TAB> return resource_methods",if not name [ 0 ] . isupper ( ) :,if is_resource_action ( member ) :,69.23822574895921,94.63,False
1233,def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self . radioButtons : <TAB><TAB> btn = self . radioButtons [ moduleID ] <TAB><TAB> <MASK> <TAB><TAB><TAB> btn . SetValue ( True ) <TAB><TAB> else : <TAB><TAB><TAB> btn . SetValue ( False ) <TAB><TAB> if self . demoModules . Exists ( moduleID ) : <TAB><TAB><TAB> btn . Enable ( True ) <TAB><TAB><TAB> if moduleID == modModified : <TAB><TAB><TAB><TAB> self . btnRestore . Enable ( True ) <TAB><TAB> else : <TAB><TAB><TAB> btn . Enable ( False ) <TAB><TAB><TAB> if moduleID == modModified : <TAB><TAB><TAB><TAB> self . btnRestore . Enable ( False ),if moduleID == active :,if active == moduleID :,98.39952644262281,98.09,False
1234,"def test_controlcharacters ( self ) : <TAB> for i in range ( 128 ) : <TAB><TAB> c = chr ( i ) <TAB><TAB> testString = "" string containing  %s "" % c <TAB><TAB> if i > = 32 or c in "" \r \n \t "" : <TAB><TAB><TAB> # \r, \n and \t are the only legal control chars in XML <TAB><TAB><TAB> data = plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( plistlib . loads ( data ) , testString ) <TAB><TAB> else : <TAB><TAB><TAB> with self . assertRaises ( ValueError ) : <TAB><TAB><TAB><TAB> plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB><TAB> plistlib . dumps ( testString , fmt = plistlib . FMT_BINARY )","if c != ""\r"" :",if data :,98.33176198038575,96.34,False
1235,"def remove_usernames ( self , username : SLT [ str ] ) - > None : <TAB> with self . __lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> f "" Can ' t set  { self . username_name }  in conjunction with (already set)  "" <TAB><TAB><TAB><TAB> f "" { self . chat_id_name } s. "" <TAB><TAB><TAB> ) <TAB><TAB> parsed_username = self . _parse_username ( username ) <TAB><TAB> self . _usernames - = parsed_username",if self . _chat_ids :,if self . _usernames :,96.28645773939552,97.10,False
1236,"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB><TAB> if isinstance ( elem , str ) : <TAB><TAB><TAB> size + = len ( elem ) <TAB><TAB> elif isinstance ( elem , np . ndarray ) : <TAB><TAB><TAB> size + = elem . size * elem . itemsize <TAB><TAB> <MASK> <TAB><TAB><TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB> elif isinstance ( elem , float ) : <TAB><TAB><TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( ) <TAB> return size","elif isinstance ( elem , int ) :","elif isinstance ( elem , int ) :",75.0,100.00,True
1237,"def before_step ( self , step , feed_dict ) : <TAB> if step == 0 : <TAB><TAB> for _type , mem in self . memories . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . gan . session . run ( tf . assign ( mem [ "" var "" ] , mem [ "" source "" ] ) )","if ""var"" in mem and ""source"" in mem :","if _type == ""step"" :",64.5239137711892,88.23,False
1238,"def write ( self , * bits ) : <TAB> for bit in bits : <TAB><TAB> if not self . bytestream : <TAB><TAB><TAB> self . bytestream . append ( 0 ) <TAB><TAB> byte = self . bytestream [ self . bytenum ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB><TAB><TAB><TAB> byte = 0 <TAB><TAB><TAB><TAB> self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB> self . bytenum + = 1 <TAB><TAB><TAB> self . bitnum = 0 <TAB><TAB> mask = 2 * * self . bitnum <TAB><TAB> if bit : <TAB><TAB><TAB> byte | = mask <TAB><TAB> else : <TAB><TAB><TAB> byte & = ~ mask <TAB><TAB> self . bytestream [ self . bytenum ] = byte <TAB><TAB> self . bitnum + = 1",if self . bitnum == 8 :,if byte :,70.839200760632,97.01,False
1239,"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB><TAB> parameter_range_key , <TAB><TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB><TAB> if parameter_range_key == "" scaling_type "" : <TAB><TAB><TAB> continue <TAB><TAB> # Categorical ranges <TAB><TAB> <MASK> <TAB><TAB><TAB> for categorical_value in parameter_range_value : <TAB><TAB><TAB><TAB> value_hp . validate ( categorical_value ) <TAB><TAB> # Continuous, Integer ranges <TAB><TAB> else : <TAB><TAB><TAB> value_hp . validate ( parameter_range_value )","if isinstance ( parameter_range_value , list ) :","if isinstance ( parameter_range_value , ( list , tuple ) ) :",97.49143739977204,97.15,False
1240,"def _trackA ( self , tracks ) : <TAB> try : <TAB><TAB> track , start , end = self . featureA <TAB><TAB> assert track in tracks <TAB><TAB> return track <TAB> except TypeError : <TAB><TAB> for track in tracks : <TAB><TAB><TAB> for feature_set in track . get_sets ( ) : <TAB><TAB><TAB><TAB> if hasattr ( feature_set , "" features "" ) : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return track <TAB><TAB> return None",if self . featureA in feature_set . features . values ( ) :,if feature_set . features == self . featureA :,91.3891361767826,94.26,False
1241,"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB><TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB><TAB><TAB> continue <TAB><TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB><TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB><TAB><TAB> continue <TAB><TAB> full_name = os . path . join ( directory , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for file_path in walk ( full_name , path ) : <TAB><TAB><TAB><TAB> yield file_path <TAB><TAB> elif os . path . isfile ( full_name ) : <TAB><TAB><TAB> yield path",if os . path . isdir ( full_name ) :,if os . path . isdir ( full_name ) :,100.0,100.00,True
1242,"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> while not self . _ipc_requests . empty ( ) : <TAB><TAB><TAB> args = self . _ipc_requests . get ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> for filename in args : <TAB><TAB><TAB><TAB><TAB> if os . path . isfile ( filename ) : <TAB><TAB><TAB><TAB><TAB><TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB><TAB> self . become_active_window ( ) <TAB> finally : <TAB><TAB> self . after ( 50 , self . _poll_ipc_requests )",if self . _ipc_requests . empty ( ) :,if self . _ipc_requests . empty ( ) :,100.0,100.00,True
1243,"def test_read1 ( self ) : <TAB> self . test_write ( ) <TAB> blocks = [ ] <TAB> nread = 0 <TAB> with gzip . GzipFile ( self . filename , "" r "" ) as f : <TAB><TAB> while True : <TAB><TAB><TAB> d = f . read1 ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> blocks . append ( d ) <TAB><TAB><TAB> nread + = len ( d ) <TAB><TAB><TAB> # Check that position was updated correctly (see issue10791). <TAB><TAB><TAB> self . assertEqual ( f . tell ( ) , nread ) <TAB> self . assertEqual ( b "" "" . join ( blocks ) , data1 * 50 )",if not d :,if not d :,100.0,100.00,True
1244,"def _target_generator ( self ) : <TAB> if self . _internal_target_generator is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> from . . . . model_zoo . rcnn . rpn . rpn_target import RPNTargetGenerator <TAB><TAB> self . _internal_target_generator = RPNTargetGenerator ( <TAB><TAB><TAB> num_sample = self . _num_sample , <TAB><TAB><TAB> pos_iou_thresh = self . _pos_iou_thresh , <TAB><TAB><TAB> neg_iou_thresh = self . _neg_iou_thresh , <TAB><TAB><TAB> pos_ratio = self . _pos_ratio , <TAB><TAB><TAB> stds = self . _box_norm , <TAB><TAB><TAB> * * self . _kwargs <TAB><TAB> ) <TAB><TAB> return self . _internal_target_generator <TAB> else : <TAB><TAB> return self . _internal_target_generator",if self . _net_none :,if self . _num_sample == 0 :,96.14558600679484,97.15,False
1245,"def time_left ( self ) : <TAB> """"""Return how many seconds are left until the timeout expires"""""" <TAB> if self . is_non_blocking : <TAB><TAB> return 0 <TAB> elif self . is_infinite : <TAB><TAB> return None <TAB> else : <TAB><TAB> delta = self . target_time - self . TIME ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # clock jumped, recalculate <TAB><TAB><TAB> self . target_time = self . TIME ( ) + self . duration <TAB><TAB><TAB> return self . duration <TAB><TAB> else : <TAB><TAB><TAB> return max ( 0 , delta )",if delta > self . duration :,if delta < 0 :,93.0109788193757,96.86,False
1246,"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB><TAB> if name not in cls . __dict__ : <TAB><TAB><TAB> continue <TAB><TAB> if name != "" __init__ "" : <TAB><TAB><TAB> if not private and name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls",if name in butnot :,if not inspect . isfunction ( meth ) :,66.2937553341275,94.42,False
1247,"def load_vocab ( vocab_file : str ) - > List : <TAB> """"""Loads a vocabulary file into a dictionary."""""" <TAB> vocab = collections . OrderedDict ( ) <TAB> with io . open ( vocab_file , "" r "" , encoding = "" UTF-8 "" ) as file : <TAB><TAB> for num , line in enumerate ( file ) : <TAB><TAB><TAB> items = convert_to_unicode ( line . strip ( ) ) . split ( "" \t "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> token = items [ 0 ] <TAB><TAB><TAB> index = items [ 1 ] if len ( items ) == 2 else num <TAB><TAB><TAB> token = token . strip ( ) <TAB><TAB><TAB> vocab [ token ] = int ( index ) <TAB><TAB> return vocab",if len ( items ) > 2 :,if len ( items ) != 2 :,99.04733501709138,98.44,False
1248,"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB><TAB> new_slice_ = [ 0 ] <TAB><TAB> offset = 0 <TAB> else : <TAB><TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB><TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_slice_ . append ( 0 ) <TAB><TAB> elif offset < len ( slice_ ) : <TAB><TAB><TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB><TAB><TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_",if self . squeeze_dims [ i ] :,if i == 0 :,68.3033403505225,95.87,False
1249,"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB><TAB> local_version = get_local_timestamp ( folder ) <TAB><TAB> if remote_version > local_version : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> update_setter . set_value ( True ) <TAB><TAB><TAB> version_setter . set_value ( remote_version ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> else : <TAB><TAB> return False",if auto :,if auto :,100.0,100.00,True
1250,"def iter_content ( self , chunk_size_bytes ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> data = self . _fp . read ( chunk_size_bytes ) <TAB><TAB> except IOError as e : <TAB><TAB><TAB> raise Fetcher . PermanentError ( <TAB><TAB><TAB><TAB> "" Problem reading chunk from  {} :  {} "" . format ( self . _fp . name , e ) <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> yield data",if not data :,if not data :,100.0,100.00,True
1251,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB><TAB> if isinstance ( arg , bool ) : <TAB><TAB><TAB> gvariant + = ""   {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB> elif isinstance ( arg , ( int , float ) ) : <TAB><TAB><TAB> gvariant + = f ""   { arg } "" <TAB><TAB> <MASK> <TAB><TAB><TAB> gvariant + = f '   "" { arg } "" ' <TAB><TAB> else : <TAB><TAB><TAB> gvariant + = f ""   { arg !s} "" <TAB> return gvariant . lstrip ( )","elif isinstance ( arg , str ) :","elif isinstance ( arg , str ) :",100.0,100.00,True
1252,"def _element_keywords ( cls , backend , elements = None ) : <TAB> "" Returns a dictionary of element names to allowed keywords "" <TAB> if backend not in Store . loaded_backends ( ) : <TAB><TAB> return { } <TAB> mapping = { } <TAB> backend_options = Store . options ( backend ) <TAB> elements = elements if elements is not None else backend_options . keys ( ) <TAB> for element in elements : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> element = element if isinstance ( element , tuple ) else ( element , ) <TAB><TAB> element_keywords = [ ] <TAB><TAB> options = backend_options [ "" . "" . join ( element ) ] <TAB><TAB> for group in Options . _option_groups : <TAB><TAB><TAB> element_keywords . extend ( options [ group ] . allowed_keywords ) <TAB><TAB> mapping [ element [ 0 ] ] = element_keywords <TAB> return mapping","if ""."" in element :","if not isinstance ( element , str ) :",83.62105962496781,96.55,False
1253,"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB> if self . use_prop or self . get_prop_name ( ) : <TAB><TAB><TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB> print ( "" V "" , value ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB> param_node . int_ = value <TAB><TAB><TAB> elif isinstance ( value , float ) : <TAB><TAB><TAB><TAB> param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB> param_node . float_ = value","if isinstance ( value , int ) :","if isinstance ( value , int ) :",100.0,100.00,True
1254,"def _get_oshape ( indices_shape , depth , axis ) : <TAB> oshape = [ ] <TAB> true_axis = len ( indices_shape ) if axis == - 1 else axis <TAB> ndim = len ( indices_shape ) + 1 <TAB> indices_index = 0 <TAB> for i in range ( 0 , ndim ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> oshape . append ( depth ) <TAB><TAB> else : <TAB><TAB><TAB> oshape . append ( indices_shape [ indices_index ] ) <TAB><TAB><TAB> indices_index + = 1 <TAB> return oshape",if i == true_axis :,if indices_index == true_axis :,68.5434829763865,97.12,False
1255,"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB><TAB> value = value . upper ( ) <TAB><TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB><TAB><TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value [ len ( prefix ) : ] <TAB><TAB><TAB> value = value . lstrip ( "" _ "" ) <TAB><TAB> if hasattr ( self . group , value ) : <TAB><TAB><TAB> return getattr ( self . group , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB> else : <TAB><TAB> return value",if value . startswith ( prefix ) :,if value . startswith ( prefix ) :,100.0,100.00,True
1256,"def shuffle_unison_inplace ( list_of_lists , random_state = None ) : <TAB> if list_of_lists : <TAB><TAB> assert all ( len ( l ) == len ( list_of_lists [ 0 ] ) for l in list_of_lists ) <TAB><TAB> <MASK> <TAB><TAB><TAB> random_state . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> p = np . random . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB><TAB> return [ l [ p ] for l in list_of_lists ] <TAB> return None",if random_state is not None :,if random_state :,93.73245284330136,97.31,False
1257,"def _load_module ( self ) : <TAB> spec = self . default_module_spec <TAB> module_identifier = self . module_identifier <TAB> if module_identifier : <TAB><TAB> impls = self . get_module_implementation_map ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ModuleNotFound ( <TAB><TAB><TAB><TAB> "" Invalid module identifier  %r  in  %s "" <TAB><TAB><TAB><TAB> % ( module_identifier , force_ascii ( repr ( self ) ) ) <TAB><TAB><TAB> ) <TAB><TAB> spec = impls [ module_identifier ] <TAB> cls = load ( <TAB><TAB> spec , context_explanation = "" Loading module for  %s "" % force_ascii ( repr ( self ) ) <TAB> ) <TAB> options = getattr ( self , self . module_options_field , None ) or { } <TAB> return cls ( self , options )",if module_identifier not in impls :,if module_identifier not in impls :,100.0,100.00,True
1258,"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB><TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB><TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( request , numbers . Integral ) : <TAB><TAB><TAB><TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> for j in range ( len ( data [ i ] ) ) : <TAB><TAB><TAB><TAB><TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data )",if shapes [ i ] is not None :,if i in shapes :,95.81348509448006,96.74,False
1259,"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB><TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB><TAB><TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB><TAB><TAB> for ak in keys : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> ak = dict ( ak ) <TAB><TAB><TAB><TAB><TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB><TAB><TAB><TAB><TAB> if ak not in res : <TAB><TAB><TAB><TAB><TAB><TAB> res . append ( ak ) <TAB><TAB> elif k not in res : <TAB><TAB><TAB> res . append ( k ) <TAB> return res","if c_date == ak [ ""CreateDate"" ] :","if isinstance ( ak , dict ) :",93.86430560078891,94.89,False
1260,"def _is_legacy_mode ( self , node ) : <TAB> """"""Checks if the ``ast.Call`` node's keywords signal using legacy mode."""""" <TAB> script_mode = False <TAB> py_version = "" py2 "" <TAB> for kw in node . keywords : <TAB><TAB> <MASK> <TAB><TAB><TAB> script_mode = ( <TAB><TAB><TAB><TAB> bool ( kw . value . value ) if isinstance ( kw . value , ast . NameConstant ) else True <TAB><TAB><TAB> ) <TAB><TAB> if kw . arg == "" py_version "" : <TAB><TAB><TAB> py_version = kw . value . s if isinstance ( kw . value , ast . Str ) else "" py3 "" <TAB> return not ( py_version . startswith ( "" py3 "" ) or script_mode )","if kw . arg == ""script_mode"" :","if kw . arg == ""script_mode"" :",100.0,100.00,True
1261,"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ] # type: List[V1EventTrigger] <TAB> for e in events : <TAB><TAB> entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB><TAB> if not entity_ref : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for kind in e . kinds : <TAB><TAB><TAB> status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB><TAB><TAB> if status : <TAB><TAB><TAB><TAB> statuses_by_refs [ entity_ref ] . append ( status ) <TAB> return statuses_by_refs",if entity_ref not in statuses_by_refs :,if entity_ref in statuses_by_refs :,98.745829665771,98.89,False
1262,"def items ( self ) : <TAB> dict = { } <TAB> for userdir in self . XDG_DIRS . keys ( ) : <TAB><TAB> prefix = self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> path = ( <TAB><TAB><TAB><TAB> os . getenv ( "" HOME "" ) <TAB><TAB><TAB><TAB> + "" / "" <TAB><TAB><TAB><TAB> + "" / "" . join ( self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 1 : ] ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> path = self . get ( userdir ) . strip ( ' "" ' ) <TAB><TAB> dict [ userdir ] = path <TAB> return dict . items ( )",if prefix :,"if prefix == ""/"" :",73.46489089018027,97.14,False
1263,"def clean_objects ( string , common_attributes ) : <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB><TAB> prefix_words_are_adj = True <TAB><TAB> for att in words [ : - 1 ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> prefix_words_are_adj = False <TAB><TAB> if prefix_words_are_adj : <TAB><TAB><TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB><TAB> else : <TAB><TAB><TAB> return [ string ] , [ ] <TAB> else : <TAB><TAB> return [ string ] , [ ]",if att not in common_attributes :,if att in common_attributes :,98.66100120751614,98.78,False
1264,"def extract_custom ( extractor , * args , * * kw ) : <TAB> for match in extractor ( * args , * * kw ) : <TAB><TAB> msg = match [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> unused = ( <TAB><TAB><TAB><TAB> "" <unused singular (hash= %s )> "" % md5 ( msg [ 1 ] . encode ( "" utf8 "" ) ) . hexdigest ( ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> msg = ( unused , msg [ 1 ] , msg [ 2 ] ) <TAB><TAB><TAB> match = ( match [ 0 ] , match [ 1 ] , msg , match [ 3 ] ) <TAB><TAB> yield match","if isinstance ( msg , tuple ) and msg [ 0 ] == """" :","if msg [ 0 ] == ""unused"" :",69.66565523578936,94.71,False
1265,"def test_convex_decomposition ( self ) : <TAB> mesh = g . get_mesh ( "" quadknot.obj "" ) <TAB> engines = [ ( "" vhacd "" , g . trimesh . interfaces . vhacd . exists ) ] <TAB> for engine , exists in engines : <TAB><TAB> <MASK> <TAB><TAB><TAB> g . log . warning ( "" skipping convex decomposition engine  %s "" , engine ) <TAB><TAB><TAB> continue <TAB><TAB> g . log . info ( "" Testing convex decomposition with engine  %s "" , engine ) <TAB><TAB> meshes = mesh . convex_decomposition ( engine = engine ) <TAB><TAB> self . assertTrue ( len ( meshes ) > 1 ) <TAB><TAB> for m in meshes : <TAB><TAB><TAB> self . assertTrue ( m . is_watertight ) <TAB><TAB> g . log . info ( "" convex decomposition succeeded with  %s "" , engine )",if not exists :,if not exists :,100.0,100.00,True
1266,"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB><TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB><TAB> hasConst = not ( <TAB><TAB><TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB><TAB> ) <TAB><TAB> if hasConst : <TAB><TAB><TAB> idx - = 1 <TAB><TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB><TAB> _lt = _l . __class__ <TAB><TAB> <MASK> <TAB><TAB><TAB> ostream . write ( ""  -  "" ) <TAB><TAB> else : <TAB><TAB><TAB> ostream . write ( ""  +  "" )",if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,if _lt . __class__ in native_numeric_types :,64.32119586150517,93.19,False
1267,"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB><TAB> data = list ( data ) <TAB><TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB><TAB> m_items = items . copy ( ) <TAB><TAB> for idx , item in enumerate ( items ) : <TAB><TAB><TAB> if item < 0 : <TAB><TAB><TAB><TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB> if i < len ( data ) and i > - 1 : <TAB><TAB><TAB><TAB> del data [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return tuple ( data ) <TAB><TAB> else : <TAB><TAB><TAB> return data <TAB> else : <TAB><TAB> return None",if is_tuple :,if is_tuple :,100.0,100.00,True
1268,"def process_error ( self , data ) : <TAB> if data . get ( "" error "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AuthCanceled ( self , data . get ( "" error_description "" , "" "" ) ) <TAB><TAB> raise AuthFailed ( self , data . get ( "" error_description "" ) or data [ "" error "" ] ) <TAB> elif "" denied "" in data : <TAB><TAB> raise AuthCanceled ( self , data [ "" denied "" ] )","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :","if ""cancelled"" in data :",65.25498273458447,85.94,False
1269,"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB> amount = random . randint ( 10 , 15 ) <TAB><TAB> if char == "" > "" : <TAB><TAB><TAB> retval + = "" > "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> elif char == "" < "" : <TAB><TAB><TAB> retval + = "" < "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> else : <TAB><TAB><TAB> retval + = char <TAB> return retval","elif char == "" "" :","elif char == ""-"" :",73.88519358602504,99.17,False
1270,"def retry_http_digest_auth ( self , req , auth ) : <TAB> token , challenge = auth . split ( ""   "" , 1 ) <TAB> chal = parse_keqv_list ( parse_http_list ( challenge ) ) <TAB> auth = self . get_authorization ( req , chal ) <TAB> if auth : <TAB><TAB> auth_val = "" Digest  %s "" % auth <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> req . add_unredirected_header ( self . auth_header , auth_val ) <TAB><TAB> resp = self . parent . open ( req ) <TAB><TAB> return resp","if req . headers . get ( self . auth_header , None ) == auth_val :","if req . headers . get ( self . auth_header , None ) == auth_val",93.7741477624823,98.56,False
1271,"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB><TAB> sockname = None <TAB><TAB> try : <TAB><TAB><TAB> sockname = self . sock . getsockname ( ) <TAB><TAB> except ( socket . error , OSError ) : <TAB><TAB><TAB> pass <TAB><TAB> self . sock . close ( ) <TAB><TAB> if type ( sockname ) is str : <TAB><TAB><TAB> # it was a Unix domain socket, remove it from the filesystem <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . remove ( sockname ) <TAB> self . sock = None",if os . path . exists ( sockname ) :,if os . path . exists ( sockname ) :,100.0,100.00,True
1272,"def to_nurbs ( self , curves ) : <TAB> result = [ ] <TAB> for i , c in enumerate ( curves ) : <TAB><TAB> nurbs = SvNurbsCurve . to_nurbs ( c ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( f "" Curve # { i }  -  { c }  - can not be converted to NURBS! "" ) <TAB><TAB> result . append ( nurbs ) <TAB> return result",if nurbs is None :,if nurbs is None :,100.0,100.00,True
1273,"def handle_1_roomid_raffle ( self , i ) : <TAB> if i [ 1 ] in [ "" handle_1_room_TV "" , "" handle_1_room_captain "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . notify ( "" post_watching_history "" , i [ 0 ] ) <TAB><TAB><TAB> await self . notify ( i [ 1 ] , i [ 0 ] , i [ 2 ] ) <TAB> else : <TAB><TAB> print ( "" hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh "" , i )","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :",if self . notify :,61.6202783897187,83.83,False
1274,"def init_ps_var_partition ( self ) : <TAB> ps_vars = { } <TAB> for v in self . _non_embed_vars . values ( ) : <TAB><TAB> if v . name not in self . _var_to_ps : <TAB><TAB><TAB> self . _var_to_ps [ v . name ] = string_to_id ( v . name , self . _ps_num ) <TAB><TAB> ps_id = self . _var_to_ps [ v . name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> ps_vars [ ps_id ] = [ v ] <TAB><TAB> else : <TAB><TAB><TAB> ps_vars [ ps_id ] . append ( v ) <TAB> self . _ps_vars = ps_vars",if ps_id not in ps_vars :,if ps_id not in ps_vars :,100.0,100.00,True
1275,"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB><TAB> for name in files : <TAB><TAB><TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if ""do_build"" not in name and ""do_populate_sdk"" not in name :","if name . endswith ( "".py"" ) :",93.10896803401216,88.55,False
1276,"def setSelectedLabelState ( self , p ) : # selected, disabled <TAB> c = self . c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c . edit_widget ( p ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> g . trace ( self . trace_n , c . edit_widget ( p ) , p ) <TAB><TAB><TAB> # g.trace(g.callers(6)) <TAB><TAB><TAB> self . trace_n + = 1 <TAB><TAB> self . setDisabledHeadlineColors ( p )",if 0 :,if self . trace_n < self . trace_len :,71.23060360158759,91.74,False
1277,"def filter_tasks ( self , task_types = None , task_states = None , task_text = None ) : <TAB> tasks = self . api . tasks ( self . id ) . get ( "" tasks "" , { } ) <TAB> if tasks and tasks . get ( "" task "" ) : <TAB><TAB> return [ <TAB><TAB><TAB> Task ( self , task ) <TAB><TAB><TAB> for task in tasks . get ( "" task "" , [ ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> and ( not task_states or task [ "" state "" ] . lower ( ) in task_states ) <TAB><TAB><TAB> and ( not task_text or task_text . lower ( ) in str ( task ) . lower ( ) ) <TAB><TAB> ] <TAB> else : <TAB><TAB> return [ ]","if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )","if task [ ""type"" ] . lower ( ) in task_types",88.6442887685058,95.55,False
1278,"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if item < vector [ - 1 ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB> break <TAB><TAB> new_vector = vector + [ item ] <TAB><TAB> if level + 1 == len ( hits ) : <TAB><TAB><TAB> yield new_vector <TAB><TAB> elif level + 1 < len ( hits ) : <TAB><TAB><TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB> yield result",if vector :,if vector :,100.0,100.00,True
1279,def _transmit_from_storage ( self ) - > None : <TAB> for blob in self . storage . gets ( ) : <TAB><TAB> # give a few more seconds for blob lease operation <TAB><TAB> # to reduce the chance of race (for perf consideration) <TAB><TAB> if blob . lease ( self . _timeout + 5 ) : <TAB><TAB><TAB> envelopes = [ TelemetryItem ( * * x ) for x in blob . get ( ) ] <TAB><TAB><TAB> result = self . _transmit ( list ( envelopes ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> blob . lease ( 1 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> blob . delete ( ),if result == ExportResult . FAILED_RETRYABLE :,if result :,97.53470666593525,95.54,False
1280,"def load_dictionary ( file ) : <TAB> oui = { } <TAB> with open ( file , "" r "" ) as f : <TAB><TAB> for line in f : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = line . split ( "" (hex) "" ) <TAB><TAB><TAB><TAB> key = data [ 0 ] . replace ( "" - "" , "" : "" ) . lower ( ) . strip ( ) <TAB><TAB><TAB><TAB> company = data [ 1 ] . strip ( ) <TAB><TAB><TAB><TAB> oui [ key ] = company <TAB> return oui","if ""(hex)"" in line :","if line . startswith ( ""company"" ) :",95.21211760703787,94.95,False
1281,"def _yield_minibatches_idx ( self , rgen , n_batches , data_ary , shuffle = True ) : <TAB> indices = np . arange ( data_ary . shape [ 0 ] ) <TAB> if shuffle : <TAB><TAB> indices = rgen . permutation ( indices ) <TAB> if n_batches > 1 : <TAB><TAB> remainder = data_ary . shape [ 0 ] % n_batches <TAB><TAB> <MASK> <TAB><TAB><TAB> minis = np . array_split ( indices [ : - remainder ] , n_batches ) <TAB><TAB><TAB> minis [ - 1 ] = np . concatenate ( ( minis [ - 1 ] , indices [ - remainder : ] ) , axis = 0 ) <TAB><TAB> else : <TAB><TAB><TAB> minis = np . array_split ( indices , n_batches ) <TAB> else : <TAB><TAB> minis = ( indices , ) <TAB> for idx_batch in minis : <TAB><TAB> yield idx_batch",if remainder :,if remainder > 0 :,88.67278168220315,98.52,False
1282,"def canonical_custom_headers ( self , headers ) : <TAB> hoi = [ ] <TAB> custom_headers = { } <TAB> for key in headers : <TAB><TAB> lk = key . lower ( ) <TAB><TAB> if headers [ key ] is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> custom_headers [ lk ] = "" , "" . join ( v . strip ( ) for v in headers . get_all ( key ) ) <TAB> sorted_header_keys = sorted ( custom_headers . keys ( ) ) <TAB> for key in sorted_header_keys : <TAB><TAB> hoi . append ( "" %s : %s "" % ( key , custom_headers [ key ] ) ) <TAB> return "" \n "" . join ( hoi )","if lk . startswith ( ""x-amz-"" ) :",if lk in custom_headers :,68.81946908071778,95.67,False
1283,"def validate ( self , data ) : <TAB> if not data . get ( "" reason "" ) : <TAB><TAB> # If reason is not provided, message is required and can not be <TAB><TAB> # null or blank. <TAB><TAB> message = data . get ( "" message "" ) <TAB><TAB> if not message : <TAB><TAB><TAB> if "" message "" not in data : <TAB><TAB><TAB><TAB> msg = serializers . Field . default_error_messages [ "" required "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> msg = serializers . Field . default_error_messages [ "" null "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> msg = serializers . CharField . default_error_messages [ "" blank "" ] <TAB><TAB><TAB> raise serializers . ValidationError ( { "" message "" : [ msg ] } ) <TAB> return data",elif message is None :,"elif ""can not be provided"" not in data :",97.35110349761224,95.59,False
1284,def tearDown ( self ) : <TAB> try : <TAB><TAB> os . chdir ( self . cwd ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . remove ( self . pythonexe ) <TAB><TAB> test_support . rmtree ( self . parent_dir ) <TAB> finally : <TAB><TAB> BaseTestCase . tearDown ( self ),if self . pythonexe != sys . executable :,if self . pythonexe :,67.02105415846489,92.81,False
1285,"def update ( self , value , label ) : <TAB> if self . _disabled : <TAB><TAB> return <TAB> try : <TAB><TAB> self . _progress . value = value <TAB><TAB> self . _label . value = label <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _displayed = True <TAB><TAB><TAB> display_widget ( self . _widget ) <TAB> except Exception as e : <TAB><TAB> self . _disabled = True <TAB><TAB> logger . exception ( e ) <TAB><TAB> wandb . termwarn ( "" Unable to render progress bar, see the user log for details "" )",if not self . _displayed :,if self . _widget :,74.23801350720007,96.87,False
1286,"def GetBinaryOperationBinder ( self , op ) : <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _binaryOperationBinders [ op ] <TAB><TAB> b = runtime . SymplBinaryOperationBinder ( op ) <TAB><TAB> self . _binaryOperationBinders [ op ] = b <TAB> return b",if self . _binaryOperationBinders . ContainsKey ( op ) :,if op in self . _binaryOperationBinders :,87.46472896789558,90.62,False
1287,"def apply ( self , l , b , evaluation ) : <TAB> "" FromDigits[l_, b_] "" <TAB> if l . get_head_name ( ) == "" System`List "" : <TAB><TAB> value = Integer ( 0 ) <TAB><TAB> for leaf in l . leaves : <TAB><TAB><TAB> value = Expression ( "" Plus "" , Expression ( "" Times "" , value , b ) , leaf ) <TAB><TAB> return value <TAB> elif isinstance ( l , String ) : <TAB><TAB> value = FromDigits . _parse_string ( l . get_string_value ( ) , b ) <TAB><TAB> <MASK> <TAB><TAB><TAB> evaluation . message ( "" FromDigits "" , "" nlst "" ) <TAB><TAB> else : <TAB><TAB><TAB> return value <TAB> else : <TAB><TAB> evaluation . message ( "" FromDigits "" , "" nlst "" )",if value is None :,if value is None :,100.0,100.00,True
1288,"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB><TAB> try : <TAB><TAB><TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB><TAB><TAB> request = self . send_queue . get ( True , 6.0 ) <TAB><TAB><TAB> if self . socket is not None : <TAB><TAB><TAB><TAB> # Socket got closed and set to None in another thread... <TAB><TAB><TAB><TAB> self . socket . sendall ( request ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . send_queue . task_done ( ) <TAB><TAB> except queue . Empty : <TAB><TAB><TAB> pass <TAB><TAB> except OSError : <TAB><TAB><TAB> self . stop_event . set ( )",if self . send_queue is not None :,if request . timeout is None :,97.23131159734226,96.52,False
1289,"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB><TAB> if isinstance ( result , str ) : <TAB><TAB><TAB> result = result . encode ( "" ascii "" ) <TAB><TAB> if isinstance ( expected , str ) : <TAB><TAB><TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB> if contains : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB> return False <TAB> return True",if eline not in rline :,if rline . startswith ( eline ) :,72.43420255691461,97.05,False
1290,"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> normal_init ( m , std = 0.001 ) <TAB><TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB><TAB> if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB> normal_init ( m , std = 0.001 , bias = 0 )","if isinstance ( m , nn . ConvTranspose2d ) :","if isinstance ( m , nn . ConvTranspose2d ) :",75.0,100.00,True
1291,"def filter_rel_attrs ( field_name , * * rel_attrs ) : <TAB> clean_dict = { } <TAB> for k , v in rel_attrs . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> splitted_key = k . split ( "" __ "" ) <TAB><TAB><TAB> key = "" __ "" . join ( splitted_key [ 1 : ] ) <TAB><TAB><TAB> clean_dict [ key ] = v <TAB><TAB> else : <TAB><TAB><TAB> clean_dict [ k ] = v <TAB> return clean_dict","if k . startswith ( field_name + ""__"" ) :","if ""__"" in k :",90.38858613743469,92.55,False
1292,"def cancel ( self ) : <TAB> with self . _condition : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _squash ( <TAB><TAB><TAB><TAB> state_root = self . _previous_state_hash , <TAB><TAB><TAB><TAB> context_ids = [ self . _previous_context_id ] , <TAB><TAB><TAB><TAB> persist = False , <TAB><TAB><TAB><TAB> clean_up = True , <TAB><TAB><TAB> ) <TAB><TAB> self . _cancelled = True <TAB><TAB> self . _condition . notify_all ( )",if not self . _cancelled and not self . _final and self . _previous_context_id :,if self . _previous_state_hash != self . _previous_state_hash :,83.94268845810473,91.05,False
1293,"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB><TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> level_ref + = len ( levels ) <TAB><TAB> if not ( 0 < = level_ref < len ( levels ) ) : <TAB><TAB><TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB><TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) )",if level_ref < 0 :,if level_ref < 0 :,100.0,100.00,True
1294,"def parse_node ( self , node , alias_map = None , conv = None ) : <TAB> sql , params , unknown = self . _parse ( node , alias_map , conv ) <TAB> if unknown and conv and params : <TAB><TAB> params = [ conv . db_value ( i ) for i in params ] <TAB> if isinstance ( node , Node ) : <TAB><TAB> if node . _negated : <TAB><TAB><TAB> sql = "" NOT  %s "" % sql <TAB><TAB> <MASK> <TAB><TAB><TAB> sql = ""   "" . join ( ( sql , "" AS "" , node . _alias ) ) <TAB><TAB> if node . _ordering : <TAB><TAB><TAB> sql = ""   "" . join ( ( sql , node . _ordering ) ) <TAB> return sql , params",if node . _alias :,if node . _alias :,100.0,100.00,True
1295,"def parse_object_id ( _ , values ) : <TAB> if values : <TAB><TAB> for key in values : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> val = values [ key ] <TAB><TAB><TAB><TAB> if len ( val ) > 10 : <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> values [ key ] = utils . ObjectIdSilent ( val ) <TAB><TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB><TAB> values [ key ] = None","if key . endswith ( ""_id"" ) :",if key in values :,90.41613144245576,94.46,False
1296,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 16 : <TAB><TAB><TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
1297,"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB> rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB> if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB><TAB> for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not checks . is_cce_value_valid ( "" CCE- "" + str ( i_value ) ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if i_type [ 0 : 3 ] == ""cce"" :","if i_type == ""product"" :",92.55977577255861,94.59,False
1298,"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB><TAB> yield ( <TAB><TAB><TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB><TAB><TAB> simple_colorize ( todesc , "" description "" ) , <TAB><TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB><TAB> if line is None : <TAB><TAB><TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB><TAB><TAB> # generated for the first line <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB><TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB><TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> yield line",if i > 0 :,if i == 0 :,98.95534774252658,98.62,False
1299,"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB><TAB> key = pattern <TAB><TAB> if "" % "" not in pattern : <TAB><TAB><TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB><TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB><TAB><TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB> else : <TAB><TAB><TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :","elif key in ( ""TAI64N"" , "" ^TAI64N""",89.3034531933328,94.87,False
1300,"def ref_max_pooling_2d ( x , kernel , stride , ignore_border , pad ) : <TAB> y = [ ] <TAB> for xx in x . reshape ( ( - 1 , ) + x . shape [ - 3 : ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> xx = xx [ np . newaxis ] <TAB><TAB> y + = [ <TAB><TAB><TAB> refs . pooling_2d ( xx , "" max "" , kernel , stride , pad , ignore_border ) [ np . newaxis ] <TAB><TAB> ] <TAB> y = np . vstack ( y ) <TAB> if x . ndim == 2 : <TAB><TAB> y = np . squeeze ( y , 1 ) <TAB> return y . reshape ( x . shape [ : - 3 ] + y . shape [ 1 : ] )",if xx . ndim == 2 :,if xx . ndim == 2 :,100.0,100.00,True
1301,"def show_topics ( ) : <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB><TAB> if not os . path . isdir ( pp ) : <TAB><TAB><TAB> continue <TAB><TAB> content = os . listdir ( pp ) <TAB><TAB> for pn in content : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> name = pn <TAB><TAB><TAB> print ( name )","if ""."" in pn :","if pn . startswith ( ""./"" ) :",95.11108972979984,95.10,False
1302,"def justify_toggle_auto ( self , event = None ) : <TAB> c = self <TAB> if c . editCommands . autojustify == 0 : <TAB><TAB> c . editCommands . autojustify = abs ( c . config . getInt ( "" autojustify "" ) or 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> g . es ( "" Autojustify on, @int autojustify ==  %s "" % c . editCommands . autojustify ) <TAB><TAB> else : <TAB><TAB><TAB> g . es ( "" Set @int autojustify in @settings "" ) <TAB> else : <TAB><TAB> c . editCommands . autojustify = 0 <TAB><TAB> g . es ( "" Autojustify off "" )",if c . editCommands . autojustify :,if c . editCommands . autojustify :,100.0,100.00,True
1303,"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB> elif token . token_type == TOKEN_VAR : <TAB><TAB><TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars",if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_VAR :,98.67906918715437,98.37,False
1304,"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB><TAB> if operation [ "" type "" ] == "" crop "" : <TAB><TAB><TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB><TAB><TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> width = operation [ "" width "" ] <TAB><TAB><TAB> height = operation [ "" height "" ] <TAB> return ( width , height )","if operation [ ""type"" ] == ""resize"" :","elif operation [ ""type"" ] == ""crop"" :",77.89629440763983,96.84,False
1305,"def get_eval_matcher ( self ) : <TAB> if isinstance ( self . data [ "" match "" ] , str ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> values = [ "" explicitDeny "" , "" implicitDeny "" ] <TAB><TAB> else : <TAB><TAB><TAB> values = [ "" allowed "" ] <TAB><TAB> vf = ValueFilter ( <TAB><TAB><TAB> { "" type "" : "" value "" , "" key "" : "" EvalDecision "" , "" value "" : values , "" op "" : "" in "" } <TAB><TAB> ) <TAB> else : <TAB><TAB> vf = ValueFilter ( self . data [ "" match "" ] ) <TAB> vf . annotate = False <TAB> return vf","if self . data [ ""match"" ] == ""denied"" :","if self . data [ ""match"" ] == ""implicitDeny"" :",98.95783192280525,98.65,False
1306,"def test_training ( self ) : <TAB> if not self . model_tester . is_training : <TAB><TAB> return <TAB> config , inputs_dict = self . model_tester . prepare_config_and_inputs_for_common ( ) <TAB> config . return_dict = True <TAB> for model_class in self . all_model_classes : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> model = model_class ( config ) <TAB><TAB> model . to ( torch_device ) <TAB><TAB> model . train ( ) <TAB><TAB> inputs = self . _prepare_for_class ( inputs_dict , model_class , return_labels = True ) <TAB><TAB> loss = model ( * * inputs ) . loss <TAB><TAB> loss . backward ( )",if model_class in MODEL_MAPPING . values ( ) :,"if model_class . __name__ == ""Model"" :",94.82899429417479,94.32,False
1307,"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB><TAB> emu . stopEmu ( ) <TAB><TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB><TAB> <MASK> <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB> elif self . arch == "" amd64 "" : <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB><TAB><TAB> self . vw . makePointer ( reg , follow = True )","if self . arch == ""i386"" :","if self . arch == ""i386"" :",100.0,100.00,True
1308,"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> bsize = 0 <TAB><TAB> elif size < = 3 : <TAB><TAB><TAB> bsize = 4 <TAB><TAB> elif size < = 6 : <TAB><TAB><TAB> bsize = 8 <TAB><TAB> elif size < = 9 : <TAB><TAB><TAB> bsize = 12 <TAB><TAB> elif size < = 12 : <TAB><TAB><TAB> bsize = 16 <TAB><TAB> else : <TAB><TAB><TAB> bsize = 20 <TAB><TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize )",if size == 0 :,if size == 0 :,100.0,100.00,True
1309,"def __new__ ( cls , dependencies ) : <TAB> deps = check . list_param ( dependencies , "" dependencies "" , of_type = DependencyDefinition ) <TAB> seen = { } <TAB> for dep in deps : <TAB><TAB> key = dep . solid + "" : "" + dep . output <TAB><TAB> <MASK> <TAB><TAB><TAB> raise DagsterInvalidDefinitionError ( <TAB><TAB><TAB><TAB> ' Duplicate dependencies on solid  "" {dep.solid} ""  output  "" {dep.output} ""   ' <TAB><TAB><TAB><TAB> "" used in the same MultiDependencyDefinition. "" . format ( dep = dep ) <TAB><TAB><TAB> ) <TAB><TAB> seen [ key ] = True <TAB> return super ( MultiDependencyDefinition , cls ) . __new__ ( cls , deps )",if key in seen :,if key in seen :,100.0,100.00,True
1310,"def get_explanation ( self , spec ) : <TAB> """"""Expand an explanation."""""" <TAB> if spec : <TAB><TAB> try : <TAB><TAB><TAB> a = self . dns_txt ( spec ) <TAB><TAB><TAB> if len ( a ) == 1 : <TAB><TAB><TAB><TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB><TAB> except PermError : <TAB><TAB><TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise # but report in harsh mode for record checking tools <TAB><TAB><TAB> pass <TAB> el<MASK> <TAB><TAB> raise PermError ( "" Empty domain-spec on exp= "" ) <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if self . strict > 1 :,if self . strict :,97.42096034895636,97.14,False
1311,"def build ( self ) : <TAB> if self . args . get ( "" sle_id "" ) : <TAB><TAB> self . process_sle_against_current_voucher ( ) <TAB> else : <TAB><TAB> entries_to_fix = self . get_future_entries_to_fix ( ) <TAB><TAB> i = 0 <TAB><TAB> while i < len ( entries_to_fix ) : <TAB><TAB><TAB> sle = entries_to_fix [ i ] <TAB><TAB><TAB> i + = 1 <TAB><TAB><TAB> self . process_sle ( sle ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . get_dependent_entries_to_fix ( entries_to_fix , sle ) <TAB> if self . exceptions : <TAB><TAB> self . raise_exceptions ( ) <TAB> self . update_bin ( )",if sle . dependant_sle_voucher_detail_no :,"if self . args . get ( ""dependent"" ) :",67.97807223603215,94.70,False
1312,"def ValidateStopLatitude ( self , problems ) : <TAB> if self . stop_lat is not None : <TAB><TAB> value = self . stop_lat <TAB><TAB> try : <TAB><TAB><TAB> if not isinstance ( value , ( float , int ) ) : <TAB><TAB><TAB><TAB> self . stop_lat = util . FloatStringToFloat ( value , problems ) <TAB><TAB> except ( ValueError , TypeError ) : <TAB><TAB><TAB> problems . InvalidValue ( "" stop_lat "" , value ) <TAB><TAB><TAB> del self . stop_lat <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> problems . InvalidValue ( "" stop_lat "" , value )",if self . stop_lat > 90 or self . stop_lat < - 90 :,if self . stop_lat < 0 :,92.91064685151112,94.07,False
1313,"def set ( self , obj , * * kwargs ) : <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB><TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for k1 in self . combinations [ k ] : <TAB><TAB><TAB><TAB> if not hasattr ( self , k1 ) : <TAB><TAB><TAB><TAB><TAB> setattr ( self , k1 , ignore )",if k in self . combinations :,if k in self . combinations :,100.0,100.00,True
1314,"def split ( self , duration , include_remainder = True ) : <TAB> # Convert seconds to timedelta, if appropriate. <TAB> duration = _seconds_or_timedelta ( duration ) <TAB> if duration < = timedelta ( seconds = 0 ) : <TAB><TAB> raise ValueError ( "" cannot call split with a non-positive timedelta "" ) <TAB> start = self . start <TAB> while start < self . end : <TAB><TAB> if start + duration < = self . end : <TAB><TAB><TAB> yield MayaInterval ( start , start + duration ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield MayaInterval ( start , self . end ) <TAB><TAB> start + = duration",elif include_remainder :,if include_remainder :,98.65870051872776,98.45,False
1315,"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB><TAB> if issubclass ( layout_object . __class__ , clz ) : <TAB><TAB><TAB> return layout_object <TAB><TAB> <MASK> <TAB><TAB><TAB> gf = get_first_field ( layout_object , clz ) <TAB><TAB><TAB> if gf : <TAB><TAB><TAB><TAB> return gf","elif hasattr ( layout_object , ""get_field_names"" ) :","elif issubclass ( layout_object , ( BaseField , BaseField ) ) :",90.23258205223682,91.41,False
1316,"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB><TAB> key = pattern <TAB><TAB> if "" % "" not in pattern : <TAB><TAB><TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB><TAB> <MASK> <TAB><TAB><TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB><TAB><TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB> else : <TAB><TAB><TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH",68.94631791944367,95.78,False
1317,"def findOwningViewController ( self , object ) : <TAB> while object : <TAB><TAB> <MASK> <TAB><TAB><TAB> description = fb . evaluateExpressionValue ( object ) . GetObjectDescription ( ) <TAB><TAB><TAB> print ( "" Found the owning view controller. \n {} "" . format ( description ) ) <TAB><TAB><TAB> cmd = ' echo  {}  | tr -d  "" \n ""  | pbcopy ' . format ( object ) <TAB><TAB><TAB> os . system ( cmd ) <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> object = self . nextResponder ( object ) <TAB> print ( "" Could not find an owning view controller "" )",if self . isViewController ( object ) :,if fb . evaluateExpressionValue ( object ) :,96.78412998238339,97.51,False
1318,"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB><TAB> if idx == num : <TAB><TAB><TAB> return element <TAB><TAB> if element [ 3 ] and element [ 4 ] : <TAB><TAB><TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return i <TAB><TAB><TAB> idx = i <TAB><TAB> else : <TAB><TAB><TAB> idx + = 1 <TAB> return idx","if not isinstance ( i , int ) :",if i :,70.67063541603183,95.29,False
1319,"def promtool ( * * kwargs ) : <TAB> key = "" prometheus:promtool "" <TAB> try : <TAB><TAB> path = pathlib . Path ( util . setting ( key ) ) <TAB> except TypeError : <TAB><TAB> yield checks . Warning ( <TAB><TAB><TAB> "" Missing setting for  %s  in  %s   "" % ( key , settings . PROMGEN_CONFIG_FILE ) , <TAB><TAB><TAB> id = "" promgen.W001 "" , <TAB><TAB> ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield checks . Warning ( "" Unable to execute file  %s "" % path , id = "" promgen.W003 "" )","if not os . access ( path , os . X_OK ) :",if not os . path . exists ( path ) :,67.43963793512484,94.47,False
1320,"def parse_config ( schema , config ) : <TAB> schemaparser = ConfigParser ( ) <TAB> schemaparser . readfp ( StringIO ( schema ) ) <TAB> cfgparser = ConfigParser ( ) <TAB> cfgparser . readfp ( StringIO ( config ) ) <TAB> result = { } <TAB> for section in cfgparser . sections ( ) : <TAB><TAB> result_section = { } <TAB><TAB> schema = { } <TAB><TAB> <MASK> <TAB><TAB><TAB> schema = dict ( schemaparser . items ( section ) ) <TAB><TAB> for key , value in cfgparser . items ( section ) : <TAB><TAB><TAB> converter = converters [ schema . get ( key , "" string "" ) ] <TAB><TAB><TAB> result_section [ key ] = converter ( value ) <TAB><TAB> result [ section ] = result_section <TAB> return result",if section in schemaparser . sections ( ) :,"if section . startswith ( ""schema"" ) :",73.80886170330638,96.60,False
1321,"def validate_arguments ( args ) : <TAB> if args . num_pss < 1 : <TAB><TAB> print ( "" Value error: must have ore than one parameter servers. "" ) <TAB><TAB> exit ( 1 ) <TAB> if not GPU_IDS : <TAB><TAB> num_cpus = multiprocessing . cpu_count ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" Value error: there are  %s  available CPUs but you are requiring  %s . "" <TAB><TAB><TAB><TAB> % ( num_cpus , args . cpu_trainers ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> exit ( 1 ) <TAB> if not os . path . isfile ( args . file ) : <TAB><TAB> print ( "" Value error: model trainning file does not exist "" ) <TAB><TAB> exit ( 1 )",if args . cpu_trainers > num_cpus :,if num_cpus > args . cpu_trainers :,69.89554992953583,97.67,False
1322,"def infer_dataset_impl ( path ) : <TAB> if IndexedRawTextDataset . exists ( path ) : <TAB><TAB> return "" raw "" <TAB> elif IndexedDataset . exists ( path ) : <TAB><TAB> with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB><TAB><TAB> magic = f . read ( 8 ) <TAB><TAB><TAB> if magic == IndexedDataset . _HDR_MAGIC : <TAB><TAB><TAB><TAB> return "" cached "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return "" mmap "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return None <TAB> elif FastaDataset . exists ( path ) : <TAB><TAB> return "" fasta "" <TAB> else : <TAB><TAB> return None",elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,elif magic == IndexedDataset . _MAGIC_MAGIC :,93.37291688385284,94.50,False
1323,"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB><TAB> for array_item in obj : <TAB><TAB><TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB><TAB> try : <TAB><TAB><TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB> except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB> pass <TAB><TAB> for item_key in obj : <TAB><TAB><TAB> if item_key != "" sourceVault "" : <TAB><TAB><TAB><TAB> _add_resource_group ( obj [ item_key ] )","if obj [ ""id"" ] :","if ""resource-group"" not in obj :",96.92900673183671,97.24,False
1324,"def reformatBody ( self , event = None ) : <TAB> """"""Reformat all paragraphs in the body."""""" <TAB> c , p = self , self . p <TAB> undoType = "" reformat-body "" <TAB> w = c . frame . body . wrapper <TAB> c . undoer . beforeChangeGroup ( p , undoType ) <TAB> w . setInsertPoint ( 0 ) <TAB> while 1 : <TAB><TAB> progress = w . getInsertPoint ( ) <TAB><TAB> c . reformatParagraph ( event , undoType = undoType ) <TAB><TAB> ins = w . getInsertPoint ( ) <TAB><TAB> s = w . getAllText ( ) <TAB><TAB> w . setInsertPoint ( ins ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> c . undoer . afterChangeGroup ( p , undoType )",if ins <= progress or ins >= len ( s ) :,"if s == """" :",66.6552200664567,93.39,False
1325,"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB><TAB> content . append ( project . readme . path . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB><TAB> if ( path / fname ) . exists ( ) : <TAB><TAB><TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB><TAB> for fpath in package : <TAB><TAB><TAB> fpath = fpath . relative_to ( project . package . path ) <TAB><TAB><TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content )","if project . readme . markup != ""rst"" :",if project . readme . to_rst ( ) . path :,90.8198194755651,96.62,False
1326,"def __init__ ( self , response ) : <TAB> error = "" {}   {} "" . format ( response . status_code , response . reason ) <TAB> extra = [ ] <TAB> try : <TAB><TAB> response_json = response . json ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> error = ""   "" . join ( error [ "" message "" ] for error in response_json [ "" error_list "" ] ) <TAB><TAB><TAB> extra = [ <TAB><TAB><TAB><TAB> error [ "" extra "" ] <TAB><TAB><TAB><TAB> for error in response_json [ "" error_list "" ] <TAB><TAB><TAB><TAB> if "" extra "" in error <TAB><TAB><TAB> ] <TAB> except JSONDecodeError : <TAB><TAB> pass <TAB> super ( ) . __init__ ( response = response , error = error , extra = extra )","if ""error_list"" in response_json :","if ""error_list"" in response_json :",100.0,100.00,True
1327,"def handle_event ( self , fileno = None , events = None ) : <TAB> if self . _state == RUN : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _it = self . _process_result ( 0 ) # non-blocking <TAB><TAB> try : <TAB><TAB><TAB> next ( self . _it ) <TAB><TAB> except ( StopIteration , CoroStop ) : <TAB><TAB><TAB> self . _it = None",if self . _it is None :,if self . _it is None :,100.0,100.00,True
1328,"def find_query ( self , needle , haystack ) : <TAB> try : <TAB><TAB> import pinyin <TAB><TAB> haystack_py = pinyin . get_initial ( haystack , "" "" ) <TAB><TAB> needle_len = len ( needle ) <TAB><TAB> start = 0 <TAB><TAB> result = [ ] <TAB><TAB> while True : <TAB><TAB><TAB> found = haystack_py . find ( needle , start ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> result . append ( ( found , needle_len ) ) <TAB><TAB><TAB> start = found + needle_len <TAB><TAB> return result <TAB> except : <TAB><TAB> return None",if found < 0 :,if found == - 1 :,68.85789198569736,97.17,False
1329,"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB><TAB> try : <TAB><TAB><TAB> result = date <TAB><TAB><TAB> if callable ( result ) : <TAB><TAB><TAB><TAB> result = result ( rv ) <TAB><TAB><TAB> if not isinstance ( result , basestring ) : <TAB><TAB><TAB><TAB> from werkzeug . http import http_date <TAB><TAB><TAB><TAB> result = http_date ( result ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> rv . headers [ "" Last-Modified "" ] = result <TAB><TAB> except Exception : <TAB><TAB><TAB> logging . getLogger ( __name__ ) . exception ( <TAB><TAB><TAB><TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB><TAB><TAB><TAB><TAB> rv <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return rv",if result :,"if result > rv . headers [ ""Last-Modified"" ] :",70.56729421764315,96.46,False
1330,"def check_require ( require_modules , require_lines ) : <TAB> for require_module in require_modules : <TAB><TAB> st = try_import ( require_module ) <TAB><TAB> if st == 0 : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" installed  {} :  {} \n "" . format ( <TAB><TAB><TAB><TAB><TAB> require_module , require_lines [ require_module ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> elif st == 2 : <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" failed installed  {} :  {} \n "" . format ( <TAB><TAB><TAB><TAB><TAB> require_module , require_lines [ require_module ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",elif st == 1 :,elif st == 1 :,100.0,100.00,True
1331,"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB><TAB> nm = _u ( nm ) <TAB><TAB> if nm . startswith ( "" . "" ) : <TAB><TAB><TAB> continue <TAB><TAB> itempath = os . path . join ( dirpath , nm ) <TAB><TAB> if os . path . isdir ( itempath ) : <TAB><TAB><TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB><TAB><TAB><TAB> self . bundle_package ( itempath ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . bundle_module ( itempath )","elif nm . endswith ( "".py"" ) :","elif os . path . exists ( os . path . join ( itempath , ""__init",67.73291057851331,91.75,False
1332,"def _find_root ( ) : <TAB> test_dirs = [ "" Src "" , "" Build "" , "" Package "" , "" Tests "" , "" Util "" ] <TAB> root = os . getcwd ( ) <TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> while not test : <TAB><TAB> last_root = root <TAB><TAB> root = os . path . dirname ( root ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Root not found "" ) <TAB><TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> return root",if root == last_root :,if root == last_root :,100.0,100.00,True
1333,"def findMarkForUnitTestNodes ( self ) : <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB><TAB> if p . v in seen : <TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB> else : <TAB><TAB><TAB> seen . append ( p . v ) <TAB><TAB><TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB><TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result . append ( p . copy ( ) ) <TAB><TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> p . moveToThreadNext ( ) <TAB> return result","elif p . h . startswith ( ""@mark-for-unit-tests"" ) :","elif g . match_word ( p . h , 0 , ""@mark-for-",92.53966839102148,94.56,False
1334,"def startTagFrameset ( self , token ) : <TAB> self . parser . parseError ( "" unexpected-start-tag "" , { "" name "" : "" frameset "" } ) <TAB> if len ( self . tree . openElements ) == 1 or self . tree . openElements [ 1 ] . name != "" body "" : <TAB><TAB> assert self . parser . innerHTML <TAB> elif not self . parser . framesetOK : <TAB><TAB> pass <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . tree . openElements [ 1 ] . parent . removeChild ( self . tree . openElements [ 1 ] ) <TAB><TAB> while self . tree . openElements [ - 1 ] . name != "" html "" : <TAB><TAB><TAB> self . tree . openElements . pop ( ) <TAB><TAB> self . tree . insertElement ( token ) <TAB><TAB> self . parser . phase = self . parser . phases [ "" inFrameset "" ]",if self . tree . openElements [ 1 ] . parent :,if self . tree . openElements [ 1 ] . parent :,100.0,100.00,True
1335,"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> val = int ( i , 2 ) <TAB><TAB> if val > 255 or val < 0 : <TAB><TAB><TAB> return None <TAB><TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB><TAB> ret = bytes ( ret ) <TAB><TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB><TAB> return ret",if len ( i ) == 0 :,"if i == """" :",93.02685296897316,95.59,False
1336,"def generator ( self , data ) : <TAB> for sock in data : <TAB><TAB> <MASK> <TAB><TAB><TAB> offset = sock . obj_offset <TAB><TAB> else : <TAB><TAB><TAB> offset = sock . obj_vm . vtop ( sock . obj_offset ) <TAB><TAB> yield ( <TAB><TAB><TAB> 0 , <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> Address ( offset ) , <TAB><TAB><TAB><TAB> int ( sock . Pid ) , <TAB><TAB><TAB><TAB> int ( sock . LocalPort ) , <TAB><TAB><TAB><TAB> int ( sock . Protocol ) , <TAB><TAB><TAB><TAB> str ( protos . protos . get ( sock . Protocol . v ( ) , "" - "" ) ) , <TAB><TAB><TAB><TAB> str ( sock . LocalIpAddress ) , <TAB><TAB><TAB><TAB> str ( sock . CreateTime ) , <TAB><TAB><TAB> ] , <TAB><TAB> )",if not self . _config . PHYSICAL_OFFSET :,if sock . obj_vm is None :,90.96976148577953,96.34,False
1337,"def __init__ ( self , num_bits = 4 , always_apply = False , p = 0.5 ) : <TAB> super ( Posterize , self ) . __init__ ( always_apply , p ) <TAB> if isinstance ( num_bits , ( list , tuple ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . num_bits = [ to_tuple ( i , 0 ) for i in num_bits ] <TAB><TAB> else : <TAB><TAB><TAB> self . num_bits = to_tuple ( num_bits , 0 ) <TAB> else : <TAB><TAB> self . num_bits = to_tuple ( num_bits , num_bits )",if len ( num_bits ) == 3 :,if len ( num_bits ) == 1 :,98.72281368343,98.55,False
1338,"def tearDown ( self ) : <TAB> """"""Just in case yn00 creates some junk files, do a clean-up."""""" <TAB> del_files = [ self . out_file , "" 2YN.dN "" , "" 2YN.dS "" , "" 2YN.t "" , "" rst "" , "" rst1 "" , "" rub "" ] <TAB> for filename in del_files : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . remove ( filename ) <TAB> if os . path . exists ( self . working_dir ) : <TAB><TAB> for filename in os . listdir ( self . working_dir ) : <TAB><TAB><TAB> filepath = os . path . join ( self . working_dir , filename ) <TAB><TAB><TAB> os . remove ( filepath ) <TAB><TAB> os . rmdir ( self . working_dir )",if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,100.0,100.00,True
1339,"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB> if startpos is None : <TAB><TAB> startpos = self . history_cursor <TAB> if _ignore_leading_spaces : <TAB><TAB> res = [ <TAB><TAB><TAB> ( idx , line . lstrip ( ) ) <TAB><TAB><TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB> else : <TAB><TAB> res = [ <TAB><TAB><TAB> ( idx , line ) <TAB><TAB><TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB> if line . startswith ( searchfor ) <TAB><TAB> ] <TAB> if res : <TAB><TAB> self . history_cursor - = res [ 0 ] [ 0 ] <TAB><TAB> return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB> return "" """,if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),if line . startswith ( searchfor ),86.97673740815648,96.11,False
1340,"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB><TAB> if not win . ref : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) : <TAB><TAB><TAB> bugs . append ( <TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB><TAB> win , <TAB><TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB><TAB><TAB> { } , <TAB><TAB><TAB><TAB><TAB> testname , <TAB><TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return bugs","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",if not win . ref . DroppedRect ( ) :,64.33398596376219,92.49,False
1341,"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB><TAB> result = self . _get_node_text ( self . ast ) <TAB><TAB> if result == self . source : <TAB><TAB><TAB> return None <TAB><TAB> return result <TAB> else : <TAB><TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB> last_end = - 1 <TAB><TAB> for match in self . matches : <TAB><TAB><TAB> start , end = match . get_region ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not self . _is_expression ( ) : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> last_end = end <TAB><TAB><TAB> replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB> collector . add_change ( start , end , replacement ) <TAB><TAB> return collector . get_changed ( )",if start < last_end :,if start != last_end :,98.9885957057996,98.68,False
1342,"def unpickle_from_file ( file_path , gzip = False ) : <TAB> """"""Unpickle obj from file_path with gzipping."""""" <TAB> with tf . io . gfile . GFile ( file_path , "" rb "" ) as f : <TAB><TAB> <MASK> <TAB><TAB><TAB> obj = pickle . load ( f ) <TAB><TAB> else : <TAB><TAB><TAB> with gzip_lib . GzipFile ( fileobj = f , compresslevel = 2 ) as gzipf : <TAB><TAB><TAB><TAB> obj = pickle . load ( gzipf ) <TAB> return obj",if not gzip :,if gzip :,84.4251103360401,98.24,False
1343,"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB><TAB> user = getattr ( request , "" user "" , None ) <TAB><TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB><TAB> if user and user . is_authenticated ( ) : <TAB><TAB><TAB> result . update ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" email "" : user . email , <TAB><TAB><TAB><TAB><TAB> "" id "" : user . id , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ "" name "" ] = user . name <TAB> else : <TAB><TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) )",if user . name :,if escape :,78.12213958662998,98.17,False
1344,"def get_item_address ( self , item ) : <TAB> """"""Get an item's address as a collection of names"""""" <TAB> result = [ ] <TAB> while True : <TAB><TAB> name = self . tree_ctrl . GetItemPyData ( item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> result . insert ( 0 , name ) <TAB><TAB><TAB> item = self . tree_ctrl . GetItemParent ( item ) <TAB> return result",if name is None :,if not name :,73.0210515190274,96.76,False
1345,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB><TAB> for col in range ( self . width ) : <TAB><TAB><TAB> if filter is None or ( row , col ) not in filter : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB> if dist < min_dist : <TAB><TAB><TAB><TAB><TAB><TAB> min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen",if self . map [ row ] [ col ] == UNSEEN :,if self . distance is not None :,95.64668385699974,94.97,False
1346,"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB><TAB> <MASK> <TAB><TAB><TAB> input_array = model . example_input_array <TAB><TAB> if input_array is not None : <TAB><TAB><TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB><TAB><TAB> self . experiment . add_graph ( model , input_array ) <TAB><TAB> else : <TAB><TAB><TAB> rank_zero_warn ( <TAB><TAB><TAB><TAB> "" Could not log computational graph since the "" <TAB><TAB><TAB><TAB> ""  `model.example_input_array` attribute is not set "" <TAB><TAB><TAB><TAB> ""  or `input_array` was not given "" , <TAB><TAB><TAB><TAB> UserWarning , <TAB><TAB><TAB> )",if input_array is None :,if input_array is None :,100.0,100.00,True
1347,"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB><TAB> if not len ( scene_exception ) == 2 : <TAB><TAB><TAB> continue <TAB><TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions",if season == scene_season :,if scene_season == season :,77.53780094193341,97.12,False
1348,def _clean_temp_files ( ) : <TAB> for pattern in _temp_files : <TAB><TAB> for path in glob . glob ( pattern ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . remove ( path ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> shutil . rmtree ( path ),if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . exists ( path ) :,62.40978045375897,89.36,False
1349,"def wait_for_completion ( self , job_id , offset , max_results , start_time , timeout ) : <TAB> """"""Wait for job completion and return the first page."""""" <TAB> while True : <TAB><TAB> result = self . get_query_results ( <TAB><TAB><TAB> job_id = job_id , page_token = None , start_index = offset , max_results = max_results <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return result <TAB><TAB> if ( time . time ( ) - start_time ) > timeout : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Timeout: the query doesn ' t finish within  %d  seconds. "" % timeout <TAB><TAB><TAB> ) <TAB><TAB> time . sleep ( 1 )","if result [ ""jobComplete"" ] :",if result :,67.7497757228833,97.00,False
1350,"def get_data ( self , element , ranges , style ) : <TAB> <MASK> <TAB><TAB> groups = element . groupby ( element . kdims ) . items ( ) <TAB> else : <TAB><TAB> groups = [ ( element . label , element ) ] <TAB> plots = [ ] <TAB> axis = "" x "" if self . invert_axes else "" y "" <TAB> for key , group in groups : <TAB><TAB> <MASK> <TAB><TAB><TAB> label = "" , "" . join ( [ d . pprint_value ( v ) for d , v in zip ( element . kdims , key ) ] ) <TAB><TAB> else : <TAB><TAB><TAB> label = key <TAB><TAB> data = { axis : group . dimension_values ( group . vdims [ 0 ] ) , "" name "" : label } <TAB><TAB> plots . append ( data ) <TAB> return plots",if element . kdims :,if self . invert_axes :,89.83773326525136,94.34,False
1351,"def get_files ( self , dirname ) : <TAB> if not self . _data . has_key ( dirname ) : <TAB><TAB> self . _create ( dirname ) <TAB> else : <TAB><TAB> new_time = self . _changed ( dirname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _update ( dirname , new_time ) <TAB><TAB><TAB> dcLog . debug ( "" ==>  "" + "" \t \n "" . join ( self . _data [ dirname ] [ "" flist "" ] ) ) <TAB> return self . _data [ dirname ] [ "" flist "" ]",if new_time :,if new_time is not None :,69.83396226441293,97.04,False
1352,"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . module_names . add ( name [ : - 3 ] ) <TAB><TAB> elif "" . "" not in name : <TAB><TAB><TAB> self . module_names . add ( name )","if name . endswith ( "".py"" ) :","if name . endswith ( "".py"" ) :",100.0,100.00,True
1353,"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB><TAB> yield clock . posedge , reset . negedge <TAB><TAB> <MASK> <TAB><TAB><TAB> count . next = 0 <TAB><TAB> else : <TAB><TAB><TAB> if enable : <TAB><TAB><TAB><TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation",if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,100.0,100.00,True
1354,"def sortkeypicker ( keynames ) : <TAB> negate = set ( ) <TAB> for i , k in enumerate ( keynames ) : <TAB><TAB> if k [ : 1 ] == "" - "" : <TAB><TAB><TAB> keynames [ i ] = k [ 1 : ] <TAB><TAB><TAB> negate . add ( k [ 1 : ] ) <TAB> def getit ( adict ) : <TAB><TAB> composite = [ adict [ k ] for k in keynames ] <TAB><TAB> for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> composite [ i ] = - v <TAB><TAB> return composite <TAB> return getit",if k in negate :,if k not in negate :,99.13167161372832,98.61,False
1355,"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . named_windows [ wnd_name ] = 1 <TAB><TAB><TAB> self . on_create_window ( wnd_name ) <TAB><TAB><TAB> if wnd_name in self . capture_mouse_windows : <TAB><TAB><TAB><TAB> self . capture_mouse ( wnd_name ) <TAB><TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB><TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" )",if self . named_windows [ wnd_name ] == 0 :,if not self . named_windows [ wnd_name ] :,85.91881192149862,96.77,False
1356,"def check_action_permitted ( self ) : <TAB> if ( <TAB><TAB> self . _action == "" sts:GetCallerIdentity "" <TAB> ) : # always allowed, even if there's an explicit Deny for it <TAB><TAB> return True <TAB> policies = self . _access_key . collect_policies ( ) <TAB> permitted = False <TAB> for policy in policies : <TAB><TAB> iam_policy = IAMPolicy ( policy ) <TAB><TAB> permission_result = iam_policy . is_action_permitted ( self . _action ) <TAB><TAB> if permission_result == PermissionResult . DENIED : <TAB><TAB><TAB> self . _raise_access_denied ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> permitted = True <TAB> if not permitted : <TAB><TAB> self . _raise_access_denied ( )",elif permission_result == PermissionResult . PERMITTED :,elif permission_result == PermissionResult . NOT_DENIED :,98.84793143742033,97.89,False
1357,"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB> # auto handle datetime <TAB><TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB> if config [ key ] [ "" inverse "" ] is True : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) - limit <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if ( datetime . now ( ) + limit ) < value : <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) + limit <TAB><TAB> elif value > limit : <TAB><TAB><TAB> value = limit <TAB> return value",if ( datetime . now ( ) - limit ) > value :,if ( datetime . now ( ) - limit ) > value :,100.0,100.00,True
1358,"def replace_dataset_ids ( path , key , value ) : <TAB> """"""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job."""""" <TAB> current_case = input_values <TAB> if key == "" id "" : <TAB><TAB> for i , p in enumerate ( path ) : <TAB><TAB><TAB> if isinstance ( current_case , ( list , dict ) ) : <TAB><TAB><TAB><TAB> current_case = current_case [ p ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return key , translate_values . get ( current_case [ "" id "" ] , value ) <TAB> return key , value","if src == current_case . get ( ""src"" ) :","if current_case [ ""id"" ] :",85.98211138907364,93.22,False
1359,"def load_ext ( name , funcs ) : <TAB> ExtModule = namedtuple ( "" ExtModule "" , funcs ) <TAB> ext_list = [ ] <TAB> lib_root = os . path . dirname ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) <TAB> for fun in funcs : <TAB><TAB> <MASK> <TAB><TAB><TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op ) <TAB><TAB> else : <TAB><TAB><TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op_ ) <TAB> return ExtModule ( * ext_list )","if fun in [ ""nms"" , ""softnms"" ] :","if name in ( ""py3"" , ""py3"" , ""py3"" ,",66.46818389885823,92.12,False
1360,"def execute_action ( self ) : <TAB> selected_actions = self . model_action . get_selected_results_with_index ( ) <TAB> if selected_actions and self . args_for_action : <TAB><TAB> for name , _ , act_idx in selected_actions : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> action = self . actions [ act_idx ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> action . act ( [ arg for arg , _ , _ in self . args_for_action ] , self ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> debug . log ( "" execute_action "" , e )",if action :,if action . act :,79.47890380777606,98.18,False
1361,"def __getattr__ ( self , attr ) : <TAB> proxy = self . __proxy <TAB> if proxy and hasattr ( proxy , attr ) : <TAB><TAB> return getattr ( proxy , attr ) <TAB> attrmap = self . __attrmap <TAB> if attr in attrmap : <TAB><TAB> source = attrmap [ attr ] <TAB><TAB> <MASK> <TAB><TAB><TAB> value = source ( ) <TAB><TAB> else : <TAB><TAB><TAB> value = _import_object ( source ) <TAB><TAB> setattr ( self , attr , value ) <TAB><TAB> self . __log . debug ( "" loaded lazy attr  %r :  %r "" , attr , value ) <TAB><TAB> return value <TAB> raise AttributeError ( "" ' module '  object has no attribute  ' %s ' "" % ( attr , ) )",if callable ( source ) :,if callable ( source ) :,100.0,100.00,True
1362,"def forward ( self , x ) : <TAB> # BxT -> BxCxT <TAB> x = x . unsqueeze ( 1 ) <TAB> for conv in self . conv_layers : <TAB><TAB> residual = x <TAB><TAB> x = conv ( x ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tsz = x . size ( 2 ) <TAB><TAB><TAB> r_tsz = residual . size ( 2 ) <TAB><TAB><TAB> residual = residual [ . . . , : : r_tsz / / tsz ] [ . . . , : tsz ] <TAB><TAB><TAB> x = ( x + residual ) * self . residual_scale <TAB> if self . log_compression : <TAB><TAB> x = x . abs ( ) <TAB><TAB> x = x + 1 <TAB><TAB> x = x . log ( ) <TAB> return x",if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,if self . use_tsz :,69.15363984078266,91.48,False
1363,"def __Prefix_Step2a ( self , token ) : <TAB> for prefix in self . __prefix_step2a : <TAB><TAB> <MASK> <TAB><TAB><TAB> token = token [ len ( prefix ) : ] <TAB><TAB><TAB> self . prefix_step2a_success = True <TAB><TAB><TAB> break <TAB> return token",if token . startswith ( prefix ) and len ( token ) > 5 :,if token . startswith ( prefix ) :,85.08023912622997,91.12,False
1364,"def is_valid ( sample ) : <TAB> if sample is None : <TAB><TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB><TAB> for s in sample : <TAB><TAB><TAB> if s is None : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB> return True","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :","elif isinstance ( s , ( list , tuple ) ) and s . size != 0 :",64.48125816616138,92.64,False
1365,"def get_all_comments ( self , gallery_id , post_no , comment_cnt ) : <TAB> comment_page_cnt = ( comment_cnt - 1 ) / / self . options . comments_per_page + 1 <TAB> comments = [ ] <TAB> headers = { "" X-Requested-With "" : "" XMLHttpRequest "" } <TAB> data = { "" ci_t "" : self . _session . cookies [ "" ci_c "" ] , "" id "" : gallery_id , "" no "" : post_no } <TAB> for i in range ( comment_page_cnt ) : <TAB><TAB> data [ "" comment_page "" ] = i + 1 <TAB><TAB> response = self . request_comment ( headers , data ) <TAB><TAB> batch = self . parse_comments ( response . text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> comments = batch + comments <TAB> return comments",if not batch :,if len ( batch ) == 0 :,70.2131200288875,96.29,False
1366,def run_on_module ( self ) : <TAB> try : <TAB><TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> if e . no_match_group_specs or e . error_group_specs : <TAB><TAB><TAB><TAB> raise e <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> e . module_depsolv_errors <TAB><TAB><TAB><TAB> and e . module_depsolv_errors [ 1 ] <TAB><TAB><TAB><TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> raise e <TAB><TAB> logger . error ( str ( e ) ),if self . base . conf . strict :,if self . opts . module_spec :,70.44213629632097,97.21,False
1367,"def find_field_notnull_differ ( self , meta , table_description , table_name ) : <TAB> if not self . can_detect_notnull_differ : <TAB><TAB> return <TAB> for field in all_local_fields ( meta ) : <TAB><TAB> attname = field . db_column or field . attname <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> null = self . get_field_db_nullable ( field , table_name ) <TAB><TAB> if field . null != null : <TAB><TAB><TAB> action = field . null and "" DROP "" or "" SET "" <TAB><TAB><TAB> self . add_difference ( "" notnull-differ "" , table_name , attname , action )","if ( table_name , attname ) in self . new_db_fields :",if attname in self . get_field_names ( field ) :,90.28164558065029,92.89,False
1368,"def _change_moving_module ( self , changes , dest ) : <TAB> if not self . source . is_folder ( ) : <TAB><TAB> pymodule = self . pycore . resource_to_pyobject ( self . source ) <TAB><TAB> source = self . import_tools . relatives_to_absolutes ( pymodule ) <TAB><TAB> pymodule = self . tools . new_pymodule ( pymodule , source ) <TAB><TAB> source = self . _change_occurrences_in_module ( dest , pymodule ) <TAB><TAB> source = self . tools . new_source ( pymodule , source ) <TAB><TAB> <MASK> <TAB><TAB><TAB> changes . add_change ( ChangeContents ( self . source , source ) )",if source != self . source . read ( ) :,if source != self . source :,68.20868495601016,96.89,False
1369,"def get ( quality_name ) : <TAB> """"""Returns a quality object based on canonical quality name."""""" <TAB> found_components = { } <TAB> for part in quality_name . lower ( ) . split ( ) : <TAB><TAB> component = _registry . get ( part ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" ` %s ` is not a valid quality string "" % part ) <TAB><TAB> if component . type in found_components : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" ` %s ` cannot be defined twice in a quality "" % component . type <TAB><TAB><TAB> ) <TAB><TAB> found_components [ component . type ] = component <TAB> if not found_components : <TAB><TAB> raise ValueError ( "" No quality specified "" ) <TAB> result = Quality ( ) <TAB> for type , component in found_components . items ( ) : <TAB><TAB> setattr ( result , type , component ) <TAB> return result",if not component :,if not component :,100.0,100.00,True
1370,def _unselected ( self ) : <TAB> selected = self . _selected <TAB> k = 0 <TAB> z = selected [ k ] <TAB> k + = 1 <TAB> for i in range ( self . _n ) : <TAB><TAB> if i == z : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> z = selected [ k ] <TAB><TAB><TAB><TAB> k + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> z = - 1 <TAB><TAB> else : <TAB><TAB><TAB> yield i,if k < len ( selected ) :,if selected [ k ] :,65.8345437159552,95.60,False
1371,"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB><TAB> parts = [ <TAB><TAB><TAB> b "" Content-Disposition: form-data;  "" , <TAB><TAB><TAB> format_form_param ( "" name "" , self . name ) , <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB><TAB><TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB><TAB> if self . content_type is not None : <TAB><TAB><TAB> content_type = self . content_type . encode ( ) <TAB><TAB><TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB><TAB> parts . append ( b "" \r \n \r \n "" ) <TAB><TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers",if self . filename :,if self . filename is not None :,97.65035240065248,98.26,False
1372,"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB><TAB> if not hasattr ( request , "" app "" ) : <TAB><TAB><TAB> request . app = None <TAB><TAB><TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> auth_prefix , auth_token = auth <TAB><TAB><TAB><TAB> if auth_prefix . lower ( ) == prefix : <TAB><TAB><TAB><TAB><TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs )",if len ( auth ) == 2 :,if len ( auth ) == 2 :,100.0,100.00,True
1373,"def _shortest_hypernym_paths ( self , simulate_root ) : <TAB> if self . offset == "" 00000000 "" : <TAB><TAB> return { self : 0 } <TAB> queue = deque ( [ ( self , 0 ) ] ) <TAB> path = { } <TAB> while queue : <TAB><TAB> s , depth = queue . popleft ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> path [ s ] = depth <TAB><TAB> depth + = 1 <TAB><TAB> queue . extend ( ( hyp , depth ) for hyp in s . _hypernyms ( ) ) <TAB> if simulate_root : <TAB><TAB> root = Synset ( self . _wordnet_corpus_reader , None , self . pos ( ) , "" 00000000 "" , "" "" ) <TAB><TAB> path [ root ] = max ( path . values ( ) ) + 1 <TAB> return path",if s in path :,if s in path :,100.0,100.00,True
1374,"def _populate_class_variables ( ) : <TAB> lookup = { } <TAB> reverse_lookup = { } <TAB> characters_for_re = [ ] <TAB> for codepoint , name in list ( codepoint2name . items ( ) ) : <TAB><TAB> character = chr ( codepoint ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # There's no point in turning the quotation mark into <TAB><TAB><TAB> # &quot;, unless it happens within an attribute value, which <TAB><TAB><TAB> # is handled elsewhere. <TAB><TAB><TAB> characters_for_re . append ( character ) <TAB><TAB><TAB> lookup [ character ] = name <TAB><TAB> # But we do want to turn &quot; into the quotation mark. <TAB><TAB> reverse_lookup [ name ] = character <TAB> re_definition = "" [ %s ] "" % "" "" . join ( characters_for_re ) <TAB> return lookup , reverse_lookup , re . compile ( re_definition )",if codepoint != 34 :,"if character not in ( ""&quot;"" , ""&quot;"" ) :",93.43847257452191,94.56,False
1375,"def prepare_data_status ( self , view : sublime . View , data : Dict [ str , Any ] ) - > Any : <TAB> """"""Prepare the returned data for status"""""" <TAB> if ( <TAB><TAB> data [ "" success "" ] <TAB><TAB> and "" No docstring "" not in data [ "" doc "" ] <TAB><TAB> and data [ "" doc "" ] != "" list \n "" <TAB> ) : <TAB><TAB> self . signature = data [ "" doc "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> try : <TAB><TAB><TAB> self . signature = self . signature . splitlines ( ) [ 2 ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> return <TAB><TAB> return self . _show_status ( view )",if self . _signature_excluded ( self . signature ) :,if not self . signature :,69.08412853266277,94.81,False
1376,"def _setup_once_tables ( cls ) : <TAB> if cls . run_define_tables == "" once "" : <TAB><TAB> cls . define_tables ( cls . metadata ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . metadata . create_all ( cls . bind ) <TAB><TAB> cls . tables . update ( cls . metadata . tables )","if cls . run_create_tables == ""once"" :","if cls . run_create_tables == ""once"" :",75.0,100.00,True
1377,"def _send_recursive ( self , files ) : <TAB> for base in files : <TAB><TAB> <MASK> <TAB><TAB><TAB> # filename mixed into the bunch <TAB><TAB><TAB> self . _send_files ( [ base ] ) <TAB><TAB><TAB> continue <TAB><TAB> last_dir = asbytes ( base ) <TAB><TAB> for root , dirs , fls in os . walk ( base ) : <TAB><TAB><TAB> self . _chdir ( last_dir , asbytes ( root ) ) <TAB><TAB><TAB> self . _send_files ( [ os . path . join ( root , f ) for f in fls ] ) <TAB><TAB><TAB> last_dir = asbytes ( root ) <TAB><TAB> # back out of the directory <TAB><TAB> for i in range ( len ( os . path . split ( last_dir ) ) ) : <TAB><TAB><TAB> self . _send_popd ( )",if not os . path . isdir ( base ) :,"if isinstance ( base , str ) :",62.457827389294515,96.37,False
1378,"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> # Automatically register models if required. <TAB> if not is_registered ( self . model ) : <TAB><TAB> inline_fields = ( ) <TAB><TAB> for inline in self . inlines : <TAB><TAB><TAB> inline_model , follow_field = self . _reversion_introspect_inline_admin ( inline ) <TAB><TAB><TAB> if inline_model : <TAB><TAB><TAB><TAB> self . _reversion_autoregister ( inline_model , ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> inline_fields + = ( follow_field , ) <TAB><TAB> self . _reversion_autoregister ( self . model , inline_fields )",if follow_field :,if follow_field :,100.0,100.00,True
1379,"def dispatch_hook ( key , hooks , hook_data , * * kwargs ) : <TAB> """"""Dispatches a hook dictionary on a given piece of data."""""" <TAB> hooks = hooks or dict ( ) <TAB> hooks = hooks . get ( key ) <TAB> if hooks : <TAB><TAB> if hasattr ( hooks , "" __call__ "" ) : <TAB><TAB><TAB> hooks = [ hooks ] <TAB><TAB> for hook in hooks : <TAB><TAB><TAB> _hook_data = hook ( hook_data , * * kwargs ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> hook_data = _hook_data <TAB> return hook_data",if _hook_data is not None :,if _hook_data :,79.09559761833827,97.46,False
1380,"def __call__ ( self , image , crop = True ) : <TAB> if isinstance ( image , PTensor ) : <TAB><TAB> return self . crop_to_output ( <TAB><TAB><TAB> numpy_to_paddle ( self ( paddle_to_numpy ( image ) , crop = False ) ) <TAB><TAB> ) <TAB> else : <TAB><TAB> warp = cv . warpAffine ( <TAB><TAB><TAB> image , <TAB><TAB><TAB> self . transform_matrix , <TAB><TAB><TAB> image . shape [ 1 : : - 1 ] , <TAB><TAB><TAB> borderMode = cv . BORDER_REPLICATE , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . crop_to_output ( warp ) <TAB><TAB> else : <TAB><TAB><TAB> return warp",if crop :,if crop :,100.0,100.00,True
1381,"def _analyze ( self ) : <TAB> lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB> prev_line = None <TAB> for line in lines : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB><TAB> elif line . startswith ( "" FAIL: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB><TAB><TAB> self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB><TAB> prev_line = line","if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :","if line . startswith ( ""ERROR:"" ) and line . startswith ( ""="" ) :",97.14358112805172,95.79,False
1382,"def end ( self , name ) : <TAB> self . soup . endData ( ) <TAB> completed_tag = self . soup . tagStack [ - 1 ] <TAB> namespace , name = self . _getNsTag ( name ) <TAB> nsprefix = None <TAB> if namespace is not None : <TAB><TAB> for inverted_nsmap in reversed ( self . nsmaps ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> nsprefix = inverted_nsmap [ namespace ] <TAB><TAB><TAB><TAB> break <TAB> self . soup . handle_endtag ( name , nsprefix ) <TAB> if len ( self . nsmaps ) > 1 : <TAB><TAB> # This tag, or one of its parents, introduced a namespace <TAB><TAB> # mapping, so pop it off the stack. <TAB><TAB> self . nsmaps . pop ( )",if inverted_nsmap is not None and namespace in inverted_nsmap :,if inverted_nsmap [ namespace ] == completed_tag :,92.53800767962194,95.27,False
1383,"def _bind_parameters ( operation , parameters ) : <TAB> # inspired by MySQL Python Connector (conversion.py) <TAB> string_parameters = { } <TAB> for ( name , value ) in parameters . iteritems ( ) : <TAB><TAB> if value is None : <TAB><TAB><TAB> string_parameters [ name ] = "" NULL "" <TAB><TAB> <MASK> <TAB><TAB><TAB> string_parameters [ name ] = "" ' "" + _escape ( value ) + "" ' "" <TAB><TAB> else : <TAB><TAB><TAB> string_parameters [ name ] = str ( value ) <TAB> return operation % string_parameters","elif isinstance ( value , basestring ) :","elif isinstance ( value , ( int , float ) ) :",72.67152220159241,95.99,False
1384,"def plugin_on_song_ended ( self , song , skipped ) : <TAB> if song is not None : <TAB><TAB> rating = song ( "" ~#rating "" ) <TAB><TAB> invrating = 1.0 - rating <TAB><TAB> delta = min ( rating , invrating ) / 2.0 <TAB><TAB> <MASK> <TAB><TAB><TAB> rating - = delta <TAB><TAB> else : <TAB><TAB><TAB> rating + = delta <TAB><TAB> song [ "" ~#rating "" ] = rating",if skipped :,if skipped :,100.0,100.00,True
1385,"def on_activated_async ( self , view ) : <TAB> if settings [ "" modified_lines_only "" ] : <TAB><TAB> self . freeze_last_version ( view ) <TAB> if settings [ "" enabled "" ] : <TAB><TAB> match_trailing_spaces ( view ) <TAB><TAB> # continuously watch view for changes to the visible region <TAB><TAB> <MASK> <TAB><TAB><TAB> # track <TAB><TAB><TAB> active_views [ view . id ( ) ] = view . visible_region ( ) <TAB><TAB><TAB> self . update_on_region_change ( view )",if not view . id ( ) in active_views :,if view . id ( ) not in active_views :,97.70758336595968,97.62,False
1386,"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( u ( "" -  "" ) ) : <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB><TAB><TAB> newdiff . append ( u ( ""    "" ) + line [ 2 : ] ) <TAB><TAB> else : <TAB><TAB><TAB> newdiff . append ( line ) <TAB> return newdiff","if line . startswith ( u ( ""Skipping"" ) ) :",if not line :,70.43898806830572,94.98,False
1387,"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB><TAB> fn_full = os . path . join ( path , fn ) <TAB><TAB> if os . path . isdir ( fn ) : <TAB><TAB><TAB> delete_all ( fn_full ) <TAB><TAB> elif fn . endswith ( "" .png "" ) : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> elif DELETE_ALL_OLD : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )","elif fn . endswith ( "".md"" ) :","elif fn . endswith ( "".png"" ) :",98.96540516768711,98.80,False
1388,"def reward ( self ) : <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB><TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB><TAB> if ts . raw_reward is not None : <TAB><TAB><TAB> raw_rewards + = ts . raw_reward <TAB><TAB> <MASK> <TAB><TAB><TAB> processed_rewards + = ts . processed_reward <TAB> return raw_rewards , processed_rewards",if ts . processed_reward is not None :,if ts . processed_reward is not None :,100.0,100.00,True
1389,"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB><TAB> s = month_name [ themonth ] <TAB><TAB> <MASK> <TAB><TAB><TAB> s = s . decode ( encoding ) <TAB><TAB> if withyear : <TAB><TAB><TAB> s = "" %s   %s "" % ( s , theyear ) <TAB><TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s",if encoding is not None :,if encoding :,74.05001362258865,96.72,False
1390,"def check_digest_auth ( user , passwd ) : <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB><TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> response_hash = response ( <TAB><TAB><TAB> credentails , <TAB><TAB><TAB> passwd , <TAB><TAB><TAB> dict ( <TAB><TAB><TAB><TAB> uri = request . script_root + request . path , <TAB><TAB><TAB><TAB> body = request . data , <TAB><TAB><TAB><TAB> method = request . method , <TAB><TAB><TAB> ) , <TAB><TAB> ) <TAB><TAB> if credentails . get ( "" response "" ) == response_hash : <TAB><TAB><TAB> return True <TAB> return False",if not credentails :,if not credentails :,100.0,100.00,True
1391,"def wrapped ( self , request ) : <TAB> try : <TAB><TAB> return self . _finished <TAB> except AttributeError : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not request . session . shouldfail and not request . session . shouldstop : <TAB><TAB><TAB><TAB> log . debug ( <TAB><TAB><TAB><TAB><TAB> "" %s  is still going to be used, not terminating it.  "" <TAB><TAB><TAB><TAB><TAB> "" Still in use on: \n %s "" , <TAB><TAB><TAB><TAB><TAB> self , <TAB><TAB><TAB><TAB><TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return <TAB><TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB><TAB> try : <TAB><TAB><TAB> return func ( request ) <TAB><TAB> finally : <TAB><TAB><TAB> self . _finished = True",if self . node_ids :,if self . _finished :,98.97405033059712,98.45,False
1392,"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB><TAB> if case ( 0 ) : <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB> elif case ( 1 , 2 ) : <TAB><TAB><TAB> print ( "" one or two "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" three or four "" ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" default "" ) <TAB><TAB><TAB> print ( "" another "" )","elif case ( 3 , 4 ) :","elif case ( 3 , 4 ) :",75.0,100.00,True
1393,"def task_done ( self ) : <TAB> with self . _cond : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB><TAB> if self . _unfinished_tasks . _semlock . _is_zero ( ) : <TAB><TAB><TAB> self . _cond . notify_all ( )",if not self . _unfinished_tasks . acquire ( False ) :,if self . _unfinished_tasks . _semlock . _is_zero ( ),58.712290098802725,89.02,False
1394,"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB><TAB><TAB> val = None <TAB><TAB> elif isinstance ( val , text_or_bytes ) : <TAB><TAB><TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val",if pwd is None :,if pwd is None :,100.0,100.00,True
1395,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB> if version is not None : # if failed to get version bail <TAB><TAB><TAB> major , minor , _ = version <TAB><TAB><TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB> if arch is not None : <TAB><TAB><TAB><TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> exe , args = exe_data <TAB><TAB><TAB><TAB><TAB> return company , major , minor , arch , exe , args",if exe_data is not None :,if exe_data is not None :,100.0,100.00,True
1396,"def run ( algs ) : <TAB> for alg in algs : <TAB><TAB> vcs = alg . get ( "" variantcaller "" ) <TAB><TAB> if vcs : <TAB><TAB><TAB> if isinstance ( vcs , dict ) : <TAB><TAB><TAB><TAB> vcs = reduce ( operator . add , vcs . values ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> vcs = [ vcs ] <TAB><TAB><TAB> return any ( vc . startswith ( prefix ) for vc in vcs if vc )","if not isinstance ( vcs , ( list , tuple ) ) :","elif not isinstance ( vcs , list ) :",89.49052716599016,93.90,False
1397,"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> uri = self . request . path + "" / "" <TAB><TAB><TAB> if self . request . query : <TAB><TAB><TAB><TAB> uri + = "" ? "" + self . request . query <TAB><TAB><TAB> self . redirect ( uri , permanent = True ) <TAB><TAB><TAB> return <TAB><TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )","if self . request . method in ( ""GET"" , ""HEAD"" ) :","if self . request . method == ""GET"" :",89.46282337005572,93.99,False
1398,"def check_response ( self , response ) : <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response : <TAB><TAB> # Skip blank lines: <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( b "" OK "" ) : <TAB><TAB><TAB> return <TAB><TAB> elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB><TAB><TAB> raise BadLogin ( line ) <TAB><TAB> else : <TAB><TAB><TAB> raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) )",if not line . strip ( ) :,"if line . startswith ( b""No such line"" ) :",96.21136093442577,93.93,False
1399,"def Walk ( self , hMenu = None ) : <TAB> if not hMenu : <TAB><TAB> hMenu = self . handle <TAB> n = user32 . GetMenuItemCount ( hMenu ) <TAB> mi = MENUITEMINFO ( ) <TAB> for i in range ( n ) : <TAB><TAB> mi . fMask = 2 #  MIIM_ID <TAB><TAB> user32 . GetMenuItemInfoA ( hMenu , i , 1 , byref ( mi ) ) <TAB><TAB> handle = user32 . GetSubMenu ( hMenu , i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield handle , self . ListItems ( handle ) <TAB><TAB><TAB> for i in self . Walk ( handle ) : <TAB><TAB><TAB><TAB> yield i",if handle :,if handle :,100.0,100.00,True
1400,"def setSelection ( self , labels ) : <TAB> input = self . __validateInput ( labels ) <TAB> if len ( input ) == 0 and not self . __allowEmptySelection : <TAB><TAB> return <TAB> if self . __allowMultipleSelection : <TAB><TAB> self . __selectedLabels [ : ] = input <TAB><TAB> self . __selectionChanged ( ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" Parameter must be single item or a list with one element. "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . __selectedLabels [ : ] = input <TAB><TAB><TAB> self . __selectionChanged ( ) <TAB> # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB> self . __validateState ( )",if len ( input ) > 1 :,"if not isinstance ( input , ( list , tuple ) ) :",91.47042682193116,95.06,False
1401,"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB><TAB> if "" axis "" in self . args : <TAB><TAB><TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB> if "" momentum "" in self . args : <TAB><TAB><TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if not isinstance ( self . momentum , ( int , float ) ) :","if not isinstance ( self . momentum , str ) :",83.49639989544609,97.02,False
1402,"def get_order ( self , aBuf ) : <TAB> if not aBuf : <TAB><TAB> return - 1 , 1 <TAB> # find out current char's byte length <TAB> first_char = wrap_ord ( aBuf [ 0 ] ) <TAB> if ( 0x81 < = first_char < = 0x9F ) or ( 0xE0 < = first_char < = 0xFC ) : <TAB><TAB> charLen = 2 <TAB> else : <TAB><TAB> charLen = 1 <TAB> # return its order if it is hiragana <TAB> if len ( aBuf ) > 1 : <TAB><TAB> second_char = wrap_ord ( aBuf [ 1 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return second_char - 0x9F , charLen <TAB> return - 1 , charLen",if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,if second_char >= 0x9F :,94.39350936130378,89.91,False
1403,"def saveSpecial ( self , * * kwargs ) : <TAB> for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST : <TAB><TAB> item = config . get_config ( "" misc "" , kw ) <TAB><TAB> value = kwargs . get ( kw ) <TAB><TAB> msg = item . set ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return badParameterResponse ( msg ) <TAB> config . save_config ( ) <TAB> raise Raiser ( self . __root )",if msg :,if not msg :,68.17840202796074,98.01,False
1404,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB> if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB><TAB><TAB> if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB><TAB><TAB><TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB> 1024 <TAB><TAB><TAB><TAB> )",if key not in valid_keys :,if key in valid_keys :,74.00669203551993,98.92,False
1405,"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB><TAB> value <TAB><TAB> if value is not None <TAB><TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if fit . calculated : <TAB><TAB><TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB><TAB><TAB> fit . clearFactorReloadDependentData ( ) <TAB><TAB><TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs",if fit is None :,if not fit . enabled :,77.8633799752122,96.93,False
1406,"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB><TAB> for col in range ( self . width ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . map [ row ] [ col ] == UNSEEN : <TAB><TAB><TAB><TAB><TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB><TAB><TAB><TAB><TAB> if dist < min_dist : <TAB><TAB><TAB><TAB><TAB><TAB> min_dist = dist <TAB><TAB><TAB><TAB><TAB><TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen","if filter is None or ( row , col ) not in filter :",if filter is not None :,95.11624697217657,95.16,False
1407,"def getAlphaClone ( lookfor , eager = None ) : <TAB> if isinstance ( lookfor , int ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> item = get_gamedata_session ( ) . query ( AlphaClone ) . get ( lookfor ) <TAB><TAB> else : <TAB><TAB><TAB> item = ( <TAB><TAB><TAB><TAB> get_gamedata_session ( ) <TAB><TAB><TAB><TAB> . query ( AlphaClone ) <TAB><TAB><TAB><TAB> . options ( * processEager ( eager ) ) <TAB><TAB><TAB><TAB> . filter ( AlphaClone . ID == lookfor ) <TAB><TAB><TAB><TAB> . first ( ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise TypeError ( "" Need integer as argument "" ) <TAB> return item",if eager is None :,if eager is None :,100.0,100.00,True
1408,"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB><TAB> if not cur : <TAB><TAB><TAB> count + = 1 <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB><TAB><TAB><TAB> count = 0 <TAB><TAB><TAB> new + = bytes ( [ cur ] ) <TAB> return new",if count :,if count :,100.0,100.00,True
1409,def result_iterator ( ) : <TAB> try : <TAB><TAB> for future in fs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield future . result ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield future . result ( end_time - time . time ( ) ) <TAB> finally : <TAB><TAB> for future in fs : <TAB><TAB><TAB> future . cancel ( ),if timeout is None :,if end_time is None :,72.84367135650123,96.34,False
1410,"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB><TAB> for key , value in segment . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return value <TAB><TAB><TAB> if hasattr ( key , "" text "" ) : <TAB><TAB><TAB><TAB> if key . text == index [ 0 ] : <TAB><TAB><TAB><TAB><TAB> return value <TAB><TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB><TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB><TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB><TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB><TAB> raise Exception ( "" Invalid state "" )",if key == index [ 0 ] :,if key == index [ 1 ] :,74.16259755852282,99.03,False
1411,"def _reset_sequences ( self , db_name ) : <TAB> conn = connections [ db_name ] <TAB> if conn . features . supports_sequence_reset : <TAB><TAB> sql_list = conn . ops . sequence_reset_by_name_sql ( <TAB><TAB><TAB> no_style ( ) , conn . introspection . sequence_list ( ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> cursor = conn . cursor ( ) <TAB><TAB><TAB><TAB> for sql in sql_list : <TAB><TAB><TAB><TAB><TAB> cursor . execute ( sql ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> transaction . rollback_unless_managed ( using = db_name ) <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> transaction . commit_unless_managed ( using = db_name )",if sql_list :,if sql_list :,100.0,100.00,True
1412,"def translate_to_statements ( self , statements , conditional_write_vars ) : <TAB> lines = [ ] <TAB> for stmt in statements : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . temporary_vars . add ( ( stmt . var , stmt . dtype ) ) <TAB><TAB> line = self . translate_statement ( stmt ) <TAB><TAB> if stmt . var in conditional_write_vars : <TAB><TAB><TAB> subs = { } <TAB><TAB><TAB> condvar = conditional_write_vars [ stmt . var ] <TAB><TAB><TAB> lines . append ( "" if  %s : "" % condvar ) <TAB><TAB><TAB> lines . append ( indent ( line ) ) <TAB><TAB> else : <TAB><TAB><TAB> lines . append ( line ) <TAB> return lines","if stmt . op == "":="" and not stmt . var in self . variables :",if stmt . var not in self . temporary_vars :,89.9502091646136,93.11,False
1413,"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB><TAB> # Since build_py handles package data installation, the <TAB><TAB> # list of outputs can contain more than just .py files. <TAB><TAB> # Make sure we only report bytecode for the .py files. <TAB><TAB> ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB><TAB> if ext != PYTHON_SOURCE_EXTENSION : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> bytecode_files . append ( py_file + "" c "" ) <TAB><TAB> if self . optimize > 0 : <TAB><TAB><TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files",if self . compile :,if self . build_py :,98.95008471535454,97.96,False
1414,"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB><TAB> yield clock . posedge , reset . negedge <TAB><TAB> if reset == ACTIVE_LOW : <TAB><TAB><TAB> count . next = 0 <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation",if enable :,if enable :,100.0,100.00,True
1415,"def _is_subnet_of ( a , b ) : <TAB> try : <TAB><TAB> # Always false if one is v4 and the other is v6. <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( "" %s  and  %s  are not of the same version "" % ( a , b ) ) <TAB><TAB> return ( <TAB><TAB><TAB> b . network_address < = a . network_address <TAB><TAB><TAB> and b . broadcast_address > = a . broadcast_address <TAB><TAB> ) <TAB> except AttributeError : <TAB><TAB> raise TypeError ( <TAB><TAB><TAB> "" Unable to test subnet containment  "" "" between  %s  and  %s "" % ( a , b ) <TAB><TAB> )",if a . _version != b . _version :,if a . version != b . version :,97.71217731327053,97.43,False
1416,"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude : <TAB><TAB> # Items ending in '/' apply only to directories. <TAB><TAB> if item . endswith ( "" / "" ) and not is_dir : <TAB><TAB><TAB> continue <TAB><TAB> # Items starting with '/' apply to the whole path. <TAB><TAB> # In any other cases just the basename is used. <TAB><TAB> match = path if item . startswith ( "" / "" ) else basename <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",if match in path :,93.47800765787697,90.93,False
1417,"def __recv_null ( self ) : <TAB> """"""Receive a null byte."""""" <TAB> while 1 : <TAB><TAB> c = self . sock . recv ( 1 ) <TAB><TAB> if c == "" "" : <TAB><TAB><TAB> self . close ( ) <TAB><TAB><TAB> raise EOFError ( "" Socket Closed "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return","if c == ""\0"" :","if c == ""\0"" :",100.0,100.00,True
1418,"def onMessage ( self , payload , isBinary ) : <TAB> if isBinary : <TAB><TAB> self . result = "" Expected text message with payload, but got binary. "" <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . result = ( <TAB><TAB><TAB><TAB> "" Expected text message with payload of length  %d , but got  %d . "" <TAB><TAB><TAB><TAB> % ( self . DATALEN , len ( payload ) ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> ## FIXME : check actual content <TAB><TAB><TAB> ## <TAB><TAB><TAB> self . behavior = Case . OK <TAB><TAB><TAB> self . result = "" Received text message of length  %d . "" % len ( payload ) <TAB> self . p . createWirelog = True <TAB> self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL )",if len ( payload ) != self . DATALEN :,if self . DATALEN != len ( payload ) :,96.2425121866363,97.63,False
1419,"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB><TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB><TAB> attr = self . getattr ( d_path ) <TAB><TAB> if stat . S_ISDIR ( attr [ "" st_mode "" ] ) : <TAB><TAB><TAB> self . rename_path ( d_path , d_new_path ) <TAB><TAB> else : <TAB><TAB><TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True )","if d in [ ""."" , "".."" ] :",if not d :,67.90117017543828,94.90,False
1420,"def dir_box_click ( self , double ) : <TAB> if double : <TAB><TAB> name = self . list_box . get_selected_name ( ) <TAB><TAB> path = os . path . join ( self . directory , name ) <TAB><TAB> suffix = os . path . splitext ( name ) [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . directory = path <TAB><TAB> else : <TAB><TAB><TAB> self . double_click_file ( name ) <TAB> self . update ( )",if suffix not in self . suffixes and os . path . isdir ( path ) :,"if suffix == "".py"" :",61.589157491194435,89.63,False
1421,"def __getattr__ ( self , key ) : <TAB> try : <TAB><TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB><TAB> pass <TAB> else : <TAB><TAB> if value is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return value . mod_ns <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB><TAB><TAB><TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB><TAB> "" Module  %r  has no mapped classes  "" <TAB><TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> )","if isinstance ( value , _ModuleMarker ) :","if isinstance ( value , _MappedClassMarker ) :",98.85939183320934,98.81,False
1422,"def poll_thread ( ) : <TAB> time . sleep ( 0.5 ) <TAB> if process . wait ( ) and process_state : <TAB><TAB> time . sleep ( 0.25 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> stdout , stderr = process . _communicate ( None ) <TAB><TAB><TAB> logger . error ( <TAB><TAB><TAB><TAB> "" Web server process exited unexpectedly "" , <TAB><TAB><TAB><TAB> "" app "" , <TAB><TAB><TAB><TAB> stdout = stdout , <TAB><TAB><TAB><TAB> stderr = stderr , <TAB><TAB><TAB> ) <TAB><TAB><TAB> time . sleep ( 1 ) <TAB><TAB><TAB> restart_server ( 1 )",if not check_global_interrupt ( ) :,if process . returncode :,90.84758140620382,95.17,False
1423,"def apply_dateparser_timezone ( utc_datetime , offset_or_timezone_abb ) : <TAB> for name , info in _tz_offsets : <TAB><TAB> <MASK> <TAB><TAB><TAB> tz = StaticTzInfo ( name , info [ "" offset "" ] ) <TAB><TAB><TAB> return utc_datetime . astimezone ( tz )","if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :","if info [ ""offset"" ] and info [ ""timezone"" ] == offset_or_",75.64023138085382,82.59,False
1424,"def _load_wordlist ( filename ) : <TAB> if filename is None : <TAB><TAB> return { } <TAB> path = None <TAB> for dir in ( CONFIG_DIR , ASSETS_DIR ) : <TAB><TAB> path = os . path . realpath ( os . path . join ( dir , filename ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> words = { } <TAB> with open ( path , encoding = "" utf-8 "" ) as f : <TAB><TAB> pairs = [ word . strip ( ) . rsplit ( ""   "" , 1 ) for word in f ] <TAB><TAB> pairs . sort ( reverse = True , key = lambda x : int ( x [ 1 ] ) ) <TAB><TAB> words = { p [ 0 ] : int ( p [ 1 ] ) for p in pairs } <TAB> return words",if os . path . exists ( path ) :,if not os . path . exists ( path ) :,96.69804150096954,98.79,False
1425,"def terminate_processes_matching_names ( match_strings , kill = False ) : <TAB> """"""Terminates processes matching particular names (case sensitive)."""""" <TAB> if isinstance ( match_strings , str ) : <TAB><TAB> match_strings = [ match_strings ] <TAB> for process in psutil . process_iter ( ) : <TAB><TAB> try : <TAB><TAB><TAB> process_info = process . as_dict ( attrs = [ "" name "" , "" pid "" ] ) <TAB><TAB><TAB> process_name = process_info [ "" name "" ] <TAB><TAB> except ( psutil . AccessDenied , psutil . NoSuchProcess , OSError ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> terminate_process ( process_info [ "" pid "" ] , kill )",if any ( x == process_name for x in match_strings ) :,if process_name in match_strings :,67.07745300342629,94.08,False
1426,"def has_scheme ( self , inp ) : <TAB> if "" :// "" in inp : <TAB><TAB> return True <TAB> else : <TAB><TAB> authority = inp . replace ( "" / "" , "" # "" ) . replace ( "" ? "" , "" # "" ) . split ( "" # "" ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> _ , host_or_port = authority . split ( "" : "" , 1 ) <TAB><TAB><TAB> # Assert it's not a port number <TAB><TAB><TAB> if re . match ( r "" ^ \ d+$ "" , host_or_port ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> return True","if "":"" in authority :","if "":"" in authority :",100.0,100.00,True
1427,"def close ( self ) : <TAB> with BrowserContext . _BROWSER_LOCK : <TAB><TAB> BrowserContext . _BROWSER_REFCNT - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . info ( "" Destroying browser main loop "" ) <TAB><TAB><TAB> BrowserContext . _BROWSER_LOOP . destroy ( ) <TAB><TAB><TAB> BrowserContext . _BROWSER_LOOP = None",if BrowserContext . _BROWSER_REFCNT == 0 :,if BrowserContext . _BROWSER_REFCNT == 0 :,100.0,100.00,True
1428,"def _mock_get_merge_ticks ( self , order_book_id_list , trading_date , last_dt = None ) : <TAB> for tick in self . _ticks : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if ( <TAB><TAB><TAB> self . env . data_proxy . get_future_trading_date ( tick . datetime ) . date ( ) <TAB><TAB><TAB> != trading_date . date ( ) <TAB><TAB> ) : <TAB><TAB><TAB> continue <TAB><TAB> if last_dt and tick . datetime < = last_dt : <TAB><TAB><TAB> continue <TAB><TAB> yield tick",if tick . order_book_id not in order_book_id_list :,"if not isinstance ( tick , OrderBookIdList ) :",90.71900001594327,90.95,False
1429,"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB><TAB> source = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB> if ss [ "" revision "" ] : <TAB><TAB><TAB> source + = str ( ss [ "" revision "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> source + = "" HEAD "" <TAB><TAB> if ss [ "" patch "" ] is not None : <TAB><TAB><TAB> source + = ""  (plus patch) "" <TAB><TAB> discriminator = "" "" <TAB><TAB> if ss [ "" codebase "" ] : <TAB><TAB><TAB> discriminator = ""   ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""branch"" ] :","if ss [ ""branch"" ] :",100.0,100.00,True
1430,"def test_open_read_bytes ( self , sftp ) : <TAB> """"""Test reading bytes from a file"""""" <TAB> f = None <TAB> try : <TAB><TAB> self . _create_file ( "" file "" , "" xxx "" ) <TAB><TAB> f = yield from sftp . open ( "" file "" , "" rb "" ) <TAB><TAB> self . assertEqual ( ( yield from f . read ( ) ) , b "" xxx "" ) <TAB> finally : <TAB><TAB> <MASK> # pragma: no branch <TAB><TAB><TAB> yield from f . close ( ) <TAB><TAB> remove ( "" file "" )",if f :,if f :,100.0,100.00,True
1431,"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB><TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB><TAB> if verbose == True : <TAB><TAB><TAB> print ( e ) <TAB><TAB> return <TAB> while True : <TAB><TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB><TAB> if sock in r : <TAB><TAB><TAB> data = sock . recv ( 1024 ) <TAB><TAB><TAB> if len ( data ) == 0 : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> chan . send ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data = chan . recv ( 1024 ) <TAB><TAB><TAB> if len ( data ) == 0 : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( )",if chan in r :,if chan in x :,97.40276715980274,99.09,False
1432,"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB><TAB> page , headers , code = get_page ( get = vector ) <TAB><TAB> retval = re . search ( r "" url \ ( ' /ks-waf-error \ .png ' \ ) "" , page , re . I ) is not None <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return retval",if retval :,if retval :,100.0,100.00,True
1433,"def __init__ ( self , raw ) : <TAB> ticker_ticks = { } <TAB> for tick in raw [ "" results "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> ticker_ticks [ tick [ "" T "" ] ] . append ( tick ) <TAB><TAB> else : <TAB><TAB><TAB> ticker_ticks [ tick [ "" T "" ] ] = [ tick ] <TAB> super ( ) . __init__ ( <TAB><TAB> { ticker : Aggsv2 ( { "" results "" : ticks } ) for ticker , ticks in ticker_ticks . items ( ) } <TAB> )","if ticker_ticks . get ( tick [ ""T"" ] ) :","if tick [ ""T"" ] in ticker_ticks :",94.11201866913724,94.63,False
1434,"def _makefiles ( self , f ) : <TAB> if isinstance ( f , dict ) : <TAB><TAB> for k , v in list ( f . items ( ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . makedir ( dirname = k , content = v ) <TAB><TAB><TAB> elif isinstance ( v , str ) : <TAB><TAB><TAB><TAB> self . make_file ( filename = k , content = v ) <TAB><TAB><TAB> else : # pragma: nocover <TAB><TAB><TAB><TAB> raise ValueError ( "" Unexpected: "" , k , v ) <TAB> elif isinstance ( f , str ) : <TAB><TAB> self . _make_empty_file ( f ) <TAB> elif isinstance ( f , list ) : <TAB><TAB> self . make_list ( f ) <TAB> else : # pragma: nocover <TAB><TAB> raise ValueError ( "" Unknown type: "" , f )","if isinstance ( v , list ) :","if isinstance ( v , ( str , unicode ) ) :",73.04429971285519,97.34,False
1435,"def migrate_command_storage ( apps , schema_editor ) : <TAB> model = apps . get_model ( "" terminal "" , "" CommandStorage "" ) <TAB> init_storage_data ( model ) <TAB> setting = get_setting ( apps , schema_editor , "" TERMINAL_COMMAND_STORAGE "" ) <TAB> if not setting : <TAB><TAB> return <TAB> values = get_storage_data ( setting ) <TAB> for name , meta in values . items ( ) : <TAB><TAB> tp = meta . pop ( "" TYPE "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> model . objects . create ( name = name , type = tp , meta = meta )","if not tp or name in [ ""default"" , ""null"" ] :",if tp is None :,64.30676528651257,91.31,False
1436,"def build_vertices ( self , ulines ) : <TAB> vertex_idx = 0 <TAB> vertices = collections . OrderedDict ( ) <TAB> for line in ulines : <TAB><TAB> for vt in line : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_vertex = ( vt . u , vt . v , 0.0 ) <TAB><TAB><TAB> if new_vertex in vertices : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> vt . index = vertex_idx <TAB><TAB><TAB> vertex_idx + = 1 <TAB><TAB><TAB> vertices [ new_vertex ] = 1 <TAB> return vertex_idx , list ( vertices . keys ( ) )",if vt . replacement is not None :,if vt . index != vertex_idx :,93.65140227226888,96.14,False
1437,"def get_quarantine_count ( self ) : <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB><TAB> for qtype in qcounts : <TAB><TAB><TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB><TAB><TAB> if os . path . exists ( qtgt ) : <TAB><TAB><TAB><TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts",if linkcount > 2 :,if linkcount > 2 :,100.0,100.00,True
1438,"def _format_arg ( self , name , trait_spec , value ) : <TAB> if name == "" mask_file "" : <TAB><TAB> return "" "" <TAB> if name == "" op_string "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isdefined ( self . inputs . mask_file ) : <TAB><TAB><TAB><TAB> return self . inputs . op_string % self . inputs . mask_file <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise ValueError ( "" -k  %s  option in op_string requires mask_file "" ) <TAB> return super ( ImageStats , self ) . _format_arg ( name , trait_spec , value )","if ""-k %s"" in self . inputs . op_string :",if self . inputs . op_string :,70.78344836211377,95.93,False
1439,"def _update_theme_style ( self , * args ) : <TAB> self . line_color_normal = self . theme_cls . divider_color <TAB> if not any ( [ self . error , self . _text_len_error ] ) : <TAB><TAB> if not self . focus : <TAB><TAB><TAB> self . _current_hint_text_color = self . theme_cls . disabled_hint_text_color <TAB><TAB><TAB> self . _current_right_lbl_color = self . theme_cls . disabled_hint_text_color <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _current_error_color = self . theme_cls . disabled_hint_text_color","if self . helper_text_mode == ""persistent"" :",if self . focus :,75.65267770905166,93.88,False
1440,"def createFields ( self ) : <TAB> for item in self . format : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield item [ 0 ] ( self , * item [ 1 : - 1 ] , * * item [ - 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> yield item [ 0 ] ( self , * item [ 1 : ] )","if isinstance ( item [ - 1 ] , dict ) :",if item [ - 1 ] :,66.23449985774869,91.77,False
1441,"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . cursor . execute ( statement , arguments ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . cursor . execute ( statement ) <TAB><TAB> except sqlite3 . OperationalError as ex : <TAB><TAB><TAB> if "" locked "" not in getSafeExString ( ex ) : <TAB><TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB><TAB> return self . cursor . fetchall ( )",if arguments :,if arguments :,100.0,100.00,True
1442,"def set_income_account_for_fixed_assets ( self ) : <TAB> disposal_account = depreciation_cost_center = None <TAB> for d in self . get ( "" items "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not disposal_account : <TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB> disposal_account , <TAB><TAB><TAB><TAB><TAB> depreciation_cost_center , <TAB><TAB><TAB><TAB> ) = get_disposal_account_and_cost_center ( self . company ) <TAB><TAB><TAB> d . income_account = disposal_account <TAB><TAB><TAB> if not d . cost_center : <TAB><TAB><TAB><TAB> d . cost_center = depreciation_cost_center",if d . is_fixed_asset :,if d . income_account is None :,95.12900263754392,97.19,False
1443,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB><TAB> if isinstance ( nbChars , int ) : <TAB><TAB><TAB> nbMinBit = nbChars * 8 <TAB><TAB><TAB> nbMaxBit = nbMinBit <TAB><TAB> else : <TAB><TAB><TAB> if nbChars [ 0 ] is not None : <TAB><TAB><TAB><TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )",if nbChars [ 1 ] is not None :,if nbChars [ 1 ] is not None :,100.0,100.00,True
1444,"def _get_service_full_name ( self , name , help_command_table ) : <TAB> if help_command_table and name not in self . _NON_SERVICE_COMMANDS : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _HIGH_LEVEL_SERVICE_FULL_NAMES [ name ] <TAB><TAB> service = help_command_table . get ( name ) <TAB><TAB> if service : <TAB><TAB><TAB> return service . service_model . metadata [ "" serviceFullName "" ]",if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,100.0,100.00,True
1445,"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 : # at least one complete IP address <TAB><TAB> while 1 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp_str + = "" # "" <TAB><TAB><TAB> tmp_str + = self . get_ip_address ( p ) <TAB><TAB><TAB> p + = 4 <TAB><TAB><TAB> if p > = self . get_len ( ) : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tmp_str + = "" ,  "" <TAB> tmp_str + = "" ]  "" <TAB> if self . get_ptr ( ) % 4 : # ptr field should be a multiple of 4 <TAB><TAB> tmp_str + = "" nonsense ptr field:  %d   "" % self . get_ptr ( ) <TAB> return tmp_str",if p + 1 == self . get_ptr ( ) :,if self . get_ptr ( ) % 4 == 0 :,97.57259949140192,97.27,False
1446,"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB><TAB> error = True <TAB><TAB> try : <TAB><TAB><TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB><TAB><TAB> error = False <TAB><TAB> except : <TAB><TAB><TAB> if not self . expect_exception : <TAB><TAB><TAB><TAB> raise <TAB><TAB> <MASK> <TAB><TAB><TAB> assert error",if self . expect_exception :,if self . expect_exception :,100.0,100.00,True
1447,"def create_composite_mounter_by_args ( args ) : <TAB> """"""Creates a CompositeMounter by the images in given args."""""" <TAB> logging . info ( "" Mount images... "" ) <TAB> mounter = composite_mounter . CompositeMounter ( ) <TAB> for partition in composite_mounter . SUPPORTED_PARTITIONS : <TAB><TAB> image_source = vars ( args ) [ partition ] <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . info ( ""    %s = %s "" , partition , image_source ) <TAB><TAB><TAB> mounter . add_by_mount_target ( partition , image_source ) <TAB> if mounter . is_empty ( ) : <TAB><TAB> raise RuntimeError ( "" Must give at least one image source. "" ) <TAB> return mounter",if image_source :,if image_source :,100.0,100.00,True
1448,"def _get_containing_class ( self , pyname ) : <TAB> if isinstance ( pyname , pynames . DefinedName ) : <TAB><TAB> scope = pyname . get_object ( ) . get_scope ( ) <TAB><TAB> parent = scope . parent <TAB><TAB> <MASK> <TAB><TAB><TAB> return parent . pyobject","if parent is not None and parent . get_kind ( ) == ""Class"" :",if parent is not None :,60.16740223825183,83.90,False
1449,"def test_chunkcoding ( self ) : <TAB> tstring_lines = [ ] <TAB> for b in self . tstring : <TAB><TAB> lines = b . split ( b "" \n "" ) <TAB><TAB> last = lines . pop ( ) <TAB><TAB> assert last == b "" "" <TAB><TAB> lines = [ line + b "" \n "" for line in lines ] <TAB><TAB> tstring_lines . append ( lines ) <TAB> for native , utf8 in zip ( * tstring_lines ) : <TAB><TAB> u = self . decode ( native ) [ 0 ] <TAB><TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] )",if self . roundtriptest :,if u :,68.90256896151034,97.68,False
1450,"def set_default_variants ( apps , schema_editor ) : <TAB> Product = apps . get_model ( "" product "" , "" Product "" ) <TAB> for product in Product . objects . iterator ( ) : <TAB><TAB> first_variant = product . variants . first ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> product . default_variant = first_variant <TAB><TAB><TAB> product . save ( update_fields = [ "" default_variant "" , "" updated_at "" ] )",if first_variant :,if first_variant :,100.0,100.00,True
1451,"def json ( self ) : <TAB> try : <TAB><TAB> if self . is_json ( ) : <TAB><TAB><TAB> raw_data = self . raw_data ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raw_data = raw_data . decode ( "" utf-8 "" ) <TAB><TAB><TAB> return json . loads ( raw_data ) <TAB> except ValueError : <TAB><TAB> pass","if not isinstance ( raw_data , text_type ) :","if isinstance ( raw_data , bytes ) :",92.7337574973832,94.30,False
1452,"def clear_react ( self , message : discord . Message , emoji : MutableMapping = None ) - > None : <TAB> try : <TAB><TAB> await message . clear_reactions ( ) <TAB> except discord . Forbidden : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> with contextlib . suppress ( discord . HTTPException ) : <TAB><TAB><TAB> async for key in AsyncIter ( emoji . values ( ) , delay = 0.2 ) : <TAB><TAB><TAB><TAB> await message . remove_reaction ( key , self . bot . user ) <TAB> except discord . HTTPException : <TAB><TAB> return",if not emoji :,if not emoji :,100.0,100.00,True
1453,"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB><TAB> value = value . upper ( ) <TAB><TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB><TAB><TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB><TAB><TAB> if value . startswith ( prefix ) : <TAB><TAB><TAB><TAB> value = value [ len ( prefix ) : ] <TAB><TAB><TAB> value = value . lstrip ( "" _ "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return getattr ( self . group , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB> else : <TAB><TAB> return value","if hasattr ( self . group , value ) :","if hasattr ( self . group , value ) :",100.0,100.00,True
1454,"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB><TAB> quote = True <TAB> else : <TAB><TAB> for x in self : <TAB><TAB><TAB> if x . token_type == "" quoted-string "" : <TAB><TAB><TAB><TAB> quote = True <TAB> if quote : <TAB><TAB> pre = post = "" "" <TAB><TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB><TAB><TAB> pre = ""   "" <TAB><TAB> <MASK> <TAB><TAB><TAB> post = ""   "" <TAB><TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB><TAB> return super ( DisplayName , self ) . value","if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :","if self [ 0 ] . token_type == ""cfws"" or self [ 0 ]",69.20949239179286,90.88,False
1455,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB><TAB> if root_path : <TAB><TAB><TAB> config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB> if config_root_path and root_path == config_root_path : <TAB><TAB><TAB><TAB> return drive <TAB><TAB> <MASK> <TAB><TAB><TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB> return drive",elif volume_guid_path :,if volume_guid_path :,89.79458384835303,98.74,False
1456,"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB><TAB> for g in m . GraphicalItems ( ) : <TAB><TAB><TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB><TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB><TAB><TAB> parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB> if bbox is None : <TAB><TAB><TAB><TAB><TAB> bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB><TAB> bbox . Normalize ( ) <TAB> return edges , bbox",if parsed_drawing :,if parsed_drawing :,100.0,100.00,True
1457,"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB> k = literal_or_identifier [ "" value "" ] <TAB><TAB> if isinstance ( k , float ) : <TAB><TAB><TAB> return unicode ( float_repr ( k ) ) <TAB><TAB> elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB> return compose_regex ( k ) <TAB><TAB> elif isinstance ( k , bool ) : <TAB><TAB><TAB> return "" true "" if k else "" false "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" null "" <TAB><TAB> else : <TAB><TAB><TAB> return unicode ( k )",elif k is None :,elif k is None :,100.0,100.00,True
1458,"def find_multiple_stats ( stats , name , _found = None , _on_found = None ) : <TAB> if _found is None : <TAB><TAB> _found = [ ] <TAB> for child_stats in stats : <TAB><TAB> if child_stats . name == name : <TAB><TAB><TAB> _found . append ( child_stats ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _on_found ( _found ) <TAB><TAB> find_multiple_stats ( child_stats , name , _found ) <TAB> return _found",if callable ( _on_found ) :,if _on_found is not None :,94.4891664838132,96.02,False
1459,"def _run_generated_code ( <TAB> self , <TAB> code , <TAB> globs , <TAB> locs , <TAB> fails_under_py3k = True , ) : <TAB> import warnings <TAB> from zope . interface . _compat import PYTHON3 <TAB> with warnings . catch_warnings ( record = True ) as log : <TAB><TAB> warnings . resetwarnings ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> exec ( code , globs , locs ) <TAB><TAB><TAB> self . assertEqual ( len ( log ) , 0 ) # no longer warn <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> exec ( code , globs , locs ) <TAB><TAB><TAB> except TypeError : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if fails_under_py3k : <TAB><TAB><TAB><TAB><TAB> self . fail ( "" Didn ' t raise TypeError "" )",if not PYTHON3 :,if PYTHON3 :,94.92927763029947,99.07,False
1460,"def _get_node ( self , node_id ) : <TAB> self . non_terminated_nodes ( { } ) # Side effect: updates cache <TAB> with self . lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . cached_nodes [ node_id ] <TAB><TAB> instance = ( <TAB><TAB><TAB> self . compute . instances ( ) <TAB><TAB><TAB> . get ( <TAB><TAB><TAB><TAB> project = self . provider_config [ "" project_id "" ] , <TAB><TAB><TAB><TAB> zone = self . provider_config [ "" availability_zone "" ] , <TAB><TAB><TAB><TAB> instance = node_id , <TAB><TAB><TAB> ) <TAB><TAB><TAB> . execute ( ) <TAB><TAB> ) <TAB><TAB> return instance",if node_id in self . cached_nodes :,if node_id in self . cached_nodes :,100.0,100.00,True
1461,"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB><TAB> tok = self . tokenizer . get_next_token ( ) <TAB><TAB> ttype = tok [ "" style "" ] <TAB><TAB> if ttype == SCE_PL_UNUSED : <TAB><TAB><TAB> return <TAB><TAB> elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB> tval = tok [ "" text "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB> nestedCount + = 1 <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB> if nestedCount < = 0 : <TAB><TAB><TAB><TAB><TAB><TAB> break",if self . opHash . has_key ( tval ) :,if tval in self . opHash :,68.36973916552338,96.20,False
1462,"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len ( kwargs ) > 0 <TAB> kwargs . update ( infer_mode = infer_mode ) <TAB> is_training = not infer_mode if infer_mode is not None else self . training <TAB> helper = self . _train_helper if is_training else self . _infer_helper <TAB> if prefer_new or helper is None : <TAB><TAB> helper = self . create_helper ( * * kwargs ) <TAB><TAB> if is_training and self . _train_helper is None : <TAB><TAB><TAB> self . _train_helper = helper <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _infer_helper = helper <TAB> return helper",elif not is_training and self . _infer_helper is None :,if not is_infer_helper and self . _infer_helper is None :,73.33419289512305,96.95,False
1463,"def get_ldset ( self , ldsets ) : <TAB> ldset = None <TAB> if self . _properties [ "" ldset_name "" ] == "" "" : <TAB><TAB> nldset = len ( ldsets ) <TAB><TAB> if nldset == 0 : <TAB><TAB><TAB> msg = _ ( "" Logical Disk Set could not be found. "" ) <TAB><TAB><TAB> raise exception . NotFound ( msg ) <TAB><TAB> else : <TAB><TAB><TAB> ldset = None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = ( <TAB><TAB><TAB><TAB> _ ( "" Logical Disk Set ` %s ` could not be found. "" ) <TAB><TAB><TAB><TAB> % self . _properties [ "" ldset_name "" ] <TAB><TAB><TAB> ) <TAB><TAB><TAB> raise exception . NotFound ( msg ) <TAB><TAB> ldset = ldsets [ self . _properties [ "" ldset_name "" ] ] <TAB> return ldset","if self . _properties [ ""ldset_name"" ] not in ldsets :",if not ldsets :,71.7938000643547,94.51,False
1464,"def calc_fractal_serial ( q , maxiter ) : <TAB> # calculate z using pure python on a numpy array <TAB> # note that, unlike the other two implementations, <TAB> # the number of iterations per point is NOT constant <TAB> z = np . zeros ( q . shape , complex ) <TAB> output = np . resize ( <TAB><TAB> np . array ( <TAB><TAB><TAB> 0 , <TAB><TAB> ) , <TAB><TAB> q . shape , <TAB> ) <TAB> for i in range ( len ( q ) ) : <TAB><TAB> for iter in range ( maxiter ) : <TAB><TAB><TAB> z [ i ] = z [ i ] * z [ i ] + q [ i ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> output [ i ] = iter <TAB><TAB><TAB><TAB> break <TAB> return output",if abs ( z [ i ] ) > 2.0 :,if z [ i ] > 1 :,72.25977312401238,96.60,False
1465,"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB><TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB><TAB><TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not inst . modctxt : <TAB><TAB><TAB><TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )","if isinstance ( inst , ( _Block , _Instantiator ) ) :","if isinstance ( inst , _Instance ) :",67.38481545760068,93.68,False
1466,"def walks_generator ( ) : <TAB> if filelist is not None : <TAB><TAB> bucket = [ ] <TAB><TAB> for filename in filelist : <TAB><TAB><TAB> with io . open ( filename ) as inf : <TAB><TAB><TAB><TAB> for line in inf : <TAB><TAB><TAB><TAB><TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( ""   "" ) ] <TAB><TAB><TAB><TAB><TAB> bucket . append ( walk ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> yield bucket <TAB><TAB><TAB><TAB><TAB><TAB> bucket = [ ] <TAB><TAB> if len ( bucket ) : <TAB><TAB><TAB> yield bucket <TAB> else : <TAB><TAB> for _ in range ( epoch ) : <TAB><TAB><TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB><TAB><TAB><TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB><TAB><TAB><TAB> yield walks",if len ( bucket ) == batch_size :,if len ( bucket ) == batch_size :,100.0,100.00,True
1467,def _traverse ( op ) : <TAB> if op in visited : <TAB><TAB> return <TAB> visited . add ( op ) <TAB> if tag . is_injective ( op . tag ) : <TAB><TAB> if op not in s . outputs : <TAB><TAB><TAB> s [ op ] . compute_inline ( ) <TAB><TAB> for tensor in op . input_tensors : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _traverse ( tensor . op ) <TAB> callback ( op ),"if isinstance ( tensor . op , tvm . te . ComputeOp ) :","if isinstance ( tensor , tf . keras . keras . keras . keras . keras . keras .",63.15502587955832,89.39,False
1468,"def unwatch_run ( self , run_id , handler ) : <TAB> with self . _dict_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _handlers_dict [ run_id ] = [ <TAB><TAB><TAB><TAB> ( start_cursor , callback ) <TAB><TAB><TAB><TAB> for ( start_cursor , callback ) in self . _handlers_dict [ run_id ] <TAB><TAB><TAB><TAB> if callback != handler <TAB><TAB><TAB> ] <TAB><TAB> if not self . _handlers_dict [ run_id ] : <TAB><TAB><TAB> del self . _handlers_dict [ run_id ] <TAB><TAB><TAB> run_id_dict = self . _run_id_dict <TAB><TAB><TAB> del run_id_dict [ run_id ] <TAB><TAB><TAB> self . _run_id_dict = run_id_dict",if run_id in self . _run_id_dict :,if run_id not in self . _handlers_dict :,97.20655431161677,97.60,False
1469,"def _PromptMySQL ( self , config ) : <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True : <TAB><TAB> self . _PromptMySQLOnce ( config ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB><TAB><TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB><TAB><TAB> if not retry : <TAB><TAB><TAB><TAB> raise ConfigInitError ( )",if self . _CheckMySQLConnection ( ) :,if self . _isConnected ( ) :,98.74391589383804,98.63,False
1470,"def get_courses_without_topic ( topic ) : <TAB> data = [ ] <TAB> for entry in frappe . db . get_all ( "" Course "" ) : <TAB><TAB> course = frappe . get_doc ( "" Course "" , entry . name ) <TAB><TAB> topics = [ t . topic for t in course . topics ] <TAB><TAB> <MASK> <TAB><TAB><TAB> data . append ( course . name ) <TAB> return data",if not topics or topic not in topics :,if topic not in topics :,66.4891315215967,96.05,False
1471,"def _error_handler ( action , * * keywords ) : <TAB> if keywords : <TAB><TAB> file_type = keywords . get ( "" file_type "" , None ) <TAB><TAB> if file_type : <TAB><TAB><TAB> raise exceptions . FileTypeNotSupported ( <TAB><TAB><TAB><TAB> constants . FILE_TYPE_NOT_SUPPORTED_FMT % ( file_type , action ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> keywords . pop ( "" on_demand "" ) <TAB><TAB><TAB> msg = "" Please check if there were typos in  "" <TAB><TAB><TAB> msg + = "" function parameters:  %s . Otherwise  "" <TAB><TAB><TAB> msg + = "" unrecognized parameters were given. "" <TAB><TAB><TAB> raise exceptions . UnknownParameters ( msg % keywords ) <TAB> else : <TAB><TAB> raise exceptions . UnknownParameters ( "" No parameters found! "" )","if ""on_demand"" in keywords :","if ""on_demand"" in keywords :",100.0,100.00,True
1472,"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB><TAB> self . view . sel ( ) . add ( r ) <TAB><TAB> <MASK> <TAB><TAB><TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> <MASK> <TAB><TAB> text = "" "" . join ( to_store ) <TAB><TAB> if not text . endswith ( "" \n "" ) : <TAB><TAB><TAB> text = text + "" \n "" <TAB><TAB> state = State ( self . view ) <TAB><TAB> state . registers [ register ] = [ text ]",if register :,if to_store :,97.16981442856708,95.29,False
1473,"def has_actor ( self , message : HasActorMessage ) - > ResultMessage : <TAB> actor_ref = message . actor_ref <TAB> # lookup allocated <TAB> for address , item in self . _allocated_actors . items ( ) : <TAB><TAB> ref = create_actor_ref ( address , actor_ref . uid ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ResultMessage ( message . message_id , True , protocol = message . protocol ) <TAB> return ResultMessage ( message . message_id , False , protocol = message . protocol )",if ref in item :,if ref . has_actor ( item ) :,97.05248025258548,93.85,False
1474,"def toggleMetaButton ( self , event ) : <TAB> """"""Process clicks on toggle buttons"""""" <TAB> clickedBtn = event . EventObject <TAB> if wx . GetMouseState ( ) . GetModifiers ( ) == wx . MOD_CONTROL : <TAB><TAB> activeBtns = [ btn for btn in self . metaButtons if btn . GetValue ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> clickedBtn . setUserSelection ( clickedBtn . GetValue ( ) ) <TAB><TAB><TAB> self . itemView . filterItemStore ( ) <TAB><TAB> else : <TAB><TAB><TAB> # Do 'nothing' if we're trying to turn last active button off <TAB><TAB><TAB> # Keep button in the same state <TAB><TAB><TAB> clickedBtn . setUserSelection ( True ) <TAB> else : <TAB><TAB> for btn in self . metaButtons : <TAB><TAB><TAB> btn . setUserSelection ( btn == clickedBtn ) <TAB><TAB> self . itemView . filterItemStore ( )",if activeBtns :,if activeBtns :,100.0,100.00,True
1475,"def __init__ ( self , hub = None ) : # pylint: disable=unused-argument <TAB> if resolver . _resolver is None : <TAB><TAB> _resolver = resolver . _resolver = _DualResolver ( ) <TAB><TAB> if config . resolver_nameservers : <TAB><TAB><TAB> _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB><TAB> <MASK> <TAB><TAB><TAB> _resolver . network_resolver . lifetime = config . resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance ( resolver . _resolver , _DualResolver ) <TAB> self . _resolver = resolver . _resolver",if config . resolver_timeout :,if config . resolver_timeout :,100.0,100.00,True
1476,"def sub_paragraph ( self , li ) : <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len ( li ) : <TAB><TAB> first = list ( li ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> m = RE_CHECKBOX . match ( first . text ) <TAB><TAB><TAB> if m is not None : <TAB><TAB><TAB><TAB> first . text = self . markdown . htmlStash . store ( <TAB><TAB><TAB><TAB><TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB><TAB><TAB><TAB> ) + m . group ( "" line "" ) <TAB><TAB><TAB><TAB> found = True <TAB> return found","if first . tag == ""p"" and first . text is not None :",if first . text :,67.32683828697303,93.34,False
1477,"def _check_mswin_locale ( locale ) : <TAB> msloc = None <TAB> try : <TAB><TAB> msloc = _LOCALE_NAMES [ locale [ : 5 ] ] [ : 2 ] <TAB><TAB> locale = locale [ : 5 ] <TAB> except KeyError : <TAB><TAB> try : <TAB><TAB><TAB> msloc = _LOCALE_NAMES [ locale [ : 2 ] ] [ : 2 ] <TAB><TAB><TAB> locale = locale [ : 2 ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> # US English is the outlier, all other English locales want <TAB><TAB><TAB> # real English: <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return ( "" en_GB "" , "" 1252 "" ) <TAB><TAB><TAB> return ( None , None ) <TAB> return ( locale , msloc )","if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :","if locale == ""en_GB"" :",93.29520701568583,90.80,False
1478,"def setLabel ( self , s , protect = False ) : <TAB> """"""Set the label of the minibuffer."""""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB><TAB> # Support for the curses gui. <TAB><TAB> <MASK> <TAB><TAB><TAB> g . app . gui . set_minibuffer_label ( c , s ) <TAB><TAB> w . setAllText ( s ) <TAB><TAB> n = len ( s ) <TAB><TAB> w . setSelectionRange ( n , n , insert = n ) <TAB><TAB> if protect : <TAB><TAB><TAB> k . mb_prefix = s","if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :","if hasattr ( g . app , gui . SetMinibuffer ) :",97.77822990747626,93.97,False
1479,"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 : # have a one element wedge <TAB><TAB> proc = ( "" first "" , "" last "" ) <TAB> else : <TAB><TAB> if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) : <TAB><TAB><TAB> proc = ( "" first "" , "" last "" ) # same element can be first and last <TAB><TAB> <MASK> <TAB><TAB><TAB> proc = ( "" first "" , ) <TAB><TAB> elif su . isLast ( innerTarget ) : <TAB><TAB><TAB> proc = ( "" last "" , ) <TAB><TAB> else : <TAB><TAB><TAB> proc = ( ) <TAB> return proc",elif su . isFirst ( innerTarget ) :,elif su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,98.6164895477773,96.33,False
1480,"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB><TAB> if iterations > 100 : <TAB><TAB><TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB><TAB><TAB> return <TAB><TAB> status = self . master . get_status ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> iterations + = 1 <TAB><TAB> time . sleep ( 1.0 )","if status . get ( ""status"" ) == ""ENDED"" :","if status == ""RUNNING"" :",78.63280499567269,91.72,False
1481,"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> text . autocompleter = Completer ( text ) <TAB><TAB><TAB> elif isinstance ( text , ShellText ) : <TAB><TAB><TAB><TAB> text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )","if isinstance ( text , CodeViewText ) :","if isinstance ( text , CodeViewText ) :",100.0,100.00,True
1482,"def validate_party_details ( self ) : <TAB> if self . party : <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB><TAB> if self . party_account and self . party_type in ( "" Customer "" , "" Supplier "" ) : <TAB><TAB><TAB> self . validate_account_type ( <TAB><TAB><TAB><TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB><TAB><TAB> )","if not frappe . db . exists ( self . party_type , self . party ) :",if not self . party_type :,89.35740944461882,91.77,False
1483,"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB><TAB> elif piece : <TAB><TAB><TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces )",if i % 2 :,if i == 0 :,95.9928459644117,96.40,False
1484,"def _convert_java_pattern_to_python ( pattern ) : <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB><TAB> c = s [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> s [ i ] = "" \\ "" <TAB><TAB> elif c == "" \\ "" and s [ i + 1 ] == "" $ "" : <TAB><TAB><TAB> s [ i ] = "" "" <TAB><TAB><TAB> i + = 1 <TAB><TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s )","if c == ""$"" and s [ i + 1 ] in ""0123456789"" :","if c == ""\\"" and s [ i + 1 ] == ""\\"" :",72.12575672907654,95.31,False
1485,"def download ( self , url , filename , * * kwargs ) : <TAB> try : <TAB><TAB> r = self . get ( url , timeout = 10 , stream = True , * * kwargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> with open ( filename , "" wb "" ) as f : <TAB><TAB><TAB> for chunk in r . iter_content ( chunk_size = 1024 ) : <TAB><TAB><TAB><TAB> if chunk : <TAB><TAB><TAB><TAB><TAB> f . write ( chunk ) <TAB><TAB> helpers . chmod_as_parent ( filename ) <TAB> except Exception as e : <TAB><TAB> sickrage . app . log . debug ( <TAB><TAB><TAB> "" Failed to download file from  {}  - ERROR:  {} "" . format ( url , e ) <TAB><TAB> ) <TAB><TAB> if os . path . exists ( filename ) : <TAB><TAB><TAB> os . remove ( filename ) <TAB><TAB> return False <TAB> return True",if r . status_code >= 400 :,if not r :,70.20648929492013,96.54,False
1486,"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedFilesWithExtension ( "" js "" ) : <TAB><TAB> items . append ( <TAB><TAB><TAB> ' <script type= "" text/javascript ""  src= "" ' <TAB><TAB><TAB> + item . pathAbsoluteFromProjectEncoded ( ) <TAB><TAB><TAB> + ' "" ></script> ' <TAB><TAB> ) <TAB> if len ( items ) > 0 : <TAB><TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sublime . status_message ( "" Items copied "" ) <TAB><TAB> else : <TAB><TAB><TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,100.0,100.00,True
1487,"def work ( self ) : <TAB> while True : <TAB><TAB> timeout = self . timeout <TAB><TAB> if idle . is_set ( ) : <TAB><TAB><TAB> timeout = self . idle_timeout <TAB><TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB><TAB> fetch . wait ( timeout ) <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Stop fetch worker "" ) <TAB><TAB><TAB> break <TAB><TAB> self . fetch ( )",if shutting_down . is_set ( ) :,if not self . is_running ( ) :,67.57559299690405,95.10,False
1488,"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB><TAB> if mode == "" start "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> mode = "" key "" <TAB><TAB> elif mode == "" key "" : <TAB><TAB><TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB><TAB><TAB><TAB> mode = "" end "" <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB><TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB> "" Encrypted APNS private keys are not supported "" <TAB><TAB><TAB><TAB> ) <TAB> if mode != "" end "" : <TAB><TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :","if ""KEY"" in s or ""KEY"" in s :",84.1501630748707,97.04,False
1489,"def compare_lists ( self , l1 , l2 , key ) : <TAB> l2_lookup = { o . get ( key ) : o for o in l2 } <TAB> for obj1 in l1 : <TAB><TAB> obj2 = l2_lookup . get ( obj1 . get ( key ) ) <TAB><TAB> for k in obj1 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( obj1 . get ( k ) , obj2 . get ( k ) )","if k not in ""id"" and obj1 . get ( k ) :",if k in obj2 :,90.38027560862147,89.38,False
1490,"def before_get_object ( self , view_kwargs ) : <TAB> if view_kwargs . get ( "" id "" ) is not None : <TAB><TAB> try : <TAB><TAB><TAB> user_favourite_event = find_user_favourite_event_by_id ( <TAB><TAB><TAB><TAB> event_id = view_kwargs [ "" id "" ] <TAB><TAB><TAB> ) <TAB><TAB> except NoResultFound : <TAB><TAB><TAB> raise ObjectNotFound ( <TAB><TAB><TAB><TAB> { "" source "" : "" /data/relationships/event "" } , "" Object: not found "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> view_kwargs [ "" id "" ] = user_favourite_event . id <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> view_kwargs [ "" id "" ] = None",if user_favourite_event is not None :,if user_favourite_event :,94.52524386393193,98.21,False
1491,"def close ( self ) : <TAB> super ( ) . close ( ) <TAB> if not sys . is_finalizing ( ) : <TAB><TAB> for sig in list ( self . _signal_handlers ) : <TAB><TAB><TAB> self . remove_signal_handler ( sig ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> f "" Closing the loop  { self !r}   "" <TAB><TAB><TAB><TAB> f "" on interpreter shutdown  "" <TAB><TAB><TAB><TAB> f "" stage, skipping signal handlers removal "" , <TAB><TAB><TAB><TAB> ResourceWarning , <TAB><TAB><TAB><TAB> source = self , <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . _signal_handlers . clear ( )",if self . _signal_handlers :,if self . _signal_handlers :,100.0,100.00,True
1492,"def install_script ( self , script , install_options = None ) : <TAB> try : <TAB><TAB> fname = utils . do_script ( <TAB><TAB><TAB> script , <TAB><TAB><TAB> python_exe = osp . join ( self . target , "" python.exe "" ) , <TAB><TAB><TAB> architecture = self . architecture , <TAB><TAB><TAB> verbose = self . verbose , <TAB><TAB><TAB> install_options = install_options , <TAB><TAB> ) <TAB> except RuntimeError : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Failed! "" ) <TAB><TAB><TAB> raise",if not self . verbose :,if self . verbose :,92.98736088764088,98.53,False
1493,"def GetRouterForUser ( self , username ) : <TAB> """"""Returns a router corresponding to a given username."""""" <TAB> for index , router in enumerate ( self . routers ) : <TAB><TAB> router_id = str ( index ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . debug ( <TAB><TAB><TAB><TAB> "" Matched router  %s  to user  %s "" , router . __class__ . __name__ , username <TAB><TAB><TAB> ) <TAB><TAB><TAB> return router <TAB> logging . debug ( <TAB><TAB> "" No router ACL rule match for user  %s . Using default  "" "" router  %s "" , <TAB><TAB> username , <TAB><TAB> self . default_router . __class__ . __name__ , <TAB> ) <TAB> return self . default_router","if self . auth_manager . CheckPermissions ( username , router_id ) :",if router . username == username :,66.62370047649955,93.41,False
1494,"def charset ( self ) : <TAB> """"""The charset from the content type."""""" <TAB> header = self . environ . get ( "" CONTENT_TYPE "" ) <TAB> if header : <TAB><TAB> ct , options = parse_options_header ( header ) <TAB><TAB> charset = options . get ( "" charset "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if is_known_charset ( charset ) : <TAB><TAB><TAB><TAB> return charset <TAB><TAB><TAB> return self . unknown_charset ( charset ) <TAB> return self . default_charset",if charset :,if charset :,100.0,100.00,True
1495,def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self . count > self . epiLen : <TAB><TAB> self . res ( ) <TAB><TAB> return True <TAB> else : <TAB><TAB> if self . count == 1 : <TAB><TAB><TAB> self . pertGlasPos ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . env . reset ( ) <TAB><TAB><TAB> self . pertGlasPos ( 1 ) <TAB><TAB> self . count + = 1 <TAB><TAB> return False,if self . count == self . epiLen / 2 + 1 :,elif self . count == 2 :,69.27465514242145,93.11,False
1496,"def mtimes_of_files ( dirnames : List [ str ] , suffix : str ) - > Iterator [ float ] : <TAB> for dirname in dirnames : <TAB><TAB> for root , dirs , files in os . walk ( dirname ) : <TAB><TAB><TAB> for sfile in files : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> yield path . getmtime ( path . join ( root , sfile ) ) <TAB><TAB><TAB><TAB><TAB> except OSError : <TAB><TAB><TAB><TAB><TAB><TAB> pass",if sfile . endswith ( suffix ) :,if sfile . endswith ( suffix ) :,100.0,100.00,True
1497,"def get_all_hashes ( self ) : <TAB> event_hashes = [ ] <TAB> sample_hashes = [ ] <TAB> for a in self . event . attributes : <TAB><TAB> h = None <TAB><TAB> if a . type in ( "" md5 "" , "" sha1 "" , "" sha256 "" ) : <TAB><TAB><TAB> h = a . value <TAB><TAB><TAB> event_hashes . append ( h ) <TAB><TAB> elif a . type in ( "" filename|md5 "" , "" filename|sha1 "" , "" filename|sha256 "" ) : <TAB><TAB><TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB><TAB><TAB> event_hashes . append ( h ) <TAB><TAB> <MASK> <TAB><TAB><TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB><TAB><TAB> sample_hashes . append ( h ) <TAB> return event_hashes , sample_hashes","elif a . type == ""malware-sample"" :","elif a . type in ( ""sample|sample"" , ""sample_hash"" )",74.94871330796764,94.03,False
1498,"def _validate ( self , event ) : <TAB> if self . type is None : <TAB><TAB> return <TAB> new = self . value <TAB> if not isinstance ( new , self . type ) and new is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . value = event . old <TAB><TAB> types = repr ( self . type ) if isinstance ( self . type , tuple ) else self . type . __name__ <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" LiteralInput expected  %s  type but value  %s   "" <TAB><TAB><TAB> "" is of type  %s . "" % ( types , new , type ( new ) . __name__ ) <TAB><TAB> )",if event :,if new != event . old :,96.93821781010396,96.06,False
1499,"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if key not in a : <TAB><TAB><TAB> a [ key ] = value <TAB><TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB><TAB><TAB> update_dict ( a [ key ] , value ) <TAB><TAB> elif isinstance ( a [ key ] , list ) : <TAB><TAB><TAB> a [ key ] . append ( value ) <TAB><TAB> else : <TAB><TAB><TAB> a [ key ] = [ a [ key ] , value ]",if value is None :,"if key == ""id"" :",96.02919679164468,95.88,False
1500,"def on_pre_save ( self , view ) : <TAB> extOrClause = "" | "" . join ( s . get ( "" format_on_save_extensions "" ) ) <TAB> extRegex = "" \\ .( "" + extOrClause + "" )$ "" <TAB> if s . get ( "" format_on_save "" ) and re . search ( extRegex , view . file_name ( ) ) : <TAB><TAB> # only auto-format on save if there are no ""lint errors"" <TAB><TAB> # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB><TAB> lints_regions = [ "" lint-keyword-underline "" , "" lint-keyword-outline "" ] <TAB><TAB> for linter in lints_regions : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> view . run_command ( "" js_format "" )",if len ( view . get_regions ( linter ) ) :,"if not l . run ( ""js_format"" ) :",96.46611736161262,95.11,False
1501,"def readMemory ( self , va , size ) : <TAB> for mva , mmaxva , mmap , mbytes in self . _map_defs : <TAB><TAB> if mva < = va < mmaxva : <TAB><TAB><TAB> mva , msize , mperms , mfname = mmap <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise envi . SegmentationViolation ( va ) <TAB><TAB><TAB> offset = va - mva <TAB><TAB><TAB> return mbytes [ offset : offset + size ] <TAB> raise envi . SegmentationViolation ( va )",if not mperms & MM_READ :,if not mperms :,76.29507756700269,95.98,False
1502,"def assertFilepathsEqual ( self , p1 , p2 ) : <TAB> if sys . platform == "" win32 "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> p1 = [ normcase ( normpath ( x ) ) for x in p1 ] <TAB><TAB><TAB> p2 = [ normcase ( normpath ( x ) ) for x in p2 ] <TAB><TAB> else : <TAB><TAB><TAB> assert isinstance ( p1 , ( str , unicode ) ) <TAB><TAB><TAB> p1 = normcase ( normpath ( p1 ) ) <TAB><TAB><TAB> p2 = normcase ( normpath ( p2 ) ) <TAB> self . assertEqual ( p1 , p2 )","if isinstance ( p1 , ( list , tuple ) ) :","if isinstance ( p1 , list ) :",95.19196262734047,96.14,False
1503,"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB><TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB><TAB> path = join ( dir_path , p ) <TAB><TAB> if isdir ( path ) : <TAB><TAB><TAB> # call recursively for each dir <TAB><TAB><TAB> paths = add_directory_csv_files ( path , paths ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # add every file to the list <TAB><TAB><TAB> paths . append ( path ) <TAB> return paths","elif isfile ( path ) and path . endswith ( "".csv"" ) :",elif isfile ( path ) :,95.68419655784626,93.57,False
1504,"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB><TAB><TAB> if not inst . modctxt : <TAB><TAB><TAB><TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :","if not isinstance ( inst , ( _Arg , _Instance ) ) :",66.45369539456986,94.69,False
1505,"def __annotations_bytes ( self ) : <TAB> if self . annotations : <TAB><TAB> a = [ ] <TAB><TAB> for k , v in self . annotations . items ( ) : <TAB><TAB><TAB> if len ( k ) != 4 : <TAB><TAB><TAB><TAB> raise errors . ProtocolError ( "" annotation key must be of length 4 "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> k = k . encode ( "" ASCII "" ) <TAB><TAB><TAB> a . append ( struct . pack ( "" !4sH "" , k , len ( v ) ) ) <TAB><TAB><TAB> a . append ( v ) <TAB><TAB> return b "" "" . join ( a ) <TAB> return b "" ""","if sys . version_info >= ( 3 , 0 ) :","if not isinstance ( k , str ) :",92.83986688941245,94.05,False
1506,"def session ( self , profile : str = "" default "" , region : str = None ) - > boto3 . Session : <TAB> region = self . _get_region ( region , profile ) <TAB> try : <TAB><TAB> session = self . _cache_lookup ( <TAB><TAB><TAB> self . _session_cache , <TAB><TAB><TAB> [ profile , region ] , <TAB><TAB><TAB> self . _boto3 . Session , <TAB><TAB><TAB> [ ] , <TAB><TAB><TAB> { "" region_name "" : region , "" profile_name "" : profile } , <TAB><TAB> ) <TAB> except ProfileNotFound : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> session = self . _boto3 . Session ( region_name = region ) <TAB><TAB> self . _cache_set ( self . _session_cache , [ profile , region ] , session ) <TAB> return session","if profile != ""default"" :",if self . _boto3 . Session is None :,95.28144446391455,96.01,False
1507,"def spans_score ( gold_spans , system_spans ) : <TAB> correct , gi , si = 0 , 0 , 0 <TAB> while gi < len ( gold_spans ) and si < len ( system_spans ) : <TAB><TAB> if system_spans [ si ] . start < gold_spans [ gi ] . start : <TAB><TAB><TAB> si + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> gi + = 1 <TAB><TAB> else : <TAB><TAB><TAB> correct + = gold_spans [ gi ] . end == system_spans [ si ] . end <TAB><TAB><TAB> si + = 1 <TAB><TAB><TAB> gi + = 1 <TAB> return Score ( len ( gold_spans ) , len ( system_spans ) , correct )",elif gold_spans [ gi ] . start < system_spans [ si ] . start :,elif system_spans [ si ] . end > gold_spans [ gi ] . end,73.36932945775989,95.94,False
1508,"def to_api ( tag , raw_value ) : <TAB> try : <TAB><TAB> api_tag , converter = _QL_TO_SC [ tag ] if tag else ( "" q "" , None ) <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise self . error ( <TAB><TAB><TAB><TAB> "" Unsupported  ' %s '  tag. Try:  %s "" % ( tag , "" ,  "" . join ( SUPPORTED ) ) <TAB><TAB><TAB> ) <TAB><TAB> return None , None <TAB> else : <TAB><TAB> value = str ( converter ( raw_value ) if converter else raw_value ) <TAB><TAB> return api_tag , value",if tag not in SUPPORTED :,if not supported :,75.84538009251158,97.02,False
1509,"def unpack ( self , buf ) : <TAB> dpkt . Packet . unpack ( self , buf ) <TAB> buf = buf [ self . __hdr_len__ : ] <TAB> # single-byte IE <TAB> if self . type & 0x80 : <TAB><TAB> self . len = 0 <TAB><TAB> self . data = b "" "" <TAB> # multi-byte IE <TAB> else : <TAB><TAB> # special PER-encoded UUIE <TAB><TAB> <MASK> <TAB><TAB><TAB> self . len = struct . unpack ( "" >H "" , buf [ : 2 ] ) [ 0 ] <TAB><TAB><TAB> buf = buf [ 2 : ] <TAB><TAB> # normal TLV-like IE <TAB><TAB> else : <TAB><TAB><TAB> self . len = struct . unpack ( "" B "" , buf [ : 1 ] ) [ 0 ] <TAB><TAB><TAB> buf = buf [ 1 : ] <TAB><TAB> self . data = buf [ : self . len ]",if self . type == USER_TO_USER :,if len ( buf ) > 2 :,97.74627792698001,95.29,False
1510,"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB><TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . current_provider . on_search ( query ) <TAB><TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB><TAB><TAB> return self . current_provider . on_url ( query ) <TAB><TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB><TAB><TAB> return self . current_provider . on_file ( query )",if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,100.0,100.00,True
1511,"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB><TAB> if not typ : <TAB><TAB><TAB> out + = text <TAB><TAB> <MASK> <TAB><TAB><TAB> out + = "" \\ fI %s \\ fR "" % text <TAB><TAB> elif typ in [ "" strong "" , "" code "" ] : <TAB><TAB><TAB> out + = "" \\ fB %s \\ fR "" % text <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out","elif typ == ""em"" :","elif typ in [ ""int"" , ""float"" , ""float"" , ""float",60.02764606844865,92.14,False
1512,"def process ( self , buckets ) : <TAB> with self . executor_factory ( max_workers = 3 ) as w : <TAB><TAB> futures = { } <TAB><TAB> results = [ ] <TAB><TAB> for b in buckets : <TAB><TAB><TAB> futures [ w . submit ( self . process_bucket , b ) ] = b <TAB><TAB> for f in as_completed ( futures ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> b = futures [ f ] <TAB><TAB><TAB><TAB> self . log . error ( <TAB><TAB><TAB><TAB><TAB> "" error modifying bucket: %s \n %s "" , b [ "" Name "" ] , f . exception ( ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> results + = filter ( None , [ f . result ( ) ] ) <TAB><TAB> return results",if f . exception ( ) :,if f . exception ( ) :,100.0,100.00,True
1513,"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB><TAB><TAB><TAB> "" False. "" % self . alias <TAB><TAB><TAB> ) <TAB><TAB> elif self . features . supports_timezones : <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB><TAB><TAB><TAB> "" handles time zones conversions natively. "" % self . alias <TAB><TAB><TAB> )",if not settings . USE_TZ :,"if self . settings_dict [ ""USE_TZ"" ] is True :",92.374920313262,93.47,False
1514,"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB><TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB><TAB> if each : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> key , value = each . split ( "" = "" , 1 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> key , value = each , "" "" <TAB><TAB><TAB> result [ key ] = value <TAB> namespace . webhook_properties = result","if ""="" in each :","if ""="" in each :",100.0,100.00,True
1515,"def _expand_query_values ( original_query_list ) : <TAB> query_list = [ ] <TAB> for key , value in original_query_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> query_list . append ( ( key , value ) ) <TAB><TAB> else : <TAB><TAB><TAB> key_fmt = key + "" [ %s ] "" <TAB><TAB><TAB> value_list = _to_kv_list ( value ) <TAB><TAB><TAB> query_list . extend ( ( key_fmt % k , v ) for k , v in value_list ) <TAB> return query_list","if isinstance ( value , basestring ) :","if isinstance ( value , ( list , tuple ) ) :",94.59506988460623,96.09,False
1516,"def tags ( ) : <TAB> """"""Return a dictionary of all tags in the form {hash: [tag_names, ...]}."""""" <TAB> tags = { } <TAB> for ( n , c ) in list_refs ( ) : <TAB><TAB> if n . startswith ( "" refs/tags/ "" ) : <TAB><TAB><TAB> name = n [ 10 : ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tags [ c ] = [ ] <TAB><TAB><TAB> tags [ c ] . append ( name ) # more than one tag can point at 'c' <TAB> return tags",if not c in tags :,if c not in tags :,98.29979360825428,98.10,False
1517,"def test_colorspiral ( self ) : <TAB> """"""Set of 625 colours, with jitter, using get_colors()."""""" <TAB> boxedge = 20 <TAB> boxes_per_row = 25 <TAB> rows = 0 <TAB> for i , c in enumerate ( get_colors ( 625 ) ) : <TAB><TAB> self . c . setFillColor ( c ) <TAB><TAB> x1 = boxedge * ( i % boxes_per_row ) <TAB><TAB> y1 = rows * boxedge <TAB><TAB> self . c . rect ( x1 , y1 , boxedge , boxedge , fill = 1 , stroke = 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> rows + = 1 <TAB> self . finish ( )",if not ( i + 1 ) % boxes_per_row :,if i % boxes_per_row == 0 :,67.35273055372062,95.21,False
1518,"def oldest_pending_update_in_days ( ) : <TAB> """"""Return the datestamp of the oldest pending update"""""" <TAB> pendingupdatespath = os . path . join ( <TAB><TAB> prefs . pref ( "" ManagedInstallDir "" ) , "" UpdateNotificationTracking.plist "" <TAB> ) <TAB> try : <TAB><TAB> pending_updates = FoundationPlist . readPlist ( pendingupdatespath ) <TAB> except FoundationPlist . NSPropertyListSerializationException : <TAB><TAB> return 0 <TAB> oldest_date = now = NSDate . date ( ) <TAB> for category in pending_updates : <TAB><TAB> for name in pending_updates [ category ] : <TAB><TAB><TAB> this_date = pending_updates [ category ] [ name ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> oldest_date = this_date <TAB> return now . timeIntervalSinceDate_ ( oldest_date ) / ( 24 * 60 * 60 )",if this_date < oldest_date :,if this_date < oldest_date :,100.0,100.00,True
1519,"def _try_read_gpg ( path ) : <TAB> path = os . path . expanduser ( path ) <TAB> cmd = _gpg_cmd ( ) + [ path ] <TAB> log . debug ( "" gpg cmd:  %s "" , cmd ) <TAB> try : <TAB><TAB> p = subprocess . Popen ( <TAB><TAB><TAB> cmd , env = os . environ , stdout = subprocess . PIPE , stderr = subprocess . PIPE <TAB><TAB> ) <TAB> except OSError as e : <TAB><TAB> log . error ( "" cannot decode  %s  with command  ' %s '  ( %s ) "" , path , ""   "" . join ( cmd ) , e ) <TAB> else : <TAB><TAB> out , err = p . communicate ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> log . error ( err . decode ( errors = "" replace "" ) . strip ( ) ) <TAB><TAB><TAB> return None <TAB><TAB> return out . decode ( errors = "" replace "" )",if p . returncode != 0 :,if err :,69.4349583574234,96.91,False
1520,"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB> if isinstance ( v [ i ] , dict ) : <TAB><TAB><TAB><TAB><TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB> d [ k ] = sorted ( v ) <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","if isinstance ( v , list ) :","if isinstance ( v , list ) :",100.0,100.00,True
1521,"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> args = [ point , index ] <TAB><TAB> else : <TAB><TAB><TAB> args = [ point ] <TAB><TAB> if pass_widget : <TAB><TAB><TAB> args . append ( widget ) <TAB><TAB> try_callback ( callback , * args ) <TAB> return",if num > 1 :,if pass_index :,93.09021386913581,96.83,False
1522,"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB><TAB> new_parameter = copy . deepcopy ( hp ) <TAB><TAB> # Allow for an empty top-level parameter <TAB><TAB> <MASK> <TAB><TAB><TAB> new_parameter . name = prefix <TAB><TAB> elif not prefix == "" "" : <TAB><TAB><TAB> new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB><TAB> new_parameters . append ( new_parameter ) <TAB> for hp in new_parameters : <TAB><TAB> _add_hp ( master_cs , hp )","if new_parameter . name == """" :",if parent_hp is not None and new_parameter . name == delimiter :,97.21387412221799,94.84,False
1523,"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . server . stop ( ) <TAB><TAB> if self . sl_hdlr : <TAB><TAB><TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB><TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,75.0,100.00,True
1524,"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB> """"""Uninstall all apps"""""" <TAB> our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB> output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB> pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB> pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB> pkgs = list ( pkgs ) <TAB> for pkg_name in pkgs : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" uninstalling "" , pkg_name , ""   "" , end = "" "" , flush = True ) <TAB><TAB> ok = self . app_uninstall ( pkg_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" OK "" if ok else "" FAIL "" ) <TAB> return pkgs",if verbose :,if verbose :,100.0,100.00,True
1525,"def httpapi ( self , arg , opts ) : <TAB> sc = HttpAPIStatsCollector ( ) <TAB> headers = [ "" #Item "" , "" Value "" ] <TAB> table = [ ] <TAB> for k , v in sc . get ( ) . getStats ( ) . items ( ) : <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> v = json . dumps ( v ) <TAB><TAB> row = [ ] <TAB><TAB> row . append ( "" # %s "" % k ) <TAB><TAB> <MASK> <TAB><TAB><TAB> row . append ( formatDateTime ( v ) ) <TAB><TAB> else : <TAB><TAB><TAB> row . append ( v ) <TAB><TAB> table . append ( row ) <TAB> self . protocol . sendData ( <TAB><TAB> tabulate ( table , headers , tablefmt = "" plain "" , numalign = "" left "" ) . encode ( "" ascii "" ) <TAB> )","if k [ - 3 : ] == ""_at"" :","if isinstance ( v , datetime . datetime ) :",93.64810796042825,94.28,False
1526,"def Get_Gene ( self , id ) : <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self . Get ( id ) <TAB> if not entry : <TAB><TAB> return None <TAB> GN = "" "" <TAB> for line in string . split ( entry , "" \n "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> GN = string . strip ( line [ 5 : ] ) <TAB><TAB><TAB> if GN [ - 1 ] == "" . "" : <TAB><TAB><TAB><TAB> GN = GN [ 0 : - 1 ] <TAB><TAB><TAB> return GN <TAB><TAB> if line [ 0 : 2 ] == "" // "" : <TAB><TAB><TAB> break <TAB> return GN","if line [ 0 : 5 ] == ""GN   "" :","if line [ 0 : 5 ] == ""gn"" :",98.53673210817186,98.77,False
1527,"def replace_dir_vars ( path , d ) : <TAB> """"""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})"""""" <TAB> dirvars = { } <TAB> # Sort by length so we get the variables we're interested in first <TAB> for var in sorted ( list ( d . keys ( ) ) , key = len ) : <TAB><TAB> if var . endswith ( "" dir "" ) and var . lower ( ) == var : <TAB><TAB><TAB> value = d . getVar ( var ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dirvars [ value ] = var <TAB> for dirpath in sorted ( list ( dirvars . keys ( ) ) , reverse = True ) : <TAB><TAB> path = path . replace ( dirpath , "" $ { %s } "" % dirvars [ dirpath ] ) <TAB> return path","if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",if value :,94.15568253678518,90.39,False
1528,"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> source = os . path . join ( root , filename ) <TAB><TAB><TAB> with open ( source , "" r "" ) as f : <TAB><TAB><TAB><TAB> lines = f . readlines ( ) <TAB><TAB><TAB> if len ( lines ) < 1 : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> with open ( source , "" w "" ) as f : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> f . write ( lines [ 0 ] ) <TAB><TAB><TAB><TAB> for line in lines [ 1 : ] : <TAB><TAB><TAB><TAB><TAB> f . write ( line )",if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,"if lines [ 0 ] . startswith ( ""timestamp"" ) :",68.83477412918796,94.04,False
1529,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB><TAB> # None is a placeholder for any plugin not having a defined order <TAB><TAB> <MASK> <TAB><TAB><TAB> all_plugins + = [ <TAB><TAB><TAB><TAB> plugin <TAB><TAB><TAB><TAB> for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB> if name not in self . plugins_callback_order and plugin . is_activated <TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> plugin = self . plugins [ name ] <TAB><TAB><TAB> if plugin . is_activated : <TAB><TAB><TAB><TAB> all_plugins . append ( plugin ) <TAB> return all_plugins",if name is None :,if name is None :,100.0,100.00,True
1530,"def test_query_level ( self ) : <TAB> "" Tests querying at a level other than max "" <TAB> # level 2 <TAB> l2 = set ( ) <TAB> for p in self . tile_paths : <TAB><TAB> l2 . add ( p [ 0 : 2 ] ) <TAB> for path in iterate_base4 ( 2 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertTrue ( self . tree . query_path ( path ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertFalse ( self . tree . query_path ( path ) ) <TAB> # level 1: <TAB> self . assertTrue ( self . tree . query_path ( ( 0 , ) ) ) <TAB> self . assertTrue ( self . tree . query_path ( ( 1 , ) ) ) <TAB> self . assertTrue ( self . tree . query_path ( ( 2 , ) ) ) <TAB> self . assertFalse ( self . tree . query_path ( ( 3 , ) ) )",if path in l2 :,if l2 :,98.81265945078667,98.51,False
1531,"def program_exists ( name ) : <TAB> paths = ( os . getenv ( "" PATH "" ) or os . defpath ) . split ( os . pathsep ) <TAB> for p in paths : <TAB><TAB> fn = "" %s / %s "" % ( p , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return not os . path . isdir ( fn ) and os . access ( fn , os . X_OK )",if os . path . exists ( fn ) :,if os . path . exists ( fn ) :,100.0,100.00,True
1532,"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB><TAB> for patching in patched . patchings : <TAB><TAB><TAB> arg = exit_stack . enter_context ( patching ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> keywargs . update ( arg ) <TAB><TAB><TAB> elif patching . new is DEFAULT : <TAB><TAB><TAB><TAB> extra_args . append ( arg ) <TAB><TAB> args + = tuple ( extra_args ) <TAB><TAB> yield ( args , keywargs )",if patching . attribute_name is not None :,if patching . new is KEY :,94.5570252272821,95.71,False
1533,"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB><TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB><TAB><TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB> if k == neighbors . CONNECT_MODE : <TAB><TAB><TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . ENABLED :,if k == neighbors . MULTI_EXIT_DISC :,98.60694803356351,96.33,False
1534,"def calcUniqueStates ( self ) : <TAB> # Here we show which colors can be relied on to map to an <TAB> # internal state.  The current position will be at the first <TAB> # character in the buffer styled that color, so this might not <TAB> # work in all cases. <TAB> self . uniqueStates = { } <TAB> for k in self . holdUniqueStates . keys ( ) : <TAB><TAB> v = self . holdUniqueStates [ k ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . uniqueStates [ k ] = v . keys ( ) [ 0 ] <TAB><TAB><TAB> log . debug ( "" Map style [ %s ] to state [ %s ] "" , k , v . keys ( ) [ 0 ] ) <TAB><TAB> log . debug ( "" Style [ %s ] maps to states [ %s ] "" , k , "" ,  "" . join ( v . keys ( ) ) ) <TAB> self . holdUniqueStates = None",if len ( v . keys ( ) ) == 1 :,if v :,71.8162211391185,94.57,False
1535,"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB><TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB><TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB><TAB> elif "" filename "" in handler . keys ( ) : <TAB><TAB><TAB> filename = handler [ "" filename "" ] <TAB><TAB><TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB><TAB><TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config )",if handler_id not in used_handlers :,if handler_id in used_handlers :,99.13718575087967,99.03,False
1536,"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB><TAB> <MASK> <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB><TAB> if self . locations and machine . location in self . locations : <TAB><TAB><TAB> selected_machines . append ( machine ) <TAB> return selected_machines",if self . _args . host and self . _args . host == machine . name :,"if self . _machine_match ( machine . name , self . name ) :",90.4559197512208,91.24,False
1537,"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB><TAB> key = "" pocsuite_target "" <TAB><TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB><TAB> logger . info ( info_msg ) <TAB><TAB> targets = r . get ( key ) <TAB><TAB> count = 0 <TAB><TAB> if targets : <TAB><TAB><TAB> for target in targets : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> count + = 1 <TAB><TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB><TAB> logger . info ( info_msg )",if self . add_target ( target ) :,"if target . name == ""pocsuite_target"" :",71.67379533112586,95.00,False
1538,"def tearDown ( self ) : <TAB> suffix = str ( os . getgid ( ) ) <TAB> cli = monitoring_v3 . MetricServiceClient ( ) <TAB> for md in cli . list_metric_descriptors ( "" projects/ {} "" . format ( PROJECT ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> cli . delete_metric_descriptor ( md . name ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> pass","if ""OpenCensus"" in md . name and suffix in md . name :",if md . name . endswith ( suffix ) :,89.63684233193666,90.84,False
1539,"def InitializeColours ( self ) : <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB><TAB> c = self . _colourData . GetCustomColour ( i ) <TAB><TAB> if c . IsOk ( ) : <TAB><TAB><TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB><TAB> else : <TAB><TAB><TAB> self . _customColours [ i ] = wx . WHITE <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _colourSelection = i",if c == curr :,if c . GetColour ( ) == curr :,74.17538407277202,96.86,False
1540,"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB><TAB> if isinstance ( index , int ) : <TAB><TAB><TAB> if index < 0 or index > = len ( self . features ) : <TAB><TAB><TAB><TAB> raise IndexError ( index ) <TAB><TAB><TAB> if self . features [ index ] is None : <TAB><TAB><TAB><TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB> self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB> return self . features [ index ] <TAB><TAB> elif isinstance ( index , slice ) : <TAB><TAB><TAB> indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]",if feature :,if len ( feature ) > 2 :,90.62205881669014,97.49,False
1541,"def _get_data_from_buffer ( obj ) : <TAB> try : <TAB><TAB> view = memoryview ( obj ) <TAB> except TypeError : <TAB><TAB> # try to use legacy buffer protocol if 2.7, otherwise re-raise <TAB><TAB> <MASK> <TAB><TAB><TAB> view = memoryview ( buffer ( obj ) ) <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" using old buffer interface to unpack  %s ;  "" <TAB><TAB><TAB><TAB> "" this leads to unpacking errors if slicing is used and  "" <TAB><TAB><TAB><TAB> "" will be removed in a future version "" % type ( obj ) , <TAB><TAB><TAB><TAB> RuntimeWarning , <TAB><TAB><TAB><TAB> stacklevel = 3 , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> raise <TAB> if view . itemsize != 1 : <TAB><TAB> raise ValueError ( "" cannot unpack from multi-byte object "" ) <TAB> return view",if PY2 :,"if sys . version_info >= ( 2 , 7 ) :",97.58250571049845,94.97,False
1542,"def import_modules ( modules , safe = True ) : <TAB> """"""Safely import a list of *modules*"""""" <TAB> all = [ ] <TAB> for mname in modules : <TAB><TAB> if mname . endswith ( "" .* "" ) : <TAB><TAB><TAB> to_load = expand_star ( mname ) <TAB><TAB> else : <TAB><TAB><TAB> to_load = [ mname ] <TAB><TAB> for module in to_load : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> all . append ( import_module ( module ) ) <TAB><TAB><TAB> except ImportError : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise <TAB> return all",if not safe :,if not safe :,100.0,100.00,True
1543,"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB><TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB><TAB> if type == "" V "" : <TAB><TAB><TAB> write_vuint ( port , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> write_vint ( port , value ) <TAB><TAB> elif type == "" s "" : <TAB><TAB><TAB> write_bvec ( port , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( )","elif type == ""v"" :","elif type == ""v"" :",100.0,100.00,True
1544,"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB><TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . mkdir ( folder ) <TAB><TAB><TAB> init_path = join ( folder , "" __init__.py "" ) <TAB><TAB><TAB> if not exists ( init_path ) : <TAB><TAB><TAB><TAB> create_file ( init_path )",if not exists ( folder ) :,if not exists ( folder ) :,100.0,100.00,True
1545,"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB><TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB><TAB> node_specific_config = self . available_node_types [ node_type ] <TAB><TAB> if fields_key in node_specific_config : <TAB><TAB><TAB> fields = node_specific_config [ fields_key ] <TAB> return fields",if node_type not in self . available_node_types :,if node_type not in self . available_node_types :,100.0,100.00,True
1546,"def _maybe_fix_sequence_in_union ( <TAB> aliases : List [ Alias ] , typecst : cst . SubscriptElement ) - > cst . SubscriptElement : <TAB> slc = typecst . slice <TAB> if isinstance ( slc , cst . Index ) : <TAB><TAB> val = slc . value <TAB><TAB> <MASK> <TAB><TAB><TAB> return cst . ensure_type ( <TAB><TAB><TAB><TAB> typecst . deep_replace ( val , _get_clean_type_from_subscript ( aliases , val ) ) , <TAB><TAB><TAB><TAB> cst . SubscriptElement , <TAB><TAB><TAB> ) <TAB> return typecst","if isinstance ( val , cst . Subscript ) :","if isinstance ( val , cst . UnionType ) :",98.55466329811861,98.47,False
1547,"def cancel_download ( self , downloads ) : <TAB> # Make sure we're always dealing with a list <TAB> if isinstance ( downloads , Download ) : <TAB><TAB> downloads = [ downloads ] <TAB> for download in downloads : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . cancel_current_download ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . __paused = True <TAB><TAB><TAB> new_queue = queue . Queue ( ) <TAB><TAB><TAB> while not self . __queue . empty ( ) : <TAB><TAB><TAB><TAB> queued_download = self . __queue . get ( ) <TAB><TAB><TAB><TAB> if download == queued_download : <TAB><TAB><TAB><TAB><TAB> download . cancel ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> new_queue . put ( queued_download ) <TAB><TAB><TAB> self . __queue = new_queue <TAB><TAB><TAB> self . __paused = False",if download == self . __current_download :,if self . __paused :,72.70281098580156,96.86,False
1548,"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB><TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB><TAB> if account . discriminator == "" easaccount "" : <TAB><TAB><TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB><TAB> else : <TAB><TAB><TAB> create_categories_for_folders ( account , db_session ) <TAB><TAB> <MASK> <TAB><TAB><TAB> set_labels_for_imapuids ( account , db_session ) <TAB><TAB> db_session . commit ( )","if account . discriminator == ""gmailaccount"" :","if account . discriminator == ""imapuids"" :",98.67233755766469,98.71,False
1549,"def __init__ ( self , fmt = None , * args ) : <TAB> if not isinstance ( fmt , BaseException ) : <TAB><TAB> Error . __init__ ( self , fmt , * args ) <TAB> else : <TAB><TAB> e = fmt <TAB><TAB> cls = e . __class__ <TAB><TAB> fmt = "" %s . %s :  %s "" % ( cls . __module__ , cls . __name__ , e ) <TAB><TAB> tb = sys . exc_info ( ) [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> fmt + = "" \n "" <TAB><TAB><TAB> fmt + = "" "" . join ( traceback . format_tb ( tb ) ) <TAB><TAB> Error . __init__ ( self , fmt )",if tb :,if tb :,100.0,100.00,True
1550,"def setLabel ( self , label ) : <TAB> if label is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . label . scene ( ) . removeItem ( self . label ) <TAB><TAB><TAB> self . label = None <TAB> else : <TAB><TAB> if self . label is None : <TAB><TAB><TAB> self . label = TextItem ( ) <TAB><TAB><TAB> self . label . setParentItem ( self ) <TAB><TAB> self . label . setText ( label ) <TAB><TAB> self . _updateLabel ( )",if self . label is not None :,if self . label :,94.77793388855702,96.83,False
1551,"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB><TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . handle_request ( ) <TAB><TAB> if self . event is not None and self . event . is_set ( ) : <TAB><TAB><TAB> break",if rd :,if rd :,100.0,100.00,True
1552,"def generateCompressedFile ( inputfile , outputfile , formatstring ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> in_file = open ( inputfile , "" rb "" ) <TAB><TAB><TAB> in_data = in_file . read ( ) <TAB><TAB><TAB> out_file = open ( inputfile + "" .xz "" , "" wb "" ) <TAB><TAB><TAB> out_file . write ( xz . compress ( in_data ) ) <TAB><TAB><TAB> in_file . close ( ) <TAB><TAB><TAB> out_file . close ( ) <TAB><TAB> else : <TAB><TAB><TAB> tarout = tarfile . open ( outputfile , formatstring ) <TAB><TAB><TAB> tarout . add ( inputfile , arcname = os . path . basename ( inputfile ) ) <TAB><TAB><TAB> tarout . close ( ) <TAB> except Exception as e : <TAB><TAB> print ( e ) <TAB><TAB> return False <TAB> return True","if formatstring == ""w:xz"" :","if os . path . isfile ( inputfile + "".xz"" ) :",95.19882168707396,94.71,False
1553,"def _datastore_get_handler ( signal , sender , keys , * * kwargs ) : <TAB> txn = current_transaction ( ) <TAB> if txn : <TAB><TAB> for key in keys : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise PreventedReadError ( <TAB><TAB><TAB><TAB><TAB> "" Attempted to read key ( %s : %s ) inside a transaction  "" <TAB><TAB><TAB><TAB><TAB> "" where it was marked protected "" % ( key . kind ( ) , key . id_or_name ( ) ) <TAB><TAB><TAB><TAB> ) <TAB><TAB> txn . _fetched_keys . update ( set ( keys ) )",if key in txn . _protected_keys :,if key . kind ( ) in txn . _fetched_keys :,94.98520839207612,95.70,False
1554,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 16 : <TAB><TAB><TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
1555,"def write_vuint ( port , x ) : <TAB> if x < 0 : <TAB><TAB> raise Exception ( "" vuints must not be negative "" ) <TAB> elif x == 0 : <TAB><TAB> port . write ( "" \0 "" ) <TAB> else : <TAB><TAB> while x : <TAB><TAB><TAB> seven_bits = x & 0x7F <TAB><TAB><TAB> x >> = 7 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> port . write ( chr ( 0x80 | seven_bits ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> port . write ( chr ( seven_bits ) )",if x :,if x & 0x80 :,71.0649253131524,97.99,False
1556,"def _expand_srcs ( self ) : <TAB> """"""Expand src to [(src, full_path)]"""""" <TAB> result = [ ] <TAB> for src in self . srcs : <TAB><TAB> full_path = self . _source_file_path ( src ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Assume generated <TAB><TAB><TAB> full_path = self . _target_file_path ( src ) <TAB><TAB> result . append ( ( src , full_path ) ) <TAB> return result",if not os . path . exists ( full_path ) :,if not full_path :,87.32558352613185,92.99,False
1557,"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB><TAB> if item . nodeid . startswith ( "" tests/ops "" ) : <TAB><TAB><TAB> if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",75.0,100.00,True
1558,"def set_shape ( self , shape ) : <TAB> """"""Sets a shape."""""" <TAB> if self . _shape is not None : <TAB><TAB> logger . warning ( ' Modifying the shape of Placeholder  "" %s "" . ' , self . name ) <TAB> if not isinstance ( shape , ( list , tuple ) ) : <TAB><TAB> shape = ( shape , ) <TAB> shape = tuple ( x if x != "" None "" else None for x in shape ) <TAB> for x in shape : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ParsingError ( <TAB><TAB><TAB><TAB> ' All entries in  "" shape ""  must be integers, or in special  ' <TAB><TAB><TAB><TAB> "" cases None. Shape is:  {} "" . format ( shape ) <TAB><TAB><TAB> ) <TAB> self . _shape = shape","if not isinstance ( x , ( int , type ( None ) ) ) :","if not isinstance ( shape , ( list , tuple ) ) :",81.01814092738512,95.78,False
1559,"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB><TAB> for field_name in field_names : <TAB><TAB><TAB> field_name = field_name . lower ( ) <TAB><TAB><TAB> if "" : "" in line : <TAB><TAB><TAB><TAB> left , right = line . split ( "" : "" , 1 ) <TAB><TAB><TAB><TAB> left = left . strip ( ) . lower ( ) <TAB><TAB><TAB><TAB> right = right . strip ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if cant_be_number : <TAB><TAB><TAB><TAB><TAB><TAB> if not right . isdigit ( ) : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> return right <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> return right <TAB> return None",if left == field_name and len ( right ) > 0 :,if left . isdigit ( ) and right . isdigit ( ) :,67.15469573298077,95.75,False
1560,"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB><TAB> value = getattr ( self , attribute . code , None ) <TAB><TAB> if value is None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> attribute . validate_value ( value ) <TAB><TAB><TAB> except ValidationError as e : <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB><TAB><TAB><TAB> )",if attribute . required :,if not attribute . is_blank :,73.2271468984991,97.43,False
1561,"def append ( self , s ) : <TAB> buf = self . buf <TAB> if buf is None : <TAB><TAB> strbuf = self . strbuf <TAB><TAB> <MASK> <TAB><TAB><TAB> self . strbuf = strbuf + s <TAB><TAB><TAB> return <TAB><TAB> buf = self . _create_buffer ( ) <TAB> buf . append ( s ) <TAB> # use buf.__len__ rather than len(buf) FBO of not getting <TAB> # OverflowError on Python 2 <TAB> sz = buf . __len__ ( ) <TAB> if not self . overflowed : <TAB><TAB> if sz > = self . overflow : <TAB><TAB><TAB> self . _set_large_buffer ( )",if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,if strbuf is not None :,88.97964788355371,92.48,False
1562,"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB><TAB> RequiredArgumentMissingError , <TAB><TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB><TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB><TAB> if namespace . name is None : <TAB><TAB><TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> <MASK> <TAB><TAB> if namespace . name is None : <TAB><TAB><TAB> raise RequiredArgumentMissingError ( "" --name is also required "" )",if namespace . by_subscription is not None :,if namespace . by_subscription is not None :,100.0,100.00,True
1563,"def Handle ( self , args , context = None ) : <TAB> for client_id in args . client_ids : <TAB><TAB> cid = str ( client_id ) <TAB><TAB> data_store . REL_DB . RemoveClientLabels ( cid , context . username , args . labels ) <TAB><TAB> labels_to_remove = set ( args . labels ) <TAB><TAB> existing_labels = data_store . REL_DB . ReadClientLabels ( cid ) <TAB><TAB> for label in existing_labels : <TAB><TAB><TAB> labels_to_remove . discard ( label . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> idx = client_index . ClientIndex ( ) <TAB><TAB><TAB> idx . RemoveClientLabels ( cid , labels_to_remove )",if labels_to_remove :,if labels_to_remove :,100.0,100.00,True
1564,"def delete_snapshot ( self , snapshot ) : <TAB> snap_name = self . _get_snap_name ( snapshot [ "" id "" ] ) <TAB> LOG . debug ( "" Deleting snapshot ( %s ) "" , snapshot [ "" id "" ] ) <TAB> self . client_login ( ) <TAB> try : <TAB><TAB> self . client . delete_snapshot ( snap_name , self . backend_type ) <TAB> except exception . DotHillRequestError as ex : <TAB><TAB> # if the volume wasn't found, ignore the error <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> LOG . exception ( "" Deleting snapshot  %s  failed "" , snapshot [ "" id "" ] ) <TAB><TAB> raise exception . Invalid ( ex ) <TAB> finally : <TAB><TAB> self . client_logout ( )","if ""The volume was not found on this system."" in ex . args :",if ex . code == 404 :,95.03005245909088,92.38,False
1565,"def jobs ( self ) : <TAB> # How many jobs have we done? <TAB> total_processed = 0 <TAB> for jobEntity in self . jobItems . query_entities ( ) : <TAB><TAB> # Process the items in the page <TAB><TAB> yield AzureJob . fromEntity ( jobEntity ) <TAB><TAB> total_processed + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> # Produce some feedback for the user, because this can take <TAB><TAB><TAB> # a long time on, for example, Azure <TAB><TAB><TAB> logger . debug ( "" Processed  %d  total jobs "" % total_processed ) <TAB> logger . debug ( "" Processed  %d  total jobs "" % total_processed )",if total_processed % 1000 == 0 :,if total_processed > self . total_processes :,72.46075555224449,95.79,False
1566,def run ( self ) : <TAB> while not self . completed : <TAB><TAB> if self . block : <TAB><TAB><TAB> time . sleep ( self . period ) <TAB><TAB> else : <TAB><TAB><TAB> self . _completed . wait ( self . period ) <TAB><TAB> self . counter + = 1 <TAB><TAB> try : <TAB><TAB><TAB> self . callback ( self . counter ) <TAB><TAB> except Exception : <TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . timeout is not None : <TAB><TAB><TAB> dt = time . time ( ) - self . _start_time <TAB><TAB><TAB> if dt > self . timeout : <TAB><TAB><TAB><TAB> self . stop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . stop ( ),if self . counter == self . count :,elif dt < self . _stop_time :,80.07976148767277,95.74,False
1567,"def get_instance ( cls , pool_size = None ) : <TAB> if cls . _instance is not None : <TAB><TAB> return cls . _instance <TAB> # Lazy init <TAB> with cls . _SINGLETON_LOCK : <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _instance = cls ( <TAB><TAB><TAB><TAB> ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB><TAB><TAB> ) <TAB> return cls . _instance",if cls . _instance is None :,"if not hasattr ( cls , ""_instance"" ) :",94.07294589012591,91.98,False
1568,"def set_state ( self , state ) : <TAB> if self . _inhibit_play : <TAB><TAB> # PLAYING, PAUSED change the state for after buffering is finished, <TAB><TAB> # everything else aborts buffering <TAB><TAB> <MASK> <TAB><TAB><TAB> # abort <TAB><TAB><TAB> self . __set_inhibit_play ( False ) <TAB><TAB><TAB> self . bin . set_state ( state ) <TAB><TAB><TAB> return <TAB><TAB> self . _wanted_state = state <TAB> else : <TAB><TAB> self . bin . set_state ( state )","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",if state == PAUSED :,90.54259095578148,90.22,False
1569,"def seen_add ( options ) : <TAB> seen_name = options . add_value <TAB> if is_imdb_url ( seen_name ) : <TAB><TAB> console ( "" IMDB url detected, try to parse ID "" ) <TAB><TAB> imdb_id = extract_id ( seen_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> seen_name = imdb_id <TAB><TAB> else : <TAB><TAB><TAB> console ( "" Could not parse IMDB ID "" ) <TAB> db . add ( seen_name , "" cli_add "" , { "" cli_add "" : seen_name } ) <TAB> console ( "" Added  %s  as seen. This will affect all tasks. "" % seen_name )",if imdb_id :,if imdb_id :,100.0,100.00,True
1570,"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB><TAB> response = self . fetch ( "" /?error=1 "" ) <TAB><TAB> if not self . http1 : <TAB><TAB><TAB> self . skipTest ( "" requires HTTP/1.x "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" curl client accepts invalid headers "" ) <TAB><TAB> self . assertEqual ( response . code , 599 )",if self . http_client . configured_class != SimpleAsyncHTTPClient :,if not response . headers :,70.72083728323422,91.60,False
1571,"def set_related_perm ( _mapper : Mapper , _connection : Connection , target : Slice ) - > None : <TAB> src_class = target . cls_model <TAB> id_ = target . datasource_id <TAB> if id_ : <TAB><TAB> ds = db . session . query ( src_class ) . filter_by ( id = int ( id_ ) ) . first ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> target . perm = ds . perm <TAB><TAB><TAB> target . schema_perm = ds . schema_perm",if ds :,if ds :,100.0,100.00,True
1572,"def on_modified_async ( self , view ) : <TAB> if self . is_command_line ( view ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> view . run_command ( "" text_pastry_selection_preview "" )","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :","if view . run_command ( ""text_pastry_selection_preview"" )",35.141858584112356,65.60,False
1573,"def _improve_answer_span ( <TAB> doc_tokens , input_start , input_end , tokenizer , orig_answer_text ) : <TAB> """"""Returns tokenized answer spans that better match the annotated answer."""""" <TAB> tok_answer_text = ""   "" . join ( tokenizer . tokenize ( orig_answer_text ) ) <TAB> for new_start in range ( input_start , input_end + 1 ) : <TAB><TAB> for new_end in range ( input_end , new_start - 1 , - 1 ) : <TAB><TAB><TAB> text_span = ""   "" . join ( doc_tokens [ new_start : ( new_end + 1 ) ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return new_start , new_end <TAB> return input_start , input_end",if text_span == tok_answer_text :,if text_span == tok_answer_text :,100.0,100.00,True
1574,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 18 : <TAB><TAB><TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 26 : <TAB><TAB><TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 34 : <TAB><TAB><TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
1575,"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB><TAB> for array_item in obj : <TAB><TAB><TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if obj [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB><TAB> except ( KeyError , IndexError , TypeError ) : <TAB><TAB><TAB> pass <TAB><TAB> for item_key in obj : <TAB><TAB><TAB> if item_key != "" sourceVault "" : <TAB><TAB><TAB><TAB> _add_resource_group ( obj [ item_key ] )","if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :","if ""resourceGroup"" not in obj :",89.0129473760841,92.33,False
1576,"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , DECODE ) <TAB> version = DECODE_VERSION <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB><TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # An older version exists, so remove these outdated files. <TAB><TAB><TAB> build_data . remove_dir ( dpath ) <TAB><TAB> build_data . make_dir ( dpath ) <TAB><TAB> # Download the data. <TAB><TAB> for downloadable_file in RESOURCES : <TAB><TAB><TAB> downloadable_file . download_file ( dpath ) <TAB><TAB> # Mark the data as built. <TAB><TAB> build_data . mark_done ( dpath , version_string = version )",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,100.0,100.00,True
1577,"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i , entry in enumerate ( self . reprentries ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tw . line ( "" "" ) <TAB><TAB> entry . toterminal ( tw ) <TAB><TAB> if i < len ( self . reprentries ) - 1 : <TAB><TAB><TAB> next_entry = self . reprentries [ i + 1 ] <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> entry . style == "" long "" <TAB><TAB><TAB><TAB> or entry . style == "" short "" <TAB><TAB><TAB><TAB> and next_entry . style == "" long "" <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> tw . sep ( self . entrysep ) <TAB> if self . extraline : <TAB><TAB> tw . line ( self . extraline )","if entry . style == ""long"" :",if last_style is not None :,72.63077592811428,96.30,False
1578,"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB><TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> found + = 1 <TAB><TAB><TAB> if found == 2 : <TAB><TAB><TAB><TAB> if division in "" \n "" . join ( lines ) : <TAB><TAB><TAB><TAB><TAB> break # already in the right place <TAB><TAB><TAB><TAB> lines . insert ( i + 1 , "" "" ) <TAB><TAB><TAB><TAB> lines . insert ( i + 2 , division ) <TAB><TAB><TAB><TAB> break <TAB> return "" \n "" . join ( lines )","if line . startswith ( '""""""' ) :",if line . startswith ( division ) :,94.34207837275387,97.08,False
1579,def run_on_module ( self ) : <TAB> try : <TAB><TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB><TAB> if self . base . conf . strict : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise e <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> e . module_depsolv_errors <TAB><TAB><TAB><TAB> and e . module_depsolv_errors [ 1 ] <TAB><TAB><TAB><TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> raise e <TAB><TAB> logger . error ( str ( e ) ),if e . no_match_group_specs or e . error_group_specs :,if e . module_base . conf . strict :,69.94351803883907,92.83,False
1580,"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB><TAB> if size == 0 : <TAB><TAB><TAB> bsize = 0 <TAB><TAB> elif size < = 3 : <TAB><TAB><TAB> bsize = 4 <TAB><TAB> elif size < = 6 : <TAB><TAB><TAB> bsize = 8 <TAB><TAB> <MASK> <TAB><TAB><TAB> bsize = 12 <TAB><TAB> elif size < = 12 : <TAB><TAB><TAB> bsize = 16 <TAB><TAB> else : <TAB><TAB><TAB> bsize = 20 <TAB><TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize )",elif size <= 9 :,elif size <= 7 :,99.00060752674547,98.87,False
1581,"def is_valid ( self ) : <TAB> """"""Determines whether file is valid for this reader"""""" <TAB> blocklist = self . open ( ) <TAB> valid = True <TAB> for line in blocklist : <TAB><TAB> line = decode_bytes ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> ( start , end ) = self . parse ( line ) <TAB><TAB><TAB><TAB> if not re . match ( r "" ^( \ d { 1,3} \ .) {4} $ "" , start + "" . "" ) or not re . match ( <TAB><TAB><TAB><TAB><TAB> r "" ^( \ d { 1,3} \ .) {4} $ "" , end + "" . "" <TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB> valid = False <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> valid = False <TAB><TAB><TAB> break <TAB> blocklist . close ( ) <TAB> return valid",if not self . is_ignored ( line ) :,if line :,72.28664919581117,96.33,False
1582,"def next ( self ) : <TAB> while self . index < len ( self . data ) : <TAB><TAB> uid = self . _read_next_word ( ) <TAB><TAB> dont_care = self . _read_next_word ( ) <TAB><TAB> entry = self . _read_next_string ( ) <TAB><TAB> total_size = int ( 4 + 4 + len ( entry ) ) <TAB><TAB> count = int ( total_size / self . SIZE ) <TAB><TAB> if count == 0 : <TAB><TAB><TAB> mod = self . SIZE - total_size <TAB><TAB> else : <TAB><TAB><TAB> mod = self . SIZE - int ( total_size - ( count * self . SIZE ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> remainder = self . _read_next_block ( mod ) <TAB><TAB> yield ( uid , entry )",if mod > 0 :,if mod != 0 :,98.99756276760844,98.46,False
1583,"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB><TAB> out + = self . _str_header ( name ) <TAB><TAB> for param in self [ name ] : <TAB><TAB><TAB> parts = [ ] <TAB><TAB><TAB> if param . name : <TAB><TAB><TAB><TAB> parts . append ( param . name ) <TAB><TAB><TAB> if param . type : <TAB><TAB><TAB><TAB> parts . append ( param . type ) <TAB><TAB><TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> out + = self . _str_indent ( param . desc ) <TAB><TAB> out + = [ "" "" ] <TAB> return out","if param . desc and """" . join ( param . desc ) . strip ( ) :",if param . desc :,88.86957792709302,93.25,False
1584,"def assert_backend ( self , expected_translated , language = "" cs "" ) : <TAB> """"""Check that backend has correct data."""""" <TAB> translation = self . get_translation ( language ) <TAB> translation . commit_pending ( "" test "" , None ) <TAB> store = translation . component . file_format_cls ( translation . get_filename ( ) , None ) <TAB> messages = set ( ) <TAB> translated = 0 <TAB> for unit in store . content_units : <TAB><TAB> id_hash = unit . id_hash <TAB><TAB> self . assertFalse ( id_hash in messages , "" Duplicate string in in backend file! "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> translated + = 1 <TAB> self . assertEqual ( <TAB><TAB> translated , <TAB><TAB> expected_translated , <TAB><TAB> "" Did not found expected number of translations ( {}  !=  {} ). "" . format ( <TAB><TAB><TAB> translated , expected_translated <TAB><TAB> ) , <TAB> )",if unit . is_translated ( ) :,if unit . is_translated :,97.82982087063363,98.64,False
1585,"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . script_running [ 1 : ] <TAB><TAB> elif self . script_last and self . script_last [ 1 ] == name : <TAB><TAB><TAB> return self . script_last [ 1 : ] <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( error )",if self . script_running and self . script_running [ 1 ] == name :,if self . script_running and self . script_running [ 1 ] == name :,100.0,100.00,True
1586,"def dict_no_value_from_proto_list ( obj_list ) : <TAB> d = dict ( ) <TAB> for item in obj_list : <TAB><TAB> possible_dict = json . loads ( item . value_json ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB><TAB><TAB> # Should investigate why the config payload even has 'wandb_version'. <TAB><TAB><TAB> logger . warning ( "" key  ' {} '  has no  ' value '  attribute "" . format ( item . key ) ) <TAB><TAB><TAB> continue <TAB><TAB> d [ item . key ] = possible_dict [ "" value "" ] <TAB> return d","if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :","if ""value"" not in possible_dict :",85.17593582073955,94.08,False
1587,"def visit ( self , node ) : <TAB> """"""dispatcher on node's class/bases name."""""" <TAB> cls = node . __class__ <TAB> try : <TAB><TAB> visitmethod = self . cache [ cls ] <TAB> except KeyError : <TAB><TAB> for subclass in cls . __mro__ : <TAB><TAB><TAB> visitmethod = getattr ( self , subclass . __name__ , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> visitmethod = self . __object <TAB><TAB> self . cache [ cls ] = visitmethod <TAB> visitmethod ( node )",if visitmethod is not None :,if visitmethod is None :,98.40522362114399,98.57,False
1588,"def _get_adapter ( <TAB> mcls , <TAB> reversed_mro : Tuple [ type , . . . ] , <TAB> collection : Dict [ Any , Dict [ type , Adapter ] ] , <TAB> kwargs : Dict [ str , Any ] , ) - > Optional [ Adapter ] : <TAB> registry_key = mcls . get_registry_key ( kwargs ) <TAB> adapters = collection . get ( registry_key ) <TAB> if adapters is None : <TAB><TAB> return None <TAB> result = None <TAB> seen : Set [ Adapter ] = set ( ) <TAB> for base in reversed_mro : <TAB><TAB> for adaptee , adapter in adapters . items ( ) : <TAB><TAB><TAB> found = mcls . _match_adapter ( base , adaptee , adapter ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = found <TAB><TAB><TAB><TAB> seen . add ( found ) <TAB> return result",if found and found not in seen :,if found not in seen :,85.39498658743173,98.82,False
1589,"def test_pt_BR_rg ( self ) : <TAB> for _ in range ( 100 ) : <TAB><TAB> to_test = self . fake . rg ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert re . search ( r "" ^ \ d {8} X "" , to_test ) <TAB><TAB> else : <TAB><TAB><TAB> assert re . search ( r "" ^ \ d {9} $ "" , to_test )","if ""X"" in to_test :",if self . fake . isdigit ( ) :,65.66689327686272,92.87,False
1590,"def get_user_extra_data_by_client_id ( self , client_id , username ) : <TAB> extra_data = { } <TAB> current_client = self . clients . get ( client_id , None ) <TAB> if current_client : <TAB><TAB> for readable_field in current_client . get_readable_fields ( ) : <TAB><TAB><TAB> attribute = list ( <TAB><TAB><TAB><TAB> filter ( <TAB><TAB><TAB><TAB><TAB> lambda f : f [ "" Name "" ] == readable_field , <TAB><TAB><TAB><TAB><TAB> self . users . get ( username ) . attributes , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> extra_data . update ( { attribute [ 0 ] [ "" Name "" ] : attribute [ 0 ] [ "" Value "" ] } ) <TAB> return extra_data",if len ( attribute ) > 0 :,if attribute :,95.21922156229799,97.11,False
1591,"def augment ( self , resources ) : <TAB> super ( ) . augment ( resources ) <TAB> for r in resources : <TAB><TAB> md = r . get ( "" SAMLMetadataDocument "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> root = sso_metadata ( md ) <TAB><TAB> r [ "" IDPSSODescriptor "" ] = root [ "" IDPSSODescriptor "" ] <TAB> return resources",if not md :,if not md :,100.0,100.00,True
1592,"def __init__ ( self , mode = 0 , decode = None ) : <TAB> self . regex = self . REGEX [ mode ] <TAB> self . decode = decode <TAB> if decode : <TAB><TAB> self . header = _ ( <TAB><TAB><TAB> "" ### This log has been decoded with automatic search pattern \n "" <TAB><TAB><TAB> "" ### If some paths are not decoded you can manually decode them with: \n "" <TAB><TAB> ) <TAB><TAB> self . header + = "" ###  ' backintime --quiet  "" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . header + = ' --profile  "" %s ""   ' % decode . config . profileName ( ) <TAB><TAB> self . header + = "" --decode <path> ' \n \n "" <TAB> else : <TAB><TAB> self . header = "" """,if int ( decode . config . currentProfile ( ) ) > 1 :,if decode . config :,69.16042062176165,94.57,False
1593,"def _get_dynamic_attr ( self , attname , obj , default = None ) : <TAB> try : <TAB><TAB> attr = getattr ( self , attname ) <TAB> except AttributeError : <TAB><TAB> return default <TAB> if callable ( attr ) : <TAB><TAB> # Check co_argcount rather than try/excepting the function and <TAB><TAB> # catching the TypeError, because something inside the function <TAB><TAB> # may raise the TypeError. This technique is more accurate. <TAB><TAB> try : <TAB><TAB><TAB> code = six . get_function_code ( attr ) <TAB><TAB> except AttributeError : <TAB><TAB><TAB> code = six . get_function_code ( attr . __call__ ) <TAB><TAB> <MASK> # one argument is 'self' <TAB><TAB><TAB> return attr ( obj ) <TAB><TAB> else : <TAB><TAB><TAB> return attr ( ) <TAB> return attr",if code . co_argcount == 2 :,if code == co_argcount :,98.04599125116434,97.37,False
1594,"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB><TAB> tokentype , token = tokens [ i ] <TAB><TAB> i + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> while ( <TAB><TAB><TAB> i + 1 < len ( tokens ) <TAB><TAB><TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB><TAB><TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB><TAB> ) : <TAB><TAB><TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB><TAB><TAB> i + = 2 <TAB><TAB> if token == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> if token in pykeywords : <TAB><TAB><TAB> continue <TAB><TAB> if token [ 0 ] in "" .0123456789 "" : <TAB><TAB><TAB> continue <TAB><TAB> yield token","if tokentype != ""id"" :","if tokentype != ""ident"" :",99.17774949153385,99.13,False
1595,"def _add_disk_config ( self , context , images ) : <TAB> for image in images : <TAB><TAB> metadata = image [ "" metadata "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raw_value = metadata [ INTERNAL_DISK_CONFIG ] <TAB><TAB><TAB> value = utils . bool_from_str ( raw_value ) <TAB><TAB><TAB> image [ API_DISK_CONFIG ] = disk_config_to_api ( value )",if INTERNAL_DISK_CONFIG in metadata :,if INTERNAL_DISK_CONFIG in metadata :,100.0,100.00,True
1596,"def test_edgeql_expr_valid_setop_07 ( self ) : <TAB> expected_error_msg = "" cannot be applied to operands "" <TAB> # IF ELSE with every scalar as the condition <TAB> for val in get_test_values ( ) : <TAB><TAB> query = f """""" SELECT 1 IF  { val }  ELSE 2; """""" <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . assert_query_result ( query , [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> # every other combination must produce an error <TAB><TAB><TAB> with self . assertRaisesRegex ( <TAB><TAB><TAB><TAB> edgedb . QueryError , expected_error_msg , msg = query <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> async with self . con . transaction ( ) : <TAB><TAB><TAB><TAB><TAB> await self . con . execute ( query )","if val == ""<bool>True"" :",if val == 1 :,98.93497622570001,96.90,False
1597,"def get_all_url_infos ( ) - > Dict [ str , UrlInfo ] : <TAB> """"""Returns dict associating URL to UrlInfo."""""" <TAB> url_infos = { } <TAB> for path in _checksum_paths ( ) . values ( ) : <TAB><TAB> dataset_url_infos = load_url_infos ( path ) <TAB><TAB> for url , url_info in dataset_url_infos . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise AssertionError ( <TAB><TAB><TAB><TAB><TAB> "" URL  {}  is registered with 2+ distinct size/checksum tuples.  "" <TAB><TAB><TAB><TAB><TAB> "" {}  vs  {} "" . format ( url , url_info , url_infos [ url ] ) <TAB><TAB><TAB><TAB> ) <TAB><TAB> url_infos . update ( dataset_url_infos ) <TAB> return url_infos","if url_infos . get ( url , url_info ) != url_info :",if url not in url_infos :,92.92674110637832,93.59,False
1598,"def global_fixes ( ) : <TAB> """"""Yield multiple (code, function) tuples."""""" <TAB> for function in list ( globals ( ) . values ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> arguments = _get_parameters ( function ) <TAB><TAB><TAB> if arguments [ : 1 ] != [ "" source "" ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> code = extract_code_from_function ( function ) <TAB><TAB><TAB> if code : <TAB><TAB><TAB><TAB> yield ( code , function )",if inspect . isfunction ( function ) :,"if isinstance ( function , ( str , unicode ) ) :",92.65278119502894,94.02,False
1599,"def createSocket ( self ) : <TAB> skt = Port . createSocket ( self ) <TAB> if self . listenMultiple : <TAB><TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEPORT , 1 ) <TAB> return skt","if hasattr ( socket , ""SO_REUSEPORT"" ) :",if self . listenTCP :,89.91884746719244,88.04,False
1600,"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB><TAB> if out and sep : <TAB><TAB><TAB> out . append ( sep ) <TAB><TAB> <MASK> <TAB><TAB><TAB> out + = item . _asStringList ( ) <TAB><TAB> else : <TAB><TAB><TAB> out . append ( str ( item ) ) <TAB> return out","if isinstance ( item , ParseResults ) :","if isinstance ( item , Token ) :",98.20749838370745,97.86,False
1601,"def parse_c_comments ( lexer , tok , ntok ) : <TAB> if tok != "" / "" or ntok != "" * "" : <TAB><TAB> return False <TAB> quotes = lexer . quotes <TAB> lexer . quotes = "" "" <TAB> while True : <TAB><TAB> tok = lexer . get_token ( ) <TAB><TAB> ntok = lexer . get_token ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> lexer . quotes = quotes <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> lexer . push_token ( ntok ) <TAB> return True","if tok == ""*"" and ntok == ""/"" :","if tok == ""c"" :",67.4273701665584,94.24,False
1602,"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB><TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB><TAB> if c1 : <TAB><TAB><TAB> v . append ( sibling ) <TAB><TAB> else : <TAB><TAB><TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> v . append ( sibling ) <TAB><TAB> ### regardless of match or not, check any children for matches <TAB><TAB> if sibling . getFirstChild ( ) : <TAB><TAB><TAB> sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB><TAB> sibling = sibling . getNextSibling ( )",if c2 :,if c2 :,100.0,100.00,True
1603,"def __view_beside ( self , onsideof , * * kwargs ) : <TAB> bounds = self . info [ "" bounds "" ] <TAB> min_dist , found = - 1 , None <TAB> for ui in UiObject ( self . session , Selector ( * * kwargs ) ) : <TAB><TAB> dist = onsideof ( bounds , ui . info [ "" bounds "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> min_dist , found = dist , ui <TAB> return found",if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,if dist < min_dist :,64.28987267013161,87.91,False
1604,"def __eq__ ( self , other ) : <TAB> if isinstance ( other , numeric_range ) : <TAB><TAB> empty_self = not bool ( self ) <TAB><TAB> empty_other = not bool ( other ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return empty_self and empty_other # True if both empty <TAB><TAB> else : <TAB><TAB><TAB> return ( <TAB><TAB><TAB><TAB> self . _start == other . _start <TAB><TAB><TAB><TAB> and self . _step == other . _step <TAB><TAB><TAB><TAB> and self . _get_by_index ( - 1 ) == other . _get_by_index ( - 1 ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> return False",if empty_self or empty_other :,if empty_self and empty_other :,98.55648429182362,98.84,False
1605,"def _buffered_generator ( self , size ) : <TAB> buf = [ ] <TAB> c_size = 0 <TAB> push = buf . append <TAB> while 1 : <TAB><TAB> try : <TAB><TAB><TAB> while c_size < size : <TAB><TAB><TAB><TAB> c = next ( self . _gen ) <TAB><TAB><TAB><TAB> push ( c ) <TAB><TAB><TAB><TAB> if c : <TAB><TAB><TAB><TAB><TAB> c_size + = 1 <TAB><TAB> except StopIteration : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> yield concat ( buf ) <TAB><TAB> del buf [ : ] <TAB><TAB> c_size = 0",if not c_size :,if not self . _gen :,73.80885770388481,97.45,False
1606,"def connect ( self ) : <TAB> with self . _conn_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Error, database not properly initialized  "" "" before opening connection "" <TAB><TAB><TAB> ) <TAB><TAB> with self . exception_wrapper ( ) : <TAB><TAB><TAB> self . __local . conn = self . _connect ( self . database , * * self . connect_kwargs ) <TAB><TAB><TAB> self . __local . closed = False <TAB><TAB><TAB> self . initialize_connection ( self . __local . conn )",if self . deferred :,if self . __local . conn is None :,95.96963771656331,94.98,False
1607,"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB><TAB> for name , var in new_subst . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> subst [ name ] = var <TAB><TAB><TAB> elif subst [ name ] is not var : <TAB><TAB><TAB><TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst",if name not in subst :,if name not in subst :,100.0,100.00,True
1608,"def remove ( self , tag ) : <TAB> """"""Removes a tag recursively from all containers."""""" <TAB> new_contents = [ ] <TAB> self . content_size = 0 <TAB> for element in self . contents : <TAB><TAB> if element . name != tag : <TAB><TAB><TAB> new_contents . append ( element ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> element . remove ( tag ) <TAB><TAB><TAB> self . content_size + = element . size ( ) <TAB> self . contents = new_contents","if isinstance ( element , Container ) :",if element . name in self . containers :,92.91499096930666,94.51,False
1609,"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB><TAB> if isinstance ( prop_value , dict ) and prop_value : <TAB><TAB><TAB> # get the first key as the convert function <TAB><TAB><TAB> func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> func = getattr ( self , func_name ) <TAB><TAB><TAB><TAB> props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB> if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB><TAB> return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB> else : <TAB><TAB> return props","if func_name . startswith ( ""_"" ) :",if func_name in self . fake_func_mapping :,97.6173584923313,96.42,False
1610,"def visit_try_stmt ( self , o : "" mypy.nodes.TryStmt "" ) - > str : <TAB> a = [ o . body ] # type: List[Any] <TAB> for i in range ( len ( o . vars ) ) : <TAB><TAB> a . append ( o . types [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> a . append ( o . vars [ i ] ) <TAB><TAB> a . append ( o . handlers [ i ] ) <TAB> if o . else_body : <TAB><TAB> a . append ( ( "" Else "" , o . else_body . body ) ) <TAB> if o . finally_body : <TAB><TAB> a . append ( ( "" Finally "" , o . finally_body . body ) ) <TAB> return self . dump ( a , o )",if o . vars [ i ] :,if o . handlers :,98.0525690426909,97.28,False
1611,"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB> if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> for i in v : <TAB><TAB><TAB><TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , _bytes ) : <TAB><TAB><TAB> return False <TAB> return True","elif isinstance ( i , _bytes ) :","elif isinstance ( i , _bytes ) and k != ""headers"" :",72.67678072936975,96.40,False
1612,"def msg_ser ( inst , sformat , lev = 0 ) : <TAB> if sformat in [ "" urlencoded "" , "" json "" ] : <TAB><TAB> if isinstance ( inst , Message ) : <TAB><TAB><TAB> res = inst . serialize ( sformat , lev ) <TAB><TAB> else : <TAB><TAB><TAB> res = inst <TAB> elif sformat == "" dict "" : <TAB><TAB> if isinstance ( inst , Message ) : <TAB><TAB><TAB> res = inst . serialize ( sformat , lev ) <TAB><TAB> <MASK> <TAB><TAB><TAB> res = inst <TAB><TAB> elif isinstance ( inst , str ) : # Iff ID Token <TAB><TAB><TAB> res = inst <TAB><TAB> else : <TAB><TAB><TAB> raise MessageException ( "" Wrong type:  %s "" % type ( inst ) ) <TAB> else : <TAB><TAB> raise PyoidcError ( "" Unknown sformat "" , inst ) <TAB> return res","elif isinstance ( inst , dict ) :","elif isinstance ( inst , ( int , float ) ) :",97.12898191516682,97.34,False
1613,"def start_container_if_stopped ( self , container , attach_logs = False , quiet = False ) : <TAB> if not container . is_running : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Starting  %s "" % container . name ) <TAB><TAB> if attach_logs : <TAB><TAB><TAB> container . attach_log_stream ( ) <TAB><TAB> return self . start_container ( container )",if not quiet :,if quiet :,93.24762352920504,97.73,False
1614,"def layer_op ( self , input_image , mask = None ) : <TAB> if not isinstance ( input_image , dict ) : <TAB><TAB> self . _set_full_border ( input_image ) <TAB><TAB> input_image = np . pad ( input_image , self . full_border , mode = self . mode ) <TAB><TAB> return input_image , mask <TAB> for name , image in input_image . items ( ) : <TAB><TAB> self . _set_full_border ( image ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tf . logging . warning ( <TAB><TAB><TAB><TAB> "" could not pad, dict name  %s  not in  %s "" , name , self . image_name <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> input_image [ name ] = np . pad ( image , self . full_border , mode = self . mode ) <TAB> return input_image , mask",if name not in self . image_name :,if name not in self . image_name :,100.0,100.00,True
1615,"def __Suffix_Noun_Step2b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step2b : <TAB><TAB> <MASK> <TAB><TAB><TAB> token = token [ : - 2 ] <TAB><TAB><TAB> self . suffix_noun_step2b_success = True <TAB><TAB><TAB> break <TAB> return token",if token . endswith ( suffix ) and len ( token ) >= 5 :,if token . endswith ( suffix ) :,83.94883851368581,90.52,False
1616,"def replace_header_items ( ps , replacments ) : <TAB> match = read_while ( ps , header_item_or_end_re . match , lambda match : match is None ) <TAB> while not ps . current_line . startswith ( "" */ "" ) : <TAB><TAB> match = header_item_re . match ( ps . current_line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> key = match . groupdict ( ) [ "" key "" ] <TAB><TAB><TAB> if key in replacments : <TAB><TAB><TAB><TAB> ps . current_line = match . expand ( <TAB><TAB><TAB><TAB><TAB> "" \ g<key> \ g<space> %s \n "" % replacments [ key ] <TAB><TAB><TAB><TAB> ) <TAB><TAB> ps . read_line ( )",if match is not None :,if match :,86.72990346727508,97.88,False
1617,"def __projectBookmark ( widget , location ) : <TAB> script = None <TAB> while widget is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> script = widget . scriptNode ( ) <TAB><TAB><TAB> if isinstance ( script , Gaffer . ScriptNode ) : <TAB><TAB><TAB><TAB> break <TAB><TAB> widget = widget . parent ( ) <TAB> if script is not None : <TAB><TAB> p = script . context ( ) . substitute ( location ) <TAB><TAB> if not os . path . exists ( p ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> os . makedirs ( p ) <TAB><TAB><TAB> except OSError : <TAB><TAB><TAB><TAB> pass <TAB><TAB> return p <TAB> else : <TAB><TAB> return os . getcwd ( )","if hasattr ( widget , ""scriptNode"" ) :","if isinstance ( widget , Gaffer . ScriptNode ) :",93.16963916818005,96.86,False
1618,"def events_to_str ( event_field , all_events ) : <TAB> result = [ ] <TAB> for ( flag , string ) in all_events : <TAB><TAB> c_flag = flag <TAB><TAB> if event_field & c_flag : <TAB><TAB><TAB> result . append ( string ) <TAB><TAB><TAB> event_field = event_field & ( ~ c_flag ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> if event_field : <TAB><TAB> result . append ( hex ( event_field ) ) <TAB> return "" | "" . join ( result )",if not event_field :,if event_field == 0 :,68.18020309640033,96.24,False
1619,"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets : <TAB><TAB> if b . get ( "" Logging "" ) : <TAB><TAB><TAB> if self_log : <TAB><TAB><TAB><TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( b [ "" Name "" ] , "" "" )","if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :","elif b [ ""Name"" ] :",92.21628096425295,92.15,False
1620,"def extract_file ( tgz , tarinfo , dst_path , buffer_size = 10 << 20 , log_function = None ) : <TAB> """"""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'."""""" <TAB> src = tgz . extractfile ( tarinfo ) <TAB> if src is None : <TAB><TAB> return <TAB> dst = tf . compat . v1 . gfile . GFile ( dst_path , "" wb "" ) <TAB> while 1 : <TAB><TAB> buf = src . read ( buffer_size ) <TAB><TAB> if not buf : <TAB><TAB><TAB> break <TAB><TAB> dst . write ( buf ) <TAB><TAB> <MASK> <TAB><TAB><TAB> log_function ( len ( buf ) ) <TAB> dst . close ( ) <TAB> src . close ( )",if log_function is not None :,if log_function :,74.09694324906933,97.73,False
1621,"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB><TAB> if k in ( "" lccn "" , "" oclc "" , "" isbn "" ) : <TAB><TAB><TAB> fields [ k ] = v <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields","if k == ""full_title"" :","if k == ""title"" :",98.257772888946,97.18,False
1622,"def disconnect_application ( self ) : <TAB> if not self . is_app_running ( self . APP_BACKDROP ) : <TAB><TAB> self . socket . send ( commands . CloseCommand ( destination_id = False ) ) <TAB><TAB> start_time = time . time ( ) <TAB><TAB> while not self . is_app_running ( None ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . socket . send_and_wait ( commands . StatusCommand ( ) ) <TAB><TAB><TAB> except cast_socket . ConnectionTerminatedException : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> current_time = time . time ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise TimeoutException ( ) <TAB><TAB><TAB> time . sleep ( self . WAIT_INTERVAL ) <TAB> else : <TAB><TAB> logger . debug ( "" Closing not necessary. Backdrop is running ... "" )",if current_time - start_time > self . timeout :,if current_time - start_time > self . MAX_TIME :,99.00551603844707,98.24,False
1623,"def matches ( self , cursor_offset , line , * * kwargs ) : <TAB> cs = lineparts . current_string ( cursor_offset , line ) <TAB> if cs is None : <TAB><TAB> return None <TAB> matches = set ( ) <TAB> username = cs . word . split ( os . path . sep , 1 ) [ 0 ] <TAB> user_dir = os . path . expanduser ( username ) <TAB> for filename in self . safe_glob ( os . path . expanduser ( cs . word ) ) : <TAB><TAB> if os . path . isdir ( filename ) : <TAB><TAB><TAB> filename + = os . path . sep <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = username + filename [ len ( user_dir ) : ] <TAB><TAB> matches . add ( filename ) <TAB> return matches","if cs . word . startswith ( ""~"" ) :",elif filename . startswith ( user_dir ) :,76.46397820226308,95.17,False
1624,"def eventFilter ( self , obj , event ) : <TAB> if event . type ( ) == QEvent . MouseButtonPress : <TAB><TAB> button = event . button ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _app . browser . back ( ) <TAB><TAB><TAB> return True <TAB><TAB> elif button == Qt . ForwardButton : <TAB><TAB><TAB> self . _app . browser . forward ( ) <TAB><TAB><TAB> return True <TAB> return False",if button == Qt . BackButton :,if button == Qt . BackButton :,100.0,100.00,True
1625,"def reset_parameters ( self ) : <TAB> for m in self . modules ( ) : <TAB><TAB> if isinstance ( m , nn . Embedding ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> nn . init . constant_ ( m . weight , 0.1 ) <TAB><TAB><TAB> nn . init . constant_ ( m . bias , 0 ) <TAB><TAB> else : <TAB><TAB><TAB> for p in m . parameters ( ) : <TAB><TAB><TAB><TAB> nn . init . normal_ ( p , 0 , 0.1 )","elif isinstance ( m , nn . LayerNorm ) :","if isinstance ( m , nn . BatchNorm2d ) :",72.05169611807929,96.76,False
1626,"def get_scalding_core ( self ) : <TAB> lib_dir = os . path . join ( self . scalding_home , "" lib "" ) <TAB> for j in os . listdir ( lib_dir ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> p = os . path . join ( lib_dir , j ) <TAB><TAB><TAB> logger . debug ( "" Found scalding-core:  %s "" , p ) <TAB><TAB><TAB> return p <TAB> raise luigi . contrib . hadoop . HadoopJobError ( "" Could not find scalding-core. "" )","if j . startswith ( ""scalding-core-"" ) :","if j . endswith ( "".scalding-core"" ) :",97.58509568059986,95.89,False
1627,"def save ( self ) : <TAB> """"""Saves a new set of golden output frames to disk."""""" <TAB> for pixels , ( relative_to_assets , filename ) in zip ( <TAB><TAB> self . iter_render ( ) , self . _iter_paths ( ) <TAB> ) : <TAB><TAB> full_directory_path = os . path . join ( self . _ASSETS_DIR , relative_to_assets ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( full_directory_path ) <TAB><TAB> path = os . path . join ( full_directory_path , filename ) <TAB><TAB> _save_pixels ( pixels , path )",if not os . path . exists ( full_directory_path ) :,if not os . path . exists ( full_directory_path ) :,100.0,100.00,True
1628,"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB><TAB> <MASK> <TAB><TAB><TAB> iter = op . inputs <TAB><TAB> else : <TAB><TAB><TAB> iter = op . outputs <TAB><TAB> for i in iter : <TAB><TAB><TAB> for name in names : <TAB><TAB><TAB><TAB> if i . raw_name == name and name not in map : <TAB><TAB><TAB><TAB><TAB> map [ i . raw_name ] = i . full_name <TAB><TAB> if len ( map ) == len ( names ) : <TAB><TAB><TAB> break <TAB> for name in names : <TAB><TAB> new_names . append ( map [ name ] ) <TAB> return new_names","if mod == ""input"" :","if mod == ""output"" :",98.95748487826621,98.92,False
1629,"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB><TAB> # The type checker can't know the true type of item! <TAB><TAB> item = cast ( TupleStr4 , item ) <TAB><TAB> if item [ 0 ] : <TAB><TAB><TAB> typ = "" number "" <TAB><TAB><TAB> val = item [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> typ = "" name "" <TAB><TAB><TAB> val = item [ 1 ] <TAB><TAB> elif item [ 2 ] : <TAB><TAB><TAB> typ = item [ 2 ] <TAB><TAB><TAB> val = item [ 2 ] <TAB><TAB> elif item [ 3 ] : <TAB><TAB><TAB> typ = item [ 3 ] <TAB><TAB><TAB> val = item [ 3 ] <TAB><TAB> yield Token ( typ , val )",elif item [ 1 ] :,elif item [ 1 ] :,75.0,100.00,True
1630,"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions : <TAB><TAB> if ex < 500 : <TAB><TAB><TAB> app . register_error_handler ( ex , error_http ) <TAB><TAB> <MASK> <TAB><TAB><TAB> app . register_error_handler ( ex , internal_error ) <TAB> if services . ldap : <TAB><TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB><TAB> @app . errorhandler ( services . ldap . LDAPException ) <TAB><TAB> def handle_exception ( e ) : <TAB><TAB><TAB> log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB><TAB><TAB> return error_http ( FailedDependency ( ) )",elif ex == 500 :,"if ex . __name__ == ""internal_error"" :",72.17693663909516,92.44,False
1631,"def decode ( self , ids ) : <TAB> ids = pad_decr ( ids ) <TAB> tokens = [ ] <TAB> for int_id in ids : <TAB><TAB> <MASK> <TAB><TAB><TAB> tokens . append ( self . _vocab_list [ int_id ] ) <TAB><TAB> else : <TAB><TAB><TAB> tokens . append ( self . _oov_token ) <TAB> return self . _decode_token_separator . join ( tokens )",if int_id < len ( self . _vocab_list ) :,if int_id in self . _vocab_list :,92.04842277137826,94.39,False
1632,"def remove_contest ( contest_id ) : <TAB> with SessionGen ( ) as session : <TAB><TAB> contest = session . query ( Contest ) . filter ( Contest . id == contest_id ) . first ( ) <TAB><TAB> if not contest : <TAB><TAB><TAB> print ( "" No contest with id  %s  found. "" % contest_id ) <TAB><TAB><TAB> return False <TAB><TAB> contest_name = contest . name <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Not removing contest ` %s ' . "" % contest_name ) <TAB><TAB><TAB> return False <TAB><TAB> session . delete ( contest ) <TAB><TAB> session . commit ( ) <TAB><TAB> print ( "" Contest ` %s '  removed. "" % contest_name ) <TAB> return True",if not ask ( contest ) :,if not session . exists ( contest_name ) :,82.67343846773528,96.34,False
1633,def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB><TAB> pass <TAB> else : <TAB><TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB><TAB> if self . expr2 is None : <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno,if self . expr3 is None :,if self . expr3 is None :,100.0,100.00,True
1634,"def _send_internal ( self , bytes_ ) : <TAB> # buffering <TAB> if self . pendings : <TAB><TAB> self . pendings + = bytes_ <TAB><TAB> bytes_ = self . pendings <TAB> try : <TAB><TAB> # reconnect if possible <TAB><TAB> self . _reconnect ( ) <TAB><TAB> # send message <TAB><TAB> self . socket . sendall ( bytes_ ) <TAB><TAB> # send finished <TAB><TAB> self . pendings = None <TAB> except Exception : # pylint: disable=broad-except <TAB><TAB> # close socket <TAB><TAB> self . _close ( ) <TAB><TAB> # clear buffer if it exceeds max bufer size <TAB><TAB> <MASK> <TAB><TAB><TAB> # TODO: add callback handler here <TAB><TAB><TAB> self . pendings = None <TAB><TAB> else : <TAB><TAB><TAB> self . pendings = bytes_",if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,if bytes_ > self . max_burnings :,68.93956331815258,93.41,False
1635,"def _unpack ( self , fmt , byt ) : <TAB> d = unpack ( self . _header [ "" byteorder "" ] + fmt , byt ) [ 0 ] <TAB> if fmt [ - 1 ] in self . MISSING_VALUES : <TAB><TAB> nmin , nmax = self . MISSING_VALUES [ fmt [ - 1 ] ] <TAB><TAB> if d < nmin or d > nmax : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return StataMissingValue ( nmax , d ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return None <TAB> return d",if self . _missing_values :,if d != nmax :,95.84404723756697,95.08,False
1636,"def tuple_iter ( self ) : <TAB> for x in range ( <TAB><TAB> self . center . x - self . max_radius , self . center . x + self . max_radius + 1 <TAB> ) : <TAB><TAB> for y in range ( <TAB><TAB><TAB> self . center . y - self . max_radius , self . center . y + self . max_radius + 1 <TAB><TAB> ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield ( x , y )","if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :","if ( x , y ) not in ( self . center . z , self . center .",61.73473163225778,86.42,False
1637,"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB><TAB> <MASK> <TAB><TAB><TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB><TAB><TAB><TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB><TAB><TAB><TAB> genename_element . attrib [ "" type "" ] , <TAB><TAB><TAB> ) <TAB><TAB><TAB> if genename_element . attrib [ "" type "" ] == "" primary "" : <TAB><TAB><TAB><TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> append_to_annotations ( ann_key , genename_element . text )","if ""type"" in genename_element . attrib :",if genename_element . tag . startswith ( NS ) :,93.58426572379148,95.73,False
1638,"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self . isSystemCurveIndex ( iFirstCurve ) : <TAB><TAB> return <TAB> nCurves = self . getNCurves ( ) <TAB> for i in range ( iFirstCurve , nCurves ) : <TAB><TAB> c = self . getSystemCurve ( i ) <TAB><TAB> if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) : <TAB><TAB><TAB> c . invalidate ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # if first curve isn't a slice, <TAB><TAB><TAB> break <TAB><TAB><TAB> # there are no dependent slices",elif i == iFirstCurve :,elif c . isDependency ( ) :,72.43246605808889,96.11,False
1639,"def gen_app_versions ( self ) : <TAB> for app_config in apps . get_app_configs ( ) : <TAB><TAB> name = app_config . verbose_name <TAB><TAB> app = app_config . module <TAB><TAB> version = self . get_app_version ( app ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield app . __name__ , name , version",if version :,if version :,100.0,100.00,True
1640,"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB><TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB><TAB> if part in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB><TAB> checkpath = os . path . join ( checkpath , part ) <TAB><TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB><TAB> if os . path . islink ( checkpath ) : <TAB><TAB><TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" )",if not os . path . exists ( checkpath ) :,if not os . path . exists ( checkpath ) :,100.0,100.00,True
1641,"def create_or_update_tag_at_scope ( cmd , resource_id = None , tags = None , tag_name = None ) : <TAB> rcf = _resource_client_factory ( cmd . cli_ctx ) <TAB> if resource_id is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IncorrectUsageError ( "" Tags could not be empty. "" ) <TAB><TAB> Tags = cmd . get_models ( "" Tags "" ) <TAB><TAB> tag_obj = Tags ( tags = tags ) <TAB><TAB> return rcf . tags . create_or_update_at_scope ( scope = resource_id , properties = tag_obj ) <TAB> return rcf . tags . create_or_update ( tag_name = tag_name )",if not tags :,if tags is None :,81.68359332164451,97.64,False
1642,"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB><TAB> compare_entry = entry <TAB><TAB> compare_base = base <TAB><TAB> if self . settings . get ( IGNORE_CASE_SETTING ) : <TAB><TAB><TAB> compare_entry = compare_entry . lower ( ) <TAB><TAB><TAB> compare_base = compare_base . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if entry not in sugg : <TAB><TAB><TAB><TAB> sugg . append ( entry ) <TAB> return sugg","if self . compare_entries ( compare_entry , compare_base ) :",if compare_entry == compare_base :,64.23966680376864,92.73,False
1643,"def createFields ( self ) : <TAB> yield String ( self , "" dict_start "" , 2 ) <TAB> while not self . eof : <TAB><TAB> addr = self . absolute_address + self . current_size <TAB><TAB> <MASK> <TAB><TAB><TAB> for field in parsePDFType ( self ) : <TAB><TAB><TAB><TAB> yield field <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> yield String ( self , "" dict_end "" , 2 )","if self . stream . readBytes ( addr , 2 ) != "">>"" :",if addr < self . absolute_address + self . current_size :,61.741089027398445,88.14,False
1644,"def Visit_and_test ( self , node ) : # pylint: disable=invalid-name <TAB> # and_test ::= not_test ('and' not_test)* <TAB> for child in node . children : <TAB><TAB> self . Visit ( child ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR )","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",75.0,100.00,True
1645,"def getfiledata ( directories ) : <TAB> columns = None <TAB> data = [ ] <TAB> counter = 1 <TAB> for directory in directories : <TAB><TAB> for f in os . listdir ( directory ) : <TAB><TAB><TAB> if not os . path . isfile ( os . path . join ( directory , f ) ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> counter + = 1 <TAB><TAB><TAB> st = os . stat ( os . path . join ( directory , f ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> columns = [ "" rowid "" , "" name "" , "" directory "" ] + [ <TAB><TAB><TAB><TAB><TAB> x for x in dir ( st ) if x . startswith ( "" st_ "" ) <TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB> data . append ( [ counter , f , directory ] + [ getattr ( st , x ) for x in columns [ 3 : ] ] ) <TAB> return columns , data",if columns is None :,if columns is None :,100.0,100.00,True
1646,"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB><TAB> value = getattr ( obj , attr , None ) <TAB><TAB> if value is None : <TAB><TAB><TAB> continue <TAB><TAB> name = name_fmt % attr <TAB><TAB> <MASK> <TAB><TAB><TAB> value = formatter ( attr , value ) <TAB><TAB> info_add ( name , value )",if formatter is not None :,if formatter is not None :,100.0,100.00,True
1647,"def main ( args ) : <TAB> ap = argparse . ArgumentParser ( ) <TAB> ap . add_argument ( "" job_ids "" , nargs = "" + "" , type = int , help = "" ID of a running job "" ) <TAB> ns = ap . parse_args ( args ) <TAB> _stash = globals ( ) [ "" _stash "" ] <TAB> """""":type : StaSh"""""" <TAB> for job_id in ns . job_ids : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" killing job  {}  ... "" . format ( job_id ) ) <TAB><TAB><TAB> worker = _stash . runtime . worker_registry . get_worker ( job_id ) <TAB><TAB><TAB> worker . kill ( ) <TAB><TAB><TAB> time . sleep ( 1 ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" error: no such job with id:  {} "" . format ( job_id ) ) <TAB><TAB><TAB> break",if job_id in _stash . runtime . worker_registry :,if job_id in _stash . runtime . workers :,74.15544452705628,98.26,False
1648,"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB><TAB> if self . choices is None : <TAB><TAB><TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise OptionError ( <TAB><TAB><TAB><TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB><TAB><TAB><TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB><TAB><TAB><TAB> self , <TAB><TAB><TAB> ) <TAB> elif self . choices is not None : <TAB><TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self )","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :","elif not isinstance ( self . choices , ( list , tuple ) ) :",66.60467511093321,93.62,False
1649,"def add_file ( pipe , srcpath , tgtpath ) : <TAB> with open ( srcpath , "" rb "" ) as handle : <TAB><TAB> <MASK> <TAB><TAB><TAB> write ( pipe , enc ( "" M 100755 inline  %s \n "" % tgtpath ) ) <TAB><TAB> else : <TAB><TAB><TAB> write ( pipe , enc ( "" M 100644 inline  %s \n "" % tgtpath ) ) <TAB><TAB> data = handle . read ( ) <TAB><TAB> write ( pipe , enc ( "" data  %d \n "" % len ( data ) ) ) <TAB><TAB> write ( pipe , enc ( data ) ) <TAB><TAB> write ( pipe , enc ( "" \n "" ) )","if os . access ( srcpath , os . X_OK ) :",if os . path . exists ( tgtpath ) :,93.6900078747583,94.47,False
1650,"def cdf ( self , x ) : <TAB> if x == numpy . inf : <TAB><TAB> return 1.0 <TAB> else : # Inefficient sum. <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" Invalid value. "" ) <TAB><TAB> c = 0.0 <TAB><TAB> for i in xrange ( x + 1 ) : <TAB><TAB><TAB> c + = self . probability ( i ) <TAB><TAB> return c",if x != int ( x ) :,if x < 0 :,70.44443974104891,93.64,False
1651,"def convert_to_strings ( self , out , seq_len ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( out ) : <TAB><TAB> utterances = [ ] <TAB><TAB> for p , utt in enumerate ( batch ) : <TAB><TAB><TAB> size = seq_len [ b ] [ p ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> transcript = "" "" . join ( <TAB><TAB><TAB><TAB><TAB> map ( lambda x : self . int_to_char [ x . item ( ) ] , utt [ 0 : size ] ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> transcript = "" "" <TAB><TAB><TAB> utterances . append ( transcript ) <TAB><TAB> results . append ( utterances ) <TAB> return results",if size > 0 :,if size > 0 :,100.0,100.00,True
1652,"def get_date_range ( self ) : <TAB> if not hasattr ( self , "" start "" ) or not hasattr ( self , "" end "" ) : <TAB><TAB> args = ( self . today . year , self . today . month ) <TAB><TAB> form = self . get_form ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> args = ( int ( form . cleaned_data [ "" year "" ] ) , int ( form . cleaned_data [ "" month "" ] ) ) <TAB><TAB> self . start = self . get_start ( * args ) <TAB><TAB> self . end = self . get_end ( * args ) <TAB> return self . start , self . end",if form . is_valid ( ) :,if form . cleaned_data :,74.58290224538676,96.37,False
1653,"def save_stats ( self ) : <TAB> LOGGER . info ( "" Saving task-level statistics. "" ) <TAB> has_headers = os . path . isfile ( paths . TABLE_COUNT_PATH ) <TAB> with open ( paths . TABLE_COUNT_PATH , "" a "" ) as csvfile : <TAB><TAB> headers = [ "" start_time "" , "" database_name "" , "" number_tables "" ] <TAB><TAB> writer = csv . DictWriter ( <TAB><TAB><TAB> csvfile , delimiter = "" , "" , lineterminator = "" \n "" , fieldnames = headers <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> writer . writeheader ( ) <TAB><TAB> writer . writerow ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" start_time "" : self . start_time , <TAB><TAB><TAB><TAB> "" database_name "" : self . database_name , <TAB><TAB><TAB><TAB> "" number_tables "" : self . count , <TAB><TAB><TAB> } <TAB><TAB> )",if not has_headers :,if has_headers :,98.59151468188665,99.07,False
1654,"def _CheckCanaryCommand ( self ) : <TAB> <MASK> # fast path <TAB><TAB> return <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> logging . info ( "" Testing OpenStack CLI command is installed and working "" ) <TAB><TAB> cmd = os_utils . OpenStackCLICommand ( self , "" image "" , "" list "" ) <TAB><TAB> stdout , stderr , _ = cmd . Issue ( ) <TAB><TAB> if stderr : <TAB><TAB><TAB> raise errors . Config . InvalidValue ( <TAB><TAB><TAB><TAB> "" OpenStack CLI test command failed. Please make sure the OpenStack  "" <TAB><TAB><TAB><TAB> "" CLI client is installed and properly configured "" <TAB><TAB><TAB> ) <TAB><TAB> OpenStackVirtualMachine . command_works = True",if OpenStackVirtualMachine . command_works :,if OpenStackVirtualMachine . command_works :,75.0,100.00,True
1655,"def test_windows_hidden ( self ) : <TAB> if not sys . platform == "" win32 "" : <TAB><TAB> self . skipTest ( "" sys.platform is not windows "" ) <TAB><TAB> return <TAB> # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB> hidden_mask = 2 <TAB> with tempfile . NamedTemporaryFile ( ) as f : <TAB><TAB> # Hide the file using <TAB><TAB> success = ctypes . windll . kernel32 . SetFileAttributesW ( f . name , hidden_mask ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" unable to set file attributes "" ) <TAB><TAB> self . assertTrue ( hidden . is_hidden ( f . name ) )",if not success :,if not success :,100.0,100.00,True
1656,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB><TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB><TAB> pr = p . recv_err <TAB> else : <TAB><TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB><TAB> r = pr ( ) <TAB><TAB> if r is None : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> y . append ( r ) <TAB><TAB> else : <TAB><TAB><TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return b "" "" . join ( y )",elif r :,if r :,79.25883572150929,98.86,False
1657,"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB><TAB> has_xml = accepts . find ( b "" xml "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> semicolon = accepts . find ( b "" ; "" ) <TAB><TAB><TAB> if semicolon < 0 or has_xml < semicolon : <TAB><TAB><TAB><TAB> return True <TAB> return False",if has_xml > 0 :,if has_xml > 0 :,75.0,100.00,True
1658,"def times ( self , value : int ) : <TAB> if value is None : <TAB><TAB> self . _times = None <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> candidate = int ( value ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> # pylint: disable:raise-missing-from <TAB><TAB><TAB> raise BarException ( f "" cannot set repeat times to:  { value !r} "" ) <TAB><TAB> if candidate < 0 : <TAB><TAB><TAB> raise BarException ( <TAB><TAB><TAB><TAB> f "" cannot set repeat times to a value less than zero:  { value } "" <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise BarException ( "" cannot set repeat times on a start Repeat "" ) <TAB><TAB> self . _times = candidate","if self . direction == ""start"" :",if self . _times is None :,98.09292784230942,96.60,False
1659,"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB><TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB><TAB> if "" self "" in stack [ 0 ] . f_locals : <TAB><TAB><TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB><TAB><TAB><TAB> print ( layer_names [ layer ] ) <TAB><TAB><TAB><TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> #     out=[out] <TAB> return out",if layer in layer_names :,if layer in layer_names :,100.0,100.00,True
1660,"def do_begin ( self , byte ) : <TAB> if byte . isspace ( ) : <TAB><TAB> return <TAB> if byte != "" < "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _leadingBodyData = byte <TAB><TAB><TAB> return "" bodydata "" <TAB><TAB> self . _parseError ( "" First char of document [ {!r} ] wasn ' t < "" . format ( byte ) ) <TAB> return "" tagstart """,if self . beExtremelyLenient :,if byte in self . _leadingBodyData :,94.70774138519255,94.27,False
1661,"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB><TAB> r = repr ( n ) <TAB><TAB> <MASK> # then it can be inside a comment! <TAB><TAB><TAB> r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB><TAB> return r <TAB> if not isinstance ( n , six . integer_types ) : <TAB><TAB> return n <TAB> if isinstance ( n , constants . Constant ) : <TAB><TAB> if comment : <TAB><TAB><TAB> return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB> elif abs ( n ) < 10 : <TAB><TAB> return str ( n ) <TAB> else : <TAB><TAB> return hex ( n )",if not comment :,"if r . startswith ( ""/x2a/"" ) :",93.77364940282014,95.63,False
1662,"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB><TAB> DEFAULT_DOMAIN_PATH , <TAB><TAB> DEFAULT_STORIES_FILE , <TAB><TAB> tmpdir . strpath , <TAB><TAB> interpreter = RegexInterpreter ( ) , <TAB><TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB><TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB><TAB> if hasattr ( policy . featurizer , "" max_history "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> assert policy . featurizer . max_history == 2 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> assert policy . featurizer . max_history == 5",if type ( policy ) == FormPolicy :,"if sys . version_info >= ( 3 , 0 ) :",71.56554373543263,94.67,False
1663,"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB><TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB> log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB><TAB> user_input = read_input_uninstall ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB><TAB> if index == user_input : <TAB><TAB><TAB><TAB><TAB> config . uninstall_distro_dir_name = _distro_dir <TAB><TAB><TAB><TAB><TAB> unin_distro ( ) <TAB> else : <TAB><TAB> log ( "" No distro installed on  "" + config . usb_disk )",if user_input is not False :,if user_input is not None :,78.07438646467632,98.91,False
1664,"def set_random_avatar ( user ) : <TAB> galleries = get_available_galleries ( include_default = True ) <TAB> if not galleries : <TAB><TAB> raise RuntimeError ( "" no avatar galleries are set "" ) <TAB> avatars_list = [ ] <TAB> for gallery in galleries : <TAB><TAB> <MASK> <TAB><TAB><TAB> avatars_list = gallery [ "" images "" ] <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> avatars_list + = gallery [ "" images "" ] <TAB> random_avatar = random . choice ( avatars_list ) <TAB> store . store_new_avatar ( user , Image . open ( random_avatar . image ) )","if gallery [ ""name"" ] == DEFAULT_GALLERY :","if not gallery [ ""images"" ] :",72.34841379228584,94.32,False
1665,"def make_query ( self , key , filters ) : <TAB> meta = self . get_meta ( key ) <TAB> q = { meta . facet_key : self . normalize_key ( meta . path ) } <TAB> if filters : <TAB><TAB> if filters . get ( "" has_fulltext "" ) == "" true "" : <TAB><TAB><TAB> q [ "" has_fulltext "" ] = "" true "" <TAB><TAB> <MASK> <TAB><TAB><TAB> q [ "" publish_year "" ] = filters [ "" publish_year "" ] <TAB> return q","if filters . get ( ""publish_year"" ) :","if filters . get ( ""publish_year"" ) == ""true"" :",83.85523773688791,95.67,False
1666,"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsNone ( constraint ) <TAB><TAB> elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","elif name == ""mean_module.constant"" :","elif name == ""gpytorch.gaussian_gaussian_gaussian_",93.61899419582423,95.97,False
1667,"def _test_pooling ( input_shape , * * kwargs ) : <TAB> _test_pooling_iteration ( input_shape , * * kwargs ) <TAB> if is_gpu_available ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> input_shape = [ input_shape [ ii ] for ii in ( 0 , 3 , 1 , 2 ) ] <TAB><TAB><TAB> kwargs [ "" data_format "" ] = "" NCHW "" <TAB><TAB><TAB> _test_pooling_iteration ( input_shape , * * kwargs )",if len ( input_shape ) == 4 :,"if kwargs . get ( ""data_format"" ) == ""NCHW"" :",90.62879023500207,89.92,False
1668,"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB><TAB> key = "" pocsuite_target "" <TAB><TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB><TAB> logger . info ( info_msg ) <TAB><TAB> targets = r . get ( key ) <TAB><TAB> count = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> for target in targets : <TAB><TAB><TAB><TAB> if self . add_target ( target ) : <TAB><TAB><TAB><TAB><TAB> count + = 1 <TAB><TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB><TAB> logger . info ( info_msg )",if targets :,if targets :,100.0,100.00,True
1669,"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB><TAB> if value is not None : <TAB><TAB><TAB> setattr ( json_api_settings , setting , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> delattr ( json_api_settings , setting )","elif hasattr ( json_api_settings , setting ) :",elif setting in DEVELOPMENTS . keys ( ) :,66.06774649410833,93.01,False
1670,"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB><TAB> if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> attrvalue = getattr ( self , attrname , None ) <TAB><TAB> if attrvalue == 0 : <TAB><TAB><TAB> continue <TAB><TAB> if attrname == "" salt_version "" : <TAB><TAB><TAB> attrname = "" version "" <TAB><TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass","elif hasattr ( self . metadata , attrname ) :","elif hasattr ( self . metadata , attrname ) :",100.0,100.00,True
1671,"def test_02_looking_at_listdir_path_ ( name ) : <TAB> for dline in listdir . json ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert dline [ "" type "" ] in ( "" DIRECTORY "" , "" FILE "" ) , listdir . text <TAB><TAB><TAB> assert dline [ "" uid "" ] == 0 , listdir . text <TAB><TAB><TAB> assert dline [ "" gid "" ] == 0 , listdir . text <TAB><TAB><TAB> assert dline [ "" name "" ] == name , listdir . text <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise AssertionError ( f "" / { path } / { name }  not found "" )","if dline [ ""path"" ] == f""{path}/{name}"" :","if dline [ ""path"" ] == path :",71.13850437190128,94.01,False
1672,"def DeletePlugin ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB><TAB> result = Mongo . coll [ "" Plugin "" ] . find_one_and_delete ( <TAB><TAB><TAB> { "" _id "" : ObjectId ( oid ) } , remove = True <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" filename "" ] = result [ "" filename "" ] + "" .py "" <TAB><TAB> if os . path . exists ( file_path + result [ "" filename "" ] ) : <TAB><TAB><TAB> os . remove ( file_path + result [ "" filename "" ] ) <TAB><TAB><TAB> return "" success "" <TAB> return "" fail ""","if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",if result :,65.7530008292054,90.82,False
1673,"def iterparent ( self , node ) : <TAB> """"""Iterator wrapper to get allowed parent and child all at once."""""" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield node , child <TAB><TAB><TAB> yield from self . iterparent ( child )","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :","if isinstance ( child , TOC ) :",87.68864725914577,78.66,False
1674,"def _get_matched_layout ( command ) : <TAB> # don't use command.split_script here because a layout mismatch will likely <TAB> # result in a non-splitable script as per shlex <TAB> cmd = command . script . split ( ""   "" ) <TAB> for source_layout in source_layouts : <TAB><TAB> is_all_match = True <TAB><TAB> for cmd_part in cmd : <TAB><TAB><TAB> if not all ( [ ch in source_layout or ch in "" -_ "" for ch in cmd_part ] ) : <TAB><TAB><TAB><TAB> is_all_match = False <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> return source_layout",if is_all_match :,if is_all_match :,75.0,100.00,True
1675,"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB><TAB> if n . op in failed_ops : <TAB><TAB><TAB> continue <TAB><TAB> tiled_n = get_tiled ( n ) <TAB><TAB> if has_unknown_shape ( tiled_n ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # some of the chunks has been fused <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB><TAB><TAB> for node in ( n , tiled_n ) : <TAB><TAB><TAB><TAB> node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB><TAB><TAB> tiled_n . _nsplits = new_nsplits",if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,if len ( tiled_n . shape ) == 0 :,64.38247801011241,93.24,False
1676,"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB><TAB> if len ( all_items ) < target : <TAB><TAB><TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB><TAB> else : <TAB><TAB><TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB><TAB> <MASK> <TAB><TAB><TAB> on . append ( o ) <TAB><TAB> else : <TAB><TAB><TAB> off . append ( o ) <TAB> return on , off",if o . selected :,"if isinstance ( o , Item ) :",96.65584132185617,96.55,False
1677,def parse_flow_sequence_entry_mapping_value ( self ) : <TAB> if self . check_token ( ValueToken ) : <TAB><TAB> token = self . get_token ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . states . append ( self . parse_flow_sequence_entry_mapping_end ) <TAB><TAB><TAB> return self . parse_flow_node ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB><TAB><TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> else : <TAB><TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB><TAB> token = self . peek_token ( ) <TAB><TAB> return self . process_empty_scalar ( token . start_mark ),"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",if token . end_mark == self . flow_sequence_entry_mapping_end :,71.78240835200626,92.34,False
1678,"def serialize_config ( self , session , key , tid , language ) : <TAB> cache_key = gen_cache_key ( key , tid , language ) <TAB> cache_obj = None <TAB> if cache_key not in self . cache : <TAB><TAB> <MASK> <TAB><TAB><TAB> cache_obj = db_admin_serialize_node ( session , tid , language ) <TAB><TAB> elif key == "" notification "" : <TAB><TAB><TAB> cache_obj = db_get_notification ( session , tid , language ) <TAB><TAB> self . cache [ cache_key ] = cache_obj <TAB> return self . cache [ cache_key ]","if key == ""node"" :","if key == ""node"" :",100.0,100.00,True
1679,"def get_lldp_neighbors ( self ) : <TAB> commands = [ "" show lldp neighbors "" ] <TAB> output = self . device . run_commands ( commands ) [ 0 ] [ "" lldpNeighbors "" ] <TAB> lldp = { } <TAB> for n in output : <TAB><TAB> <MASK> <TAB><TAB><TAB> lldp [ n [ "" port "" ] ] = [ ] <TAB><TAB> lldp [ n [ "" port "" ] ] . append ( <TAB><TAB><TAB> { "" hostname "" : n [ "" neighborDevice "" ] , "" port "" : n [ "" neighborPort "" ] } <TAB><TAB> ) <TAB> return lldp","if n [ ""port"" ] not in lldp . keys ( ) :","if n [ ""port"" ] not in lldp :",80.29193050719067,96.60,False
1680,"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB><TAB> name = venv . path . name <TAB><TAB> if self . option ( "" full-path "" ) : <TAB><TAB><TAB> name = str ( venv . path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB><TAB><TAB> continue <TAB><TAB> self . line ( name )",if venv == current_env :,if name in current_env :,77.42707842586086,97.28,False
1681,"def resolve_env_secrets ( config , environ ) : <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance ( config , dict ) : <TAB><TAB> if list ( config . keys ( ) ) == [ "" $env "" ] : <TAB><TAB><TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB><TAB> else : <TAB><TAB><TAB> return { <TAB><TAB><TAB><TAB> key : resolve_env_secrets ( value , environ ) <TAB><TAB><TAB><TAB> for key , value in config . items ( ) <TAB><TAB><TAB> } <TAB> elif isinstance ( config , list ) : <TAB><TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB><TAB> return config","elif list ( config . keys ( ) ) == [ ""$file"" ] :","elif isinstance ( config . keys ( ) ) == [ ""$name"" ] :",73.39572266114861,98.17,False
1682,"def _is_valid_16bit_as_path ( cls , buf ) : <TAB> two_byte_as_size = struct . calcsize ( "" !H "" ) <TAB> while buf : <TAB><TAB> ( type_ , num_as ) = struct . unpack_from ( <TAB><TAB><TAB> cls . _SEG_HDR_PACK_STR , six . binary_type ( buf ) <TAB><TAB> ) <TAB><TAB> if type_ is not cls . _AS_SET and type_ is not cls . _AS_SEQUENCE : <TAB><TAB><TAB> return False <TAB><TAB> buf = buf [ struct . calcsize ( cls . _SEG_HDR_PACK_STR ) : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> buf = buf [ num_as * two_byte_as_size : ] <TAB> return True",if len ( buf ) < num_as * two_byte_as_size :,if num_as * two_byte_as_size != two_byte_as_,70.23731498097948,95.20,False
1683,"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB><TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> newParent . _element . text = "" "" <TAB><TAB> if self . _element . text is not None : <TAB><TAB><TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent )",if not newParent . _element . text :,if self . _element . text is None :,71.75911811858275,95.82,False
1684,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB><TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB> if not operation_name : <TAB><TAB><TAB><TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB> if operation : <TAB><TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB><TAB> operation = definition <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return definition <TAB> return operation",elif definition . name and definition . name . value == operation_name :,"elif isinstance ( definition , ast . Name ) :",95.25119378104363,94.02,False
1685,"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB><TAB> <MASK> <TAB><TAB><TAB> return str ( item ) <TAB><TAB> elif vw . isValidPointer ( item ) : <TAB><TAB><TAB> return vw . reprPointer ( item ) <TAB><TAB> else : <TAB><TAB><TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB><TAB> return reprComplex ( vw , item ) # recurse <TAB> elif ptype is dict : <TAB><TAB> return "" { %s } "" % "" , "" . join ( <TAB><TAB><TAB> [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB><TAB> ) <TAB> else : <TAB><TAB> return repr ( item )",if - 1024 < item < 1024 :,if vw . isValidString ( item ) :,68.69333083244425,96.78,False
1686,"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> cmds = cmd . split ( "" & "" ) <TAB><TAB><TAB> for c in cmds : <TAB><TAB><TAB><TAB> if len ( c ) > 0 : <TAB><TAB><TAB><TAB><TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB><TAB> else : <TAB><TAB><TAB> b64cmd = base64 . b64encode ( cmd ) <TAB><TAB><TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB><TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd",if reverseConn not in cmd :,"if ""&"" in cmd :",60.325967943275515,97.96,False
1687,"def render_tasks ( self ) - > List : <TAB> results = [ ] <TAB> for task in self . tasks . values ( ) : <TAB><TAB> job_entry = self . jobs . get ( task . job_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not self . should_render_job ( job_entry ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB> files = self . get_file_counts ( [ task ] ) <TAB><TAB> entry = ( <TAB><TAB><TAB> task . job_id , <TAB><TAB><TAB> task . task_id , <TAB><TAB><TAB> task . state , <TAB><TAB><TAB> task . type . name , <TAB><TAB><TAB> task . target , <TAB><TAB><TAB> files , <TAB><TAB><TAB> task . pool , <TAB><TAB><TAB> task . end_time , <TAB><TAB> ) <TAB><TAB> results . append ( entry ) <TAB> return results",if job_entry :,if job_entry :,100.0,100.00,True
1688,"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB><TAB> if key not in environ : <TAB><TAB><TAB> continue <TAB><TAB> request_uri = unquote ( environ [ key ] ) <TAB><TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB> break <TAB> return self . app ( environ , start_response )",if request_uri . startswith ( script_name ) :,if request_uri . startswith ( script_name ) :,100.0,100.00,True
1689,"def _add_role_information ( self , function_dict , role_id ) : <TAB> # Make it easier to build rules based on policies attached to execution roles <TAB> function_dict [ "" role_arn "" ] = role_id <TAB> role_name = role_id . split ( "" / "" ) [ - 1 ] <TAB> function_dict [ <TAB><TAB> "" execution_role "" <TAB> ] = await self . facade . awslambda . get_role_with_managed_policies ( role_name ) <TAB> if function_dict . get ( "" execution_role "" ) : <TAB><TAB> statements = [ ] <TAB><TAB> for policy in function_dict [ "" execution_role "" ] . get ( "" policies "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> statements + = policy [ "" Document "" ] [ "" Statement "" ] <TAB><TAB> function_dict [ "" execution_role "" ] [ "" policy_statements "" ] = statements","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :","if policy [ ""Document"" ] [ ""Policy"" ] :",71.77158509722764,95.46,False
1690,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 8 : <TAB><TAB><TAB> self . set_ts ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
1691,"def format_counts ( results , json_output = False , human_readable = False ) : <TAB> if json_output : <TAB><TAB> for result in results : <TAB><TAB><TAB> yield json . dumps ( result ) <TAB> else : <TAB><TAB> for result in results : <TAB><TAB><TAB> space_consumed = result . get ( "" spaceConsumed "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> space_consumed = _sizeof_fmt ( int ( result . get ( "" spaceConsumed "" ) ) ) <TAB><TAB><TAB> yield "" %12s   %12s   %18s   %s "" % ( <TAB><TAB><TAB><TAB> result . get ( "" directoryCount "" ) , <TAB><TAB><TAB><TAB> result . get ( "" fileCount "" ) , <TAB><TAB><TAB><TAB> space_consumed , <TAB><TAB><TAB><TAB> result . get ( "" path "" ) , <TAB><TAB><TAB> )",if human_readable :,if human_readable :,100.0,100.00,True
1692,"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB><TAB> for g in m . GraphicalItems ( ) : <TAB><TAB><TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB><TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB><TAB><TAB> parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB> if parsed_drawing : <TAB><TAB><TAB><TAB> edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB><TAB> bbox . Normalize ( ) <TAB> return edges , bbox",if bbox is None :,if bbox is None :,100.0,100.00,True
1693,"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB><TAB> if k . step is not None : <TAB><TAB><TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Must specify start index "" ) <TAB><TAB> elif k . stop is not None : <TAB><TAB><TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB><TAB> else : <TAB><TAB><TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB><TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB><TAB> addr = k <TAB> return self . _deeper ( addr = addr )",elif k . start is None :,elif k . start is None :,100.0,100.00,True
1694,"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB><TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> subobj = self . subcon . _parse ( stream , context . __copy__ ( ) ) <TAB><TAB><TAB><TAB> obj . append ( subobj ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> subobj = self . subcon . _parse ( stream , context ) <TAB><TAB><TAB><TAB> obj . append ( subobj ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB> except ConstructError as ex : <TAB><TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj","if self . predicate ( subobj , context ) :",if self . subcon . conflags & self . FLAG_END_OF_CONTEXT,76.56136427169467,89.84,False
1695,"def before_run ( self , run_context ) : <TAB> if "" featurizer "" in self . model_portion and ( <TAB><TAB> self . need_to_refresh or self . refresh_base_model <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . refresh_base_model = True <TAB><TAB> self . init_fn ( <TAB><TAB><TAB> None , run_context . session , self . model_portion , self . refresh_base_model <TAB><TAB> ) <TAB><TAB> self . need_to_refresh = False <TAB><TAB> self . refresh_base_model = False","if self . model_portion == ""whole_featurizer"" :",if self . refresh_base_model :,93.30177613475257,93.58,False
1696,"def run ( self ) : <TAB> while True : <TAB><TAB> task = self . requestQueue . get ( ) <TAB><TAB> if task is None : <TAB><TAB><TAB> # The ""None"" value is used as a sentinel by <TAB><TAB><TAB> # ThreadPool.cleanup().  This indicates that there <TAB><TAB><TAB> # are no more tasks, so we should quit. <TAB><TAB><TAB> break <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise SCons . Errors . BuildError ( task . targets [ 0 ] , errstr = interrupt_msg ) <TAB><TAB><TAB> task . execute ( ) <TAB><TAB> except : <TAB><TAB><TAB> task . exception_set ( ) <TAB><TAB><TAB> ok = False <TAB><TAB> else : <TAB><TAB><TAB> ok = True <TAB><TAB> self . resultsQueue . put ( ( task , ok ) )",if self . interrupted ( ) :,if task . targets :,97.52782120401187,97.51,False
1697,"def get_overdue_evergreen_documents ( * , db_session ) - > List [ Optional [ Document ] ] : <TAB> """"""Returns all documents that have need had a recent evergreen notification."""""" <TAB> documents = ( <TAB><TAB> db_session . query ( Document ) . filter ( Document . evergreen == True ) <TAB> ) . all ( ) # noqa <TAB> overdue_documents = [ ] <TAB> now = datetime . utcnow ( ) <TAB> for d in documents : <TAB><TAB> next_reminder = d . evergreen_last_reminder_at + timedelta ( <TAB><TAB><TAB> days = d . evergreen_reminder_interval <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> overdue_documents . append ( d ) <TAB> return overdue_documents",if now > next_reminder :,if next_reminder > now :,98.23363942967981,97.68,False
1698,"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB><TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB><TAB> if not exists ( folder ) : <TAB><TAB><TAB> os . mkdir ( folder ) <TAB><TAB><TAB> init_path = join ( folder , "" __init__.py "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> create_file ( init_path )",if not exists ( init_path ) :,if exists ( init_path ) :,74.95570524106391,98.49,False
1699,"def generate ( ) : <TAB> for leaf in u . leaves : <TAB><TAB> <MASK> <TAB><TAB><TAB> val = leaf . get_int_value ( ) <TAB><TAB><TAB> if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB> yield val <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB> if leaf == SymbolTrue : <TAB><TAB><TAB><TAB> yield 1 <TAB><TAB><TAB> elif leaf == SymbolFalse : <TAB><TAB><TAB><TAB> yield 0 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> else : <TAB><TAB><TAB> raise _NoBoolVector","if isinstance ( leaf , Integer ) :","if isinstance ( leaf , Integer ) :",100.0,100.00,True
1700,"def replace ( self , old , new ) : <TAB> v_m = self . var_map <TAB> size = v_m [ self . size ] <TAB> if not ( size . is_const ( ) or size . is_ident ( ) ) : <TAB><TAB> size . replace ( old , new ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> v_m [ new . value ( ) ] = new <TAB><TAB><TAB> self . size = new . value ( ) <TAB><TAB> else : <TAB><TAB><TAB> v_m [ old ] = new",if new . is_ident ( ) :,if new . is_ident ( ) :,100.0,100.00,True
1701,"def method_for_doctype ( doctype ) : <TAB> method = "" xhtml "" <TAB> if doctype : <TAB><TAB> if doctype . startswith ( "" html "" ) : <TAB><TAB><TAB> method = "" html "" <TAB><TAB> <MASK> <TAB><TAB><TAB> method = "" xhtml "" <TAB><TAB> elif doctype . startswith ( "" svg "" ) : <TAB><TAB><TAB> method = "" xml "" <TAB><TAB> else : <TAB><TAB><TAB> method = "" xhtml "" <TAB> return method","elif doctype . startswith ( ""xhtml"" ) :","elif doctype . startswith ( ""xhtml"" ) :",100.0,100.00,True
1702,"def delete ( self , trans , * * kwd ) : <TAB> idnum = kwd [ self . tagged_item_id ] <TAB> item = self . _get_item_from_id ( trans , idnum , check_writable = True ) <TAB> if item is not None : <TAB><TAB> ex_obj = self . get_item_extended_metadata_obj ( trans , item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . unset_item_extended_metadata_obj ( trans , item ) <TAB><TAB><TAB> self . delete_extended_metadata ( trans , ex_obj )",if ex_obj is not None :,if ex_obj is not None :,100.0,100.00,True
1703,"def check_testv ( self , testv ) : <TAB> test_good = True <TAB> f = open ( self . home , "" rb+ "" ) <TAB> for ( offset , length , operator , specimen ) in testv : <TAB><TAB> data = self . _read_share_data ( f , offset , length ) <TAB><TAB> <MASK> <TAB><TAB><TAB> test_good = False <TAB><TAB><TAB> break <TAB> f . close ( ) <TAB> return test_good","if not testv_compare ( data , operator , specimen ) :",if not data :,68.46025713384618,91.14,False
1704,"def get_history_user ( self , instance ) : <TAB> """"""Get the modifying user from instance or middleware."""""" <TAB> try : <TAB><TAB> return instance . _history_user <TAB> except AttributeError : <TAB><TAB> request = None <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> request = self . thread . request <TAB><TAB> except AttributeError : <TAB><TAB><TAB> pass <TAB> return self . get_user ( instance = instance , request = request )",if self . thread . request . user . is_authenticated :,if self . thread :,80.04940475909285,93.46,False
1705,"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB><TAB> for width in VALUES : <TAB><TAB><TAB> strlen = abs ( width * height ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> strlen * = size <TAB><TAB><TAB> if strlen < MAX_LEN : <TAB><TAB><TAB><TAB> data = "" A "" * strlen <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> data = AAAAA <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> arguments = ( data , size , width , height ) + extra <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> arguments = ( data , width , height ) + extra <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> func ( * arguments ) <TAB><TAB><TAB> except ( ValueError , imageop . error ) : <TAB><TAB><TAB><TAB> pass",if size :,if size :,100.0,100.00,True
1706,"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB><TAB> if value and value != "" "" : <TAB><TAB><TAB> if value [ 0 ] != "" / "" : <TAB><TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB><TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB><TAB><TAB><TAB> ) <TAB> elif name == "" load_time "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Page load time must be specified in integer milliseconds. "" <TAB><TAB><TAB> ) <TAB> object . __setattr__ ( self , name , value )","if value and not isinstance ( value , int ) :","if not isinstance ( value , int ) :",70.3792390489475,98.34,False
1707,"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB><TAB> return "" <recursion> "" <TAB> try : <TAB><TAB> self . _in_repr = True <TAB><TAB> if self . is_computed ( ) : <TAB><TAB><TAB> status = "" computed,  "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . value ( ) is self : <TAB><TAB><TAB><TAB><TAB> status + = "" = self "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> status = "" isn ' t computed "" <TAB><TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB><TAB> self . _in_repr = False",if self . error ( ) is None :,if self . is_function ( ) :,97.79570410908747,98.11,False
1708,"def _exclude_node ( self , name ) : <TAB> if "" exclude_nodes "" in self . node_filters : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . loggit . info ( ' Excluding node  "" {0} ""  due to node_filters ' . format ( name ) ) <TAB><TAB><TAB> return True <TAB> return False","if name in self . node_filters [ ""exclude_nodes"" ] :","if self . node_filters [ ""exclude_nodes"" ] :",68.49275155638799,96.44,False
1709,"def enumerate_projects ( ) : <TAB> """"""List projects in _DEFAULT_APP_DIR."""""" <TAB> src_path = os . path . join ( _DEFAULT_APP_DIR , "" src "" ) <TAB> projects = { } <TAB> for project in os . listdir ( src_path ) : <TAB><TAB> projects [ project ] = [ ] <TAB><TAB> project_path = os . path . join ( src_path , project ) <TAB><TAB> for file in os . listdir ( project_path ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> projects [ project ] . append ( file [ : - 8 ] ) <TAB> return projects","if file . endswith ( "".gwt.xml"" ) :","if file . endswith ( "".py"" ) and file . endswith ( "".py"" ) :",68.38791554329913,93.35,False
1710,"def zip_readline_read_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile . ZipFile ( f , "" r "" ) as zipfp , zipfp . open ( TESTFN ) as zipopen : <TAB><TAB> data = b "" "" <TAB><TAB> while True : <TAB><TAB><TAB> read = zipopen . readline ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> data + = read <TAB><TAB><TAB> read = zipopen . read ( 100 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> data + = read <TAB> self . assertEqual ( data , self . data )",if not read :,if not read :,100.0,100.00,True
1711,"def f ( view , s ) : <TAB> if mode == modes . NORMAL : <TAB><TAB> return sublime . Region ( 0 ) <TAB> elif mode == modes . VISUAL : <TAB><TAB> <MASK> <TAB><TAB><TAB> return sublime . Region ( s . a + 1 , 0 ) <TAB><TAB> else : <TAB><TAB><TAB> return sublime . Region ( s . a , 0 ) <TAB> elif mode == modes . INTERNAL_NORMAL : <TAB><TAB> return sublime . Region ( view . full_line ( s . b ) . b , 0 ) <TAB> elif mode == modes . VISUAL_LINE : <TAB><TAB> <MASK> <TAB><TAB><TAB> return sublime . Region ( 0 , s . b ) <TAB><TAB> else : <TAB><TAB><TAB> return sublime . Region ( 0 , s . a ) <TAB> return s",if s . a < s . b :,if s . a < s . b :,75.0,100.00,True
1712,def response ( self ) : <TAB> try : <TAB><TAB> response = requests . get ( str ( self ) ) <TAB><TAB> rjson = response . json ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( response . text ) <TAB><TAB> return rjson <TAB> except Exception as e : <TAB><TAB> raise ResponseFanartError ( str ( e ) ),"if not isinstance ( rjson , dict ) :","if rjson [ ""error"" ] != ""404"" :",63.42859939686023,88.25,False
1713,"def __get_type ( self , cexpr ) : <TAB> """"""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument"""""" <TAB> child = cexpr <TAB> for p in reversed ( self . parents ) : <TAB><TAB> assert p , "" Failed to get type at  "" + helper . to_hex ( self . __function_address ) <TAB><TAB> if p . cexpr . op == idaapi . cot_call : <TAB><TAB><TAB> return "" Arg "" <TAB><TAB> if not p . is_expr ( ) : <TAB><TAB><TAB> return "" R "" <TAB><TAB> if p . cexpr . op == idaapi . cot_asg : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return "" W "" <TAB><TAB><TAB> return "" R "" <TAB><TAB> child = p . cexpr",if p . cexpr . x == child :,if not p . is_expr ( ) :,91.94149331650615,96.21,False
1714,"def _extract_lemma ( self , parse : Parse ) - > str : <TAB> special_feats = [ x for x in self . SPECIAL_FEATURES if x in parse . tag ] <TAB> if len ( special_feats ) == 0 : <TAB><TAB> return parse . normal_form <TAB> # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB> for other in parse . lexeme : <TAB><TAB> tag = other . tag <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if ( <TAB><TAB><TAB> tag . case == "" nomn "" <TAB><TAB><TAB> and tag . gender == parse . tag . gender <TAB><TAB><TAB> and tag . number == "" sing "" <TAB><TAB> ) : <TAB><TAB><TAB> return other . word <TAB> return parse . normal_form",if any ( x not in tag for x in special_feats ) :,"if tag . case == ""surnames"" and tag . number in special_feats :",95.3806260729095,93.50,False
1715,"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB><TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB><TAB><TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB><TAB> else : <TAB><TAB><TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB><TAB><TAB> matched = False <TAB><TAB><TAB> for w in self . words : <TAB><TAB><TAB><TAB> matched = bool ( re . search ( _regex , w ) ) <TAB><TAB><TAB><TAB> if matched : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] )","if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :","elif wildcard_count == - 1 and argument [ 0 ] . endswith ( ""*"" ) :",98.02542436698648,98.28,False
1716,def getAllEntries ( self ) : <TAB> entries = [ ] <TAB> for bucket in self . buckets : <TAB><TAB> last = None <TAB><TAB> for entry in bucket . entries : <TAB><TAB><TAB> if last is not None : <TAB><TAB><TAB><TAB> last . size = entry . virtualOffset - last . virtualOffset <TAB><TAB><TAB> last = entry <TAB><TAB><TAB> entries . append ( entry ) <TAB><TAB> <MASK> <TAB><TAB><TAB> entries [ - 1 ] . size = bucket . endOffset - entries [ - 1 ] . virtualOffset <TAB> return entries,if len ( entries ) != 0 :,if len ( entries ) > 1 :,81.67295894830276,97.12,False
1717,def clean ( self ) : <TAB> if self . _ctx : <TAB><TAB> <MASK> <TAB><TAB><TAB> libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) <TAB><TAB> else : <TAB><TAB><TAB> libcrypto . EVP_CIPHER_CTX_reset ( self . _ctx ) <TAB><TAB> libcrypto . EVP_CIPHER_CTX_free ( self . _ctx ),"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",if libcrypto . EVP_CIPHER_CTX_cleanup ( self . _,56.5937801536907,90.61,False
1718,"def _addTab ( self , name , label , idx = None ) : <TAB> label = getLanguageString ( label ) <TAB> tab = Tab ( self , name , label ) <TAB> tab . idx = self . _makeTab ( tab , idx ) <TAB> if idx != None : <TAB><TAB> # Update index list when inserting tabs at arbitrary positions <TAB><TAB> newIdxList = { } <TAB><TAB> for tIdx , t in list ( self . _tabs_by_idx . items ( ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> t . idx + = 1 <TAB><TAB><TAB> newIdxList [ t . idx ] = t <TAB><TAB> self . _tabs_by_idx = newIdxList <TAB> self . _tabs_by_idx [ tab . idx ] = tab <TAB> self . _tabs_by_name [ tab . name ] = tab <TAB> return tab",if int ( tIdx ) >= idx :,if t . name == name :,97.33740068877627,96.30,False
1719,"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB><TAB> user = self . users . get ( current_user . id , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB><TAB> else : <TAB><TAB><TAB> if _new_login : <TAB><TAB><TAB><TAB> user [ "" session_count "" ] + = 1 <TAB><TAB><TAB> user [ "" key "" ] = _key",if user is None :,if user is None :,100.0,100.00,True
1720,"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try : <TAB><TAB> self . rpcserver . stop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . backend_rpcserver . stop ( ) <TAB><TAB> if self . cluster_rpcserver : <TAB><TAB><TAB> self . cluster_rpcserver . stop ( ) <TAB> except Exception : <TAB><TAB> pass <TAB> if self . coordination : <TAB><TAB> try : <TAB><TAB><TAB> coordination . COORDINATOR . stop ( ) <TAB><TAB> except Exception : <TAB><TAB><TAB> pass <TAB> super ( Service , self ) . stop ( graceful = True )",if self . backend_rpcserver :,if self . backend_rpcserver :,75.0,100.00,True
1721,"def __genmenuOnlyAllocated ( menu ) : <TAB> for submenu in menu . Submenus : <TAB><TAB> __genmenuOnlyAllocated ( submenu ) <TAB> if menu . OnlyUnallocated == True : <TAB><TAB> tmp [ "" cache "" ] . addMenuEntries ( menu . AppDirs ) <TAB><TAB> menuentries = [ ] <TAB><TAB> for rule in menu . Rules : <TAB><TAB><TAB> menuentries = rule . do ( <TAB><TAB><TAB><TAB> tmp [ "" cache "" ] . getMenuEntries ( menu . AppDirs ) , rule . Type , 2 <TAB><TAB><TAB> ) <TAB><TAB> for menuentry in menuentries : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> menuentry . Parents . append ( menu ) <TAB><TAB><TAB><TAB> #   menuentry.Add = False <TAB><TAB><TAB><TAB> #   menuentry.Allocated = True <TAB><TAB><TAB><TAB> menu . MenuEntries . append ( menuentry )",if menuentry . Add == True :,if menuentry . Add :,96.64360831904797,98.13,False
1722,"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB><TAB> from pygments . lexers . _lua_builtins import MODULES <TAB><TAB> for mod , func in iteritems ( MODULES ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options )",if mod not in self . disabled_modules :,if mod in self . func_name_highlighting :,72.40082538235426,95.71,False
1723,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB><TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB><TAB> pr = p . recv_err <TAB> else : <TAB><TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB><TAB> r = pr ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> elif r : <TAB><TAB><TAB> y . append ( r ) <TAB><TAB> else : <TAB><TAB><TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y )",if r is None :,if r == e :,75.24238480745366,97.96,False
1724,"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB><TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB><TAB><TAB> if child . h . startswith ( tag ) : <TAB><TAB><TAB><TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> aList . append ( ( "" %s   %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB><TAB><TAB><TAB><TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB><TAB><TAB><TAB> break <TAB> return aList","if tag == ""@menu"" :",if child . b is None :,84.07662695426652,96.72,False
1725,"def import_suffix_generator ( a_block , datatype = False ) : <TAB> if datatype is False : <TAB><TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield name , suffix <TAB> else : <TAB><TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB><TAB><TAB> if ( suffix . import_enabled ( ) is True ) and ( <TAB><TAB><TAB><TAB> suffix . get_datatype ( ) is datatype <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> yield name , suffix",if suffix . import_enabled ( ) is True :,if suffix . import_enabled ( ) is True :,100.0,100.00,True
1726,"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB><TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB><TAB> if part in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB><TAB> checkpath = os . path . join ( checkpath , part ) <TAB><TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB><TAB> if not os . path . exists ( checkpath ) : <TAB><TAB><TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" )",if os . path . islink ( checkpath ) :,if not os . path . islink ( checkpath ) :,81.57775920040217,98.91,False
1727,"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB><TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if fstyle . startswith ( "" % ( "" ) and fstyle . endswith ( "" )s "" ) : <TAB><TAB><TAB><TAB> key = fstyle [ 2 : - 2 ] <TAB><TAB><TAB><TAB> fstyle = context [ key ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> fstyle = fstyle % context <TAB><TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats","if isinstance ( fstyle , basestring ) :",if fstyle :,74.54074202981532,97.31,False
1728,"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB><TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB><TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ci_names = val . replace ( "" , "" , ""   "" ) . lower ( ) . split ( ) if val else [ ] <TAB><TAB><TAB> if len ( ci_names ) == 0 or ci . lower ( ) in ci_names : <TAB><TAB><TAB><TAB> result = True <TAB> return result","if key == ""CI_KEEP_ALIVE"" :","if key == ""alive"" :",99.0437705934092,96.83,False
1729,"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB><TAB> fn = mo . groups ( ) [ 0 ] <TAB><TAB> fn = fn . replace ( ""   "" , "" _ "" ) <TAB><TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB><TAB> if not fn : <TAB><TAB><TAB> return "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB><TAB> else : <TAB><TAB><TAB> fn = unicode ( fn ) <TAB><TAB> if note_markdown ( note ) : <TAB><TAB><TAB> fn + = "" .mkdn "" <TAB><TAB> else : <TAB><TAB><TAB> fn + = "" .txt "" <TAB><TAB> return fn <TAB> else : <TAB><TAB> return "" ""","if isinstance ( fn , str ) :","if isinstance ( fn , str ) :",100.0,100.00,True
1730,"def post ( self , orgname , teamname ) : <TAB> if _syncing_setup_allowed ( orgname ) : <TAB><TAB> try : <TAB><TAB><TAB> team = model . team . get_organization_team ( orgname , teamname ) <TAB><TAB> except model . InvalidTeamException : <TAB><TAB><TAB> raise NotFound ( ) <TAB><TAB> config = request . get_json ( ) <TAB><TAB> # Ensure that the specified config points to a valid group. <TAB><TAB> status , err = authentication . check_group_lookup_args ( config ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidRequest ( "" Could not sync to group:  %s "" % err ) <TAB><TAB> # Set the team's syncing config. <TAB><TAB> model . team . set_team_syncing ( team , authentication . federated_service , config ) <TAB><TAB> return team_view ( orgname , team ) <TAB> raise Unauthorized ( )",if not status :,if status != 200 :,98.40854288491133,97.74,False
1731,"def _marshalData ( self ) : <TAB> if self . _cache == None : <TAB><TAB> d = self . _data <TAB><TAB> s = "" "" <TAB><TAB> s = time . strftime ( "" % H: % M: % S "" , ( 0 , 0 , 0 ) + d + ( 0 , 0 , - 1 ) ) <TAB><TAB> f = d [ 2 ] - int ( d [ 2 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> s + = ( "" %g "" % f ) [ 1 : ] <TAB><TAB> s + = "" Z "" <TAB><TAB> self . _cache = s <TAB> return self . _cache",if f != 0 :,if f > 0 :,98.88926599274323,97.93,False
1732,"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB><TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB><TAB> if level_ref < 0 : <TAB><TAB><TAB> level_ref + = len ( levels ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB><TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) )",if not ( 0 <= level_ref < len ( levels ) ) :,if level_ref >= len ( levels ) :,67.66311064254086,93.72,False
1733,"def iterfieldselect ( source , field , where , complement , missing ) : <TAB> it = iter ( source ) <TAB> hdr = next ( it ) <TAB> yield tuple ( hdr ) <TAB> indices = asindices ( hdr , field ) <TAB> getv = operator . itemgetter ( * indices ) <TAB> for row in it : <TAB><TAB> try : <TAB><TAB><TAB> v = getv ( row ) <TAB><TAB> except IndexError : <TAB><TAB><TAB> v = missing <TAB><TAB> <MASK> # XOR <TAB><TAB><TAB> yield tuple ( row )",if bool ( where ( v ) ) != complement :,if v == where :,81.32737462779738,92.65,False
1734,"def _test_wait_read_invalid_switch ( self , sleep ) : <TAB> sock1 , sock2 = socket . socketpair ( ) <TAB> try : <TAB><TAB> p = gevent . spawn ( <TAB><TAB><TAB> util . wrap_errors ( <TAB><TAB><TAB><TAB> AssertionError , socket . wait_read <TAB><TAB><TAB> ) , # pylint:disable=no-member <TAB><TAB><TAB> sock1 . fileno ( ) , <TAB><TAB> ) <TAB><TAB> gevent . get_hub ( ) . loop . run_callback ( switch_None , p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> gevent . sleep ( sleep ) <TAB><TAB> result = p . get ( ) <TAB><TAB> assert isinstance ( result , AssertionError ) , result <TAB><TAB> assert "" Invalid switch "" in str ( result ) , repr ( str ( result ) ) <TAB> finally : <TAB><TAB> sock1 . close ( ) <TAB><TAB> sock2 . close ( )",if sleep is not None :,if sleep is not None :,100.0,100.00,True
1735,"def train ( config , args ) : <TAB> gan = setup_gan ( config , inputs , args ) <TAB> test_batches = [ ] <TAB> for i in range ( args . steps ) : <TAB><TAB> gan . step ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> correct_prediction = 0 <TAB><TAB><TAB> total = 0 <TAB><TAB><TAB> for ( x , y ) in gan . inputs . testdata ( ) : <TAB><TAB><TAB><TAB> prediction = gan . generator ( x ) <TAB><TAB><TAB><TAB> correct_prediction + = ( <TAB><TAB><TAB><TAB><TAB> torch . argmax ( prediction , 1 ) == torch . argmax ( y , 1 ) <TAB><TAB><TAB><TAB> ) . sum ( ) <TAB><TAB><TAB><TAB> total + = y . shape [ 0 ] <TAB><TAB><TAB> accuracy = ( float ( correct_prediction ) / total ) * 100 <TAB><TAB><TAB> print ( "" accuracy:  "" , accuracy ) <TAB> return sum_metrics",if i % args . sample_every == 0 and i > 0 :,if i == args . steps - 1 :,93.37746871671524,95.39,False
1736,"def process_response ( self , request , response , spider ) : <TAB> if not response . body : <TAB><TAB> return response <TAB> for fmt , func in six . iteritems ( self . _formats ) : <TAB><TAB> new_response = func ( response ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( <TAB><TAB><TAB><TAB> "" Decompressed response with format:  %(responsefmt)s "" , <TAB><TAB><TAB><TAB> { "" responsefmt "" : fmt } , <TAB><TAB><TAB><TAB> extra = { "" spider "" : spider } , <TAB><TAB><TAB> ) <TAB><TAB><TAB> return new_response <TAB> return response",if new_response :,if new_response is not None :,83.41516848603888,97.54,False
1737,"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB> if option != other_option : <TAB><TAB><TAB><TAB><TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB><TAB><TAB><TAB><TAB><TAB> raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return option","if scan_argv ( self . argv , option ) is not None :","if option . startswith ( ""://"" ) :",66.74953237635751,93.48,False
1738,"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr ( storefile , "" read "" ) : <TAB><TAB> storefile = open ( storefile , "" rb "" ) <TAB> # Adjust store to have translations <TAB> store = cls . convertfile ( storefile , template_store ) <TAB> for unit in store . units : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # HTML does this properly on loading, others need it <TAB><TAB> if cls . needs_target_sync : <TAB><TAB><TAB> unit . target = unit . source <TAB><TAB><TAB> unit . rich_target = unit . rich_source <TAB> return store",if unit . isheader ( ) :,if unit . is_inline :,73.01865049717522,97.51,False
1739,"def _pre_get_table ( self , _ctx , table_name ) : <TAB> vsctl_table = self . _get_table ( table_name ) <TAB> schema_helper = self . schema_helper <TAB> schema_helper . register_table ( vsctl_table . table_name ) <TAB> for row_id in vsctl_table . row_ids : <TAB><TAB> <MASK> <TAB><TAB><TAB> schema_helper . register_table ( row_id . table ) <TAB><TAB> if row_id . name_column : <TAB><TAB><TAB> schema_helper . register_columns ( row_id . table , [ row_id . name_column ] ) <TAB><TAB> if row_id . uuid_column : <TAB><TAB><TAB> schema_helper . register_columns ( row_id . table , [ row_id . uuid_column ] ) <TAB> return vsctl_table",if row_id . table :,"if isinstance ( row_id . table , str ) :",96.2910855600516,96.44,False
1740,"def __init__ ( self , pin = None , pull_up = False ) : <TAB> super ( InputDevice , self ) . __init__ ( pin ) <TAB> try : <TAB><TAB> self . pin . function = "" input "" <TAB><TAB> pull = "" up "" if pull_up else "" down "" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . pin . pull = pull <TAB> except : <TAB><TAB> self . close ( ) <TAB><TAB> raise <TAB> self . _active_state = False if pull_up else True <TAB> self . _inactive_state = True if pull_up else False",if self . pin . pull != pull :,if pull :,82.4064969347235,94.77,False
1741,"def _increment_operations_count ( self , operation , executed ) : <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _executed_operations + = 1 <TAB><TAB><TAB> self . _executed [ operation . job_type ] + = 1 <TAB><TAB> else : <TAB><TAB><TAB> self . _skipped [ operation . job_type ] + = 1",if executed :,if executed :,100.0,100.00,True
1742,"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super ( ) . emit ( type , info ) <TAB> if self . _has_proxy is True and self . _session . status > 0 : <TAB><TAB> # implicit: and self._disposed is False: <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB><TAB> elif type in self . __event_types_at_proxy : <TAB><TAB><TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] )",if type in self . __proxy_properties__ :,if type in self . __event_types_at_proxy :,98.99518337698258,96.46,False
1743,"def validate_pull_secret ( namespace ) : <TAB> if namespace . pull_secret is None : <TAB><TAB> # TODO: add aka.ms link here <TAB><TAB> warning = ( <TAB><TAB><TAB> "" No --pull-secret provided: cluster will not include samples or operators from  "" <TAB><TAB><TAB> + "" Red Hat or from certified partners. "" <TAB><TAB> ) <TAB><TAB> logger . warning ( warning ) <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Exception ( ) <TAB><TAB> except : <TAB><TAB><TAB> raise InvalidArgumentValueError ( "" Invalid --pull-secret. "" )","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :","if namespace . pull_secret not in ( ""samples"" , ""operators"" ) :",93.75516389897281,93.44,False
1744,"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB><TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB><TAB> if type == "" V "" : <TAB><TAB><TAB> write_vuint ( port , value ) <TAB><TAB> elif type == "" v "" : <TAB><TAB><TAB> write_vint ( port , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> write_bvec ( port , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( )","elif type == ""s"" :","elif type == ""bvec"" :",99.02661778217407,98.77,False
1745,"def data ( self ) : <TAB> if self . _data is not None : <TAB><TAB> return self . _data <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> with open ( self . path , "" rb "" ) as jsonfile : <TAB><TAB><TAB><TAB> data = jsonfile . read ( ) . decode ( "" utf8 "" ) <TAB><TAB><TAB><TAB> data = json . loads ( data ) <TAB><TAB><TAB><TAB> self . _data = data <TAB><TAB><TAB><TAB> return self . _data <TAB><TAB> else : <TAB><TAB><TAB> return dict ( )",if os . path . exists ( self . path ) :,if os . path . exists ( self . path ) :,100.0,100.00,True
1746,"def interact ( self ) : <TAB> self . output . write ( "" \n "" ) <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> request = self . getline ( "" help>  "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> except ( KeyboardInterrupt , EOFError ) : <TAB><TAB><TAB> break <TAB><TAB> request = strip ( request ) <TAB><TAB> # Make sure significant trailing quotation marks of literals don't <TAB><TAB> # get deleted while cleaning input <TAB><TAB> if ( <TAB><TAB><TAB> len ( request ) > 2 <TAB><TAB><TAB> and request [ 0 ] == request [ - 1 ] in ( "" ' "" , ' "" ' ) <TAB><TAB><TAB> and request [ 0 ] not in request [ 1 : - 1 ] <TAB><TAB> ) : <TAB><TAB><TAB> request = request [ 1 : - 1 ] <TAB><TAB> if lower ( request ) in ( "" q "" , "" quit "" ) : <TAB><TAB><TAB> break <TAB><TAB> self . help ( request )",if not request :,"if request == """" :",96.36515175232928,97.85,False
1747,"def api_attachment_metadata ( self ) : <TAB> resp = [ ] <TAB> for part in self . parts : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> k = { <TAB><TAB><TAB> "" content_type "" : part . block . content_type , <TAB><TAB><TAB> "" size "" : part . block . size , <TAB><TAB><TAB> "" filename "" : part . block . filename , <TAB><TAB><TAB> "" id "" : part . block . public_id , <TAB><TAB> } <TAB><TAB> content_id = part . content_id <TAB><TAB> if content_id : <TAB><TAB><TAB> if content_id [ 0 ] == "" < "" and content_id [ - 1 ] == "" > "" : <TAB><TAB><TAB><TAB> content_id = content_id [ 1 : - 1 ] <TAB><TAB><TAB> k [ "" content_id "" ] = content_id <TAB><TAB> resp . append ( k ) <TAB> return resp",if not part . is_attachment :,if part . block . public_id is None :,71.14166258498716,96.62,False
1748,"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB><TAB> if line . startswith ( u ( "" Skipping "" ) ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB><TAB><TAB> newdiff . append ( u ( ""    "" ) + line [ 2 : ] ) <TAB><TAB> else : <TAB><TAB><TAB> newdiff . append ( line ) <TAB> return newdiff","if line . startswith ( u ( ""- "" ) ) :","if line . startswith ( u ( ""Not Found"" ) ) :",98.95558981561932,98.58,False
1749,"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB><TAB> API_CACHE_LOCK . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> API_CACHE = { } <TAB><TAB><TAB> if API_CACHE . get ( url ) is None : <TAB><TAB><TAB><TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB><TAB> finally : <TAB><TAB><TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api",if API_CACHE is None :,if API_CACHE is None :,100.0,100.00,True
1750,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_index_name_ : <TAB><TAB> res + = prefix + ( "" index_name:  %s \n "" % self . DebugFormatString ( self . index_name_ ) ) <TAB> cnt = 0 <TAB> for e in self . prefix_value_ : <TAB><TAB> elm = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> elm = "" ( %d ) "" % cnt <TAB><TAB> res + = prefix + ( "" prefix_value %s :  %s \n "" % ( elm , self . DebugFormatString ( e ) ) ) <TAB><TAB> cnt + = 1 <TAB> if self . has_value_prefix_ : <TAB><TAB> res + = prefix + ( <TAB><TAB><TAB> "" value_prefix:  %s \n "" % self . DebugFormatBool ( self . value_prefix_ ) <TAB><TAB> ) <TAB> return res",if printElemNumber :,if printElemNumber :,100.0,100.00,True
1751,"def add_group ( x , nl , in_group , mw ) : <TAB> if len ( x ) == 0 : <TAB><TAB> return x <TAB> if len ( x ) > 1 and not in_group : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ "" [[ "" ] + x + [ "" ]] "" ] <TAB><TAB> mw . warn ( <TAB><TAB><TAB> "" Equation will multiplex and may produce inaccurate results (see manual) "" <TAB><TAB> ) <TAB> return [ "" [ "" ] + x + [ "" ] "" ]","if supports_group ( x , nl ) :",if nl :,68.60017032081373,93.70,False
1752,"def unfulfilled_items ( self ) : <TAB> unfulfilled_items = 0 <TAB> for order_item in self . items . all ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> aggr = order_item . deliver_item . aggregate ( delivered = Sum ( "" quantity "" ) ) <TAB><TAB><TAB> unfulfilled_items + = order_item . quantity - ( aggr [ "" delivered "" ] or 0 ) <TAB> return unfulfilled_items",if not order_item . canceled :,if order_item . quantity :,68.97186130201781,95.48,False
1753,"def _get_pattern ( self , pattern_id ) : <TAB> """"""Get pattern item by id."""""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> data = self . tagged_blocks . get_data ( key ) <TAB><TAB><TAB> for pattern in data : <TAB><TAB><TAB><TAB> if pattern . pattern_id == pattern_id : <TAB><TAB><TAB><TAB><TAB> return pattern <TAB> return None",if key in self . tagged_blocks :,if self . tagged_blocks . has_key ( key ) :,93.0166769533117,93.45,False
1754,"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB><TAB> rs = domain . connection . query_with_attributes ( <TAB><TAB><TAB> domain , query , attr_names , next_token = next_token <TAB><TAB> ) <TAB><TAB> for item in rs : <TAB><TAB><TAB> if max_items : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise StopIteration <TAB><TAB><TAB> yield item <TAB><TAB><TAB> num_results + = 1 <TAB><TAB> next_token = rs . next_token <TAB><TAB> more_results = next_token != None",if num_results == max_items :,if num_results >= max_items :,98.67473751783298,98.89,False
1755,"def find_deprecated_settings ( source ) : # pragma: no cover <TAB> from celery . utils import deprecated <TAB> for name , opt in flatten ( NAMESPACES ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> deprecated . warn ( <TAB><TAB><TAB><TAB> description = "" The  {0!r}  setting "" . format ( name ) , <TAB><TAB><TAB><TAB> deprecation = opt . deprecate_by , <TAB><TAB><TAB><TAB> removal = opt . remove_by , <TAB><TAB><TAB><TAB> alternative = "" Use the  {0.alt}  instead "" . format ( opt ) , <TAB><TAB><TAB> ) <TAB> return source","if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",if opt . deprecate_by and not opt . remove_by :,66.61495413187741,91.43,False
1756,"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . server . stop ( 2.0 ) <TAB><TAB> if self . sl_hdlr : <TAB><TAB><TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB><TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,75.0,100.00,True
1757,"def broadcast_events ( self , events ) : <TAB> LOGGER . debug ( "" Broadcasting events:  %s "" , events ) <TAB> with self . _subscribers_cv : <TAB><TAB> # Copy the subscribers <TAB><TAB> subscribers = { conn : sub . copy ( ) for conn , sub in self . _subscribers . items ( ) } <TAB> if subscribers : <TAB><TAB> for connection_id , subscriber in subscribers . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> subscriber_events = [ <TAB><TAB><TAB><TAB><TAB> event for event in events if subscriber . is_subscribed ( event ) <TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB><TAB> event_list = EventList ( events = subscriber_events ) <TAB><TAB><TAB><TAB> self . _send ( connection_id , event_list . SerializeToString ( ) )",if subscriber . is_listening ( ) :,"if isinstance ( subscriber , EventSubscriber ) :",97.72220970615366,96.97,False
1758,"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB><TAB> stdout = None <TAB><TAB> try : <TAB><TAB><TAB> stdout , stderr = Popen ( <TAB><TAB><TAB><TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB><TAB><TAB><TAB> stdout = PIPE , <TAB><TAB><TAB><TAB> stderr = PIPE , <TAB><TAB><TAB> ) . communicate ( ) <TAB><TAB> except OSError : <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> if stdout : <TAB><TAB><TAB><TAB> for line in stdout . splitlines ( ) : <TAB><TAB><TAB><TAB><TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info",if len ( line ) == 2 :,if len ( line ) > 1 :,82.00259316915674,98.53,False
1759,"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB><TAB> "" memcmp "" , <TAB><TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB><TAB> if a . is_null != b . is_null : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> if len ( a ) != b . len : <TAB><TAB><TAB> return False <TAB><TAB> if a . ptr == b . ptr : <TAB><TAB><TAB> return True <TAB><TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if a is None :,if a . ptr != b . ptr :,96.39225770513178,96.49,False
1760,"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB><TAB> for item in args : <TAB><TAB><TAB> if type ( item ) is ActionHandle : <TAB><TAB><TAB><TAB> ahs . add ( item ) <TAB><TAB><TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB><TAB><TAB><TAB> for ah in item : <TAB><TAB><TAB><TAB><TAB> <MASK> # pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB> ahs . add ( ah ) <TAB><TAB><TAB> else : # pragma:nocover <TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs",if type ( ah ) is not ActionHandle :,"if not isinstance ( ah , ActionHandle ) :",94.53462328023883,97.12,False
1761,"def startElement ( self , name , attrs , connection ) : <TAB> if name == "" Parameter "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self [ self . _current_param . name ] = self . _current_param <TAB><TAB> self . _current_param = Parameter ( self ) <TAB><TAB> return self . _current_param",if self . _current_param :,if self . _current_param :,100.0,100.00,True
1762,"def _find_class_in_descendants ( self , search_key ) : <TAB> for cls in self . primitive_classes : <TAB><TAB> cls_key = ( cls . __name__ , cls . __module__ ) <TAB><TAB> self . class_cache [ cls_key ] = cls <TAB><TAB> <MASK> <TAB><TAB><TAB> return cls",if cls_key == search_key :,if search_key in cls_key :,70.43884729652818,94.67,False
1763,"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB><TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB><TAB> if c1 : <TAB><TAB><TAB> v . append ( sibling ) <TAB><TAB> else : <TAB><TAB><TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB><TAB><TAB> if c2 : <TAB><TAB><TAB><TAB> v . append ( sibling ) <TAB><TAB> ### regardless of match or not, check any children for matches <TAB><TAB> <MASK> <TAB><TAB><TAB> sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB><TAB> sibling = sibling . getNextSibling ( )",if sibling . getFirstChild ( ) :,if sibling . getFirstChild ( ) :,100.0,100.00,True
1764,"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB><TAB> if i > 0 : <TAB><TAB><TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB><TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB><TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB><TAB> outputs . append ( block_out ) <TAB><TAB> <MASK> <TAB><TAB><TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB><TAB><TAB> route = self . upsample ( route ) <TAB> return outputs",if i < 2 :,if route is not None :,77.54641210812888,97.21,False
1765,"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude : <TAB><TAB> # Items ending in '/' apply only to directories. <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # Items starting with '/' apply to the whole path. <TAB><TAB> # In any other cases just the basename is used. <TAB><TAB> match = path if item . startswith ( "" / "" ) else basename <TAB><TAB> if fnmatch . fnmatch ( match , item . strip ( "" / "" ) ) : <TAB><TAB><TAB> return True <TAB> return False","if item . endswith ( ""/"" ) and not is_dir :","if is_dir and not item . startswith ( ""/"" ) :",96.5537721999603,95.56,False
1766,"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB><TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> if line . startswith ( ' "" "" "" ' ) : <TAB><TAB><TAB> found + = 1 <TAB><TAB><TAB> if found == 2 : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break # already in the right place <TAB><TAB><TAB><TAB> lines . insert ( i + 1 , "" "" ) <TAB><TAB><TAB><TAB> lines . insert ( i + 2 , division ) <TAB><TAB><TAB><TAB> break <TAB> return "" \n "" . join ( lines )","if division in ""\n"" . join ( lines ) :",if lines [ i + 1 ] == division :,93.32459982850199,94.62,False
1767,"def buildImage ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" COCO-IMG-2015 "" ) <TAB> version = "" 1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB><TAB> print ( "" [building image data:  "" + dpath + "" ] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # An older version exists, so remove these outdated files. <TAB><TAB><TAB> build_data . remove_dir ( dpath ) <TAB><TAB> build_data . make_dir ( dpath ) <TAB><TAB> # Download the data. <TAB><TAB> for downloadable_file in RESOURCES [ : 1 ] : <TAB><TAB><TAB> downloadable_file . download_file ( dpath ) <TAB><TAB> # Mark the data as built. <TAB><TAB> build_data . mark_done ( dpath , version_string = version )",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,100.0,100.00,True
1768,"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB><TAB> col = text [ 1 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return col <TAB><TAB> elif len ( col ) == 3 : <TAB><TAB><TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB><TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text",if len ( col ) == 6 :,if len ( col ) == 4 :,98.64199878325732,98.18,False
1769,"def tree_print ( tree ) : <TAB> for key in tree : <TAB><TAB> print ( key , end = ""   "" ) # end=' ' prevents a newline character <TAB><TAB> tree_element = tree [ key ] # multiple lookups is expensive, even amortized O(1)! <TAB><TAB> for subElem in tree_element : <TAB><TAB><TAB> print ( ""  ->  "" , subElem , end = ""   "" ) <TAB><TAB><TAB> <MASK> # OP wants indenting after digits <TAB><TAB><TAB><TAB> print ( "" \n   "" ) # newline and a space to match indenting <TAB><TAB> print ( ) # forces a newline",if type ( subElem ) != str :,if len ( tree_element ) > 1 :,71.55365526991574,94.58,False
1770,"def is_dse_cluster ( path ) : <TAB> try : <TAB><TAB> with open ( os . path . join ( path , "" CURRENT "" ) , "" r "" ) as f : <TAB><TAB><TAB> name = f . readline ( ) . strip ( ) <TAB><TAB><TAB> cluster_path = os . path . join ( path , name ) <TAB><TAB><TAB> filename = os . path . join ( cluster_path , "" cluster.conf "" ) <TAB><TAB><TAB> with open ( filename , "" r "" ) as f : <TAB><TAB><TAB><TAB> data = yaml . load ( f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> except IOError : <TAB><TAB> return False","if ""dse_dir"" in data :","if data [ ""version"" ] == ""1.0.0"" :",68.89588611964786,94.21,False
1771,"def delete_old_target_output_files ( classpath_prefix ) : <TAB> """"""Delete existing output files or symlinks for target."""""" <TAB> directory , basename = os . path . split ( classpath_prefix ) <TAB> pattern = re . compile ( <TAB><TAB> r "" ^ {basename} (([0-9]+)( \ .jar)?|classpath \ .txt)$ "" . format ( <TAB><TAB><TAB> basename = re . escape ( basename ) <TAB><TAB> ) <TAB> ) <TAB> files = [ filename for filename in os . listdir ( directory ) if pattern . match ( filename ) ] <TAB> for rel_path in files : <TAB><TAB> path = os . path . join ( directory , rel_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> safe_delete ( path )",if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . exists ( path ) :,66.57677248355013,94.68,False
1772,"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB> names = [ ] <TAB> for d in self . test_directories : <TAB><TAB> test_dir = os . path . join ( dist_dir , d ) <TAB><TAB> for n in os . listdir ( test_dir ) : <TAB><TAB><TAB> if n . endswith ( "" .py "" ) and not n . startswith ( "" bad "" ) : <TAB><TAB><TAB><TAB> names . append ( os . path . join ( test_dir , n ) ) <TAB> for filename in names : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Testing  %s "" % filename ) <TAB><TAB> source = read_pyfile ( filename ) <TAB><TAB> self . check_roundtrip ( source )",if test_support . verbose :,if self . verbose :,74.1632233921046,98.10,False
1773,"def __str__ ( self ) : <TAB> if self . HasError ( ) : <TAB><TAB> return self . ErrorAsStr ( ) <TAB> else : <TAB><TAB> # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB><TAB> string = self . _action <TAB><TAB> if self . _target is not None : <TAB><TAB><TAB> string + = '   "" {target} "" ' . format ( target = self . _target ) <TAB><TAB> <MASK> <TAB><TAB><TAB> path = self . _filename <TAB><TAB><TAB> if self . _lineno is not None : <TAB><TAB><TAB><TAB> path + = "" : {lineno} "" . format ( lineno = self . _lineno ) <TAB><TAB><TAB> string + = ""  ( {path} ) "" . format ( path = path ) <TAB><TAB> return string",if self . _filename is not None :,if self . _filename is not None :,100.0,100.00,True
1774,"def extra_action_out ( self , input_dict , state_batches , model , action_dist ) : <TAB> with self . _no_grad_context ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> stats_dict = extra_action_out_fn ( <TAB><TAB><TAB><TAB> self , input_dict , state_batches , model , action_dist <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> stats_dict = parent_cls . extra_action_out ( <TAB><TAB><TAB><TAB> self , input_dict , state_batches , model , action_dist <TAB><TAB><TAB> ) <TAB><TAB> return self . _convert_to_non_torch_type ( stats_dict )",if extra_action_out_fn :,if extra_action_out_fn :,100.0,100.00,True
1775,"def _retract_bindings ( fstruct , inv_bindings , fs_class , visited ) : <TAB> # Visit each node only once: <TAB> if id ( fstruct ) in visited : <TAB><TAB> return <TAB> visited . add ( id ( fstruct ) ) <TAB> if _is_mapping ( fstruct ) : <TAB><TAB> items = fstruct . items ( ) <TAB> elif _is_sequence ( fstruct ) : <TAB><TAB> items = enumerate ( fstruct ) <TAB> else : <TAB><TAB> raise ValueError ( "" Expected mapping or sequence "" ) <TAB> for ( fname , fval ) in items : <TAB><TAB> if isinstance ( fval , fs_class ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> fstruct [ fname ] = inv_bindings [ id ( fval ) ] <TAB><TAB><TAB> _retract_bindings ( fval , inv_bindings , fs_class , visited )",if id ( fval ) in inv_bindings :,if id ( fval ) in inv_bindings :,75.0,100.00,True
1776,"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not isinstance ( dep . repo , WarehouseBaseRepo ) : <TAB><TAB><TAB> continue <TAB><TAB> for repo in dep . repo . repos : <TAB><TAB><TAB> if repo . from_config : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) )",if dep . repo is None :,if dep . repo is None :,100.0,100.00,True
1777,"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB><TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB><TAB> if not isinstance ( key , str ) : <TAB><TAB><TAB> key = str ( key ) <TAB><TAB> detyper = self . get_detyper ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # cannot be detyped <TAB><TAB><TAB> continue <TAB><TAB> deval = detyper ( val ) <TAB><TAB> if deval is None : <TAB><TAB><TAB> # cannot be detyped <TAB><TAB><TAB> continue <TAB><TAB> ctx [ key ] = deval <TAB> self . _detyped = ctx <TAB> return ctx",if detyper is None :,if detyper is None :,100.0,100.00,True
1778,"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB><TAB> # If field should be deleted, clean it up <TAB><TAB> <MASK> <TAB><TAB><TAB> field . delete ( ) <TAB><TAB><TAB> return <TAB><TAB> if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) : <TAB><TAB><TAB> if not field . grid_id : <TAB><TAB><TAB><TAB> func = field . put <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> func = field . replace <TAB><TAB><TAB> func ( <TAB><TAB><TAB><TAB> self . data . stream , <TAB><TAB><TAB><TAB> filename = self . data . filename , <TAB><TAB><TAB><TAB> content_type = self . data . content_type , <TAB><TAB><TAB> )",if self . _should_delete :,if self . data . deleted :,98.60643542664927,97.88,False
1779,"def _load ( container ) : <TAB> if isinstance ( container , str ) : <TAB><TAB> # If container is a filename. <TAB><TAB> <MASK> <TAB><TAB><TAB> with open ( container , "" rb "" ) as f : <TAB><TAB><TAB><TAB> return pickle . load ( f ) <TAB><TAB> # If container is a pickle string. <TAB><TAB> else : <TAB><TAB><TAB> return pickle . loads ( container ) <TAB> # If container is an open file <TAB> elif isinstance ( container , IOBase ) : <TAB><TAB> return pickle . load ( container ) <TAB> # What else could it be? <TAB> else : <TAB><TAB> l . error ( "" Cannot unpickle container of type  %s "" , type ( container ) ) <TAB><TAB> return None",if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,if os . path . isfile ( container ) :,93.68702549172609,92.07,False
1780,"def append_row ( self , row ) : <TAB> self . allocate_future_payments ( row ) <TAB> self . set_invoice_details ( row ) <TAB> self . set_party_details ( row ) <TAB> self . set_ageing ( row ) <TAB> if self . filters . get ( "" group_by_party "" ) : <TAB><TAB> self . update_sub_total_row ( row , row . party ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . append_subtotal_row ( self . previous_party ) <TAB><TAB> self . previous_party = row . party <TAB> self . data . append ( row )",if self . previous_party and ( self . previous_party != row . party ) :,if self . previous_party :,84.56504765284218,91.47,False
1781,"def gg1 ( ) : <TAB> while 1 : <TAB><TAB> tt = 3 <TAB><TAB> while tt > 0 : <TAB><TAB><TAB> trace . append ( tt ) <TAB><TAB><TAB> val = yield <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tt = 10 # <= uncomment this line <TAB><TAB><TAB><TAB> trace . append ( "" breaking early... "" ) <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> tt - = 1 <TAB><TAB> trace . append ( "" try! "" )",if val is not None :,if val is not None :,100.0,100.00,True
1782,"def migrate_common_facts ( facts ) : <TAB> """"""Migrate facts from various roles into common"""""" <TAB> params = { "" node "" : ( "" portal_net "" ) , "" master "" : ( "" portal_net "" ) } <TAB> if "" common "" not in facts : <TAB><TAB> facts [ "" common "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB><TAB> if role in facts : <TAB><TAB><TAB> for param in params [ role ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> facts [ "" common "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts",if param in facts [ role ] :,"if param in facts [ ""common"" ] :",98.93668103102364,97.63,False
1783,"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB> results = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if object_name == "" Image "" : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" ] <TAB><TAB> if self . do_overlap : <TAB><TAB><TAB> results + = [ "" Overlap "" , "" K "" ] <TAB><TAB> if self . do_manders : <TAB><TAB><TAB> results + = [ "" Manders "" ] <TAB><TAB> if self . do_rwc : <TAB><TAB><TAB> results + = [ "" RWC "" ] <TAB><TAB> if self . do_costes : <TAB><TAB><TAB> results + = [ "" Costes "" ] <TAB><TAB> return results <TAB> return [ ]",if self . do_corr_and_slope :,if self . do_correlation :,99.11571885693424,97.64,False
1784,"def access_modes ( self ) : <TAB> """"""access_modes property"""""" <TAB> if self . _access_modes is None : <TAB><TAB> self . _access_modes = self . get_access_modes ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _access_modes = list ( self . _access_modes ) <TAB> return self . _access_modes","if not isinstance ( self . _access_modes , list ) :","if isinstance ( self . _access_modes , list ) :",91.45633505587635,97.71,False
1785,"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : <TAB><TAB><TAB><TAB> self . context [ "" total "" ] = len ( data ) <TAB><TAB><TAB><TAB> return data <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB><TAB> else : <TAB><TAB><TAB> self . context [ "" total "" ] = 0 <TAB><TAB><TAB> data = { "" items "" : [ ] } <TAB><TAB> return data [ "" items "" ] <TAB> return data","if data [ ""items"" ] :",if data :,96.76728652826661,96.66,False
1786,"def to_string ( self , fmt = "" {:.4f} "" ) : <TAB> result_str = "" "" <TAB> for key in self . measures : <TAB><TAB> result = self . m_dict [ key ] [ 0 ] ( ) <TAB><TAB> result_str + = ( <TAB><TAB><TAB> "" , "" . join ( fmt . format ( x ) for x in result ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else fmt . format ( result ) <TAB><TAB> ) <TAB><TAB> result_str + = "" , "" <TAB> return result_str [ : - 1 ] # trim the last comma","if isinstance ( result , tuple )",if len ( result ) == 1,69.43294783458018,95.45,False
1787,"def on_torrent_created ( self , result ) : <TAB> if not result : <TAB><TAB> return <TAB> self . dialog_widget . btn_create . setEnabled ( True ) <TAB> self . dialog_widget . edit_channel_create_torrent_progress_label . setText ( <TAB><TAB> "" Created torrent "" <TAB> ) <TAB> if "" torrent "" in result : <TAB><TAB> self . create_torrent_notification . emit ( { "" msg "" : "" Torrent successfully created "" } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_torrent_to_channel ( result [ "" torrent "" ] ) <TAB><TAB> self . close_dialog ( )",if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,"if result [ ""torrent"" ] :",67.74236277830762,89.61,False
1788,"def save ( self ) : <TAB> for var_name in self . default_config : <TAB><TAB> <MASK> <TAB><TAB><TAB> if var_name in self . file_config : <TAB><TAB><TAB><TAB> del self . file_config [ var_name ] <TAB><TAB> else : <TAB><TAB><TAB> self . file_config [ var_name ] = getattr ( self , var_name ) <TAB> with open ( self . config_path , "" w "" ) as f : <TAB><TAB> f . write ( json . dumps ( self . file_config , indent = 2 ) )","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",if var_name not in self . file_config :,89.27479194295648,87.83,False
1789,"def get_class_parameters ( kwarg ) : <TAB> ret = { "" attrs "" : [ ] } <TAB> for key in ( "" rsc "" , "" fsc "" , "" usc "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret [ "" attrs "" ] . append ( <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> "" TCA_HFSC_ %s "" % key . upper ( ) , <TAB><TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB><TAB> "" m1 "" : get_rate ( kwarg [ key ] . get ( "" m1 "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB><TAB> "" d "" : get_time ( kwarg [ key ] . get ( "" d "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB><TAB> "" m2 "" : get_rate ( kwarg [ key ] . get ( "" m2 "" , 0 ) ) , <TAB><TAB><TAB><TAB><TAB> } , <TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB> ) <TAB> return ret",if key in kwarg :,if kwarg [ key ] :,97.99608789057415,98.32,False
1790,"def forward ( self , x ) : <TAB> f_x = x <TAB> if self . exp : <TAB><TAB> f_x = self . exp_swish ( self . exp_bn ( self . exp ( f_x ) ) ) <TAB> f_x = self . dwise_swish ( self . dwise_bn ( self . dwise ( f_x ) ) ) <TAB> f_x = self . se ( f_x ) <TAB> f_x = self . lin_proj_bn ( self . lin_proj ( f_x ) ) <TAB> if self . has_skip : <TAB><TAB> <MASK> <TAB><TAB><TAB> f_x = drop_connect ( f_x , effnet_cfg . EN . DC_RATIO ) <TAB><TAB> f_x = x + f_x <TAB> return f_x",if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,if effnet_cfg . EN . DC_RATIO not in f_x :,69.2380286477479,95.71,False
1791,"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB><TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB> log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB><TAB> user_input = read_input_uninstall ( ) <TAB><TAB> if user_input is not False : <TAB><TAB><TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> config . uninstall_distro_dir_name = _distro_dir <TAB><TAB><TAB><TAB><TAB> unin_distro ( ) <TAB> else : <TAB><TAB> log ( "" No distro installed on  "" + config . usb_disk )",if index == user_input :,if user_input == _distro_dir :,94.847000581019,96.45,False
1792,"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB><TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB><TAB> if alias . name == "" * "" : <TAB><TAB><TAB> self . scope . importStarred = True <TAB><TAB><TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB> continue <TAB><TAB> name = alias . asname or alias . name <TAB><TAB> importation = Importation ( name , node ) <TAB><TAB> if node . module == "" __future__ "" : <TAB><TAB><TAB> importation . used = ( self . scope , node ) <TAB><TAB> self . addBinding ( node , importation )",if not self . futuresAllowed :,if self . futuresAllowed :,74.78234863240921,98.96,False
1793,"def _split_and_load ( batch , ctx_list ) : <TAB> """"""Split data to 1 batch each device."""""" <TAB> new_batch = [ ] <TAB> for _ , data in enumerate ( batch ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_data = [ x . as_in_context ( ctx ) for x , ctx in zip ( data , ctx_list ) ] <TAB><TAB> else : <TAB><TAB><TAB> new_data = [ data . as_in_context ( ctx_list [ 0 ] ) ] <TAB><TAB> new_batch . append ( new_data ) <TAB> return new_batch","if isinstance ( data , ( list , tuple ) ) :","if isinstance ( data , ( list , tuple ) ) :",100.0,100.00,True
1794,"def wait_success ( self , timeout = 60 * 10 ) : <TAB> for i in range ( timeout / / 10 ) : <TAB><TAB> time . sleep ( 10 ) <TAB><TAB> status = self . query_job ( ) <TAB><TAB> print ( "" job  {}  status is  {} "" . format ( self . job_id , status ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> if status and status in [ <TAB><TAB><TAB> StatusSet . CANCELED , <TAB><TAB><TAB> StatusSet . TIMEOUT , <TAB><TAB><TAB> StatusSet . FAILED , <TAB><TAB> ] : <TAB><TAB><TAB> return False <TAB> return False",if status and status == StatusSet . SUCCESS :,if status :,93.68719618819374,95.35,False
1795,"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB><TAB> else : <TAB><TAB><TAB> rel_root = "" "" <TAB><TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB><TAB><TAB> continue <TAB><TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB><TAB> if not os . path . exists ( dst_root ) : <TAB><TAB><TAB> os . makedirs ( dst_root ) <TAB><TAB> for f in files : <TAB><TAB><TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) )",if src_root != src_dir :,"if src_root . startswith ( ""src"" ) :",95.5328289562296,96.72,False
1796,"def _make_padded_shapes ( self , dataset , decoders ) : <TAB> padded_shapes = dataset . output_shapes <TAB> for i , hparams_i in enumerate ( self . _hparams . datasets ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not hparams_i [ "" pad_to_max_seq_length "" ] : <TAB><TAB><TAB> continue <TAB><TAB> text_and_id_shapes = MonoTextData . _make_padded_text_and_id_shapes ( <TAB><TAB><TAB> dataset , hparams_i , decoders [ i ] , self . text_name ( i ) , self . text_id_name ( i ) <TAB><TAB> ) <TAB><TAB> padded_shapes . update ( text_and_id_shapes ) <TAB> return padded_shapes","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :","if not hparams_i [ ""num_layers"" ] :",82.59706772337395,93.10,False
1797,"def format_errors ( messages ) : <TAB> errors = { } <TAB> for k , v in messages . items ( ) : <TAB><TAB> key = camelize ( k , uppercase_first_letter = False ) <TAB><TAB> <MASK> <TAB><TAB><TAB> errors [ key ] = format_errors ( v ) <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> errors [ key ] = v [ 0 ] <TAB> return errors","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",100.0,100.00,True
1798,"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for item in value : <TAB><TAB><TAB><TAB> if isinstance ( item , AST ) : <TAB><TAB><TAB><TAB><TAB> self . visit ( item , parents ) <TAB><TAB> elif isinstance ( value , AST ) : <TAB><TAB><TAB> self . visit ( value , parents )","if isinstance ( value , list ) :","if isinstance ( value , list ) :",100.0,100.00,True
1799,"def get_override_css ( self ) : <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB><TAB> filename = self . view . file_name ( ) <TAB><TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB><TAB> if filename and filetypes : <TAB><TAB><TAB> for filetype in filetypes : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB><TAB><TAB><TAB><TAB> if os . path . isfile ( css_filename ) : <TAB><TAB><TAB><TAB><TAB><TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" """,if filename . endswith ( filetype ) :,"if filetype . startswith ( ""css"" ) :",94.79958537725398,96.69,False
1800,"def clean ( self ) : <TAB> super ( ) . clean ( ) <TAB> # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB> if self . cluster . site is not None : <TAB><TAB> for device in self . cleaned_data . get ( "" devices "" , [ ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB><TAB> "" devices "" : "" {}  belongs to a different site ( {} ) than the cluster ( {} ) "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> device , device . site , self . cluster . site <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB><TAB> } <TAB><TAB><TAB><TAB> )",if device . site != self . cluster . site :,if device . site != self . cluster . site :,100.0,100.00,True
1801,"def _setProcessPriority ( process , nice_val , disable_gc ) : <TAB> org_nice_val = Computer . _process_original_nice_value <TAB> try : <TAB><TAB> process . nice ( nice_val ) <TAB><TAB> Computer . in_high_priority_mode = nice_val != org_nice_val <TAB><TAB> <MASK> <TAB><TAB><TAB> gc . disable ( ) <TAB><TAB> else : <TAB><TAB><TAB> gc . enable ( ) <TAB><TAB> return True <TAB> except psutil . AccessDenied : <TAB><TAB> print2err ( <TAB><TAB><TAB> "" WARNING: Could not set process  {}  priority  "" <TAB><TAB><TAB> "" to  {} "" . format ( process . pid , nice_val ) <TAB><TAB> ) <TAB><TAB> return False",if disable_gc :,if disable_gc :,100.0,100.00,True
1802,"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB><TAB><TAB><TAB> "" may only return a single token for an And alternative,  "" <TAB><TAB><TAB><TAB> "" in future will return the full list of tokens "" . format ( <TAB><TAB><TAB><TAB><TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB><TAB><TAB><TAB><TAB> name , <TAB><TAB><TAB><TAB><TAB> type ( self ) . __name__ , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> stacklevel = 3 , <TAB><TAB><TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches )","if any ( isinstance ( e , And ) for e in self . exprs ) :",if len ( self . _tokens ) > 1 :,86.7427361733926,94.44,False
1803,"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB><TAB> content . append ( project . readme . path . name ) <TAB><TAB> if project . readme . markup != "" rst "" : <TAB><TAB><TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB><TAB> for fpath in package : <TAB><TAB><TAB> fpath = fpath . relative_to ( project . package . path ) <TAB><TAB><TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content )",if ( path / fname ) . exists ( ) :,if os . path . isfile ( fname ) :,86.87195802144517,96.60,False
1804,"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB><TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB><TAB> for j , s in enumerate ( c ) : <TAB><TAB><TAB> if j < segmentCount : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> controlPointIndices [ index ] = 1 <TAB><TAB><TAB> index + = s [ 1 ] <TAB> return controlPointIndices","if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",if s [ 0 ] == va [ j ] :,65.75894093824446,90.07,False
1805,"def MergeFrom ( self , other ) : <TAB> if self . message_class is not None : <TAB><TAB> if other . Parse ( self . message_class ) : <TAB><TAB><TAB> self . message . MergeFrom ( other . message ) <TAB> elif other . message_class is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . message = other . message_class ( ) <TAB><TAB><TAB> self . message_class = other . message_class <TAB><TAB> self . message . MergeFrom ( other . message ) <TAB> else : <TAB><TAB> self . message + = other . message",if not self . Parse ( other . message_class ) :,"if not hasattr ( other , ""message"" ) :",94.13230817878404,94.17,False
1806,"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . unlink ( file ) <TAB><TAB><TAB> elif os . path . isdir ( file ) : <TAB><TAB><TAB><TAB> shutil . rmtree ( file ) <TAB><TAB> except Exception as error : <TAB><TAB><TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB><TAB><TAB> sys . exit ( 1 )",if os . path . isfile ( file ) :,if os . path . isfile ( file ) :,75.0,100.00,True
1807,"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB><TAB> val = self . nodeValue <TAB><TAB> if not isinstance ( val , str ) : <TAB><TAB><TAB> val = str ( self . nodeValue ) <TAB> else : <TAB><TAB> v = self . nodeValue <TAB><TAB> if not isinstance ( v , str ) : <TAB><TAB><TAB> v = str ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> v = ""   "" . join ( v . split ( ) ) <TAB><TAB> val = escape ( v ) <TAB> w ( val )",if strip :,"if isinstance ( v , list ) :",78.67655837513774,96.63,False
1808,"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB><TAB> value = getattr ( self , attribute . code , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if attribute . required : <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> attribute . validate_value ( value ) <TAB><TAB><TAB> except ValidationError as e : <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB><TAB><TAB><TAB> )",if value is None :,if value is None :,100.0,100.00,True
1809,"def PyJsHoisted_BinaryExpression_ ( node , parent , this , arguments , var = var ) : <TAB> var = Scope ( <TAB><TAB> { u "" node "" : node , u "" this "" : this , u "" arguments "" : arguments , u "" parent "" : parent } , var <TAB> ) <TAB> var . registers ( [ u "" node "" , u "" parent "" ] ) <TAB> if PyJsStrictEq ( var . get ( u "" node "" ) . get ( u "" operator "" ) , Js ( u "" in "" ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return var . get ( u "" true "" ) <TAB><TAB> if var . get ( u "" t "" ) . callprop ( u "" isFor "" , var . get ( u "" parent "" ) ) : <TAB><TAB><TAB> return var . get ( u "" true "" ) <TAB> return Js ( False )","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :","if var . get ( u""t"" ) . callprop ( u""isFor""",93.60980538988747,93.37,False
1810,"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB><TAB> if isinstance ( n , Field ) : <TAB><TAB><TAB> if n . _child . isidentical ( expr ) : <TAB><TAB><TAB><TAB> n = n . _name <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB> elif n not in fields : <TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )","if not isinstance ( n , _strtypes ) :","elif not isinstance ( n , ( Name , Field ) ) :",69.33042233304289,96.58,False
1811,"def encode ( self , msg ) : <TAB> """"""Encodes the message to the stream encoding."""""" <TAB> stream = self . stream <TAB> rv = msg + "" \n "" <TAB> if ( PY2 and is_unicode ( rv ) ) or not ( <TAB><TAB> PY2 or is_unicode ( rv ) or _is_text_stream ( stream ) <TAB> ) : <TAB><TAB> enc = self . encoding <TAB><TAB> <MASK> <TAB><TAB><TAB> enc = getattr ( stream , "" encoding "" , None ) or "" utf-8 "" <TAB><TAB> rv = rv . encode ( enc , "" replace "" ) <TAB> return rv",if enc is None :,if enc is None :,100.0,100.00,True
1812,"def color_convert ( self , to_color_space , preserve_alpha = True ) : <TAB> if to_color_space == self . color_space and preserve_alpha : <TAB><TAB> return self <TAB> else : <TAB><TAB> pixels = pixels_as_float ( self . pixels ) <TAB><TAB> converted = convert_color ( <TAB><TAB><TAB> pixels , self . color_space , to_color_space , preserve_alpha <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> return Image ( converted , to_color_space )",if converted is None :,if converted is None :,100.0,100.00,True
1813,"def seek ( self , pos ) : <TAB> if self . closed : <TAB><TAB> raise IOError ( "" Cannot seek on a closed file "" ) <TAB> for n , idx in enumerate ( self . _indexes [ : : - 1 ] ) : <TAB><TAB> if idx . offset < = pos : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _idxiter = iter ( self . _indexes [ - ( n + 1 ) : ] ) <TAB><TAB><TAB><TAB> self . _nextidx ( ) <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise Exception ( "" Cannot seek to pos "" ) <TAB> self . _curfile . seek ( pos - self . _curidx . offset )",if idx != self . _curidx :,if n + 1 < len ( self . _indexes ) :,89.62497903321612,94.24,False
1814,"def load_from_json ( self , node_data : dict , import_version : float ) : <TAB> if import_version < = 0.08 : <TAB><TAB> self . image_pointer = unpack_pointer_property_name ( <TAB><TAB><TAB> bpy . data . images , node_data , "" image_name "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> proposed_name = node_data . get ( "" image_name "" ) <TAB><TAB><TAB> self . info ( f "" image data not found in current  { proposed_name } "" )",if not self . image_pointer :,if self . image_pointer is None :,75.1979533901435,96.65,False
1815,"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB><TAB> if operator == "" Average "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB><TAB> elif operator == "" Max "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB><TAB> elif operator == "" Min "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB><TAB> elif operator == "" Sum "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _SumAggregator ( ) )","elif operator == ""Count"" :","elif operator == ""Count"" :",100.0,100.00,True
1816,"def attrgetter ( item ) : <TAB> items = [ None ] * len ( attribute ) <TAB> for i , attribute_part in enumerate ( attribute ) : <TAB><TAB> item_i = item <TAB><TAB> for part in attribute_part : <TAB><TAB><TAB> item_i = environment . getitem ( item_i , part ) <TAB><TAB> <MASK> <TAB><TAB><TAB> item_i = postprocess ( item_i ) <TAB><TAB> items [ i ] = item_i <TAB> return items",if postprocess is not None :,if postprocess :,79.23677751080425,96.51,False
1817,"def work ( self ) : <TAB> while True : <TAB><TAB> timeout = self . timeout <TAB><TAB> <MASK> <TAB><TAB><TAB> timeout = self . idle_timeout <TAB><TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB><TAB> fetch . wait ( timeout ) <TAB><TAB> if shutting_down . is_set ( ) : <TAB><TAB><TAB> log . info ( "" Stop fetch worker "" ) <TAB><TAB><TAB> break <TAB><TAB> self . fetch ( )",if idle . is_set ( ) :,if self . idle_timeout is not None :,67.55735928098485,94.09,False
1818,"def testCoreInterfaceIntInputData ( ) : <TAB> result_testing = False <TAB> for _ in range ( 10 ) : <TAB><TAB> hsyncnet_instance = hsyncnet ( <TAB><TAB><TAB> [ [ 1 ] , [ 2 ] , [ 3 ] , [ 20 ] , [ 21 ] , [ 22 ] ] , 2 , initial_type . EQUIPARTITION , ccore = True <TAB><TAB> ) <TAB><TAB> analyser = hsyncnet_instance . process ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result_testing = True <TAB><TAB><TAB> break <TAB> assert result_testing",if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,if analyser [ 0 ] == initial_type . EQUIPARTITION :,65.52219463087768,90.96,False
1819,"def _gen ( ) : <TAB> buf = [ ] <TAB> iterable = dataset ( ) <TAB> try : <TAB><TAB> while len ( buf ) < buffer_size : <TAB><TAB><TAB> buf . append ( next ( iterable ) ) <TAB><TAB> while 1 : <TAB><TAB><TAB> i = random . randint ( 0 , buffer_size - 1 ) <TAB><TAB><TAB> n = next ( iterable ) <TAB><TAB><TAB> yield buf [ i ] <TAB><TAB><TAB> buf [ i ] = n <TAB> except StopIteration : <TAB><TAB> <MASK> <TAB><TAB><TAB> random . shuffle ( buf ) <TAB><TAB><TAB> for i in buf : <TAB><TAB><TAB><TAB> yield i",if len ( buf ) :,if shuffle :,96.29034921988375,97.18,False
1820,"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB><TAB> if isinstance ( elt , ( int , long ) ) : <TAB><TAB><TAB> l . append ( _names . get ( elt , elt ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> l . append ( elt ) <TAB><TAB> else : <TAB><TAB><TAB> l . append ( debug_tree ( elt ) ) <TAB> return l","elif isinstance ( elt , str ) :","elif isinstance ( elt , dict ) :",98.32591732179338,97.98,False
1821,"def reverse_code ( apps : StateApps , schema_editor : DatabaseSchemaEditor ) - > None : <TAB> PreregistrationUser = apps . get_model ( "" zerver "" , "" PreregistrationUser "" ) <TAB> for user in PreregistrationUser . objects . all ( ) : <TAB><TAB> <MASK> # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB><TAB><TAB> user . invited_as_admin = True <TAB><TAB> else : # PreregistrationUser.INVITE_AS['MEMBER'] <TAB><TAB><TAB> user . invited_as_admin = False <TAB><TAB> user . save ( update_fields = [ "" invited_as_admin "" ] )",if user . invited_as == 2 :,if user . invited_as_admin :,94.39842221690078,97.08,False
1822,"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB><TAB> with open ( data_file ) as in_handle : <TAB><TAB><TAB> for line in in_handle : <TAB><TAB><TAB><TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB><TAB><TAB><TAB><TAB> in_section = True <TAB><TAB><TAB><TAB> elif in_section : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB><TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out","if line . startswith ( "">>END"" ) :","if line . startswith ( ""## "" ) :",98.64694774088993,98.21,False
1823,"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB><TAB> if text [ 0 ] in ""   \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = str ( self . best_indent ) <TAB><TAB> <MASK> <TAB><TAB><TAB> hints + = "" - "" <TAB><TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = "" + "" <TAB> return hints","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :","elif text [ - 1 ] in ""\n\x85\u2028\u",66.35312362622486,93.97,False
1824,"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB><TAB> if not which ( "" initdb "" ) : <TAB><TAB><TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB><TAB> if not psycopg2 : <TAB><TAB><TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> pytest . skip ( <TAB><TAB><TAB><TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB><TAB><TAB> ) <TAB> return request . getfixturevalue ( request . param )","if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",if not GALAXY_TEST_AMQP_INTERNAL_CONNECTION :,67.29017058973716,94.08,False
1825,"def do_rollout ( agent , env , num_steps , render = False ) : <TAB> total_rew = 0 <TAB> ob = env . reset ( ) <TAB> for t in range ( num_steps ) : <TAB><TAB> a = agent . act ( ob ) <TAB><TAB> ( ob , reward , done , _info ) = env . step ( a ) <TAB><TAB> total_rew + = reward <TAB><TAB> <MASK> <TAB><TAB><TAB> env . render ( ) <TAB><TAB> if done : <TAB><TAB><TAB> break <TAB> return total_rew , t + 1",if render and t % 3 == 0 :,if render :,68.12676787510537,94.50,False
1826,"def _handle_subrepos ( self , ctx , dirty_trees ) : <TAB> substate = util . parse_hgsubstate ( ctx [ "" .hgsubstate "" ] . data ( ) . splitlines ( ) ) <TAB> sub = util . OrderedDict ( ) <TAB> if "" .hgsub "" in ctx : <TAB><TAB> sub = util . parse_hgsub ( ctx [ "" .hgsub "" ] . data ( ) . splitlines ( ) ) <TAB> for path , sha in substate . iteritems ( ) : <TAB><TAB> # Ignore non-Git repositories keeping state in .hgsubstate. <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> d = os . path . dirname ( path ) <TAB><TAB> dirty_trees . add ( d ) <TAB><TAB> tree = self . _dirs . setdefault ( d , dulobjs . Tree ( ) ) <TAB><TAB> tree . add ( os . path . basename ( path ) , dulobjs . S_IFGITLINK , sha )","if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :","if not self . _is_git_repo ( path , sub ) :",95.75618377512703,92.82,False
1827,"def get_property_file_image_choices ( self , pipeline ) : <TAB> columns = pipeline . get_measurement_columns ( ) <TAB> image_names = [ ] <TAB> for column in columns : <TAB><TAB> object_name , feature , coltype = column [ : 3 ] <TAB><TAB> choice = feature [ ( len ( C_FILE_NAME ) + 1 ) : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> image_names . append ( choice ) <TAB> return image_names","if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :","if choice not in [ C_FILE_NAME , C_FILE_NAME , C_",58.47663051353964,86.00,False
1828,"def check_all_decorator_order ( ) : <TAB> """"""Check that in all test files, the slow decorator is always last."""""" <TAB> errors = [ ] <TAB> for fname in os . listdir ( PATH_TO_TESTS ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = os . path . join ( PATH_TO_TESTS , fname ) <TAB><TAB><TAB> new_errors = check_decorator_order ( filename ) <TAB><TAB><TAB> errors + = [ f "" -  { filename } , line  { i } "" for i in new_errors ] <TAB> if len ( errors ) > 0 : <TAB><TAB> msg = "" \n "" . join ( errors ) <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> f "" The parameterized decorator (and its variants) should always be first, but this is not the case in the following files: \n { msg } "" <TAB><TAB> )","if fname . endswith ( "".py"" ) :","if fname . endswith ( "".py"" ) :",100.0,100.00,True
1829,"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB><TAB> if col and col . get_title ( ) == _ ( "" Active "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB><TAB> else : <TAB><TAB><TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id )","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",if client . autoadd . get_watchdir_id ( ) == 0 :,94.36253350889633,93.89,False
1830,"def get_conv_output_size ( input_size , kernel_size , stride , padding , dilation ) : <TAB> ndim = len ( input_size ) <TAB> output_size = [ ] <TAB> for i in range ( ndim ) : <TAB><TAB> size = ( <TAB><TAB><TAB> input_size [ i ] + 2 * padding [ i ] - dilation [ i ] * ( kernel_size [ i ] - 1 ) - 1 <TAB><TAB> ) / / stride [ i ] + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> output_size . append ( 1 ) <TAB><TAB> else : <TAB><TAB><TAB> output_size . append ( size ) <TAB> return output_size",if kernel_size [ i ] == - 1 :,if size == 1 :,67.49398299977653,94.81,False
1831,"def from_location ( cls , location , basename , metadata = None , * * kw ) : <TAB> project_name , version , py_version , platform = [ None ] * 4 <TAB> basename , ext = os . path . splitext ( basename ) <TAB> if ext . lower ( ) in ( "" .egg "" , "" .egg-info "" ) : <TAB><TAB> match = EGG_NAME ( basename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> project_name , version , py_version , platform = match . group ( <TAB><TAB><TAB><TAB> "" name "" , "" ver "" , "" pyver "" , "" plat "" <TAB><TAB><TAB> ) <TAB> return cls ( <TAB><TAB> location , <TAB><TAB> metadata , <TAB><TAB> project_name = project_name , <TAB><TAB> version = version , <TAB><TAB> py_version = py_version , <TAB><TAB> platform = platform , <TAB><TAB> * * kw <TAB> )",if match :,if match :,100.0,100.00,True
1832,"def __new__ ( metacls , typename , bases , namespace ) : <TAB> annotations = namespace . get ( "" __annotations__ "" , { } ) <TAB> for t in annotations . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for ut in t . __args__ : <TAB><TAB><TAB><TAB> _assert_tensorizer_type ( ut ) <TAB><TAB> else : <TAB><TAB><TAB> _assert_tensorizer_type ( t ) <TAB> return super ( ) . __new__ ( metacls , typename , bases , namespace )","if getattr ( t , ""__origin__"" , """" ) is Union :","if hasattr ( t , ""__args__"" ) :",91.13567296921428,92.46,False
1833,"def decode_content ( self ) : <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB><TAB> ct , options = parse_options_header ( ct ) <TAB><TAB> charset = options . get ( "" charset "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . json ( charset ) <TAB><TAB> elif ct . startswith ( "" text/ "" ) : <TAB><TAB><TAB> return self . text ( charset ) <TAB><TAB> elif ct == FORM_URL_ENCODED : <TAB><TAB><TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content",if ct in JSON_CONTENT_TYPES :,"if ct . startswith ( ""json/"" ) :",69.59421065944647,95.26,False
1834,"def get_full_path ( path ) : <TAB> if "" :// "" not in path : <TAB><TAB> path = os . path . join ( self . AUTO_COLL_TEMPL , path , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> path = os . path . join ( abs_path , path ) <TAB> return path",if abs_path :,if abs_path :,100.0,100.00,True
1835,"def __getitem__ ( self , name_or_path ) : <TAB> if isinstance ( name_or_path , integer_types ) : <TAB><TAB> return list . __getitem__ ( self , name_or_path ) <TAB> elif isinstance ( name_or_path , tuple ) : <TAB><TAB> try : <TAB><TAB><TAB> val = self <TAB><TAB><TAB> for fid in name_or_path : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise KeyError # path contains base value <TAB><TAB><TAB><TAB> val = val [ fid ] <TAB><TAB><TAB> return val <TAB><TAB> except ( KeyError , IndexError ) : <TAB><TAB><TAB> raise KeyError ( name_or_path ) <TAB> else : <TAB><TAB> raise TypeError ( self . _INDEX_ERROR % name_or_path )","if not isinstance ( val , FeatStruct ) :",if fid not in val :,67.29485002644753,96.62,False
1836,"def scan ( scope ) : <TAB> for s in scope . children : <TAB><TAB> if s . start_pos < = position < = s . end_pos : <TAB><TAB><TAB> if isinstance ( s , ( tree . Scope , tree . Flow ) ) : <TAB><TAB><TAB><TAB> return scan ( s ) or s <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return scan ( s ) <TAB> return None","elif s . type in ( ""suite"" , ""decorated"" ) :","elif isinstance ( s , tree . Scope ) :",90.78064909802308,90.12,False
1837,"def _get_key ( self ) : <TAB> if not self . key : <TAB><TAB> self . _channel . send ( u "" pake "" , self . msg1 ) <TAB><TAB> pake_msg = self . _channel . get ( u "" pake "" ) <TAB><TAB> self . key = self . sp . finish ( pake_msg ) <TAB><TAB> self . verifier = self . derive_key ( u "" wormhole:verifier "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> confkey = self . derive_key ( u "" wormhole:confirmation "" ) <TAB><TAB> nonce = os . urandom ( CONFMSG_NONCE_LENGTH ) <TAB><TAB> confmsg = make_confmsg ( confkey , nonce ) <TAB><TAB> self . _channel . send ( u "" _confirm "" , confmsg )",if not self . _send_confirm :,if not self . verifier :,78.07116674324955,97.31,False
1838,"def executeScript ( self , script ) : <TAB> if len ( script ) > 0 : <TAB><TAB> commands = [ ] <TAB><TAB> for l in script : <TAB><TAB><TAB> extracted = self . extract_command ( l ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> commands . append ( extracted ) <TAB><TAB> for command in commands : <TAB><TAB><TAB> cmd , argv = command <TAB><TAB><TAB> self . dispatch_command ( cmd , argv )",if extracted :,if extracted :,100.0,100.00,True
1839,"def create_path ( n , fullname , meta ) : <TAB> if meta : <TAB><TAB> meta . create_path ( fullname ) <TAB> else : <TAB><TAB> # These fallbacks are important -- meta could be null if, for <TAB><TAB> # example, save created a ""fake"" item, i.e. a new strip/graft <TAB><TAB> # path element, etc.  You can find cases like that by <TAB><TAB> # searching for ""Metadata()"". <TAB><TAB> unlink ( fullname ) <TAB><TAB> if stat . S_ISDIR ( n . mode ) : <TAB><TAB><TAB> mkdirp ( fullname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . symlink ( n . readlink ( ) , fullname )",elif stat . S_ISLNK ( n . mode ) :,elif stat . S_ISLINK ( n . mode ) :,98.8614971725562,98.71,False
1840,def get_cycle ( self ) : <TAB> if self . has_cycle ( ) : <TAB><TAB> cross_node = self . path [ - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . path [ self . path . index ( cross_node ) : ] <TAB><TAB> else : <TAB><TAB><TAB> return self . path <TAB> return [ ],if self . path . count ( cross_node ) > 1 :,if cross_node in self . path :,63.10682297003494,90.19,False
1841,"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB><TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> depth + = 1 <TAB><TAB> elif str_in [ pos ] == end_tag : <TAB><TAB><TAB> depth - = 1 <TAB><TAB> if depth == 0 : <TAB><TAB><TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",if str_in [ pos ] == start_tag :,if str_in [ pos ] == start_tag :,100.0,100.00,True
1842,"def device ( self ) : <TAB> """"""Device on which the data array of this variable reside."""""" <TAB> # lazy initialization for performance <TAB> if self . _device is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _device = backend . CpuDevice ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . _device = backend . get_device_from_array ( self . _data [ 0 ] ) <TAB> return self . _device",if self . _data [ 0 ] is None :,if self . _data is None :,97.04428121019777,96.46,False
1843,"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB><TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB><TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB><TAB><TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB><TAB> if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) : <TAB><TAB><TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB><TAB> raise",if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,if e . get_dbus_name ( ) == DBUS_NOT_FOUND :,73.76789478502707,96.85,False
1844,"def run ( self ) : <TAB> """"""Continual loop evaluating when_statements"""""" <TAB> while len ( self . library ) > 0 : <TAB><TAB> for name , expression in self . library . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del self . library [ name ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> expression . evaluate ( ) <TAB><TAB> sleep ( 0.01 ) <TAB> return",if expression . remove_me == True :,"if isinstance ( expression , WhenStatement ) :",67.41682129059316,92.95,False
1845,"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB> amount = random . randint ( 10 , 15 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> retval + = "" > "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> elif char == "" < "" : <TAB><TAB><TAB> retval + = "" < "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> elif char == ""   "" : <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> else : <TAB><TAB><TAB> retval + = char <TAB> return retval","if char == "">"" :","if char == "">"" :",100.0,100.00,True
1846,"def _source_target_path ( source , source_path , source_location ) : <TAB> target_path_attr = source . target_path or source . resdef . target_path <TAB> if source . preserve_path : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . warning ( <TAB><TAB><TAB><TAB> "" target-path  ' %s '  specified with preserve-path - ignoring "" , <TAB><TAB><TAB><TAB> target_path_attr , <TAB><TAB><TAB> ) <TAB><TAB> return os . path . relpath ( os . path . dirname ( source_path ) , source_location ) <TAB> else : <TAB><TAB> return target_path_attr or source . resdef . target_path or "" """,if target_path_attr :,if target_path_attr :,100.0,100.00,True
1847,"def _load_user_from_header ( self , header ) : <TAB> if self . _header_callback : <TAB><TAB> user = self . _header_callback ( header ) <TAB><TAB> <MASK> <TAB><TAB><TAB> app = current_app . _get_current_object ( ) <TAB><TAB><TAB> user_loaded_from_header . send ( app , user = user ) <TAB><TAB><TAB> return user <TAB> return None",if user is not None :,if user :,79.46383570625694,96.16,False
1848,"def setup ( cls ) : <TAB> "" Check dependencies and warn about firewalling "" <TAB> pathCheck ( "" brctl "" , moduleName = "" bridge-utils "" ) <TAB> # Disable Linux bridge firewalling so that traffic can flow! <TAB> for table in "" arp "" , "" ip "" , "" ip6 "" : <TAB><TAB> cmd = "" sysctl net.bridge.bridge-nf-call- %s tables "" % table <TAB><TAB> out = quietRun ( cmd ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> warn ( "" Warning: Linux bridge may not work with "" , out , "" \n "" )","if out . endswith ( ""1"" ) :",if out :,96.90037087386246,94.04,False
1849,"def _browse_your_music ( web_client , variant ) : <TAB> if not web_client . logged_in : <TAB><TAB> return [ ] <TAB> if variant in ( "" tracks "" , "" albums "" ) : <TAB><TAB> items = flatten ( <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> page . get ( "" items "" , [ ] ) <TAB><TAB><TAB><TAB> for page in web_client . get_all ( <TAB><TAB><TAB><TAB><TAB> f "" me/ { variant } "" , <TAB><TAB><TAB><TAB><TAB> params = { "" market "" : "" from_token "" , "" limit "" : 50 } , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> if page <TAB><TAB><TAB> ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return list ( translator . web_to_track_refs ( items ) ) <TAB><TAB> else : <TAB><TAB><TAB> return list ( translator . web_to_album_refs ( items ) ) <TAB> else : <TAB><TAB> return [ ]","if variant == ""tracks"" :","if variant == ""tracks"" :",100.0,100.00,True
1850,"def reset_styling ( self ) : <TAB> for edge in self . fsm_graph . edges_iter ( ) : <TAB><TAB> style_attr = self . fsm_graph . style_attributes . get ( "" edge "" , { } ) . get ( "" default "" ) <TAB><TAB> edge . attr . update ( style_attr ) <TAB> for node in self . fsm_graph . nodes_iter ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> style_attr = self . fsm_graph . style_attributes . get ( "" node "" , { } ) . get ( "" inactive "" ) <TAB><TAB><TAB> node . attr . update ( style_attr ) <TAB> for sub_graph in self . fsm_graph . subgraphs_iter ( ) : <TAB><TAB> style_attr = self . fsm_graph . style_attributes . get ( "" graph "" , { } ) . get ( "" default "" ) <TAB><TAB> sub_graph . graph_attr . update ( style_attr )","if ""point"" not in node . attr [ ""shape"" ] :",if node . inactive :,94.03866487238355,94.43,False
1851,"def set_message_type_visibility ( self , message_type : MessageType ) : <TAB> try : <TAB><TAB> rows = { <TAB><TAB><TAB> i <TAB><TAB><TAB> for i , msg in enumerate ( self . proto_analyzer . messages ) <TAB><TAB><TAB> <MASK> <TAB><TAB> } <TAB><TAB> if message_type . show : <TAB><TAB><TAB> self . ui . tblViewProtocol . show_rows ( rows ) <TAB><TAB> else : <TAB><TAB><TAB> self . ui . tblViewProtocol . hide_rows ( rows ) <TAB> except Exception as e : <TAB><TAB> logger . exception ( e )",if msg . message_type == message_type,"if isinstance ( msg , Message )",67.06053487590539,93.54,False
1852,"def POP ( cpu , * regs ) : <TAB> for reg in regs : <TAB><TAB> val = cpu . stack_pop ( cpu . address_bit_size / / 8 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cpu . _set_mode_by_val ( val ) <TAB><TAB><TAB> val = val & ~ 0x1 <TAB><TAB> reg . write ( val )","if reg . reg in ( ""PC"" , ""R15"" ) :",if cpu . _set_mode_by_val :,63.73226135607993,87.08,False
1853,"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB><TAB> if "" track "" in field : <TAB><TAB><TAB> self . processTrack ( field [ "" track "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] )","if ""movie_hdr"" in field :","if ""movie_hdr"" in field :",75.0,100.00,True
1854,"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB><TAB> local_version = get_local_timestamp ( folder ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if auto : <TAB><TAB><TAB><TAB> update_setter . set_value ( True ) <TAB><TAB><TAB> version_setter . set_value ( remote_version ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> else : <TAB><TAB> return False",if remote_version > local_version :,if local_version . isdigit ( ) :,68.42348763628266,96.11,False
1855,"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB><TAB> for region in view . sel ( ) : <TAB><TAB><TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB> if idx > = len ( selections ) : <TAB><TAB><TAB> break <TAB><TAB> i = index - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> values . append ( selections [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB><TAB> if len ( values ) + 1 < idx : <TAB><TAB><TAB> values . append ( value ) <TAB> self . stack = values",if i >= 0 and i < len ( selections ) :,if i >= 0 :,93.7262775344329,96.45,False
1856,"def find_int_identifiers ( directory ) : <TAB> results = find_rules ( directory , has_int_identifier ) <TAB> print ( "" Number of rules with integer identifiers:  %d "" % len ( results ) ) <TAB> for result in results : <TAB><TAB> rule_path = result [ 0 ] <TAB><TAB> product_yaml_path = result [ 1 ] <TAB><TAB> product_yaml = None <TAB><TAB> <MASK> <TAB><TAB><TAB> product_yaml = yaml . open_raw ( product_yaml_path ) <TAB><TAB> fix_file ( rule_path , product_yaml , fix_int_identifier )",if product_yaml_path is not None :,if product_yaml_path :,75.30028340540488,97.21,False
1857,"def condition ( self ) : <TAB> if self . __condition is None : <TAB><TAB> if len ( self . flat_conditions ) == 1 : <TAB><TAB><TAB> # Avoid an extra indirection in the common case of only one condition. <TAB><TAB><TAB> self . __condition = self . flat_conditions [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB><TAB><TAB> self . __condition = lambda _ : True <TAB><TAB> else : <TAB><TAB><TAB> self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB> return self . __condition",elif len ( self . flat_conditions ) == 0 :,elif self . flat_conditions [ 0 ] . is_filter :,96.44404485939322,94.86,False
1858,"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB><TAB> if season == scene_season : <TAB><TAB><TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions",if not len ( scene_exception ) == 2 :,"if scene_exception == """" :",68.28291660039227,92.97,False
1859,"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB><TAB> for region in view . sel ( ) : <TAB><TAB><TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> i = index - 1 <TAB><TAB> if i > = 0 and i < len ( selections ) : <TAB><TAB><TAB> values . append ( selections [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB><TAB> if len ( values ) + 1 < idx : <TAB><TAB><TAB> values . append ( value ) <TAB> self . stack = values",if idx >= len ( selections ) :,if index == 0 :,93.31257284386945,96.58,False
1860,"def to_tool_path ( self , path_or_uri_like , * * kwds ) : <TAB> if "" :// "" not in path_or_uri_like : <TAB><TAB> path = path_or_uri_like <TAB> else : <TAB><TAB> uri_like = path_or_uri_like <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Invalid URI passed to get_tool_source "" ) <TAB><TAB> scheme , rest = uri_like . split ( "" : "" , 2 ) <TAB><TAB> if scheme not in self . resolver_classes : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Unknown tool scheme [ {} ] for URI [ {} ] "" . format ( scheme , uri_like ) <TAB><TAB><TAB> ) <TAB><TAB> path = self . resolver_classes [ scheme ] ( ) . get_tool_source_path ( uri_like ) <TAB> return path","if "":"" not in path_or_uri_like :",if not uri_like :,67.0940301339835,95.91,False
1861,def mainWindow ( ) : <TAB> global MW <TAB> if not MW : <TAB><TAB> for i in qApp . topLevelWidgets ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> MW = i <TAB><TAB><TAB><TAB> return MW <TAB><TAB> return None <TAB> else : <TAB><TAB> return MW,"if i . objectName ( ) == ""MainWindow"" :",if i . isVisible ( ) :,82.43570119014913,91.29,False
1862,"def async_get_service ( hass , config , discovery_info = None ) : <TAB> # pylint: disable=unused-argument <TAB> """"""Get the demo notification service."""""" <TAB> for account , account_dict in hass . data [ DATA_ALEXAMEDIA ] [ "" accounts "" ] . items ( ) : <TAB><TAB> for key , _ in account_dict [ "" devices "" ] [ "" media_player "" ] . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _LOGGER . debug ( <TAB><TAB><TAB><TAB><TAB> "" %s : Media player  %s  not loaded yet; delaying load "" , <TAB><TAB><TAB><TAB><TAB> hide_email ( account ) , <TAB><TAB><TAB><TAB><TAB> hide_serial ( key ) , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return False <TAB> return AlexaNotificationService ( hass )","if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :","if not config . get ( ""load_status"" ) :",95.2773975378682,92.73,False
1863,"def _migrate_bool ( self , name : str , true_value : str , false_value : str ) - > None : <TAB> if name not in self . _settings : <TAB><TAB> return <TAB> values = self . _settings [ name ] <TAB> if not isinstance ( values , dict ) : <TAB><TAB> return <TAB> for scope , val in values . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_value = true_value if val else false_value <TAB><TAB><TAB> self . _settings [ name ] [ scope ] = new_value <TAB><TAB><TAB> self . changed . emit ( )","if isinstance ( val , bool ) :","if isinstance ( val , bool ) :",100.0,100.00,True
1864,"def send ( self , data , flags = 0 ) : <TAB> self . _checkClosed ( ) <TAB> if self . _sslobj : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" non-zero flags not allowed in calls to send() on  %s "" % self . __class__ <TAB><TAB><TAB> ) <TAB><TAB> return self . _sslobj . write ( data ) <TAB> else : <TAB><TAB> return socket . send ( self , data , flags )",if flags != 0 :,if flags != 0 :,100.0,100.00,True
1865,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB><TAB> dep_cnts = services . get ( dep ) <TAB><TAB> if not dep_cnts : <TAB><TAB><TAB> continue <TAB><TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB> if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB> deps . update ( new_deps ) <TAB> return deps",if dep_cnt :,if dep_cnt :,100.0,100.00,True
1866,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB><TAB> return None <TAB> for item in dirs : <TAB><TAB> if item . endswith ( "" / "" ) : <TAB><TAB><TAB> records = as_dict ( path + item , version , section ) <TAB><TAB><TAB> if records : <TAB><TAB><TAB><TAB> result [ item [ : - 1 ] ] = records <TAB><TAB> <MASK> <TAB><TAB><TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB> if records : <TAB><TAB><TAB><TAB> result [ name ] = records <TAB><TAB> else : <TAB><TAB><TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result",elif is_dict . match ( item ) :,elif is_dict . match ( item ) :,100.0,100.00,True
1867,"def PrintColGroup ( col_names , schema ) : <TAB> """"""Print HTML colgroup element, used for JavaScript sorting."""""" <TAB> print ( ""   <colgroup> "" ) <TAB> for i , col in enumerate ( col_names ) : <TAB><TAB> if col . endswith ( "" _HREF "" ) : <TAB><TAB><TAB> continue <TAB><TAB> # CSS class is used for sorting <TAB><TAB> <MASK> <TAB><TAB><TAB> css_class = "" number "" <TAB><TAB> else : <TAB><TAB><TAB> css_class = "" case-insensitive "" <TAB><TAB> # NOTE: id is a comment only; not used <TAB><TAB> print ( '     <col id= "" {} ""  type= "" {} ""  /> ' . format ( col , css_class ) ) <TAB> print ( ""   </colgroup> "" )",if schema . IsNumeric ( col ) :,if i == 0 :,96.92069929141894,96.47,False
1868,"def check_region ( self , region ) : <TAB> for other in self . regions : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if ( other . start < region . start < other . end ) or ( <TAB><TAB><TAB> other . start < region . end < other . end <TAB><TAB> ) : <TAB><TAB><TAB> raise Exception ( "" %r  overlaps with  %r "" % ( region , other ) )",if other is region :,if region . start == other . start and region . end == other . end :,85.48326244005332,86.18,False
1869,"def _write_value ( self , rng , value , scalar ) : <TAB> if rng . api and value : <TAB><TAB> # it is assumed by this stage that value is a list of lists <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value [ 0 ] [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> rng = rng . resize ( len ( value ) , len ( value [ 0 ] ) ) <TAB><TAB> rng . raw_value = value",if scalar :,if scalar :,100.0,100.00,True
1870,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 24 : <TAB><TAB><TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
1871,"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [ ] <TAB> for i , face in enumerate ( dcel_mesh . faces ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB><TAB><TAB><TAB> i <TAB><TAB><TAB> ) <TAB><TAB> if not face . outer or del_flag in face . flags : <TAB><TAB><TAB> continue <TAB><TAB> if only_select and not face . select : <TAB><TAB><TAB> continue <TAB><TAB> sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB> return sv_faces",if face . inners and face . outer :,if face . outer :,98.3724874483888,98.21,False
1872,"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> x_value = str ( xValue ) <TAB> for anime in self . xmlMap . findall ( "" anime "" ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return int ( anime . get ( y , 0 ) ) <TAB><TAB> except ValueError as e : <TAB><TAB><TAB> continue <TAB> return 0","if anime . get ( x , False ) == x_value :","if anime . get ( x , 0 ) == x_value :",73.39090625637184,98.43,False
1873,"def dir_copy ( src_dir , dest_dir , merge_if_exists = True ) : <TAB> try : <TAB><TAB> if not os . path . exists ( dest_dir ) : <TAB><TAB><TAB> shutil . copytree ( src_dir , dest_dir ) <TAB><TAB> <MASK> <TAB><TAB><TAB> merge_dir ( src_dir , dest_dir ) <TAB> except OSError as e : <TAB><TAB> # If source is not a directory, copy with shutil.copy <TAB><TAB> if e . errno == errno . ENOTDIR : <TAB><TAB><TAB> shutil . copy ( src_dir , dest_dir ) <TAB><TAB> else : <TAB><TAB><TAB> logging . error ( "" Could not copy  %s  to  %s "" , src_dir , dest_dir )",elif merge_if_exists :,elif merge_if_exists :,100.0,100.00,True
1874,"def mapping ( self ) : <TAB> m = { } <TAB> if getGdriveCredentialsFile ( ) is not None : <TAB><TAB> m [ "" gdrive "" ] = "" "" <TAB> unknown = 0 <TAB> for f in self . scan : <TAB><TAB> bits = f . split ( "" # "" , 2 ) <TAB><TAB> if len ( bits ) == 1 : <TAB><TAB><TAB> label = os . path . basename ( f ) <TAB><TAB> else : <TAB><TAB><TAB> label = bits [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> label = "" L "" + str ( unknown ) <TAB><TAB><TAB> unknown + = 1 <TAB><TAB> m [ label ] = bits [ 0 ] <TAB> return m","if not label or len ( label ) == 0 or label == """" :",if unknown :,66.29486975143007,91.22,False
1875,"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB><TAB> return [ ] <TAB> if not http . headers : <TAB><TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance ( headers , dict ) : <TAB><TAB> headers = headers . items ( ) <TAB> output = [ ] <TAB> for key , value in headers : <TAB><TAB> if key != "" User-Agent "" : <TAB><TAB><TAB> continue <TAB><TAB> ua = Parse ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> result = self . get_tag_from_ua ( ua ) <TAB><TAB> if result : <TAB><TAB><TAB> output . append ( result ) <TAB> return output",if not ua :,if not ua :,100.0,100.00,True
1876,"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB><TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB><TAB> for i , g in enumerate ( groups ) : <TAB><TAB><TAB> if g : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> t [ i ] = g <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB><TAB><TAB><TAB><TAB> g1 = [ ] <TAB><TAB><TAB><TAB><TAB> for _ , vs in g : <TAB><TAB><TAB><TAB><TAB><TAB> g1 . extend ( vs ) <TAB><TAB><TAB><TAB><TAB> t [ i ] = g1 <TAB><TAB> yield k , tuple ( t )",if i in direct_upstreams :,if len ( g ) == 1 and g [ 0 ] not in direct_upstreams :,72.16931998267646,94.97,False
1877,"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB><TAB> <MASK> <TAB><TAB><TAB> skip = True <TAB><TAB> if letter == "" > "" : <TAB><TAB><TAB> skip = False <TAB><TAB> if skip : <TAB><TAB><TAB> continue <TAB><TAB> if letter . isalnum ( ) or letter == ""   "" : <TAB><TAB><TAB> if letter == ""   "" : <TAB><TAB><TAB><TAB> letter = "" _ "" <TAB><TAB><TAB> question + = letter . lower ( ) <TAB> return question","if letter == ""<"" :","if letter == ""<"" :",100.0,100.00,True
1878,"def _module_repr_from_spec ( spec ) : <TAB> """"""Return the repr to use for the module."""""" <TAB> # We mostly replicate _module_repr() using the spec attributes. <TAB> name = "" ? "" if spec . name is None else spec . name <TAB> if spec . origin is None : <TAB><TAB> if spec . loader is None : <TAB><TAB><TAB> return "" <module  {!r} > "" . format ( name ) <TAB><TAB> else : <TAB><TAB><TAB> return "" <module  {!r}  ( {!r} )> "" . format ( name , spec . loader ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" <module  {!r}  from  {!r} > "" . format ( name , spec . origin ) <TAB><TAB> else : <TAB><TAB><TAB> return "" <module  {!r}  ( {} )> "" . format ( spec . name , spec . origin )",if spec . has_location :,if spec . name is None :,98.75953936348536,98.18,False
1879,"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> value = row [ idx ] <TAB><TAB> except IndexError : <TAB><TAB><TAB> value = "" "" <TAB><TAB> result = test ( value ) <TAB><TAB> if self . any_match : <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> return not self . inverse # True <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . inverse # False <TAB> if self . any_match : <TAB><TAB> return self . inverse # False <TAB> else : <TAB><TAB> return not self . inverse # True",if not result :,if self . any_match and not result :,98.34970806146407,96.43,False
1880,"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> interval = sys . getswitchinterval ( ) <TAB><TAB><TAB> sys . setswitchinterval ( 1e-6 ) <TAB><TAB> else : <TAB><TAB><TAB> interval = sys . getcheckinterval ( ) <TAB><TAB><TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB><TAB> yield <TAB> finally : <TAB><TAB> if not sys . platform . startswith ( "" java "" ) : <TAB><TAB><TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB><TAB><TAB><TAB> sys . setswitchinterval ( interval ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sys . setcheckinterval ( interval )","if hasattr ( sys , ""getswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",98.97951305689078,98.93,False
1881,"def record_expected_exportable_production ( self , ticks ) : <TAB> """"""Record the amount of production that should be transferred to other islands."""""" <TAB> for ( quota_holder , resource_id ) , amount in self . _low_priority_requests . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _settlement_manager_id [ quota_holder ] = WorldObject . get_object_by_id ( <TAB><TAB><TAB><TAB> int ( quota_holder [ 1 : ] . split ( "" , "" ) [ 0 ] ) <TAB><TAB><TAB> ) . settlement_manager . worldid <TAB><TAB> self . trade_storage [ self . _settlement_manager_id [ quota_holder ] ] [ resource_id ] + = ( <TAB><TAB><TAB> ticks * amount <TAB><TAB> )",if quota_holder not in self . _settlement_manager_id :,if quota_holder not in self . trade_storage :,98.16328932176708,96.68,False
1882,"def _method_events_callback ( self , values ) : <TAB> try : <TAB><TAB> previous_echoed = ( <TAB><TAB><TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" echo foo2 \n "" <TAB><TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB><TAB><TAB> return "" echo foo3 \n "" <TAB><TAB> elif previous_echoed . endswith ( "" foo3 "" ) : <TAB><TAB><TAB> return "" exit \n "" <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB><TAB> return "" echo foo1 \n ""","if previous_echoed . endswith ( ""foo1"" ) :","if previous_echoed . endswith ( ""foo1"" ) :",100.0,100.00,True
1883,"def describe_cluster_snapshots ( self , cluster_identifier = None , snapshot_identifier = None ) : <TAB> if cluster_identifier : <TAB><TAB> cluster_snapshots = [ ] <TAB><TAB> for snapshot in self . snapshots . values ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cluster_snapshots . append ( snapshot ) <TAB><TAB> if cluster_snapshots : <TAB><TAB><TAB> return cluster_snapshots <TAB> if snapshot_identifier : <TAB><TAB> if snapshot_identifier in self . snapshots : <TAB><TAB><TAB> return [ self . snapshots [ snapshot_identifier ] ] <TAB><TAB> raise ClusterSnapshotNotFoundError ( snapshot_identifier ) <TAB> return self . snapshots . values ( )",if snapshot . cluster . cluster_identifier == cluster_identifier :,if snapshot . cluster_identifier == cluster_identifier :,97.02754828112138,98.83,False
1884,def get_snippet_edit_handler ( model ) : <TAB> if model not in SNIPPET_EDIT_HANDLERS : <TAB><TAB> <MASK> <TAB><TAB><TAB> # use the edit handler specified on the page class <TAB><TAB><TAB> edit_handler = model . edit_handler <TAB><TAB> else : <TAB><TAB><TAB> panels = extract_panel_definitions_from_model_class ( model ) <TAB><TAB><TAB> edit_handler = ObjectList ( panels ) <TAB><TAB> SNIPPET_EDIT_HANDLERS [ model ] = edit_handler . bind_to ( model = model ) <TAB> return SNIPPET_EDIT_HANDLERS [ model ],"if hasattr ( model , ""edit_handler"" ) :","if hasattr ( model , ""edit_handler"" ) :",100.0,100.00,True
1885,"def start ( ) : <TAB> if os . environ . get ( "" RUN_MAIN "" ) != "" true "" : <TAB><TAB> try : <TAB><TAB><TAB> exit_code = restart_with_reloader ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . kill ( os . getpid ( ) , - exit_code ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sys . exit ( exit_code ) <TAB><TAB> except KeyboardInterrupt : <TAB><TAB><TAB> pass",if exit_code < 0 :,if exit_code < 0 :,100.0,100.00,True
1886,"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB><TAB> if len ( l ) < 5 : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> int ( l [ 2 ] ) <TAB><TAB><TAB> int ( l [ 3 ] ) <TAB><TAB> except : <TAB><TAB><TAB> continue <TAB><TAB> #           ret.append(improve(l[0])) <TAB><TAB> ret . append ( l [ 0 ] ) <TAB> ret . sort ( ) <TAB> for item in objlist : <TAB><TAB> ret . append ( item ) <TAB> return ret","if l [ 0 ] == ""Filename"" :",if len ( l ) < 4 :,94.30648474786892,94.93,False
1887,"def ipfs_publish ( self , lib ) : <TAB> with tempfile . NamedTemporaryFile ( ) as tmp : <TAB><TAB> self . ipfs_added_albums ( lib , tmp . name ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cmd = "" ipfs add --nocopy -q  "" . split ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> cmd = "" ipfs add -q  "" . split ( ) <TAB><TAB><TAB> cmd . append ( tmp . name ) <TAB><TAB><TAB> output = util . command_output ( cmd ) <TAB><TAB> except ( OSError , subprocess . CalledProcessError ) as err : <TAB><TAB><TAB> msg = "" Failed to publish library. Error:  {0} "" . format ( err ) <TAB><TAB><TAB> self . _log . error ( msg ) <TAB><TAB><TAB> return False <TAB><TAB> self . _log . info ( "" hash of library:  {0} "" , output )","if self . config [ ""nocopy"" ] :",if self . _log . getEffectiveLevel ( ) <= logging . DEBUG :,95.9936816283197,95.29,False
1888,"def spends ( self ) : <TAB> # Return spends indexed by hashX <TAB> spends = defaultdict ( list ) <TAB> utxos = self . mempool_utxos ( ) <TAB> for tx_hash , tx in self . txs . items ( ) : <TAB><TAB> for n , input in enumerate ( tx . inputs ) : <TAB><TAB><TAB> if input . is_generation ( ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> prevout = ( input . prev_hash , input . prev_idx ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> hashX , value = utxos . pop ( prevout ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> hashX , value = self . db_utxos [ prevout ] <TAB><TAB><TAB> spends [ hashX ] . append ( prevout ) <TAB> return spends",if prevout in utxos :,if n == tx_hash :,73.00069419853408,96.63,False
1889,"def terminate ( self ) : <TAB> if self . returncode is None : <TAB><TAB> try : <TAB><TAB><TAB> os . kill ( self . pid , TERM_SIGNAL ) <TAB><TAB> except OSError as exc : <TAB><TAB><TAB> if getattr ( exc , "" errno "" , None ) != errno . ESRCH : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise",if self . wait ( timeout = 0.1 ) is None :,if exc . errno != errno . ESRCH :,62.10962878818221,90.85,False
1890,"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB><TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self . _value in dynamicStrToScalar : <TAB><TAB> return dynamicStrToScalar [ self . _value ] <TAB> else : <TAB><TAB> thisDynamic = self . _value <TAB><TAB> # ignore leading s like in sf <TAB><TAB> <MASK> <TAB><TAB><TAB> thisDynamic = thisDynamic [ 1 : ] <TAB><TAB> # ignore closing z like in fz <TAB><TAB> if thisDynamic [ - 1 ] == "" z "" : <TAB><TAB><TAB> thisDynamic = thisDynamic [ : - 1 ] <TAB><TAB> if thisDynamic in dynamicStrToScalar : <TAB><TAB><TAB> return dynamicStrToScalar [ thisDynamic ] <TAB><TAB> else : <TAB><TAB><TAB> return dynamicStrToScalar [ None ]","if ""s"" in thisDynamic :","if thisDynamic [ 0 ] == ""sf"" :",97.54292487438389,95.51,False
1891,"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB><TAB> if "" . "" in valname : <TAB><TAB><TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB><TAB><TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB><TAB> else : <TAB><TAB><TAB> config [ valname ] = value <TAB> for name in config : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config",if name in self . values :,if name not in self . __dict__ :,97.83024396173725,94.85,False
1892,"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB><TAB> if not isinstance ( op_list , list ) : <TAB><TAB><TAB> op_list = ( op_list , ) <TAB><TAB> for item in chain ( * op_list ) : <TAB><TAB><TAB> if item is None : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> dictionary = item . dictionary <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> paths . add ( dictionary . path ) <TAB><TAB><TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list",if dictionary . path in paths :,if dictionary . path in paths :,100.0,100.00,True
1893,"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _list [ key ] <TAB><TAB> elif isinstance ( key , slice ) : <TAB><TAB><TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB><TAB> if k . lower ( ) == ikey : <TAB><TAB><TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB><TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key )","if isinstance ( key , ( int , long ) ) :","if isinstance ( key , string_types ) :",95.01777686849574,97.09,False
1894,"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB><TAB> else : <TAB><TAB><TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB><TAB> if o . selected : <TAB><TAB><TAB> on . append ( o ) <TAB><TAB> else : <TAB><TAB><TAB> off . append ( o ) <TAB> return on , off",if len ( all_items ) < target :,if len ( items ) == target :,96.70338622553014,97.22,False
1895,"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir : <TAB><TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB><TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB><TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB><TAB> if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) : <TAB><TAB><TAB> return gdirs [ 0 ]",if seq_file and os . path . exists ( seq_file ) :,if seq_file :,68.64409015273425,94.32,False
1896,"def _PrintFuncs ( self , names ) : <TAB> # type: (List[str]) -> int <TAB> status = 0 <TAB> for name in names : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( name ) <TAB><TAB><TAB> # TODO: Could print LST for -f, or render LST.  Bash does this.  'trap' <TAB><TAB><TAB> # could use that too. <TAB><TAB> else : <TAB><TAB><TAB> status = 1 <TAB> return status",if name in self . funcs :,"if name . endswith ( ""-f"" ) :",70.53651565996257,93.76,False
1897,"def package_files ( self ) : <TAB> seen_package_directories = ( ) <TAB> directories = self . distribution . package_dir or { } <TAB> empty_directory_exists = "" "" in directories <TAB> packages = self . distribution . packages or [ ] <TAB> for package in packages : <TAB><TAB> if package in directories : <TAB><TAB><TAB> package_directory = directories [ package ] <TAB><TAB> elif empty_directory_exists : <TAB><TAB><TAB> package_directory = os . path . join ( directories [ "" "" ] , package ) <TAB><TAB> else : <TAB><TAB><TAB> package_directory = package <TAB><TAB> <MASK> <TAB><TAB><TAB> seen_package_directories + = ( package_directory + "" . "" , ) <TAB><TAB><TAB> yield package_directory",if not package_directory . startswith ( seen_package_directories ) :,if package_directory not in seen_package_directories :,66.15952811834494,95.70,False
1898,"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB><TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with open ( conf_file ) as conf_handle : <TAB><TAB><TAB><TAB> value = fn ( conf_handle ) <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> return value <TAB> return None",if conf_file :,if os . path . exists ( conf_file ) :,65.35724248686401,92.64,False
1899,"def on_text ( self , text ) : <TAB> if text != self . chosen_text : <TAB><TAB> self . fail_test ( ' Expected  "" {} "" , received  "" {} "" ' . format ( self . chosen_text , text ) ) <TAB> else : <TAB><TAB> self . checks_passed + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . pass_test ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . _select_next_text ( )",if self . checks_passed >= self . number_of_checks :,if self . checks_passed == self . number_of_checks :,98.34335035528214,98.24,False
1900,"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB><TAB> if self . _is_ast_node ( name , item ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # Index(value) just returns value now. <TAB><TAB><TAB><TAB> # The argument is required. <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> x = item ( ) <TAB><TAB><TAB> if isinstance ( x , ast . AST ) : <TAB><TAB><TAB><TAB> self . assertEqual ( type ( x . _fields ) , tuple )","if name == ""Index"" :","if name == ""value"" :",98.47191976154575,98.61,False
1901,"def apply ( self , response ) : <TAB> updated_headers = self . update_headers ( response ) <TAB> if updated_headers : <TAB><TAB> response . headers . update ( updated_headers ) <TAB><TAB> warning_header_value = self . warning ( response ) <TAB><TAB> <MASK> <TAB><TAB><TAB> response . headers . update ( { "" Warning "" : warning_header_value } ) <TAB> return response",if warning_header_value is not None :,if warning_header_value :,65.63222291671626,95.95,False
1902,"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB><TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB><TAB> if self . use_parallel_executor and not self . use_double_buffer : <TAB><TAB><TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB><TAB> else : <TAB><TAB><TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB><TAB><TAB><TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) )",if not self . use_parallel_executor :,if self . use_parallel_executor :,72.38694452703281,98.97,False
1903,def finalize ( self ) : <TAB> if self . _started : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _queue . put ( None ) <TAB><TAB><TAB> self . _queue . join ( ) <TAB><TAB><TAB> self . _consumer . join ( ) <TAB><TAB> self . _started = False <TAB> self . _finalized = True,if not self . _finalized :,if self . _queue :,84.80590332351676,94.93,False
1904,"def _get_ilo_version ( self ) : <TAB> try : <TAB><TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> if e . code == 405 : <TAB><TAB><TAB><TAB> return 3 <TAB><TAB><TAB> if e . code == 501 : <TAB><TAB><TAB><TAB> return 1 <TAB><TAB> raise <TAB> return 2","if hasattr ( e , ""code"" ) :",if e . code == 404 :,67.06542183473508,94.01,False
1905,"def _check_data ( self , source , expected_bytes , expected_duration ) : <TAB> received_bytes = 0 <TAB> received_seconds = 0.0 <TAB> bytes_to_read = 1024 <TAB> while True : <TAB><TAB> data = source . get_audio_data ( bytes_to_read ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> received_bytes + = data . length <TAB><TAB> received_seconds + = data . duration <TAB><TAB> self . assertEqual ( data . length , len ( data . data ) ) <TAB> self . assertAlmostEqual ( expected_duration , received_seconds , places = 1 ) <TAB> self . assertAlmostEqual ( expected_bytes , received_bytes , delta = 5 )",if data is None :,if not data :,66.98349678480992,97.63,False
1906,"def __randomize_interval_task ( self ) : <TAB> for job in self . aps_scheduler . get_jobs ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . aps_scheduler . modify_job ( <TAB><TAB><TAB><TAB> job . id , <TAB><TAB><TAB><TAB> next_run_time = datetime . now ( ) <TAB><TAB><TAB><TAB> + timedelta ( <TAB><TAB><TAB><TAB><TAB> seconds = randrange ( <TAB><TAB><TAB><TAB><TAB><TAB> job . trigger . interval . total_seconds ( ) * 0.75 , <TAB><TAB><TAB><TAB><TAB><TAB> job . trigger . interval . total_seconds ( ) , <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB> )","if isinstance ( job . trigger , IntervalTrigger ) :",if job . trigger . interval . total_seconds ( ) > 0.75 :,75.2838635502128,94.85,False
1907,"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB><TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB><TAB> p , q = i . as_numer_denom ( ) <TAB><TAB> tol = c / q * * 2 <TAB><TAB> <MASK> <TAB><TAB><TAB> return i <TAB><TAB> if tol < machine_epsilon : <TAB><TAB><TAB> break <TAB> return x",if abs ( i - x ) <= tol :,if p == 0 :,63.2807022116722,92.97,False
1908,"def fix_newlines ( lines ) : <TAB> """"""Convert newlines to unix."""""" <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> if line . endswith ( "" \r \n "" ) : <TAB><TAB><TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB><TAB> <MASK> <TAB><TAB><TAB> lines [ i ] = line [ : - 1 ] + "" \n ""","elif line . endswith ( ""\r"" ) :","elif line . endswith ( ""\r\n"" ) :",94.66172709430455,97.11,False
1909,"def payment_control_render ( self , request : HttpRequest , payment : OrderPayment ) : <TAB> template = get_template ( "" pretixplugins/paypal/control.html "" ) <TAB> sale_id = None <TAB> for trans in payment . info_data . get ( "" transactions "" , [ ] ) : <TAB><TAB> for res in trans . get ( "" related_resources "" , [ ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sale_id = res [ "" sale "" ] [ "" id "" ] <TAB> ctx = { <TAB><TAB> "" request "" : request , <TAB><TAB> "" event "" : self . event , <TAB><TAB> "" settings "" : self . settings , <TAB><TAB> "" payment_info "" : payment . info_data , <TAB><TAB> "" order "" : payment . order , <TAB><TAB> "" sale_id "" : sale_id , <TAB> } <TAB> return template . render ( ctx )","if ""sale"" in res and ""id"" in res [ ""sale"" ] :","if res [ ""sale"" ] :",95.13867663937823,95.35,False
1910,"def for_name ( self , name ) : <TAB> try : <TAB><TAB> name_resources = self . _resources [ name ] <TAB> except KeyError : <TAB><TAB> raise LookupError ( name ) <TAB> else : <TAB><TAB> for res in name_resources : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> inst = res . inst ( ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> log . exception ( "" error initializing  %s "" , res ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> log . error ( "" error initializing  %s :  %s "" , res , e ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield inst",if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,100.0,100.00,True
1911,"def describe ( self , done = False ) : <TAB> description = ShellCommand . describe ( self , done ) <TAB> if done : <TAB><TAB> <MASK> <TAB><TAB><TAB> description = [ "" compile "" ] <TAB><TAB> description . append ( "" %d  projects "" % self . getStatistic ( "" projects "" , 0 ) ) <TAB><TAB> description . append ( "" %d  files "" % self . getStatistic ( "" files "" , 0 ) ) <TAB><TAB> warnings = self . getStatistic ( "" warnings "" , 0 ) <TAB><TAB> if warnings > 0 : <TAB><TAB><TAB> description . append ( "" %d  warnings "" % warnings ) <TAB><TAB> errors = self . getStatistic ( "" errors "" , 0 ) <TAB><TAB> if errors > 0 : <TAB><TAB><TAB> description . append ( "" %d  errors "" % errors ) <TAB> return description",if not description :,if not description :,100.0,100.00,True
1912,"def parse_list ( tl ) : <TAB> ls = [ ] <TAB> nm = [ ] <TAB> while True : <TAB><TAB> term , nmt , tl = parse_term ( tl ) <TAB><TAB> ls . append ( term ) <TAB><TAB> <MASK> <TAB><TAB><TAB> nm . append ( nmt ) <TAB><TAB> if tl [ 0 ] != "" , "" : <TAB><TAB><TAB> break <TAB><TAB> tl = tl [ 1 : ] <TAB> return ls , nm , tl",if nmt is not None :,if nmt :,73.48568812993877,96.59,False
1913,"def infer_dataset_impl ( path ) : <TAB> if IndexedRawTextDataset . exists ( path ) : <TAB><TAB> return "" raw "" <TAB> elif IndexedDataset . exists ( path ) : <TAB><TAB> with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB><TAB><TAB> magic = f . read ( 8 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return "" cached "" <TAB><TAB><TAB> elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] : <TAB><TAB><TAB><TAB> return "" mmap "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return None <TAB> elif FastaDataset . exists ( path ) : <TAB><TAB> return "" fasta "" <TAB> else : <TAB><TAB> return None",if magic == IndexedDataset . _HDR_MAGIC :,if magic == IndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,71.22262381196053,96.33,False
1914,"def _get ( self ) : <TAB> fut = item = None <TAB> with self . _mutex : <TAB><TAB> # Critical section never blocks. <TAB><TAB> <MASK> <TAB><TAB><TAB> fut = Future ( ) <TAB><TAB><TAB> fut . add_done_callback ( <TAB><TAB><TAB><TAB> lambda f : self . _get_complete ( ) if not f . cancelled ( ) else None <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . _getters . append ( fut ) <TAB><TAB> else : <TAB><TAB><TAB> item = self . _get_item ( ) <TAB><TAB><TAB> self . _get_complete ( ) <TAB> return item , fut",if not self . _queue or self . _getters :,if self . _is_async :,95.18482480401237,94.96,False
1915,"def validate ( self ) : <TAB> dates = [ ] <TAB> for d in self . get ( "" leave_block_list_dates "" ) : <TAB><TAB> # date is not repeated <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . msgprint ( <TAB><TAB><TAB><TAB> _ ( "" Date is repeated "" ) + "" : "" + d . block_date , raise_exception = 1 <TAB><TAB><TAB> ) <TAB><TAB> dates . append ( d . block_date )",if d . block_date in dates :,if d . block_date not in dates :,98.63294748250621,98.13,False
1916,"def on_choose_watch_dir_clicked ( self ) : <TAB> if self . window ( ) . watchfolder_enabled_checkbox . isChecked ( ) : <TAB><TAB> previous_watch_dir = self . window ( ) . watchfolder_location_input . text ( ) or "" "" <TAB><TAB> watch_dir = QFileDialog . getExistingDirectory ( <TAB><TAB><TAB> self . window ( ) , <TAB><TAB><TAB> "" Please select the watch folder "" , <TAB><TAB><TAB> previous_watch_dir , <TAB><TAB><TAB> QFileDialog . ShowDirsOnly , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> self . window ( ) . watchfolder_location_input . setText ( watch_dir )",if not watch_dir :,if not watch_dir :,100.0,100.00,True
1917,"def log_generator ( self , limit = 6000 , * * kwargs ) : <TAB> # Generator for show_log_panel <TAB> skip = 0 <TAB> while True : <TAB><TAB> logs = self . log ( limit = limit , skip = skip , * * kwargs ) <TAB><TAB> if not logs : <TAB><TAB><TAB> break <TAB><TAB> for entry in logs : <TAB><TAB><TAB> yield entry <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> skip = skip + limit",if len ( logs ) < limit :,if skip >= limit :,95.93358553430822,95.30,False
1918,"def _setUpClass ( cls ) : <TAB> global solver <TAB> import pyomo . environ <TAB> from pyomo . solvers . tests . io . writer_test_cases import testCases <TAB> for test_case in testCases : <TAB><TAB> <MASK> <TAB><TAB><TAB> solver [ ( test_case . name , test_case . io ) ] = True","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :","if isinstance ( test_case , pyomo . solvers . tests . io . writer",78.1177058726317,77.45,False
1919,"def _get_file_data ( self , normpath , normrev ) : <TAB> data = self . client . cat ( normpath , normrev ) <TAB> if has_expanded_svn_keywords ( data ) : <TAB><TAB> # Find out if this file has any keyword expansion set. <TAB><TAB> # If it does, collapse these keywords. This is because SVN <TAB><TAB> # will return the file expanded to us, which would break patching. <TAB><TAB> keywords = self . client . propget ( "" svn:keywords "" , normpath , normrev , recurse = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data = collapse_svn_keywords ( data , force_bytes ( keywords [ normpath ] ) ) <TAB> return data",if normpath in keywords :,if keywords :,98.27596675882745,97.98,False
1920,"def add_controller_list ( path ) : <TAB> if not os . path . exists ( os . path . join ( path , "" __init__.py "" ) ) : <TAB><TAB> bb . fatal ( "" Controllers directory  %s  exists but is missing __init__.py "" % path ) <TAB> files = sorted ( <TAB><TAB> [ f for f in os . listdir ( path ) if f . endswith ( "" .py "" ) and not f . startswith ( "" _ "" ) ] <TAB> ) <TAB> for f in files : <TAB><TAB> module = "" oeqa.controllers. "" + f [ : - 3 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> controllerslist . append ( module ) <TAB><TAB> else : <TAB><TAB><TAB> bb . warn ( <TAB><TAB><TAB><TAB> "" Duplicate controller module found for  %s , only one added. Layers should create unique controller module names "" <TAB><TAB><TAB><TAB> % module <TAB><TAB><TAB> )",if module not in controllerslist :,if module in controllerslist :,99.06312405461007,99.01,False
1921,"def on_session2 ( event ) : <TAB> new_xmpp . get_roster ( ) <TAB> new_xmpp . send_presence ( ) <TAB> logging . info ( roster [ 0 ] ) <TAB> data = roster [ 0 ] [ "" roster "" ] [ "" items "" ] <TAB> logging . info ( data ) <TAB> for jid , item in data . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_xmpp . send_presence ( ptype = "" subscribe "" , pto = jid ) <TAB><TAB> new_xmpp . update_roster ( jid , name = item [ "" name "" ] , groups = item [ "" groups "" ] ) <TAB> new_xmpp . disconnect ( )","if item [ ""subscription"" ] != ""none"" :","if item [ ""pto"" ] :",95.96396844966327,94.96,False
1922,"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB><TAB><TAB> results . update ( result ) <TAB><TAB> elif isinstance ( sym , ast . ClassDef ) : <TAB><TAB><TAB> result = _parse_class_simplified ( sym ) <TAB><TAB><TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB><TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results","if isinstance ( sym , ast . FunctionDef ) :","if isinstance ( sym , ast . FunctionDef ) :",100.0,100.00,True
1923,"def check_args ( args ) : <TAB> """"""Checks that the args are coherent."""""" <TAB> check_args_has_attributes ( args ) <TAB> if args . v : <TAB><TAB> non_version_attrs = [ v for k , v in args . __dict__ . items ( ) if k != "" v "" ] <TAB><TAB> print ( "" non_version_attrs "" , non_version_attrs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fail ( "" Cannot show the version number with another command. "" ) <TAB><TAB> return <TAB> if args . i is None : <TAB><TAB> fail ( "" Cannot draw ER diagram of no database. "" ) <TAB> if args . o is None : <TAB><TAB> fail ( "" Cannot draw ER diagram with no output file. "" )",if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,if non_version_attrs :,62.724601783253284,90.76,False
1924,"def handle ( self , * args , * * options ) : <TAB> if not settings . ST_BASE_DIR . endswith ( "" spirit "" ) : <TAB><TAB> raise CommandError ( <TAB><TAB><TAB> "" settings.ST_BASE_DIR is not the spirit root folder, are you overriding it? "" <TAB><TAB> ) <TAB> for root , dirs , files in os . walk ( settings . ST_BASE_DIR ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> with utils . pushd ( root ) : <TAB><TAB><TAB> call_command ( <TAB><TAB><TAB><TAB> "" makemessages "" , stdout = self . stdout , stderr = self . stderr , * * options <TAB><TAB><TAB> ) <TAB> self . stdout . write ( "" ok "" )","if ""locale"" not in dirs :","if not root . endswith ( "".py"" ) :",94.19173254243567,94.86,False
1925,"def scan ( scope ) : <TAB> for s in scope . children : <TAB><TAB> if s . start_pos < = position < = s . end_pos : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return scan ( s ) or s <TAB><TAB><TAB> elif s . type in ( "" suite "" , "" decorated "" ) : <TAB><TAB><TAB><TAB> return scan ( s ) <TAB> return None","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :","if s . type in ( ""suite"" , ""decorated"" ) :",88.51999935892682,89.37,False
1926,def run_sync ( self ) : <TAB> count = 0 <TAB> while count < self . args . num_messages : <TAB><TAB> batch = self . receiver . fetch_next ( max_batch_size = self . args . num_messages - count ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for msg in batch : <TAB><TAB><TAB><TAB> msg . complete ( ) <TAB><TAB> count + = len ( batch ),if self . args . peeklock :,if len ( batch ) :,65.95463737455255,94.36,False
1927,"def __getitem__ ( self , item ) : <TAB> if self . _datas is not None : <TAB><TAB> ret = [ ] <TAB><TAB> for data in self . _datas : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . append ( data [ self . _offset ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret . append ( data . iloc [ self . _offset ] ) <TAB><TAB> self . _offset + = 1 <TAB><TAB> return ret <TAB> else : <TAB><TAB> return self . _get_data ( item )","if isinstance ( data , np . ndarray ) :",if self . _offset == item :,84.40027277044356,94.50,False
1928,"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB><TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB><TAB> try : <TAB><TAB><TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB> except error_perm as error : <TAB><TAB><TAB> code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB> if code == "" 550 "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB> if not self . isempty ( path ) : <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB> raise # pragma: no cover",if self . isfile ( path ) :,if self . isempty ( path ) :,74.05106971240627,99.02,False
1929,"def replaces_in_file ( file , replacement_list ) : <TAB> rs = [ ( re . compile ( regexp ) , repl ) for ( regexp , repl ) in replacement_list ] <TAB> file_tmp = file + "" . "" + str ( os . getpid ( ) ) + "" .tmp "" <TAB> with open ( file , "" r "" ) as f : <TAB><TAB> with open ( file_tmp , "" w "" ) as f_tmp : <TAB><TAB><TAB> for line in f : <TAB><TAB><TAB><TAB> for r , replace in rs : <TAB><TAB><TAB><TAB><TAB> match = r . search ( line ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> line = replace + "" \n "" <TAB><TAB><TAB><TAB> f_tmp . write ( line ) <TAB> shutil . move ( file_tmp , file )",if match :,if match :,100.0,100.00,True
1930,"def _get_path_check_mem ( self , i , size ) : <TAB> if size > 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> p = self . _get_path ( i , - 1 ) <TAB><TAB> else : <TAB><TAB><TAB> p = self . _get_path ( i , size ) <TAB><TAB><TAB> if p . startswith ( "" /dev/shm "" ) : <TAB><TAB><TAB><TAB> env . meminfo . add ( size ) <TAB> else : <TAB><TAB> p = self . _get_path ( i , size ) <TAB> return p",if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,if size == 1 :,85.94541990302781,89.20,False
1931,"def find_widget_by_id ( self , id , parent = None ) : <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None : <TAB><TAB> if id in self : <TAB><TAB><TAB> return self [ id ] # Do things fast if possible <TAB><TAB> parent = self [ "" editor "" ] <TAB> for c in parent . get_children ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if c . get_id ( ) == id : <TAB><TAB><TAB><TAB> return c <TAB><TAB> if isinstance ( c , Gtk . Container ) : <TAB><TAB><TAB> r = self . find_widget_by_id ( id , c ) <TAB><TAB><TAB> if not r is None : <TAB><TAB><TAB><TAB> return r <TAB> return None","if hasattr ( c , ""get_id"" ) :","if isinstance ( c , Gtk . Widget ) :",97.51808891276117,96.05,False
1932,"def _deserialize ( cls , io ) : <TAB> flags = VideoFlags ( ) <TAB> flags . byte = U8 . read ( io ) <TAB> if flags . bit . type == VIDEO_FRAME_TYPE_COMMAND_FRAME : <TAB><TAB> data = VideoCommandFrame . deserialize ( io ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> data = AVCVideoData . deserialize ( io ) <TAB><TAB> else : <TAB><TAB><TAB> data = io . read ( ) <TAB> return cls ( flags . bit . type , flags . bit . codec , data )",if flags . bit . codec == VIDEO_CODEC_ID_AVC :,if flags . bit . type == AVC_Video_TYPE_ADC_DATA :,80.86155775499466,92.30,False
1933,"def asciiLogData ( data , maxlen = 64 , replace = False ) : <TAB> ellipses = ""  ... "" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> dd = data [ : maxlen ] + ellipses <TAB><TAB> else : <TAB><TAB><TAB> dd = data <TAB><TAB> return dd . decode ( "" utf8 "" , errors = "" replace "" if replace else "" strict "" ) <TAB> except : <TAB><TAB> return "" 0x "" + binLogData ( data , maxlen )",if len ( data ) > maxlen - len ( ellipses ) :,if len ( data ) > maxlen :,91.19392060783113,95.09,False
1934,"def _check_units ( self , new_unit_system ) : <TAB> # If no unit system has been specified for me yet, adopt the incoming <TAB> # system <TAB> if self . unit_system is None : <TAB><TAB> self . unit_system = new_unit_system <TAB> else : <TAB><TAB> # Otherwise, make sure they match <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Unit system mismatch  %d  v.  %d "" % ( self . unit_system , new_unit_system ) <TAB><TAB><TAB> )",if self . unit_system != new_unit_system :,if self . unit_system != new_unit_system :,75.0,100.00,True
1935,"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB><TAB> visitor = process_file ( filename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB><TAB><TAB> if fix : <TAB><TAB><TAB><TAB> print ( "" Fixing:  %s "" % filename ) <TAB><TAB><TAB><TAB> fix_file ( filename )",if visitor . needs_fix ( ) :,if visitor :,67.67641001486633,94.45,False
1936,"def assign_attributes_to_variants ( variant_attributes ) : <TAB> for value in variant_attributes : <TAB><TAB> pk = value [ "" pk "" ] <TAB><TAB> defaults = value [ "" fields "" ] <TAB><TAB> defaults [ "" variant_id "" ] = defaults . pop ( "" variant "" ) <TAB><TAB> defaults [ "" assignment_id "" ] = defaults . pop ( "" assignment "" ) <TAB><TAB> assigned_values = defaults . pop ( "" values "" ) <TAB><TAB> assoc , created = AssignedVariantAttribute . objects . update_or_create ( <TAB><TAB><TAB> pk = pk , defaults = defaults <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assoc . values . set ( AttributeValue . objects . filter ( pk__in = assigned_values ) )",if created :,if created :,100.0,100.00,True
1937,"def _info ( self , userlist ) : <TAB> for strng in userlist : <TAB><TAB> group_matched = False <TAB><TAB> for env in self . base . comps . environments_by_pattern ( strng ) : <TAB><TAB><TAB> self . output . display_groups_in_environment ( env ) <TAB><TAB><TAB> group_matched = True <TAB><TAB> for group in self . base . comps . groups_by_pattern ( strng ) : <TAB><TAB><TAB> self . output . display_pkgs_in_groups ( group ) <TAB><TAB><TAB> group_matched = True <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . error ( _ ( "" Warning: Group  %s  does not exist. "" ) , strng ) <TAB> return 0 , [ ]",if not group_matched :,if not group_matched :,100.0,100.00,True
1938,"def parse_implements_interfaces ( parser ) : <TAB> types = [ ] <TAB> if parser . token . value == "" implements "" : <TAB><TAB> advance ( parser ) <TAB><TAB> while True : <TAB><TAB><TAB> types . append ( parse_named_type ( parser ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> return types","if not peek ( parser , TokenKind . NAME ) :",if not parser . token . value :,88.82344106722715,91.75,False
1939,"def generate ( ) : <TAB> for leaf in u . leaves : <TAB><TAB> if isinstance ( leaf , Integer ) : <TAB><TAB><TAB> val = leaf . get_int_value ( ) <TAB><TAB><TAB> if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB> yield val <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB> if leaf == SymbolTrue : <TAB><TAB><TAB><TAB> yield 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield 0 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> else : <TAB><TAB><TAB> raise _NoBoolVector",elif leaf == SymbolFalse :,elif leaf == SymbolFalse :,100.0,100.00,True
1940,"def update_gstin ( context ) : <TAB> dirty = False <TAB> for key , value in iteritems ( frappe . form_dict ) : <TAB><TAB> if key != "" party "" : <TAB><TAB><TAB> address_name = frappe . get_value ( "" Address "" , key ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> address = frappe . get_doc ( "" Address "" , address_name ) <TAB><TAB><TAB><TAB> address . gstin = value . upper ( ) <TAB><TAB><TAB><TAB> address . save ( ignore_permissions = True ) <TAB><TAB><TAB><TAB> dirty = True <TAB> if dirty : <TAB><TAB> frappe . db . commit ( ) <TAB><TAB> context . updated = True",if address_name :,if address_name :,100.0,100.00,True
1941,"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> for i in v : <TAB><TAB><TAB><TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB><TAB> elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , _bytes ) : <TAB><TAB><TAB> return False <TAB> return True","if isinstance ( v , dict ) and k != ""headers"" :","if isinstance ( v , dict ) :",70.88216663878359,96.27,False
1942,"def check_graph ( graph ) : # pragma: no cover <TAB> for c in graph : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" cannot have fuse "" ) <TAB><TAB> for inp in c . inputs : <TAB><TAB><TAB> if isinstance ( inp . op , Fuse ) : <TAB><TAB><TAB><TAB> raise RuntimeError ( "" cannot have fuse "" )","if isinstance ( c . op , Fuse ) :","if isinstance ( c . op , Fuse ) :",75.0,100.00,True
1943,"def __getattr__ ( self , key ) : <TAB> try : <TAB><TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB><TAB> pass <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( value , _ModuleMarker ) : <TAB><TAB><TAB><TAB> return value . mod_ns <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB><TAB><TAB><TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB><TAB> "" Module  %r  has no mapped classes  "" <TAB><TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> )",if value is not None :,"if hasattr ( value , ""mod_ns"" ) :",94.91779817694675,94.80,False
1944,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB><TAB> nw_id_ = port . network_id <TAB><TAB> if port . port_no == in_port : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB><TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB> return ret",if nw_id_ == nw_id :,if nw_id_ == self . nw_id_unknown :,96.56434737159654,96.56,False
1945,"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> for line in contents . splitlines ( ) : <TAB><TAB> if not len ( line . strip ( ) ) : <TAB><TAB><TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> entries . append ( ( "" option "" , [ head . split ( None ) , tail ] ) ) <TAB> return entries",if not len ( head ) :,"if head . startswith ( ""#"" ) :",69.26493401069743,95.68,False
1946,"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB><TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB><TAB><TAB> # Don't tab complete undocumented commands/params <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if getattr ( command , "" positional_arg "" , False ) : <TAB><TAB><TAB> continue <TAB><TAB> names . append ( key ) <TAB> return names",if startswith is not None and not key . startswith ( startswith ) :,if startswith and key . startswith ( startswith ) :,96.07035744193637,96.06,False
1947,"def _convert_example ( example , use_bfloat16 ) : <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list ( example . keys ( ) ) : <TAB><TAB> val = example [ key ] <TAB><TAB> <MASK> <TAB><TAB><TAB> val = tf . sparse . to_dense ( val ) <TAB><TAB> if val . dtype == tf . int64 : <TAB><TAB><TAB> val = tf . cast ( val , tf . int32 ) <TAB><TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB><TAB><TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB><TAB> example [ key ] = val",if tf . keras . backend . is_sparse ( val ) :,"if isinstance ( val , tf . sparse . Sparse ) :",68.01235283339776,94.49,False
1948,"def _get_lang_zone ( self , lang ) : <TAB> if lang not in self . _lang_zone_from_lang : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _lang_zone_from_lang [ lang ] = MultiLangZone ( self . mgr , lang ) <TAB><TAB> else : <TAB><TAB><TAB> self . _lang_zone_from_lang [ lang ] = LangZone ( self . mgr , lang ) <TAB> return self . _lang_zone_from_lang [ lang ]",if self . mgr . is_multilang ( lang ) :,if self . mgr . multi_lang :,91.92037600387619,94.77,False
1949,"def dispatch ( self , request , * args , * * kwargs ) : <TAB> try : <TAB><TAB> return super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB> except Http404 as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> request . original_path_info = request . path_info <TAB><TAB><TAB><TAB> request . path_info = settings . FEINCMS_CMS_404_PAGE <TAB><TAB><TAB><TAB> response = super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB><TAB><TAB><TAB> response . status_code = 404 <TAB><TAB><TAB><TAB> return response <TAB><TAB><TAB> except Http404 : <TAB><TAB><TAB><TAB> raise e <TAB><TAB> else : <TAB><TAB><TAB> raise",if settings . FEINCMS_CMS_404_PAGE :,if request . path_info :,96.41394380623696,95.83,False
1950,"def _maybe_update_dropout ( self , step ) : <TAB> for i in range ( len ( self . dropout_steps ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . model . update_dropout ( self . dropout [ i ] ) <TAB><TAB><TAB> logger . info ( "" Updated dropout to  %f  from step  %d "" % ( self . dropout [ i ] , step ) )",if step > 1 and step == self . dropout_steps [ i ] + 1 :,if self . dropout [ i ] != self . dropout [ i ] :,62.134681650386746,87.25,False
1951,"def bulk_move ( * args , * * kwargs ) : <TAB> for arg in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PopupException ( _ ( "" Source path and destination path cannot be same "" ) ) <TAB><TAB> request . fs . rename ( <TAB><TAB><TAB> urllib . unquote ( arg [ "" src_path "" ] ) , urllib . unquote ( arg [ "" dest_path "" ] ) <TAB><TAB> )","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :","if arg [ ""src_path"" ] != arg [ ""dest_path"" ] :",98.4092399780947,98.01,False
1952,"def asisWrite ( self , root ) : <TAB> at , c = self , self . c <TAB> try : <TAB><TAB> c . endEditing ( ) <TAB><TAB> c . init_error_dialogs ( ) <TAB><TAB> fileName = at . initWriteIvars ( root , root . atAsisFileNodeName ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> at . addToOrphanList ( root ) <TAB><TAB><TAB> return <TAB><TAB> at . openOutputStream ( ) <TAB><TAB> for p in root . self_and_subtree ( copy = False ) : <TAB><TAB><TAB> at . writeAsisNode ( p ) <TAB><TAB> contents = at . closeOutputStream ( ) <TAB><TAB> at . replaceFile ( contents , at . encoding , fileName , root ) <TAB> except Exception : <TAB><TAB> at . writeException ( fileName , root )","if not at . precheck ( fileName , root ) :",if not fileName :,66.81837339871659,95.61,False
1953,"def next_event ( it ) : <TAB> """"""read an event from an eventstream"""""" <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> line = next ( it ) <TAB><TAB> except StopIteration : <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> return json . loads ( line . split ( "" : "" , 1 ) [ 1 ] )","if line . startswith ( ""data:"" ) :","if line . startswith ( ""event:"" ) :",97.9423940437251,97.80,False
1954,"def process_formdata ( self , valuelist ) : <TAB> if valuelist : <TAB><TAB> if valuelist [ 0 ] == "" __None "" : <TAB><TAB><TAB> self . data = None <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . data = None <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> obj = self . queryset . get ( pk = valuelist [ 0 ] ) <TAB><TAB><TAB><TAB> self . data = obj <TAB><TAB><TAB> except DoesNotExist : <TAB><TAB><TAB><TAB> self . data = None",if self . queryset is None :,"if valuelist [ 0 ] == ""__None"" :",91.78812903568986,93.60,False
1955,"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB><TAB><TAB><TAB> "" will return a list of all parsed tokens in an And alternative,  "" <TAB><TAB><TAB><TAB> "" in prior versions only the first token was returned "" . format ( <TAB><TAB><TAB><TAB><TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB><TAB><TAB><TAB><TAB> name , <TAB><TAB><TAB><TAB><TAB> type ( self ) . __name__ , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> stacklevel = 3 , <TAB><TAB><TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches )","if any ( isinstance ( e , And ) for e in self . exprs ) :",if name in self . _named_tokens :,84.69090082868446,94.57,False
1956,"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB><TAB> form = BookMarkForm ( request . POST ) <TAB><TAB> if form . is_valid ( ) : <TAB><TAB><TAB> form_type = form . save ( ) <TAB><TAB><TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB><TAB> else : <TAB><TAB><TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB><TAB> <MASK> <TAB><TAB><TAB> url = reverse ( "" servers "" ) <TAB><TAB> else : <TAB><TAB><TAB> url = reverse ( "" metrics "" ) <TAB><TAB> return redirect ( url ) <TAB> else : <TAB><TAB> return redirect ( reverse ( "" servers "" ) )","if form_type == ""server"" :","if form_type == ""metrics"" :",99.01638255345395,98.88,False
1957,"def __init__ ( self , post_id , artist , page , tzInfo = None , dateFormat = None ) : <TAB> self . imageUrls = list ( ) <TAB> self . imageResizedUrls = list ( ) <TAB> self . imageId = int ( post_id ) <TAB> self . _tzInfo = tzInfo <TAB> self . dateFormat = dateFormat <TAB> if page is not None : <TAB><TAB> post_json = demjson . decode ( page ) <TAB><TAB> <MASK> <TAB><TAB><TAB> artist_id = post_json [ "" data "" ] [ "" item "" ] [ "" user "" ] [ "" id "" ] <TAB><TAB><TAB> self . artist = SketchArtist ( artist_id , page , tzInfo , dateFormat ) <TAB><TAB> else : <TAB><TAB><TAB> self . artist = artist <TAB><TAB> self . parse_post ( post_json [ "" data "" ] [ "" item "" ] )",if artist is None :,"if post_json [ ""data"" ] [ ""item"" ] [ ""user"" ]",71.88550397738342,91.64,False
1958,"def _create_batch_iterator ( <TAB> self , <TAB> mark_as_delete : Callable [ [ Any ] , None ] , <TAB> to_key : Callable [ [ Any ] , Any ] , <TAB> to_value : Callable [ [ Any ] , Any ] , <TAB> batch : Iterable [ EventT ] , ) - > Iterable [ Tuple [ Any , Any ] ] : <TAB> for event in batch : <TAB><TAB> key = to_key ( event . key ) <TAB><TAB> # to delete keys in the table we set the raw value to None <TAB><TAB> <MASK> <TAB><TAB><TAB> mark_as_delete ( key ) <TAB><TAB><TAB> continue <TAB><TAB> yield key , to_value ( event . value )",if event . message . value is None :,if event . value is None :,98.86461379347519,98.53,False
1959,"def test_lc_numeric_nl_langinfo ( self ) : <TAB> # Test nl_langinfo against known values <TAB> tested = False <TAB> for loc in candidate_locales : <TAB><TAB> try : <TAB><TAB><TAB> setlocale ( LC_NUMERIC , loc ) <TAB><TAB><TAB> setlocale ( LC_CTYPE , loc ) <TAB><TAB> except Error : <TAB><TAB><TAB> continue <TAB><TAB> for li , lc in ( ( RADIXCHAR , "" decimal_point "" ) , ( THOUSEP , "" thousands_sep "" ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tested = True <TAB> if not tested : <TAB><TAB> self . skipTest ( "" no suitable locales "" )","if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :","if setlocale ( LC_CTYPE , lc ) :",68.30575421002847,88.95,False
1960,"def _level_up_logging ( self ) : <TAB> for handler in self . log . handlers : <TAB><TAB> <MASK> <TAB><TAB><TAB> if handler . level != logging . DEBUG : <TAB><TAB><TAB><TAB> handler . setLevel ( logging . DEBUG ) <TAB><TAB><TAB><TAB> self . log . debug ( "" Leveled up log file verbosity "" )","if issubclass ( handler . __class__ , logging . FileHandler ) :","if hasattr ( handler , ""level"" ) :",64.2549511387382,87.44,False
1961,def _show_axes_changed ( self ) : <TAB> marker = self . marker <TAB> if ( self . _vtk_control is not None ) and ( marker is not None ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> marker . interactor = None <TAB><TAB><TAB> marker . enabled = False <TAB><TAB> else : <TAB><TAB><TAB> marker . interactor = self . interactor <TAB><TAB><TAB> marker . enabled = True <TAB><TAB> self . render ( ),if not self . show_axes :,if self . interactor is None :,70.00552717913084,94.85,False
1962,"def handle_keypress ( self , rawKey , modifiers , key , * args ) : <TAB> if self . recordKeyboard and self . __delayPassed ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . insideKeys = True <TAB><TAB><TAB> self . targetParent . start_key_sequence ( ) <TAB><TAB> modifierCount = len ( modifiers ) <TAB><TAB> if ( <TAB><TAB><TAB> modifierCount > 1 <TAB><TAB><TAB> or ( modifierCount == 1 and Key . SHIFT not in modifiers ) <TAB><TAB><TAB> or ( Key . SHIFT in modifiers and len ( rawKey ) > 1 ) <TAB><TAB> ) : <TAB><TAB><TAB> self . targetParent . append_hotkey ( rawKey , modifiers ) <TAB><TAB> elif key not in MODIFIERS : <TAB><TAB><TAB> self . targetParent . append_key ( key )",if not self . insideKeys :,if key == Key . SHIFT :,85.60033608473732,96.68,False
1963,"def transform ( self , data ) : <TAB> with timer ( "" transform  %s "" % self . name , logging . DEBUG ) : <TAB><TAB> if self . operator in { "" lat "" , "" latitude "" } : <TAB><TAB><TAB> return self . series ( data ) . apply ( GeoIP . get_latitude ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . series ( data ) . apply ( GeoIP . get_longitude ) <TAB><TAB> elif self . operator in { "" acc "" , "" accuracy "" } : <TAB><TAB><TAB> return self . series ( data ) . apply ( GeoIP . get_accuracy ) <TAB><TAB> raise NameError ( "" Unknown GeoIP operator [lat, lon, acc]:  %s "" % self . operator )","elif self . operator in { ""lon"" , ""longitude"" } :","elif self . operator in { ""lon"" , ""longitude"" } :",75.0,100.00,True
1964,"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB><TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB><TAB> <MASK> <TAB><TAB><TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB><TAB><TAB> if self . environment_id : <TAB><TAB><TAB><TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected",if self . service_id :,if self . service_id :,100.0,100.00,True
1965,"def _run_response_middleware ( self , request , response , request_name = None ) : <TAB> named_middleware = self . named_response_middleware . get ( request_name , deque ( ) ) <TAB> applicable_middleware = self . response_middleware + named_middleware <TAB> if applicable_middleware : <TAB><TAB> for middleware in applicable_middleware : <TAB><TAB><TAB> _response = middleware ( request , response ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _response = await _response <TAB><TAB><TAB> if _response : <TAB><TAB><TAB><TAB> response = _response <TAB><TAB><TAB><TAB> break <TAB> return response",if isawaitable ( _response ) :,if asyncio . iscoroutinefunction ( _response ) :,83.42723823426319,97.53,False
1966,"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB><TAB> # If field should be deleted, clean it up <TAB><TAB> if self . _should_delete : <TAB><TAB><TAB> field . delete ( ) <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> if not field . grid_id : <TAB><TAB><TAB><TAB> func = field . put <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> func = field . replace <TAB><TAB><TAB> func ( <TAB><TAB><TAB><TAB> self . data . stream , <TAB><TAB><TAB><TAB> filename = self . data . filename , <TAB><TAB><TAB><TAB> content_type = self . data . content_type , <TAB><TAB><TAB> )","if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :",if self . _should_replace :,92.2200338848026,91.98,False
1967,"def _import_hash ( self , operator ) : <TAB> # Import required modules into local namespace so that pipelines <TAB> # may be evaluated directly <TAB> for key in sorted ( operator . import_hash . keys ( ) ) : <TAB><TAB> module_list = "" ,  "" . join ( sorted ( operator . import_hash [ key ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> exec ( "" from  {}  import  {} "" . format ( key [ 4 : ] , module_list ) ) <TAB><TAB> else : <TAB><TAB><TAB> exec ( "" from  {}  import  {} "" . format ( key , module_list ) ) <TAB><TAB> for var in operator . import_hash [ key ] : <TAB><TAB><TAB> self . operators_context [ var ] = eval ( var )","if key . startswith ( ""tpot."" ) :","if key . startswith ( ""required"" ) :",74.04815000520276,98.29,False
1968,"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB><TAB> f_path = os . path . join ( folder , f ) <TAB><TAB> <MASK> <TAB><TAB><TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB><TAB><TAB> if extension in file_extensions : <TAB><TAB><TAB><TAB> os . remove ( f_path )",if os . path . isfile ( f_path ) :,if os . path . isfile ( f_path ) :,100.0,100.00,True
1969,"def clearBuffer ( self ) : <TAB> if self . shouldLose == - 1 : <TAB><TAB> return <TAB> if self . producer : <TAB><TAB> self . producer . resumeProducing ( ) <TAB> if self . buffer : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . logFile . write ( "" loopback receiving  %s \n "" % repr ( self . buffer ) ) <TAB><TAB> buffer = self . buffer <TAB><TAB> self . buffer = b "" "" <TAB><TAB> self . target . dataReceived ( buffer ) <TAB> if self . shouldLose == 1 : <TAB><TAB> self . shouldLose = - 1 <TAB><TAB> self . target . connectionLost ( failure . Failure ( main . CONNECTION_DONE ) )",if self . logFile :,if self . logLoopback :,98.92989472693552,98.59,False
1970,"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB><TAB> if self . _write_line : <TAB><TAB><TAB> sys . stderr . write ( fn + "" :  "" ) <TAB><TAB> if bytes : <TAB><TAB><TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB><TAB> else : <TAB><TAB><TAB> sys . stderr . write ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _write_line = True <TAB><TAB> else : <TAB><TAB><TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data )","if ( data [ - 1 ] ) == ""\n"" :",if not self . _write_line :,91.74514725632454,92.40,False
1971,def stop ( self ) : <TAB> self . queue_com . state_lock . acquire ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . queue_com . state = STOPPED <TAB><TAB><TAB> self . remove ( ) <TAB><TAB><TAB> return True <TAB><TAB> return False <TAB> finally : <TAB><TAB> self . queue_com . state_lock . release ( ),if self . queue_com . state == RUNNING and self . stop_task ( ) :,if self . queue_com . state == STOPPED :,78.7858213538223,91.56,False
1972,"def _handle_special_args ( self , pyobjects ) : <TAB> if len ( pyobjects ) == len ( self . arguments . args ) : <TAB><TAB> if self . arguments . vararg : <TAB><TAB><TAB> pyobjects . append ( rope . base . builtins . get_list ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pyobjects . append ( rope . base . builtins . get_dict ( ) )",if self . arguments . kwarg :,elif self . arguments . vararg :,71.04237729599566,95.26,False
1973,"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB><TAB> filename , position = self . last_edit_cursor_pos <TAB><TAB> if not osp . isfile ( filename ) : <TAB><TAB><TAB> self . last_edit_cursor_pos = None <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> self . load ( filename ) <TAB><TAB><TAB> editor = self . get_current_editor ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> editor . set_cursor_position ( position )",if position < editor . document ( ) . characterCount ( ) :,if editor is not None :,62.46201220743075,93.16,False
1974,"def _create_sentence_objects ( self ) : <TAB> """"""Returns a list of Sentence objects from the raw text."""""" <TAB> sentence_objects = [ ] <TAB> sent_tokenizer = SentenceTokenizer ( locale = self . language . code ) <TAB> seq = Sequence ( self . raw ) <TAB> seq = sent_tokenizer . transform ( seq ) <TAB> for start_index , end_index in zip ( seq . idx [ : - 1 ] , seq . idx [ 1 : ] ) : <TAB><TAB> # Sentences share the same models as their parent blob <TAB><TAB> sent = seq . text [ start_index : end_index ] . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> s = Sentence ( sent , start_index = start_index , end_index = end_index ) <TAB><TAB> s . detected_languages = self . detected_languages <TAB><TAB> sentence_objects . append ( s ) <TAB> return sentence_objects",if not sent :,"if sent == """" :",98.56323022611897,97.40,False
1975,"def to_json_schema ( self , parent = None ) : <TAB> schema = { } <TAB> if not parent : <TAB><TAB> schema [ "" title "" ] = self . title <TAB><TAB> <MASK> <TAB><TAB><TAB> schema [ "" description "" ] = self . description <TAB><TAB> if self . has_default : <TAB><TAB><TAB> schema [ "" default "" ] = self . default <TAB><TAB> schema [ "" _required_ "" ] = self . required <TAB> if self . null : <TAB><TAB> schema [ "" type "" ] = [ "" string "" , "" null "" ] <TAB> else : <TAB><TAB> schema [ "" type "" ] = "" string "" <TAB> if self . enum is not None : <TAB><TAB> schema [ "" enum "" ] = self . enum <TAB> return schema",if self . description :,if self . description is not None :,92.72938859451601,97.84,False
1976,def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB><TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB><TAB> return # do not clear link - we can get out of dir <TAB> for f in os . listdir ( dirname ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> path = dirname + os . sep + f <TAB><TAB> if os . path . isdir ( path ) : <TAB><TAB><TAB> rmdir ( path ) <TAB><TAB> else : <TAB><TAB><TAB> os . unlink ( path ) <TAB> os . rmdir ( dirname ),"if f in ( ""."" , "".."" ) :","if f . startswith ( ""__"" ) :",97.22058303533483,94.84,False
1977,"def convert_whole_dir ( path = Path ( "" marian_ckpt/ "" ) ) : <TAB> for subdir in tqdm ( list ( path . ls ( ) ) ) : <TAB><TAB> dest_dir = f "" marian_converted/ { subdir . name } "" <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> convert ( source_dir , dest_dir )","if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",if dest_dir in path . ls ( ) :,68.7270708759618,86.31,False
1978,"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB><TAB> col = text [ 1 : ] <TAB><TAB> if len ( col ) == 6 : <TAB><TAB><TAB> return col <TAB><TAB> <MASK> <TAB><TAB><TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB><TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text",elif len ( col ) == 3 :,elif len ( col ) == 3 :,100.0,100.00,True
1979,"def _init_rel_seek ( self ) : <TAB> "" Sets the file object ' s position to the relative location set above. "" <TAB> rs , fo = self . _rel_seek , self . _file_obj <TAB> if rs == 0.0 : <TAB><TAB> fo . seek ( 0 , os . SEEK_SET ) <TAB> else : <TAB><TAB> fo . seek ( 0 , os . SEEK_END ) <TAB><TAB> size = fo . tell ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _cur_pos = size <TAB><TAB> else : <TAB><TAB><TAB> target = int ( size * rs ) <TAB><TAB><TAB> fo . seek ( target , os . SEEK_SET ) <TAB><TAB><TAB> self . _align_to_newline ( ) <TAB><TAB><TAB> self . _cur_pos = fo . tell ( )",if rs == 1.0 :,if size < self . _max_size :,87.38315720050281,95.87,False
1980,"def parse_command_line ( self , argv = None ) : <TAB> """"""Parse the command line"""""" <TAB> if self . config : <TAB><TAB> parser = argparse . ArgumentParser ( add_help = False ) <TAB><TAB> self . settings [ "" config "" ] . add_argument ( parser ) <TAB><TAB> opts , _ = parser . parse_known_args ( argv ) <TAB><TAB> if opts . config is not None : <TAB><TAB><TAB> self . set ( "" config "" , opts . config ) <TAB><TAB> self . params . update ( self . import_from_module ( ) ) <TAB> parser = self . parser ( ) <TAB> opts = parser . parse_args ( argv ) <TAB> for k , v in opts . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . set ( k . lower ( ) , v )",if v is None :,"if k . startswith ( ""_"" ) :",71.03635518165152,95.98,False
1981,"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( <TAB><TAB> "" shield "" , region_name = "" us-east-1 "" <TAB> ) <TAB> protections = get_type_protections ( client , self . manager . get_model ( ) ) <TAB> protected_resources = { p [ "" ResourceArn "" ] for p in protections } <TAB> state = self . data . get ( "" state "" , False ) <TAB> results = [ ] <TAB> for arn , r in zip ( self . manager . get_arns ( resources ) , resources ) : <TAB><TAB> r [ "" c7n:ShieldProtected "" ] = shielded = arn in protected_resources <TAB><TAB> <MASK> <TAB><TAB><TAB> results . append ( r ) <TAB><TAB> elif not shielded and not state : <TAB><TAB><TAB> results . append ( r ) <TAB> return results",if shielded and state :,if arn in self . data :,71.92393744614812,97.10,False
1982,"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> j = i <TAB><TAB><TAB> i = self . skip_ws ( aList , i ) <TAB><TAB><TAB> assert j < i <TAB><TAB><TAB> if i > = len ( aList ) or aList [ i ] == "" \n "" : <TAB><TAB><TAB><TAB> # print ""removing trailing ws:"", `i-j` <TAB><TAB><TAB><TAB> del aList [ j : i ] <TAB><TAB><TAB><TAB> i = j <TAB><TAB> else : <TAB><TAB><TAB> i + = 1",if self . is_ws ( aList [ i ] ) :,"if aList [ i ] == ""\r"" :",92.86971230883836,94.90,False
1983,"def predict ( request : Request ) : <TAB> form = await request . form ( ) <TAB> files , entry = convert_input ( form ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return JSONResponse ( ALL_FEATURES_PRESENT_ERROR , status_code = 400 ) <TAB><TAB> try : <TAB><TAB><TAB> resp = model . predict ( data_dict = [ entry ] ) . to_dict ( "" records "" ) [ 0 ] <TAB><TAB><TAB> return JSONResponse ( resp ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> logger . error ( "" Error:  {} "" . format ( str ( e ) ) ) <TAB><TAB><TAB> return JSONResponse ( COULD_NOT_RUN_INFERENCE_ERROR , status_code = 500 ) <TAB> finally : <TAB><TAB> for f in files : <TAB><TAB><TAB> os . remove ( f . name )",if ( entry . keys ( ) & input_features ) != input_features :,"if entry in ( ""*"" , ""*"" ) :",66.29907446131766,93.08,False
1984,"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __conn . close ( ) <TAB><TAB><TAB> self . __conn = None <TAB><TAB> for _ , l in self . _library_cache . items ( ) : <TAB><TAB><TAB> if hasattr ( l , "" _reset "" ) and callable ( l . _reset ) : <TAB><TAB><TAB><TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB><TAB><TAB><TAB> l . _reset ( ) # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",if self . __conn is not None :,if self . __conn :,87.41690201355283,97.64,False
1985,"def read ( self ) : <TAB> if op . isfile ( self . fileName ) : <TAB><TAB> with textfile_open ( self . fileName , "" rt "" ) as fid : <TAB><TAB><TAB> items = json . load ( fid ) <TAB><TAB><TAB> # TODO: catch JSON exception... <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> items = dict ( ) <TAB> else : <TAB><TAB> items = dict ( ) <TAB> self . _items . clear ( ) <TAB> self . _items . update ( items ) <TAB> self . _haveReadData = True",if items is None :,if not items :,97.2574523441918,97.22,False
1986,"def get_django_comment ( text : str , i : int ) - > str : <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end < = len ( text ) : <TAB><TAB> if text [ end - 2 : end ] == "" #} "" : <TAB><TAB><TAB> return text [ i : end ] <TAB><TAB> <MASK> <TAB><TAB><TAB> unclosed_end = end <TAB><TAB> end + = 1 <TAB> raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] )","if not unclosed_end and text [ end ] == ""<"" :","if text [ end ] == ""#}"" :",82.6513214884817,93.95,False
1987,"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB><TAB> # get cached return value if present <TAB><TAB> value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # evaluate the late-bound function <TAB><TAB><TAB> value_ = self . _eval_late_binding ( value ) <TAB><TAB><TAB> schema = self . late_bind_schemas . get ( key ) <TAB><TAB><TAB> if schema is not None : <TAB><TAB><TAB><TAB> value_ = schema . validate ( value_ ) <TAB><TAB><TAB> # cache result of late bound func <TAB><TAB><TAB> self . _late_binding_returnvalues [ key ] = value_ <TAB><TAB> return value_ <TAB> else : <TAB><TAB> return value",if value_ is KeyError :,if value_ is not None :,98.72849240844066,98.52,False
1988,"def connect ( * args , * * ckwargs ) : <TAB> if "" give_content_type "" in kwargs : <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs [ "" give_content_type "" ] ( args [ 6 ] [ "" content-type "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> kwargs [ "" give_content_type "" ] ( "" "" ) <TAB> if "" give_connect "" in kwargs : <TAB><TAB> kwargs [ "" give_connect "" ] ( * args , * * ckwargs ) <TAB> status = code_iter . next ( ) <TAB> etag = etag_iter . next ( ) <TAB> timestamp = timestamps_iter . next ( ) <TAB> if status == - 1 : <TAB><TAB> raise HTTPException ( ) <TAB> return FakeConn ( status , etag , body = kwargs . get ( "" body "" , "" "" ) , timestamp = timestamp )","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :","if args [ 6 ] [ ""content-type"" ] :",93.83311915089233,93.04,False
1989,"def _reset ( self ) : <TAB> self . _handle_connect ( ) <TAB> if self . rewarder_session : <TAB><TAB> <MASK> <TAB><TAB><TAB> env_id = random . choice ( self . _sample_env_ids ) <TAB><TAB><TAB> logger . info ( "" Randomly sampled env_id= {} "" . format ( env_id ) ) <TAB><TAB> else : <TAB><TAB><TAB> env_id = None <TAB><TAB> self . rewarder_session . reset ( env_id = env_id ) <TAB> else : <TAB><TAB> logger . info ( <TAB><TAB><TAB> "" No rewarder session exists, so cannot send a reset via the rewarder channel "" <TAB><TAB> ) <TAB> self . _reset_mask ( ) <TAB> return [ None ] * self . n",if self . _sample_env_ids :,if self . _sample_env_ids :,100.0,100.00,True
1990,"def _create_architecture_list ( architectures , current_arch ) : <TAB> if not architectures : <TAB><TAB> return [ _Architecture ( build_on = [ current_arch ] ) ] <TAB> build_architectures : List [ str ] = [ ] <TAB> architecture_list : List [ _Architecture ] = [ ] <TAB> for item in architectures : <TAB><TAB> if isinstance ( item , str ) : <TAB><TAB><TAB> build_architectures . append ( item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> architecture_list . append ( <TAB><TAB><TAB><TAB> _Architecture ( build_on = item . get ( "" build-on "" ) , run_on = item . get ( "" run-on "" ) ) <TAB><TAB><TAB> ) <TAB> if build_architectures : <TAB><TAB> architecture_list . append ( _Architecture ( build_on = build_architectures ) ) <TAB> return architecture_list","if isinstance ( item , dict ) :","elif isinstance ( item , dict ) :",98.86045663269525,98.91,False
1991,"def inspect ( self , pokemon ) : <TAB> # Make sure it was not caught! <TAB> for caught_pokemon in self . cache : <TAB><TAB> same_latitude = "" {0:.4f} "" . format ( pokemon [ "" latitude "" ] ) == "" {0:.4f} "" . format ( <TAB><TAB><TAB> caught_pokemon [ "" latitude "" ] <TAB><TAB> ) <TAB><TAB> same_longitude = "" {0:.4f} "" . format ( pokemon [ "" longitude "" ] ) == "" {0:.4f} "" . format ( <TAB><TAB><TAB> caught_pokemon [ "" longitude "" ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB> if len ( self . cache ) > = 200 : <TAB><TAB> self . cache . pop ( 0 ) <TAB> self . cache . append ( pokemon )",if same_latitude and same_longitude :,if not same_latitude and not same_longitude :,73.49598904469453,97.77,False
1992,"def parley ( self ) : <TAB> for x in [ 0 , 1 ] : <TAB><TAB> a = self . agents [ x ] . act ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" [DONE] "" in a [ "" text "" ] : <TAB><TAB><TAB><TAB> self . agents [ x - 1 ] . observe ( <TAB><TAB><TAB><TAB><TAB> { "" id "" : "" World "" , "" text "" : "" The other agent has ended the chat. "" } <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> self . episodeDone = True <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . agents [ x - 1 ] . observe ( a )",if a is not None :,if self . episodeDone :,69.50004338511174,97.21,False
1993,"def _prepare_subset ( <TAB> full_data : torch . Tensor , <TAB> full_targets : torch . Tensor , <TAB> num_samples : int , <TAB> digits : Sequence , ) : <TAB> classes = { d : 0 for d in digits } <TAB> indexes = [ ] <TAB> for idx , target in enumerate ( full_targets ) : <TAB><TAB> label = target . item ( ) <TAB><TAB> if classes . get ( label , float ( "" inf "" ) ) > = num_samples : <TAB><TAB><TAB> continue <TAB><TAB> indexes . append ( idx ) <TAB><TAB> classes [ label ] + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> data = full_data [ indexes ] <TAB> targets = full_targets [ indexes ] <TAB> return data , targets",if all ( classes [ k ] >= num_samples for k in classes ) :,if not classes [ label ] :,71.48769315990963,92.31,False
1994,"def get_work_root ( self , flags ) : <TAB> _flags = flags . copy ( ) <TAB> _flags [ "" is_toplevel "" ] = True <TAB> target = self . _get_target ( _flags ) <TAB> if target : <TAB><TAB> _flags [ "" target "" ] = target . name <TAB><TAB> tool = self . get_tool ( _flags ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return target . name + "" - "" + tool <TAB><TAB> else : <TAB><TAB><TAB> raise SyntaxError ( <TAB><TAB><TAB><TAB> "" Failed to determine work root. Could not resolve tool for target  "" <TAB><TAB><TAB><TAB> + target . name <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise SyntaxError ( "" Failed to determine work root. Could not resolve target "" )",if tool :,if tool :,100.0,100.00,True
1995,"def run_command ( self , data ) : <TAB> """"""Run editor commands."""""" <TAB> parts = data . split ( ""   "" ) <TAB> cmd = parts [ 0 ] . lower ( ) <TAB> if cmd in self . operations . keys ( ) : <TAB><TAB> return self . run_operation ( cmd ) <TAB> args = ""   "" . join ( parts [ 1 : ] ) <TAB> self . logger . debug ( "" Looking for command  ' {0} ' "" . format ( cmd ) ) <TAB> if cmd in self . modules . modules . keys ( ) : <TAB><TAB> self . logger . debug ( "" Trying to run command  ' {0} ' "" . format ( cmd ) ) <TAB><TAB> self . get_editor ( ) . store_action_state ( cmd ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> else : <TAB><TAB> self . set_status ( "" Command  ' {0} '  not found. "" . format ( cmd ) ) <TAB><TAB> return False <TAB> return True","if not self . run_module ( cmd , args ) :","if args != ""none"" :",69.19632670276567,95.29,False
1996,"def get_main_chain_layers ( self ) : <TAB> """"""Return a list of layer IDs in the main chain."""""" <TAB> main_chain = self . get_main_chain ( ) <TAB> ret = [ ] <TAB> for u in main_chain : <TAB><TAB> for v , layer_id in self . adj_list [ u ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . append ( layer_id ) <TAB> return ret",if v in main_chain and u in main_chain :,if v == self . main_chain_size :,90.39984719187551,92.61,False
1997,"def hash ( self , context ) : <TAB> with context : <TAB><TAB> <MASK> <TAB><TAB><TAB> return IECore . MurmurHash ( ) <TAB><TAB> h = GafferDispatch . TaskNode . hash ( self , context ) <TAB><TAB> h . append ( self [ "" fileName "" ] . hash ( ) ) <TAB><TAB> h . append ( self [ "" in "" ] . hash ( ) ) <TAB><TAB> h . append ( self . __parameterHandler . hash ( ) ) <TAB><TAB> return h","if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :","if self [ ""is_hash"" ] :",82.86067813255906,80.86,False
1998,"def consume_buf ( ) : <TAB> ty = state [ "" ty "" ] - 1 <TAB> for i in xrange ( state [ "" buf "" ] . shape [ 1 ] / / N ) : <TAB><TAB> tx = x / / N + i <TAB><TAB> src = state [ "" buf "" ] [ : , i * N : ( i + 1 ) * N , : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> with self . tile_request ( tx , ty , readonly = False ) as dst : <TAB><TAB><TAB><TAB> mypaintlib . tile_convert_rgba8_to_rgba16 ( src , dst , self . EOTF ) <TAB> if state [ "" progress "" ] : <TAB><TAB> try : <TAB><TAB><TAB> state [ "" progress "" ] . completed ( ty - ty0 ) <TAB><TAB> except Exception : <TAB><TAB><TAB> logger . exception ( "" Progress.completed() failed "" ) <TAB><TAB><TAB> state [ "" progress "" ] = None","if src [ : , : , 3 ] . any ( ) :",if tx < N :,67.65234298059853,94.67,False
1999,"def check_permissions ( self , obj ) : <TAB> request = self . context . get ( "" request "" ) <TAB> for Perm in permissions : <TAB><TAB> perm = Perm ( ) <TAB><TAB> if not perm . has_permission ( request , self ) : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return True","if not perm . has_object_permission ( request , self , obj ) :","if not obj . has_permission ( request , self ) :",61.23889803143769,92.28,False
2000,"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB><TAB> lift_stmt [ - 1 ] . append ( op ) <TAB><TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB><TAB> if op . attr_key == "" storage_scope "" : <TAB><TAB><TAB> lift_stmt [ - 1 ] . append ( op ) <TAB><TAB><TAB> return op . body <TAB><TAB> <MASK> <TAB><TAB><TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB><TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB><TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" )","if op . attr_key == ""virtual_thread"" :","if isinstance ( op , tvm . tir . For ) :",71.35189531233986,94.40,False
2001,"def task_done ( self ) : <TAB> with self . _cond : <TAB><TAB> if not self . _unfinished_tasks . acquire ( False ) : <TAB><TAB><TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _cond . notify_all ( )",if self . _unfinished_tasks . _semlock . _is_zero ( ) :,if self . _unfinished_tasks . is_set ( ) :,67.29250032147843,92.38,False
2002,"def get_json ( self ) : <TAB> if not hasattr ( self , "" _json "" ) : <TAB><TAB> self . _json = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _json = json . loads ( self . request . body ) <TAB> return self . _json","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :","if self . request . method == ""GET"" :",62.60613172936304,77.65,False
2003,"def userfullname ( ) : <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> <MASK> <TAB><TAB> uid = os . getuid ( ) <TAB><TAB> entry = pwd_from_uid ( uid ) <TAB><TAB> if entry : <TAB><TAB><TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname",if not _userfullname :,if not _userfullname :,100.0,100.00,True
2004,"def test_scatter ( self ) : <TAB> for rank in range ( self . world_size ) : <TAB><TAB> tensor = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> tensor = [ torch . tensor ( i ) for i in range ( self . world_size ) ] <TAB><TAB> result = comm . get ( ) . scatter ( tensor , rank , size = ( ) ) <TAB><TAB> self . assertTrue ( torch . is_tensor ( result ) ) <TAB><TAB> self . assertEqual ( result . item ( ) , self . rank )",if self . rank == rank :,if self . rank == 0 :,81.45807109702639,98.20,False
2005,"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB><TAB> if pos in decompiler . targets : <TAB><TAB><TAB> decompiler . process_target ( pos ) <TAB><TAB> method = getattr ( decompiler , opname , None ) <TAB><TAB> if method is None : <TAB><TAB><TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB><TAB> decompiler . pos = pos <TAB><TAB> decompiler . next_pos = next_pos <TAB><TAB> x = method ( * arg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> decompiler . stack . append ( x )",if x is not None :,if x is not None :,100.0,100.00,True
2006,"def print_scenario_ran ( self , scenario ) : <TAB> if scenario . passed : <TAB><TAB> self . wrt ( "" OK "" ) <TAB> elif scenario . failed : <TAB><TAB> reason = self . scenarios_and_its_fails [ scenario ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . wrt ( "" FAILED "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . wrt ( "" ERROR "" ) <TAB> self . wrt ( "" \n "" )","if isinstance ( reason . exception , AssertionError ) :",if reason :,65.48550636191727,92.81,False
2007,"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB><TAB> if scan_argv ( self . argv , option ) is not None : <TAB><TAB><TAB> for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB> if option != other_option : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return option","if scan_argv ( self . argv , other_option ) is not None :",if other_option != option :,66.36371168998693,92.70,False
2008,"def print_po_snippet ( en_loc_old_lists , context ) : <TAB> for m , localized , old in zip ( * en_loc_old_lists ) : <TAB><TAB> if m == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> localized = old <TAB><TAB> print ( <TAB><TAB><TAB> "" #:  {file} : {line} \n "" <TAB><TAB><TAB> ' msgid  "" {context} {en_month} "" \n ' <TAB><TAB><TAB> ' msgstr  "" {localized_month} "" \n ' . format ( <TAB><TAB><TAB><TAB> context = context , <TAB><TAB><TAB><TAB> file = filename , <TAB><TAB><TAB><TAB> line = print_po_snippet . line , <TAB><TAB><TAB><TAB> en_month = m , <TAB><TAB><TAB><TAB> localized_month = localized , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> print_po_snippet . line + = 1",if m == localized :,if localized == m :,98.25012812787327,98.51,False
2009,"def set_status ( self , dict_new ) : <TAB> for i , value in dict_new . items ( ) : <TAB><TAB> self . dict_bili [ i ] = value <TAB><TAB> <MASK> <TAB><TAB><TAB> self . dict_bili [ "" pcheaders "" ] [ "" cookie "" ] = value <TAB><TAB><TAB> self . dict_bili [ "" appheaders "" ] [ "" cookie "" ] = value","if i == ""cookie"" :","if ""pcheaders"" in self . dict_bili [ ""pchead",61.79475041982779,88.51,False
2010,"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB><TAB> child = pathobj . child ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pathdict [ key ] = child <TAB><TAB><TAB> child . setContent ( value ) <TAB><TAB> elif isinstance ( value , dict ) : <TAB><TAB><TAB> child . createDirectory ( ) <TAB><TAB><TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict","if isinstance ( value , bytes ) :","if isinstance ( value , str ) :",98.81078951272626,98.53,False
2011,"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB><TAB> example = list ( example ) <TAB><TAB> if len_map is not None : <TAB><TAB><TAB> for key , max_len in len_map . items ( ) : <TAB><TAB><TAB><TAB> example_len = example [ key ] . shape <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB><TAB> yield tuple ( example )",if example_len > max_len :,if example_len > max_len :,100.0,100.00,True
2012,"def check ( self , * * kw ) : <TAB> if not kw : <TAB><TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB><TAB> if "" dir "" in kw : <TAB><TAB><TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw )","if ""file"" in kw :","if ""file"" in kw :",75.0,100.00,True
2013,"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> if parser . is_quoted ( ) : <TAB><TAB><TAB> parser . read_line ( line ) <TAB><TAB><TAB> continue <TAB><TAB> parser . read_line ( line ) <TAB><TAB> if not line . strip ( ) : # empty line <TAB><TAB><TAB> if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> return False <TAB> return False","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :","if line . startswith ( ""function"" ) :",96.25981568297868,93.92,False
2014,"def askCheckReadFile ( self , localFile , remoteFile ) : <TAB> if not kb . bruteMode : <TAB><TAB> message = "" do you want confirmation that the remote file  ' %s '   "" % remoteFile <TAB><TAB> message + = "" has been successfully downloaded from the back-end  "" <TAB><TAB> message + = "" DBMS file system? [Y/n]  "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _checkFileLength ( localFile , remoteFile , True ) <TAB> return None","if readInput ( message , default = ""Y"" , boolean = True ) :",if self . confirm ( message ) :,61.01032208081942,89.07,False
2015,"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB><TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB><TAB> if version is not None : # if failed to get version bail <TAB><TAB><TAB> major , minor , _ = version <TAB><TAB><TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB><TAB><TAB><TAB> if exe_data is not None : <TAB><TAB><TAB><TAB><TAB> exe , args = exe_data <TAB><TAB><TAB><TAB><TAB> return company , major , minor , arch , exe , args",if arch is not None :,if arch is not None :,100.0,100.00,True
2016,"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB><TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB><TAB> c = s [ pos ] <TAB><TAB> if c == "" { "" : <TAB><TAB><TAB> depth + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> depth - = 1 <TAB><TAB> if depth == 0 : <TAB><TAB><TAB> break <TAB><TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB><TAB> return pos <TAB> return None","elif c == ""}"" :","elif c == ""}"" :",100.0,100.00,True
2017,"def pred ( field , value , item ) : <TAB> for suffix , p in _BUILTIN_PREDS . iteritems ( ) : <TAB><TAB> if field . endswith ( suffix ) : <TAB><TAB><TAB> f = field [ : field . index ( suffix ) ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> return p ( getattr ( item , f ) , value ) <TAB> if not hasattr ( item , field ) or getattr ( item , field ) is None : <TAB><TAB> return False <TAB> if isinstance ( value , type ( lambda x : x ) ) : <TAB><TAB> return value ( getattr ( item , field ) ) <TAB> return getattr ( item , field ) == value","if not hasattr ( item , f ) or getattr ( item , f ) is None :","if not hasattr ( item , f ) :",68.86227268239328,94.61,False
2018,"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB><TAB> if isinstance ( m , nn . ConvTranspose2d ) : <TAB><TAB><TAB> normal_init ( m , std = 0.001 ) <TAB><TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> normal_init ( m , std = 0.001 , bias = 0 )","if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Linear ) :",73.70957851102936,98.49,False
2019,"def test_byteswap ( self ) : <TAB> if self . typecode == "" u "" : <TAB><TAB> example = "" \U00100100 "" <TAB> else : <TAB><TAB> example = self . example <TAB> a = array . array ( self . typecode , example ) <TAB> self . assertRaises ( TypeError , a . byteswap , 42 ) <TAB> if a . itemsize in ( 1 , 2 , 4 , 8 ) : <TAB><TAB> b = array . array ( self . typecode , example ) <TAB><TAB> b . byteswap ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( a , b ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertNotEqual ( a , b ) <TAB><TAB> b . byteswap ( ) <TAB><TAB> self . assertEqual ( a , b )",if a . itemsize == 1 :,if a . itemsize == 1 :,100.0,100.00,True
2020,"def _remove_blocks_from_variables ( variables ) : <TAB> new_variables = [ ] <TAB> for name , variable in variables : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_variables . extend ( variable . locals ) <TAB><TAB><TAB> new_variables . append ( ( name , variable . result ) ) <TAB><TAB> else : <TAB><TAB><TAB> new_variables . append ( ( name , variable ) ) <TAB> return new_variables",if variable . is_block ( ) :,"if isinstance ( variable , BlockVariable ) :",92.64571035472319,94.31,False
2021,def scope ( self ) : <TAB> <MASK> <TAB><TAB> self . lazy_init_lock_ . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . scope_ = Scope ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . scope_,if self . scope_ is None :,if self . scope_ is None :,100.0,100.00,True
2022,"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( ) # Discard attribute list from reader. <TAB> attrs = { } <TAB> d = AttributeList . match . groupdict ( ) <TAB> for k , v in d . items ( ) : <TAB><TAB> if v is not None : <TAB><TAB><TAB> if k == "" attrlist "" : <TAB><TAB><TAB><TAB> v = subs_attrs ( v ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> parse_attributes ( v , attrs ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> AttributeList . attrs [ k ] = v <TAB> AttributeList . subs ( attrs ) <TAB> AttributeList . attrs . update ( attrs )",if v :,"if isinstance ( v , dict ) :",97.94657137474644,96.47,False
2023,"def parse ( self , response ) : <TAB> try : <TAB><TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB><TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB><TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB><TAB> return <TAB> for item in content [ "" data "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB><TAB> elif "" hoverURL "" in item : <TAB><TAB><TAB> img_url = item [ "" hoverURL "" ] <TAB><TAB> else : <TAB><TAB><TAB> continue <TAB><TAB> yield dict ( file_url = img_url )","if ""objURL"" in item :","if ""objURL"" in item :",100.0,100.00,True
2024,"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == "" MOV "" : <TAB><TAB> if instr . mnemonic . startswith ( "" lsr "" ) : <TAB><TAB><TAB> return "" LSR "" <TAB><TAB> elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB><TAB><TAB> return "" LSL "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" ASR "" <TAB> return OP_NAME_MAP . get ( name , name )","elif instr . mnemonic . startswith ( ""asr"" ) :","elif instr . mnemonic . startswith ( ""asr"" ) :",100.0,100.00,True
2025,"def _clean_regions ( items , region ) : <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB><TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( target , six . string_types ) and os . path . isfile ( target ) : <TAB><TAB><TAB><TAB> target = _load_regions ( target ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> target = [ target ] <TAB><TAB><TAB> return target",if target :,if target :,100.0,100.00,True
2026,def reader_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB><TAB> self . active_readers - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . active_writers + = 1 <TAB><TAB><TAB> self . waiting_writers - = 1 <TAB><TAB><TAB> self . can_write . release ( ) <TAB> finally : <TAB><TAB> self . mutex . release ( ),if self . active_readers == 0 and self . waiting_writers != 0 :,if self . active_readers == 0 and self . waiting_readers == 0 :,72.49859101608031,97.31,False
2027,"def _bpe_to_words ( sentence , delimiter = "" @@ "" ) : <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [ ] <TAB> word = "" "" <TAB> delimiter_len = len ( delimiter ) <TAB> for subwords in sentence : <TAB><TAB> <MASK> <TAB><TAB><TAB> word + = subwords [ : - delimiter_len ] <TAB><TAB> else : <TAB><TAB><TAB> word + = subwords <TAB><TAB><TAB> words . append ( word ) <TAB><TAB><TAB> word = "" "" <TAB> return words",if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,if len ( subwords ) > delimiter_len :,83.2498974089023,90.82,False
2028,"def _make_var_names ( exog ) : <TAB> if hasattr ( exog , "" name "" ) : <TAB><TAB> var_names = exog . name <TAB> elif hasattr ( exog , "" columns "" ) : <TAB><TAB> var_names = exog . columns <TAB> else : <TAB><TAB> raise ValueError ( "" exog is not a Series or DataFrame or is unnamed. "" ) <TAB> try : <TAB><TAB> var_names = ""   "" . join ( var_names ) <TAB> except TypeError : # cannot have names that are numbers, pandas default <TAB><TAB> from statsmodels . base . data import _make_exog_names <TAB><TAB> <MASK> <TAB><TAB><TAB> var_names = "" x1 "" <TAB><TAB> else : <TAB><TAB><TAB> var_names = ""   "" . join ( _make_exog_names ( exog ) ) <TAB> return var_names",if exog . ndim == 1 :,if exog . dtype == np . ndarray :,97.96846405269157,96.97,False
2029,"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> for extension in self . extensions : <TAB><TAB><TAB><TAB> self [ extension ] = self . type <TAB><TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB><TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB><TAB> pattern = attrs [ "" pattern "" ] <TAB><TAB> if pattern . startswith ( "" *. "" ) : <TAB><TAB><TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) )",if self . type :,if self . extensions :,98.82942565771128,98.54,False
2030,"def nodes ( self , id = None , name = None ) : <TAB> for node_dict in self . node_ls ( id = id , name = name ) : <TAB><TAB> node_id = node_dict [ "" ID "" ] <TAB><TAB> node = DockerNode ( self , node_id , inspect = node_dict ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> yield node",if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,if not node . is_valid ( ) :,58.877701799283166,83.61,False
2031,"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB><TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB> if e . value is None : <TAB><TAB><TAB><TAB><TAB> e . value = [ ] <TAB><TAB><TAB><TAB> elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB> e . value = e . value . split ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> e . value = 0 <TAB> return self",if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,elif e . argcount == 0 :,71.62667128068681,93.34,False
2032,"def vi_search ( self , rng ) : <TAB> for i in rng : <TAB><TAB> line_history = self . _history . history [ i ] <TAB><TAB> pos = line_history . get_line_text ( ) . find ( self . _vi_search_text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _history . history_cursor = i <TAB><TAB><TAB> self . l_buffer . line_buffer = list ( line_history . line_buffer ) <TAB><TAB><TAB> self . l_buffer . point = pos <TAB><TAB><TAB> self . vi_undo_restart ( ) <TAB><TAB><TAB> return True <TAB> self . _bell ( ) <TAB> return False",if pos >= 0 :,if pos != - 1 :,94.63503990501141,97.21,False
2033,"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB><TAB> <MASK> <TAB><TAB><TAB> if type ( test . value ) in self . _const_types : <TAB><TAB><TAB><TAB> if not test . value : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB> self . visit ( test , scope ) <TAB><TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB><TAB> self . visit ( node . else_ , scope )","if isinstance ( test , ast . Const ) :","if isinstance ( test , ast . If ) :",73.56352373096794,98.31,False
2034,"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB><TAB> squid_host = self . squid_hosts [ nickname ] <TAB><TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fulldata = fulldata . splitlines ( ) <TAB><TAB><TAB> for data in fulldata : <TAB><TAB><TAB><TAB> matches = self . stat_pattern . match ( data ) <TAB><TAB><TAB><TAB> if matches : <TAB><TAB><TAB><TAB><TAB> self . publish_counter ( <TAB><TAB><TAB><TAB><TAB><TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB><TAB><TAB><TAB><TAB> )",if fulldata is not None :,if self . verbose :,95.91371141606155,97.64,False
2035,"def convert ( x , base , exponents ) : <TAB> out = [ ] <TAB> for e in exponents : <TAB><TAB> d = int ( x / ( base * * e ) ) <TAB><TAB> x - = d * ( base * * e ) <TAB><TAB> out . append ( digits [ d ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return out",if x == 0 and e < 0 :,if d >= base :,63.132475764212984,91.19,False
2036,"def print_doc ( manager , options ) : <TAB> plugin_name = options . doc <TAB> plugin = plugins . get ( plugin_name , None ) <TAB> if plugin : <TAB><TAB> <MASK> <TAB><TAB><TAB> console ( "" Plugin  %s  does not have documentation "" % plugin_name ) <TAB><TAB> else : <TAB><TAB><TAB> console ( "" "" ) <TAB><TAB><TAB> console ( trim ( plugin . instance . __doc__ ) ) <TAB><TAB><TAB> console ( "" "" ) <TAB> else : <TAB><TAB> console ( "" Could not find plugin  %s "" % plugin_name )",if not plugin . instance . __doc__ :,if not plugin . instance . __doc__ :,100.0,100.00,True
2037,"def _set_attrs ( self , attrs ) : <TAB> for attr in self . ATTRS : <TAB><TAB> if attr in attrs : <TAB><TAB><TAB> setattr ( self , attr , attrs [ attr ] ) <TAB><TAB><TAB> del attrs [ attr ] <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> setattr ( self , attr , NO_DEFAULT ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> setattr ( self , attr , None ) <TAB> if attrs : <TAB><TAB> attrs = sorted ( attrs . keys ( ) ) <TAB><TAB> raise OptionError ( "" invalid keyword arguments:  %s "" % "" ,  "" . join ( attrs ) , self )","if attr == ""default"" :","if attr == ""default"" :",100.0,100.00,True
2038,"def _get_set_scope ( <TAB> ir_set : irast . Set , scope_tree : irast . ScopeTreeNode ) - > irast . ScopeTreeNode : <TAB> if ir_set . path_scope_id : <TAB><TAB> new_scope = scope_tree . root . find_by_unique_id ( ir_set . path_scope_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise errors . InternalServerError ( <TAB><TAB><TAB><TAB> f "" dangling scope pointer to node with uid "" <TAB><TAB><TAB><TAB> f "" : { ir_set . path_scope_id }  in  { ir_set !r} "" <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> new_scope = scope_tree <TAB> return new_scope",if new_scope is None :,if new_scope is None :,100.0,100.00,True
2039,"def test_leave_one_out ( self ) : <TAB> correct = 0 <TAB> k = 3 <TAB> model = kNN . train ( xs , ys , k ) <TAB> predictions = [ 1 , 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 ] <TAB> for i in range ( len ( predictions ) ) : <TAB><TAB> model = kNN . train ( xs [ : i ] + xs [ i + 1 : ] , ys [ : i ] + ys [ i + 1 : ] , k ) <TAB><TAB> prediction = kNN . classify ( model , xs [ i ] ) <TAB><TAB> self . assertEqual ( prediction , predictions [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> correct + = 1 <TAB> self . assertEqual ( correct , 13 )",if prediction == ys [ i ] :,if i + 1 < len ( predictions ) :,68.25389256065313,95.58,False
2040,"def import_files ( self , files ) : <TAB> """"""Import a list of MORE (.csv) files."""""" <TAB> c = self . c <TAB> if files : <TAB><TAB> changed = False <TAB><TAB> self . tab_width = c . getTabWidth ( c . p ) <TAB><TAB> for fileName in files : <TAB><TAB><TAB> g . setGlobalOpenDir ( fileName ) <TAB><TAB><TAB> p = self . import_file ( fileName ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> p . contract ( ) <TAB><TAB><TAB><TAB> p . setDirty ( ) <TAB><TAB><TAB><TAB> c . setChanged ( True ) <TAB><TAB><TAB><TAB> changed = True <TAB><TAB> if changed : <TAB><TAB><TAB> c . redraw ( p )",if p :,if p :,100.0,100.00,True
2041,"def getPageTemplate ( payload , place ) : <TAB> retVal = ( kb . originalPage , kb . errorIsNone ) <TAB> if payload and place : <TAB><TAB> <MASK> <TAB><TAB><TAB> page , _ , _ = Request . queryPage ( payload , place , content = True , raise404 = False ) <TAB><TAB><TAB> kb . pageTemplates [ ( payload , place ) ] = ( page , kb . lastParserStatus is None ) <TAB><TAB> retVal = kb . pageTemplates [ ( payload , place ) ] <TAB> return retVal","if ( payload , place ) not in kb . pageTemplates :","if ( payload , place ) not in kb . pageTemplates :",100.0,100.00,True
2042,"def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB><TAB> if isinstance ( constraint_data , LinearCanonicalRepn ) : <TAB><TAB><TAB> if constraint_data . variables is None : <TAB><TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False",if constraint_data . body . polynomial_degree ( ) == 0 :,"if constraint_data . variables . issubset ( [ ""true"" , ""false"" ]",60.255080939412906,88.45,False
2043,"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB><TAB> if self . _return_feature ( f ) and hasattr ( f , name ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB><TAB><TAB> feat = f <TAB> if feat is None : <TAB><TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name )",if feat is not None :,if not self . _is_unique ( f ) :,79.77170614263535,92.37,False
2044,"def hideEvent ( self , event ) : <TAB> """"""Reimplement Qt method"""""" <TAB> if not self . light : <TAB><TAB> for plugin in self . widgetlist : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> plugin . visibility_changed ( True ) <TAB> QMainWindow . hideEvent ( self , event )",if plugin . isAncestorOf ( self . last_focused_widget ) :,"if isinstance ( plugin , Qt . QWidgetWidget ) :",88.90632653439904,87.48,False
2045,"def move_stdout_to_stderr ( self ) : <TAB> to_remove = [ ] <TAB> to_add = [ ] <TAB> for consumer_level , consumer in self . consumers : <TAB><TAB> <MASK> <TAB><TAB><TAB> to_remove . append ( ( consumer_level , consumer ) ) <TAB><TAB><TAB> to_add . append ( ( consumer_level , sys . stderr ) ) <TAB> for item in to_remove : <TAB><TAB> self . consumers . remove ( item ) <TAB> self . consumers . extend ( to_add )",if consumer == sys . stdout :,if consumer . is_stdout :,95.1033722184938,96.28,False
2046,"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB><TAB> self . context . log . info ( <TAB><TAB><TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB><TAB> ) <TAB><TAB> subject = self . derived_by_original . get ( <TAB><TAB><TAB> exported_python_target , exported_python_target <TAB><TAB> ) <TAB><TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB><TAB> created [ exported_python_target ] = setup_dir <TAB><TAB> <MASK> <TAB><TAB><TAB> for dep in dependencies : <TAB><TAB><TAB><TAB> if is_exported_python_target ( dep ) : <TAB><TAB><TAB><TAB><TAB> create ( dep )",if self . _recursive :,if dependencies :,89.65465280236185,97.59,False
2047,"def __add__ ( self , other ) : <TAB> other = ArithmeticExpression . try_unpack_const ( other ) <TAB> if not self . symbolic and type ( other ) is int : <TAB><TAB> return SpOffset ( self . _bits , self . _to_signed ( self . offset + other ) ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return SpOffset ( self . _bits , self . offset + other ) <TAB><TAB> else : <TAB><TAB><TAB> return SpOffset ( <TAB><TAB><TAB><TAB> self . _bits , <TAB><TAB><TAB><TAB> ArithmeticExpression ( <TAB><TAB><TAB><TAB><TAB> ArithmeticExpression . Add , <TAB><TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB><TAB> self . offset , <TAB><TAB><TAB><TAB><TAB><TAB> other , <TAB><TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB> )",if self . symbolic :,if self . symbolic :,100.0,100.00,True
2048,"def check_connection ( conn ) : <TAB> tables = [ <TAB><TAB> r [ 0 ] <TAB><TAB> for r in conn . execute ( <TAB><TAB><TAB> "" select name from sqlite_master where type= ' table ' "" <TAB><TAB> ) . fetchall ( ) <TAB> ] <TAB> for table in tables : <TAB><TAB> try : <TAB><TAB><TAB> conn . execute ( <TAB><TAB><TAB><TAB> f "" PRAGMA table_info( { escape_sqlite ( table ) } ); "" , <TAB><TAB><TAB> ) <TAB><TAB> except sqlite3 . OperationalError as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise SpatialiteConnectionProblem ( e ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise ConnectionProblem ( e )","if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :","if ""sqlite3 connection problem"" in str ( e ) :",92.64216520184503,93.06,False
2049,"def _get_github_client ( self ) - > "" Github "" : <TAB> from github import Github <TAB> if self . access_token_secret is not None : <TAB><TAB> # If access token secret specified, load it <TAB><TAB> access_token = Secret ( self . access_token_secret ) . get ( ) <TAB> else : <TAB><TAB> # Otherwise, fallback to loading from local secret or environment variable <TAB><TAB> access_token = prefect . context . get ( "" secrets "" , { } ) . get ( "" GITHUB_ACCESS_TOKEN "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> access_token = os . getenv ( "" GITHUB_ACCESS_TOKEN "" ) <TAB> return Github ( access_token )",if access_token is None :,if access_token is None :,100.0,100.00,True
2050,"def make_tab ( lists ) : <TAB> if hasattr ( lists , "" tolist "" ) : <TAB><TAB> lists = lists . tolist ( ) <TAB> ut = [ ] <TAB> for rad in lists : <TAB><TAB> <MASK> <TAB><TAB><TAB> ut . append ( "" \t "" . join ( [ "" %s "" % x for x in rad ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> ut . append ( "" %s "" % rad ) <TAB> return "" \n "" . join ( ut )","if type ( rad ) in [ list , tuple ] :","if isinstance ( rad , ( list , tuple ) ) :",92.55484881286611,93.54,False
2051,"def _ensure_ffi_initialized ( cls ) : <TAB> with cls . _init_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . lib = build_conditional_library ( lib , CONDITIONAL_NAMES ) <TAB><TAB><TAB> cls . _lib_loaded = True <TAB><TAB><TAB> # initialize the SSL library <TAB><TAB><TAB> cls . lib . SSL_library_init ( ) <TAB><TAB><TAB> # adds all ciphers/digests for EVP <TAB><TAB><TAB> cls . lib . OpenSSL_add_all_algorithms ( ) <TAB><TAB><TAB> # loads error strings for libcrypto and libssl functions <TAB><TAB><TAB> cls . lib . SSL_load_error_strings ( ) <TAB><TAB><TAB> cls . _register_osrandom_engine ( )",if not cls . _lib_loaded :,if not cls . lib :,96.19584803609281,97.49,False
2052,def writer_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB><TAB> self . active_writers - = 1 <TAB><TAB> if self . waiting_writers != 0 : <TAB><TAB><TAB> self . active_writers + = 1 <TAB><TAB><TAB> self . waiting_writers - = 1 <TAB><TAB><TAB> self . can_write . release ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> t = self . waiting_readers <TAB><TAB><TAB> self . waiting_readers = 0 <TAB><TAB><TAB> self . active_readers + = t <TAB><TAB><TAB> while t > 0 : <TAB><TAB><TAB><TAB> self . can_read . release ( ) <TAB><TAB><TAB><TAB> t - = 1 <TAB> finally : <TAB><TAB> self . mutex . release ( ),elif self . waiting_readers != 0 :,if self . waiting_readers != 0 :,73.67575694309639,98.94,False
2053,"def _spans ( self , operands ) : <TAB> spans = { } <TAB> k = 0 <TAB> j = 0 <TAB> for mode in ( self . FLOAT , self . MPMATH ) : <TAB><TAB> for i , operand in enumerate ( operands [ k : ] ) : <TAB><TAB><TAB> if operand [ 0 ] > mode : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> j = i + k + 1 <TAB><TAB> <MASK> # only init state? then ignore. <TAB><TAB><TAB> j = 0 <TAB><TAB> spans [ mode ] = slice ( k , j ) <TAB><TAB> k = j <TAB> spans [ self . SYMBOLIC ] = slice ( k , len ( operands ) ) <TAB> return spans",if k == 0 and j == 1 :,if j == len ( operands ) :,93.08678223131723,95.39,False
2054,"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB><TAB> # Only include the text in case of error. <TAB><TAB> <MASK> <TAB><TAB><TAB> status = location . Status ( response . status_code , response . text ) <TAB><TAB> else : <TAB><TAB><TAB> status = location . Status ( response . status_code ) <TAB> else : <TAB><TAB> status = location . Status ( 500 , message ) <TAB> if response is None or not response . ok : <TAB><TAB> if completion_routine : <TAB><TAB><TAB> return completion_routine ( status ) <TAB><TAB> raise IOError ( response . text ) <TAB> else : <TAB><TAB> if completion_routine : <TAB><TAB><TAB> completion_routine ( status ) <TAB> return location . Status ( 200 , response . content )",if not response . ok :,if response . text :,98.10262222767349,97.90,False
2055,"def readinto ( self , buf ) : <TAB> if self . current_frame : <TAB><TAB> n = self . current_frame . readinto ( buf ) <TAB><TAB> if n == 0 and len ( buf ) != 0 : <TAB><TAB><TAB> self . current_frame = None <TAB><TAB><TAB> n = len ( buf ) <TAB><TAB><TAB> buf [ : ] = self . file_read ( n ) <TAB><TAB><TAB> return n <TAB><TAB> <MASK> <TAB><TAB><TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB><TAB> return n <TAB> else : <TAB><TAB> n = len ( buf ) <TAB><TAB> buf [ : ] = self . file_read ( n ) <TAB><TAB> return n",if n < len ( buf ) :,elif n == 0 :,79.27001446693451,95.98,False
2056,"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB><TAB> value = mydict [ name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return value <TAB><TAB> myid = id ( mydict ) <TAB><TAB> assert myid not in visited <TAB><TAB> visited . add ( myid ) <TAB><TAB> mydict = mydict . Parent <TAB><TAB> if mydict is None : <TAB><TAB><TAB> return",if value is not None :,if value is not None :,100.0,100.00,True
2057,"def _handle_Mul ( self , expr ) : <TAB> arg0 , arg1 = expr . args <TAB> expr_0 = self . _expr ( arg0 ) <TAB> if expr_0 is None : <TAB><TAB> return None <TAB> expr_1 = self . _expr ( arg1 ) <TAB> if expr_1 is None : <TAB><TAB> return None <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> # self.tyenv is not used <TAB><TAB><TAB> mask = ( 1 << expr . result_size ( self . tyenv ) ) - 1 <TAB><TAB><TAB> return ( expr_0 * expr_1 ) & mask <TAB><TAB> else : <TAB><TAB><TAB> return expr_0 * expr_1 <TAB> except TypeError as e : <TAB><TAB> self . l . warning ( e ) <TAB><TAB> return None","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",if expr_0 == expr_1 :,86.8471725832054,93.30,False
2058,"def end_request ( self , request_id ) : <TAB> """"""Removes the information associated with given request_id."""""" <TAB> with self . _lock : <TAB><TAB> del self . _request_wsgi_environ [ request_id ] <TAB><TAB> del self . _request_id_to_server_configuration [ request_id ] <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _request_id_to_instance [ request_id ]",if request_id in self . _request_id_to_instance :,if request_id in self . _request_id_to_instance :,75.0,100.00,True
2059,def generate ( ) : <TAB> <MASK> <TAB><TAB> decoder = zlib . decompressobj ( 16 + zlib . MAX_WBITS ) <TAB> while True : <TAB><TAB> chunk = self . raw . read ( chunk_size ) <TAB><TAB> if not chunk : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> chunk = decoder . decompress ( chunk ) <TAB><TAB> yield chunk,if self . _gzipped :,if chunk_size :,67.00496451384103,90.69,False
2060,"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB><TAB> name = venv . path . name <TAB><TAB> <MASK> <TAB><TAB><TAB> name = str ( venv . path ) <TAB><TAB> if venv == current_env : <TAB><TAB><TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB><TAB><TAB> continue <TAB><TAB> self . line ( name )","if self . option ( ""full-path"" ) :",if name is None :,71.58037555167054,94.23,False
2061,"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB><TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB><TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB><TAB> for aggr in aggrs : <TAB><TAB><TAB> for c in cols : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> c . aggregators = [ ] <TAB><TAB><TAB><TAB> if aggr and aggr not in c . aggregators : <TAB><TAB><TAB><TAB><TAB> c . aggregators + = [ aggr ]","if not hasattr ( c , ""aggregators"" ) :","if not hasattr ( c , ""aggregators"" ) :",100.0,100.00,True
2062,"def on_pre_output_coercion ( <TAB> directive_args : Dict [ str , Any ] , <TAB> next_directive : Callable , <TAB> value : Any , <TAB> ctx : Optional [ Any ] , <TAB> info : "" ResolveInfo "" , ) : <TAB> value = await next_directive ( value , ctx , info ) <TAB> if value is None : <TAB><TAB> return value <TAB> try : <TAB><TAB> py_enum = _ENUM_MAP [ directive_args [ "" name "" ] ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ None if item is None else py_enum ( item ) . name for item in value ] <TAB><TAB> return py_enum ( value ) . name <TAB> except Exception : <TAB><TAB> pass <TAB> return value","if isinstance ( value , list ) :","if isinstance ( value , ( list , tuple ) ) :",90.03031446190495,96.88,False
2063,def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB><TAB> <MASK> <TAB><TAB><TAB> for word in __cut ( blk ) : <TAB><TAB><TAB><TAB> if word not in Force_Split_Words : <TAB><TAB><TAB><TAB><TAB> yield word <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> for c in word : <TAB><TAB><TAB><TAB><TAB><TAB> yield c <TAB><TAB> else : <TAB><TAB><TAB> tmp = re_skip . split ( blk ) <TAB><TAB><TAB> for x in tmp : <TAB><TAB><TAB><TAB> if x : <TAB><TAB><TAB><TAB><TAB> yield x,if re_han . match ( blk ) :,if __cut :,94.9636057928764,96.06,False
2064,"def refresh_archive_action ( self ) : <TAB> archive_name = self . selected_archive_name ( ) <TAB> if archive_name is not None : <TAB><TAB> params = BorgInfoArchiveThread . prepare ( self . profile ( ) , archive_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> thread = BorgInfoArchiveThread ( params [ "" cmd "" ] , params , parent = self . app ) <TAB><TAB><TAB> thread . updated . connect ( self . _set_status ) <TAB><TAB><TAB> thread . result . connect ( self . refresh_archive_result ) <TAB><TAB><TAB> self . _toggle_all_buttons ( False ) <TAB><TAB><TAB> thread . start ( )","if params [ ""ok"" ] :",if params :,84.06114216500421,96.34,False
2065,"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB><TAB> if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB> if not name [ 0 ] . isupper ( ) : <TAB><TAB><TAB><TAB> if not name . startswith ( "" wait_until "" ) : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> resource_methods [ name ] = member <TAB> return resource_methods",if is_resource_action ( member ) :,if inspect . isclass ( member ) :,95.4859975805116,96.23,False
2066,"def _get_compressor ( compress_type , compresslevel = None ) : <TAB> if compress_type == ZIP_DEFLATED : <TAB><TAB> <MASK> <TAB><TAB><TAB> return zlib . compressobj ( compresslevel , zlib . DEFLATED , - 15 ) <TAB><TAB> return zlib . compressobj ( zlib . Z_DEFAULT_COMPRESSION , zlib . DEFLATED , - 15 ) <TAB> elif compress_type == ZIP_BZIP2 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return bz2 . BZ2Compressor ( compresslevel ) <TAB><TAB> return bz2 . BZ2Compressor ( ) <TAB> # compresslevel is ignored for ZIP_LZMA <TAB> elif compress_type == ZIP_LZMA : <TAB><TAB> return LZMACompressor ( ) <TAB> else : <TAB><TAB> return None",if compresslevel is not None :,if compresslevel is not None :,100.0,100.00,True
2067,"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [ ] <TAB> properties = [ ] <TAB> num_points = None <TAB> while b "" end_header "" not in line and line != b "" "" : <TAB><TAB> line = plyfile . readline ( ) <TAB><TAB> if b "" element "" in line : <TAB><TAB><TAB> line = line . split ( ) <TAB><TAB><TAB> num_points = int ( line [ 2 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line = line . split ( ) <TAB><TAB><TAB> properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB> return num_points , properties","elif b""property"" in line :","elif b""end_header"" in line :",73.96076013483109,97.70,False
2068,"def download_release_artifacts ( self , version ) : <TAB> try : <TAB><TAB> os . mkdir ( self . artifacts_dir ) <TAB> except FileExistsError : <TAB><TAB> pass <TAB> for job_name in self . build_ids : <TAB><TAB> build_number = self . build_ids . get ( job_name ) <TAB><TAB> build_status = self . _get_build_status ( job_name , build_number ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _download_job_artifact ( job_name , build_number , version ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" Build for  {}  is not fininished "" . format ( job_name ) ) <TAB><TAB><TAB> print ( "" \t Run  ' build '  action to check status of  {} "" . format ( job_name ) )","if build_status == ""built"" :","if build_status == "" fininished"" :",98.69242925971075,98.87,False
2069,"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> attrvalue = getattr ( self , attrname , None ) <TAB><TAB> if attrvalue == 0 : <TAB><TAB><TAB> continue <TAB><TAB> if attrname == "" salt_version "" : <TAB><TAB><TAB> attrname = "" version "" <TAB><TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB> elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass","if attrname . startswith ( ""__"" ) :","if not hasattr ( self , attrname ) :",94.49229854653916,96.31,False
2070,"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB><TAB> name = heur [ "" name "" ] <TAB><TAB> if name in excluded : <TAB><TAB><TAB> continue <TAB><TAB> sql = heur [ "" sql "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB><TAB><TAB> print ( sql ) <TAB><TAB><TAB> assert sql . find ( name ) != - 1 <TAB><TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs )",if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,if not sql :,63.337939931207046,90.97,False
2071,def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield child . nodeValue <TAB><TAB> if child . nodeType == child . ELEMENT_NODE : <TAB><TAB><TAB> for item in gettext ( child ) : <TAB><TAB><TAB><TAB> yield item,if child . nodeType == child . TEXT_NODE :,if child . nodeType == child . TEXT_NODE :,75.0,100.00,True
2072,"def update ( self ) : <TAB> """"""Update properties over dbus."""""" <TAB> self . _check_dbus ( ) <TAB> _LOGGER . info ( "" Updating service information "" ) <TAB> self . _services . clear ( ) <TAB> try : <TAB><TAB> systemd_units = await self . sys_dbus . systemd . list_units ( ) <TAB><TAB> for service_data in systemd_units [ 0 ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . _services . add ( ServiceInfo . read_from ( service_data ) ) <TAB> except ( HassioError , IndexError ) : <TAB><TAB> _LOGGER . warning ( "" Can ' t update host service information! "" )","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :","if service_data == ""host"" :",63.007367475744424,87.71,False
2073,"def filtercomments ( source ) : <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB><TAB> <MASK> <TAB><TAB><TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB><TAB> elif re . search ( r "" ^ \ s* \ / \ / "" , source ) : <TAB><TAB><TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB><TAB> else : <TAB><TAB><TAB> comment = None <TAB><TAB> if comment : <TAB><TAB><TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB><TAB><TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source","if re . search ( r""^\s*\/\*"" , source ) :","if re . search ( r""^\s*/"" , source ) . group ( 0",76.27021840542915,96.99,False
2074,"def _getSourceStamp_sync ( self , ssid ) : <TAB> if ssid in self . sourcestamps : <TAB><TAB> ssdict = self . sourcestamps [ ssid ] . copy ( ) <TAB><TAB> ssdict [ "" ssid "" ] = ssid <TAB><TAB> patchid = ssdict [ "" patchid "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> ssdict . update ( self . patches [ patchid ] ) <TAB><TAB><TAB> ssdict [ "" patchid "" ] = patchid <TAB><TAB> else : <TAB><TAB><TAB> ssdict [ "" patch_body "" ] = None <TAB><TAB><TAB> ssdict [ "" patch_level "" ] = None <TAB><TAB><TAB> ssdict [ "" patch_subdir "" ] = None <TAB><TAB><TAB> ssdict [ "" patch_author "" ] = None <TAB><TAB><TAB> ssdict [ "" patch_comment "" ] = None <TAB><TAB> return ssdict <TAB> else : <TAB><TAB> return None",if patchid :,if patchid in self . patches :,87.77005282095584,97.70,False
2075,"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB><TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB><TAB> if self . defaultValue is not self . __optionalNotMatched : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB><TAB><TAB><TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tokens = [ self . defaultValue ] <TAB><TAB> else : <TAB><TAB><TAB> tokens = [ ] <TAB> return loc , tokens",if self . expr . resultsName :,if self . expr . resultsName :,100.0,100.00,True
2076,"def _find_exceptions ( ) : <TAB> for _name , obj in iteritems ( globals ( ) ) : <TAB><TAB> try : <TAB><TAB><TAB> is_http_exception = issubclass ( obj , HTTPException ) <TAB><TAB> except TypeError : <TAB><TAB><TAB> is_http_exception = False <TAB><TAB> if not is_http_exception or obj . code is None : <TAB><TAB><TAB> continue <TAB><TAB> __all__ . append ( obj . __name__ ) <TAB><TAB> old_obj = default_exceptions . get ( obj . code , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> default_exceptions [ obj . code ] = obj","if old_obj is not None and issubclass ( obj , old_obj ) :",if old_obj is not None and obj . code not in old_obj :,77.17229553548086,96.10,False
2077,"def generator ( self , data ) : <TAB> for ( proc_as , key_buf_ptr ) in data : <TAB><TAB> key_buf = proc_as . read ( key_buf_ptr , 24 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> key = "" "" . join ( "" %02X "" % ord ( k ) for k in key_buf ) <TAB><TAB> yield ( <TAB><TAB><TAB> 0 , <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> str ( key ) , <TAB><TAB><TAB> ] , <TAB><TAB> )",if not key_buf :,if not key_buf :,100.0,100.00,True
2078,"def calculateEnableMargins ( self ) : <TAB> self . cnc . resetEnableMargins ( ) <TAB> for block in self . blocks : <TAB><TAB> <MASK> <TAB><TAB><TAB> CNC . vars [ "" xmin "" ] = min ( CNC . vars [ "" xmin "" ] , block . xmin ) <TAB><TAB><TAB> CNC . vars [ "" ymin "" ] = min ( CNC . vars [ "" ymin "" ] , block . ymin ) <TAB><TAB><TAB> CNC . vars [ "" zmin "" ] = min ( CNC . vars [ "" zmin "" ] , block . zmin ) <TAB><TAB><TAB> CNC . vars [ "" xmax "" ] = max ( CNC . vars [ "" xmax "" ] , block . xmax ) <TAB><TAB><TAB> CNC . vars [ "" ymax "" ] = max ( CNC . vars [ "" ymax "" ] , block . ymax ) <TAB><TAB><TAB> CNC . vars [ "" zmax "" ] = max ( CNC . vars [ "" zmax "" ] , block . zmax )",if block . enable :,if block . xmin :,98.92392624239982,98.93,False
2079,"def __init__ ( self , client , job_id , callback = None ) : <TAB> self . client = client <TAB> self . job_id = job_id <TAB> # If a job event has been received already then we must set an Event <TAB> # to wait for this job to finish. <TAB> # Otherwise we create a new stub for the job with the Event for when <TAB> # the job event arrives to use existing event. <TAB> with client . _jobs_lock : <TAB><TAB> job = client . _jobs . get ( job_id ) <TAB><TAB> self . event = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . event = job . get ( "" __ready "" ) <TAB><TAB> if self . event is None : <TAB><TAB><TAB> self . event = job [ "" __ready "" ] = Event ( ) <TAB><TAB> job [ "" __callback "" ] = callback",if job :,if job :,100.0,100.00,True
2080,"def asset ( * paths ) : <TAB> for path in paths : <TAB><TAB> fspath = www_root + "" /assets/ "" + path <TAB><TAB> etag = "" "" <TAB><TAB> try : <TAB><TAB><TAB> if env . cache_static : <TAB><TAB><TAB><TAB> etag = asset_etag ( fspath ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . stat ( fspath ) <TAB><TAB> except FileNotFoundError as e : <TAB><TAB><TAB> if path == paths [ - 1 ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> continue <TAB><TAB> except Exception as e : <TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )","if not os . path . exists ( fspath + "".spt"" ) :",if e . errno == errno . ENOENT :,92.84720900441108,94.52,False
2081,"def set_conf ( ) : <TAB> """"""Collapse all object_trail config into cherrypy.request.config."""""" <TAB> base = cherrypy . config . copy ( ) <TAB> # Note that we merge the config from each node <TAB> # even if that node was None. <TAB> for name , obj , conf , segleft in object_trail : <TAB><TAB> base . update ( conf ) <TAB><TAB> <MASK> <TAB><TAB><TAB> base [ "" tools.staticdir.section "" ] = "" / "" + "" / "" . join ( <TAB><TAB><TAB><TAB> fullpath [ 0 : fullpath_len - segleft ] <TAB><TAB><TAB> ) <TAB> return base","if ""tools.staticdir.dir"" in conf :",if segleft :,97.51611294850807,93.95,False
2082,"def __init__ ( self ) : <TAB> self . setLayers ( None , None ) <TAB> self . interface = None <TAB> self . event_callbacks = { } <TAB> self . __stack = None <TAB> self . lock = threading . Lock ( ) <TAB> members = inspect . getmembers ( self , predicate = inspect . ismethod ) <TAB> for m in members : <TAB><TAB> <MASK> <TAB><TAB><TAB> fname = m [ 0 ] <TAB><TAB><TAB> fn = m [ 1 ] <TAB><TAB><TAB> self . event_callbacks [ fn . event_callback ] = getattr ( self , fname )","if hasattr ( m [ 1 ] , ""event_callback"" ) :","if isinstance ( m [ 0 ] , types . FunctionType ) :",66.73534084892579,93.13,False
2083,def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _tail_data + = data <TAB><TAB> if len ( self . _tail_data ) == self . _base_number : <TAB><TAB><TAB> yield self . _tail_data <TAB><TAB><TAB> self . _tail_data = [ ],if len ( self . _tail_data ) < self . _base_number :,if data :,79.01251468854777,85.54,False
2084,"def replace_field_to_value ( layout , cb ) : <TAB> for i , lo in enumerate ( layout . fields ) : <TAB><TAB> if isinstance ( lo , Field ) or issubclass ( lo . __class__ , Field ) : <TAB><TAB><TAB> layout . fields [ i ] = ShowField ( <TAB><TAB><TAB><TAB> cb , * lo . fields , attrs = lo . attrs , wrapper_class = lo . wrapper_class <TAB><TAB><TAB> ) <TAB><TAB> elif isinstance ( lo , basestring ) : <TAB><TAB><TAB> layout . fields [ i ] = ShowField ( cb , lo ) <TAB><TAB> <MASK> <TAB><TAB><TAB> replace_field_to_value ( lo , cb )","elif hasattr ( lo , ""get_field_names"" ) :","elif isinstance ( lo , ( Field , FieldList ) ) :",67.81935556669417,94.30,False
2085,"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB><TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB><TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB><TAB><TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB><TAB> if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT : <TAB><TAB><TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB><TAB> raise","if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",if e . get_dbus_name ( ) == DBUS_NO_SUCH_,66.99272626182392,93.02,False
2086,"def results_iter ( self ) : <TAB> if self . connection . ops . oracle : <TAB><TAB> from django . db . models . fields import DateTimeField <TAB><TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB><TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB><TAB> for row in rows : <TAB><TAB><TAB> date = row [ offset ] <TAB><TAB><TAB> if self . connection . ops . oracle : <TAB><TAB><TAB><TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> date = typecast_timestamp ( str ( date ) ) <TAB><TAB><TAB> yield date",elif needs_string_cast :,if needs_string_cast :,84.81806196520193,98.90,False
2087,"def handle_label ( self , path , * * options ) : <TAB> verbosity = int ( options . get ( "" verbosity "" , 1 ) ) <TAB> result = finders . find ( path , all = options [ "" all "" ] ) <TAB> path = smart_unicode ( path ) <TAB> if result : <TAB><TAB> if not isinstance ( result , ( list , tuple ) ) : <TAB><TAB><TAB> result = [ result ] <TAB><TAB> output = u "" \n    "" . join ( <TAB><TAB><TAB> ( smart_unicode ( os . path . realpath ( path ) ) for path in result ) <TAB><TAB> ) <TAB><TAB> self . stdout . write ( smart_str ( u "" Found  ' %s '  here: \n    %s \n "" % ( path , output ) ) ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . stderr . write ( smart_str ( "" No matching file found for  ' %s ' . \n "" % path ) )",if verbosity >= 1 :,if verbosity >= 1 :,100.0,100.00,True
2088,"def name ( self ) : <TAB> """"""Get the enumeration name of this storage class."""""" <TAB> if self . _name_map is None : <TAB><TAB> self . _name_map = { } <TAB><TAB> for key , value in list ( StorageClass . __dict__ . items ( ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _name_map [ value ] = key <TAB> return self . _name_map [ self ]","if isinstance ( value , StorageClass ) :","if isinstance ( value , StorageClass ) :",100.0,100.00,True
2089,"def index ( self , value ) : <TAB> if self . _growing : <TAB><TAB> if self . _start < = value < self . _stop : <TAB><TAB><TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB><TAB><TAB> if r == self . _zero : <TAB><TAB><TAB><TAB> return int ( q ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB><TAB><TAB> if r == self . _zero : <TAB><TAB><TAB><TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) )",if self . _start >= value > self . _stop :,if self . _start >= value and self . _stop >= value :,96.55503549570533,96.76,False
2090,"def extract_cookie ( cookie_header , cookie_name ) : <TAB> inx = cookie_header . find ( cookie_name ) <TAB> if inx > = 0 : <TAB><TAB> end_inx = cookie_header . find ( "" ; "" , inx ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = cookie_header [ inx : end_inx ] <TAB><TAB> else : <TAB><TAB><TAB> value = cookie_header [ inx : ] <TAB><TAB> return value <TAB> return "" """,if end_inx > 0 :,if end_inx >= 0 :,98.17617264241628,98.12,False
2091,"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB><TAB> if isinstance ( elem , str ) : <TAB><TAB><TAB> size + = len ( elem ) <TAB><TAB> <MASK> <TAB><TAB><TAB> size + = elem . size * elem . itemsize <TAB><TAB> elif isinstance ( elem , int ) : <TAB><TAB><TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB> elif isinstance ( elem , float ) : <TAB><TAB><TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( ) <TAB> return size","elif isinstance ( elem , np . ndarray ) :","elif isinstance ( elem , ( Base , Base ) ) :",73.04371766263517,97.07,False
2092,"def createFields ( self ) : <TAB> size = self . size / 8 <TAB> if size > 2 : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield UInt8 ( self , "" cs "" , "" 10ms units, values from 0 to 199 "" ) <TAB><TAB> yield Bits ( self , "" 2sec "" , 5 , "" seconds/2 "" ) <TAB><TAB> yield Bits ( self , "" min "" , 6 , "" minutes "" ) <TAB><TAB> yield Bits ( self , "" hour "" , 5 , "" hours "" ) <TAB> yield Bits ( self , "" day "" , 5 , "" (1-31) "" ) <TAB> yield Bits ( self , "" month "" , 4 , "" (1-12) "" ) <TAB> yield Bits ( self , "" year "" , 7 , "" (0 = 1980, 127 = 2107) "" )",if size > 4 :,if size % 2 == 0 :,96.55810345375599,96.75,False
2093,"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB><TAB> page , headers , code = get_page ( get = vector ) <TAB><TAB> retval = ( <TAB><TAB><TAB> re . search ( <TAB><TAB><TAB><TAB> r "" incap_ses|visid_incap "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB><TAB><TAB> ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> retval | = re . search ( r "" Incapsula "" , headers . get ( "" X-CDN "" , "" "" ) , re . I ) is not None <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return retval",if retval :,if retval :,100.0,100.00,True
2094,"def _get_order_information ( self , node_id , timeout = 1200 , check_interval = 5 ) : <TAB> mask = { <TAB><TAB> "" billingItem "" : "" "" , <TAB><TAB> "" powerState "" : "" "" , <TAB><TAB> "" operatingSystem "" : { "" passwords "" : "" "" } , <TAB><TAB> "" provisionDate "" : "" "" , <TAB> } <TAB> for i in range ( 0 , timeout , check_interval ) : <TAB><TAB> res = self . connection . request ( <TAB><TAB><TAB> "" SoftLayer_Virtual_Guest "" , "" getObject "" , id = node_id , object_mask = mask <TAB><TAB> ) . object <TAB><TAB> <MASK> <TAB><TAB><TAB> return res <TAB><TAB> time . sleep ( check_interval ) <TAB> raise SoftLayerException ( "" Timeout on getting node details "" )","if res . get ( ""provisionDate"" , None ) :",if res :,75.84945959077561,95.18,False
2095,"def _process_param_change ( self , msg ) : <TAB> msg = super ( Select , self ) . _process_param_change ( msg ) <TAB> labels , values = self . labels , self . values <TAB> if "" value "" in msg : <TAB><TAB> msg [ "" value "" ] = [ <TAB><TAB><TAB> labels [ indexOf ( v , values ) ] for v in msg [ "" value "" ] if isIn ( v , values ) <TAB><TAB> ] <TAB> if "" options "" in msg : <TAB><TAB> msg [ "" options "" ] = labels <TAB><TAB> <MASK> <TAB><TAB><TAB> self . value = [ v for v in self . value if isIn ( v , values ) ] <TAB> return msg","if any ( not isIn ( v , values ) for v in self . value ) :",if self . value :,68.89889938654073,91.54,False
2096,"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB><TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB><TAB> if not o . name : <TAB><TAB><TAB> continue <TAB><TAB> if o . name . lower ( ) == name . lower ( ) : <TAB><TAB><TAB> return o <TAB> if check_symlinks : <TAB><TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> name = m [ 0 ] <TAB><TAB> return self . get_object_from_name ( name , False )",if m :,if len ( m ) == 1 :,83.53283942154589,96.13,False
2097,"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if v [ "" _class "" ] == "" User "" : <TAB><TAB><TAB> if v [ "" email "" ] == "" "" : <TAB><TAB><TAB><TAB> v [ "" email "" ] = None <TAB><TAB><TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB><TAB><TAB><TAB> v [ "" ip "" ] = None <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",100.0,100.00,True
2098,"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB><TAB> for ent_id , ent_desc in _md . items ( ) : <TAB><TAB><TAB> if descriptor in ent_desc : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> # print(""duplicated entity_id: %s"" % res) <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> res . append ( ent_id ) <TAB> return res",if ent_id in res :,if ent_id in res :,100.0,100.00,True
2099,"def test_add_participant ( self ) : <TAB> async with self . chat_client : <TAB><TAB> await self . _create_thread ( ) <TAB><TAB> async with self . chat_thread_client : <TAB><TAB><TAB> share_history_time = datetime . utcnow ( ) <TAB><TAB><TAB> share_history_time = share_history_time . replace ( tzinfo = TZ_UTC ) <TAB><TAB><TAB> new_participant = ChatThreadParticipant ( <TAB><TAB><TAB><TAB> user = self . new_user , <TAB><TAB><TAB><TAB> display_name = "" name "" , <TAB><TAB><TAB><TAB> share_history_time = share_history_time , <TAB><TAB><TAB> ) <TAB><TAB><TAB> await self . chat_thread_client . add_participant ( new_participant ) <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . chat_client . delete_chat_thread ( self . thread_id )",if not self . is_playback ( ) :,if self . is_live :,73.21493142624644,97.28,False
2100,"def url ( regex , view , kwargs = None , name = None , prefix = "" "" ) : <TAB> if isinstance ( view , ( list , tuple ) ) : <TAB><TAB> # For include(...) processing. <TAB><TAB> urlconf_module , app_name , namespace = view <TAB><TAB> return RegexURLResolver ( <TAB><TAB><TAB> regex , urlconf_module , kwargs , app_name = app_name , namespace = namespace <TAB><TAB> ) <TAB> else : <TAB><TAB> if isinstance ( view , basestring ) : <TAB><TAB><TAB> if not view : <TAB><TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB><TAB> "" Empty URL pattern view name not permitted (for pattern  %r ) "" % regex <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> view = prefix + "" . "" + view <TAB><TAB> return RegexURLPattern ( regex , view , kwargs , name )",if prefix :,if prefix :,100.0,100.00,True
2101,"def tx ( ) : <TAB> # Sync receiver ready to avoid loss of first packets <TAB> while not sub_ready . ready ( ) : <TAB><TAB> pub . send ( b "" test BEGIN "" ) <TAB><TAB> eventlet . sleep ( 0.005 ) <TAB> for i in range ( 1 , 101 ) : <TAB><TAB> msg = "" test  {0} "" . format ( i ) . encode ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pub . send ( msg ) <TAB><TAB> else : <TAB><TAB><TAB> pub . send ( b "" test LAST "" ) <TAB><TAB><TAB> sub_last . wait ( ) <TAB><TAB> # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB><TAB> # just yield eventlet.sleep(0) doesn't cut it <TAB><TAB> eventlet . sleep ( 0.001 ) <TAB> pub . send ( b "" done DONE "" )",if i != 50 :,if i % 2 == 0 :,73.44520563702706,97.27,False
2102,"def remove_tmp_snapshot_file ( self , files ) : <TAB> for filepath in files : <TAB><TAB> path = Path ( filepath ) <TAB><TAB> if path . is_dir ( ) and path . exists ( ) : <TAB><TAB><TAB> shutil . rmtree ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> path . unlink ( )",elif path . is_file ( ) and path . exists ( ) :,elif path . is_file ( ) and path . exists ( ) :,100.0,100.00,True
2103,"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB><TAB> if count == 1 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> eol = view . line ( s . b ) . b <TAB><TAB><TAB><TAB> return R ( s . b , eol ) <TAB><TAB><TAB> return s <TAB> return s",if view . line ( s . b ) . size ( ) > 0 :,if s . b . b . count ( ) == 0 :,86.8097955986595,89.92,False
2104,"def get_ids ( self , * * kwargs ) : <TAB> id = [ ] <TAB> if "" id "" in kwargs : <TAB><TAB> id = kwargs [ "" id "" ] <TAB><TAB> # Coerce ids to list <TAB><TAB> <MASK> <TAB><TAB><TAB> id = id . split ( "" , "" ) <TAB><TAB> # Ensure ids are integers <TAB><TAB> try : <TAB><TAB><TAB> id = list ( map ( int , id ) ) <TAB><TAB> except Exception : <TAB><TAB><TAB> decorators . error ( "" Invalid id "" ) <TAB> return id","if not isinstance ( id , list ) :","if "","" in id :",95.56291116158195,94.91,False
2105,"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self : <TAB><TAB> <MASK> <TAB><TAB><TAB> return token . stripped_value <TAB><TAB> if token . token_type == "" quoted-string "" : <TAB><TAB><TAB> for token in token : <TAB><TAB><TAB><TAB> if token . token_type == "" bare-quoted-string "" : <TAB><TAB><TAB><TAB><TAB> for token in token : <TAB><TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB><TAB> return token . stripped_value <TAB> return "" ""","if token . token_type == ""value"" :","if token . token_type == ""handle-quoted-string"" :",72.0609056008236,97.53,False
2106,"def get_all_start_methods ( self ) : <TAB> if sys . platform == "" win32 "" : <TAB><TAB> return [ "" spawn "" ] <TAB> else : <TAB><TAB> methods = [ "" spawn "" , "" fork "" ] if sys . platform == "" darwin "" else [ "" fork "" , "" spawn "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> methods . append ( "" forkserver "" ) <TAB><TAB> return methods",if reduction . HAVE_SEND_HANDLE :,if self . _is_server :,97.09010496400752,93.32,False
2107,"def _process_watch ( self , watched_event ) : <TAB> logger . debug ( "" process_watch:  %r "" , watched_event ) <TAB> with handle_exception ( self . _tree . _error_listeners ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert self . _parent is None , "" unexpected CREATED on non-root "" <TAB><TAB><TAB> self . on_created ( ) <TAB><TAB> elif watched_event . type == EventType . DELETED : <TAB><TAB><TAB> self . on_deleted ( ) <TAB><TAB> elif watched_event . type == EventType . CHANGED : <TAB><TAB><TAB> self . _refresh_data ( ) <TAB><TAB> elif watched_event . type == EventType . CHILD : <TAB><TAB><TAB> self . _refresh_children ( )",if watched_event . type == EventType . CREATED :,if watched_event . type == EventType . CREATED :,75.0,100.00,True
2108,"def assert_open ( self , sock , * rest ) : <TAB> if isinstance ( sock , fd_types ) : <TAB><TAB> self . __assert_fd_open ( sock ) <TAB> else : <TAB><TAB> fileno = sock . fileno ( ) <TAB><TAB> assert isinstance ( fileno , fd_types ) , fileno <TAB><TAB> sockname = sock . getsockname ( ) <TAB><TAB> assert isinstance ( sockname , tuple ) , sockname <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __assert_fd_open ( fileno ) <TAB><TAB> else : <TAB><TAB><TAB> self . _assert_sock_open ( sock ) <TAB> if rest : <TAB><TAB> self . assert_open ( rest [ 0 ] , * rest [ 1 : ] )",if not WIN :,if fileno :,70.18200537796059,98.20,False
2109,"def detype ( self ) : <TAB> """"""De-types the instance, allowing it to be exported to the environment."""""" <TAB> style = self . style <TAB> if self . _detyped is None : <TAB><TAB> self . _detyped = "" : "" . join ( <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> key <TAB><TAB><TAB><TAB> + "" = "" <TAB><TAB><TAB><TAB> + "" ; "" . join ( <TAB><TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB><TAB> LsColors . target_value <TAB><TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> else ansi_color_name_to_escape_code ( v , cmap = style ) <TAB><TAB><TAB><TAB><TAB><TAB> for v in val <TAB><TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> for key , val in sorted ( self . _d . items ( ) ) <TAB><TAB><TAB> ] <TAB><TAB> ) <TAB> return self . _detyped",if key in self . _targets,"if not isinstance ( val , ( list , tuple ) )",87.63080390546588,96.22,False
2110,"def gather_metrics ( dry_run = False ) : <TAB> today = datetime . date . today ( ) <TAB> first = today . replace ( day = 1 ) <TAB> last_month = first - datetime . timedelta ( days = 1 ) <TAB> filename = "" form_types_ {} .csv "" . format ( last_month . strftime ( "" % Y- % m "" ) ) <TAB> with connection . cursor ( ) as cursor : <TAB><TAB> cursor . execute ( REGISTRATION_METRICS_SQL ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for row in cursor . fetchall ( ) : <TAB><TAB><TAB><TAB> logger . info ( encode_row ( row ) ) <TAB><TAB> else : <TAB><TAB><TAB> write_raw_data ( cursor = cursor , filename = filename )",if dry_run :,if dry_run :,100.0,100.00,True
2111,"def cat ( tensors , dim = 0 ) : <TAB> assert isinstance ( tensors , list ) , "" input to cat must be a list "" <TAB> if len ( tensors ) == 1 : <TAB><TAB> return tensors [ 0 ] <TAB> from . autograd_cryptensor import AutogradCrypTensor <TAB> if any ( isinstance ( t , AutogradCrypTensor ) for t in tensors ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tensors [ 0 ] = AutogradCrypTensor ( tensors [ 0 ] , requires_grad = False ) <TAB><TAB> return tensors [ 0 ] . cat ( * tensors [ 1 : ] , dim = dim ) <TAB> else : <TAB><TAB> return get_default_backend ( ) . cat ( tensors , dim = dim )","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",100.0,100.00,True
2112,"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB><TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB><TAB> installed = True if dlc_version else False <TAB><TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB><TAB> if not installed : <TAB><TAB><TAB> status = self . legacy_get_dlc_status ( dlc_title ) <TAB><TAB><TAB> installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB><TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> installed = True <TAB> return installed",if self . install_dir and os . path . exists ( self . install_dir ) :,"if self . legacy_get_dlc_status ( ""installed"" ) :",94.8908183445343,92.50,False
2113,"def on_copy ( self ) : <TAB> source_objects = self . __getSelection ( ) <TAB> for source in source_objects : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_obj = model . Phrase ( "" "" , "" "" ) <TAB><TAB> else : <TAB><TAB><TAB> new_obj = model . Script ( "" "" , "" "" ) <TAB><TAB> new_obj . copy ( source ) <TAB><TAB> self . cutCopiedItems . append ( new_obj )","if isinstance ( source , model . Phrase ) :",if source . is_editable ( ) :,90.54674054095705,94.04,False
2114,"def FetchFn ( type_name ) : <TAB> """"""Fetches all hunt results of a given type."""""" <TAB> offset = 0 <TAB> while True : <TAB><TAB> results = data_store . REL_DB . ReadHuntResults ( <TAB><TAB><TAB> hunt_id , offset = offset , count = self . _RESULTS_PAGE_SIZE , with_type = type_name <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> for r in results : <TAB><TAB><TAB> msg = r . AsLegacyGrrMessage ( ) <TAB><TAB><TAB> msg . source_urn = source_urn <TAB><TAB><TAB> yield msg <TAB><TAB> offset + = self . _RESULTS_PAGE_SIZE",if not results :,if not results :,100.0,100.00,True
2115,"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" TINYBLOB "" <TAB><TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB><TAB><TAB> return "" BLOB "" <TAB><TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB><TAB><TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_TINYBLOB :,if length <= self . LENGTH_LIMIT_TINYBLOB :,100.0,100.00,True
2116,"def decode ( cls , data ) : <TAB> while data : <TAB><TAB> ( <TAB><TAB><TAB> length , <TAB><TAB><TAB> atype , <TAB><TAB> ) = unpack ( cls . Header . PACK , data [ : cls . Header . LEN ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AttributesError ( "" Buffer underrun  %d  <  %d "" % ( len ( data ) , length ) ) <TAB><TAB> payload = data [ cls . Header . LEN : length ] <TAB><TAB> yield atype , payload <TAB><TAB> data = data [ int ( ( length + 3 ) / 4 ) * 4 : ]",if len ( data ) < length :,if length < 0 :,71.76888289285375,95.73,False
2117,"def test_join_diffs ( db , series_of_diffs , expected ) : <TAB> diffs = [ ] <TAB> for changes in series_of_diffs : <TAB><TAB> tracker = DBDiffTracker ( ) <TAB><TAB> for key , val in changes . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del tracker [ key ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tracker [ key ] = val <TAB><TAB> diffs . append ( tracker . diff ( ) ) <TAB> DBDiff . join ( diffs ) . apply_to ( db ) <TAB> assert db == expected",if val is None :,if key in tracker :,93.30381420339923,97.24,False
2118,"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB><TAB> tmp + = "" m  "" <TAB><TAB> for col in row : <TAB><TAB><TAB> if col == LAND : <TAB><TAB><TAB><TAB> tmp + = "" . "" <TAB><TAB><TAB> elif col == BARRIER : <TAB><TAB><TAB><TAB> tmp + = "" % "" <TAB><TAB><TAB> elif col == FOOD : <TAB><TAB><TAB><TAB> tmp + = "" * "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp + = "" ? "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> players [ col ] = True <TAB><TAB><TAB><TAB> tmp + = chr ( col + 97 ) <TAB><TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == UNSEEN :,elif col == FOOD :,76.39689491520359,99.16,False
2119,"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB><TAB> # Only include the text in case of error. <TAB><TAB> if not response . ok : <TAB><TAB><TAB> status = location . Status ( response . status_code , response . text ) <TAB><TAB> else : <TAB><TAB><TAB> status = location . Status ( response . status_code ) <TAB> else : <TAB><TAB> status = location . Status ( 500 , message ) <TAB> if response is None or not response . ok : <TAB><TAB> <MASK> <TAB><TAB><TAB> return completion_routine ( status ) <TAB><TAB> raise IOError ( response . text ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> completion_routine ( status ) <TAB> return location . Status ( 200 , response . content )",if completion_routine :,if completion_routine :,100.0,100.00,True
2120,"def _generate_examples ( self , src_path = None , tgt_path = None , replace_unk = None ) : <TAB> """"""Yields examples."""""" <TAB> with tf . io . gfile . GFile ( src_path ) as f_d , tf . io . gfile . GFile ( tgt_path ) as f_s : <TAB><TAB> for i , ( doc_text , sum_text ) in enumerate ( zip ( f_d , f_s ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield i , { <TAB><TAB><TAB><TAB><TAB> _DOCUMENT : doc_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB><TAB><TAB><TAB><TAB> _SUMMARY : sum_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield i , { _DOCUMENT : doc_text . strip ( ) , _SUMMARY : sum_text . strip ( ) }",if replace_unk :,if replace_unk :,100.0,100.00,True
2121,"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB><TAB> if "" & "" in text : <TAB><TAB><TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB> if "" > "" in text : <TAB><TAB><TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB> if "" < "" in text : <TAB><TAB><TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB> if ' "" ' in text : <TAB><TAB><TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB> if "" ' "" in text : <TAB><TAB><TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" \n "" in text : <TAB><TAB><TAB><TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text",if newline :,if newline :,100.0,100.00,True
2122,"def _handle_url_click ( self , event ) : <TAB> url = _extract_click_text ( self . info_text , event , "" url "" ) <TAB> if url is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> import webbrowser <TAB><TAB><TAB> webbrowser . open ( url ) <TAB><TAB> elif os . path . sep in url : <TAB><TAB><TAB> os . makedirs ( url , exist_ok = True ) <TAB><TAB><TAB> open_path_in_system_file_manager ( url ) <TAB><TAB> else : <TAB><TAB><TAB> self . _start_show_package_info ( url )","if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :","if os . name == ""nt"" :",88.83826523896707,89.27,False
2123,"def SConsignFile ( self , name = "" .sconsign "" , dbm_module = None ) : <TAB> if name is not None : <TAB><TAB> name = self . subst ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> name = os . path . join ( str ( self . fs . SConstruct_dir ) , name ) <TAB> if name : <TAB><TAB> name = os . path . normpath ( name ) <TAB><TAB> sconsign_dir = os . path . dirname ( name ) <TAB><TAB> if sconsign_dir and not os . path . exists ( sconsign_dir ) : <TAB><TAB><TAB> self . Execute ( SCons . Defaults . Mkdir ( sconsign_dir ) ) <TAB> SCons . SConsign . File ( name , dbm_module )",if not os . path . isabs ( name ) :,if not name :,70.43065185467499,95.07,False
2124,"def on_train_start ( self , trainer : Trainer , pl_module : LightningModule ) - > None : <TAB> super ( ) . on_train_start ( trainer , pl_module ) <TAB> submodule_dict = dict ( pl_module . named_modules ( ) ) <TAB> self . _hook_handles = [ ] <TAB> for name in self . _get_submodule_names ( pl_module ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rank_zero_warn ( <TAB><TAB><TAB><TAB> f "" { name }  is not a valid identifier for a submodule in  { pl_module . __class__ . __name__ } , "" <TAB><TAB><TAB><TAB> ""  skipping this key. "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> handle = self . _register_hook ( name , submodule_dict [ name ] ) <TAB><TAB> self . _hook_handles . append ( handle )",if name not in submodule_dict :,if name not in submodule_dict :,100.0,100.00,True
2125,"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> super ( ) . validate_configuration ( configuration ) <TAB> if configuration is None : <TAB><TAB> configuration = self . configuration <TAB> try : <TAB><TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB><TAB> assert isinstance ( <TAB><TAB><TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB><TAB> ) , "" value_set must be a list or a set "" <TAB><TAB> <MASK> <TAB><TAB><TAB> assert ( <TAB><TAB><TAB><TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB><TAB><TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key. ' <TAB> except AssertionError as e : <TAB><TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",100.0,100.00,True
2126,"def check_refcounts ( expected , timeout = 10 ) : <TAB> start = time . time ( ) <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> _check_refcounts ( expected ) <TAB><TAB><TAB> break <TAB><TAB> except AssertionError as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise e <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> time . sleep ( 0.1 )",if time . time ( ) - start > timeout :,if time . time ( ) - start >= timeout :,97.97837355845301,98.14,False
2127,"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB><TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB><TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB><TAB> line = f . readline ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> if prog . match ( line ) : <TAB><TAB><TAB> text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB> while 1 : <TAB><TAB><TAB><TAB> line = f . readline ( ) <TAB><TAB><TAB><TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> text = text + line <TAB><TAB><TAB> return text . strip ( ) <TAB> return None",if not line :,if not line :,100.0,100.00,True
2128,def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> r = event_regexp . search ( line ) <TAB><TAB> if r : <TAB><TAB><TAB> f . close ( ) <TAB><TAB><TAB> return True <TAB><TAB> f . close ( ) <TAB><TAB> return False,"if line [ 0 ] == ""#"" :","if line . startswith ( ""#"" ) :",92.07929604913461,93.75,False
2129,"def link_pantsrefs ( soups , precomputed ) : <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB><TAB> for a in soup . find_all ( "" a "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> pantsref = a [ "" pantsref "" ] <TAB><TAB><TAB> if pantsref not in precomputed . pantsref : <TAB><TAB><TAB><TAB> raise TaskError ( <TAB><TAB><TAB><TAB><TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] )","if not a . has_attr ( ""pantsref"" ) :","if ""href"" not in a :",91.62810135144942,95.28,False
2130,"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB><TAB> self . querylist = [ ] <TAB> else : <TAB><TAB> self . querylist = querylist <TAB><TAB> for query in self . querylist : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . query_id = query . query_id <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if self . query_id != query . query_id : <TAB><TAB><TAB><TAB><TAB> raise ValueError ( "" query in list must be same query_id "" )",if self . query_id == - 1 :,"if isinstance ( query , QueryId ) :",89.27547061651964,94.37,False
2131,"def _draw_number ( <TAB> screen , x_offset , y_offset , number , token = Token . Clock , transparent = False ) : <TAB> "" Write number at position. "" <TAB> fg = Char ( ""   "" , token ) <TAB> bg = Char ( ""   "" , Token ) <TAB> for y , row in enumerate ( _numbers [ number ] ) : <TAB><TAB> screen_row = screen . data_buffer [ y + y_offset ] <TAB><TAB> for x , n in enumerate ( row ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> screen_row [ x + x_offset ] = fg <TAB><TAB><TAB> elif not transparent : <TAB><TAB><TAB><TAB> screen_row [ x + x_offset ] = bg","if n == ""#"" :",if n == number :,81.99213261616248,97.72,False
2132,"def init ( self ) : <TAB> self . sock . setblocking ( True ) <TAB> if self . parser is None : <TAB><TAB> # wrap the socket if needed <TAB><TAB> <MASK> <TAB><TAB><TAB> self . sock = ssl . wrap_socket ( <TAB><TAB><TAB><TAB> self . sock , server_side = True , * * self . cfg . ssl_options <TAB><TAB><TAB> ) <TAB><TAB> # initialize the parser <TAB><TAB> self . parser = http . RequestParser ( self . cfg , self . sock )",if self . cfg . is_ssl :,if ssl :,96.27209465074796,94.76,False
2133,"def intersect_face ( pt ) : <TAB> # todo: rewrite! inefficient! <TAB> nonlocal vis_faces2D <TAB> for f , vs in vis_faces2D : <TAB><TAB> v0 = vs [ 0 ] <TAB><TAB> for v1 , v2 in iter_pairs ( vs [ 1 : ] , False ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return f <TAB> return None","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",if v0 == v1 and v2 == pt :,66.84871167054673,85.81,False
2134,"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB><TAB> if not self . futuresAllowed : <TAB><TAB><TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB><TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . scope . importStarred = True <TAB><TAB><TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB><TAB><TAB> continue <TAB><TAB> name = alias . asname or alias . name <TAB><TAB> importation = Importation ( name , node ) <TAB><TAB> if node . module == "" __future__ "" : <TAB><TAB><TAB> importation . used = ( self . scope , node ) <TAB><TAB> self . addBinding ( node , importation )","if alias . name == ""*"" :","if alias . asname and alias . name == ""__future__"" :",97.33972454529442,95.67,False
2135,"def PyObject_Bytes ( obj ) : <TAB> if type ( obj ) == bytes : <TAB><TAB> return obj <TAB> if hasattr ( obj , "" __bytes__ "" ) : <TAB><TAB> res = obj . __bytes__ ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> "" __bytes__ returned non-bytes (type  %s ) "" % type ( res ) . __name__ <TAB><TAB><TAB> ) <TAB> return PyBytes_FromObject ( obj )","if not isinstance ( res , bytes ) :","if not isinstance ( res , bytes ) :",100.0,100.00,True
2136,"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB><TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB><TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB><TAB><TAB> return self . current_provider . on_search ( query ) <TAB><TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB><TAB><TAB> return self . current_provider . on_url ( query ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . current_provider . on_file ( query )",elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,100.0,100.00,True
2137,"def remove ( self , name ) : <TAB> for s in [ self . __storage ( self . __category ) , self . __storage ( None ) ] : <TAB><TAB> for i , b in enumerate ( s ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del s [ i ] <TAB><TAB><TAB><TAB> if b . persistent : <TAB><TAB><TAB><TAB><TAB> self . __save ( ) <TAB><TAB><TAB><TAB> return <TAB> raise KeyError ( name )",if b . name == name :,if name == b . name :,70.56985913855887,97.40,False
2138,"def _wrapper ( data , axis = None , keepdims = False ) : <TAB> if not keepdims : <TAB><TAB> return func ( data , axis = axis ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> axis = axis if isinstance ( axis , int ) else axis [ 0 ] <TAB><TAB><TAB> out_shape = list ( data . shape ) <TAB><TAB><TAB> out_shape [ axis ] = 1 <TAB><TAB> else : <TAB><TAB><TAB> out_shape = [ 1 for _ in range ( len ( data . shape ) ) ] <TAB><TAB> return func ( data , axis = axis ) . reshape ( out_shape )",if axis is not None :,if axis is not None :,100.0,100.00,True
2139,"def authn_info ( self ) : <TAB> res = [ ] <TAB> for astat in self . assertion . authn_statement : <TAB><TAB> context = astat . authn_context <TAB><TAB> try : <TAB><TAB><TAB> authn_instant = astat . authn_instant <TAB><TAB> except AttributeError : <TAB><TAB><TAB> authn_instant = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> aclass = context . authn_context_class_ref . text <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> aclass = "" "" <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> authn_auth = [ a . text for a in context . authenticating_authority ] <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> authn_auth = [ ] <TAB><TAB><TAB> res . append ( ( aclass , authn_auth , authn_instant ) ) <TAB> return res",if context :,if context . authn_context_class_ref :,75.36902795728311,96.50,False
2140,"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB><TAB> if self . posts : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB> if self . stories : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path )",if self . latest :,if self . merge_json :,98.17430631466122,96.54,False
2141,"def update_record_image_detail ( input_image_record , updated_image_detail , session = None ) : <TAB> if not session : <TAB><TAB> session = db . Session <TAB> image_record = { } <TAB> image_record . update ( input_image_record ) <TAB> image_record . pop ( "" created_at "" , None ) <TAB> image_record . pop ( "" last_updated "" , None ) <TAB> if image_record [ "" image_type "" ] == "" docker "" : <TAB><TAB> for tag_record in updated_image_detail : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> image_record [ "" image_detail "" ] . append ( tag_record ) <TAB><TAB><TAB><TAB> return update_record ( image_record , session = session ) <TAB> return image_record","if tag_record not in image_record [ ""image_detail"" ] :","if tag_record [ ""name"" ] == ""tag_record"" :",94.80774989674805,95.42,False
2142,"def backup ( self ) : <TAB> for ds in [ ( "" activedirectory "" , "" AD "" ) , ( "" ldap "" , "" LDAP "" ) , ( "" nis "" , "" NIS "" ) ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> ds_cache = self . middleware . call_sync ( "" cache.get "" , f "" { ds [ 1 ] } _cache "" ) <TAB><TAB><TAB><TAB> with open ( f "" /var/db/system/. { ds [ 1 ] } _cache_backup "" , "" wb "" ) as f : <TAB><TAB><TAB><TAB><TAB> pickle . dump ( ds_cache , f ) <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> self . logger . debug ( "" No cache exists for directory service [ %s ]. "" , ds [ 0 ] )","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :","if ds [ 0 ] == ""cache"" :",74.14543419049929,89.51,False
2143,"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB><TAB> contents = self . setup_cfg . read_text ( ) <TAB><TAB> base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB><TAB> try : <TAB><TAB><TAB> parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB><TAB> except Exception : <TAB><TAB><TAB> if six . PY2 : <TAB><TAB><TAB><TAB> contents = self . setup_cfg . read_bytes ( ) <TAB><TAB><TAB> parsed = parse_setup_cfg ( contents , base_dir ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return { } <TAB><TAB> return parsed <TAB> return { }",if not parsed :,if parsed is None :,73.24832308980807,98.24,False
2144,"def parts ( ) : <TAB> for l in lists . leaves : <TAB><TAB> head_name = l . get_head_name ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield l . leaves <TAB><TAB> elif head_name != "" System`Missing "" : <TAB><TAB><TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l )","if head_name == ""System`List"" :","if head_name == ""Catenate"" :",97.62039407134606,95.64,False
2145,"def _get_callback_and_order ( self , hook ) : <TAB> if callable ( hook ) : <TAB><TAB> return hook , None <TAB> elif isinstance ( hook , tuple ) and len ( hook ) == 2 : <TAB><TAB> callback , order = hook <TAB><TAB> # test that callback is a callable <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Hook callback is not a callable "" ) <TAB><TAB> # test that number is an int <TAB><TAB> try : <TAB><TAB><TAB> int ( order ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise ValueError ( "" Hook order is not a number "" ) <TAB><TAB> return callback , order <TAB> else : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" Invalid hook definition, neither a callable nor a 2-tuple (callback, order):  {!r} "" . format ( <TAB><TAB><TAB><TAB> hook <TAB><TAB><TAB> ) <TAB><TAB> )",if not callable ( callback ) :,if not callable ( callback ) :,100.0,100.00,True
2146,"def _resize_masks ( self , results ) : <TAB> """"""Resize masks with ``results['scale']``"""""" <TAB> for key in results . get ( "" mask_fields "" , [ ] ) : <TAB><TAB> if results [ key ] is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> results [ key ] = results [ key ] . rescale ( results [ "" scale "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> results [ key ] = results [ key ] . resize ( results [ "" img_shape "" ] [ : 2 ] )",if self . keep_ratio :,"if results [ key ] . get ( ""scale"" ) :",94.64561157997444,92.45,False
2147,"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB><TAB> c = self . getSystemCurve ( i ) <TAB><TAB> if not c . isVisible ( ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> nPoints = c . getNPoints ( ) <TAB><TAB><TAB> for j in range ( nPoints ) : <TAB><TAB><TAB><TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB><TAB> return Double . NaN <TAB> return result",if c . getYAxis ( ) == Y_AXIS :,if result != Double . NaN :,67.90832939381708,94.12,False
2148,"def _check_token ( self ) : <TAB> if settings . app . sso_client_cache and self . server_auth_token : <TAB><TAB> doc = self . sso_client_cache_collection . find_one ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" user_id "" : self . user . id , <TAB><TAB><TAB><TAB> "" server_id "" : self . server . id , <TAB><TAB><TAB><TAB> "" device_id "" : self . device_id , <TAB><TAB><TAB><TAB> "" device_name "" : self . device_name , <TAB><TAB><TAB><TAB> "" auth_token "" : self . server_auth_token , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . has_token = True",if doc :,"if doc and doc . get ( ""auth_token"" ) :",68.87342980896022,94.71,False
2149,"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [ ] <TAB> properties = [ ] <TAB> num_points = None <TAB> while b "" end_header "" not in line and line != b "" "" : <TAB><TAB> line = plyfile . readline ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line = line . split ( ) <TAB><TAB><TAB> num_points = int ( line [ 2 ] ) <TAB><TAB> elif b "" property "" in line : <TAB><TAB><TAB> line = line . split ( ) <TAB><TAB><TAB> properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB> return num_points , properties","if b""element"" in line :","if b""num_points"" not in line :",73.75764226369441,96.83,False
2150,"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB><TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB><TAB> for finfo in self . data : <TAB><TAB><TAB> self . __update_editor_margins ( finfo . editor ) <TAB><TAB><TAB> finfo . cleanup_analysis_results ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if current_finfo is not finfo : <TAB><TAB><TAB><TAB><TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 )",if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,if run_pyflakes is not None and run_pep8 is not None :,64.47302254718029,93.70,False
2151,"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB><TAB> line = line and line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> line_modules = line . split ( ) <TAB><TAB> for module in line_modules : <TAB><TAB><TAB> if module . endswith ( self . default_indicator ) : <TAB><TAB><TAB><TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB><TAB><TAB> module_parts = module . split ( "" / "" ) <TAB><TAB><TAB> module_version = None <TAB><TAB><TAB> if len ( module_parts ) == 2 : <TAB><TAB><TAB><TAB> module_version = module_parts [ 1 ] <TAB><TAB><TAB> module_name = module_parts [ 0 ] <TAB><TAB><TAB> yield module_name , module_version","if not line or line . startswith ( ""-"" ) :",if not line :,70.62847586590308,96.25,False
2152,"def _set_trailing_size ( self , size ) : <TAB> if self . is_free ( ) : <TAB><TAB> next_chunk = self . next_chunk ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . state . memory . store ( next_chunk . base , size , self . state . arch . bytes )",if next_chunk is not None :,if next_chunk :,64.5370575634742,94.83,False
2153,"def _execute_for_all_tables ( self , app , bind , operation , skip_tables = False ) : <TAB> app = self . get_app ( app ) <TAB> if bind == "" __all__ "" : <TAB><TAB> binds = [ None ] + list ( app . config . get ( "" SQLALCHEMY_BINDS "" ) or ( ) ) <TAB> elif isinstance ( bind , string_types ) or bind is None : <TAB><TAB> binds = [ bind ] <TAB> else : <TAB><TAB> binds = bind <TAB> for bind in binds : <TAB><TAB> extra = { } <TAB><TAB> <MASK> <TAB><TAB><TAB> tables = self . get_tables_for_bind ( bind ) <TAB><TAB><TAB> extra [ "" tables "" ] = tables <TAB><TAB> op = getattr ( self . Model . metadata , operation ) <TAB><TAB> op ( bind = self . get_engine ( app , bind ) , * * extra )",if not skip_tables :,if skip_tables :,94.53671175091276,98.94,False
2154,"def getFileName ( ) : <TAB> extension = "" .json "" <TAB> file = "" %s -stats "" % self . clusterName <TAB> counter = 0 <TAB> while True : <TAB><TAB> suffix = str ( counter ) . zfill ( 3 ) + extension <TAB><TAB> fullName = os . path . join ( self . statsPath , file + suffix ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return fullName <TAB><TAB> counter + = 1",if not os . path . exists ( fullName ) :,if os . path . exists ( fullName ) :,91.84091339747515,97.87,False
2155,def logic ( ) : <TAB> # direction <TAB> if goRight == ACTIVE : <TAB><TAB> dir . next = DirType . RIGHT <TAB><TAB> run . next = True <TAB> elif goLeft == ACTIVE : <TAB><TAB> dir . next = DirType . LEFT <TAB><TAB> run . next = True <TAB> # stop <TAB> if stop == ACTIVE : <TAB><TAB> run . next = False <TAB> # counter action <TAB> if run : <TAB><TAB> <MASK> <TAB><TAB><TAB> q . next [ 4 : 1 ] = q [ 3 : ] <TAB><TAB><TAB> q . next [ 0 ] = not q [ 3 ] <TAB><TAB> else : <TAB><TAB><TAB> q . next [ 3 : ] = q [ 4 : 1 ] <TAB><TAB><TAB> q . next [ 3 ] = not q [ 0 ],if dir == DirType . LEFT :,if q [ 0 ] :,72.67242235675248,96.61,False
2156,"def test_broadcast ( self ) : <TAB> """"""Test example broadcast functionality."""""" <TAB> self . create_lang_connection ( "" 1000000000 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000001 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000002 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000003 "" , "" es "" ) <TAB> self . create_lang_connection ( "" 1000000004 "" , "" es "" ) <TAB> app . lang_broadcast ( ) <TAB> self . assertEqual ( 2 , len ( self . outbound ) ) <TAB> for message in self . outbound : <TAB><TAB> if message . text == "" hello "" : <TAB><TAB><TAB> self . assertEqual ( 3 , len ( message . connections ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( 2 , len ( message . connections ) )","elif message . text == ""hola"" :","elif message . text == ""hello2"" :",74.15872603781199,98.90,False
2157,"def get_ovf_env ( dirname ) : <TAB> env_names = ( "" ovf-env.xml "" , "" ovf_env.xml "" , "" OVF_ENV.XML "" , "" OVF-ENV.XML "" ) <TAB> for fname in env_names : <TAB><TAB> full_fn = os . path . join ( dirname , fname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> contents = util . load_file ( full_fn ) <TAB><TAB><TAB><TAB> return ( fname , contents ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> util . logexc ( LOG , "" Failed loading ovf file  %s "" , full_fn ) <TAB> return ( None , False )",if os . path . isfile ( full_fn ) :,if os . path . isfile ( full_fn ) :,100.0,100.00,True
2158,"def _calc_offsets_children ( self , offset , is_last ) : <TAB> if self . elems : <TAB><TAB> elem_last = self . elems [ - 1 ] <TAB><TAB> for elem in self . elems : <TAB><TAB><TAB> offset = elem . _calc_offsets ( offset , ( elem is elem_last ) ) <TAB><TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> elif not self . props or self . id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL : <TAB><TAB> <MASK> <TAB><TAB><TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> return offset",if not is_last :,if is_last :,66.7497264575367,98.39,False
2159,"def publish_state ( cls , payload , state ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> if state == action_constants . LIVEACTION_STATUS_REQUESTED : <TAB><TAB><TAB><TAB> cls . process ( payload ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB><TAB> traceback . print_exc ( ) <TAB><TAB> print ( payload )","if isinstance ( payload , LiveActionDB ) :",if state :,66.64519361963266,94.39,False
2160,"def log_predictive_density ( self , x_test , y_test , Y_metadata = None ) : <TAB> if isinstance ( x_test , list ) : <TAB><TAB> x_test , y_test , ind = util . multioutput . build_XY ( x_test , y_test ) <TAB><TAB> <MASK> <TAB><TAB><TAB> Y_metadata = { "" output_index "" : ind , "" trials "" : np . ones ( ind . shape ) } <TAB> return super ( MultioutputGP , self ) . log_predictive_density ( x_test , y_test , Y_metadata )",if Y_metadata is None :,if Y_metadata is None :,100.0,100.00,True
2161,"def minimalBases ( classes ) : <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3 : # pragma: no cover <TAB><TAB> classes = [ c for c in classes if c is not ClassType ] <TAB> candidates = [ ] <TAB> for m in classes : <TAB><TAB> for n in classes : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> # m has no subclasses in 'classes' <TAB><TAB><TAB> if m in candidates : <TAB><TAB><TAB><TAB> candidates . remove ( m ) # ensure that we're later in the list <TAB><TAB><TAB> candidates . append ( m ) <TAB> return candidates","if issubclass ( n , m ) and m is not n :",if n is not ClassType :,95.04091189425824,94.30,False
2162,"def apply ( self , operations , rotations = None , * * kwargs ) : <TAB> rotations = rotations or [ ] <TAB> # apply the circuit operations <TAB> for i , operation in enumerate ( operations ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise DeviceError ( <TAB><TAB><TAB><TAB> "" Operation  {}  cannot be used after other Operations have already been applied  "" <TAB><TAB><TAB><TAB> "" on a  {}  device. "" . format ( operation . name , self . short_name ) <TAB><TAB><TAB> ) <TAB> for operation in operations : <TAB><TAB> self . _apply_operation ( operation ) <TAB> # store the pre-rotated state <TAB> self . _pre_rotated_state = self . _state <TAB> # apply the circuit rotations <TAB> for operation in rotations : <TAB><TAB> self . _apply_operation ( operation )","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",if i % self . _num_operations == 0 :,94.90600081713367,93.70,False
2163,"def __str__ ( self ) : <TAB> txt = str ( self . _called ) <TAB> if self . call_gas or self . call_value : <TAB><TAB> gas = f "" gas:  { self . call_gas } "" if self . call_gas else "" "" <TAB><TAB> value = f "" value:  { self . call_value } "" if self . call_value else "" "" <TAB><TAB> salt = f "" salt:  { self . call_salt } "" if self . call_salt else "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> options = [ gas , value , salt ] <TAB><TAB><TAB> txt + = "" { "" + "" , "" . join ( [ o for o in options if o != "" "" ] ) + "" } "" <TAB> return txt + "" ( "" + "" , "" . join ( [ str ( a ) for a in self . _arguments ] ) + "" ) """,if gas or value or salt :,if self . call_salt :,83.23455304452601,97.59,False
2164,"def pop ( self ) : <TAB> """"""Pop a nonterminal.  (Internal)"""""" <TAB> popdfa , popstate , popnode = self . stack . pop ( ) <TAB> newnode = self . convert ( self . grammar , popnode ) <TAB> if newnode is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> dfa , state , node = self . stack [ - 1 ] <TAB><TAB><TAB> node . children . append ( newnode ) <TAB><TAB> else : <TAB><TAB><TAB> self . rootnode = newnode",if self . stack :,if self . stack :,100.0,100.00,True
2165,"def pollpacket ( self , wait ) : <TAB> self . _stage0 ( ) <TAB> if len ( self . buffer ) < self . bufneed : <TAB><TAB> r , w , x = select . select ( [ self . sock . fileno ( ) ] , [ ] , [ ] , wait ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> try : <TAB><TAB><TAB> s = self . sock . recv ( BUFSIZE ) <TAB><TAB> except socket . error : <TAB><TAB><TAB> raise EOFError <TAB><TAB> if len ( s ) == 0 : <TAB><TAB><TAB> raise EOFError <TAB><TAB> self . buffer + = s <TAB><TAB> self . _stage0 ( ) <TAB> return self . _stage1 ( )",if len ( r ) == 0 :,if r == 0 :,70.51615942861254,97.36,False
2166,"def increaseToolReach ( self ) : <TAB> if self . draggingFace is not None : <TAB><TAB> d = ( 1 , - 1 ) [ self . draggingFace & 1 ] <TAB><TAB> <MASK> # xxxxx y <TAB><TAB><TAB> d = - d <TAB><TAB> self . draggingY + = d <TAB><TAB> x , y , z = self . editor . mainViewport . cameraPosition <TAB><TAB> pos = [ x , y , z ] <TAB><TAB> pos [ self . draggingFace >> 1 ] + = d <TAB><TAB> self . editor . mainViewport . cameraPosition = tuple ( pos ) <TAB> else : <TAB><TAB> self . cloneCameraDistance = self . editor . _incrementReach ( self . cloneCameraDistance ) <TAB> return True",if self . draggingFace >> 1 != 1 :,if d < 0 :,88.73306640451442,94.21,False
2167,"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB><TAB> if box == self . level . bounds : <TAB><TAB><TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB> return <TAB><TAB> selectedChunks = self . selectedChunks <TAB><TAB> boxedChunks = set ( box . chunkPositions ) <TAB><TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB><TAB><TAB> remove = True <TAB><TAB> <MASK> <TAB><TAB><TAB> selectedChunks . difference_update ( boxedChunks ) <TAB><TAB> else : <TAB><TAB><TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if remove and not add :,if remove :,74.08515098031967,97.61,False
2168,"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ProjectForm , self ) . __init__ ( * args , * * kwargs ) <TAB> if self . instance . id : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . fields [ "" localfiletype "" ] . widget . attrs [ "" disabled "" ] = True <TAB><TAB><TAB> self . fields [ "" localfiletype "" ] . required = False <TAB><TAB> if ( <TAB><TAB><TAB> self . instance . treestyle != "" auto "" <TAB><TAB><TAB> and self . instance . translationproject_set . count ( ) <TAB><TAB><TAB> and self . instance . treestyle == self . instance . _detect_treestyle ( ) <TAB><TAB> ) : <TAB><TAB><TAB> self . fields [ "" treestyle "" ] . widget . attrs [ "" disabled "" ] = True <TAB><TAB><TAB> self . fields [ "" treestyle "" ] . required = False",if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,"if self . instance . localfiletype != ""auto"" :",91.9574837196096,91.99,False
2169,"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB><TAB> if arg is None : <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( arg , bytes ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = bytes <TAB><TAB> else : <TAB><TAB><TAB> if return_type is bytes : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = str <TAB> if return_type is None : <TAB><TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if return_type is str :,if return_type is None :,92.60821323663363,98.99,False
2170,"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB><TAB> inst . add ( gadget . _gadget ) <TAB><TAB> if len ( inst ) > count : <TAB><TAB><TAB> count = len ( inst ) <TAB><TAB><TAB> toReturn . append ( gadget ) <TAB><TAB><TAB> added = True <TAB><TAB> <MASK> <TAB><TAB><TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB><TAB><TAB> added = False <TAB> return toReturn",if callback :,if callback :,100.0,100.00,True
2171,"def send_all ( self , data : bytes ) : <TAB> with self . _conflict_detector : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise _core . ClosedResourceError ( "" this pipe is already closed "" ) <TAB><TAB> if not data : <TAB><TAB><TAB> await _core . checkpoint ( ) <TAB><TAB><TAB> return <TAB><TAB> try : <TAB><TAB><TAB> written = await _core . write_overlapped ( self . _handle_holder . handle , data ) <TAB><TAB> except BrokenPipeError as ex : <TAB><TAB><TAB> raise _core . BrokenResourceError from ex <TAB><TAB> # By my reading of MSDN, this assert is guaranteed to pass so long <TAB><TAB> # as the pipe isn't in nonblocking mode, but... let's just <TAB><TAB> # double-check. <TAB><TAB> assert written == len ( data )",if self . _handle_holder . closed :,if self . _closed :,91.60193218855268,97.56,False
2172,"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB> print ( "" V "" , value ) <TAB><TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB><TAB> param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB> param_node . int_ = value <TAB><TAB><TAB> elif isinstance ( value , float ) : <TAB><TAB><TAB><TAB> param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB> param_node . float_ = value",if self . use_prop or self . get_prop_name ( ) :,if self . sv_get ( ) :,93.26254035206046,94.33,False
2173,"def collect_active_inst_idx_list ( inst_beams , word_prob , inst_idx_to_position_map ) : <TAB> active_inst_idx_list = [ ] <TAB> for inst_idx , inst_position in inst_idx_to_position_map . items ( ) : <TAB><TAB> is_inst_complete = inst_beams [ inst_idx ] . advance ( word_prob [ inst_position ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> active_inst_idx_list + = [ inst_idx ] <TAB> return active_inst_idx_list",if not is_inst_complete :,if is_inst_complete :,73.39866479514954,98.30,False
2174,"def compare_member_req_resp_without_key ( self , request , response ) : <TAB> for user_response in resp_json ( response ) [ "" data "" ] : <TAB><TAB> for user_request in request : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> assert user_request [ "" role "" ] == user_response [ "" role "" ]","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :","if ""role"" in user_request and ""role"" in user_response :",63.24619900309345,82.87,False
2175,"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB><TAB> if name . endswith ( "" .py "" ) : <TAB><TAB><TAB> self . module_names . add ( name [ : - 3 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . module_names . add ( name )","elif ""."" not in name :","elif name . endswith ( "".pyc"" ) :",92.63731682971394,91.72,False
2176,"def _read_filter ( self , data ) : <TAB> if data : <TAB><TAB> if self . expected_inner_sha256 : <TAB><TAB><TAB> self . inner_sha . update ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . inner_md5 . update ( data ) <TAB> return data",if self . expected_inner_md5sum :,if self . expected_inner_md5 :,72.11282328646425,97.15,False
2177,"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB><TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> if s . consume_re ( _newline_esc_re ) : <TAB><TAB><TAB> pass <TAB><TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB><TAB><TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> s . expect_re ( _escapes_re ) <TAB><TAB><TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res )","if not s . consume ( ""\\"" ) :",if s . last ( ) . group ( 0 ) == _basicstr_re :,81.47372424669351,93.58,False
2178,"def process_response ( self , request , response ) : <TAB> if ( <TAB><TAB> response . status_code == 404 <TAB><TAB> and request . path_info . endswith ( "" / "" ) <TAB><TAB> and not is_valid_path ( request . path_info ) <TAB><TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB><TAB> # Use request.path because we munged app/locale in path_info. <TAB><TAB> newurl = request . path [ : - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> with safe_query_string ( request ) : <TAB><TAB><TAB><TAB> newurl + = "" ? "" + request . META . get ( "" QUERY_STRING "" , "" "" ) <TAB><TAB> return HttpResponsePermanentRedirect ( newurl ) <TAB> else : <TAB><TAB> return response",if request . GET :,"if request . GET . get ( ""QUERY_STRING"" , """" ) :",98.03124888435406,94.26,False
2179,"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB><TAB> del obj [ k ] <TAB><TAB> <MASK> <TAB><TAB><TAB> k = dumps ( k ) <TAB><TAB><TAB> # Keep track of which keys need to be decoded when loading. <TAB><TAB><TAB> if Types . KEYS not in obj : <TAB><TAB><TAB><TAB> obj [ Types . KEYS ] = [ ] <TAB><TAB><TAB> obj [ Types . KEYS ] . append ( k ) <TAB><TAB> obj [ k ] = convertObjects ( v ) <TAB> return obj","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :","if isinstance ( k , dict ) :",68.39550420441311,91.99,False
2180,"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB><TAB> return "" <recursion> "" <TAB> try : <TAB><TAB> self . _in_repr = True <TAB><TAB> <MASK> <TAB><TAB><TAB> status = "" computed,  "" <TAB><TAB><TAB> if self . error ( ) is None : <TAB><TAB><TAB><TAB> if self . value ( ) is self : <TAB><TAB><TAB><TAB><TAB> status + = "" = self "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> status = "" isn ' t computed "" <TAB><TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB><TAB> self . _in_repr = False",if self . is_computed ( ) :,if self . is_computed ( ) :,100.0,100.00,True
2181,"def allocate_network ( ipv = "" ipv4 "" ) : <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try : <TAB><TAB> cx = httplib . HTTPConnection ( "" localhost:7623 "" ) <TAB><TAB> cx . request ( "" POST "" , "" /v1/network/ %s / "" % ipv , body = dtcd_uuid ) <TAB><TAB> resp = cx . getresponse ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> network = netaddr . IPNetwork ( resp . read ( ) . decode ( "" utf-8 "" ) ) <TAB><TAB> cx . close ( ) <TAB> except Exception : <TAB><TAB> pass <TAB> if network is None : <TAB><TAB> network = network_pool [ ipv ] . pop ( ) <TAB><TAB> allocations [ network ] = True <TAB> return network",if resp . status == 200 :,if resp . status_code == 200 :,99.05758164253908,98.37,False
2182,"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB><TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB><TAB> if ind < len ( strings ) and strings [ ind ] . startswith ( ""   "" ) : <TAB><TAB><TAB> ind + = 1 <TAB><TAB> else : <TAB><TAB><TAB> if start < ind : <TAB><TAB><TAB><TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB> start = ind <TAB><TAB><TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB><TAB> <MASK> <TAB><TAB><TAB> lines = line . split ( "" : "" ) <TAB><TAB><TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d","if "":"" in line and len ( line ) > 0 :","if line . startswith ( ""args:"" ) :",79.28829647209116,95.66,False
2183,"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> print ( "" killing  %s "" % member ) <TAB><TAB><TAB> proc = hosts [ member ] [ "" proc "" ] <TAB><TAB><TAB> # Not sure if cygwin makes sense here... <TAB><TAB><TAB> if sys . platform in ( "" win32 "" , "" cygwin "" ) : <TAB><TAB><TAB><TAB> os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . kill ( proc . pid , sig ) <TAB><TAB> except OSError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> print ( "" %s  already dead? "" % member )",if ha_tools_debug :,if verbose :,97.91626458807798,94.62,False
2184,"def check ( self ) : <TAB> for path in self . paths : <TAB><TAB> response = self . http_request ( <TAB><TAB><TAB> method = "" GET "" , <TAB><TAB><TAB> path = path , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if any ( <TAB><TAB><TAB> map ( <TAB><TAB><TAB><TAB> lambda x : x in response . text , <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> "" report.db.server.name "" , <TAB><TAB><TAB><TAB><TAB> "" report.db.server.sa.pass "" , <TAB><TAB><TAB><TAB><TAB> "" report.db.server.user.pass "" , <TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB> ) <TAB><TAB> ) : <TAB><TAB><TAB> self . valid = path <TAB><TAB><TAB> return True # target is vulnerable <TAB> return False # target not vulnerable",if response is None :,if response is None :,100.0,100.00,True
2185,"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB><TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB><TAB> if r . ok : <TAB><TAB><TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB><TAB><TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB><TAB><TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB><TAB><TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB><TAB><TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB><TAB><TAB> time . sleep ( 1 ) # spider rule <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> return result",if not last_date :,if r . status_code == 200 :,98.3250257619414,96.69,False
2186,"def button_press_cb ( self , tdw , event ) : <TAB> self . _update_zone_and_cursors ( tdw , event . x , event . y ) <TAB> if self . _zone in ( _EditZone . CREATE_FRAME , _EditZone . REMOVE_FRAME ) : <TAB><TAB> button = event . button <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _click_info = ( button , self . _zone ) <TAB><TAB><TAB> return False <TAB> return super ( FrameEditMode , self ) . button_press_cb ( tdw , event )",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,if button :,69.45805232969073,88.15,False
2187,"def first_timestep ( ) : <TAB> assignment = self . has_previous . assign ( <TAB><TAB> value = tf_util . constant ( value = True , dtype = "" bool "" ) , read_value = False <TAB> ) <TAB> with tf . control_dependencies ( control_inputs = ( assignment , ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> current = x <TAB><TAB> else : <TAB><TAB><TAB> current = tf . expand_dims ( input = x , axis = ( self . axis + 1 ) ) <TAB><TAB> multiples = tuple ( <TAB><TAB><TAB> self . length if dims == self . axis + 1 else 1 <TAB><TAB><TAB> for dims in range ( self . output_spec ( ) . rank + 1 ) <TAB><TAB> ) <TAB><TAB> return tf . tile ( input = current , multiples = multiples )",if self . concatenate :,if self . axis == 0 :,81.62220316658352,97.52,False
2188,"def main ( ) - > None : <TAB> onefuzz = Onefuzz ( ) <TAB> jobs = onefuzz . jobs . list ( ) <TAB> for job in jobs : <TAB><TAB> print ( <TAB><TAB><TAB> "" job: "" , <TAB><TAB><TAB> str ( job . job_id ) [ : 8 ] , <TAB><TAB><TAB> "" : "" . join ( [ job . config . project , job . config . name , job . config . build ] ) , <TAB><TAB> ) <TAB><TAB> for task in onefuzz . tasks . list ( job_id = job . job_id ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> ""      "" , <TAB><TAB><TAB><TAB> str ( task . task_id ) [ : 8 ] , <TAB><TAB><TAB><TAB> task . config . task . type , <TAB><TAB><TAB><TAB> task . config . task . target_exe , <TAB><TAB><TAB> )","if task . state in [ ""stopped"" , ""stopping"" ] :","if task . config . task . type == ""test"" :",95.85398064432844,95.82,False
2189,"def update_stack ( self , full_name , template_url , parameters , tags ) : <TAB> """"""Updates an existing stack in CloudFormation."""""" <TAB> try : <TAB><TAB> logger . info ( "" Attempting to update stack  %s . "" , full_name ) <TAB><TAB> self . conn . cloudformation . update_stack ( <TAB><TAB><TAB> full_name , <TAB><TAB><TAB> template_url = template_url , <TAB><TAB><TAB> parameters = parameters , <TAB><TAB><TAB> tags = tags , <TAB><TAB><TAB> capabilities = [ "" CAPABILITY_IAM "" ] , <TAB><TAB> ) <TAB><TAB> return SUBMITTED <TAB> except BotoServerError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . info ( "" Stack  %s  did not change, not updating. "" , full_name ) <TAB><TAB><TAB> return SKIPPED <TAB><TAB> raise","if ""No updates are to be performed."" in e . message :",if e . response . status_code == 404 :,76.08878314564582,94.51,False
2190,"def header_tag_files ( env , files , legal_header , script_files = False ) : <TAB> """"""Apply the legal_header to the list of files"""""" <TAB> try : <TAB><TAB> import apply_legal_header <TAB> except : <TAB><TAB> xbc . cdie ( "" XED ERROR: mfile.py could not find scripts directory "" ) <TAB> for g in files : <TAB><TAB> print ( "" G:  "" , g ) <TAB><TAB> for f in mbuild . glob ( g ) : <TAB><TAB><TAB> print ( "" F:  "" , f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> apply_legal_header . apply_header_to_data_file ( legal_header , f ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> apply_legal_header . apply_header_to_source_file ( legal_header , f )",if script_files :,if script_files :,100.0,100.00,True
2191,"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB><TAB> if reverseConn not in cmd : <TAB><TAB><TAB> cmds = cmd . split ( "" & "" ) <TAB><TAB><TAB> for c in cmds : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB><TAB> else : <TAB><TAB><TAB> b64cmd = base64 . b64encode ( cmd ) <TAB><TAB><TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB><TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd",if len ( c ) > 0 :,if reverseConn == c :,91.12738722810911,96.71,False
2192,"def test_form ( self ) : <TAB> n_qubits = 6 <TAB> random_operator = get_fermion_operator ( random_interaction_operator ( n_qubits ) ) <TAB> chemist_operator = chemist_ordered ( random_operator ) <TAB> for term , _ in chemist_operator . terms . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> self . assertTrue ( term [ 0 ] [ 1 ] ) <TAB><TAB><TAB> self . assertTrue ( term [ 2 ] [ 1 ] ) <TAB><TAB><TAB> self . assertFalse ( term [ 1 ] [ 1 ] ) <TAB><TAB><TAB> self . assertFalse ( term [ 3 ] [ 1 ] ) <TAB><TAB><TAB> self . assertTrue ( term [ 0 ] [ 0 ] > term [ 2 ] [ 0 ] ) <TAB><TAB><TAB> self . assertTrue ( term [ 1 ] [ 0 ] > term [ 3 ] [ 0 ] )",if len ( term ) == 2 or not len ( term ) :,if len ( term ) == 3 :,69.00871278949565,96.62,False
2193,"def do ( server , handler , config , modargs ) : <TAB> data = [ ] <TAB> clients = server . get_clients ( handler . default_filter ) <TAB> if not clients : <TAB><TAB> return <TAB> for client in clients : <TAB><TAB> tags = config . tags ( client . node ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tags . remove ( * modargs . remove ) <TAB><TAB> if modargs . add : <TAB><TAB><TAB> tags . add ( * modargs . add ) <TAB><TAB> data . append ( { "" ID "" : client . node ( ) , "" TAGS "" : tags } ) <TAB> config . save ( project = modargs . write_project , user = modargs . write_user ) <TAB> handler . display ( Table ( data ) )",if modargs . remove :,if modargs . remove :,100.0,100.00,True
2194,"def validate ( self ) : <TAB> if self . data . get ( "" state "" ) == "" enabled "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PolicyValidationError ( <TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB> "" redshift logging enablement requires `bucket`  "" <TAB><TAB><TAB><TAB><TAB> "" and `prefix` specification on  %s "" % ( self . manager . data , ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return self","if ""bucket"" not in self . data :","if self . data . get ( ""bucket"" ) and self . data . get ( """,59.536898252187775,89.68,False
2195,"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB><TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sx , sy = m . groups ( ) <TAB><TAB><TAB> x = colname2num ( sx ) <TAB><TAB><TAB> y = int ( sy ) <TAB><TAB><TAB> if x1 < = x < = x2 and y1 < = y < = y2 : <TAB><TAB><TAB><TAB> part = cellname ( x + dx , y + dy ) <TAB><TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment )",if m is not None :,if m :,77.83977975399648,98.03,False
2196,"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB><TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB><TAB> if v is None : <TAB><TAB><TAB> continue <TAB><TAB> v = str ( v ) <TAB><TAB> if len ( v ) == 0 and not allow_empty : <TAB><TAB><TAB> continue <TAB><TAB> contents [ k ] = v <TAB><TAB> updated_am + = 1 <TAB> if updated_am : <TAB><TAB> lines = [ <TAB><TAB><TAB> str ( contents ) , <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB><TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 )",if not exists :,if not exists :,100.0,100.00,True
2197,"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB><TAB> if desc . getAttributeNS ( RDF_NAMESPACE , "" about "" ) == aboutUri : <TAB><TAB><TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield attr <TAB><TAB><TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB><TAB><TAB><TAB> yield element",if attr != None :,if attr :,70.06148954984374,96.72,False
2198,"def get_store_name_from_connection_string ( connection_string ) : <TAB> if is_valid_connection_string ( connection_string ) : <TAB><TAB> segments = dict ( seg . split ( "" = "" , 1 ) for seg in connection_string . split ( "" ; "" ) ) <TAB><TAB> endpoint = segments . get ( "" Endpoint "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return endpoint . split ( "" // "" ) [ 1 ] . split ( "" . "" ) [ 0 ] <TAB> return None",if endpoint :,if endpoint :,100.0,100.00,True
2199,"def insertLoopTemplate ( self , layout ) : <TAB> col = layout . column ( align = True ) <TAB> for socket in self . activeNode . outputs : <TAB><TAB> <MASK> <TAB><TAB><TAB> props = col . operator ( <TAB><TAB><TAB><TAB> "" an.insert_loop_for_iterator "" , <TAB><TAB><TAB><TAB> text = "" Loop through  {} "" . format ( repr ( socket . getDisplayedName ( ) ) ) , <TAB><TAB><TAB><TAB> icon = "" MOD_ARRAY "" , <TAB><TAB><TAB> ) <TAB><TAB><TAB> props . nodeIdentifier = self . activeNode . identifier <TAB><TAB><TAB> props . socketIndex = socket . getIndex ( )",if not socket . hide and isList ( socket . bl_idname ) :,if socket . isVisible ( ) :,72.48573431905926,93.37,False
2200,"def do_task ( self , task ) : <TAB> self . running_task + = 1 <TAB> result = yield gen . Task ( self . fetcher . fetch , task ) <TAB> type , task , response = result . args <TAB> self . processor . on_task ( task , response ) <TAB> # do with message <TAB> while not self . processor . inqueue . empty ( ) : <TAB><TAB> _task , _response = self . processor . inqueue . get ( ) <TAB><TAB> self . processor . on_task ( _task , _response ) <TAB> # do with results <TAB> while not self . processor . result_queue . empty ( ) : <TAB><TAB> _task , _result = self . processor . result_queue . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . result_worker . on_result ( _task , _result ) <TAB> self . running_task - = 1",if self . result_worker :,if _result :,98.51530995731508,97.31,False
2201,"def _parse_config_result ( data ) : <TAB> command_list = ""  ;  "" . join ( [ x . strip ( ) for x in data [ 0 ] ] ) <TAB> config_result = data [ 1 ] <TAB> if isinstance ( config_result , list ) : <TAB><TAB> result = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> for key in config_result [ 0 ] : <TAB><TAB><TAB><TAB> result + = config_result [ 0 ] [ key ] <TAB><TAB><TAB> config_result = result <TAB><TAB> else : <TAB><TAB><TAB> config_result = config_result [ 0 ] <TAB> return [ command_list , config_result ]","if isinstance ( config_result [ 0 ] , dict ) :","if isinstance ( config_result [ 0 ] , dict ) :",100.0,100.00,True
2202,"def load_api_handler ( self , mod_name ) : <TAB> for name , hdl in API_HANDLERS : <TAB><TAB> name = name . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> handler = self . mods . get ( name ) <TAB><TAB><TAB> if not handler : <TAB><TAB><TAB><TAB> handler = hdl ( self . emu ) <TAB><TAB><TAB><TAB> self . mods . update ( { name : handler } ) <TAB><TAB><TAB> return handler <TAB> return None",if mod_name and name == mod_name . lower ( ) :,if name . startswith ( mod_name ) :,74.13544882010112,92.00,False
2203,def heal ( self ) : <TAB> if not self . doctors : <TAB><TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB><TAB> # get proc every time for latest state <TAB><TAB> proc = PipelineProcess . objects . get ( id = proc_id ) <TAB><TAB> if not proc . is_alive or proc . is_frozen : <TAB><TAB><TAB> continue <TAB><TAB> for dr in self . doctors : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dr . cure ( proc ) <TAB><TAB><TAB><TAB> break,if dr . confirm ( proc ) :,if dr . is_alive :,96.98785536639731,96.84,False
2204,"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB><TAB> if len ( kwargs ) : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB><TAB><TAB><TAB><TAB> cls . __name__ <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return super ( ) . __new__ ( cls ) <TAB><TAB> if isinstance ( args [ 0 ] , cls ) : <TAB><TAB><TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )",if not args [ 0 ] :,"if isinstance ( args [ 0 ] , ( list , tuple ) ) :",69.51619068870654,94.67,False
2205,"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try : <TAB><TAB> A , B = self [ 0 ] , other [ 0 ] <TAB><TAB> # uses logical clock value first <TAB><TAB> <MASK> # use logical clock if available <TAB><TAB><TAB> if A == B : # equal clocks use lower process id <TAB><TAB><TAB><TAB> return self [ 2 ] < other [ 2 ] <TAB><TAB><TAB> return A < B <TAB><TAB> return self [ 1 ] < other [ 1 ] # ... or use timestamp <TAB> except IndexError : <TAB><TAB> return NotImplemented",if A and B :,if A is not None :,72.94369204499748,97.38,False
2206,"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB><TAB> if str . lower ( key ) == str . lower ( resource_provider ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return GeneralPrivateEndpointClient ( <TAB><TAB><TAB><TAB><TAB> key , <TAB><TAB><TAB><TAB><TAB> value [ "" api_version "" ] , <TAB><TAB><TAB><TAB><TAB> value [ "" support_list_or_not "" ] , <TAB><TAB><TAB><TAB><TAB> value [ "" resource_get_api_version "" ] , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return value ( ) <TAB> raise CLIError ( <TAB><TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> )","if isinstance ( value , dict ) :","if value [ ""api_type"" ] == ""private"" :",95.24972463653152,94.50,False
2207,"def test_progressbar_format_pos ( runner , pos , length ) : <TAB> with _create_progress ( length , length_known = length != 0 , pos = pos ) as progress : <TAB><TAB> result = progress . format_pos ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert result == f "" { pos } / { length } "" <TAB><TAB> else : <TAB><TAB><TAB> assert result == str ( pos )",if progress . length_known :,if length :,66.79839937122199,94.65,False
2208,"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB><TAB> if not Placeholder . check_resolved ( v . size ) : <TAB><TAB><TAB> continue <TAB><TAB> height , width = TextureShape . get ( v ) <TAB><TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> flag_changed = True <TAB><TAB><TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed",if not v . has_attribute ( SplitTarget ) :,if v . size == 1 :,74.47131692293824,94.82,False
2209,"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB><TAB> tmp + = "" m  "" <TAB><TAB> for col in row : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp + = "" . "" <TAB><TAB><TAB> elif col == BARRIER : <TAB><TAB><TAB><TAB> tmp + = "" % "" <TAB><TAB><TAB> elif col == FOOD : <TAB><TAB><TAB><TAB> tmp + = "" * "" <TAB><TAB><TAB> elif col == UNSEEN : <TAB><TAB><TAB><TAB> tmp + = "" ? "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> players [ col ] = True <TAB><TAB><TAB><TAB> tmp + = chr ( col + 97 ) <TAB><TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",if col == LAND :,if col == NONE :,99.19101256226242,99.16,False
2210,"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB><TAB> if self . __conn is not None : <TAB><TAB><TAB> self . __conn . close ( ) <TAB><TAB><TAB> self . __conn = None <TAB><TAB> for _ , l in self . _library_cache . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB><TAB><TAB><TAB> l . _reset ( ) # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth","if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :","if hasattr ( l , ""_reset"" ) :",93.83131445892407,95.37,False
2211,"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB><TAB> x = cand . creator <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if x not in fan_out : <TAB><TAB><TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB><TAB><TAB> heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB><TAB> fan_out [ x ] + = 1",if x is None :,if x is None :,100.0,100.00,True
2212,"def on_task_modify ( self , task , config ) : <TAB> for entry in task . entries : <TAB><TAB> <MASK> <TAB><TAB><TAB> size = entry [ "" torrent "" ] . size / 1024 / 1024 <TAB><TAB><TAB> log . debug ( "" %s  size:  %s  MB "" % ( entry [ "" title "" ] , size ) ) <TAB><TAB><TAB> entry [ "" content_size "" ] = size","if ""torrent"" in entry :","if ""torrent"" in entry and ""torrent"" in entry :",96.51147221094229,94.89,False
2213,"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB> results = [ ] <TAB><TAB> if self . do_corr_and_slope : <TAB><TAB><TAB> if object_name == "" Image "" : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" ] <TAB><TAB> if self . do_overlap : <TAB><TAB><TAB> results + = [ "" Overlap "" , "" K "" ] <TAB><TAB> if self . do_manders : <TAB><TAB><TAB> results + = [ "" Manders "" ] <TAB><TAB> if self . do_rwc : <TAB><TAB><TAB> results + = [ "" RWC "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> results + = [ "" Costes "" ] <TAB><TAB> return results <TAB> return [ ]",if self . do_costes :,if self . do_costes :,100.0,100.00,True
2214,"def create_root ( cls , site = None , title = "" Root "" , request = None , * * kwargs ) : <TAB> if not site : <TAB><TAB> site = Site . objects . get_current ( ) <TAB> root_nodes = cls . objects . root_nodes ( ) . filter ( site = site ) <TAB> if not root_nodes : <TAB><TAB> article = Article ( ) <TAB><TAB> revision = ArticleRevision ( title = title , * * kwargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> revision . set_from_request ( request ) <TAB><TAB> article . add_revision ( revision , save = True ) <TAB><TAB> article . save ( ) <TAB><TAB> root = cls . objects . create ( site = site , article = article ) <TAB><TAB> article . add_object_relation ( root ) <TAB> else : <TAB><TAB> root = root_nodes [ 0 ] <TAB> return root",if request :,if request :,100.0,100.00,True
2215,"def get ( self , key ) : <TAB> filename = self . _get_filename ( key ) <TAB> try : <TAB><TAB> with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB> pickle_time = pickle . load ( f ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return pickle . load ( f ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . remove ( filename ) <TAB><TAB><TAB><TAB> return None <TAB> except ( IOError , OSError , pickle . PickleError ) : <TAB><TAB> return None",if pickle_time == 0 or pickle_time >= time ( ) :,if pickle_time < self . _max_age :,64.86016459053575,92.29,False
2216,"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_body ( message , value ) <TAB><TAB> elif name == "" EMAIL_ATTACHMENT "" : <TAB><TAB><TAB> self . add_attachment ( message , value ) <TAB><TAB> else : # From, To, Subject, etc. <TAB><TAB><TAB> self . set_option ( message , name , value , target ) <TAB> return message","if name == ""EMAIL_BODY"" :","if name == ""EMAIL_BODY"" :",100.0,100.00,True
2217,"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB><TAB> <MASK> <TAB><TAB><TAB> core . config . globalVariables [ name ] . append ( data ) <TAB><TAB> elif mode == "" add "" : <TAB><TAB><TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB><TAB> core . config . globalVariables [ name ] = data","if mode == ""append"" :","if mode == ""append"" :",100.0,100.00,True
2218,"def insert_errors ( <TAB> el , <TAB> errors , <TAB> form_id = None , <TAB> form_index = None , <TAB> error_class = "" error "" , <TAB> error_creator = default_error_creator , ) : <TAB> el = _find_form ( el , form_id = form_id , form_index = form_index ) <TAB> for name , error in errors . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for error_el , message in _find_elements_for_name ( el , name , error ) : <TAB><TAB><TAB> assert isinstance ( message , ( basestring , type ( None ) , ElementBase ) ) , ( <TAB><TAB><TAB><TAB> "" Bad message:  %r "" % message <TAB><TAB><TAB> ) <TAB><TAB><TAB> _insert_error ( error_el , message , error_class , error_creator )",if error is None :,if name == error_class :,96.23386531709738,96.96,False
2219,"def read ( self , item , recursive = False , sort = False ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _store [ item ] <TAB><TAB><TAB> raise KeyError ( item ) <TAB><TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> else : <TAB><TAB> return self . _read_dir ( item , recursive = recursive , sort = sort )",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if not recursive :,74.72831916437198,82.12,False
2220,"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB><TAB> for s in states : <TAB><TAB><TAB> ns = state_func ( s ) <TAB><TAB><TAB> if isinstance ( ns , SimState ) : <TAB><TAB><TAB><TAB> split . append ( ns ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> split . extend ( ns ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB><TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB><TAB> keep = states <TAB> return keep , split","elif isinstance ( ns , ( list , tuple , set ) ) :","elif isinstance ( ns , list ) :",94.41628213737773,96.15,False
2221,"def run ( self ) : <TAB> while self . runflag : <TAB><TAB> <MASK> <TAB><TAB><TAB> with self . lock : <TAB><TAB><TAB><TAB> tasks = list ( self . queue ) <TAB><TAB><TAB><TAB> self . queue . clear ( ) <TAB><TAB><TAB> while len ( tasks ) > 0 : <TAB><TAB><TAB><TAB> pathname , remotepath = tasks . pop ( 0 ) <TAB><TAB><TAB><TAB> self . bcloud_app . upload_page . add_bg_task ( pathname , remotepath ) <TAB><TAB><TAB> self . last = time ( ) <TAB><TAB> else : <TAB><TAB><TAB> sleep ( 1 )",if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,if self . queue :,88.66837030606841,90.85,False
2222,"def _append_patch ( self , patch_dir , patch_files ) : <TAB> for patch in patch_files : <TAB><TAB> <MASK> <TAB><TAB><TAB> tmp = patch <TAB><TAB><TAB> patch = { } <TAB><TAB><TAB> for key in tmp . keys ( ) : <TAB><TAB><TAB><TAB> patch [ os . path . join ( patch_dir , key ) ] = tmp [ key ] <TAB><TAB><TAB> self . patches . append ( patch ) <TAB><TAB> else : <TAB><TAB><TAB> self . patches . append ( os . path . join ( patch_dir , patch ) )",if type ( patch ) is dict :,"if isinstance ( patch , dict ) :",94.27145694715452,96.24,False
2223,"def __remote_port ( self ) : <TAB> port = 22 <TAB> if self . git_has_remote : <TAB><TAB> m = re . match ( r "" ^(.*?)?@([^/:]*):?([0-9]+)? "" , self . git_remote . url ) <TAB><TAB> if m : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> port = m . group ( 3 ) <TAB> return int ( port )",if m . group ( 3 ) :,if m . group ( 3 ) :,100.0,100.00,True
2224,"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len ( kwargs ) > 0 <TAB> kwargs . update ( infer_mode = infer_mode ) <TAB> is_training = not infer_mode if infer_mode is not None else self . training <TAB> helper = self . _train_helper if is_training else self . _infer_helper <TAB> if prefer_new or helper is None : <TAB><TAB> helper = self . create_helper ( * * kwargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _train_helper = helper <TAB><TAB> elif not is_training and self . _infer_helper is None : <TAB><TAB><TAB> self . _infer_helper = helper <TAB> return helper",if is_training and self . _train_helper is None :,if not is_training and self . _train_helper is None :,74.24906333064057,98.91,False
2225,"def flushChangeClassifications ( self , schedulerid , less_than = None ) : <TAB> if less_than is not None : <TAB><TAB> classifications = self . classifications . setdefault ( schedulerid , { } ) <TAB><TAB> for changeid in list ( classifications ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del classifications [ changeid ] <TAB> else : <TAB><TAB> self . classifications [ schedulerid ] = { } <TAB> return defer . succeed ( None )",if changeid < less_than :,if changeid < less_than :,100.0,100.00,True
2226,"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB><TAB> try : <TAB><TAB><TAB> pid = int ( pid ) <TAB><TAB><TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB><TAB><TAB> if name in pname : <TAB><TAB><TAB><TAB> return pid <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return pid <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name )","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :","if cmdline == ""all"" :",88.86466715136882,91.75,False
2227,"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB><TAB> <MASK> <TAB><TAB><TAB> seenUID = True <TAB><TAB> if part . type == "" body "" : <TAB><TAB><TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB><TAB> else : <TAB><TAB><TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB><TAB><TAB> yield f ( id , msg , write , flush ) <TAB><TAB> if part is not query [ - 1 ] : <TAB><TAB><TAB> space ( ) <TAB> if uid and not seenUID : <TAB><TAB> space ( ) <TAB><TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( )","if part . type == ""uid"" :",if part . uid :,94.88406458025571,96.76,False
2228,"def rx ( ) : <TAB> while True : <TAB><TAB> rx_i = rep . recv ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> rep . send ( b "" done "" ) <TAB><TAB><TAB> break <TAB><TAB> rep . send ( b "" i "" )","if rx_i == b""1000"" :","if rx_i == b""Done"" :",97.11282328646425,97.01,False
2229,"def test_search_incorrect_base_exception_1 ( self ) : <TAB> self . connection_1c . bind ( ) <TAB> try : <TAB><TAB> result = self . connection_1c . search ( <TAB><TAB><TAB> "" o=nonexistant "" , "" (cn=*) "" , search_scope = SUBTREE , attributes = [ "" cn "" , "" sn "" ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _ , result = self . connection_1c . get_response ( result ) <TAB><TAB> self . fail ( "" exception not raised "" ) <TAB> except LDAPNoSuchObjectResult : <TAB><TAB> pass",if not self . connection_1c . strategy . sync :,if not self . connection_1c . is_connected ( ) :,75.23956156894819,96.14,False
2230,"def value_from_datadict ( self , data , files , prefix ) : <TAB> count = int ( data [ "" %s -count "" % prefix ] ) <TAB> values_with_indexes = [ ] <TAB> for i in range ( 0 , count ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> values_with_indexes . append ( <TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB> int ( data [ "" %s - %d -order "" % ( prefix , i ) ] ) , <TAB><TAB><TAB><TAB> self . child_block . value_from_datadict ( <TAB><TAB><TAB><TAB><TAB> data , files , "" %s - %d -value "" % ( prefix , i ) <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> values_with_indexes . sort ( ) <TAB> return [ v for ( i , v ) in values_with_indexes ]","if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",if i == count - 1 :,94.67281150252475,93.84,False
2231,"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB><TAB> if not self . _nchannels : <TAB><TAB><TAB> raise Error ( "" # channels not specified "" ) <TAB><TAB> if not self . _sampwidth : <TAB><TAB><TAB> raise Error ( "" sample width not specified "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Error ( "" sampling rate not specified "" ) <TAB><TAB> self . _write_header ( datasize )",if not self . _framerate :,if not self . _samprate :,73.33971121134269,98.10,False
2232,def wait_til_ready ( cls ) : <TAB> while True : <TAB><TAB> now = time . time ( ) <TAB><TAB> next_iteration = now / / 1.0 + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> await cls . _clock . run_til ( next_iteration ) <TAB><TAB> await asyncio . sleep ( 1.0 ),if cls . connector . ready :,if cls . _clock . is_running ( next_iteration ) :,65.41227591041047,89.64,False
2233,"def lookup_actions ( self , resp ) : <TAB> actions = { } <TAB> for action , conditions in self . actions . items ( ) : <TAB><TAB> for condition , opts in conditions : <TAB><TAB><TAB> for key , val in condition : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if resp . match ( key [ : - 1 ] , val ) : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> if not resp . match ( key , val ) : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> actions [ action ] = opts <TAB> return actions","if key [ - 1 ] == ""!"" :","if key . endswith ( ""/"" ) :",94.48803451988262,95.58,False
2234,"def close ( self , wait = True , abort = False ) : <TAB> """"""Close the socket connection."""""" <TAB> if not self . closed and not self . closing : <TAB><TAB> self . closing = True <TAB><TAB> self . server . _trigger_event ( "" disconnect "" , self . sid , run_async = False ) <TAB><TAB> if not abort : <TAB><TAB><TAB> self . send ( packet . Packet ( packet . CLOSE ) ) <TAB><TAB> self . closed = True <TAB><TAB> self . queue . put ( None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . queue . join ( )",if wait :,if wait :,100.0,100.00,True
2235,"def model_parse ( self ) : <TAB> for name , submodel in self . model . named_modules ( ) : <TAB><TAB> for op_type in SUPPORTED_OP_TYPE : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . target_layer [ name ] = submodel <TAB><TAB><TAB><TAB> self . already_pruned [ name ] = 0","if isinstance ( submodel , op_type ) :",if name in self . target_layer and self . target_layer [ name ] == op,80.4497029017894,82.50,False
2236,"def pack_identifier ( self ) : <TAB> """"""Return a combined identifier for the whole pack if this has more than one episode."""""" <TAB> # Currently only supports ep mode <TAB> if self . id_type == "" ep "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" S %02d E %02d -E %02d "" % ( <TAB><TAB><TAB><TAB> self . season , <TAB><TAB><TAB><TAB> self . episode , <TAB><TAB><TAB><TAB> self . episode + self . episodes - 1 , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> return self . identifier <TAB> else : <TAB><TAB> return self . identifier",if self . episodes > 1 :,if self . episode < self . season :,97.22795441491446,96.64,False
2237,"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB><TAB> return <TAB> if args . strings and not args . no_content : <TAB><TAB> if type ( res ) == tuple : <TAB><TAB><TAB> f , v = res <TAB><TAB><TAB> if type ( f ) == unicode : <TAB><TAB><TAB><TAB> f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB> elif not args . content_only : <TAB><TAB><TAB> self . success ( res ) <TAB> else : <TAB><TAB> self . success ( res )",if type ( v ) == unicode :,if type ( v ) == unicode :,100.0,100.00,True
2238,"def _enable_contours_changed ( self , value ) : <TAB> """"""Turns on and off the contours."""""" <TAB> if self . module_manager is None : <TAB><TAB> return <TAB> if value : <TAB><TAB> self . actor . inputs = [ self . contour ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . actor . mapper . scalar_mode = "" use_cell_data "" <TAB> else : <TAB><TAB> self . actor . inputs = [ self . grid_plane ] <TAB><TAB> self . actor . mapper . scalar_mode = "" default "" <TAB> self . render ( )",if self . contour . filled_contours :,if self . contour_mode :,93.33995971137708,96.74,False
2239,"def _apply_abs_paths ( data , script_dir ) : <TAB> for flag_data in data . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> default = flag_data . get ( "" default "" ) <TAB><TAB> if ( <TAB><TAB><TAB> not default <TAB><TAB><TAB> or not isinstance ( default , six . string_types ) <TAB><TAB><TAB> or os . path . sep not in default <TAB><TAB> ) : <TAB><TAB><TAB> continue <TAB><TAB> abs_path = os . path . join ( script_dir , default ) <TAB><TAB> if os . path . exists ( abs_path ) : <TAB><TAB><TAB> flag_data [ "" default "" ] = abs_path","if not isinstance ( flag_data , dict ) :","if ""default"" not in flag_data :",91.88208502276626,95.81,False
2240,"def button_release ( self , mapper ) : <TAB> self . pressed = False <TAB> if self . waiting_task and self . active is None and not self . action : <TAB><TAB> # In HoldModifier, button released before timeout <TAB><TAB> mapper . cancel_task ( self . waiting_task ) <TAB><TAB> self . waiting_task = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . normalaction . button_press ( mapper ) <TAB><TAB><TAB> mapper . schedule ( 0.02 , self . normalaction . button_release ) <TAB> elif self . active : <TAB><TAB> # Released held button <TAB><TAB> self . active . button_release ( mapper ) <TAB><TAB> self . active = None",if self . normalaction :,if self . normalaction :,100.0,100.00,True
2241,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB><TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB><TAB> if p and p . isMarked ( ) : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> p . moveToThreadBack ( ) <TAB><TAB> elif wrapped : <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> wrapped = True <TAB><TAB><TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB><TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",elif p :,elif p :,100.0,100.00,True
2242,"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB><TAB> if self . script_running and self . script_running [ 1 ] == name : <TAB><TAB><TAB> return self . script_running [ 1 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . script_last [ 1 : ] <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( error )",elif self . script_last and self . script_last [ 1 ] == name :,elif self . script_last and self . script_last [ 1 ] == name :,100.0,100.00,True
2243,"def _stderr_supports_color ( ) : <TAB> try : <TAB><TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> curses . setupterm ( ) <TAB><TAB><TAB><TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> elif colorama : <TAB><TAB><TAB><TAB> if sys . stderr is getattr ( <TAB><TAB><TAB><TAB><TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB> except Exception : <TAB><TAB> # Very broad exception handling because it's always better to <TAB><TAB> # fall back to non-colored logs than to break at startup. <TAB><TAB> pass <TAB> return False",if curses :,if curses :,100.0,100.00,True
2244,"def main ( ) : <TAB> configFilename = "" twitterbot.ini "" <TAB> if sys . argv [ 1 : ] : <TAB><TAB> configFilename = sys . argv [ 1 ] <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( ) <TAB><TAB> load_config ( configFilename ) <TAB> except Exception as e : <TAB><TAB> print ( "" Error while loading ini file  %s "" % ( configFilename ) , file = sys . stderr ) <TAB><TAB> print ( e , file = sys . stderr ) <TAB><TAB> print ( __doc__ , file = sys . stderr ) <TAB><TAB> sys . exit ( 1 ) <TAB> bot = TwitterBot ( configFilename ) <TAB> return bot . run ( )",if not os . path . exists ( configFilename ) :,if not os . path . exists ( configFilename ) :,100.0,100.00,True
2245,def safe_to_kill ( request ) : <TAB> if os . path . exists ( DRAIN_FILE ) : <TAB><TAB> with open ( DRAIN_FILE ) as f : <TAB><TAB><TAB> dt = datetime . datetime . fromtimestamp ( float ( f . read ( ) ) ) <TAB><TAB><TAB> delta = datetime . datetime . now ( ) - dt <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return Response ( status_int = 200 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return Response ( status_int = 400 ) <TAB> else : <TAB><TAB> return Response ( status_int = 400 ),if delta . seconds > 2 :,if delta < dt :,69.13486997136215,96.84,False
2246,"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> class_name = parent . name <TAB><TAB> elif isinstance ( parent , pytest . Module ) : <TAB><TAB><TAB> module_name = parent . module . __name__ <TAB><TAB><TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "" .tasks. "" not in module_name : <TAB><TAB> return "" {} . {} "" . format ( module_name , class_name ) <TAB> else : <TAB><TAB> return module_name","if isinstance ( parent , pytest . Class ) :","if isinstance ( parent , pytest . Class ) :",100.0,100.00,True
2247,"def getAllFitsLite ( ) : <TAB> fits = eos . db . getFitListLite ( ) <TAB> shipMap = { f . shipID : None for f in fits } <TAB> for shipID in shipMap : <TAB><TAB> ship = eos . db . getItem ( shipID ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shipMap [ shipID ] = ( ship . name , ship . getShortName ( ) ) <TAB> fitsToPurge = set ( ) <TAB> for fit in fits : <TAB><TAB> try : <TAB><TAB><TAB> fit . shipName , fit . shipNameShort = shipMap [ fit . shipID ] <TAB><TAB> except ( KeyError , TypeError ) : <TAB><TAB><TAB> fitsToPurge . add ( fit ) <TAB> for fit in fitsToPurge : <TAB><TAB> fits . remove ( fit ) <TAB> return fits",if ship is not None :,if ship . name is not None :,85.05466648051825,98.20,False
2248,"def _process ( self , event_data ) : <TAB> self . machine . callbacks ( self . machine . prepare_event , event_data ) <TAB> _LOGGER . debug ( <TAB><TAB> "" %s Executed machine preparation callbacks before conditions. "" , self . machine . name <TAB> ) <TAB> try : <TAB><TAB> for trans in self . transitions [ event_data . state . name ] : <TAB><TAB><TAB> event_data . transition = trans <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> event_data . result = True <TAB><TAB><TAB><TAB> break <TAB> except Exception as err : <TAB><TAB> event_data . error = err <TAB><TAB> raise <TAB> finally : <TAB><TAB> self . machine . callbacks ( self . machine . finalize_event , event_data ) <TAB><TAB> _LOGGER . debug ( "" %s Executed machine finalize callbacks "" , self . machine . name ) <TAB> return event_data . result",if trans . execute ( event_data ) :,if event_data . transition . state . name == self . machine . name :,69.19222410211997,93.92,False
2249,"def fetch_comments ( self , force = False , limit = None ) : <TAB> comments = [ ] <TAB> if ( force is True ) or ( self . badges [ "" comments "" ] > 0 ) : <TAB><TAB> query_params = { "" filter "" : "" commentCard,copyCommentCard "" } <TAB><TAB> <MASK> <TAB><TAB><TAB> query_params [ "" limit "" ] = limit <TAB><TAB> comments = self . client . fetch_json ( <TAB><TAB><TAB> "" /cards/ "" + self . id + "" /actions "" , query_params = query_params <TAB><TAB> ) <TAB><TAB> return sorted ( comments , key = lambda comment : comment [ "" date "" ] ) <TAB> return comments",if limit is not None :,if limit is not None :,100.0,100.00,True
2250,"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB><TAB> result = self . _get_node_text ( self . ast ) <TAB><TAB> if result == self . source : <TAB><TAB><TAB> return None <TAB><TAB> return result <TAB> else : <TAB><TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB> last_end = - 1 <TAB><TAB> for match in self . matches : <TAB><TAB><TAB> start , end = match . get_region ( ) <TAB><TAB><TAB> if start < last_end : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> last_end = end <TAB><TAB><TAB> replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB> collector . add_change ( start , end , replacement ) <TAB><TAB> return collector . get_changed ( )",if not self . _is_expression ( ) :,if end == last_end :,82.10746292810506,96.14,False
2251,"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB><TAB> home = ( <TAB><TAB><TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB> if builtins . __xonsh__ . env . get ( "" FORCE_POSIX_PATHS "" ) : <TAB><TAB><TAB> x = x . replace ( os . sep , os . altsep ) <TAB><TAB> return x <TAB> else : <TAB><TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB> return x",if x . startswith ( home ) :,if home :,68.0378010568565,93.95,False
2252,"def project_review ( plans ) : <TAB> for plan in plans : <TAB><TAB> print ( "" Inspecting  {}  plan "" . format ( plan ) ) <TAB><TAB> branches = get_branches_from_plan ( plan ) <TAB><TAB> for branch in branches : <TAB><TAB><TAB> build_results = get_results_from_branch ( branch ) <TAB><TAB><TAB> for build in build_results : <TAB><TAB><TAB><TAB> build_key = build . get ( "" buildResultKey "" ) or None <TAB><TAB><TAB><TAB> print ( "" Inspecting build -  {} "" . format ( build_key ) ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> for status in STATUS_CLEANED_RESULTS : <TAB><TAB><TAB><TAB><TAB><TAB> remove_build_result ( build_key = build_key , status = status )",if build_key :,if build_key :,100.0,100.00,True
2253,"def _check_for_batch_clashes ( xs ) : <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB><TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB><TAB> if batches : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> batches = [ batches ] <TAB><TAB><TAB> for batch in batches : <TAB><TAB><TAB><TAB> if batch in names : <TAB><TAB><TAB><TAB><TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB><TAB><TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB><TAB> )","if not isinstance ( batches , ( list , tuple ) ) :","if not isinstance ( batches , list ) :",96.33354492372801,97.67,False
2254,"def _check_signal ( self ) : <TAB> """"""Checks if a signal was received and issues a message."""""" <TAB> proc_signal = getattr ( self . proc , "" signal "" , None ) <TAB> if proc_signal is None : <TAB><TAB> return <TAB> sig , core = proc_signal <TAB> sig_str = SIGNAL_MESSAGES . get ( sig ) <TAB> if sig_str : <TAB><TAB> if core : <TAB><TAB><TAB> sig_str + = ""  (core dumped) "" <TAB><TAB> print ( sig_str , file = sys . stderr ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . errors + = sig_str + "" \n """,if self . errors is not None :,if self . errors :,93.55946954254894,97.49,False
2255,"def loadLabelFile ( self , labelpath ) : <TAB> labeldict = { } <TAB> if not os . path . exists ( labelpath ) : <TAB><TAB> f = open ( labelpath , "" w "" , encoding = "" utf-8 "" ) <TAB> else : <TAB><TAB> with open ( labelpath , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB> data = f . readlines ( ) <TAB><TAB><TAB> for each in data : <TAB><TAB><TAB><TAB> file , label = each . split ( "" \t "" ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> label = label . replace ( "" false "" , "" False "" ) <TAB><TAB><TAB><TAB><TAB> label = label . replace ( "" true "" , "" True "" ) <TAB><TAB><TAB><TAB><TAB> labeldict [ file ] = eval ( label ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> labeldict [ file ] = [ ] <TAB> return labeldict",if label :,if self . is_bool :,72.14624583020202,97.64,False
2256,"def exists_col_to_many ( self , select_columns : List [ str ] ) - > bool : <TAB> for column in select_columns : <TAB><TAB> <MASK> <TAB><TAB><TAB> root_relation = get_column_root_relation ( column ) <TAB><TAB><TAB> if self . is_relation_many_to_many ( <TAB><TAB><TAB><TAB> root_relation <TAB><TAB><TAB> ) or self . is_relation_one_to_many ( root_relation ) : <TAB><TAB><TAB><TAB> return True <TAB> return False",if is_column_dotted ( column ) :,if column . is_relation ( ) :,94.28348309290983,95.31,False
2257,"def check_sequence_matches ( seq , template ) : <TAB> i = 0 <TAB> for pattern in template : <TAB><TAB> <MASK> <TAB><TAB><TAB> pattern = { pattern } <TAB><TAB> got = set ( seq [ i : i + len ( pattern ) ] ) <TAB><TAB> assert got == pattern <TAB><TAB> i + = len ( got )","if not isinstance ( pattern , set ) :","if not isinstance ( pattern , dict ) :",85.50023562174553,97.47,False
2258,"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB><TAB> print ( loading_message ) <TAB> for name in to_load : <TAB><TAB> module = load ( name ) <TAB><TAB> if module is None or not hasattr ( module , attr ) : <TAB><TAB><TAB> continue <TAB><TAB> cls = getattr ( module , attr ) <TAB><TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB> if alias not in excluded_aliases : <TAB><TAB><TAB><TAB><TAB> modules_dict [ alias ] = module <TAB><TAB> else : <TAB><TAB><TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB><TAB> print ( )","if hasattr ( module , ""aliases"" ) :","if hasattr ( module , ""aliases"" ) :",100.0,100.00,True
2259,"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R , V = rays , virtual_rays <TAB> if V is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> V = normalize_rays ( V , lattice ) <TAB><TAB> if check : <TAB><TAB><TAB> R = PointCollection ( V , lattice ) <TAB><TAB><TAB> V = PointCollection ( V , lattice ) <TAB><TAB><TAB> d = lattice . dimension ( ) <TAB><TAB><TAB> if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d : <TAB><TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB><TAB> "" virtual rays must be linearly  "" <TAB><TAB><TAB><TAB><TAB> "" independent and with other rays span the ambient space. "" <TAB><TAB><TAB><TAB> ) <TAB> return RationalPolyhedralFan ( cones , R , lattice , is_complete , V )",if normalize :,if normalize :,75.0,100.00,True
2260,"def communicate ( self , _input = None , _timeout = None ) - > Tuple [ bytes , bytes ] : <TAB> if parse_args ( ) . print_commands : <TAB><TAB> <MASK> <TAB><TAB><TAB> print_stderr ( <TAB><TAB><TAB><TAB> color_line ( "" =>  "" , 14 ) + ""   "" . join ( str ( arg ) for arg in self . args ) <TAB><TAB><TAB> ) <TAB> stdout , stderr = super ( ) . communicate ( _input , _timeout ) <TAB> self . stdout_text = stdout . decode ( "" utf-8 "" ) if stdout else None <TAB> self . stderr_text = stderr . decode ( "" utf-8 "" ) if stderr else None <TAB> return stdout , stderr",if self . args != get_sudo_refresh_command ( ) :,if self . args :,95.43565210224835,93.28,False
2261,"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB><TAB> # noinspection PyCompatibility <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB><TAB> elif isinstance ( d , basestring ) : <TAB><TAB><TAB> result . append ( d ) <TAB> return result","if isinstance ( d , tuple ) and len ( d ) == 2 :","if isinstance ( d , tuple ) :",94.07619030172785,91.30,False
2262,"def validate ( self , value ) : <TAB> try : <TAB><TAB> value = [ <TAB><TAB><TAB> datetime . datetime . strptime ( range , "" % Y- % m- %d   % H: % M: % S "" ) <TAB><TAB><TAB> for range in value . split ( ""  to  "" ) <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> except ValueError : <TAB><TAB> return False",if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,if len ( value ) == 2 :,58.96112005431351,88.03,False
2263,"def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB><TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB><TAB> return # do not clear link - we can get out of dir <TAB> for f in os . listdir ( dirname ) : <TAB><TAB> if f in ( "" . "" , "" .. "" ) : <TAB><TAB><TAB> continue <TAB><TAB> path = dirname + os . sep + f <TAB><TAB> <MASK> <TAB><TAB><TAB> rmdir ( path ) <TAB><TAB> else : <TAB><TAB><TAB> os . unlink ( path ) <TAB> os . rmdir ( dirname )",if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,100.0,100.00,True
2264,"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB><TAB> if not l : <TAB><TAB><TAB> continue <TAB><TAB> l = l . split ( "" : "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setSlides ( res )",if len ( l ) != 2 :,if len ( l ) != 2 :,100.0,100.00,True
2265,"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB> if "" init "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if item . nodeid . startswith ( ""tests/infer"" ) :","if isinstance ( item , pytest . mark . __class__ ) :",67.90605444841368,90.07,False
2266,"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB><TAB> if name == "" EMAIL_BODY "" : <TAB><TAB><TAB> self . add_body ( message , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_attachment ( message , value ) <TAB><TAB> else : # From, To, Subject, etc. <TAB><TAB><TAB> self . set_option ( message , name , value , target ) <TAB> return message","elif name == ""EMAIL_ATTACHMENT"" :","elif name == ""EMAIL_ATTACHMENT"" :",100.0,100.00,True
2267,def extend_with_zeroes ( b ) : <TAB> try : <TAB><TAB> for x in b : <TAB><TAB><TAB> x = to_constant ( x ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield ( x ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield ( 0 ) <TAB><TAB> for _ in range ( 32 ) : <TAB><TAB><TAB> yield ( 0 ) <TAB> except Exception as e : <TAB><TAB> return,"if isinstance ( x , int ) :",if x != 0 :,66.15787003110155,94.94,False
2268,"def _start_cluster ( * , cleanup_atexit = True ) : <TAB> global _default_cluster <TAB> if _default_cluster is None : <TAB><TAB> cluster_addr = os . environ . get ( "" EDGEDB_TEST_CLUSTER_ADDR "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> conn_spec = json . loads ( cluster_addr ) <TAB><TAB><TAB> _default_cluster = edgedb_cluster . RunningCluster ( * * conn_spec ) <TAB><TAB> else : <TAB><TAB><TAB> data_dir = os . environ . get ( "" EDGEDB_TEST_DATA_DIR "" ) <TAB><TAB><TAB> _default_cluster = _init_cluster ( <TAB><TAB><TAB><TAB> data_dir = data_dir , cleanup_atexit = cleanup_atexit <TAB><TAB><TAB> ) <TAB> return _default_cluster",if cluster_addr :,if cluster_addr :,100.0,100.00,True
2269,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB><TAB> with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> line = f1 . readline ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB> if line != ""   "" and line != "" "" : <TAB><TAB><TAB><TAB><TAB> if line [ 0 ] == ""   "" : <TAB><TAB><TAB><TAB><TAB><TAB> line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB> f2 . writelines ( line + "" \n "" )",if not line :,if not line :,100.0,100.00,True
2270,"def is_entirely_italic ( line ) : <TAB> style = subs . styles . get ( line . style , SSAStyle . DEFAULT_STYLE ) <TAB> for fragment , sty in parse_tags ( line . text , style , subs . styles ) : <TAB><TAB> fragment = fragment . replace ( r "" \ h "" , ""   "" ) <TAB><TAB> fragment = fragment . replace ( r "" \ n "" , "" \n "" ) <TAB><TAB> fragment = fragment . replace ( r "" \ N "" , "" \n "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return True",if not sty . italic and fragment and not fragment . isspace ( ) :,"if fragment . startswith ( r""\h"" ) :",63.29241012630244,91.99,False
2271,def __get_all_nodes ( self ) : <TAB> nodes = [ ] <TAB> next_level = [ self . __tree . get_root ( ) ] <TAB> while len ( next_level ) != 0 : <TAB><TAB> cur_level = next_level <TAB><TAB> nodes + = next_level <TAB><TAB> next_level = [ ] <TAB><TAB> for cur_node in cur_level : <TAB><TAB><TAB> children = cur_node . get_children ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> next_level + = children <TAB> return nodes,if children is not None :,if children :,68.50408685346311,97.21,False
2272,"def _openvpn_stdout ( self ) : <TAB> while True : <TAB><TAB> line = self . process . stdout . readline ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> time . sleep ( 0.05 ) <TAB><TAB><TAB> continue <TAB><TAB> yield <TAB><TAB> try : <TAB><TAB><TAB> self . server . output . push_output ( line ) <TAB><TAB> except : <TAB><TAB><TAB> logger . exception ( <TAB><TAB><TAB><TAB> "" Failed to push vpn output "" , <TAB><TAB><TAB><TAB> "" server "" , <TAB><TAB><TAB><TAB> server_id = self . server . id , <TAB><TAB><TAB> ) <TAB><TAB> yield",if self . process . poll ( ) is not None or self . is_interrupted ( ) :,if self . process . poll ( ) is not None :,74.34565642584465,96.00,False
2273,"def payment_received_handler ( event ) : <TAB> if isinstance ( event . message . action , types . MessageActionPaymentSentMe ) : <TAB><TAB> payment : types . MessageActionPaymentSentMe = event . message . action <TAB><TAB> # do something after payment was received <TAB><TAB> if payment . payload . decode ( "" UTF-8 "" ) == "" product A "" : <TAB><TAB><TAB> await bot . send_message ( <TAB><TAB><TAB><TAB> event . message . from_id , "" Thank you for buying product A! "" <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> await bot . send_message ( <TAB><TAB><TAB><TAB> event . message . from_id , "" Thank you for buying product B! "" <TAB><TAB><TAB> ) <TAB><TAB> raise events . StopPropagation","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :","elif payment . payload . decode ( ""UTF-8"" ) == ""product B""",98.98596681890992,98.88,False
2274,"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB><TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB><TAB> <MASK> <TAB><TAB><TAB> return LintProblem ( <TAB><TAB><TAB><TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB><TAB><TAB> ) <TAB><TAB> elif min != - 1 and spaces < min : <TAB><TAB><TAB> return LintProblem ( <TAB><TAB><TAB><TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB><TAB><TAB> )",if max != - 1 and spaces > max :,if max != - 1 and spaces > max :,100.0,100.00,True
2275,"def seek_to_block ( self , pos ) : <TAB> baseofs = 0 <TAB> ofs = 0 <TAB> for b in self . blocks : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current_block = b <TAB><TAB><TAB> break <TAB><TAB> baseofs + = b . compressed_size <TAB><TAB> ofs + = b . uncompressed_size <TAB> else : <TAB><TAB> self . current_block = None <TAB><TAB> self . current_stream = BytesIO ( b "" "" ) <TAB><TAB> return <TAB> self . current_block_start = ofs <TAB> self . stream . seek ( self . basepos + baseofs ) <TAB> buf = BytesIO ( self . stream . read ( self . current_block . compressed_size ) ) <TAB> self . current_stream = self . current_block . decompress ( buf )",if ofs + b . uncompressed_size > pos :,if b . pos == pos :,94.92244866233798,95.95,False
2276,"def rewrite_hunks ( hunks ) : <TAB> # type: (List[Hunk]) -> Iterator[Hunk] <TAB> # Assumes `hunks` are sorted, and from the same file <TAB> deltas = ( hunk . b_length - hunk . a_length for hunk in hunks ) <TAB> offsets = accumulate ( deltas , initial = 0 ) <TAB> for hunk , offset in zip ( hunks , offsets ) : <TAB><TAB> new_b = hunk . a_start + offset <TAB><TAB> if hunk_of_additions_only ( hunk ) : <TAB><TAB><TAB> new_b + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> new_b - = 1 <TAB><TAB> yield hunk . _replace ( b_start = new_b )",elif hunk_of_removals_only ( hunk ) :,if hunk_of_removals_only ( hunk ) :,73.62802166327612,98.70,False
2277,"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB><TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . append ( value ) <TAB><TAB><TAB> elif is_iterable ( value ) : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB><TAB> else : <TAB><TAB><TAB> if not is_iterable ( value ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if key == qkey : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",if len ( q ) == 1 :,"if isinstance ( value , ( list , tuple ) ) :",95.41209965322139,95.91,False
2278,"def get_url ( token , base_url ) : <TAB> """"""Parse an <url> token."""""" <TAB> if token . type == "" url "" : <TAB><TAB> return _get_url_tuple ( token . value , base_url ) <TAB> elif token . type == "" function "" : <TAB><TAB> if token . name == "" attr "" : <TAB><TAB><TAB> return check_attr_function ( token , "" url "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Ignore url modifiers <TAB><TAB><TAB> # See https://drafts.csswg.org/css-values-3/#urls <TAB><TAB><TAB> return _get_url_tuple ( token . arguments [ 0 ] . value , base_url )","elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :","elif token . name == ""modifiers"" :",84.89694188183087,92.09,False
2279,"def read ( self , count ) : <TAB> if self . closed : <TAB><TAB> return self . upstream . read ( count ) <TAB> try : <TAB><TAB> while len ( self . upstream ) < count : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> with self . buf_in : <TAB><TAB><TAB><TAB><TAB> self . transport . downstream_recv ( self . buf_in ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> break <TAB><TAB> return self . upstream . read ( count ) <TAB> except : <TAB><TAB> logger . debug ( traceback . format_exc ( ) )",if self . buf_in or self . _poll_read ( 10 ) :,if self . buf_in :,68.44283497596373,93.73,False
2280,"def get_timestamp_for_block ( <TAB> self , block_hash : HexBytes , max_tries : Optional [ int ] = 10 ) - > int : <TAB> counter = 0 <TAB> block : AttributeDict = None <TAB> if block_hash in self . _block_cache . keys ( ) : <TAB><TAB> block = self . _block_cache . get ( block_hash ) <TAB> else : <TAB><TAB> while block is None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValueError ( f "" Block hash  { block_hash . hex ( ) }  does not exist. "" ) <TAB><TAB><TAB> counter + = 1 <TAB><TAB><TAB> block = self . _block_cache . get ( block_hash ) <TAB><TAB><TAB> await asyncio . sleep ( 0.5 ) <TAB> return block . get ( "" timestamp "" )",if counter == max_tries :,if counter >= max_tries :,98.99598823930711,98.86,False
2281,"def reader ( ) : <TAB> batch_out = [ ] <TAB> for video_name in self . video_list : <TAB><TAB> video_idx = self . video_list . index ( video_name ) <TAB><TAB> video_feat = self . load_file ( video_name ) <TAB><TAB> batch_out . append ( ( video_feat , video_idx ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield batch_out <TAB><TAB><TAB> batch_out = [ ]",if len ( batch_out ) == self . batch_size :,if len ( batch_out ) == self . batch_size :,100.0,100.00,True
2282,"def cleanup ( ) : <TAB> gscript . message ( _ ( "" Erasing temporary files... "" ) ) <TAB> for temp_map , maptype in temp_maps : <TAB><TAB> <MASK> <TAB><TAB><TAB> gscript . run_command ( <TAB><TAB><TAB><TAB> "" g.remove "" , flags = "" f "" , type = maptype , name = temp_map , quiet = True <TAB><TAB><TAB> )","if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :","if not gscript . run_command ( ""g.add"" , name = temp_",67.61586672037593,85.31,False
2283,"def run ( self ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> with DelayedKeyboardInterrupt ( ) : <TAB><TAB><TAB><TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> if self . _flow_type == BATCH : <TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB> elif self . _flow_type == REALTIME : <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = False ) <TAB><TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB> except KeyboardInterrupt : <TAB><TAB><TAB> continue",if self . _has_stop_signal ( raw_inputs ) :,if self . _flow_type == SKIP :,70.5796568537708,96.42,False
2284,"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB><TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB><TAB><TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB><TAB> <MASK> <TAB><TAB><TAB> sent . append ( self . handle_word ( child ) ) <TAB><TAB> elif child . tag not in self . tags_to_ignore : <TAB><TAB><TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent )","elif child . tag in ( ""w"" , ""c"" ) :","elif child . tag in ( ""wm"" , ""hi"" , "" corr""",67.65698891782094,94.67,False
2285,"def bind_subscribers_to_graphql_type ( self , graphql_type ) : <TAB> for field , subscriber in self . _subscribers . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Field  %s  is not defined on type  %s "" % ( field , self . name ) ) <TAB><TAB> graphql_type . fields [ field ] . subscribe = subscriber",if field not in graphql_type . fields :,if field not in graphql_type . fields :,100.0,100.00,True
2286,"def _get_from_json ( self , * , name , version ) : <TAB> url = urljoin ( self . url , posixpath . join ( name , str ( version ) , "" json "" ) ) <TAB> async with aiohttp_session ( auth = self . auth ) as session : <TAB><TAB> async with session . get ( url ) as response : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise PackageNotFoundError ( package = name , url = url ) <TAB><TAB><TAB> response . raise_for_status ( ) <TAB><TAB><TAB> response = await response . json ( ) <TAB> dist = response [ "" info "" ] [ "" requires_dist "" ] or [ ] <TAB> if dist : <TAB><TAB> return dist <TAB> # If no requires_dist then package metadata can be broken. <TAB> # Let's check distribution files. <TAB> return await self . _get_from_files ( response [ "" urls "" ] )",if response . status == 404 :,"if response . status not in ( 404 , 404 ) :",96.83530526998427,96.52,False
2287,"def is_active ( self ) : <TAB> if not self . pk : <TAB><TAB> log_level = get_setting ( "" LOG_MISSING_SWITCHES "" ) <TAB><TAB> if log_level : <TAB><TAB><TAB> logger . log ( log_level , "" Switch  %s  not found "" , self . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> switch , _created = Switch . objects . get_or_create ( <TAB><TAB><TAB><TAB> name = self . name , defaults = { "" active "" : get_setting ( "" SWITCH_DEFAULT "" ) } <TAB><TAB><TAB> ) <TAB><TAB><TAB> cache = get_cache ( ) <TAB><TAB><TAB> cache . set ( self . _cache_key ( self . name ) , switch ) <TAB><TAB> return get_setting ( "" SWITCH_DEFAULT "" ) <TAB> return self . active","if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",if self . active :,95.43953629361717,94.19,False
2288,"def add_requirements ( self , requirements ) : <TAB> if self . _legacy : <TAB><TAB> self . _legacy . add_requirements ( requirements ) <TAB> else : <TAB><TAB> run_requires = self . _data . setdefault ( "" run_requires "" , [ ] ) <TAB><TAB> always = None <TAB><TAB> for entry in run_requires : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> always = entry <TAB><TAB><TAB><TAB> break <TAB><TAB> if always is None : <TAB><TAB><TAB> always = { "" requires "" : requirements } <TAB><TAB><TAB> run_requires . insert ( 0 , always ) <TAB><TAB> else : <TAB><TAB><TAB> rset = set ( always [ "" requires "" ] ) | set ( requirements ) <TAB><TAB><TAB> always [ "" requires "" ] = sorted ( rset )","if ""environment"" not in entry and ""extra"" not in entry :","if entry [ ""requires"" ] == requirements :",92.59222620294312,94.27,False
2289,"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB><TAB> message : Optional [ str ] <TAB><TAB> if check . message : <TAB><TAB><TAB> message = f "" { idx } .  { check . message } "" <TAB><TAB> else : <TAB><TAB><TAB> message = None <TAB><TAB> example = cast ( Case , check . example ) # filtered in `_get_unique_failures` <TAB><TAB> display_example ( example , check . name , message , result . seed ) <TAB><TAB> # Display every time except the last check <TAB><TAB> <MASK> <TAB><TAB><TAB> click . echo ( "" \n "" )",if idx != len ( checks ) :,if idx == result . seed :,97.70197408326334,96.96,False
2290,"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB><TAB> event not in SUPPORTED_EVENTS <TAB><TAB> or code . co_name == "" trace_types "" <TAB><TAB> or self . should_trace <TAB><TAB> and not self . should_trace ( code ) <TAB> ) : <TAB><TAB> return self <TAB> try : <TAB><TAB> if event == EVENT_CALL : <TAB><TAB><TAB> self . handle_call ( frame ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . handle_return ( frame , arg ) <TAB><TAB> else : <TAB><TAB><TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB><TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self",elif event == EVENT_RETURN :,elif event == EVENT_RETURN :,100.0,100.00,True
2291,"def get_maps ( test ) : <TAB> pages = set ( ) <TAB> for addr in test [ "" pre "" ] [ "" memory "" ] . keys ( ) : <TAB><TAB> pages . add ( addr >> 12 ) <TAB> for addr in test [ "" pos "" ] [ "" memory "" ] . keys ( ) : <TAB><TAB> pages . add ( addr >> 12 ) <TAB> maps = [ ] <TAB> for p in sorted ( pages ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> maps [ - 1 ] = ( maps [ - 1 ] [ 0 ] , maps [ - 1 ] [ 1 ] + 0x1000 ) <TAB><TAB> else : <TAB><TAB><TAB> maps . append ( ( p << 12 , 0x1000 ) ) <TAB> return maps",if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,if maps :,74.8471191674476,84.66,False
2292,"def process_rotate_aes_key ( self ) : <TAB> if hasattr ( self . options , "" rotate_aes_key "" ) and isinstance ( <TAB><TAB> self . options . rotate_aes_key , six . string_types <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . options . rotate_aes_key = True <TAB><TAB> elif self . options . rotate_aes_key . lower ( ) == "" false "" : <TAB><TAB><TAB> self . options . rotate_aes_key = False","if self . options . rotate_aes_key . lower ( ) == ""true"" :","if self . options . rotate_aes_key . lower ( ) == ""true"" :",100.0,100.00,True
2293,"def apply_figure ( self , figure ) : <TAB> super ( legend_text_legend , self ) . apply_figure ( figure ) <TAB> properties = self . properties . copy ( ) <TAB> with suppress ( KeyError ) : <TAB><TAB> del properties [ "" margin "" ] <TAB> with suppress ( KeyError ) : <TAB><TAB> texts = figure . _themeable [ "" legend_text_legend "" ] <TAB><TAB> for text in texts : <TAB><TAB><TAB> <MASK> # textarea <TAB><TAB><TAB><TAB> text = text . _text <TAB><TAB><TAB> text . set ( * * properties )","if not hasattr ( text , ""_x"" ) :","if hasattr ( text , ""_text"" ) :",88.98647645346516,96.89,False
2294,"def tearDown ( self ) : <TAB> for i in range ( len ( self . tree ) - 1 , - 1 , - 1 ) : <TAB><TAB> s = os . path . join ( self . root , self . tree [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . rmdir ( s ) <TAB><TAB> else : <TAB><TAB><TAB> os . remove ( s ) <TAB> os . rmdir ( self . root )","if not ""."" in s :",if os . path . isdir ( s ) :,66.23776660970026,92.38,False
2295,"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB><TAB> if type != fields [ - 2 ] : <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Expected id of type  %s  but found type  %s   %s "" , type , fields [ - 2 ] , id <TAB><TAB><TAB> ) <TAB><TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB><TAB> itype = fields [ - 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Expected id of type  %s  but found type  %s   %s "" , type , itype , id <TAB><TAB><TAB> ) <TAB><TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id",if type != itype :,if itype != type :,77.64545042371543,98.34,False
2296,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB><TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield s <TAB><TAB> if recurseInAnon : <TAB><TAB><TAB> yield from s . children_recurse_anon <TAB><TAB> else : <TAB><TAB><TAB> yield from s . _children <TAB><TAB> if s . siblingAbove is None : <TAB><TAB><TAB> break <TAB><TAB> s = s . siblingAbove <TAB><TAB> if Symbol . debug_lookup : <TAB><TAB><TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",if matchSelf :,if s . _children is None :,97.65869145052886,97.11,False
2297,"def records ( account_id ) : <TAB> """"""Fetch locks data"""""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB><TAB> if "" LockDate "" in r : <TAB><TAB><TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) )","if ""RevisionDate"" in r :","if ""RevisionDate"" in r :",100.0,100.00,True
2298,"def _handle_errors ( errors ) : <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors : <TAB><TAB> return <TAB> log_all = True # pylint: disable=unused-variable <TAB> err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB> print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB> for module , err in errors : <TAB><TAB> err_str = str ( err ) <TAB><TAB> if log_all : <TAB><TAB><TAB> print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" From module  %s "" % module ) <TAB><TAB><TAB> raise err","if not _is_import_err_msg ( err_str , module ) :",if module not in data_generators :,96.63400829230025,92.36,False
2299,"def find_needle ( self , tree , focused = None ) : <TAB> if isinstance ( tree , list ) : <TAB><TAB> for el in tree : <TAB><TAB><TAB> res = self . find_needle ( el , focused ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return res <TAB> elif isinstance ( tree , dict ) : <TAB><TAB> nodes = tree . get ( "" nodes "" , [ ] ) + tree . get ( "" floating_nodes "" , [ ] ) <TAB><TAB> if focused : <TAB><TAB><TAB> for node in nodes : <TAB><TAB><TAB><TAB> if node [ "" id "" ] == focused [ "" id "" ] : <TAB><TAB><TAB><TAB><TAB> return tree <TAB><TAB> elif tree [ "" focused "" ] : <TAB><TAB><TAB> return tree <TAB><TAB> return self . find_needle ( nodes , focused ) <TAB> return { }",if res :,if res :,100.0,100.00,True
2300,"def available_datasets ( self ) : <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB><TAB> if isinstance ( val , netCDF4 . Variable ) : <TAB><TAB><TAB> ds_info = { <TAB><TAB><TAB><TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB><TAB><TAB><TAB> "" resolution "" : res , <TAB><TAB><TAB> } <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ds_info [ "" coordinates "" ] = coordinates <TAB><TAB><TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info",if not self . is_geo :,if coordinates :,79.56332997734886,96.62,False
2301,"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB><TAB> test_path = k . get_path ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB> if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB> sub = sub [ 1 : ] <TAB><TAB><TAB> end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB> if end_slash > = 0 : <TAB><TAB><TAB><TAB> sub = sub [ : end_slash ] <TAB><TAB><TAB> if not sub : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> subkeys . append ( sub ) <TAB> return subkeys",if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,if test_path . startswith ( parent_path ) :,71.3662540282851,96.18,False
2302,"def default ( self , o ) : <TAB> try : <TAB><TAB> if type ( o ) == datetime . datetime : <TAB><TAB><TAB> return str ( o ) <TAB><TAB> else : <TAB><TAB><TAB> # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB> if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB> del o . profile <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del o . credentials <TAB><TAB><TAB> if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB> del o . metadata_path <TAB><TAB><TAB> if hasattr ( o , "" services_config "" ) : <TAB><TAB><TAB><TAB> del o . services_config <TAB><TAB><TAB> return vars ( o ) <TAB> except Exception as e : <TAB><TAB> return str ( o )","if hasattr ( o , ""credentials"" ) :","if hasattr ( o , ""credentials"" ) :",100.0,100.00,True
2303,"def submit ( self , fn , * args , * * kwargs ) : <TAB> with self . _shutdown_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" cannot schedule new futures after shutdown "" ) <TAB><TAB> f = _base . Future ( ) <TAB><TAB> w = _WorkItem ( f , fn , args , kwargs ) <TAB><TAB> self . _work_queue . put ( w ) <TAB><TAB> self . _adjust_thread_count ( ) <TAB><TAB> return f",if self . _shutdown :,if self . _shutdown :,100.0,100.00,True
2304,"def __viewerKeyPress ( viewer , event ) : <TAB> view = viewer . view ( ) <TAB> if not isinstance ( view , GafferSceneUI . SceneView ) : <TAB><TAB> return False <TAB> if event == __editSourceKeyPress : <TAB><TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB><TAB> <MASK> <TAB><TAB><TAB> __editSourceNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB><TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB><TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB><TAB> <MASK> <TAB><TAB><TAB> __editTweaksNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB><TAB> return True",if selectedPath is not None :,if selectedPath :,75.15006026294682,95.13,False
2305,"def _split_to_option_groups_and_paths ( self , args ) : <TAB> opt_groups = [ ] <TAB> current = [ ] <TAB> for arg in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> opts = self . _arg_parser . parse_args ( current ) [ 0 ] <TAB><TAB><TAB> opt_groups . append ( opts ) <TAB><TAB><TAB> current = [ ] <TAB><TAB> else : <TAB><TAB><TAB> current . append ( arg ) <TAB> if opt_groups : <TAB><TAB> return opt_groups , current <TAB> raise ValueError ( "" Nothing to split "" )","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :","if arg == ""groups"" :",82.87720955186595,87.85,False
2306,"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB><TAB> if isinstance ( value , bool ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB> if value != 1 : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> elif value is None : <TAB><TAB><TAB> continue <TAB><TAB> elif len ( value ) != 0 : <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> break <TAB> self . _reset_button . disabled = not changed",if value :,if value != 0 :,89.3777576864746,97.98,False
2307,"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB><TAB> try : <TAB><TAB><TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB><TAB><TAB> if target_pid == pid : <TAB><TAB><TAB><TAB> return <TAB><TAB> except OSError : <TAB><TAB><TAB> e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out """,if e . args [ 0 ] == errno . ECHILD :,if e . errno == errno . EINTR :,92.19341770961984,95.94,False
2308,"def _get_os_version_lsb_release ( ) : <TAB> try : <TAB><TAB> output = subprocess . check_output ( "" lsb_release -sri "" , shell = True ) <TAB><TAB> lines = output . strip ( ) . split ( ) <TAB><TAB> name , version = lines <TAB><TAB> <MASK> <TAB><TAB><TAB> version = "" "" <TAB><TAB> return name , version <TAB> except : <TAB><TAB> return _get_os_version_uname ( )","if version . lower ( ) == ""rolling"" :","if version == ""0.0.0"" :",65.5494167583702,93.97,False
2309,"def _check_snapshot_status_healthy ( self , snapshot_uuid ) : <TAB> status = "" "" <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> status , locked = self . _get_snapshot_status ( snapshot_uuid ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> eventlet . sleep ( 2 ) <TAB> except Exception : <TAB><TAB> with excutils . save_and_reraise_exception ( ) : <TAB><TAB><TAB> LOG . exception ( "" Failed to get snapshot status. [ %s ] "" , snapshot_uuid ) <TAB> LOG . debug ( <TAB><TAB> "" Lun [ %(snapshot)s ], status [ %(status)s ]. "" , <TAB><TAB> { "" snapshot "" : snapshot_uuid , "" status "" : status } , <TAB> ) <TAB> return status == "" Healthy """,if not locked :,if locked :,88.42366668806424,98.90,False
2310,"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB> return 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasMaximizeButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasMinimizeButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasPinButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB> return n",if self . HasCloseButton ( ) :,if self . HasMinimizeButton ( ) :,97.456120749397,98.66,False
2311,"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB><TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not isinstance ( key , bytes ) : <TAB><TAB><TAB> key = text_type ( key ) . encode ( charset ) <TAB><TAB> if not isinstance ( value , bytes ) : <TAB><TAB><TAB> value = text_type ( value ) . encode ( charset ) <TAB><TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value )",if value is None :,if not encode_keys :,80.58273489006926,97.33,False
2312,"def get_response ( self , exc_fmt = None ) : <TAB> self . callback = None <TAB> if __debug__ : <TAB><TAB> self . parent . _log ( 3 , "" %s : %s .ready.wait "" % ( self . name , self . tag ) ) <TAB> self . ready . wait ( ) <TAB> if self . aborted is not None : <TAB><TAB> typ , val = self . aborted <TAB><TAB> <MASK> <TAB><TAB><TAB> exc_fmt = "" %s  -  %% s "" % typ <TAB><TAB> raise typ ( exc_fmt % str ( val ) ) <TAB> return self . response",if exc_fmt is None :,if exc_fmt is None :,100.0,100.00,True
2313,"def extract_items ( self ) : <TAB> responses = self . fetch ( ) <TAB> items = [ ] <TAB> for response in responses : <TAB><TAB> page_key = response . meta . get ( "" page_key "" ) or response . url <TAB><TAB> item = { "" key "" : page_key , "" items "" : None , "" templates "" : None } <TAB><TAB> extracted_items = [ <TAB><TAB><TAB> dict ( i ) for i in self . spider . parse ( response ) if not isinstance ( i , Request ) <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> item [ "" items "" ] = extracted_items <TAB><TAB><TAB> item [ "" templates "" ] = [ <TAB><TAB><TAB><TAB> i [ "" _template "" ] for i in extracted_items if i . get ( "" _template "" ) <TAB><TAB><TAB> ] <TAB><TAB><TAB> items . append ( item ) <TAB> return items",if extracted_items :,if extracted_items :,100.0,100.00,True
2314,"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB><TAB> if self . with_centering : <TAB><TAB><TAB> self . median [ i ] . update ( xi ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . iqr [ i ] . update ( xi ) <TAB> return self",if self . with_scaling :,elif self . with_iqr :,70.57191750756529,94.59,False
2315,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB><TAB> if left == 0 : <TAB><TAB><TAB> done = True <TAB><TAB> <MASK> <TAB><TAB><TAB> left - = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> done = False <TAB> while not done : <TAB><TAB> if right == len ( text ) : <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB> right + = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> return left , right",elif not self . word_boundary_char ( text [ left - 1 ] ) :,elif self . word_boundary_char ( text [ left ] ) and allowed_chars,68.41633412508678,96.24,False
2316,"def _validate_duplicate_detection_history_time_window ( namespace ) : <TAB> if namespace . duplicate_detection_history_time_window : <TAB><TAB> if iso8601pattern . match ( namespace . duplicate_detection_history_time_window ) : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> raise CLIError ( <TAB><TAB><TAB><TAB> "" --duplicate-detection-history-time-window Value Error :  {0}  value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min "" . format ( <TAB><TAB><TAB><TAB><TAB> namespace . duplicate_detection_history_time_window <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,elif durationpattern . match ( namespace . duplicate_detection_history_time_window ),75.51783764197417,97.76,False
2317,"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB><TAB> test_path = k . get_path ( ) <TAB><TAB> if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB><TAB><TAB> sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB> if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB> sub = sub [ 1 : ] <TAB><TAB><TAB> end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB> if end_slash > = 0 : <TAB><TAB><TAB><TAB> sub = sub [ : end_slash ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> subkeys . append ( sub ) <TAB> return subkeys",if not sub :,"if sub == ""\\"" :",73.52694347740709,97.00,False
2318,"def generator ( self , data ) : <TAB> <MASK> <TAB><TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB><TAB> for var , val in task . environment_variables ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if var in silent_vars : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> int ( task . UniqueProcessId ) , <TAB><TAB><TAB><TAB><TAB> str ( task . ImageFileName ) , <TAB><TAB><TAB><TAB><TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB><TAB><TAB><TAB><TAB> str ( var ) , <TAB><TAB><TAB><TAB><TAB> str ( val ) , <TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB> )",if self . _config . SILENT :,if val is not None :,91.15320716619553,94.79,False
2319,"def start_requests ( self ) : <TAB> if self . fail_before_yield : <TAB><TAB> 1 / 0 <TAB> for s in range ( 100 ) : <TAB><TAB> qargs = { "" total "" : 10 , "" seed "" : s } <TAB><TAB> url = self . mockserver . url ( "" /follow? %s "" ) % urlencode ( qargs , doseq = 1 ) <TAB><TAB> yield Request ( url , meta = { "" seed "" : s } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> 2 / 0 <TAB> assert self . seedsseen , "" All start requests consumed before any download happened """,if self . fail_yielding :,if self . fail_before_yield :,98.80701920898194,97.12,False
2320,"def populateGridlines ( self ) : <TAB> cTicks = self . getSystemCurve ( self . ticksId ) <TAB> cGridlines = self . getSystemCurve ( self . gridlinesId ) <TAB> cGridlines . clearPoints ( ) <TAB> nTicks = cTicks . getNPoints ( ) <TAB> for iTick in range ( nTicks ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> p = cTicks . getPoint ( iTick ) <TAB><TAB><TAB> cGridlines . addPoint ( p . getX ( ) , p . getY ( ) )",if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,if iTick != 0 :,68.3318144663866,89.03,False
2321,"def handle_before_events ( request , event_list ) : <TAB> if not event_list : <TAB><TAB> return "" "" <TAB> if not hasattr ( event_list , "" __iter__ "" ) : <TAB><TAB> project = event_list . project <TAB><TAB> event_list = [ event_list ] <TAB> else : <TAB><TAB> projects = set ( e . project for e in event_list ) <TAB><TAB> <MASK> <TAB><TAB><TAB> project = projects . pop ( ) <TAB><TAB> else : <TAB><TAB><TAB> project = None <TAB> for plugin in plugins . for_project ( project ) : <TAB><TAB> safe_execute ( plugin . before_events , request , event_list ) <TAB> return "" """,if len ( projects ) == 1 :,if projects :,67.92540237169652,95.79,False
2322,"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _raise_exclusive_error ( ) <TAB><TAB> if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 : <TAB><TAB><TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args )",if self . mutually_exclusive . intersection ( opts ) :,if self . multiple and len ( opts [ self . name ] ) > 1 :,66.00706921440856,90.11,False
2323,"def current_word ( cursor_offset , line ) : <TAB> """"""the object.attribute.attribute just before or under the cursor"""""" <TAB> pos = cursor_offset <TAB> start = pos <TAB> end = pos <TAB> word = None <TAB> for m in current_word_re . finditer ( line ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> start = m . start ( 1 ) <TAB><TAB><TAB> end = m . end ( 1 ) <TAB><TAB><TAB> word = m . group ( 1 ) <TAB> if word is None : <TAB><TAB> return None <TAB> return LinePart ( start , end , word )",if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,if m . start ( 1 ) == start and m . end ( 1 ) == end :,87.26276399339157,95.13,False
2324,"def query_to_script_path ( path , query ) : <TAB> if path != "" * "" : <TAB><TAB> script = os . path . join ( path , query . split ( ""   "" ) [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IOError ( "" Script  ' {} '  not found in script directory "" . format ( query ) ) <TAB><TAB> return os . path . join ( path , query ) . split ( ""   "" ) <TAB> return query",if not os . path . exists ( script ) :,if not os . path . exists ( script ) :,100.0,100.00,True
2325,"def expand ( self , pbegin ) : <TAB> # TODO(b/151921205): we have to do an identity map for unmodified <TAB> # PCollections below because otherwise we get an error from beam. <TAB> identity_map = "" Identity "" >> beam . Map ( lambda x : x ) <TAB> if self . _dataset_key . is_flattened_dataset_key ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _flat_pcollection | identity_map <TAB><TAB> else : <TAB><TAB><TAB> return list ( <TAB><TAB><TAB><TAB> self . _pcollection_dict . values ( ) <TAB><TAB><TAB> ) | "" FlattenAnalysisInputs "" >> beam . Flatten ( pipeline = pbegin . pipeline ) <TAB> else : <TAB><TAB> return self . _pcollection_dict [ self . _dataset_key ] | identity_map",if self . _flat_pcollection :,if self . _flat_pcollection :,75.0,100.00,True
2326,"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB><TAB> for _dir , offsets in faceDirections : <TAB><TAB><TAB> if _dir == FaceYIncreasing : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> dx , dy , dz = offsets <TAB><TAB><TAB> p = ( x + dx , y + dy , z + dz ) <TAB><TAB><TAB> if p not in box : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> nx , ny , nz = p <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB><TAB><TAB><TAB> newcoords . append ( p ) <TAB> return newcoords","if level . blockAt ( nx , ny , nz ) == 0 :",if nx != 0 and nz != 0 :,69.6451654877153,94.75,False
2327,"def delete_byfilter ( userId , remove = True , session = None , * * dbfilter ) : <TAB> if not session : <TAB><TAB> session = db . Session <TAB> ret = False <TAB> results = session . query ( ObjectStorageMetadata ) . filter_by ( * * dbfilter ) <TAB> if results : <TAB><TAB> for result in results : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> session . delete ( result ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> result . update ( <TAB><TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB><TAB> "" record_state_key "" : "" to_delete "" , <TAB><TAB><TAB><TAB><TAB><TAB> "" record_state_val "" : str ( time . time ( ) ) , <TAB><TAB><TAB><TAB><TAB> } <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ret = True <TAB> return ret",if remove :,if remove :,100.0,100.00,True
2328,"def fields ( self , fields ) : <TAB> fields_xml = "" "" <TAB> for field in fields : <TAB><TAB> field_dict = DEFAULT_FIELD . copy ( ) <TAB><TAB> field_dict . update ( field ) <TAB><TAB> <MASK> <TAB><TAB><TAB> field_dict [ "" required "" ] = "" true "" <TAB><TAB> fields_xml + = FIELD_XML_TEMPLATE % field_dict + "" \n "" <TAB> self . xml = force_unicode ( <TAB><TAB> force_unicode ( self . xml ) . replace ( <TAB><TAB><TAB> u "" <!-- REPLACE FIELDS --> "" , force_unicode ( fields_xml ) <TAB><TAB> ) <TAB> )","if self . unique_key_field == field [ ""name"" ] :","if field_dict [ ""required"" ] :",93.45409849641626,92.99,False
2329,"def get_all_users ( self , access_token , timeout = None ) : <TAB> if timeout is None : <TAB><TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self . retrieve_header ( access_token ) <TAB> try : <TAB><TAB> response = await self . standard_request ( <TAB><TAB><TAB> "" get "" , "" /walkoff/api/users "" , timeout = DEFAULT_TIMEOUT , headers = headers <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> resp = await response . json ( ) <TAB><TAB><TAB> return resp , "" Success "" <TAB><TAB> else : <TAB><TAB><TAB> return "" Invalid Credentials "" <TAB> except asyncio . CancelledError : <TAB><TAB> return False , "" TimedOut """,if response . status == 200 :,if response . status == 200 :,100.0,100.00,True
2330,"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB><TAB> row = model [ idx ] <TAB><TAB> if value and row [ 0 ] == value : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB><TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB><TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB><TAB> return None",if idx == len ( os_widget . get_model ( ) ) - 1 :,if idx == len ( model ) :,89.57060088596369,92.80,False
2331,"def translate_module_name ( module : str , relative : int ) - > Tuple [ str , int ] : <TAB> for pkg in VENDOR_PACKAGES : <TAB><TAB> for alt in "" six.moves "" , "" six "" : <TAB><TAB><TAB> substr = "" {} . {} "" . format ( pkg , alt ) <TAB><TAB><TAB> if module . endswith ( "" . "" + substr ) or ( module == substr and relative ) : <TAB><TAB><TAB><TAB> return alt , 0 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return alt + "" . "" + module . partition ( "" . "" + substr + "" . "" ) [ 2 ] , 0 <TAB> return module , relative","if ""."" + substr + ""."" in module :","elif module . startswith ( ""."" + substr ) or ( module == substr and relative ) :",93.38650476515289,91.12,False
2332,"def escape ( m ) : <TAB> all , tail = m . group ( 0 , 1 ) <TAB> assert all . startswith ( "" \\ "" ) <TAB> esc = simple_escapes . get ( tail ) <TAB> if esc is not None : <TAB><TAB> return esc <TAB> if tail . startswith ( "" x "" ) : <TAB><TAB> hexes = tail [ 1 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB><TAB> try : <TAB><TAB><TAB> i = int ( hexes , 16 ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> i = int ( tail , 8 ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise ValueError ( "" invalid octal string escape ( ' \\ %s ' ) "" % tail ) <TAB> return chr ( i )",if len ( hexes ) < 2 :,if hexes < 0 :,83.0519058542476,97.41,False
2333,"def __get_k8s_container_name ( self , job_wrapper ) : <TAB> # These must follow a specific regex for Kubernetes. <TAB> raw_id = job_wrapper . job_destination . id <TAB> if isinstance ( raw_id , str ) : <TAB><TAB> cleaned_id = re . sub ( "" [^-a-z0-9] "" , "" - "" , raw_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cleaned_id = "" x %s x "" % cleaned_id <TAB><TAB> return cleaned_id <TAB> return "" job-container ""","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",if cleaned_id :,66.80226734261328,87.15,False
2334,"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB><TAB> yc / / = 10 <TAB><TAB> ye + = 1 <TAB> if xc == 1 : <TAB><TAB> xe * = yc <TAB><TAB> while xe % 10 == 0 : <TAB><TAB><TAB> xe / / = 10 <TAB><TAB><TAB> ye + = 1 <TAB><TAB> if ye < 0 : <TAB><TAB><TAB> return None <TAB><TAB> exponent = xe * 10 * * ye <TAB><TAB> <MASK> <TAB><TAB><TAB> xc = exponent <TAB><TAB> else : <TAB><TAB><TAB> xc = 0 <TAB><TAB> return 5",if y and xe :,if exponent < xc :,75.45828825180554,97.82,False
2335,"def lpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB><TAB> _client . lpush ( key , * vals ) <TAB> else : <TAB><TAB> pipe = _client . pipeline ( ) <TAB><TAB> pipe . lpush ( key , * vals ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pipe . ltrim ( key , 0 , cap ) <TAB><TAB> if ttl : <TAB><TAB><TAB> pipe . expire ( key , ttl ) <TAB><TAB> pipe . execute ( )",if cap :,if cap :,100.0,100.00,True
2336,"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB><TAB> parts = [ <TAB><TAB><TAB> b "" Content-Disposition: form-data;  "" , <TAB><TAB><TAB> format_form_param ( "" name "" , self . name ) , <TAB><TAB> ] <TAB><TAB> if self . filename : <TAB><TAB><TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB><TAB><TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> content_type = self . content_type . encode ( ) <TAB><TAB><TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB><TAB> parts . append ( b "" \r \n \r \n "" ) <TAB><TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers",if self . content_type is not None :,if self . content_type :,98.03342846181583,98.24,False
2337,"def validate_custom_field_data ( field_type : int , field_data : ProfileFieldData ) - > None : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Choice type field must have at least have one choice <TAB><TAB><TAB> if len ( field_data ) < 1 : <TAB><TAB><TAB><TAB> raise JsonableError ( _ ( "" Field must have at least one choice. "" ) ) <TAB><TAB><TAB> validate_choice_field_data ( field_data ) <TAB><TAB> elif field_type == CustomProfileField . EXTERNAL_ACCOUNT : <TAB><TAB><TAB> validate_external_account_field_data ( field_data ) <TAB> except ValidationError as error : <TAB><TAB> raise JsonableError ( error . message )",if field_type == CustomProfileField . CHOICE :,if field_type == CustomProfileField . Choice :,98.68508424209168,98.72,False
2338,"def get_data ( self , path ) : <TAB> """"""Gross hack to contort loader to deal w/ load_*()'s bad API."""""" <TAB> if self . file and path == self . path : <TAB><TAB> <MASK> <TAB><TAB><TAB> file = self . file <TAB><TAB> else : <TAB><TAB><TAB> self . file = file = open ( self . path , "" r "" ) <TAB><TAB> with file : <TAB><TAB><TAB> # Technically should be returning bytes, but <TAB><TAB><TAB> # SourceLoader.get_code() just passed what is returned to <TAB><TAB><TAB> # compile() which can handle str. And converting to bytes would <TAB><TAB><TAB> # require figuring out the encoding to decode to and <TAB><TAB><TAB> # tokenize.detect_encoding() only accepts bytes. <TAB><TAB><TAB> return file . read ( ) <TAB> else : <TAB><TAB> return super ( ) . get_data ( path )",if not self . file . closed :,"if isinstance ( self . file , str ) :",77.85607258734896,96.94,False
2339,"def handle_read ( self ) : <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try : <TAB><TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB><TAB> pass <TAB> except socket . error : <TAB><TAB> self . handle_error ( ) <TAB> else : <TAB><TAB> self . tot_bytes_received + = len ( chunk ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . transfer_finished = True <TAB><TAB><TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB><TAB><TAB> return <TAB><TAB> if self . _data_wrapper is not None : <TAB><TAB><TAB> chunk = self . _data_wrapper ( chunk ) <TAB><TAB> try : <TAB><TAB><TAB> self . file_obj . write ( chunk ) <TAB><TAB> except OSError as err : <TAB><TAB><TAB> raise _FileReadWriteError ( err )",if not chunk :,if self . tot_bytes_received >= self . transfer_size :,95.04548319960293,94.41,False
2340,"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> line = line . split ( ""   "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB><TAB><TAB> if not ( "" < "" in line or line in dep ) : <TAB><TAB><TAB><TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ]","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :","if line . startswith ( ""dependency:"" ) :",84.01134737103006,91.22,False
2341,"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB><TAB> if not self . editing : <TAB><TAB><TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets )",elif scroll_if_editing :,elif self . editing and self . _my_widgets :,83.9996681503805,92.79,False
2342,"def test_getline ( self ) : <TAB> with tokenize . open ( self . file_name ) as fp : <TAB><TAB> for index , line in enumerate ( fp ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> line + = "" \n "" <TAB><TAB><TAB> cached_line = linecache . getline ( self . file_name , index + 1 ) <TAB><TAB><TAB> self . assertEqual ( line , cached_line )","if not line . endswith ( ""\n"" ) :",if line :,86.78059862928028,90.85,False
2343,"def selectRow ( self , rowNumber , highlight = None ) : <TAB> if rowNumber == "" h "" : <TAB><TAB> rowNumber = 0 <TAB> else : <TAB><TAB> rowNumber = int ( rowNumber ) + 1 <TAB> if 1 > rowNumber > = len ( self . cells ) + 1 : <TAB><TAB> raise Exception ( "" Invalid row number. "" ) <TAB> else : <TAB><TAB> selected = self . cells [ rowNumber ] [ 0 ] . selected <TAB><TAB> for cell in self . cells [ rowNumber ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if selected : <TAB><TAB><TAB><TAB><TAB> cell . deselect ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> cell . select ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if highlight : <TAB><TAB><TAB><TAB><TAB> cell . mouseEnter ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> cell . mouseLeave ( )",if highlight is None :,if cell . selected :,73.73521103949206,98.43,False
2344,"def put ( self , session ) : <TAB> with sess_lock : <TAB><TAB> self . parent . put ( session ) <TAB><TAB> # Do not store the session if skip paths <TAB><TAB> for sp in self . skip_paths : <TAB><TAB><TAB> if request . path . startswith ( sp ) : <TAB><TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> del self . _cache [ session . sid ] <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> pass <TAB><TAB> self . _cache [ session . sid ] = session <TAB> self . _normalize ( )",if session . sid in self . _cache :,if session . sid in self . _cache :,100.0,100.00,True
2345,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 18 :,if tt == 18 :,100.0,100.00,True
2346,"def extract ( self , zip ) : <TAB> max_nb = maxNbFile ( self ) <TAB> for index , field in enumerate ( zip . array ( "" file "" ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . warning ( <TAB><TAB><TAB><TAB> "" ZIP archive contains many files, but only first  %s  files are processed "" <TAB><TAB><TAB><TAB> % max_nb <TAB><TAB><TAB> ) <TAB><TAB><TAB> break <TAB><TAB> self . processFile ( field )",if max_nb is not None and max_nb <= index :,if index > max_nb :,90.60564691728179,91.24,False
2347,"def get_norm ( norm , out_channels ) : <TAB> if isinstance ( norm , str ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> norm = { <TAB><TAB><TAB> "" BN "" : BatchNorm2d , <TAB><TAB><TAB> "" GN "" : lambda channels : nn . GroupNorm ( 32 , channels ) , <TAB><TAB><TAB> "" nnSyncBN "" : nn . SyncBatchNorm , # keep for debugging <TAB><TAB><TAB> "" "" : lambda x : x , <TAB><TAB> } [ norm ] <TAB> return norm ( out_channels )",if len ( norm ) == 0 :,"if norm . startswith ( ""bn"" ) :",93.08365969860866,94.35,False
2348,"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB><TAB> model_class = self . model_class <TAB><TAB> query_meta = self . get_query_meta ( ) <TAB><TAB> if self . _tuples : <TAB><TAB><TAB> ResultWrapper = TuplesQueryResultWrapper <TAB><TAB> elif self . _dicts : <TAB><TAB><TAB> ResultWrapper = DictQueryResultWrapper <TAB><TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB><TAB><TAB> ResultWrapper = NaiveQueryResultWrapper <TAB><TAB> <MASK> <TAB><TAB><TAB> ResultWrapper = AggregateQueryResultWrapper <TAB><TAB> else : <TAB><TAB><TAB> ResultWrapper = ModelQueryResultWrapper <TAB><TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB> self . _dirty = False <TAB><TAB> return self . _qr <TAB> else : <TAB><TAB> return self . _qr",elif self . _aggregate_rows :,elif self . _aggregate or not self . verify_aggregate ( ) :,70.36960408361126,96.05,False
2349,"def emitIpToDomainsData ( self , data , event ) : <TAB> self . emitRawRirData ( data , event ) <TAB> domains = data . get ( "" domains "" ) <TAB> if isinstance ( domains , list ) : <TAB><TAB> for domain in domains : <TAB><TAB><TAB> if self . checkForStop ( ) : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> domain = domain . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . emitHostname ( domain , event )",if domain :,if domain :,100.0,100.00,True
2350,"def delete ( self ) : <TAB> from weblate . trans . models import Change , Suggestion , Vote <TAB> fast_deletes = [ ] <TAB> for item in self . fast_deletes : <TAB><TAB> <MASK> <TAB><TAB><TAB> fast_deletes . append ( Vote . objects . filter ( suggestion__in = item ) ) <TAB><TAB><TAB> fast_deletes . append ( Change . objects . filter ( suggestion__in = item ) ) <TAB><TAB> fast_deletes . append ( item ) <TAB> self . fast_deletes = fast_deletes <TAB> return super ( ) . delete ( )",if item . model is Suggestion :,if Suggestion . objects . filter ( suggestion__in = item ) :,93.57686590784628,91.19,False
2351,"def token ( self ) : <TAB> if not self . _token : <TAB><TAB> try : <TAB><TAB><TAB> cookie_token = self . state [ "" request "" ] . headers . cookie [ CSRF_TOKEN ] . value <TAB><TAB> except KeyError : <TAB><TAB><TAB> cookie_token = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _token = cookie_token <TAB><TAB> else : <TAB><TAB><TAB> self . _token = get_random_string ( TOKEN_LENGTH ) <TAB> return self . _token",if len ( cookie_token ) == TOKEN_LENGTH :,if cookie_token :,71.13903400246325,92.78,False
2352,"def get_logs ( last_file = None , last_time = None ) : <TAB> try : <TAB><TAB> response = client . get_logs ( last_file = last_file , last_time = last_time ) <TAB><TAB> get_logs_streamer ( <TAB><TAB><TAB> show_timestamp = not hide_time , <TAB><TAB><TAB> all_containers = all_containers , <TAB><TAB><TAB> all_info = all_info , <TAB><TAB> ) ( response ) <TAB><TAB> return response <TAB> except ( ApiException , HTTPError ) as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> handle_cli_error ( <TAB><TAB><TAB><TAB> e , <TAB><TAB><TAB><TAB> message = "" Could not get logs for run ` {} `. "" . format ( client . run_uuid ) , <TAB><TAB><TAB> ) <TAB><TAB><TAB> sys . exit ( 1 )",if not follow :,if e . status_code == 404 :,79.24318752264608,96.23,False
2353,"def update ( self , targets ) : <TAB> Section . update ( self , targets ) <TAB> outputNames = set ( ) <TAB> for target in targets : <TAB><TAB> g = target . globals ( ) <TAB><TAB> outputNames . update ( [ k for k in g . keys ( ) if k . startswith ( "" output: "" ) ] ) <TAB> rows = [ ] <TAB> outputNames = sorted ( outputNames ) <TAB> for outputName in outputNames : <TAB><TAB> row = self . __rows . get ( outputName ) <TAB><TAB> <MASK> <TAB><TAB><TAB> row = _OutputRow ( outputName ) <TAB><TAB><TAB> self . __rows [ outputName ] = row <TAB><TAB> row . update ( targets ) <TAB><TAB> row . setAlternate ( len ( rows ) % 2 ) <TAB><TAB> rows . append ( row ) <TAB> self . _mainColumn ( ) [ : ] = rows",if row is None :,if not row :,77.03240369135762,98.08,False
2354,"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB><TAB> if git_branch_line . startswith ( "" * "" ) : <TAB><TAB><TAB> git_branch_line = git_branch_line [ 1 : ] <TAB><TAB> git_branch_line = git_branch_line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB><TAB><TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB><TAB> else : <TAB><TAB><TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned",if BRANCH_ALIAS_MARKER in git_branch_line :,if BRANCH_ALIAS_MARKER in git_branch_line :,100.0,100.00,True
2355,"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB><TAB> if _has_newline ( header ) : <TAB><TAB><TAB> return True <TAB> if self . subject : <TAB><TAB> if _has_newline ( self . subject ) : <TAB><TAB><TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB><TAB><TAB><TAB> if not line : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if _has_newline ( line ) : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> if len ( line . strip ( ) ) == 0 : <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if linenum > 0 and line [ 0 ] not in ""\t "" :",if linenum == 0 :,93.3663729004953,94.89,False
2356,"def resolve_references ( self , note , reflist ) : <TAB> assert len ( note [ "" ids "" ] ) == 1 <TAB> id = note [ "" ids "" ] [ 0 ] <TAB> for ref in reflist : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> ref . delattr ( "" refname "" ) <TAB><TAB> ref [ "" refid "" ] = id <TAB><TAB> assert len ( ref [ "" ids "" ] ) == 1 <TAB><TAB> note . add_backref ( ref [ "" ids "" ] [ 0 ] ) <TAB><TAB> ref . resolved = 1 <TAB> note . resolved = 1",if ref . resolved :,if ref . resolved :,100.0,100.00,True
2357,"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB><TAB> minDist = None <TAB><TAB> minGuide = None <TAB><TAB> for guide in self . guides [ color ] : <TAB><TAB><TAB> guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB> if minDist == None or guideDist < minDist : <TAB><TAB><TAB><TAB> minDist = guideDist <TAB><TAB><TAB><TAB> minGuide = guide <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if minGuide == None : <TAB><TAB><TAB> return <TAB><TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB> currentPos = minGuide <TAB><TAB> self . guides [ color ] . remove ( minGuide )","if dist ( currentPos , self . ends [ color ] ) == 1 :",if guideDist == 0 :,69.0775141384634,93.77,False
2358,"def __hierarchyViewKeyPress ( hierarchyView , event ) : <TAB> if event == __editSourceKeyPress : <TAB><TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB><TAB> <MASK> <TAB><TAB><TAB> __editSourceNode ( <TAB><TAB><TAB><TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB><TAB><TAB> ) <TAB><TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB><TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB><TAB> <MASK> <TAB><TAB><TAB> __editTweaksNode ( <TAB><TAB><TAB><TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB><TAB><TAB> ) <TAB><TAB> return True",if selectedPath is not None :,if selectedPath :,64.84944964222518,95.34,False
2359,"def getSubsegments ( self ) : <TAB> for num , localdata in self . lfh . LocalData : <TAB><TAB> for bucket , seginfo in localdata . SegmentInfo : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield Win32Subsegment ( self . trace , self . heap , seginfo . ActiveSubsegment )",if seginfo . ActiveSubsegment == 0 :,if seginfo . ActiveSubsegment == 0 :,75.0,100.00,True
2360,"def test_full_hd_bluray ( self ) : <TAB> cur_test = "" full_hd_bluray "" <TAB> cur_qual = common . Quality . FULLHDBLURAY <TAB> for name , tests in iteritems ( self . test_cases ) : <TAB><TAB> for test in tests : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( cur_qual , common . Quality . name_quality ( test ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertNotEqual ( cur_qual , common . Quality . name_quality ( test ) )",if name == cur_test :,if name == cur_test :,100.0,100.00,True
2361,"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB><TAB> self . clear ( ) <TAB><TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB><TAB> if self . op == "" + "" : <TAB><TAB><TAB> self . current + = num <TAB><TAB> elif self . op == "" - "" : <TAB><TAB><TAB> self . current - = num <TAB><TAB> elif self . op == "" * "" : <TAB><TAB><TAB> self . current * = num <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current / = num <TAB><TAB> self . op = op <TAB> else : <TAB><TAB> self . op = op <TAB><TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB><TAB> self . clear ( ) <TAB> return res","elif self . op == ""/"" :","elif self . op == ""/"" :",100.0,100.00,True
2362,"def strip_export_type ( path ) : <TAB> matched = re . search ( r "" #([a-zA-Z0-9 \ -]+ \\ +[a-zA-Z0-9 \ -]+)?$ "" , path . encode ( "" utf-8 "" ) ) <TAB> mime_type = None <TAB> if matched : <TAB><TAB> fragment = matched . group ( 0 ) <TAB><TAB> mime_type = matched . group ( 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> mime_type = mime_type . replace ( "" + "" , "" / "" ) <TAB><TAB> path = path [ : - len ( fragment ) ] <TAB> return ( path , mime_type )",if mime_type is not None :,"if fragment == ""export"" :",71.4948317962231,95.52,False
2363,"def _save_as_module ( file , data , binary = False ) : <TAB> if not data : <TAB><TAB> return <TAB> with open ( file , "" w "" ) as f : <TAB><TAB> f . write ( "" DATA= "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> f . write ( ' "" ' ) <TAB><TAB><TAB> f . write ( base64 . b64encode ( data ) . decode ( "" ascii "" ) ) <TAB><TAB><TAB> f . write ( ' "" ' ) <TAB><TAB> else : <TAB><TAB><TAB> f . write ( str ( data ) . replace ( "" \\ \\ "" , "" \\ "" ) ) <TAB><TAB> f . flush ( )",if binary :,if binary :,100.0,100.00,True
2364,"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB><TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB><TAB> <MASK> <TAB><TAB><TAB> if len ( self . _scopeStrictModes ) > 0 : <TAB><TAB><TAB><TAB> self . _scopeStrictModes . pop ( ) <TAB><TAB><TAB> self . _useStrictCurrent = True <TAB><TAB><TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent )","if text == '""use strict""' or text == ""'use strict'"" :",if text == self . _lastToken . text :,72.67608685374604,89.41,False
2365,"def run ( self , ttl = None ) : <TAB> self . zeroconf = zeroconf . Zeroconf ( ) <TAB> zeroconf . ServiceBrowser ( self . zeroconf , self . domain , MDNSHandler ( self ) ) <TAB> if ttl : <TAB><TAB> gobject . timeout_add ( ttl * 1000 , self . shutdown ) <TAB> self . __running = True <TAB> self . __mainloop = gobject . MainLoop ( ) <TAB> context = self . __mainloop . get_context ( ) <TAB> while self . __running : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> context . iteration ( True ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> time . sleep ( 0.1 ) <TAB><TAB> except KeyboardInterrupt : <TAB><TAB><TAB> break <TAB> self . zeroconf . close ( ) <TAB> logger . debug ( "" MDNSListener.run() quit "" )",if context . pending ( ) :,if context . is_running ( ) :,99.0964800476418,98.08,False
2366,"def topology_change_notify ( self , port_state ) : <TAB> notice = False <TAB> if port_state is PORT_STATE_FORWARD : <TAB><TAB> for port in self . ports . values ( ) : <TAB><TAB><TAB> if port . role is DESIGNATED_PORT : <TAB><TAB><TAB><TAB> notice = True <TAB><TAB><TAB><TAB> break <TAB> else : <TAB><TAB> notice = True <TAB> if notice : <TAB><TAB> self . send_event ( EventTopologyChange ( self . dp ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _transmit_tc_bpdu ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . _transmit_tcn_bpdu ( )",if self . is_root_bridge :,"if self . dp . type == ""transmit_tcn"" :",96.24706975246107,94.38,False
2367,def close_open_fds ( keep = None ) : # noqa <TAB> keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB> for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB><TAB> if fd not in keep : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> os . close ( fd ) <TAB><TAB><TAB> except OSError as exc : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise,if exc . errno != errno . EBADF :,if exc . errno != errno . ENOTCONN :,98.57401404372258,98.42,False
2368,"def collect_attributes ( options , node , master_list ) : <TAB> """"""Collect all attributes"""""" <TAB> for ii in node . instructions : <TAB><TAB> if field_check ( ii , "" attributes "" ) : <TAB><TAB><TAB> s = getattr ( ii , "" attributes "" ) <TAB><TAB><TAB> if isinstance ( s , list ) : <TAB><TAB><TAB><TAB> for x in s : <TAB><TAB><TAB><TAB><TAB> if x not in master_list : <TAB><TAB><TAB><TAB><TAB><TAB> master_list . append ( x ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> master_list . append ( s ) <TAB> for nxt in node . next . values ( ) : <TAB><TAB> collect_attributes ( options , nxt , master_list )",elif s != None and s not in master_list :,"elif isinstance ( s , dict ) :",93.70900059788116,94.62,False
2369,"def remove_test_run_directories ( expiry_time : int = 60 * 60 ) - > int : <TAB> removed = 0 <TAB> directories = glob . glob ( os . path . join ( UUID_VAR_DIR , "" test-backend "" , "" run_* "" ) ) <TAB> for test_run in directories : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> shutil . rmtree ( test_run ) <TAB><TAB><TAB><TAB> removed + = 1 <TAB><TAB><TAB> except FileNotFoundError : <TAB><TAB><TAB><TAB> pass <TAB> return removed",if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,if os . path . exists ( test_run ) and expiry_time < time . time,62.86368873879835,90.60,False
2370,"def read_work_titles ( fields ) : <TAB> found = [ ] <TAB> if "" 240 "" in fields : <TAB><TAB> for line in fields [ "" 240 "" ] : <TAB><TAB><TAB> title = join_subfield_values ( line , [ "" a "" , "" m "" , "" n "" , "" p "" , "" r "" ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> found . append ( title ) <TAB> if "" 130 "" in fields : <TAB><TAB> for line in fields [ "" 130 "" ] : <TAB><TAB><TAB> title = ""   "" . join ( get_lower_subfields ( line ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> found . append ( title ) <TAB> return { "" work_titles "" : found } if found else { }",if title not in found :,if title :,74.48529404455057,95.83,False
2371,"def _process_v1_msg ( prot , msg ) : <TAB> header = None <TAB> body = msg [ 1 ] <TAB> if not isinstance ( body , ( binary_type , mmap , memoryview ) ) : <TAB><TAB> raise ValidationError ( body , "" Body must be a bytestream. "" ) <TAB> if len ( msg ) > 2 : <TAB><TAB> header = msg [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( header , "" Header must be a dict. "" ) <TAB><TAB> for k , v in header . items ( ) : <TAB><TAB><TAB> header [ k ] = msgpack . unpackb ( v ) <TAB> ctx = MessagePackMethodContext ( prot , MessagePackMethodContext . SERVER ) <TAB> ctx . in_string = [ body ] <TAB> ctx . transport . in_header = header <TAB> return ctx","if not isinstance ( header , dict ) :","if not isinstance ( header , dict ) :",100.0,100.00,True
2372,"def find ( self , node ) : <TAB> typename = type ( node ) . __name__ <TAB> method = getattr ( self , "" find_ {} "" . format ( typename ) , None ) <TAB> if method is None : <TAB><TAB> fields = getattr ( node , "" _fields "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> for field in fields : <TAB><TAB><TAB> value = getattr ( node , field ) <TAB><TAB><TAB> for result in self . find ( value ) : <TAB><TAB><TAB><TAB> yield result <TAB> else : <TAB><TAB> for result in method ( node ) : <TAB><TAB><TAB> yield result",if fields is None :,if fields is None :,100.0,100.00,True
2373,"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB><TAB> out + = self . _str_header ( name ) <TAB><TAB> for param in self [ name ] : <TAB><TAB><TAB> parts = [ ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> parts . append ( param . name ) <TAB><TAB><TAB> if param . type : <TAB><TAB><TAB><TAB> parts . append ( param . type ) <TAB><TAB><TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB><TAB><TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB><TAB><TAB><TAB> out + = self . _str_indent ( param . desc ) <TAB><TAB> out + = [ "" "" ] <TAB> return out",if param . name :,if param . name :,100.0,100.00,True
2374,"def _get_image ( self , image_list , source ) : <TAB> if source . startswith ( "" wx "" ) : <TAB><TAB> img = wx . ArtProvider_GetBitmap ( source , wx . ART_OTHER , _SIZE ) <TAB> else : <TAB><TAB> path = os . path . join ( _BASE , source ) <TAB><TAB> <MASK> <TAB><TAB><TAB> img = wx . Image ( path , wx . BITMAP_TYPE_GIF ) . ConvertToBitmap ( ) <TAB><TAB> else : <TAB><TAB><TAB> img = wx . Image ( path , wx . BITMAP_TYPE_PNG ) . ConvertToBitmap ( ) <TAB> return image_list . Add ( img )","if source . endswith ( ""gif"" ) :","if os . name == ""nt"" :",85.7541763251276,94.82,False
2375,"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB><TAB> <MASK> <TAB><TAB><TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB><TAB> if type ( submob ) != AnnularSector : <TAB><TAB><TAB> # it's the shadow, don't dim it <TAB><TAB><TAB> continue <TAB><TAB> alpha = self . opacity_function ( r ) <TAB><TAB> submob . set_fill ( opacity = alpha )",if type ( submob ) == AnnularSector :,if submob . is_shadow :,92.84949452646384,95.59,False
2376,"def _sqlite_post_configure_engine ( url , engine , follower_ident ) : <TAB> from sqlalchemy import event <TAB> @event . listens_for ( engine , "" connect "" ) <TAB> def connect ( dbapi_connection , connection_record ) : <TAB><TAB> # use file DBs in all cases, memory acts kind of strangely <TAB><TAB> # as an attached <TAB><TAB> <MASK> <TAB><TAB><TAB> dbapi_connection . execute ( ' ATTACH DATABASE  "" test_schema.db ""  AS test_schema ' ) <TAB><TAB> else : <TAB><TAB><TAB> dbapi_connection . execute ( <TAB><TAB><TAB><TAB> ' ATTACH DATABASE  "" %s _test_schema.db ""  AS test_schema ' % follower_ident <TAB><TAB><TAB> )",if not follower_ident :,"if follower_ident == ""file"" :",97.84256864984839,95.96,False
2377,"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB><TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB><TAB> if conf_file : <TAB><TAB><TAB> with open ( conf_file ) as conf_handle : <TAB><TAB><TAB><TAB> value = fn ( conf_handle ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return value <TAB> return None",if value :,if value is not None :,67.05726683718629,96.59,False
2378,"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB><TAB> "" memcmp "" , <TAB><TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB><TAB> if a . is_null != b . is_null : <TAB><TAB><TAB> return False <TAB><TAB> if a is None : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> if a . ptr == b . ptr : <TAB><TAB><TAB> return True <TAB><TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if len ( a ) != b . len :,if b is None :,94.70727880884682,95.66,False
2379,"def _get_initialized_app ( app ) : <TAB> """"""Returns a reference to an initialized App instance."""""" <TAB> if app is None : <TAB><TAB> return firebase_admin . get_app ( ) <TAB> if isinstance ( app , firebase_admin . App ) : <TAB><TAB> initialized_app = firebase_admin . get_app ( app . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Illegal app argument. App instance not  "" <TAB><TAB><TAB><TAB> "" initialized via the firebase module. "" <TAB><TAB><TAB> ) <TAB><TAB> return app <TAB> raise ValueError ( <TAB><TAB> "" Illegal app argument. Argument must be of type  "" <TAB><TAB> '  firebase_admin.App, but given  "" {0} "" . ' . format ( type ( app ) ) <TAB> )",if app is not initialized_app :,if initialized_app is None :,95.54146188634459,97.60,False
2380,def compiled_query ( self ) : <TAB> <MASK> <TAB><TAB> self . lazy_init_lock_ . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . compiled_query_ = CompiledQuery ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . compiled_query_,if self . compiled_query_ is None :,if self . compiled_query_ is None :,100.0,100.00,True
2381,"def clean_subevent ( event , subevent ) : <TAB> if event . has_subevents : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( _ ( "" Subevent cannot be null for event series. "" ) ) <TAB><TAB> if event != subevent . event : <TAB><TAB><TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) <TAB> else : <TAB><TAB> if subevent : <TAB><TAB><TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) )",if not subevent :,if subevent . event is None :,69.19792862043775,95.50,False
2382,"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB><TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB><TAB><TAB> return "" TINYBLOB "" <TAB><TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB><TAB><TAB> return "" BLOB "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,100.0,100.00,True
2383,"def decompress ( self , data ) : <TAB> if not data : <TAB><TAB> return data <TAB> if not self . _first_try : <TAB><TAB> return self . _obj . decompress ( data ) <TAB> self . _data + = data <TAB> try : <TAB><TAB> decompressed = self . _obj . decompress ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _first_try = False <TAB><TAB><TAB> self . _data = None <TAB><TAB> return decompressed <TAB> except zlib . error : <TAB><TAB> self . _first_try = False <TAB><TAB> self . _obj = zlib . decompressobj ( - zlib . MAX_WBITS ) <TAB><TAB> try : <TAB><TAB><TAB> return self . decompress ( self . _data ) <TAB><TAB> finally : <TAB><TAB><TAB> self . _data = None",if decompressed :,if decompressed == 0 :,71.43125271477496,98.02,False
2384,"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB><TAB> self . events [ path ] . append ( events ) <TAB><TAB> if events | pyuv . fs . UV_RENAME : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . watches . pop ( path ) . close ( )",if not os . path . exists ( path ) :,if path in self . watches :,62.75014534605401,90.47,False
2385,"def __init__ ( self , duration , batch_shape , event_shape , validate_args = None ) : <TAB> if duration is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Infer duration from event_shape. <TAB><TAB><TAB> duration = event_shape [ 0 ] <TAB> elif duration != event_shape [ 0 ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" duration, event_shape mismatch:  {}  vs  {} "" . format ( duration , event_shape ) <TAB><TAB><TAB> ) <TAB><TAB> # Infer event_shape from duration. <TAB><TAB> event_shape = torch . Size ( ( duration , ) + event_shape [ 1 : ] ) <TAB> self . _duration = duration <TAB> super ( ) . __init__ ( batch_shape , event_shape , validate_args )",if event_shape [ 0 ] != 1 :,if len ( event_shape ) != 1 :,89.91046003925102,95.11,False
2386,"def _CheckPrerequisites ( self ) : <TAB> """"""Exits if any of the prerequisites is not met."""""" <TAB> if not FLAGS . kubectl : <TAB><TAB> raise Exception ( <TAB><TAB><TAB> "" Please provide path to kubectl tool using --kubectl  "" "" flag. Exiting. "" <TAB><TAB> ) <TAB> if not FLAGS . kubeconfig : <TAB><TAB> raise Exception ( <TAB><TAB><TAB> "" Please provide path to kubeconfig using --kubeconfig  "" "" flag. Exiting. "" <TAB><TAB> ) <TAB> if self . disk_specs and self . disk_specs [ 0 ] . disk_type == disk . STANDARD : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Please provide a list of Ceph Monitors using  "" "" --ceph_monitors flag. "" <TAB><TAB><TAB> )",if not FLAGS . ceph_monitors :,if not FLAGS . ceph_monitors :,100.0,100.00,True
2387,"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self . isSystemCurveIndex ( iFirstCurve ) : <TAB><TAB> return <TAB> nCurves = self . getNCurves ( ) <TAB> for i in range ( iFirstCurve , nCurves ) : <TAB><TAB> c = self . getSystemCurve ( i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> c . invalidate ( ) <TAB><TAB> elif i == iFirstCurve : <TAB><TAB><TAB> # if first curve isn't a slice, <TAB><TAB><TAB> break <TAB><TAB><TAB> # there are no dependent slices","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",if c . isSubscribed ( ) :,67.74694938432174,90.66,False
2388,"def find_backwards ( self , offset ) : <TAB> try : <TAB><TAB> for _ , token_type , token_value in reversed ( self . tokens [ self . offset : offset ] ) : <TAB><TAB><TAB> if token_type in ( "" comment "" , "" linecomment "" ) : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> prefix , comment = token_value . split ( None , 1 ) <TAB><TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return [ comment . rstrip ( ) ] <TAB><TAB> return [ ] <TAB> finally : <TAB><TAB> self . offset = offset",if prefix in self . comment_tags :,"if comment . startswith ( "" "" ) :",94.60366773999314,96.21,False
2389,"def parse_column_definitions ( self , elem ) : <TAB> for column_elem in elem . findall ( "" column "" ) : <TAB><TAB> name = column_elem . get ( "" name "" , None ) <TAB><TAB> assert name is not None , "" Required  ' name '  attribute missing from column def "" <TAB><TAB> index = column_elem . get ( "" index "" , None ) <TAB><TAB> assert index is not None , "" Required  ' index '  attribute missing from column def "" <TAB><TAB> index = int ( index ) <TAB><TAB> self . columns [ name ] = index <TAB><TAB> <MASK> <TAB><TAB><TAB> self . largest_index = index <TAB> assert "" value "" in self . columns , "" Required  ' value '  column missing from column def "" <TAB> if "" name "" not in self . columns : <TAB><TAB> self . columns [ "" name "" ] = self . columns [ "" value "" ]",if index > self . largest_index :,if index < self . largest_index :,99.23674572834169,98.91,False
2390,"def __find_smallest ( self ) : <TAB> """"""Find the smallest uncovered value in the matrix."""""" <TAB> minval = sys . maxsize <TAB> for i in range ( self . n ) : <TAB><TAB> for j in range ( self . n ) : <TAB><TAB><TAB> if ( not self . row_covered [ i ] ) and ( not self . col_covered [ j ] ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> minval = self . C [ i ] [ j ] <TAB> return minval",if minval > self . C [ i ] [ j ] :,if self . C [ i ] [ j ] < minval :,95.39926646519794,96.88,False
2391,"def includes_tools_for_display_in_tool_panel ( self ) : <TAB> if self . includes_tools : <TAB><TAB> tool_dicts = self . metadata [ "" tools "" ] <TAB><TAB> for tool_dict in tool_dicts : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False","if tool_dict . get ( ""add_to_tool_panel"" , True ) :","if tool_dict [ ""display"" ] == ""in"" :",86.78828097721815,85.04,False
2392,"def commit ( self , notify = False ) : <TAB> if self . editing : <TAB><TAB> text = self . _text <TAB><TAB> if text : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> value = self . type ( text ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> value = self . clamp_value ( value ) <TAB><TAB> else : <TAB><TAB><TAB> value = self . empty <TAB><TAB><TAB> if value is NotImplemented : <TAB><TAB><TAB><TAB> return <TAB><TAB> self . value = value <TAB><TAB> self . insertion_point = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . change_text ( unicode ( value ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . _text = unicode ( value ) <TAB><TAB> self . editing = False <TAB> else : <TAB><TAB> self . insertion_point = None",if notify :,if notify :,100.0,100.00,True
2393,"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB> start = vma . vm_start <TAB><TAB> end = vma . vm_end <TAB><TAB> # Skip the entire region. <TAB><TAB> if end < self . plugin_args . start : <TAB><TAB><TAB> continue <TAB><TAB> # Done. <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB> if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB><TAB><TAB><TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) )",if start > self . plugin_args . end :,if start >= self . plugin_args . end :,99.04081916954466,98.93,False
2394,"def _check_for_duplicate_host_entries ( self , task_entries ) : <TAB> non_host_statuses = ( <TAB><TAB> models . HostQueueEntry . Status . PARSING , <TAB><TAB> models . HostQueueEntry . Status . ARCHIVING , <TAB> ) <TAB> for task_entry in task_entries : <TAB><TAB> using_host = ( <TAB><TAB><TAB> task_entry . host is not None and task_entry . status not in non_host_statuses <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _assert_host_has_no_agent ( task_entry )",if using_host :,if using_host :,100.0,100.00,True
2395,"def get_biggest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB><TAB> <MASK> <TAB><TAB><TAB> lowest_wall = j [ "" wall_time "" ] <TAB><TAB> if lowest_wall < j [ "" wall_time "" ] : <TAB><TAB><TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall",if lowest_wall is None :,if lowest_wall is None :,100.0,100.00,True
2396,"def log_change_report ( self , old_value , new_value , include_details = False ) : <TAB> from octoprint . util import map_boolean <TAB> with self . _check_mutex : <TAB><TAB> self . _logger . info ( <TAB><TAB><TAB> "" Connectivity changed from  {}  to  {} "" . format ( <TAB><TAB><TAB><TAB> map_boolean ( old_value , "" online "" , "" offline "" ) , <TAB><TAB><TAB><TAB> map_boolean ( new_value , "" online "" , "" offline "" ) , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log_details ( )",if include_details :,if include_details :,100.0,100.00,True
2397,"def _include_block ( self , value , context = None ) : <TAB> if hasattr ( value , "" render_as_block "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_context = context . get_all ( ) <TAB><TAB> else : <TAB><TAB><TAB> new_context = { } <TAB><TAB> return jinja2 . Markup ( value . render_as_block ( context = new_context ) ) <TAB> return jinja2 . Markup ( value )",if context :,if context :,100.0,100.00,True
2398,"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try : <TAB><TAB> A , B = self [ 0 ] , other [ 0 ] <TAB><TAB> # uses logical clock value first <TAB><TAB> if A and B : # use logical clock if available <TAB><TAB><TAB> <MASK> # equal clocks use lower process id <TAB><TAB><TAB><TAB> return self [ 2 ] < other [ 2 ] <TAB><TAB><TAB> return A < B <TAB><TAB> return self [ 1 ] < other [ 1 ] # ... or use timestamp <TAB> except IndexError : <TAB><TAB> return NotImplemented",if A == B :,if A == B :,75.0,100.00,True
2399,"def _get_port ( ) : <TAB> while True : <TAB><TAB> port = 20000 + random . randint ( 1 , 9999 ) <TAB><TAB> for i in range ( 5 ) : <TAB><TAB><TAB> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <TAB><TAB><TAB> result = sock . connect_ex ( ( "" 127.0.0.1 "" , port ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> else : <TAB><TAB><TAB> return port",if result == 0 :,if not result :,66.5347263737513,96.33,False
2400,"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB><TAB> # Ensure targets is a tuple <TAB><TAB> if type ( targets ) != list and type ( targets ) != tuple : <TAB><TAB><TAB> targets = tuple ( <TAB><TAB><TAB><TAB> targets , <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> targets = tuple ( targets ) <TAB> for target in targets : <TAB><TAB> self . _fetch_targets ( api_client , q , target )",elif type ( targets ) != tuple :,if type ( targets ) != list and type ( targets ) != list :,95.35693363981612,92.45,False
2401,"def migrate_node_facts ( facts ) : <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB><TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB><TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for param in params [ role ] : <TAB><TAB><TAB><TAB> if param in facts [ role ] : <TAB><TAB><TAB><TAB><TAB> facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts",if role in facts :,if role in facts :,100.0,100.00,True
2402,"def build_dimension_param ( self , dimension , params ) : <TAB> prefix = "" Dimensions.member "" <TAB> i = 0 <TAB> for dim_name in dimension : <TAB><TAB> dim_value = dimension [ dim_name ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( dim_value , six . string_types ) : <TAB><TAB><TAB><TAB> dim_value = [ dim_value ] <TAB><TAB><TAB> for value in dim_value : <TAB><TAB><TAB><TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB><TAB><TAB><TAB> params [ "" %s . %d .Value "" % ( prefix , i + 1 ) ] = value <TAB><TAB><TAB><TAB> i + = 1 <TAB><TAB> else : <TAB><TAB><TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB><TAB><TAB> i + = 1",if dim_value :,if dim_value :,100.0,100.00,True
2403,"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB><TAB> for typ , key in keys : <TAB><TAB><TAB> flag = 1 <TAB><TAB><TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> flag = 0 <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if flag : <TAB><TAB><TAB><TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB><TAB> self . issuer_keys [ issuer ] [ use ] = keys",if _typ == typ and key is _key :,if typ in _key :,92.5071281785503,95.78,False
2404,"def run ( self ) : <TAB> while True : <TAB><TAB> message = self . in_queue . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . reset ( ) <TAB><TAB> elif message == EXIT : <TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> index , transaction = message <TAB><TAB><TAB> self . results_queue . put ( ( index , self . validate ( transaction ) ) )",if message == RESET :,if message == RESET :,100.0,100.00,True
2405,"def __run ( self ) : <TAB> threads = self . parameters ( ) [ "" threads "" ] . getTypedValue ( ) <TAB> with IECore . tbb_global_control ( <TAB><TAB> IECore . tbb_global_control . parameter . max_allowed_parallelism , <TAB><TAB> IECore . hardwareConcurrency ( ) if threads == 0 else threads , <TAB> ) : <TAB><TAB> self . _executeStartupFiles ( self . root ( ) . getName ( ) ) <TAB><TAB> # Append DEBUG message with process information to all messages <TAB><TAB> defaultMessageHandler = IECore . MessageHandler . getDefaultHandler ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> IECore . MessageHandler . setDefaultHandler ( <TAB><TAB><TAB><TAB> Gaffer . ProcessMessageHandler ( defaultMessageHandler ) <TAB><TAB><TAB> ) <TAB><TAB> return self . _run ( self . parameters ( ) . getValidatedValue ( ) )","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",if defaultMessageHandler :,96.01795988329343,95.24,False
2406,"def adjust_uri ( self , uri , relativeto ) : <TAB> """"""Adjust the given ``uri`` based on the given relative URI."""""" <TAB> key = ( uri , relativeto ) <TAB> if key in self . _uri_cache : <TAB><TAB> return self . _uri_cache [ key ] <TAB> if uri [ 0 ] != "" / "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> v = self . _uri_cache [ key ] = posixpath . join ( <TAB><TAB><TAB><TAB> posixpath . dirname ( relativeto ) , uri <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> v = self . _uri_cache [ key ] = "" / "" + uri <TAB> else : <TAB><TAB> v = self . _uri_cache [ key ] = uri <TAB> return v",if relativeto is not None :,if relativeto :,95.59157834199283,97.93,False
2407,"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB><TAB> <MASK> <TAB><TAB><TAB> decode . append ( "" & "" ) <TAB><TAB> elif c == "" - "" and decode : <TAB><TAB><TAB> if len ( decode ) == 1 : <TAB><TAB><TAB><TAB> r . append ( "" & "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB> decode = [ ] <TAB><TAB> elif decode : <TAB><TAB><TAB> decode . append ( c ) <TAB><TAB> else : <TAB><TAB><TAB> r . append ( c ) <TAB> if decode : <TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )","if c == ""&"" and not decode :","if c == ""+"" and decode :",97.37832372259089,98.30,False
2408,"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB><TAB> line = line . strip ( ) <TAB><TAB> if line . startswith ( "" - "" ) : <TAB><TAB><TAB> args . extend ( self . _split_option ( line ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> args . append ( line ) <TAB> return args","elif line and not line . startswith ( ""#"" ) :","elif line . startswith ( ""args"" ) :",92.94478322407986,94.74,False
2409,"def _method_events_callback ( self , values ) : <TAB> try : <TAB><TAB> previous_echoed = ( <TAB><TAB><TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB><TAB> ) <TAB><TAB> if previous_echoed . endswith ( "" foo1 "" ) : <TAB><TAB><TAB> return "" echo foo2 \n "" <TAB><TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB><TAB><TAB> return "" echo foo3 \n "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" exit \n "" <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB><TAB> return "" echo foo1 \n ""","elif previous_echoed . endswith ( ""foo3"" ) :","elif previous_echoed . endswith ( ""foo3"" ) :",100.0,100.00,True
2410,"def __delete_hook ( self , rpc ) : <TAB> try : <TAB><TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB><TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( DELETE_SUCCESSFUL ) <TAB><TAB> elif status == MemcacheDeleteResponse . NOT_FOUND : <TAB><TAB><TAB> result . append ( DELETE_ITEM_MISSING ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result",if status == MemcacheDeleteResponse . DELETED :,if status == MemcacheDeleteResponse . SUCCESSFUL :,98.53101635551671,98.52,False
2411,"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB><TAB> randomNode = Gaffer . Random ( ) <TAB><TAB> parentNode . addChild ( randomNode ) <TAB><TAB> <MASK> <TAB><TAB><TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB><TAB> elif isinstance ( plug , Gaffer . Color3fPlug ) : <TAB><TAB><TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode )","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :","if isinstance ( plug , Gaffer . Float3fPlug ) :",66.56699254152572,94.11,False
2412,"def escapeentities ( self , line ) : <TAB> "" Escape all Unicode characters to HTML entities. "" <TAB> result = "" "" <TAB> pos = TextPosition ( line ) <TAB> while not pos . finished ( ) : <TAB><TAB> if ord ( pos . current ( ) ) > 128 : <TAB><TAB><TAB> codepoint = hex ( ord ( pos . current ( ) ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> codepoint = hex ( ord ( pos . next ( ) ) + 0xF800 ) <TAB><TAB><TAB> result + = "" &# "" + codepoint [ 1 : ] + "" ; "" <TAB><TAB> else : <TAB><TAB><TAB> result + = pos . current ( ) <TAB><TAB> pos . skipcurrent ( ) <TAB> return result","if codepoint == ""0xd835"" :",if codepoint [ 0 ] == 0xF800 :,88.91729162459741,96.59,False
2413,def get_and_set_all_aliases ( self ) : <TAB> all_aliases = [ ] <TAB> for page in self . pages : <TAB><TAB> <MASK> <TAB><TAB><TAB> all_aliases . extend ( page . relations . aliases_norm ) <TAB><TAB> if page . relations . aliases is not None : <TAB><TAB><TAB> all_aliases . extend ( page . relations . aliases ) <TAB> return set ( all_aliases ),if page . relations . aliases_norm is not None :,if page . relations . aliases_norm is not None :,100.0,100.00,True
2414,"def _list_cases ( suite ) : <TAB> for test in suite : <TAB><TAB> <MASK> <TAB><TAB><TAB> _list_cases ( test ) <TAB><TAB> elif isinstance ( test , unittest . TestCase ) : <TAB><TAB><TAB> if support . match_test ( test ) : <TAB><TAB><TAB><TAB> print ( test . id ( ) )","if isinstance ( test , unittest . TestSuite ) :","if isinstance ( test , unittest . TestCaseList ) :",72.74638813235875,97.54,False
2415,"def get_next_requests ( self , max_n_requests , * * kwargs ) : <TAB> next_pages = [ ] <TAB> partitions = set ( kwargs . pop ( "" partitions "" , [ ] ) ) <TAB> for partition_id in range ( 0 , self . queue_partitions ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> results = self . queue . get_next_requests ( max_n_requests , partition_id ) <TAB><TAB> next_pages . extend ( results ) <TAB><TAB> self . logger . debug ( <TAB><TAB><TAB> "" Got  %d  requests for partition id  %d "" , len ( results ) , partition_id <TAB><TAB> ) <TAB> return next_pages",if partition_id not in partitions :,if partition_id not in partitions :,100.0,100.00,True
2416,"def __iter__ ( self ) : <TAB> if ( self . query is not None ) and sqlite . is_read_only_query ( self . query ) : <TAB><TAB> cur = self . connection . cursor ( ) <TAB><TAB> results = cur . execute ( self . query ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield [ col [ 0 ] for col in cur . description ] <TAB><TAB> for i , row in enumerate ( results ) : <TAB><TAB><TAB> if i > = self . limit : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> yield [ val for val in row ] <TAB> else : <TAB><TAB> yield",if self . headers :,if results :,69.85158081827785,97.43,False
2417,"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB><TAB> if operation == "" insert "" : <TAB><TAB><TAB> values . remove ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> old_value , new_value = values <TAB><TAB><TAB> if new_value . full_filename != old_value . full_filename : <TAB><TAB><TAB><TAB> os . unlink ( new_value . full_filename ) <TAB><TAB><TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( )","elif operation == ""update"" :","elif operation == ""delete"" :",98.38865646849847,98.49,False
2418,"def index ( self , value ) : <TAB> if self . _growing : <TAB><TAB> if self . _start < = value < self . _stop : <TAB><TAB><TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return int ( q ) <TAB> else : <TAB><TAB> if self . _start > = value > self . _stop : <TAB><TAB><TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) )",if r == self . _zero :,if r == 0 :,67.22496484553875,94.64,False
2419,"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB><TAB> value = body . get ( attribute ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( value , six . string_types ) : <TAB><TAB><TAB><TAB> body [ attribute ] = value . strip ( ) <TAB><TAB><TAB> if check_length : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> utils . check_string_length ( <TAB><TAB><TAB><TAB><TAB><TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> except exception . InvalidInput as error : <TAB><TAB><TAB><TAB><TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg )",if value is not None :,if value :,72.83051644147854,98.29,False
2420,"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB><TAB> if m [ 0 ] == "" "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> output ( "" |} "" ) <TAB><TAB><TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB><TAB><TAB> firstHeading = True <TAB><TAB> else : <TAB><TAB><TAB> output ( "" |- "" ) <TAB><TAB><TAB> output ( <TAB><TAB><TAB><TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB><TAB><TAB><TAB> + m [ 0 ] <TAB><TAB><TAB><TAB> + "" </tt></span> || ||  "" <TAB><TAB><TAB><TAB> + m [ 1 ] <TAB><TAB><TAB> ) <TAB> output ( "" |} "" )",if firstHeading :,if firstHeading :,100.0,100.00,True
2421,"def _get_platforms ( data ) : <TAB> platform_list = [ ] <TAB> for item in data : <TAB><TAB> if item . startswith ( "" PlatformEdit.html? "" ) : <TAB><TAB><TAB> parameter_list = item . split ( "" PlatformEdit.html? "" , 1 ) [ 1 ] . split ( "" & "" ) <TAB><TAB><TAB> for parameter in parameter_list : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> platform_list . append ( parameter . split ( "" = "" ) [ 1 ] ) <TAB> return platform_list","if parameter . startswith ( ""platformName"" ) :","if parameter . startswith ( ""platform"" ) :",98.52623024152395,98.40,False
2422,"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB><TAB> v = f . features [ name ] <TAB><TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB><TAB><TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB><TAB><TAB><TAB><TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","if name . startswith ( ""SCE_"" ) :","if name . startswith ( ""SCINTilla_"" ) :",98.93101970480124,98.76,False
2423,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB><TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB> if operation : <TAB><TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB><TAB> operation = definition <TAB><TAB><TAB> elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB> return definition <TAB> return operation",if not operation_name :,if definition . name . value == operation_name :,90.03919377565424,96.70,False
2424,"def _insertNewItemAtParent ( self , targetIndex ) : <TAB> if not self . isContainer ( targetIndex ) : <TAB><TAB> return <TAB> elif not self . isContainerOpen ( targetIndex ) : <TAB><TAB> uri = self . _rows [ targetIndex ] . uri <TAB><TAB> modelNode = self . getNodeForURI ( uri ) <TAB><TAB> <MASK> <TAB><TAB><TAB> modelNode . markForRefreshing ( ) <TAB><TAB> return <TAB> self . refreshView ( targetIndex )",if modelNode :,if modelNode :,100.0,100.00,True
2425,"def _get_trace ( self , model , guide , args , kwargs ) : <TAB> model_trace , guide_trace = super ( ) . _get_trace ( model , guide , args , kwargs ) <TAB> # Mark all sample sites with require_backward to gather enumerated <TAB> # sites and adjust cond_indep_stack of all sample sites. <TAB> for node in model_trace . nodes . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> log_prob = node [ "" packed "" ] [ "" unscaled_log_prob "" ] <TAB><TAB><TAB> require_backward ( log_prob ) <TAB> self . _saved_state = model , model_trace , guide_trace , args , kwargs <TAB> return model_trace , guide_trace","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :","if ""packed"" in node and ""unscaled_log_prob"" in node [",94.2772823432813,89.41,False
2426,"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB><TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB><TAB> if value is None : <TAB><TAB><TAB> continue <TAB><TAB> if not isinstance ( key , bytes ) : <TAB><TAB><TAB> key = text_type ( key ) . encode ( charset ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = text_type ( value ) . encode ( charset ) <TAB><TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value )","if not isinstance ( value , bytes ) :","if not isinstance ( value , bytes ) :",100.0,100.00,True
2427,"def handle_parse_result ( self , ctx , opts , args ) : <TAB> with augment_usage_errors ( ctx , param = self ) : <TAB><TAB> value = self . consume_value ( ctx , opts ) <TAB><TAB> try : <TAB><TAB><TAB> value = self . full_process_value ( ctx , value ) <TAB><TAB> except Exception : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> value = None <TAB><TAB> if self . callback is not None : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> value = invoke_param_callback ( self . callback , ctx , self , value ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise <TAB> if self . expose_value : <TAB><TAB> ctx . params [ self . name ] = value <TAB> return value , args",if not ctx . resilient_parsing :,if ctx . params [ self . name ] is None :,67.38875473517169,92.18,False
2428,"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB><TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB><TAB> if pattern [ i ] not in dict : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB><TAB><TAB> set_value . add ( list_str [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> if dict [ pattern [ i ] ] != list_str [ i ] : <TAB><TAB><TAB><TAB> return False <TAB> return True",if list_str [ i ] in set_value :,if set_value . issuperset ( dict [ pattern [ i ] ] ) :,68.15990551914841,94.51,False
2429,"def create ( self , path , wipe = False ) : <TAB> # type: (Text, bool) -> bool <TAB> _path = self . validatepath ( path ) <TAB> with ftp_errors ( self , path ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> empty_file = io . BytesIO ( ) <TAB><TAB><TAB> self . ftp . storbinary ( <TAB><TAB><TAB><TAB> str ( "" STOR  "" ) + _encode ( _path , self . ftp . encoding ) , empty_file <TAB><TAB><TAB> ) <TAB><TAB><TAB> return True <TAB> return False",if wipe or not self . isfile ( path ) :,if wipe :,94.46524092848631,94.00,False
2430,"def build_output_for_item ( self , item ) : <TAB> output = [ ] <TAB> for field in self . fields : <TAB><TAB> values = self . _get_item ( item , field ) <TAB><TAB> <MASK> <TAB><TAB><TAB> values = [ values ] <TAB><TAB> for value in values : <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> output . append ( self . build_output_for_single_value ( value ) ) <TAB> return "" "" . join ( output )","if not isinstance ( values , list ) :","if not isinstance ( values , list ) :",100.0,100.00,True
2431,"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB><TAB> if not name . startswith ( "" _ "" ) : <TAB><TAB><TAB> if not name [ 0 ] . isupper ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if is_resource_action ( member ) : <TAB><TAB><TAB><TAB><TAB><TAB> resource_methods [ name ] = member <TAB> return resource_methods","if not name . startswith ( ""wait_until"" ) :",if inspect . isclass ( member ) and inspect . isfunction ( member [ 0 ] ) :,68.57802648366447,90.97,False
2432,"def get_command ( cls ) : <TAB> ifconfig_cmd = "" ifconfig "" <TAB> for path in [ "" /sbin "" , "" /usr/sbin "" , "" /bin "" , "" /usr/bin "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> ifconfig_cmd = os . path . join ( path , ifconfig_cmd ) <TAB><TAB><TAB> break <TAB> ifconfig_cmd = ifconfig_cmd + ""  -a "" <TAB> return ifconfig_cmd","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",if os . path . exists ( path ) :,86.28208993425696,89.84,False
2433,"def main ( ) : <TAB> base_dir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "" .. "" , "" .. "" ) <TAB> for path in PATHS : <TAB><TAB> path = os . path . join ( base_dir , path ) <TAB><TAB> for root , _ , files in os . walk ( path ) : <TAB><TAB><TAB> for file in files : <TAB><TAB><TAB><TAB> extension = os . path . splitext ( file ) [ 1 ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> path = os . path . join ( root , file ) <TAB><TAB><TAB><TAB><TAB> validate_header ( path )",if extension in EXTENSIONS :,"if extension == "".py"" :",96.4153605855626,96.22,False
2434,"def auth_login ( request ) : <TAB> form = RegistrationForm ( request . POST or None ) <TAB> if form . is_valid ( ) : <TAB><TAB> authed_user = authenticate ( <TAB><TAB><TAB> username = form . cleaned_data [ "" username "" ] , <TAB><TAB><TAB> password = form . cleaned_data [ "" password "" ] , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> login ( request , authed_user ) <TAB><TAB><TAB> return HttpResponse ( "" Success "" ) <TAB> raise Http404",if authed_user :,if authed_user :,100.0,100.00,True
2435,"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB><TAB> user = self . users . get ( current_user . id , None ) <TAB><TAB> if user is None : <TAB><TAB><TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> user [ "" session_count "" ] + = 1 <TAB><TAB><TAB> user [ "" key "" ] = _key",if _new_login :,if _new_login :,100.0,100.00,True
2436,"def fetch ( self , fingerprints ) : <TAB> to_fetch = [ f for f in fingerprints if f not in self . _cache ] <TAB> self . _logger . debug ( "" cache size  %s "" % len ( self . _cache ) ) <TAB> self . _logger . debug ( "" to fetch  %d  from  %d "" % ( len ( to_fetch ) , len ( fingerprints ) ) ) <TAB> [ self . _redis_pipeline . hgetall ( key ) for key in to_fetch ] <TAB> responses = self . _redis_pipeline . execute ( ) <TAB> for index , key in enumerate ( to_fetch ) : <TAB><TAB> response = responses [ index ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _cache [ key ] = response [ FIELD_STATE ] <TAB><TAB> else : <TAB><TAB><TAB> self . _cache [ key ] = self . NOT_CRAWLED",if len ( response ) > 0 and FIELD_STATE in response :,if response [ FIELD_STATE ] :,68.96431083845758,94.74,False
2437,"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB> for part in parts : <TAB><TAB> if part : # split may produce empty string in the beginning or start <TAB><TAB><TAB> # split the data so that very long lines separated <TAB><TAB><TAB> for block in re . split ( <TAB><TAB><TAB><TAB> "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . _queued_io_events . append ( ( block , stream_name ) )",if block :,if block not in self . _queued_io_events :,73.42553864542825,95.13,False
2438,"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB><TAB> path = os . path . join ( path , self . index_file ) <TAB><TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> return self . get_static_file ( path , url ) <TAB><TAB> except IsDirectoryError : <TAB><TAB><TAB> if os . path . isfile ( os . path . join ( path , self . index_file ) ) : <TAB><TAB><TAB><TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path )",if os . path . isfile ( path ) :,if url . endswith ( self . index_file ) :,96.34076381916188,96.07,False
2439,"def module_list ( target , fast ) : <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB><TAB> module_name , ext = os . path . splitext ( name ) <TAB><TAB> if ext == "" .py "" or ext == "" "" and os . path . isdir ( os . path . join ( basedir , name ) ) : <TAB><TAB><TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> modules . append ( module_name ) <TAB> return set ( modules )",if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,if fast :,66.87008226285009,93.04,False
2440,"def housenumber ( self ) : <TAB> if self . address : <TAB><TAB> expression = r "" \ d+ "" <TAB><TAB> pattern = re . compile ( expression ) <TAB><TAB> match = pattern . search ( self . address ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return int ( match . group ( 0 ) )",if match :,if match :,100.0,100.00,True
2441,"def get_pip_version ( import_path = BASE_IMPORT_PATH ) : <TAB> try : <TAB><TAB> pip = importlib . import_module ( import_path ) <TAB> except ImportError : <TAB><TAB> <MASK> <TAB><TAB><TAB> return get_pip_version ( import_path = "" pip "" ) <TAB><TAB> else : <TAB><TAB><TAB> import subprocess <TAB><TAB><TAB> version = subprocess . check_output ( [ "" pip "" , "" --version "" ] ) <TAB><TAB><TAB> if version : <TAB><TAB><TAB><TAB> version = version . decode ( "" utf-8 "" ) . split ( ) [ 1 ] <TAB><TAB><TAB><TAB> return version <TAB><TAB><TAB> return "" 0.0.0 "" <TAB> version = getattr ( pip , "" __version__ "" , None ) <TAB> return version","if import_path != ""pip"" :","if import_path == ""python"" :",98.39799885845682,97.87,False
2442,"def __animate_progress ( self ) : <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True : <TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB> with self . __progress_lock : <TAB><TAB><TAB> if not self . __progress_status : <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . __progress_status . show_as_ready ( ) <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB> # Allow some time for progress status to be updated. <TAB><TAB> time . sleep ( sleep_time )",elif self . __show_animation :,elif self . __current_operation_name :,98.77444890896909,97.74,False
2443,"def range_key_names ( self ) : <TAB> keys = [ self . range_key_attr ] <TAB> for index in self . global_indexes : <TAB><TAB> range_key = None <TAB><TAB> for key in index . schema : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> range_key = keys . append ( key [ "" AttributeName "" ] ) <TAB><TAB> keys . append ( range_key ) <TAB> return keys","if key [ ""KeyType"" ] == ""RANGE"" :","if key [ ""Type"" ] == ""RangeKey"" :",96.38072638578201,96.01,False
2444,"def run ( self ) : <TAB> dist = self . distribution <TAB> commands = dist . command_options . keys ( ) <TAB> settings = { } <TAB> for cmd in commands : <TAB><TAB> if cmd == "" saveopts "" : <TAB><TAB><TAB> continue # don't save our own options! <TAB><TAB> for opt , ( src , val ) in dist . get_option_dict ( cmd ) . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> settings . setdefault ( cmd , { } ) [ opt ] = val <TAB> edit_config ( self . filename , settings , self . dry_run )","if src == ""command line"" :","if src == ""save"" :",98.32953667799553,97.88,False
2445,"def parse_move ( self , node ) : <TAB> old , new = "" "" , "" "" <TAB> for child in node : <TAB><TAB> tag , text = child . tag , child . text <TAB><TAB> text = text . strip ( ) if text else None <TAB><TAB> if tag == "" Old "" and text : <TAB><TAB><TAB> old = text <TAB><TAB> <MASK> <TAB><TAB><TAB> new = text <TAB> return Move ( old , new )","elif tag == ""New"" and text :","elif tag == ""New"" and text :",100.0,100.00,True
2446,"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB><TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB><TAB> for finfo in self . data : <TAB><TAB><TAB> self . __update_editor_margins ( finfo . editor ) <TAB><TAB><TAB> finfo . cleanup_analysis_results ( ) <TAB><TAB><TAB> if ( run_pyflakes or run_pep8 ) and current_finfo is not None : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 )",if current_finfo is not finfo :,if current_finfo is not None :,96.1482764846409,98.60,False
2447,"def tchg ( var , width ) : <TAB> "" Convert time string to given length "" <TAB> ret = "" %2d h %02d "" % ( var / 60 , var % 60 ) <TAB> <MASK> <TAB><TAB> ret = "" %2d h "" % ( var / 60 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ret = "" %2d d "" % ( var / 60 / 24 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret = "" %2d w "" % ( var / 60 / 24 / 7 ) <TAB> return ret",if len ( ret ) > width :,if width :,62.97752992948017,87.30,False
2448,"def spider_log_activity ( self , messages ) : <TAB> for i in range ( 0 , messages ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . sp_sl_p . send ( <TAB><TAB><TAB><TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , <TAB><TAB><TAB><TAB> b "" http://helloworld.com/way/to/the/sun/ "" + b "" 0 "" , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . sp_sl_p . send ( <TAB><TAB><TAB><TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , b "" http://way.to.the.sun "" + b "" 0 "" <TAB><TAB><TAB> ) <TAB> self . sp_sl_p . flush ( )",if i % 2 == 0 :,if i == messages - 1 :,70.87121003135749,97.42,False
2449,"def decode_serial ( self , offset ) : <TAB> serialnum = ( <TAB><TAB> ( self . cache [ offset + 3 ] << 24 ) <TAB><TAB> + ( self . cache [ offset + 2 ] << 16 ) <TAB><TAB> + ( self . cache [ offset + 1 ] << 8 ) <TAB><TAB> + self . cache [ offset ] <TAB> ) <TAB> serialstr = "" "" <TAB> is_alnum = True <TAB> for i in range ( 4 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> is_alnum = False <TAB><TAB><TAB> break <TAB><TAB> serialstr + = chr ( self . cache [ offset + 3 - i ] ) <TAB> serial = serialstr if is_alnum else str ( serialnum ) <TAB> self . ann_field ( offset , offset + 3 , "" Serial  "" + serial )",if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,if self . cache [ offset + 3 - i ] == 0 :,77.71216575051483,95.08,False
2450,def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB><TAB> if child . nodeType == child . TEXT_NODE : <TAB><TAB><TAB> yield child . nodeValue <TAB><TAB> <MASK> <TAB><TAB><TAB> for item in gettext ( child ) : <TAB><TAB><TAB><TAB> yield item,if child . nodeType == child . ELEMENT_NODE :,elif child . nodeType == child . ELEMENT_NODE :,72.2006714962613,97.33,False
2451,"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB><TAB> if text [ 0 ] in ""   \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = str ( self . best_indent ) <TAB><TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = "" - "" <TAB><TAB> <MASK> <TAB><TAB><TAB> hints + = "" + "" <TAB> return hints","elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :","if text [ - 2 ] not in ""\n\x85\u2028\u",65.73841023095518,89.45,False
2452,"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB><TAB> if arg is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> if return_type is str : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = bytes <TAB><TAB> else : <TAB><TAB><TAB> if return_type is bytes : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = str <TAB> if return_type is None : <TAB><TAB> return str # tempfile APIs return a str by default. <TAB> return return_type","if isinstance ( arg , bytes ) :",if arg . is_bytes :,95.51336152261031,97.18,False
2453,"def as_iconbitmap ( cls , rkey ) : <TAB> """"""Get image path for use in iconbitmap property"""""" <TAB> img = None <TAB> if rkey in cls . _stock : <TAB><TAB> data = cls . _stock [ rkey ] <TAB><TAB> <MASK> <TAB><TAB><TAB> fpath = data [ "" filename "" ] <TAB><TAB><TAB> fname = os . path . basename ( fpath ) <TAB><TAB><TAB> name , file_ext = os . path . splitext ( fname ) <TAB><TAB><TAB> file_ext = str ( file_ext ) . lower ( ) <TAB><TAB><TAB> if file_ext in TK_BITMAP_FORMATS : <TAB><TAB><TAB><TAB> img = BITMAP_TEMPLATE . format ( fpath ) <TAB> return img","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :","if ""filename"" in data :",66.62428123492128,89.79,False
2454,"def anonymize_ip ( ip ) : <TAB> if ip : <TAB><TAB> match = RE_FIRST_THREE_OCTETS_OF_IP . findall ( str ( ip ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" %s %s "" % ( match [ 0 ] [ 0 ] , "" 0 "" ) <TAB> return "" """,if match :,if match :,100.0,100.00,True
2455,"def serialize_tail ( self ) : <TAB> msg = bytearray ( ) <TAB> for v in self . info : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = v [ "" value "" ] . encode ( "" utf-8 "" ) <TAB><TAB> elif v [ "" type "" ] == BMP_TERM_TYPE_REASON : <TAB><TAB><TAB> value = struct . pack ( "" !H "" , v [ "" value "" ] ) <TAB><TAB> v [ "" len "" ] = len ( value ) <TAB><TAB> msg + = struct . pack ( self . _TLV_PACK_STR , v [ "" type "" ] , v [ "" len "" ] ) <TAB><TAB> msg + = value <TAB> return msg","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :","if v [ ""type"" ] == BMP_TERM_TYPE_UTF8 :",98.94679359886202,98.68,False
2456,"def get_django_comment ( text : str , i : int ) - > str : <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end < = len ( text ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return text [ i : end ] <TAB><TAB> if not unclosed_end and text [ end ] == "" < "" : <TAB><TAB><TAB> unclosed_end = end <TAB><TAB> end + = 1 <TAB> raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] )","if text [ end - 2 : end ] == ""#}"" :","if text [ end ] == ""<"" :",76.43983455923322,94.44,False
2457,"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB><TAB> if not win . ref : <TAB><TAB><TAB> continue <TAB><TAB> if win . Class ( ) != "" ComboBox "" or win . ref . Class ( ) != "" ComboBox "" : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> bugs . append ( <TAB><TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB><TAB> win , <TAB><TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB><TAB><TAB> { } , <TAB><TAB><TAB><TAB><TAB> testname , <TAB><TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return bugs",if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,if win . dropped_height != win . ref . dropped_height :,90.75542435209137,94.23,False
2458,"def testBadModeArgument ( self ) : <TAB> # verify that we get a sensible error message for bad mode argument <TAB> bad_mode = "" qwerty "" <TAB> try : <TAB><TAB> f = self . open ( TESTFN , bad_mode ) <TAB> except ValueError as msg : <TAB><TAB> <MASK> <TAB><TAB><TAB> s = str ( msg ) <TAB><TAB><TAB> if TESTFN in s or bad_mode not in s : <TAB><TAB><TAB><TAB> self . fail ( "" bad error message for invalid mode:  %s "" % s ) <TAB><TAB> # if msg.args[0] == 0, we're probably on Windows where there may be <TAB><TAB> # no obvious way to discover why open() failed. <TAB> else : <TAB><TAB> f . close ( ) <TAB><TAB> self . fail ( "" no error for invalid mode:  %s "" % bad_mode )",if msg . args [ 0 ] != 0 :,if msg . args [ 0 ] == 0 :,74.11205368297067,98.91,False
2459,"def command_group_expired ( self , command_group_name ) : <TAB> try : <TAB><TAB> deprecate_info = self . _command_loader . command_group_table [ <TAB><TAB><TAB> command_group_name <TAB><TAB> ] . group_kwargs . get ( "" deprecate_info "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return deprecate_info . expired ( ) <TAB> except AttributeError : <TAB><TAB> # Items with only token presence in the command table will not have any data. They can't be expired. <TAB><TAB> pass <TAB> return False",if deprecate_info :,if deprecate_info :,100.0,100.00,True
2460,"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB><TAB> if val == 0 : <TAB><TAB><TAB> assert 2500 - 500 < count < 2500 + 500 <TAB><TAB> <MASK> <TAB><TAB><TAB> assert 7500 - 500 < count < 7500 + 500 <TAB><TAB> else : <TAB><TAB><TAB> assert False",elif val == 1 :,elif val == 1 :,100.0,100.00,True
2461,"def get_labels ( directory ) : <TAB> cache = get_labels . __cache <TAB> if directory not in cache : <TAB><TAB> l = { } <TAB><TAB> for t in get_visual_configs ( directory ) [ 0 ] [ LABEL_SECTION ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> Messager . warning ( <TAB><TAB><TAB><TAB><TAB> "" In configuration, labels for  ' %s '  defined more than once. Only using the last set. "" <TAB><TAB><TAB><TAB><TAB> % t . storage_form ( ) , <TAB><TAB><TAB><TAB><TAB> - 1 , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> # first is storage for, rest are labels. <TAB><TAB><TAB> l [ t . storage_form ( ) ] = t . terms [ 1 : ] <TAB><TAB> cache [ directory ] = l <TAB> return cache [ directory ]",if t . storage_form ( ) in l :,if t . storage_form ( ) in l :,100.0,100.00,True
2462,"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB><TAB> if len ( i ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> val = int ( i , 2 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB><TAB> ret = bytes ( ret ) <TAB><TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB><TAB> return ret",if val > 255 or val < 0 :,if val == 0 :,84.24270631330802,96.18,False
2463,"def setCellValue ( self , row_idx , col , value ) : <TAB> assert col . id == "" repls-marked "" <TAB> with self . _lock : <TAB><TAB> rgroup = self . events [ row_idx ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> rgroup . _marked = value == "" true "" and True or False <TAB> if self . _tree : <TAB><TAB> self . _tree . invalidateCell ( row_idx , col )","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",if rgroup . _marked is None :,64.15957945318186,92.01,False
2464,"def create ( cls , settlement_manager , resource_id ) : <TAB> """"""Create a production chain that can produce the given resource."""""" <TAB> resource_producer = { } <TAB> for abstract_building in AbstractBuilding . buildings . values ( ) : <TAB><TAB> for resource , production_line in abstract_building . lines . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> resource_producer [ resource ] = [ ] <TAB><TAB><TAB> resource_producer [ resource ] . append ( ( production_line , abstract_building ) ) <TAB> return ProductionChain ( settlement_manager , resource_id , resource_producer )",if resource not in resource_producer :,if resource not in resource_producer :,100.0,100.00,True
2465,def get_all_partition_sets ( self ) : <TAB> partition_sets = [ ] <TAB> if self . partitions_handle : <TAB><TAB> partition_sets . extend ( self . partitions_handle . get_partition_sets ( ) ) <TAB> if self . scheduler_handle : <TAB><TAB> partition_sets . extend ( <TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB> schedule_def . get_partition_set ( ) <TAB><TAB><TAB><TAB> for schedule_def in self . scheduler_handle . all_schedule_defs ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> ] <TAB><TAB> ) <TAB> return partition_sets,"if isinstance ( schedule_def , PartitionScheduleDefinition )","if isinstance ( schedule_def , ScheduleDef )",98.30307939815681,98.65,False
2466,"def _sendDatapointsNow ( self , datapoints ) : <TAB> metrics = { } <TAB> payload_pb = Payload ( ) <TAB> for metric , datapoint in datapoints : <TAB><TAB> <MASK> <TAB><TAB><TAB> metric_pb = payload_pb . metrics . add ( ) <TAB><TAB><TAB> metric_pb . metric = metric <TAB><TAB><TAB> metrics [ metric ] = metric_pb <TAB><TAB> else : <TAB><TAB><TAB> metric_pb = metrics [ metric ] <TAB><TAB> point_pb = metric_pb . points . add ( ) <TAB><TAB> point_pb . timestamp = int ( datapoint [ 0 ] ) <TAB><TAB> point_pb . value = datapoint [ 1 ] <TAB> self . sendString ( payload_pb . SerializeToString ( ) )",if metric not in metrics :,if metric not in metrics :,100.0,100.00,True
2467,"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB><TAB> model_class = self . model_class <TAB><TAB> query_meta = self . get_query_meta ( ) <TAB><TAB> if self . _tuples : <TAB><TAB><TAB> ResultWrapper = TuplesQueryResultWrapper <TAB><TAB> <MASK> <TAB><TAB><TAB> ResultWrapper = DictQueryResultWrapper <TAB><TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB><TAB><TAB> ResultWrapper = NaiveQueryResultWrapper <TAB><TAB> elif self . _aggregate_rows : <TAB><TAB><TAB> ResultWrapper = AggregateQueryResultWrapper <TAB><TAB> else : <TAB><TAB><TAB> ResultWrapper = ModelQueryResultWrapper <TAB><TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB> self . _dirty = False <TAB><TAB> return self . _qr <TAB> else : <TAB><TAB> return self . _qr",elif self . _dicts :,elif self . _dicts :,100.0,100.00,True
2468,"def get_metrics ( ) : <TAB> classifier , feature_labels = load_classifier ( ) <TAB> available_metrics = ImgageMetrics . get_metric_classes ( ) <TAB> # todo review: DONE IN DOCS <TAB> #  effective_metrics isn't used after filling it with values <TAB> #  in the loops below <TAB> effective_metrics = [ ] <TAB> for metric in available_metrics : <TAB><TAB> for label in feature_labels : <TAB><TAB><TAB> for label_part in metric . get_labels ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> effective_metrics . append ( metric ) <TAB> return ( classifier , feature_labels , available_metrics )",if label_part == label and metric not in effective_metrics :,if label_part . lower ( ) == label :,95.59514715712241,94.62,False
2469,"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB><TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB><TAB> if "" pseudo-interface "" in nic . replace ( ""   "" , "" - "" ) . lower ( ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic )",if nic not in out :,if out != str ( nic ) :,68.77406692495423,95.65,False
2470,"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result : <TAB><TAB> if replace : <TAB><TAB><TAB> self [ key ] = result <TAB><TAB> <MASK> <TAB><TAB><TAB> result . parent = self <TAB><TAB><TAB> result . key = key <TAB> return result","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",elif result . parent is None :,91.31296624434238,88.98,False
2471,"def _EvaluateFile ( self , test_list , file ) : <TAB> ( name , ext ) = os . path . splitext ( file ) <TAB> if ext == "" .cc "" or ext == "" .cpp "" or ext == "" .c "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . SilentLog ( "" Found native test file  %s "" % file ) <TAB><TAB><TAB> test_list . append ( name )","if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",if name in self . native_files :,91.17390772111197,74.09,False
2472,"def leading_whitespace ( self , inputstring ) : <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> leading_ws . append ( c ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB><TAB> if self . indchar is None : <TAB><TAB><TAB> self . indchar = c <TAB><TAB> elif c != self . indchar : <TAB><TAB><TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws )",if c in legal_indent_chars :,if c in self . _whitespace_re . split ( ) :,95.31371596069434,94.03,False
2473,"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB><TAB> value = None <TAB><TAB> # XXX: how will this interact with orig_prefix ? <TAB><TAB> #      not exposing attrs for now if orig_prefix is set. <TAB><TAB> <MASK> <TAB><TAB><TAB> wrapped = self . wrapped <TAB><TAB><TAB> idents = getattr ( wrapped , "" ident_values "" , None ) <TAB><TAB><TAB> if idents : <TAB><TAB><TAB><TAB> value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB><TAB><TAB> ##else: <TAB><TAB><TAB> ##    ident = self.ident <TAB><TAB><TAB> ##    if ident is not None: <TAB><TAB><TAB> ##        value = [ident] <TAB><TAB> self . _ident_values = value <TAB> return value",if not self . orig_prefix :,if self . _ident_values is not None :,97.62364002023425,96.25,False
2474,"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB><TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB> for child in elem : <TAB><TAB><TAB> name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if name not in found_names : <TAB><TAB><TAB><TAB><TAB> found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB> cplns . append ( ( ilk , name ) ) <TAB><TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB> if not scoperef : <TAB><TAB><TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )",if name . startswith ( expr ) :,"if expr in child . get ( ""symbols"" ) :",88.11163368014664,96.26,False
2475,"def pid_from_name ( name ) : <TAB> # quick and dirty, works with all linux not depending on ps output <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB><TAB> try : <TAB><TAB><TAB> int ( pid ) <TAB><TAB> except : <TAB><TAB><TAB> continue <TAB><TAB> pname = "" "" <TAB><TAB> with open ( "" /proc/ %s /cmdline "" % pid , "" r "" ) as f : <TAB><TAB><TAB> pname = f . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return int ( pid ) <TAB> raise ProcessException ( "" No process with such name:  %s "" % name )",if name in pname :,if pname == name :,72.92677610495002,97.20,False
2476,"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB><TAB> try : <TAB><TAB><TAB> self . parent ( ) . touch ( ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> pass <TAB><TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB><TAB> if self . watcher : <TAB><TAB><TAB> self . watcher . emit ( "" created "" , self )",if not node . isdir :,if not node :,70.6954930424136,97.69,False
2477,"def setUp ( self ) : <TAB> BaseTestCase . setUp ( self ) <TAB> self . rawData = [ ] <TAB> self . dataByKey = { } <TAB> for i in range ( 1 , 11 ) : <TAB><TAB> stringCol = "" String  %d "" % i <TAB><TAB> fixedCharCol = ( "" Fixed Char  %d "" % i ) . ljust ( 40 ) <TAB><TAB> rawCol = "" Raw  %d "" % i <TAB><TAB> <MASK> <TAB><TAB><TAB> nullableCol = "" Nullable  %d "" % i <TAB><TAB> else : <TAB><TAB><TAB> nullableCol = None <TAB><TAB> dataTuple = ( i , stringCol , rawCol , fixedCharCol , nullableCol ) <TAB><TAB> self . rawData . append ( dataTuple ) <TAB><TAB> self . dataByKey [ i ] = dataTuple",if i % 2 :,if i % 2 == 0 :,70.43743609583186,97.70,False
2478,"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB><TAB> if vector : <TAB><TAB><TAB> if item < vector [ - 1 ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB> break <TAB><TAB> new_vector = vector + [ item ] <TAB><TAB> <MASK> <TAB><TAB><TAB> yield new_vector <TAB><TAB> elif level + 1 < len ( hits ) : <TAB><TAB><TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB> yield result",if level + 1 == len ( hits ) :,if level == 0 :,69.94823778153402,96.07,False
2479,"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . keydata : <TAB><TAB> <MASK> <TAB><TAB><TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB><TAB> elif hasattr ( self . key , k ) : <TAB><TAB><TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB><TAB> attrs . append ( "" private "" ) <TAB> return "" < %s  @0x %x   %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) )","if k == ""p"" :","if k == ""p"" :",100.0,100.00,True
2480,"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> if get_osx_theme ( ) == 1 : <TAB><TAB><TAB><TAB> theme = DARK <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> theme = LIGHT <TAB><TAB> else : <TAB><TAB><TAB> theme = self . guess_system_theme ( ) <TAB><TAB><TAB> if theme == Dark : <TAB><TAB><TAB><TAB> theme = MacOSDark <TAB> else : # user settings have highest priority <TAB><TAB> theme = self . _app . config . THEME <TAB> self . load_theme ( theme )","if sys . platform == ""darwin"" :",if self . _app . config . USE_DARK :,94.25332747830497,94.33,False
2481,"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB><TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB><TAB> c = s [ pos ] <TAB><TAB> if c == "" { "" : <TAB><TAB><TAB> depth + = 1 <TAB><TAB> elif c == "" } "" : <TAB><TAB><TAB> depth - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB><TAB> return pos <TAB> return None",if depth == 0 :,if depth == 0 :,100.0,100.00,True
2482,"def update_meter ( self , output , target , meters = { "" accuracy "" } ) : <TAB> output = self . __to_tensor ( output ) <TAB> target = self . __to_tensor ( target ) <TAB> for meter in meters : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __addmeter ( meter ) <TAB><TAB> if meter in [ "" ap "" , "" map "" , "" confusion "" ] : <TAB><TAB><TAB> target_th = self . _ver2tensor ( target ) <TAB><TAB><TAB> self . meter [ meter ] . add ( output , target_th ) <TAB><TAB> else : <TAB><TAB><TAB> self . meter [ meter ] . add ( output , target )",if meter not in self . meter . keys ( ) :,if not self . meter [ meter ] :,69.7114491412334,94.94,False
2483,"def _reinit_optimizers_with_oss ( self ) : <TAB> optimizers = self . lightning_module . trainer . optimizers <TAB> for x , optimizer in enumerate ( optimizers ) : <TAB><TAB> if is_lightning_optimizer ( optimizer ) : <TAB><TAB><TAB> optimizer = optimizer . _optimizer <TAB><TAB> <MASK> <TAB><TAB><TAB> optim_class = type ( optimizer ) <TAB><TAB><TAB> zero_optimizer = OSS ( <TAB><TAB><TAB><TAB> params = optimizer . param_groups , optim = optim_class , * * optimizer . defaults <TAB><TAB><TAB> ) <TAB><TAB><TAB> optimizers [ x ] = zero_optimizer <TAB><TAB><TAB> del optimizer <TAB> trainer = self . lightning_module . trainer <TAB> trainer . optimizers = optimizers <TAB> trainer . convert_to_lightning_optimizers ( )","if not isinstance ( optimizer , OSS ) :","if isinstance ( optimizer , OSS ) :",90.36396474090579,98.86,False
2484,"def OnSelChanged ( self , event ) : <TAB> self . item = event . GetItem ( ) <TAB> if self . item : <TAB><TAB> self . log . write ( "" OnSelChanged:  %s "" % self . GetItemText ( self . item ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . write ( <TAB><TAB><TAB><TAB> "" , BoundingRect:  %s \n "" % self . GetBoundingRect ( self . item , True ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . log . write ( "" \n "" ) <TAB> event . Skip ( )","if wx . Platform == ""__WXMSW__"" :",if self . GetBoundingRect ( self . item ) :,94.34914881408959,92.07,False
2485,"def parse_batch ( args ) : <TAB> errmsg = "" Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1). "" <TAB> if args . batch is not None : <TAB><TAB> rule , batchdef = parse_key_value_arg ( args . batch , errmsg = errmsg ) <TAB><TAB> try : <TAB><TAB><TAB> batch , batches = batchdef . split ( "" / "" ) <TAB><TAB><TAB> batch = int ( batch ) <TAB><TAB><TAB> batches = int ( batches ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise ValueError ( errmsg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( errmsg ) <TAB><TAB> return Batch ( rule , batch , batches ) <TAB> return None",if batch > batches or batch < 1 :,if len ( batches ) != 2 :,66.89374030198138,96.09,False
2486,"def get_foreign_key_columns ( self , engine , table_name ) : <TAB> foreign_keys = set ( ) <TAB> table = db_utils . get_table ( engine , table_name ) <TAB> inspector = reflection . Inspector . from_engine ( engine ) <TAB> for column_dict in inspector . get_columns ( table_name ) : <TAB><TAB> column_name = column_dict [ "" name "" ] <TAB><TAB> column = getattr ( table . c , column_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> foreign_keys . add ( column_name ) <TAB> return foreign_keys",if column . foreign_keys :,if column . foreign_key :,73.502583792969,98.37,False
2487,"def update ( self , t ) : <TAB> l = int ( t * self . nr_of_tiles ) <TAB> for i in range ( self . nr_of_tiles ) : <TAB><TAB> t = self . tiles_order [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . turn_off_tile ( t ) <TAB><TAB> else : <TAB><TAB><TAB> self . turn_on_tile ( t )",if i < l :,if l < int ( t * self . nr_of_tiles ) :,64.12965798075649,87.92,False
2488,"def read ( self , amt = None ) : <TAB> # the _rbuf test is only in this first if for speed.  It's not <TAB> # logically necessary <TAB> if self . _rbuf and not amt is None : <TAB><TAB> L = len ( self . _rbuf ) <TAB><TAB> <MASK> <TAB><TAB><TAB> amt - = L <TAB><TAB> else : <TAB><TAB><TAB> s = self . _rbuf [ : amt ] <TAB><TAB><TAB> self . _rbuf = self . _rbuf [ amt : ] <TAB><TAB><TAB> return s <TAB> s = self . _rbuf + self . _raw_read ( amt ) <TAB> self . _rbuf = b "" "" <TAB> return s",if amt > L :,if amt > L :,100.0,100.00,True
2489,"def draw_menu_button ( self , context , layout , node , text ) : <TAB> if ( <TAB><TAB> hasattr ( node . id_data , "" sv_show_socket_menus "" ) <TAB><TAB> and node . id_data . sv_show_socket_menus <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> layout . menu ( "" SV_MT_SocketOptionsMenu "" , text = "" "" , icon = "" TRIA_DOWN "" )",if self . is_output or self . is_linked or not self . use_prop :,if node . id_data . sv_show_socket_menus :,59.055041018164765,85.94,False
2490,"def __enter__ ( self ) : <TAB> with DB . connection_context ( ) : <TAB><TAB> session_record = SessionRecord ( ) <TAB><TAB> session_record . f_session_id = self . _session_id <TAB><TAB> session_record . f_engine_name = self . _engine_name <TAB><TAB> session_record . f_engine_type = EngineType . STORAGE <TAB><TAB> # TODO: engine address <TAB><TAB> session_record . f_engine_address = { } <TAB><TAB> session_record . f_create_time = current_timestamp ( ) <TAB><TAB> rows = session_record . save ( force_insert = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( f "" create session record  { self . _session_id }  failed "" ) <TAB><TAB> LOGGER . debug ( f "" save session  { self . _session_id }  record "" ) <TAB> self . create ( ) <TAB> return self",if rows != 1 :,if not rows :,98.27345714579307,97.85,False
2491,"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB><TAB> if self . server : <TAB><TAB><TAB> self . server . stop ( 2.0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB><TAB> BaseTest . tearDown ( self )",if self . sl_hdlr :,if self . sl_hdlr :,75.0,100.00,True
2492,"def _dec_device ( self , srcdev , dstdev ) : <TAB> if srcdev : <TAB><TAB> self . srcdevs [ srcdev ] - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . srcdevs [ srcdev ] <TAB><TAB> self . _set_limits ( "" read "" , self . srcdevs ) <TAB> if dstdev : <TAB><TAB> self . dstdevs [ dstdev ] - = 1 <TAB><TAB> if self . dstdevs [ dstdev ] == 0 : <TAB><TAB><TAB> del self . dstdevs [ dstdev ] <TAB><TAB> self . _set_limits ( "" write "" , self . dstdevs )",if self . srcdevs [ srcdev ] == 0 :,if self . srcdevs [ srcdev ] == 0 :,100.0,100.00,True
2493,"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _tail <TAB><TAB> node = self . _root <TAB><TAB> level = self . _shift <TAB><TAB> while level > 0 : <TAB><TAB><TAB> assert isinstance ( node , Node ) <TAB><TAB><TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB><TAB><TAB> level - = 5 <TAB><TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" )",if i >= self . tailoff ( ) :,if i >= self . _tail_offset :,95.2758110123601,96.73,False
2494,"def convert_tensor ( self , offsets , sizes ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( offsets ) : <TAB><TAB> utterances = [ ] <TAB><TAB> for p , utt in enumerate ( batch ) : <TAB><TAB><TAB> size = sizes [ b ] [ p ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> utterances . append ( utt [ 0 : size ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> utterances . append ( torch . tensor ( [ ] , dtype = torch . int ) ) <TAB><TAB> results . append ( utterances ) <TAB> return results",if sizes [ b ] [ p ] > 0 :,if size > 0 :,67.55030004231293,95.12,False
2495,"def _predict_proba ( self , X , preprocess = True ) : <TAB> if preprocess : <TAB><TAB> X = self . preprocess ( X ) <TAB> if self . problem_type == REGRESSION : <TAB><TAB> return self . model . predict ( X ) <TAB> y_pred_proba = self . model . predict_proba ( X ) <TAB> if self . problem_type == BINARY : <TAB><TAB> if len ( y_pred_proba . shape ) == 1 : <TAB><TAB><TAB> return y_pred_proba <TAB><TAB> <MASK> <TAB><TAB><TAB> return y_pred_proba [ : , 1 ] <TAB><TAB> else : <TAB><TAB><TAB> return y_pred_proba <TAB> elif y_pred_proba . shape [ 1 ] > 2 : <TAB><TAB> return y_pred_proba <TAB> else : <TAB><TAB> return y_pred_proba [ : , 1 ]",elif y_pred_proba . shape [ 1 ] > 1 :,elif len ( y_pred_proba . shape ) == 2 :,96.06933703184049,96.31,False
2496,def timeout ( self ) : <TAB> now = ptime . time ( ) <TAB> dt = now - self . lastPlayTime <TAB> if dt < 0 : <TAB><TAB> return <TAB> n = int ( self . playRate * dt ) <TAB> if n != 0 : <TAB><TAB> self . lastPlayTime + = float ( n ) / self . playRate <TAB><TAB> <MASK> <TAB><TAB><TAB> self . play ( 0 ) <TAB><TAB> self . jumpFrames ( n ),"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",if self . lastPlayTime >= self . lastPlayRate :,60.09957010747715,85.35,False
2497,"def __init__ ( self , data , weights = None , ddof = 0 ) : <TAB> self . data = np . asarray ( data ) <TAB> if weights is None : <TAB><TAB> self . weights = np . ones ( self . data . shape [ 0 ] ) <TAB> else : <TAB><TAB> self . weights = np . asarray ( weights ) . astype ( float ) <TAB><TAB> # TODO: why squeeze? <TAB><TAB> <MASK> <TAB><TAB><TAB> self . weights = self . weights . squeeze ( ) <TAB> self . ddof = ddof",if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,if self . weights . ndim == 1 :,92.38244465688683,88.87,False
2498,"def writerow ( self , row ) : <TAB> unicode_row = [ ] <TAB> for col in row : <TAB><TAB> <MASK> <TAB><TAB><TAB> unicode_row . append ( col . encode ( "" utf-8 "" ) . strip ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> unicode_row . append ( col ) <TAB> self . writer . writerow ( unicode_row ) <TAB> # Fetch UTF-8 output from the queue ... <TAB> data = self . queue . getvalue ( ) <TAB> data = data . decode ( "" utf-8 "" ) <TAB> # ... and reencode it into the target encoding <TAB> data = self . encoder . encode ( data ) <TAB> # write to the target stream <TAB> self . stream . write ( data ) <TAB> # empty queue <TAB> self . queue . truncate ( 0 )",if type ( col ) == str or type ( col ) == unicode :,"if isinstance ( col , unicode_str ) :",88.5652997264675,92.96,False
2499,"def __init__ ( self , choices , allow_blank = False , * * kwargs ) : <TAB> self . choiceset = choices <TAB> self . allow_blank = allow_blank <TAB> self . _choices = dict ( ) <TAB> # Unpack grouped choices <TAB> for k , v in choices : <TAB><TAB> <MASK> <TAB><TAB><TAB> for k2 , v2 in v : <TAB><TAB><TAB><TAB> self . _choices [ k2 ] = v2 <TAB><TAB> else : <TAB><TAB><TAB> self . _choices [ k ] = v <TAB> super ( ) . __init__ ( * * kwargs )","if type ( v ) in [ list , tuple ] :","if isinstance ( v , ( list , tuple ) ) :",95.358773600939,94.56,False
2500,"def simp_ext ( _ , expr ) : <TAB> if expr . op . startswith ( "" zeroExt_ "" ) : <TAB><TAB> arg = expr . args [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return arg <TAB><TAB> return ExprCompose ( arg , ExprInt ( 0 , expr . size - arg . size ) ) <TAB> if expr . op . startswith ( "" signExt_ "" ) : <TAB><TAB> arg = expr . args [ 0 ] <TAB><TAB> add_size = expr . size - arg . size <TAB><TAB> new_expr = ExprCompose ( <TAB><TAB><TAB> arg , <TAB><TAB><TAB> ExprCond ( <TAB><TAB><TAB><TAB> arg . msb ( ) , ExprInt ( size2mask ( add_size ) , add_size ) , ExprInt ( 0 , add_size ) <TAB><TAB><TAB> ) , <TAB><TAB> ) <TAB><TAB> return new_expr <TAB> return expr",if expr . size == arg . size :,if arg . size == 0 :,84.66552970429473,97.42,False
2501,"def mark_differences ( value : str , compare_against : str ) : <TAB> result = [ ] <TAB> for i , char in enumerate ( value ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result . append ( ' <font color= "" red "" > {} </font> ' . format ( char ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> result . append ( char ) <TAB><TAB> except IndexError : <TAB><TAB><TAB> result . append ( char ) <TAB> return "" "" . join ( result )",if char != compare_against [ i ] :,if compare_against == char :,93.85967937247524,94.80,False
2502,"def run_query ( self , query , user ) : <TAB> url = "" %s %s "" % ( self . base_url , "" & "" . join ( query . split ( "" \n "" ) ) ) <TAB> error = None <TAB> data = None <TAB> try : <TAB><TAB> response = requests . get ( url , auth = self . auth , verify = self . verify ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data = _transform_result ( response ) <TAB><TAB> else : <TAB><TAB><TAB> error = "" Failed getting results ( %d ) "" % response . status_code <TAB> except Exception as ex : <TAB><TAB> data = None <TAB><TAB> error = str ( ex ) <TAB> return data , error",if response . status_code == 200 :,if response . status_code == 200 :,100.0,100.00,True
2503,"def on_enter ( self ) : <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB><TAB> else : <TAB><TAB><TAB> if not self . focus_color : <TAB><TAB><TAB><TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . md_bg_color = self . focus_color","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",if self . focus_color == self . theme_cls . bg_normal :,89.03982303100737,93.26,False
2504,"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> try : <TAB><TAB><TAB> if self . storage_account_name is not None : <TAB><TAB><TAB><TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> try : <TAB><TAB><TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( )",if self . hosted_service_name is not None :,if self . hosted_service_name is not None :,75.0,100.00,True
2505,"def name2cp ( k ) : <TAB> if k == "" apos "" : <TAB><TAB> return ord ( "" ' "" ) <TAB> if hasattr ( htmlentitydefs , "" name2codepoint "" ) : # requires Python 2.3 <TAB><TAB> return htmlentitydefs . name2codepoint [ k ] <TAB> else : <TAB><TAB> k = htmlentitydefs . entitydefs [ k ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return int ( k [ 2 : - 1 ] ) # not in latin-1 <TAB><TAB> return ord ( codecs . latin_1_decode ( k ) [ 0 ] )","if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :","if k . startswith ( ""latin-"" ) :",70.26570328164283,91.53,False
2506,"def _para_set ( self , params , part ) : <TAB> if len ( params ) == 0 : <TAB><TAB> result = suggest ( [ i . get_name ( ) for i in self . _options ] , part ) <TAB><TAB> return result <TAB> elif len ( params ) == 1 : <TAB><TAB> paramName = params [ 0 ] <TAB><TAB> if paramName not in self . _options : <TAB><TAB><TAB> return [ ] <TAB><TAB> opt = self . _options [ paramName ] <TAB><TAB> paramType = opt . get_type ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> values = [ opt . get_default_value ( ) == "" True "" and "" False "" or "" True "" ] <TAB><TAB> else : <TAB><TAB><TAB> values = self . _memory [ paramName ] <TAB><TAB> return suggest ( values , part ) <TAB> else : <TAB><TAB> return [ ]","if paramType == ""boolean"" :","if paramType == ""bool"" :",99.13337200180969,98.97,False
2507,"def hexcmp ( x , y ) : <TAB> try : <TAB><TAB> a = int ( x , 16 ) <TAB><TAB> b = int ( y , 16 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return - 1 <TAB><TAB> if a > b : <TAB><TAB><TAB> return 1 <TAB><TAB> return 0 <TAB> except : <TAB><TAB> return cmp ( x , y )",if a < b :,if a < b :,100.0,100.00,True
2508,"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> if arguments : <TAB><TAB><TAB><TAB> self . cursor . execute ( statement , arguments ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . cursor . execute ( statement ) <TAB><TAB> except sqlite3 . OperationalError as ex : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB><TAB> return self . cursor . fetchall ( )","if ""locked"" not in getSafeExString ( ex ) :",if ex . errno != sqlite3 . EEXIST :,93.68729541584821,94.56,False
2509,"def _test_forever ( self , tests ) : <TAB> while True : <TAB><TAB> for test_name in tests : <TAB><TAB><TAB> yield test_name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> if self . ns . fail_env_changed and self . environment_changed : <TAB><TAB><TAB><TAB> return",if self . bad :,"if self . ns . fail_fast_run and self . test_name in ( """,57.38076955833038,85.58,False
2510,"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB><TAB> user = self . _users [ username ] <TAB><TAB> if user . room : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB><TAB> self . _users . pop ( username ) <TAB><TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB><TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB><TAB> self . _client . lastLeftTime = time . time ( ) <TAB><TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( )",if self . isRoomSame ( user . room ) :,if not hideFromOSD :,66.99959490298247,95.28,False
2511,"def AutoTest ( ) : <TAB> with open ( sys . argv [ 1 ] , "" rb "" ) as f : <TAB><TAB> for line in f . read ( ) . split ( b "" \n "" ) : <TAB><TAB><TAB> line = BYTES2SYSTEMSTR ( line . strip ( ) ) <TAB><TAB><TAB> if not line : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> elif line . startswith ( "" # "" ) : <TAB><TAB><TAB><TAB> print ( line ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> print ( "" >>>  "" + line ) <TAB><TAB><TAB><TAB> os . system ( line ) <TAB><TAB><TAB><TAB> sys . stdout . write ( "" \n press enter to continue... "" ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> input ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> raw_input ( ) <TAB><TAB><TAB><TAB> sys . stdout . write ( "" \n "" )",if PY3 :,"if sys . argv [ 1 ] == b""input"" :",96.90466973245069,95.64,False
2512,"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB><TAB> <MASK> <TAB><TAB><TAB> return layout_object <TAB><TAB> elif hasattr ( layout_object , "" get_field_names "" ) : <TAB><TAB><TAB> gf = get_first_field ( layout_object , clz ) <TAB><TAB><TAB> if gf : <TAB><TAB><TAB><TAB> return gf","if issubclass ( layout_object . __class__ , clz ) :","if isinstance ( layout_object , clz ) :",91.86497756322461,92.13,False
2513,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB><TAB> if key not in valid_keys : <TAB><TAB><TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB> if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB> 1024 <TAB><TAB><TAB><TAB> )","if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :","if kwargs [ ""event_data"" ] [ key ] :",72.2198207551363,96.54,False
2514,"def visit_productionlist ( self , node ) : <TAB> self . new_state ( ) <TAB> names = [ ] <TAB> for production in node : <TAB><TAB> names . append ( production [ "" tokenname "" ] ) <TAB> maxlen = max ( len ( name ) for name in names ) <TAB> for production in node : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_text ( production [ "" tokenname "" ] . ljust ( maxlen ) + ""  ::= "" ) <TAB><TAB><TAB> lastname = production [ "" tokenname "" ] <TAB><TAB> else : <TAB><TAB><TAB> self . add_text ( "" %s      "" % ( ""   "" * len ( lastname ) ) ) <TAB><TAB> self . add_text ( production . astext ( ) + self . nl ) <TAB> self . end_state ( wrap = False ) <TAB> raise nodes . SkipNode","if production [ ""tokenname"" ] :","if production [ ""tokenname"" ] :",100.0,100.00,True
2515,"def uuid ( self ) : <TAB> if not getattr ( self , "" _uuid "" , None ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _uuid = self . repository . _kp_uuid ( <TAB><TAB><TAB><TAB> self . path <TAB><TAB><TAB> ) # Use repository UUID (even if None) <TAB><TAB> else : <TAB><TAB><TAB> self . _uuid = str ( uuid . uuid4 ( ) ) <TAB> return self . _uuid",if self . repository is not None :,if self . repository :,93.10369770075242,96.54,False
2516,"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB> values = [ values ] <TAB> for v in values : <TAB><TAB> v = str ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _definition . pop ( v , None ) <TAB><TAB> elif self . _definition == "" ANY "" : <TAB><TAB><TAB> if v == "" ANY "" : <TAB><TAB><TAB><TAB> self . _definition = [ ] <TAB><TAB> elif v in self . _definition : <TAB><TAB><TAB> self . _definition . remove ( v ) <TAB> if ( <TAB><TAB> self . _value is not None <TAB><TAB> and self . _value not in self . _definition <TAB><TAB> and self . _not_any ( ) <TAB> ) : <TAB><TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )","if isinstance ( self . _definition , dict ) :","if self . _definition == ""NONE"" :",69.7160818931041,96.97,False
2517,"def make ( self ) : <TAB> pygments_dir = join ( self . dir , "" externals "" , "" pygments "" ) <TAB> if exists ( pygments_dir ) : <TAB><TAB> run_in_dir ( "" hg pull "" , pygments_dir , self . log . info ) <TAB><TAB> run_in_dir ( "" hg update "" , pygments_dir , self . log . info ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( dirname ( pygments_dir ) ) <TAB><TAB> run_in_dir ( <TAB><TAB><TAB> "" hg clone http://dev.pocoo.org/hg/pygments-main  %s "" <TAB><TAB><TAB> % basename ( pygments_dir ) , <TAB><TAB><TAB> dirname ( pygments_dir ) , <TAB><TAB><TAB> self . log . info , <TAB><TAB> )",if not exists ( dirname ( pygments_dir ) ) :,if not exists ( dirname ( pygments_dir ) ) :,100.0,100.00,True
2518,def set_field ( self ) : <TAB> i = 0 <TAB> for string in self . display_string : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . config [ self . field + str ( i ) ] = self . conversion_fn ( self . str [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . config [ self . field + str ( i ) ] = self . str [ i ] <TAB><TAB> i = i + 1,if self . conversion_fn :,if self . conversion_fn :,100.0,100.00,True
2519,"def cleanup ( self ) : <TAB> with self . lock : <TAB><TAB> for proc in self . processes : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> proc . join ( ) <TAB><TAB><TAB> self . processes . remove ( proc ) <TAB><TAB><TAB> log . debug ( "" Subprocess  %s  cleaned up "" , proc . name )",if proc . is_alive ( ) :,if proc . is_alive ( ) :,75.0,100.00,True
2520,"def setup ( self , gen ) : <TAB> Node . setup ( self , gen ) <TAB> for c in self . children : <TAB><TAB> c . setup ( gen ) <TAB> if not self . accepts_epsilon : <TAB><TAB> # If it's not already accepting epsilon, it might now do so. <TAB><TAB> for c in self . children : <TAB><TAB><TAB> # any non-epsilon means all is non-epsilon <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> self . accepts_epsilon = 1 <TAB><TAB><TAB> gen . changed ( )",if not c . accepts_epsilon :,if c . accept_epsilon :,97.23125143125482,97.15,False
2521,"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB><TAB> self . _pending_ack + = 1 <TAB><TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB><TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB><TAB> self . _pending_ack - = 1 <TAB><TAB> message . ack ( ) <TAB><TAB> self . completed_calls + = 1 <TAB><TAB> if self . completed_calls > = self . _resolve_at_msg_count : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . done_future . set_result ( None )",if not self . done_future . done ( ) :,if self . done_future :,66.85723957386863,96.48,False
2522,"def build_canned_image_list ( path ) : <TAB> layers_path = get_bitbake_var ( "" BBLAYERS "" ) <TAB> canned_wks_layer_dirs = [ ] <TAB> if layers_path is not None : <TAB><TAB> for layer_path in layers_path . split ( ) : <TAB><TAB><TAB> for wks_path in ( WIC_DIR , SCRIPTS_CANNED_IMAGE_DIR ) : <TAB><TAB><TAB><TAB> cpath = os . path . join ( layer_path , wks_path ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> cpath = os . path . join ( path , CANNED_IMAGE_DIR ) <TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> return canned_wks_layer_dirs",if os . path . isdir ( cpath ) :,if cpath not in canned_wks_layer_dirs :,80.65589602314192,94.94,False
2523,"def _recv_loop ( self ) - > None : <TAB> async with self . _ws as connection : <TAB><TAB> self . _connected = True <TAB><TAB> self . connection = connection <TAB><TAB> while self . _connected : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> resp = await self . connection . recv ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> await self . _on_message ( resp ) <TAB><TAB><TAB> except ( websockets . ConnectionClosed , ConnectionResetError ) : <TAB><TAB><TAB><TAB> logger . info ( "" connection closed "" ) <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> await asyncio . sleep ( 0 ) <TAB> if self . _connected : <TAB><TAB> self . _loop . create_task ( self . dispose ( ) )",if resp :,if resp :,100.0,100.00,True
2524,"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB><TAB> if start in line : <TAB><TAB><TAB> should_yield = True <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if should_yield and line : <TAB><TAB><TAB> yield line . strip ( ) . split ( ""   "" ) [ 0 ]",if end and end in line :,if end is not None and end in line :,86.74442109759714,96.67,False
2525,"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB><TAB> if self . mutually_exclusive . intersection ( opts ) : <TAB><TAB><TAB> self . _raise_exclusive_error ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args )",if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,if self . exclusive_not_set . intersection ( opts ) :,59.59599604017776,87.54,False
2526,"def write ( self , s ) : <TAB> if self . interactive : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . active_mode . write ( s ) <TAB><TAB> else : <TAB><TAB><TAB> component . get ( "" CmdLine "" ) . add_line ( s , False ) <TAB><TAB><TAB> self . events . append ( s ) <TAB> else : <TAB><TAB> print ( colors . strip_colors ( s ) )","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",if self . active_mode :,60.13794405542552,86.09,False
2527,"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB><TAB> # ignore hidden files/dirs and other unwanted files <TAB><TAB> if name . startswith ( "" . "" ) or name == "" lastsnap.jpg "" : <TAB><TAB><TAB> continue <TAB><TAB> pathname = os . path . join ( path , name ) <TAB><TAB> st = os . lstat ( pathname ) <TAB><TAB> mode = st . st_mode <TAB><TAB> <MASK> <TAB><TAB><TAB> files . extend ( findfiles ( pathname ) ) <TAB><TAB> elif stat . S_ISREG ( mode ) : <TAB><TAB><TAB> files . append ( ( pathname , name , st ) ) <TAB> return files",if stat . S_ISDIR ( mode ) :,if stat . S_ISDIR ( mode ) :,100.0,100.00,True
2528,"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB><TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB><TAB><TAB> # Don't tab complete undocumented commands/params <TAB><TAB><TAB> continue <TAB><TAB> if startswith is not None and not key . startswith ( startswith ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> names . append ( key ) <TAB> return names","if getattr ( command , ""positional_arg"" , False ) :",if key in self . _documented_completions :,94.76595986776537,91.67,False
2529,"def fix_newlines ( lines ) : <TAB> """"""Convert newlines to unix."""""" <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB><TAB> elif line . endswith ( "" \r "" ) : <TAB><TAB><TAB> lines [ i ] = line [ : - 1 ] + "" \n ""","if line . endswith ( ""\r\n"" ) :","if line . endswith ( ""\n"" ) :",95.09269987178263,97.70,False
2530,"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB> start = vma . vm_start <TAB><TAB> end = vma . vm_end <TAB><TAB> # Skip the entire region. <TAB><TAB> if end < self . plugin_args . start : <TAB><TAB><TAB> continue <TAB><TAB> # Done. <TAB><TAB> if start > self . plugin_args . end : <TAB><TAB><TAB> break <TAB><TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) )",if self . plugin_args . start <= vaddr <= self . plugin_args . end :,if vaddr not in self . plugin_args . pages :,95.45843220194257,93.16,False
2531,"def get_shape_at_node ( self , node , assumptions ) : <TAB> for k , v in assumptions . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return v <TAB> if node . inputs : <TAB><TAB> return node . container . shape ( <TAB><TAB><TAB> input_shapes = [ <TAB><TAB><TAB><TAB> self . get_shape_at_node ( input_node , assumptions ) <TAB><TAB><TAB><TAB> for input_node in node . inputs <TAB><TAB><TAB> ] <TAB><TAB> ) <TAB> else : <TAB><TAB> return node . container . shape ( None )",if k in node . names :,"if k == ""shape"" :",94.82541836596528,96.25,False
2532,"def fix_doc ( self , doc ) : <TAB> type = doc . get ( "" type "" , { } ) . get ( "" key "" ) <TAB> if type == "" /type/work "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> # some record got empty author records because of an error <TAB><TAB><TAB> # temporary hack to fix <TAB><TAB><TAB> doc [ "" authors "" ] = [ <TAB><TAB><TAB><TAB> a for a in doc [ "" authors "" ] if "" author "" in a and "" key "" in a [ "" author "" ] <TAB><TAB><TAB> ] <TAB> elif type == "" /type/edition "" : <TAB><TAB> # get rid of title_prefix. <TAB><TAB> if "" title_prefix "" in doc : <TAB><TAB><TAB> title = doc [ "" title_prefix "" ] . strip ( ) + ""   "" + doc . get ( "" title "" , "" "" ) <TAB><TAB><TAB> doc [ "" title "" ] = title . strip ( ) <TAB><TAB><TAB> del doc [ "" title_prefix "" ] <TAB> return doc","if doc . get ( ""authors"" ) :","if ""authors"" in doc :",95.17546805720579,97.29,False
2533,"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB><TAB> gate = column [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> elif isinstance ( gate , ParityControlCell ) : <TAB><TAB><TAB> # The first parity control to modify the column must merge all <TAB><TAB><TAB> # of the other parity controls into itself. <TAB><TAB><TAB> column [ i ] = None <TAB><TAB><TAB> self . _basis_change + = gate . _basis_change <TAB><TAB><TAB> self . qubits + = gate . qubits <TAB><TAB> elif gate is not None : <TAB><TAB><TAB> column [ i ] = gate . controlled_by ( self . qubits [ 0 ] )",if gate is self :,"if isinstance ( gate , ( ParityControl , ParityControl ) ) :",75.19327170250409,94.87,False
2534,"def onSync ( self , auto = False , reload = True ) : <TAB> if not auto or ( <TAB><TAB> self . pm . profile [ "" syncKey "" ] and self . pm . profile [ "" autoSync "" ] and not self . safeMode <TAB> ) : <TAB><TAB> from aqt . sync import SyncManager <TAB><TAB> if not self . unloadCollection ( ) : <TAB><TAB><TAB> return <TAB><TAB> # set a sync state so the refresh timer doesn't fire while deck <TAB><TAB> # unloaded <TAB><TAB> self . state = "" sync "" <TAB><TAB> self . syncer = SyncManager ( self , self . pm ) <TAB><TAB> self . syncer . sync ( ) <TAB> if reload : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . loadCollection ( )",if not self . col :,"if self . pm . profile [ ""syncKey"" ] :",97.34435998973895,94.68,False
2535,"def _has_url_match ( self , match , request_url ) : <TAB> url = match [ "" url "" ] <TAB> if _is_string ( url ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _has_strict_url_match ( url , request_url ) <TAB><TAB> else : <TAB><TAB><TAB> url_without_qs = request_url . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB> return url == url_without_qs <TAB> elif isinstance ( url , re . _pattern_type ) and url . match ( request_url ) : <TAB><TAB> return True <TAB> else : <TAB><TAB> return False","if match [ ""match_querystring"" ] :",if re . _strict_url_match :,89.41091631662701,95.08,False
2536,"def pool_image ( self , image ) : <TAB> if self . count < self . pool_size : <TAB><TAB> self . pool . append ( image ) <TAB><TAB> self . count + = 1 <TAB><TAB> return image <TAB> else : <TAB><TAB> p = random . random ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> random_id = random . randint ( 0 , self . pool_size - 1 ) <TAB><TAB><TAB> temp = self . pool [ random_id ] <TAB><TAB><TAB> self . pool [ random_id ] = image <TAB><TAB><TAB> return temp <TAB><TAB> else : <TAB><TAB><TAB> return image",if p > 0.5 :,if p < self . pool_size :,69.67002250569828,95.93,False
2537,"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB><TAB> <MASK> <TAB><TAB><TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB><TAB><TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB><TAB> if operation [ "" type "" ] == "" resize "" : <TAB><TAB><TAB> width = operation [ "" width "" ] <TAB><TAB><TAB> height = operation [ "" height "" ] <TAB> return ( width , height )","if operation [ ""type"" ] == ""crop"" :","if operation [ ""type"" ] == ""resize"" :",98.77027204810516,98.43,False
2538,"def validate_matrix ( matrix ) : <TAB> if not matrix : <TAB><TAB> return None <TAB> for key , value in matrix . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> "" ` {} ` defines a non uniform distribution,  "" <TAB><TAB><TAB><TAB> "" and it cannot be used with bayesian optimization. "" . format ( key ) <TAB><TAB><TAB> ) <TAB> return matrix",if value . is_distribution and not value . is_uniform :,"if not isinstance ( value , ( float , int ) ) :",63.00399246584405,90.32,False
2539,"def scm_to_conandata ( self ) : <TAB> try : <TAB><TAB> scm_to_conandata = get_env ( "" CONAN_SCM_TO_CONANDATA "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> scm_to_conandata = self . get_item ( "" general.scm_to_conandata "" ) <TAB><TAB> return scm_to_conandata . lower ( ) in ( "" 1 "" , "" true "" ) <TAB> except ConanException : <TAB><TAB> return False",if scm_to_conandata is None :,if not scm_to_conandata :,65.41863538916506,95.99,False
2540,"def _link_vrf_table ( self , vrf_table , rt_list ) : <TAB> route_family = vrf_table . route_family <TAB> for rt in rt_list : <TAB><TAB> rt_rf_id = rt + "" : "" + str ( route_family ) <TAB><TAB> table_set = self . _tables_for_rt . get ( rt_rf_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> table_set = set ( ) <TAB><TAB><TAB> self . _tables_for_rt [ rt_rf_id ] = table_set <TAB><TAB> table_set . add ( vrf_table ) <TAB><TAB> LOG . debug ( "" Added VrfTable  %s  to import RT table list:  %s "" , vrf_table , rt )",if table_set is None :,if table_set is None :,100.0,100.00,True
2541,"def add_tags ( <TAB> self , cve_results : Dict [ str , Dict [ str , Dict [ str , str ] ] ] , file_object : FileObject ) : <TAB> # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB> for component in cve_results : <TAB><TAB> for cve_id in cve_results [ component ] : <TAB><TAB><TAB> entry = cve_results [ component ] [ cve_id ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . add_analysis_tag ( <TAB><TAB><TAB><TAB><TAB> file_object , "" CVE "" , "" critical CVE "" , TagColor . RED , True <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return",if self . _entry_has_critical_rating ( entry ) :,"if entry [ ""score2"" ] == ""6.4"" :",96.37775534256224,93.44,False
2542,"def _validate ( self ) : <TAB> try : <TAB><TAB> super ( CustomClassifier , self ) . _validate ( ) <TAB> except UnsupportedDataType : <TAB><TAB> if self . dtype in FACTOR_DTYPES : <TAB><TAB><TAB> raise UnsupportedDataType ( <TAB><TAB><TAB><TAB> typename = type ( self ) . __name__ , <TAB><TAB><TAB><TAB> dtype = self . dtype , <TAB><TAB><TAB><TAB> hint = "" Did you mean to create a CustomFactor? "" , <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise UnsupportedDataType ( <TAB><TAB><TAB><TAB> typename = type ( self ) . __name__ , <TAB><TAB><TAB><TAB> dtype = self . dtype , <TAB><TAB><TAB><TAB> hint = "" Did you mean to create a CustomFilter? "" , <TAB><TAB><TAB> ) <TAB><TAB> raise",elif self . dtype in FILTER_DTYPES :,if self . dtype in FILTER_DTYPES :,98.73380660208161,99.00,False
2543,"def formatMessage ( self , record ) : <TAB> recordcopy = copy ( record ) <TAB> levelname = recordcopy . levelname <TAB> seperator = ""   "" * ( 8 - len ( recordcopy . levelname ) ) <TAB> if self . use_colors : <TAB><TAB> levelname = self . color_level_name ( levelname , recordcopy . levelno ) <TAB><TAB> <MASK> <TAB><TAB><TAB> recordcopy . msg = recordcopy . __dict__ [ "" color_message "" ] <TAB><TAB><TAB> recordcopy . __dict__ [ "" message "" ] = recordcopy . getMessage ( ) <TAB> recordcopy . __dict__ [ "" levelprefix "" ] = levelname + "" : "" + seperator <TAB> return super ( ) . formatMessage ( recordcopy )","if ""color_message"" in recordcopy . __dict__ :",if recordcopy . msg is None :,75.46950645617282,92.44,False
2544,"def dumpregs ( self ) : <TAB> for reg in ( <TAB><TAB> list ( self . regs . retaddr ) <TAB><TAB> + list ( self . regs . misc ) <TAB><TAB> + list ( self . regs . common ) <TAB><TAB> + list ( self . regs . flags ) <TAB> ) : <TAB><TAB> enum = self . get_reg_enum ( reg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> debug ( "" # Could not dump register  %r "" % reg ) <TAB><TAB><TAB> continue <TAB><TAB> name = "" U.x86_const.UC_X86_REG_ %s "" % reg . upper ( ) <TAB><TAB> value = self . uc . reg_read ( enum ) <TAB><TAB> debug ( "" uc.reg_read( %(name)s ) ==>  %(value)x "" % locals ( ) )",if not reg or enum is None :,if not enum :,71.79624423044604,97.19,False
2545,"def filter ( self , lexer , stream ) : <TAB> current_type = None <TAB> current_value = None <TAB> for ttype , value in stream : <TAB><TAB> if ttype is current_type : <TAB><TAB><TAB> current_value + = value <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield current_type , current_value <TAB><TAB><TAB> current_type = ttype <TAB><TAB><TAB> current_value = value <TAB> <MASK> <TAB><TAB> yield current_type , current_value",if current_type is not None :,if current_type is not None :,100.0,100.00,True
2546,"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> should_yield = True <TAB><TAB><TAB> continue <TAB><TAB> if end and end in line : <TAB><TAB><TAB> return <TAB><TAB> if should_yield and line : <TAB><TAB><TAB> yield line . strip ( ) . split ( ""   "" ) [ 0 ]",if start in line :,if start and start in line :,97.5606141132821,97.95,False
2547,"def parse_git_config ( path ) : <TAB> """"""Parse git config file."""""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB><TAB> for line in f : <TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB> if line . startswith ( "" [ "" ) : <TAB><TAB><TAB><TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB><TAB><TAB><TAB> config [ section ] = dict ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> key , value = line . replace ( ""   "" , "" "" ) . split ( "" = "" ) <TAB><TAB><TAB><TAB> config [ section ] [ key ] = value <TAB> return config",elif section :,"elif line . startswith ( ""git="" ) :",75.57325328800665,95.48,False
2548,"def test_has_arg ( fn , name , accept_all , expected ) : <TAB> if isinstance ( fn , str ) : <TAB><TAB> context = dict ( ) <TAB><TAB> try : <TAB><TAB><TAB> exec ( "" def  {} : pass "" . format ( fn ) , context ) <TAB><TAB> except SyntaxError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> pytest . skip ( "" Function is not compatible with Python 2 "" ) <TAB><TAB> # Sometimes exec adds builtins to the context <TAB><TAB> context . pop ( "" __builtins__ "" , None ) <TAB><TAB> ( fn , ) = context . values ( ) <TAB> assert has_arg ( fn , name , accept_all ) is expected","if sys . version_info >= ( 3 , ) :",if not PY2 :,91.53230721389036,93.91,False
2549,"def ObjectExpression ( self , properties , * * kwargs ) : <TAB> data = [ ] <TAB> for prop in properties : <TAB><TAB> self . emit ( prop [ "" value "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise NotImplementedError ( <TAB><TAB><TAB><TAB> "" ECMA 5.1 does not support computed object properties! "" <TAB><TAB><TAB> ) <TAB><TAB> data . append ( ( to_key ( prop [ "" key "" ] ) , prop [ "" kind "" ] [ 0 ] ) ) <TAB> self . emit ( "" LOAD_OBJECT "" , tuple ( data ) )","if prop [ ""computed"" ] :","if prop [ ""kind"" ] [ 0 ] is None :",95.56685212612813,94.46,False
2550,"def run ( self ) : <TAB> for domain , locale , po in self . locales : <TAB><TAB> <MASK> <TAB><TAB><TAB> path = os . path . join ( "" locale "" , locale , "" LC_MESSAGES "" ) <TAB><TAB> else : <TAB><TAB><TAB> path = os . path . join ( self . build_dir , locale , "" LC_MESSAGES "" ) <TAB><TAB> mo = os . path . join ( path , "" %s .mo "" % domain ) <TAB><TAB> self . mkpath ( path ) <TAB><TAB> self . spawn ( [ "" msgfmt "" , "" -o "" , mo , po ] )",if self . inplace :,"if domain == ""en"" :",95.82221014827164,95.35,False
2551,"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB><TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB><TAB> if second_byte == None : <TAB><TAB><TAB> return "" XED_ILD_MAP1 "" <TAB><TAB> if second_byte == 0x38 : <TAB><TAB><TAB> return "" XED_ILD_MAP2 "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" XED_ILD_MAP3 "" <TAB><TAB> if second_byte == 0x0F and self . amd_enabled : <TAB><TAB><TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) )",if second_byte == 0x3A :,if second_byte == 0x40 and self . amd_enabled :,97.3211152223916,95.98,False
2552,"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> buf . append ( c ) <TAB><TAB> elif c == "" \\ "" : <TAB><TAB><TAB> escaped = True <TAB><TAB> elif c == "" > "" : <TAB><TAB><TAB> return "" "" . join ( buf ) <TAB><TAB> else : <TAB><TAB><TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) )",if escaped :,if escaped :,100.0,100.00,True
2553,"def print_pairs ( attrs = None , offset_y = 0 ) : <TAB> fmt = ""  ( {0} : {1} )  "" <TAB> fmt_len = len ( fmt ) <TAB> for bg , fg in get_fg_bg ( ) : <TAB><TAB> try : <TAB><TAB><TAB> color = curses . color_pair ( pair_number ( fg , bg ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for attr in attrs : <TAB><TAB><TAB><TAB><TAB> color | = attr <TAB><TAB><TAB> screen . addstr ( offset_y + bg , fg * fmt_len , fmt . format ( fg , bg ) , color ) <TAB><TAB><TAB> pass <TAB><TAB> except curses . error : <TAB><TAB><TAB> pass",if not attrs is None :,if attrs :,81.56528147042224,97.49,False
2554,"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 : # default, torch have only data, axis=None, keepdims=False <TAB><TAB> <MASK> <TAB><TAB><TAB> axis = int ( inputs [ 1 ] ) <TAB><TAB> elif _is_int_seq ( inputs [ 1 ] ) : <TAB><TAB><TAB> axis = inputs [ 1 ] <TAB><TAB> else : <TAB><TAB><TAB> axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB><TAB> keepdims = bool ( inputs [ 2 ] ) <TAB> return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims )","if isinstance ( inputs [ 1 ] , int ) :",if _is_int_seq ( inputs [ 1 ] ) :,97.52476057025149,95.60,False
2555,"def run ( self , args , * * kwargs ) : <TAB> # Filtering options <TAB> if args . trace_tag : <TAB><TAB> kwargs [ "" trace_tag "" ] = args . trace_tag <TAB> if args . trigger_instance : <TAB><TAB> kwargs [ "" trigger_instance "" ] = args . trigger_instance <TAB> if args . execution : <TAB><TAB> kwargs [ "" execution "" ] = args . execution <TAB> if args . rule : <TAB><TAB> kwargs [ "" rule "" ] = args . rule <TAB> if args . sort_order : <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs [ "" sort_asc "" ] = True <TAB><TAB> elif args . sort_order in [ "" desc "" , "" descending "" ] : <TAB><TAB><TAB> kwargs [ "" sort_desc "" ] = True <TAB> return self . manager . query_with_count ( limit = args . last , * * kwargs )","if args . sort_order in [ ""asc"" , ""ascending"" ] :","if args . sort_order in [ ""asc"" , ""descending"" ] :",74.18631972411787,98.97,False
2556,def retaddr ( ) : <TAB> sp = pwndbg . regs . sp <TAB> stack = pwndbg . vmmap . find ( sp ) <TAB> # Enumerate all return addresses <TAB> frame = gdb . newest_frame ( ) <TAB> addresses = [ ] <TAB> while frame : <TAB><TAB> addresses . append ( frame . pc ( ) ) <TAB><TAB> frame = frame . older ( ) <TAB> # Find all of them on the stack <TAB> start = stack . vaddr <TAB> stop = start + stack . memsz <TAB> while addresses and start < sp < stop : <TAB><TAB> value = pwndbg . memory . u ( sp ) <TAB><TAB> <MASK> <TAB><TAB><TAB> index = addresses . index ( value ) <TAB><TAB><TAB> del addresses [ : index ] <TAB><TAB><TAB> print ( pwndbg . chain . format ( sp ) ) <TAB><TAB> sp + = pwndbg . arch . ptrsize,if value in addresses :,if value in addresses :,100.0,100.00,True
2557,"def update_from_dictio ( self , dictio_item ) : <TAB> for index , dictio_payload in enumerate ( dictio_item , 1 ) : <TAB><TAB> fuzz_payload = None <TAB><TAB> for fuzz_payload in self . payloads [ index ] : <TAB><TAB><TAB> fuzz_payload . content = dictio_payload . content <TAB><TAB><TAB> fuzz_payload . type = dictio_payload . type <TAB><TAB> # payload generated not used in seed but in filters <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add ( <TAB><TAB><TAB><TAB> { "" full_marker "" : None , "" word "" : None , "" index "" : index , "" field "" : None } , <TAB><TAB><TAB><TAB> dictio_item [ index - 1 ] , <TAB><TAB><TAB> )",if fuzz_payload is None :,if fuzz_payload is not None :,99.08393445024639,98.83,False
2558,"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = result . encode ( "" ascii "" ) <TAB><TAB> if isinstance ( expected , str ) : <TAB><TAB><TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB> if contains : <TAB><TAB><TAB> if eline not in rline : <TAB><TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB> return False <TAB> return True","if isinstance ( result , str ) :","if isinstance ( result , str ) :",100.0,100.00,True
2559,"def execute_sql ( self , sql , params = None , commit = True ) : <TAB> try : <TAB><TAB> cursor = super ( RetryOperationalError , self ) . execute_sql ( sql , params , commit ) <TAB> except OperationalError : <TAB><TAB> if not self . is_closed ( ) : <TAB><TAB><TAB> self . close ( ) <TAB><TAB> with __exception_wrapper__ : <TAB><TAB><TAB> cursor = self . cursor ( ) <TAB><TAB><TAB> cursor . execute ( sql , params or ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . commit ( ) <TAB> return cursor",if commit and not self . in_transaction ( ) :,if commit :,89.45880086136431,93.96,False
2560,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB><TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB><TAB><TAB> if not operation_name : <TAB><TAB><TAB><TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB><TAB> operation = definition <TAB><TAB><TAB> elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB> return definition <TAB> return operation",if operation :,if definition . name . value == document_ast . name . value :,97.19006593098635,94.14,False
2561,"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB><TAB> if self . is_ws ( aList [ i ] ) : <TAB><TAB><TAB> j = i <TAB><TAB><TAB> i = self . skip_ws ( aList , i ) <TAB><TAB><TAB> assert j < i <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # print ""removing trailing ws:"", `i-j` <TAB><TAB><TAB><TAB> del aList [ j : i ] <TAB><TAB><TAB><TAB> i = j <TAB><TAB> else : <TAB><TAB><TAB> i + = 1","if i >= len ( aList ) or aList [ i ] == ""\n"" :",if aList [ j ] == aList [ j ] :,88.34006965177335,91.27,False
2562,"def _process_filter ( self , query , host_state ) : <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query : <TAB><TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> arg = self . _process_filter ( arg , host_state ) <TAB><TAB> elif isinstance ( arg , basestring ) : <TAB><TAB><TAB> arg = self . _parse_string ( arg , host_state ) <TAB><TAB> if arg is not None : <TAB><TAB><TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result","if isinstance ( arg , list ) :","if isinstance ( arg , ( list , tuple ) ) :",72.72340616442915,97.04,False
2563,"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB><TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB><TAB><TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB><TAB> elif child . tag in ( "" w "" , "" c "" ) : <TAB><TAB><TAB> sent . append ( self . handle_word ( child ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent )",elif child . tag not in self . tags_to_ignore :,"elif child . tag not in ( ""n"" , ""c"" ) :",96.32404939832115,94.27,False
2564,"def get_display_price ( <TAB> base : Union [ TaxedMoney , TaxedMoneyRange ] , display_gross : bool = False ) - > Money : <TAB> """"""Return the price amount that should be displayed based on settings."""""" <TAB> if not display_gross : <TAB><TAB> display_gross = display_gross_prices ( ) <TAB> if isinstance ( base , TaxedMoneyRange ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> base = MoneyRange ( start = base . start . gross , stop = base . stop . gross ) <TAB><TAB> else : <TAB><TAB><TAB> base = MoneyRange ( start = base . start . net , stop = base . stop . net ) <TAB> if isinstance ( base , TaxedMoney ) : <TAB><TAB> base = base . gross if display_gross else base . net <TAB> return base",if display_gross :,if display_gross :,100.0,100.00,True
2565,"def check_classes ( self , node ) : <TAB> if isinstance ( node , nodes . Element ) : <TAB><TAB> for class_value in node [ "" classes "" ] [ : ] : <TAB><TAB><TAB> if class_value in self . strip_classes : <TAB><TAB><TAB><TAB> node [ "" classes "" ] . remove ( class_value ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return 1",if class_value in self . strip_elements :,"if len ( node [ ""classes"" ] ) == 0 :",66.98843934547904,89.14,False
2566,"def validate ( outfile = sys . stdout , silent_success = False ) : <TAB> "" Validates all installed models. "" <TAB> try : <TAB><TAB> num_errors = get_validation_errors ( outfile ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> outfile . write ( <TAB><TAB><TAB> "" %s  error %s  found. \n "" % ( num_errors , num_errors != 1 and "" s "" or "" "" ) <TAB><TAB> ) <TAB> except ImproperlyConfigured : <TAB><TAB> outfile . write ( "" Skipping validation because things aren ' t configured properly. "" )",if silent_success and num_errors == 0 :,if num_errors == 0 :,82.77235445118714,96.58,False
2567,"def check_basename_conflicts ( self , targets ) : <TAB> """"""Apps' basenames are used as bundle directory names. Ensure they are all unique."""""" <TAB> basename_seen = { } <TAB> for target in targets : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise self . BasenameConflictError ( <TAB><TAB><TAB><TAB> "" Basename must be unique, found two targets use  "" <TAB><TAB><TAB><TAB> "" the same basename:  {} ' \n \t {}  and  \n \t {} "" . format ( <TAB><TAB><TAB><TAB><TAB> target . basename , <TAB><TAB><TAB><TAB><TAB> basename_seen [ target . basename ] . address . spec , <TAB><TAB><TAB><TAB><TAB> target . address . spec , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> basename_seen [ target . basename ] = target",if target . basename in basename_seen :,if target . basename in basename_seen :,100.0,100.00,True
2568,"def __init__ ( self , api_version_str ) : <TAB> try : <TAB><TAB> self . latest = self . preview = False <TAB><TAB> self . yyyy = self . mm = self . dd = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . latest = True <TAB><TAB> else : <TAB><TAB><TAB> if "" preview "" in api_version_str : <TAB><TAB><TAB><TAB> self . preview = True <TAB><TAB><TAB> parts = api_version_str . split ( "" - "" ) <TAB><TAB><TAB> self . yyyy = int ( parts [ 0 ] ) <TAB><TAB><TAB> self . mm = int ( parts [ 1 ] ) <TAB><TAB><TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB><TAB> )","if api_version_str == ""latest"" :","if api_version_str == """" :",99.13670338215881,99.08,False
2569,"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB><TAB> y = self . _curve . b <TAB> else : <TAB><TAB> result = self . sqrtp ( <TAB><TAB><TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> y = result [ 0 ] <TAB><TAB> elif len ( result ) == 2 : <TAB><TAB><TAB> y1 , y2 = result <TAB><TAB><TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> return ec . Point ( self . _curve , x , y )",if len ( result ) == 1 :,if len ( result ) == 1 :,100.0,100.00,True
2570,"def _visit_import_alike ( self , node : Union [ cst . Import , cst . ImportFrom ] ) - > bool : <TAB> names = node . names <TAB> if isinstance ( names , cst . ImportStar ) : <TAB><TAB> return False <TAB> # make sure node.names is Sequence[ImportAlias] <TAB> for name in names : <TAB><TAB> self . provider . set_metadata ( name , self . scope ) <TAB><TAB> asname = name . asname <TAB><TAB> <MASK> <TAB><TAB><TAB> name_values = _gen_dotted_names ( cst . ensure_type ( asname . name , cst . Name ) ) <TAB><TAB> else : <TAB><TAB><TAB> name_values = _gen_dotted_names ( name . name ) <TAB><TAB> for name_value , _ in name_values : <TAB><TAB><TAB> self . scope . record_assignment ( name_value , node ) <TAB> return False",if asname is not None :,if asname :,97.94539511420159,98.05,False
2571,"def test_sanity_no_unmatched_parentheses ( CorpusType : Type [ ColumnCorpus ] ) : <TAB> corpus = CorpusType ( ) <TAB> unbalanced_entities = [ ] <TAB> for sentence in corpus . get_all_sentences ( ) : <TAB><TAB> entities = sentence . get_spans ( "" ner "" ) <TAB><TAB> for entity in entities : <TAB><TAB><TAB> entity_text = "" "" . join ( t . text for t in entity . tokens ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> unbalanced_entities . append ( entity_text ) <TAB> assert unbalanced_entities == [ ]",if not has_balanced_parantheses ( entity_text ) :,if entity_text not in unbalanced_entities :,67.6033225464868,93.51,False
2572,"def _learn_rate_adjust ( self ) : <TAB> if self . learn_rate_decays == 1.0 : <TAB><TAB> return <TAB> learn_rate_decays = self . _vp ( self . learn_rate_decays ) <TAB> learn_rate_minimums = self . _vp ( self . learn_rate_minimums ) <TAB> for index , decay in enumerate ( learn_rate_decays ) : <TAB><TAB> new_learn_rate = self . net_ . learnRates [ index ] * decay <TAB><TAB> <MASK> <TAB><TAB><TAB> self . net_ . learnRates [ index ] = new_learn_rate <TAB> if self . verbose > = 2 : <TAB><TAB> print ( "" Learn rates:  {} "" . format ( self . net_ . learnRates ) )",if new_learn_rate >= learn_rate_minimums [ index ] :,if new_learn_rate != 0.0 :,68.20591888472013,94.32,False
2573,"def set_attr_from_xmp_tag ( self , attr , xmp_tags , tags , cast = None ) : <TAB> v = self . get_xmp_tag ( xmp_tags , tags ) <TAB> if v is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( self , attr , v ) <TAB><TAB> else : <TAB><TAB><TAB> # Handle fractions <TAB><TAB><TAB> if ( cast == float or cast == int ) and "" / "" in v : <TAB><TAB><TAB><TAB> v = self . try_parse_fraction ( v ) <TAB><TAB><TAB> setattr ( self , attr , cast ( v ) )",if cast is None :,if cast is None :,100.0,100.00,True
2574,"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB><TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB><TAB> s = i - 1 <TAB><TAB> e = i + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB> e + = 1 <TAB><TAB> if re . match ( "" [0-9] "" , str ( tokens [ e ] ) ) : <TAB><TAB><TAB> e + = 1 <TAB><TAB><TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB><TAB><TAB> i - = 1 <TAB> return tokens","if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :",if e == 0 :,72.11478843015391,91.38,False
2575,"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> executable = winpymap . get ( name , None ) <TAB><TAB><TAB> if executable : <TAB><TAB><TAB><TAB> executable = py . path . local ( executable ) <TAB><TAB><TAB><TAB> if executable . check ( ) : <TAB><TAB><TAB><TAB><TAB> return executable <TAB><TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable","if sys . platform == ""win32"" :",if name in winpymap :,90.54234874167373,94.13,False
2576,"def set_meta ( self , dataset , overwrite = True , * * kwd ) : <TAB> super ( ) . set_meta ( dataset , overwrite = overwrite , * * kwd ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> with tarfile . open ( dataset . file_name , "" r "" ) as temptar : <TAB><TAB><TAB><TAB> dataset . metadata . fast5_count = sum ( <TAB><TAB><TAB><TAB><TAB> 1 for f in temptar if f . name . endswith ( "" .fast5 "" ) <TAB><TAB><TAB><TAB> ) <TAB> except Exception as e : <TAB><TAB> log . warning ( "" %s , set_meta Exception:  %s "" , self , e )",if dataset and tarfile . is_tarfile ( dataset . file_name ) :,if dataset . file_name :,86.89390861788935,94.10,False
2577,"def run ( self ) : <TAB> for k in list ( iterkeys ( self . objs ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> v = self . objs [ k ] <TAB><TAB> if v [ "" _class "" ] == "" User "" : <TAB><TAB><TAB> self . split_user ( k , v ) <TAB><TAB> elif v [ "" _class "" ] in [ <TAB><TAB><TAB> "" Message "" , <TAB><TAB><TAB> "" PrintJob "" , <TAB><TAB><TAB> "" Question "" , <TAB><TAB><TAB> "" Submission "" , <TAB><TAB><TAB> "" UserTest "" , <TAB><TAB> ] : <TAB><TAB><TAB> v [ "" participation "" ] = v [ "" user "" ] <TAB><TAB><TAB> del v [ "" user "" ] <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",100.0,100.00,True
2578,"def _findInTree ( t , n ) : <TAB> ret = [ ] <TAB> if type ( t ) is dict : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( t ) <TAB><TAB> for k , v in t . items ( ) : <TAB><TAB><TAB> ret + = _findInTree ( v , n ) <TAB> if type ( t ) is list : <TAB><TAB> for v in t : <TAB><TAB><TAB> ret + = _findInTree ( v , n ) <TAB> return ret","if ""_name"" in t and t [ ""_name"" ] == n :",if n in t :,90.74220662350231,87.76,False
2579,"def parseArrayPattern ( self ) : <TAB> node = Node ( ) <TAB> elements = [ ] <TAB> self . expect ( "" [ "" ) <TAB> while not self . match ( "" ] "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . lex ( ) <TAB><TAB><TAB> elements . append ( null ) <TAB><TAB> else : <TAB><TAB><TAB> if self . match ( "" ... "" ) : <TAB><TAB><TAB><TAB> restNode = Node ( ) <TAB><TAB><TAB><TAB> self . lex ( ) <TAB><TAB><TAB><TAB> rest = self . parseVariableIdentifier ( ) <TAB><TAB><TAB><TAB> elements . append ( restNode . finishRestElement ( rest ) ) <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> elements . append ( self . parsePatternWithDefault ( ) ) <TAB><TAB><TAB> if not self . match ( "" ] "" ) : <TAB><TAB><TAB><TAB> self . expect ( "" , "" ) <TAB> self . expect ( "" ] "" ) <TAB> return node . finishArrayPattern ( elements )","if self . match ( "","" ) :","if self . match ( ""]"" ) :",99.21586432106044,99.17,False
2580,"def _set_log_writer ( self ) : <TAB> if self . config [ "" logging "" ] : <TAB><TAB> config = self . config [ "" log_writer_config "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log_writer = LogWriter ( * * config ) <TAB><TAB> elif config [ "" writer "" ] == "" tensorboard "" : <TAB><TAB><TAB> self . log_writer = TensorBoardWriter ( * * config ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( f "" Unrecognized writer option:  { config [ ' writer ' ] } "" ) <TAB> else : <TAB><TAB> self . log_writer = None","if config [ ""writer"" ] == ""json"" :","if config [ ""writer"" ] == ""log"" :",98.7731393588137,98.58,False
2581,"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB> if not len ( head ) : <TAB><TAB><TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB><TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB><TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries",if not len ( line . strip ( ) ) :,"if line . strip ( ) == """" :",69.50096088570166,97.08,False
2582,"def get_all_values ( self , project ) : <TAB> if isinstance ( project , models . Model ) : <TAB><TAB> project_id = project . id <TAB> else : <TAB><TAB> project_id = project <TAB> if project_id not in self . __cache : <TAB><TAB> cache_key = self . _make_key ( project_id ) <TAB><TAB> result = cache . get ( cache_key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = self . reload_cache ( project_id ) <TAB><TAB> else : <TAB><TAB><TAB> self . __cache [ project_id ] = result <TAB> return self . __cache . get ( project_id , { } )",if result is None :,if result is None :,100.0,100.00,True
2583,"def needed_libraries ( self ) : <TAB> for cmd in self . load_commands_of_type ( 0xC ) : # LC_LOAD_DYLIB <TAB><TAB> tname = self . _get_typename ( "" dylib_command "" ) <TAB><TAB> dylib_command = cmd . cast ( tname ) <TAB><TAB> name_addr = cmd . obj_offset + dylib_command . name <TAB><TAB> dylib_name = self . obj_vm . read ( name_addr , 256 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> idx = dylib_name . find ( "" \x00 "" ) <TAB><TAB><TAB> if idx != - 1 : <TAB><TAB><TAB><TAB> dylib_name = dylib_name [ : idx ] <TAB><TAB><TAB> yield dylib_name",if dylib_name :,if dylib_name :,100.0,100.00,True
2584,"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> error = self . error_messages [ "" invalid_year "" ] <TAB><TAB><TAB> raise forms . ValidationError ( error ) <TAB><TAB> if data_list [ 0 ] in forms . fields . EMPTY_VALUES : <TAB><TAB><TAB> error = self . error_messages [ "" invalid_month "" ] <TAB><TAB><TAB> raise forms . ValidationError ( error ) <TAB><TAB> year = int ( data_list [ 1 ] ) <TAB><TAB> month = int ( data_list [ 0 ] ) <TAB><TAB> # find last day of the month <TAB><TAB> day = monthrange ( year , month ) [ 1 ] <TAB><TAB> return date ( year , month , day ) <TAB> return None",if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,100.0,100.00,True
2585,"def put ( self , obj , block = True , timeout = None ) : <TAB> assert not self . _closed <TAB> if not self . _sem . acquire ( block , timeout ) : <TAB><TAB> raise Full <TAB> with self . _notempty : <TAB><TAB> with self . _cond : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _start_thread ( ) <TAB><TAB><TAB> self . _buffer . append ( obj ) <TAB><TAB><TAB> self . _unfinished_tasks . release ( ) <TAB><TAB><TAB> self . _notempty . notify ( )",if self . _thread is None :,if self . _thread is None :,100.0,100.00,True
2586,"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB><TAB> module_directory = join ( directory , module ) <TAB><TAB> has_module_directory = isdir ( module_directory ) <TAB><TAB> if not version : <TAB><TAB><TAB> has_module = has_module_directory or exists ( <TAB><TAB><TAB><TAB> module_directory <TAB><TAB><TAB> ) # could be a bare modulefile <TAB><TAB> else : <TAB><TAB><TAB> modulefile = join ( module_directory , version ) <TAB><TAB><TAB> has_modulefile = exists ( modulefile ) <TAB><TAB><TAB> has_module = has_module_directory and has_modulefile <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return has_module",if has_module :,if has_module :,100.0,100.00,True
2587,"def expanduser ( path ) : <TAB> if path [ : 1 ] == "" ~ "" : <TAB><TAB> c = path [ 1 : 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return gethome ( ) <TAB><TAB> if c == os . sep : <TAB><TAB><TAB> return asPyString ( File ( gethome ( ) , path [ 2 : ] ) . getPath ( ) ) <TAB> return path",if not c :,if c == os . path . expanduser ( ) :,66.03013455654305,89.98,False
2588,"def mock_touch ( self , bearer , version = None , revision = None , * * kwargs ) : <TAB> if version : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return self . versions [ int ( version ) - 1 ] <TAB><TAB><TAB> except ( IndexError , ValueError ) : <TAB><TAB><TAB><TAB> return None <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> return file_models . FileVersion ( )",if self . versions :,if int ( version ) > 0 :,93.78767615477473,94.45,False
2589,"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB> members = inspect . getmembers ( match ) <TAB><TAB> for member in members : <TAB><TAB><TAB> if member [ 0 ] == key : <TAB><TAB><TAB><TAB> field_value = member [ 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> wildcards = member [ 1 ] <TAB><TAB> if key == "" nw_src "" : <TAB><TAB><TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB> elif key == "" nw_dst "" : <TAB><TAB><TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB><TAB> field_value = match [ key ] <TAB> return field_value","elif member [ 0 ] == ""wildcards"" :","elif member [ 0 ] == ""nw_src_ref"" :",98.95107179152033,97.45,False
2590,"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB><TAB> if isinstance ( result , str ) : <TAB><TAB><TAB> result = result . encode ( "" ascii "" ) <TAB><TAB> if isinstance ( expected , str ) : <TAB><TAB><TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if eline not in rline : <TAB><TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB> return False <TAB> return True",if contains :,if contains :,100.0,100.00,True
2591,"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB><TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB><TAB><TAB> self . _cancel_editing ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _update_value ( ) <TAB><TAB> elif event . GetKeyCode ( ) == wx . WXK_DELETE : <TAB><TAB><TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB><TAB> # Don't send skip event if enter key is pressed <TAB><TAB> # On some platforms this event is sent too late and causes crash <TAB><TAB> event . Skip ( )",elif event . GetKeyCode ( ) == wx . WXK_RETURN :,elif event . GetKeyCode ( ) == wx . WXK_UPDATE :,98.90494922554146,98.68,False
2592,"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB><TAB> print ( loading_message ) <TAB> for name in to_load : <TAB><TAB> module = load ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> cls = getattr ( module , attr ) <TAB><TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB><TAB><TAB> continue <TAB><TAB> if hasattr ( module , "" aliases "" ) : <TAB><TAB><TAB> for alias in module . aliases ( ) : <TAB><TAB><TAB><TAB> if alias not in excluded_aliases : <TAB><TAB><TAB><TAB><TAB> modules_dict [ alias ] = module <TAB><TAB> else : <TAB><TAB><TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB><TAB> print ( )","if module is None or not hasattr ( module , attr ) :",if not module :,78.6273467584648,95.45,False
2593,def eventIterator ( ) : <TAB> while True : <TAB><TAB> yield eventmodule . wait ( ) <TAB><TAB> while True : <TAB><TAB><TAB> event = eventmodule . poll ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield event,if event . type == NOEVENT :,if event is None :,65.39912731514654,93.58,False
2594,"def _get_state_without_padding ( self , state_with_padding , padding ) : <TAB> lean_state = { } <TAB> for key , value in state_with_padding . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> lean_length = value . numel ( ) - padding <TAB><TAB><TAB> lean_state [ key ] = value [ : lean_length ] <TAB><TAB> else : <TAB><TAB><TAB> lean_state [ key ] = value <TAB> return lean_state",if torch . is_tensor ( value ) :,if padding :,88.52121893513774,93.01,False
2595,"def _get_validate ( data ) : <TAB> """"""Retrieve items to validate, from single samples or from combined joint calls."""""" <TAB> if data . get ( "" vrn_file "" ) and tz . get_in ( [ "" config "" , "" algorithm "" , "" validate "" ] , data ) : <TAB><TAB> return utils . deepish_copy ( data ) <TAB> elif "" group_orig "" in data : <TAB><TAB> for sub in multi . get_orig_items ( data ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sub_val = utils . deepish_copy ( sub ) <TAB><TAB><TAB><TAB> sub_val [ "" vrn_file "" ] = data [ "" vrn_file "" ] <TAB><TAB><TAB><TAB> return sub_val <TAB> return None","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :","if sub . get ( ""group_orig"" ) :",92.85161852767054,92.74,False
2596,"def OnPopup ( self , form , popup_handle ) : <TAB> for num , action_name , menu_name , shortcut in self . actions : <TAB><TAB> <MASK> <TAB><TAB><TAB> ida_kernwin . attach_action_to_popup ( form , popup_handle , None ) <TAB><TAB> else : <TAB><TAB><TAB> handler = command_handler_t ( self , num , 2 ) <TAB><TAB><TAB> desc = ida_kernwin . action_desc_t ( action_name , menu_name , handler , shortcut ) <TAB><TAB><TAB> ida_kernwin . attach_dynamic_action_to_popup ( form , popup_handle , desc )",if menu_name is None :,"if action_name == ""action"" :",93.15424743283396,94.85,False
2597,"def show ( self , indent = 0 ) : <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0 : <TAB><TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB><TAB> <MASK> <TAB><TAB><TAB> offset = "" 0x?? "" <TAB><TAB> else : <TAB><TAB><TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB><TAB> print ( "" {} + {}   {}   {} "" . format ( ""   "" * indent , offset , field . name , field . type ) ) <TAB><TAB> if isinstance ( field . type , Structure ) : <TAB><TAB><TAB> field . type . show ( indent + 1 )",if field . offset is None :,if field . offset is None :,100.0,100.00,True
2598,"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not operation_name : <TAB><TAB><TAB><TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB><TAB><TAB><TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB><TAB><TAB><TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB><TAB><TAB><TAB> if operation : <TAB><TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB><TAB> operation = definition <TAB><TAB><TAB> elif definition . name and definition . name . value == operation_name : <TAB><TAB><TAB><TAB> return definition <TAB> return operation","if isinstance ( definition , ast . OperationDefinition ) :",if definition . name and definition . name . value == document_ast . name . value :,70.2651619390605,92.92,False
2599,"def getSubMenu ( self , callingWindow , context , mainItem , selection , rootMenu , i , pitem ) : <TAB> msw = True if "" wxMSW "" in wx . PlatformInfo else False <TAB> self . context = context <TAB> self . abilityIds = { } <TAB> sub = wx . Menu ( ) <TAB> for ability in self . fighter . abilities : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> menuItem = self . addAbility ( rootMenu if msw else sub , ability ) <TAB><TAB> sub . Append ( menuItem ) <TAB><TAB> menuItem . Check ( ability . active ) <TAB> return sub",if not ability . effect . isImplemented :,if ability . disabled :,77.06512815820302,95.44,False
2600,"def consume ( self , event : Dict [ str , Any ] ) - > None : <TAB> with self . lock : <TAB><TAB> logging . debug ( "" Received missedmessage_emails event:  %s "" , event ) <TAB><TAB> # When we process an event, just put it into the queue and ensure we have a timer going. <TAB><TAB> user_profile_id = event [ "" user_profile_id "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . batch_start_by_recipient [ user_profile_id ] = time . time ( ) <TAB><TAB> self . events_by_recipient [ user_profile_id ] . append ( event ) <TAB><TAB> self . ensure_timer ( )",if user_profile_id not in self . batch_start_by_recipient :,if user_profile_id not in self . batch_start_by_recipient :,100.0,100.00,True
2601,"def __init__ ( self , start_enabled = False , use_hardware = True ) : <TAB> self . _use_hardware = use_hardware <TAB> if use_hardware : <TAB><TAB> self . _button = Button ( BUTTON_GPIO_PIN ) <TAB><TAB> self . _enabled = start_enabled <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _button . when_pressed = self . _enable",if not start_enabled :,if self . _enable :,69.37581048326687,95.14,False
2602,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB><TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _execute_map ( ctx , op ) <TAB><TAB> elif op . stage == OperandStage . combine : <TAB><TAB><TAB> cls . _execute_combine ( ctx , op ) <TAB><TAB> elif op . stage == OperandStage . agg : <TAB><TAB><TAB> cls . _execute_agg ( ctx , op ) <TAB><TAB> else : # pragma: no cover <TAB><TAB><TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB><TAB> pd . reset_option ( "" mode.use_inf_as_na "" )",if op . stage == OperandStage . map :,if op . stage == OperandStage . map :,75.0,100.00,True
2603,"def load_package ( name , path ) : <TAB> if os . path . isdir ( path ) : <TAB><TAB> extensions = machinery . SOURCE_SUFFIXES [ : ] + machinery . BYTECODE_SUFFIXES [ : ] <TAB><TAB> for extension in extensions : <TAB><TAB><TAB> init_path = os . path . join ( path , "" __init__ "" + extension ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> path = init_path <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" {!r}  is not a package "" . format ( path ) ) <TAB> spec = util . spec_from_file_location ( name , path , submodule_search_locations = [ ] ) <TAB> if name in sys . modules : <TAB><TAB> return _exec ( spec , sys . modules [ name ] ) <TAB> else : <TAB><TAB> return _load ( spec )",if os . path . exists ( init_path ) :,if os . path . exists ( init_path ) :,100.0,100.00,True
2604,def setup ( level = None ) : <TAB> from pipeline . logging import pipeline_logger as logger <TAB> from pipeline . log . handlers import EngineLogHandler <TAB> if level in set ( logging . _levelToName . values ( ) ) : <TAB><TAB> logger . setLevel ( level ) <TAB> logging . _acquireLock ( ) <TAB> try : <TAB><TAB> for hdl in logger . handlers : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> hdl = EngineLogHandler ( ) <TAB><TAB><TAB> hdl . setLevel ( logger . level ) <TAB><TAB><TAB> logger . addHandler ( hdl ) <TAB> finally : <TAB><TAB> logging . _releaseLock ( ),"if isinstance ( hdl , EngineLogHandler ) :","if hdl . name == ""log"" :",92.60204244669606,95.14,False
2605,"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB><TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB><TAB> p , q = i . as_numer_denom ( ) <TAB><TAB> tol = c / q * * 2 <TAB><TAB> if abs ( i - x ) < = tol : <TAB><TAB><TAB> return i <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return x",if tol < machine_epsilon :,if p == 1 :,67.39287592485277,95.56,False
2606,"def resolve ( <TAB> self , debug : bool = False , silent : bool = False , level : Optional [ int ] = None ) - > bool : <TAB> if silent : <TAB><TAB> spinner = nullcontext ( type ( "" Mock "" , ( ) , { } ) ) <TAB> else : <TAB><TAB> spinner = yaspin ( text = "" resolving... "" ) <TAB> with spinner as spinner : <TAB><TAB> while True : <TAB><TAB><TAB> resolved = self . _resolve ( <TAB><TAB><TAB><TAB> debug = debug , silent = silent , level = level , spinner = spinner <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . graph . clear ( ) # remove unused deps from graph <TAB><TAB><TAB> return resolved",if resolved is None :,if resolved is None :,100.0,100.00,True
2607,"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == "" MOV "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" LSR "" <TAB><TAB> elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB><TAB><TAB> return "" LSL "" <TAB><TAB> elif instr . mnemonic . startswith ( "" asr "" ) : <TAB><TAB><TAB> return "" ASR "" <TAB> return OP_NAME_MAP . get ( name , name )","if instr . mnemonic . startswith ( ""lsr"" ) :","if instr . mnemonic . startswith ( ""lsr"" ) :",100.0,100.00,True
2608,"def run_all ( rule_list , defined_variables , defined_actions , stop_on_first_trigger = False ) : <TAB> rule_was_triggered = False <TAB> for rule in rule_list : <TAB><TAB> result = run ( rule , defined_variables , defined_actions ) <TAB><TAB> if result : <TAB><TAB><TAB> rule_was_triggered = True <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return rule_was_triggered",if stop_on_first_trigger :,if stop_on_first_trigger :,100.0,100.00,True
2609,"def get_filters ( self , request ) : <TAB> filter_specs = [ ] <TAB> if self . lookup_opts . admin . list_filter and not self . opts . one_to_one_field : <TAB><TAB> filter_fields = [ <TAB><TAB><TAB> self . lookup_opts . get_field ( field_name ) <TAB><TAB><TAB> for field_name in self . lookup_opts . admin . list_filter <TAB><TAB> ] <TAB><TAB> for f in filter_fields : <TAB><TAB><TAB> spec = FilterSpec . create ( f , request , self . params , self . model ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> filter_specs . append ( spec ) <TAB> return filter_specs , bool ( filter_specs )",if spec and spec . has_output ( ) :,if spec . has_specs ( ) :,70.2042005701357,97.45,False
2610,"def get_type ( type_ref ) : <TAB> kind = type_ref . get ( "" kind "" ) <TAB> if kind == TypeKind . LIST : <TAB><TAB> item_ref = type_ref . get ( "" ofType "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB><TAB> return GraphQLList ( get_type ( item_ref ) ) <TAB> elif kind == TypeKind . NON_NULL : <TAB><TAB> nullable_ref = type_ref . get ( "" ofType "" ) <TAB><TAB> if not nullable_ref : <TAB><TAB><TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB><TAB> return GraphQLNonNull ( get_type ( nullable_ref ) ) <TAB> return get_named_type ( type_ref [ "" name "" ] )",if not item_ref :,if not item_ref :,100.0,100.00,True
2611,"def _1_0_cloud_ips_cip_jsjc5_map ( self , method , url , body , headers ) : <TAB> if method == "" POST "" : <TAB><TAB> body = json . loads ( body ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . test_response ( httplib . ACCEPTED , "" "" ) <TAB><TAB> else : <TAB><TAB><TAB> data = ' { "" error_name "" : "" bad destination "" ,  "" errors "" : [ "" Bad destination "" ]} ' <TAB><TAB><TAB> return self . test_response ( httplib . BAD_REQUEST , data )","if ""destination"" in body :","if body [ ""status"" ] == ""available"" :",77.15144477722174,92.66,False
2612,"def _get_prefixed_values ( data , prefix ) : <TAB> """"""Collect lines which start with prefix; with trimming"""""" <TAB> matches = [ ] <TAB> for line in data . splitlines ( ) : <TAB><TAB> line = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> match = line [ len ( prefix ) : ] <TAB><TAB><TAB> match = match . strip ( ) <TAB><TAB><TAB> matches . append ( match ) <TAB> return matches",if line . startswith ( prefix ) :,if line . startswith ( prefix ) :,100.0,100.00,True
2613,"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB><TAB> yc / / = 10 <TAB><TAB> ye + = 1 <TAB> if xc == 1 : <TAB><TAB> xe * = yc <TAB><TAB> while xe % 10 == 0 : <TAB><TAB><TAB> xe / / = 10 <TAB><TAB><TAB> ye + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> exponent = xe * 10 * * ye <TAB><TAB> if y and xe : <TAB><TAB><TAB> xc = exponent <TAB><TAB> else : <TAB><TAB><TAB> xc = 0 <TAB><TAB> return 5",if ye < 0 :,if ye == 1 :,85.4785952579686,97.83,False
2614,"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB><TAB> for region in view . sel ( ) : <TAB><TAB><TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB><TAB> if idx > = len ( selections ) : <TAB><TAB><TAB> break <TAB><TAB> i = index - 1 <TAB><TAB> if i > = 0 and i < len ( selections ) : <TAB><TAB><TAB> values . append ( selections [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> values . append ( value ) <TAB> self . stack = values",if len ( values ) + 1 < idx :,if value is not None :,97.06684991602384,96.06,False
2615,"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB><TAB> value <TAB><TAB> if value is not None <TAB><TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB><TAB> if fit is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB><TAB><TAB> fit . clearFactorReloadDependentData ( ) <TAB><TAB><TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs",if fit . calculated :,if fit . isConfigured ( ) :,96.95708052811945,97.38,False
2616,"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for m in self . predict_layers . modules ( ) : <TAB><TAB> if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB> kaiming_init ( m ) <TAB><TAB> <MASK> <TAB><TAB><TAB> constant_init ( m , 1 ) <TAB><TAB> elif isinstance ( m , nn . Linear ) : <TAB><TAB><TAB> normal_init ( m , std = 0.01 )","elif isinstance ( m , nn . BatchNorm2d ) :","elif isinstance ( m , nn . BatchNorm2d ) :",75.0,100.00,True
2617,"def _unzip_file ( self , filepath , ext ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> zf = zipfile . ZipFile ( filepath ) <TAB><TAB><TAB> zf . extractall ( os . path . dirname ( filepath ) ) <TAB><TAB><TAB> zf . close ( ) <TAB><TAB> elif ext == "" .tar "" : <TAB><TAB><TAB> tf = tarfile . open ( filepath ) <TAB><TAB><TAB> tf . extractall ( os . path . dirname ( filepath ) ) <TAB><TAB><TAB> tf . close ( ) <TAB> except Exception as e : <TAB><TAB> raise ValueError ( "" Error reading file  %r ! \n %s "" % ( filepath , e ) )","if ext == "".zip"" :","if ext == "".zip"" :",100.0,100.00,True
2618,"def add_multiple_tasks ( data , parent ) : <TAB> data = json . loads ( data ) <TAB> new_doc = { <TAB><TAB> "" doctype "" : "" Task "" , <TAB><TAB> "" parent_task "" : parent if parent != "" All Tasks "" else "" "" , <TAB> } <TAB> new_doc [ "" project "" ] = frappe . db . get_value ( "" Task "" , { "" name "" : parent } , "" project "" ) or "" "" <TAB> for d in data : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> new_doc [ "" subject "" ] = d . get ( "" subject "" ) <TAB><TAB> new_task = frappe . get_doc ( new_doc ) <TAB><TAB> new_task . insert ( )","if not d . get ( ""subject"" ) :","if d . get ( ""project"" ) != new_doc [ ""project"" ] :",89.72100998057338,92.77,False
2619,"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB><TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> seenDict [ key ] = None <TAB><TAB> if checkContained and keyword in key : <TAB><TAB><TAB> matchesappend ( key ) <TAB><TAB><TAB> continue <TAB><TAB> if kwdSndx == soundex ( key . encode ( "" ascii "" , "" ignore "" ) ) : <TAB><TAB><TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches )",if key in seenDict :,if key in seenDict :,100.0,100.00,True
2620,"def visit_If ( self , node ) : <TAB> self . newline ( ) <TAB> self . write ( "" if  "" ) <TAB> self . visit ( node . test ) <TAB> self . write ( "" : "" ) <TAB> self . body ( node . body ) <TAB> while True : <TAB><TAB> else_ = node . orelse <TAB><TAB> <MASK> <TAB><TAB><TAB> node = else_ [ 0 ] <TAB><TAB><TAB> self . newline ( ) <TAB><TAB><TAB> self . write ( "" elif  "" ) <TAB><TAB><TAB> self . visit ( node . test ) <TAB><TAB><TAB> self . write ( "" : "" ) <TAB><TAB><TAB> self . body ( node . body ) <TAB><TAB> else : <TAB><TAB><TAB> self . newline ( ) <TAB><TAB><TAB> self . write ( "" else: "" ) <TAB><TAB><TAB> self . body ( else_ ) <TAB><TAB><TAB> break","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",if len ( else_ ) == 1 :,68.73103123843204,95.30,False
2621,"def _eyeLinkHardwareAndSoftwareVersion ( self ) : <TAB> try : <TAB><TAB> tracker_software_ver = 0 <TAB><TAB> eyelink_ver = self . _eyelink . getTrackerVersion ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tvstr = self . _eyelink . getTrackerVersionString ( ) <TAB><TAB><TAB> vindex = tvstr . find ( "" EYELINK CL "" ) <TAB><TAB><TAB> tracker_software_ver = int ( <TAB><TAB><TAB><TAB> float ( tvstr [ ( vindex + len ( "" EYELINK CL "" ) ) : ] . strip ( ) ) <TAB><TAB><TAB> ) <TAB><TAB> return eyelink_ver , tracker_software_ver <TAB> except Exception : <TAB><TAB> print2err ( "" EYELINK Error during _eyeLinkHardwareAndSoftwareVersion: "" ) <TAB><TAB> printExceptionDetailsToStdErr ( ) <TAB><TAB> return EyeTrackerConstants . EYETRACKER_ERROR",if eyelink_ver == 3 :,if eyelink_ver == EyeTrackerConstants . EYETRACKER_ERROR,69.88718356116901,97.02,False
2622,"def execute ( self , context ) : <TAB> for monad in context . blend_data . node_groups : <TAB><TAB> if monad . bl_idname == "" SverchGroupTreeType "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> monad . update_cls ( ) <TAB><TAB><TAB><TAB> except Exception as err : <TAB><TAB><TAB><TAB><TAB> print ( err ) <TAB><TAB><TAB><TAB><TAB> print ( "" {}  group class could not be created "" . format ( monad . name ) ) <TAB> return { "" FINISHED "" }","if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",if monad . update_cls :,64.09380494319538,90.47,False
2623,"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB><TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB><TAB> if pattern [ i ] not in dict : <TAB><TAB><TAB> if list_str [ i ] in set_value : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB><TAB><TAB> set_value . add ( list_str [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB> return True",if dict [ pattern [ i ] ] != list_str [ i ] :,if set_value != set_value :,66.12702443982845,93.06,False
2624,"def decorator_handle ( tokens ) : <TAB> """"""Process decorators."""""" <TAB> defs = [ ] <TAB> decorates = [ ] <TAB> for i , tok in enumerate ( tokens ) : <TAB><TAB> if "" simple "" in tok and len ( tok ) == 1 : <TAB><TAB><TAB> decorates . append ( "" @ "" + tok [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> varname = decorator_var + "" _ "" + str ( i ) <TAB><TAB><TAB> defs . append ( varname + ""  =  "" + tok [ 0 ] ) <TAB><TAB><TAB> decorates . append ( "" @ "" + varname ) <TAB><TAB> else : <TAB><TAB><TAB> raise CoconutInternalException ( "" invalid decorator tokens "" , tok ) <TAB> return "" \n "" . join ( defs + decorates ) + "" \n ""","elif ""test"" in tok and len ( tok ) == 1 :","elif ""decorator"" in tok and len ( tok ) == 2 :",98.24161180822189,97.75,False
2625,"def wait_impl ( self , cpid ) : <TAB> for i in range ( 10 ) : <TAB><TAB> # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB><TAB> # in the forking tests.  This is an attempt to fix the problem. <TAB><TAB> spid , status , rusage = os . wait3 ( os . WNOHANG ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( 1.0 ) <TAB> self . assertEqual ( spid , cpid ) <TAB> self . assertEqual ( status , 0 , "" cause =  %d , exit =  %d "" % ( status & 0xFF , status >> 8 ) ) <TAB> self . assertTrue ( rusage )",if spid == cpid :,if spid == cpid :,100.0,100.00,True
2626,"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> assert 2500 - 500 < count < 2500 + 500 <TAB><TAB> elif val == 1 : <TAB><TAB><TAB> assert 7500 - 500 < count < 7500 + 500 <TAB><TAB> else : <TAB><TAB><TAB> assert False",if val == 0 :,if val == 0 :,100.0,100.00,True
2627,"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB><TAB> # Ignore return events in generator except when stepping. <TAB><TAB> if self . stopframe and frame . f_code . co_flags & CO_GENERATOR : <TAB><TAB><TAB> return self . trace_dispatch <TAB><TAB> try : <TAB><TAB><TAB> self . frame_returning = frame <TAB><TAB><TAB> self . user_return ( frame , arg ) <TAB><TAB> finally : <TAB><TAB><TAB> self . frame_returning = None <TAB><TAB> <MASK> <TAB><TAB><TAB> raise BdbQuit <TAB><TAB> # The user issued a 'next' or 'until' command. <TAB><TAB> if self . stopframe is frame and self . stoplineno != - 1 : <TAB><TAB><TAB> self . _set_stopinfo ( None , None ) <TAB> return self . trace_dispatch",if self . quitting :,if self . frame_returning :,99.03250229775202,98.15,False
2628,"def mouse ( self , button , mods , x , y ) : <TAB> if button == 1 : <TAB><TAB> for i in range ( 4 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . hit = i <TAB> elif button == - 1 : <TAB><TAB> self . hit = None <TAB> elif self . hit != None : <TAB><TAB> self . coords [ self . hit ] = ( x , y ) <TAB><TAB> self . view . dirty ( )","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :","if mods [ i ] == ( x , y ) :",77.30123891719767,82.70,False
2629,"def __init__ ( self , * commands ) : <TAB> self . all_cmds = list ( <TAB><TAB> map ( lambda cmd : cmd [ 0 ] if isinstance ( cmd , list ) else cmd , commands ) <TAB> ) <TAB> for command in commands : <TAB><TAB> self . cmd = command if isinstance ( command , list ) else [ command ] <TAB><TAB> self . cmd_path = pwndbg . which . which ( self . cmd [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if self . cmd_path :,if self . cmd_path in self . all_cmds :,68.5107466060972,94.53,False
2630,"def _recv_obj ( self , suppress_error = False ) : <TAB> """"""Receive a (picklable) object"""""" <TAB> if self . conn . closed : <TAB><TAB> raise OSError ( "" handle is closed "" ) <TAB> try : <TAB><TAB> buf = self . conn . recv_bytes ( ) <TAB> except ( ConnectionError , EOFError ) as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> logger . debug ( "" receive has failed "" , exc_info = e ) <TAB><TAB> try : <TAB><TAB><TAB> self . _set_remote_close_cause ( e ) <TAB><TAB><TAB> raise PipeShutdownError ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . _close ( ) <TAB> obj = RemoteObjectUnpickler . loads ( buf , self ) <TAB> logger . debug ( "" received  %r "" , obj ) <TAB> return obj",if suppress_error :,if suppress_error :,100.0,100.00,True
2631,"def act ( self , obs ) : <TAB> with chainer . no_backprop_mode ( ) : <TAB><TAB> batch_obs = self . batch_states ( [ obs ] , self . xp , self . phi ) <TAB><TAB> action_distrib = self . model ( batch_obs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return chainer . cuda . to_cpu ( action_distrib . most_probable . array ) [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> return chainer . cuda . to_cpu ( action_distrib . sample ( ) . array ) [ 0 ]",if self . act_deterministically :,if self . act_in_parallel :,98.57321592028283,97.02,False
2632,"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB><TAB> for node in level : <TAB><TAB><TAB> if node . binary == BINARY_MISSING : <TAB><TAB><TAB><TAB> missing . append ( node ) <TAB><TAB><TAB> elif node . binary == BINARY_INVALID : <TAB><TAB><TAB><TAB> invalid . append ( node ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",elif node . binary == BINARY_DENIED_SET :,93.48924233588866,93.96,False
2633,"def persist ( self , * _ ) : <TAB> for key , obj in self . _objects . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> state = obj . get_state ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> md5 = hashlib . md5 ( state ) . hexdigest ( ) <TAB><TAB><TAB> if self . _last_state . get ( key ) == md5 : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . _persist_provider . store ( key , state ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> system_log . exception ( "" PersistHelper.persist fail "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . _last_state [ key ] = md5",if not state :,if not state :,100.0,100.00,True
2634,"def enter ( self , doc , * * kwds ) : <TAB> """"""Enters the mode, arranging for necessary grabs ASAP"""""" <TAB> super ( ColorPickMode , self ) . enter ( doc , * * kwds ) <TAB> if self . _started_from_key_press : <TAB><TAB> # Pick now using the last recorded event position <TAB><TAB> doc = self . doc <TAB><TAB> tdw = self . doc . tdw <TAB><TAB> t , x , y = doc . get_last_event_info ( tdw ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _pick_color_mode ( tdw , x , y , self . _pickmode ) <TAB><TAB> # Start the drag when possible <TAB><TAB> self . _start_drag_on_next_motion_event = True <TAB><TAB> self . _needs_drag_start = True","if None not in ( x , y ) :","if t == ""ColorPickMode"" :",95.75867868461154,95.67,False
2635,"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB><TAB> name = f . get_basename ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if name . endswith ( "" .sccprofile "" ) : <TAB><TAB><TAB> name = name [ 0 : - 11 ] <TAB><TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 )","if name . endswith ( "".mod"" ) :",if not name :,74.68268157156814,93.59,False
2636,"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB><TAB> if completed_process . stdout is not None : <TAB><TAB><TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB><TAB> if raise_error : <TAB><TAB><TAB> raise PipxError ( <TAB><TAB><TAB><TAB> f "" { '   ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> logger . info ( f "" { '   ' . join ( completed_process . args ) !r}  failed "" )",if completed_process . stderr is not None :,if completed_process . stderr is not None :,75.0,100.00,True
2637,"def test_connect ( <TAB> ipaddr , port , device , partition , method , path , headers = None , query_string = None ) : <TAB> if path == "" /a "" : <TAB><TAB> for k , v in headers . iteritems ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> test_errors . append ( "" %s :  %s  not in  %s "" % ( test_header , test_value , headers ) )",if k . lower ( ) == test_header . lower ( ) and v == test_value :,if test_header == k and test_value == v :,88.91712843389077,88.33,False
2638,"def test_stat_result_pickle ( self ) : <TAB> result = os . stat ( self . fname ) <TAB> for proto in range ( pickle . HIGHEST_PROTOCOL + 1 ) : <TAB><TAB> p = pickle . dumps ( result , proto ) <TAB><TAB> self . assertIn ( b "" stat_result "" , p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIn ( b "" cos \n stat_result \n "" , p ) <TAB><TAB> unpickled = pickle . loads ( p ) <TAB><TAB> self . assertEqual ( result , unpickled )",if proto < 4 :,if proto == pickle . HIGHEST_PROTOCOL :,74.44417469910694,94.19,False
2639,"def run_sql ( sql ) : <TAB> table = sql . split ( ""   "" ) [ 5 ] <TAB> logger . info ( "" Updating table  {} "" . format ( table ) ) <TAB> with transaction . atomic ( ) : <TAB><TAB> with connection . cursor ( ) as cursor : <TAB><TAB><TAB> cursor . execute ( sql ) <TAB><TAB><TAB> rows = cursor . fetchall ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Exception ( "" Sentry notification that  {}  is migrated "" . format ( table ) )",if not rows :,if rows :,82.63122792841715,98.20,False
2640,"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB><TAB> if x < self . box [ 0 ] : <TAB><TAB><TAB> self . box [ 0 ] = x <TAB><TAB> <MASK> <TAB><TAB><TAB> self . box [ 2 ] = x <TAB><TAB> if y < self . box [ 1 ] : <TAB><TAB><TAB> self . box [ 1 ] = y <TAB><TAB> if y > self . box [ 3 ] : <TAB><TAB><TAB> self . box [ 3 ] = y",if x > self . box [ 2 ] :,if x > self . box [ 2 ] :,100.0,100.00,True
2641,"def _packageFocusOutViaKeyPress ( self , row , column , txt ) : <TAB> if txt : <TAB><TAB> self . _set_current_cell ( row + 1 , column ) <TAB> else : <TAB><TAB> widget = self . cellWidget ( row + 1 , column ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _delete_cell ( row , column ) <TAB><TAB> new_request = self . get_request ( ) <TAB><TAB> self . context_model . set_request ( new_request ) <TAB><TAB> self . _update_request_column ( column , self . context_model )","if widget and isinstance ( widget , PackageSelectWidget ) :",if widget . is_pressed ( ) :,77.94373970706381,95.39,False
2642,"def parse_bash_set_output ( output ) : <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB><TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB><TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB><TAB> # line does not imply a continuation. <TAB><TAB> output = output . replace ( "" \\ \n "" , "" "" ) <TAB> environ = { } <TAB> for line in output . splitlines ( 0 ) : <TAB><TAB> line = line . rstrip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue # skip black lines <TAB><TAB> item = _ParseBashEnvStr ( line ) <TAB><TAB> if item : <TAB><TAB><TAB> environ [ item [ 0 ] ] = item [ 1 ] <TAB> return environ",if not line :,if not line :,100.0,100.00,True
2643,"def _get ( self , domain ) : <TAB> with self . lock : <TAB><TAB> try : <TAB><TAB><TAB> record = self . cache [ domain ] <TAB><TAB><TAB> time_now = time . time ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> record = None <TAB><TAB> except KeyError : <TAB><TAB><TAB> record = None <TAB><TAB> if not record : <TAB><TAB><TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB><TAB> # self.cache[domain] = record <TAB><TAB> return record","if time_now - record [ ""update"" ] > self . ttl :",if time_now > self . cache_max_age :,93.0331470001082,94.30,False
2644,"def test_filehash ( self ) : <TAB> """"""tests the hashes of the files in data/"""""" <TAB> fp = self . get_data_path ( ) <TAB> for fn in os . listdir ( fp ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # file used for something else <TAB><TAB><TAB> continue <TAB><TAB> expected_hash = fn <TAB><TAB> fullp = os . path . join ( fp , fn ) <TAB><TAB> output = self . run_command ( "" sha1sum  "" + fullp , exitcode = 0 ) <TAB><TAB> result = output . split ( ""   "" ) [ 0 ] <TAB><TAB> self . assertEqual ( result , expected_hash )","if ""."" in fn :","if fn . startswith ( ""__"" ) :",93.78003465835991,94.72,False
2645,"def test_new_vs_reference_code_stream_read_during_iter ( read_idx , read_len , bytecode ) : <TAB> reference = SlowCodeStream ( bytecode ) <TAB> latest = CodeStream ( bytecode ) <TAB> for index , ( actual , expected ) in enumerate ( zip ( latest , reference ) ) : <TAB><TAB> assert actual == expected <TAB><TAB> if index == read_idx : <TAB><TAB><TAB> readout_actual = latest . read ( read_len ) <TAB><TAB><TAB> readout_expected = reference . read ( read_len ) <TAB><TAB><TAB> assert readout_expected == readout_actual <TAB><TAB> <MASK> <TAB><TAB><TAB> assert latest . program_counter > = len ( reference ) <TAB><TAB> else : <TAB><TAB><TAB> assert latest . program_counter == reference . program_counter",if reference . program_counter >= len ( reference ) :,if index == read_idx :,73.50222710287406,94.61,False
2646,"def setup_logging ( ) : <TAB> try : <TAB><TAB> logconfig = config . get ( "" logging_config_file "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . config . fileConfig ( logconfig , disable_existing_loggers = False ) <TAB><TAB> logger . info ( "" logging initialized "" ) <TAB><TAB> logger . debug ( "" debug "" ) <TAB> except Exception as e : <TAB><TAB> print ( "" Unable to set logging configuration: "" , str ( e ) , file = sys . stderr ) <TAB><TAB> raise",if logconfig and os . path . exists ( logconfig ) :,if logconfig :,65.24056279684078,92.65,False
2647,"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> word = "" "" <TAB><TAB><TAB> if c . isalnum ( ) : <TAB><TAB><TAB><TAB> # We found the start of a word <TAB><TAB><TAB><TAB> word = c . lower ( ) <TAB><TAB><TAB><TAB> start_char = False <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> if c . isalnum ( ) : <TAB><TAB><TAB><TAB> word + = c . lower ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # We found end of word, emit it <TAB><TAB><TAB><TAB> start_char = True <TAB><TAB><TAB><TAB> yield word",if start_char == True :,if start_char :,95.45824042989943,98.24,False
2648,"def _get_nonce ( self , url , new_nonce_url ) : <TAB> if not self . _nonces : <TAB><TAB> logger . debug ( "" Requesting fresh nonce "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> response = self . head ( url ) <TAB><TAB> else : <TAB><TAB><TAB> # request a new nonce from the acme newNonce endpoint <TAB><TAB><TAB> response = self . _check_response ( self . head ( new_nonce_url ) , content_type = None ) <TAB><TAB> self . _add_nonce ( response ) <TAB> return self . _nonces . pop ( )",if new_nonce_url is None :,if self . _is_fresh_nonce ( ) :,78.60472286563035,93.78,False
2649,"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> if line . startswith ( comment ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if is_magic ( line , main_language ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> continue <TAB><TAB> return i > 0 and _BLANK_LINE . match ( line ) <TAB> return True",if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,if _BLANK_LINE . match ( line ) :,61.253744732880364,90.03,False
2650,"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB><TAB> if isinstance ( arg , bool ) : <TAB><TAB><TAB> gvariant + = ""   {} "" . format ( str ( arg ) . lower ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> gvariant + = f ""   { arg } "" <TAB><TAB> elif isinstance ( arg , str ) : <TAB><TAB><TAB> gvariant + = f '   "" { arg } "" ' <TAB><TAB> else : <TAB><TAB><TAB> gvariant + = f ""   { arg !s} "" <TAB> return gvariant . lstrip ( )","elif isinstance ( arg , ( int , float ) ) :","elif isinstance ( arg , int ) :",78.21147086600578,96.74,False
2651,"def _SkipGroup ( buffer , pos , end ) : <TAB> """"""Skip sub-group.  Returns the new position."""""" <TAB> while 1 : <TAB><TAB> ( tag_bytes , pos ) = ReadTag ( buffer , pos ) <TAB><TAB> new_pos = SkipField ( buffer , pos , end , tag_bytes ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return pos <TAB><TAB> pos = new_pos",if new_pos == - 1 :,if new_pos == pos :,77.22567965248265,96.85,False
2652,"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB><TAB> if participant is None or participant == self . simulator_config . broadcast_part : <TAB><TAB><TAB> continue <TAB><TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB><TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB><TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . participants_dict [ participant ] . refresh ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB><TAB> self . update_view ( )",if participant in self . participants_dict :,if self . participants_dict [ participant ] :,96.22033588055177,97.27,False
2653,"def feature_reddit ( layer_data , graph ) : <TAB> feature = { } <TAB> times = { } <TAB> indxs = { } <TAB> for _type in layer_data : <TAB><TAB> if len ( layer_data [ _type ] ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> idxs = np . array ( list ( layer_data [ _type ] . keys ( ) ) ) <TAB><TAB> tims = np . array ( list ( layer_data [ _type ] . values ( ) ) ) [ : , 1 ] <TAB><TAB> feature [ _type ] = np . array ( <TAB><TAB><TAB> list ( graph . node_feature [ _type ] . loc [ idxs , "" emb "" ] ) , dtype = np . float <TAB><TAB> ) <TAB><TAB> times [ _type ] = tims <TAB><TAB> indxs [ _type ] = idxs <TAB><TAB> <MASK> <TAB><TAB><TAB> attr = feature [ _type ] <TAB> return feature , times , indxs , attr","if _type == ""def"" :",if _type in feature :,72.43621756251116,97.49,False
2654,"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB><TAB> if tag . has_sort : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB> if tag . internal : <TAB><TAB><TAB><TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts",if tag . user :,if tag . internal :,97.03235704591208,98.28,False
2655,"def max_radius ( iterator ) : <TAB> radius_result = dict ( ) <TAB> for k , v in iterator : <TAB><TAB> if v [ 0 ] not in radius_result : <TAB><TAB><TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB> return radius_result",elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,elif v [ 0 ] not in radius_result :,84.30459528780912,90.48,False
2656,"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB><TAB> main_vault_directory = os . path . join ( <TAB><TAB><TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB><TAB> ) <TAB><TAB> if os . path . exists ( main_vault_directory ) : <TAB><TAB><TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB><TAB><TAB><TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB><TAB><TAB><TAB><TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> pwd_found . append ( cred ) <TAB> return pwd_found",if cred :,if cred :,100.0,100.00,True
2657,"def disconnect_sync ( self , connection , close_connection = False ) : <TAB> key = id ( connection ) <TAB> ts = self . in_use . pop ( key ) <TAB> if close_connection : <TAB><TAB> self . connections_map . pop ( key ) <TAB><TAB> self . _connection_close_sync ( connection ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . connections_map . pop ( key ) <TAB><TAB><TAB> self . _connection_close_sync ( connection ) <TAB><TAB> else : <TAB><TAB><TAB> with self . _lock_sync : <TAB><TAB><TAB><TAB> heapq . heappush ( self . connections_sync , ( ts , key ) )",if self . stale_timeout and self . is_stale ( ts ) :,if ts == 0 :,92.82624394376889,92.22,False
2658,"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> self . _populate_dict ( element , k , v ) <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> self . _populate_list ( element , k , v ) <TAB><TAB> elif isinstance ( v , bool ) : <TAB><TAB><TAB> self . _populate_bool ( element , k , v ) <TAB><TAB> elif isinstance ( v , basestring ) : <TAB><TAB><TAB> self . _populate_str ( element , k , v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _populate_number ( element , k , v )","elif type ( v ) in [ int , float , long , complex ] :","elif isinstance ( v , int ) :",67.53365209306014,93.98,False
2659,"def readframes ( self , nframes ) : <TAB> if self . _ssnd_seek_needed : <TAB><TAB> self . _ssnd_chunk . seek ( 0 ) <TAB><TAB> dummy = self . _ssnd_chunk . read ( 8 ) <TAB><TAB> pos = self . _soundpos * self . _framesize <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _ssnd_chunk . seek ( pos + 8 ) <TAB><TAB> self . _ssnd_seek_needed = 0 <TAB> if nframes == 0 : <TAB><TAB> return "" "" <TAB> data = self . _ssnd_chunk . read ( nframes * self . _framesize ) <TAB> if self . _convert and data : <TAB><TAB> data = self . _convert ( data ) <TAB> self . _soundpos = self . _soundpos + len ( data ) / ( self . _nchannels * self . _sampwidth ) <TAB> return data",if pos :,if pos :,100.0,100.00,True
2660,"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB><TAB><TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB><TAB><TAB> if __opts__ . get ( "" ssh_user "" ) : <TAB><TAB><TAB><TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret","if fnmatch . fnmatch ( tgt , host ) :",if host in tgt :,85.1248947183399,94.60,False
2661,"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB><TAB> self . logger . debug ( "" get attr val:  %s   %s "" , nodeid , attr ) <TAB><TAB> if nodeid not in self . _nodes : <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB> return dv <TAB><TAB> node = self . _nodes [ nodeid ] <TAB><TAB> if attr not in node . attributes : <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB> return dv <TAB><TAB> attval = node . attributes [ attr ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return attval . value_callback ( ) <TAB><TAB> return attval . value",if attval . value_callback :,if attval . value_callback :,100.0,100.00,True
2662,"def remove_property ( self , key ) : # type: (str) -> None <TAB> with self . secure ( ) as config : <TAB><TAB> keys = key . split ( "" . "" ) <TAB><TAB> current_config = config <TAB><TAB> for i , key in enumerate ( keys ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> if i == len ( keys ) - 1 : <TAB><TAB><TAB><TAB> del current_config [ key ] <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> current_config = current_config [ key ]",if key not in current_config :,if key not in current_config :,75.0,100.00,True
2663,"def _class_browser ( parent ) : # Wrapper for htest <TAB> try : <TAB><TAB> file = __file__ <TAB> except NameError : <TAB><TAB> file = sys . argv [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> file = sys . argv [ 1 ] <TAB><TAB> else : <TAB><TAB><TAB> file = sys . argv [ 0 ] <TAB> dir , file = os . path . split ( file ) <TAB> name = os . path . splitext ( file ) [ 0 ] <TAB> flist = PyShell . PyShellFileList ( parent ) <TAB> global file_open <TAB> file_open = flist . open <TAB> ClassBrowser ( flist , name , [ dir ] , _htest = True )",if sys . argv [ 1 : ] :,if sys . argv [ 1 ] :,73.95956518813998,98.63,False
2664,"def get_only_text_part ( self , msg ) : <TAB> count = 0 <TAB> only_text_part = None <TAB> for part in msg . walk ( ) : <TAB><TAB> if part . is_multipart ( ) : <TAB><TAB><TAB> continue <TAB><TAB> count + = 1 <TAB><TAB> mimetype = part . get_content_type ( ) or "" text/plain "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> only_text_part = part <TAB> return only_text_part","if mimetype != ""text/plain"" or count != 1 :","if mimetype not in ( ""text/plain"" , ""text/plain"" ) :",82.8117330173244,92.17,False
2665,"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB><TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB><TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB><TAB> if key == "" CI_KEEP_ALIVE "" : <TAB><TAB><TAB> ci_names = val . replace ( "" , "" , ""   "" ) . lower ( ) . split ( ) if val else [ ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = True <TAB> return result",if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,if ci in ci_names :,73.48113123142707,91.90,False
2666,"def _calc_block_io ( self , blkio ) : <TAB> """"""Calculate block IO stats."""""" <TAB> for stats in blkio [ "" io_service_bytes_recursive "" ] : <TAB><TAB> if stats [ "" op "" ] == "" Read "" : <TAB><TAB><TAB> self . _blk_read + = stats [ "" value "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _blk_write + = stats [ "" value "" ]","elif stats [ ""op"" ] == ""Write"" :","if stats [ ""op"" ] == ""Write"" :",97.89786105593798,98.04,False
2667,"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB><TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB> ) <TAB> return six . text_type ( value )",if settings . USE_TZ :,if USE_TZ :,98.02089016324993,97.80,False
2668,"def load_state_dict ( self , state_dict ) : <TAB> for module_name , module_state_dict in state_dict . items ( ) : <TAB><TAB> if module_name in self . module_pool : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . module_pool [ module_name ] . module . load_state_dict ( module_state_dict ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . module_pool [ module_name ] . load_state_dict ( module_state_dict ) <TAB><TAB> else : <TAB><TAB><TAB> logging . info ( f "" Missing  { module_name }  in module_pool, skip it.. "" )","if self . config [ ""dataparallel"" ] :","if isinstance ( self . module_pool [ module_name ] . module , Module ) :",67.4405962322017,91.46,False
2669,"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB><TAB> if i > = min ( len ( scales ) , len ( vidxs ) / / 2 ) : <TAB><TAB><TAB> break <TAB><TAB> scale = scales [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB><TAB><TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData",if not math . isnan ( scale ) :,if scale != 0 :,69.9554589658341,94.78,False
2670,"def __init__ ( self , factors , contrast_matrices , num_columns ) : <TAB> self . factors = tuple ( factors ) <TAB> factor_set = frozenset ( factors ) <TAB> if not isinstance ( contrast_matrices , dict ) : <TAB><TAB> raise ValueError ( "" contrast_matrices must be dict "" ) <TAB> for factor , contrast_matrix in six . iteritems ( contrast_matrices ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Unexpected factor in contrast_matrices dict "" ) <TAB><TAB> if not isinstance ( contrast_matrix , ContrastMatrix ) : <TAB><TAB><TAB> raise ValueError ( "" Expected a ContrastMatrix, not  %r "" % ( contrast_matrix , ) ) <TAB> self . contrast_matrices = contrast_matrices <TAB> if not isinstance ( num_columns , six . integer_types ) : <TAB><TAB> raise ValueError ( "" num_columns must be an integer "" ) <TAB> self . num_columns = num_columns",if factor not in factor_set :,if factor not in factor_set :,100.0,100.00,True
2671,"def app ( scope , receive , send ) : <TAB> while True : <TAB><TAB> message = await receive ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB><TAB><TAB> pass <TAB><TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB><TAB><TAB> break","if message [ ""type"" ] == ""websocket.connect"" :","if message [ ""type"" ] == ""websocket.connect"" :",100.0,100.00,True
2672,"def value__set ( self , value ) : <TAB> for i , ( option , checked ) in enumerate ( self . options ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . selectedIndex = i <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" Option  %r  not found (from  %s ) "" <TAB><TAB><TAB> % ( value , "" ,  "" . join ( [ repr ( o ) for o , c in self . options ] ) ) <TAB><TAB> )",if option == str ( value ) :,if value == option :,94.30746377365675,94.95,False
2673,"def init_links ( self ) : <TAB> links = LinkCallback . find_links ( self ) <TAB> callbacks = [ ] <TAB> for link , src_plot , tgt_plot in links : <TAB><TAB> cb = Link . _callbacks [ "" bokeh "" ] [ type ( link ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> callbacks . append ( cb ( self . root , link , src_plot , tgt_plot ) ) <TAB> return callbacks",if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,if not cb :,57.89954681305153,83.39,False
2674,"def _validate_scalar_extensions ( self ) - > List [ str ] : <TAB> errors = [ ] <TAB> for extension in [ <TAB><TAB> x for x in self . extensions if isinstance ( x , GraphQLScalarTypeExtension ) <TAB> ] : <TAB><TAB> extended = self . type_definitions . get ( extension . name ) <TAB><TAB> ext_errors = _validate_extension ( <TAB><TAB><TAB> extended , extension . name , GraphQLScalarType , "" SCALAR "" <TAB><TAB> ) <TAB><TAB> errors . extend ( ext_errors ) <TAB><TAB> <MASK> <TAB><TAB><TAB> errors . extend ( _validate_extension_directives ( extension , extended , "" SCALAR "" ) ) <TAB> return errors",if not ext_errors :,if extended :,69.549703942318,96.88,False
2675,"def copy_tcltk ( src , dest , symlink ) : <TAB> """"""copy tcl/tk libraries on Windows (issue #93)"""""" <TAB> for libversion in "" 8.5 "" , "" 8.6 "" : <TAB><TAB> for libname in "" tcl "" , "" tk "" : <TAB><TAB><TAB> srcdir = join ( src , "" tcl "" , libname + libversion ) <TAB><TAB><TAB> destdir = join ( dest , "" tcl "" , libname + libversion ) <TAB><TAB><TAB> # Only copy the dirs from the above combinations that exist <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> copyfileordir ( srcdir , destdir , symlink )",if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,if os . path . exists ( srcdir ) and not os . path . exists ( dest,98.03287417449108,97.46,False
2676,"def parse ( self , response ) : <TAB> try : <TAB><TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB><TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB><TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB><TAB> return <TAB> for item in content [ "" data "" ] : <TAB><TAB> if "" objURL "" in item : <TAB><TAB><TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> img_url = item [ "" hoverURL "" ] <TAB><TAB> else : <TAB><TAB><TAB> continue <TAB><TAB> yield dict ( file_url = img_url )","elif ""hoverURL"" in item :","elif ""hoverURL"" in item :",100.0,100.00,True
2677,"def check_and_reload ( self ) : <TAB> # Check if tables have been modified, if so reload <TAB> for table_name , table_version in self . _table_versions . items ( ) : <TAB><TAB> table = self . app . tool_data_tables . get ( table_name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . reload_genomes ( )",if table is not None and not table . is_current_version ( table_version ) :,if table and table . version == self . _table_version :,65.78255389443713,86.31,False
2678,"def _get_query_defaults ( self , query_defns ) : <TAB> defaults = { } <TAB> for k , v in query_defns . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> defaults [ k ] = self . _get_default_obj ( v [ "" schema "" ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> defaults [ k ] = v [ "" schema "" ] [ "" default "" ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> pass <TAB> return defaults","if v [ ""schema"" ] [ ""type"" ] == ""object"" :","if isinstance ( v [ ""schema"" ] , dict ) :",93.46328254754536,92.20,False
2679,"def ftp_login ( host , port , username = None , password = None , anonymous = False ) : <TAB> ret = False <TAB> try : <TAB><TAB> ftp = ftplib . FTP ( ) <TAB><TAB> ftp . connect ( host , port , timeout = 6 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ftp . login ( ) <TAB><TAB> else : <TAB><TAB><TAB> ftp . login ( username , password ) <TAB><TAB> ret = True <TAB><TAB> ftp . quit ( ) <TAB> except Exception : <TAB><TAB> pass <TAB> return ret",if anonymous :,if anonymous :,100.0,100.00,True
2680,"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB><TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self . _value in dynamicStrToScalar : <TAB><TAB> return dynamicStrToScalar [ self . _value ] <TAB> else : <TAB><TAB> thisDynamic = self . _value <TAB><TAB> # ignore leading s like in sf <TAB><TAB> if "" s "" in thisDynamic : <TAB><TAB><TAB> thisDynamic = thisDynamic [ 1 : ] <TAB><TAB> # ignore closing z like in fz <TAB><TAB> if thisDynamic [ - 1 ] == "" z "" : <TAB><TAB><TAB> thisDynamic = thisDynamic [ : - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return dynamicStrToScalar [ thisDynamic ] <TAB><TAB> else : <TAB><TAB><TAB> return dynamicStrToScalar [ None ]",if thisDynamic in dynamicStrToScalar :,if thisDynamic in dynamicStrToScalar :,100.0,100.00,True
2681,"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB><TAB> for _dir , offsets in faceDirections : <TAB><TAB><TAB> if _dir == FaceYIncreasing : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> dx , dy , dz = offsets <TAB><TAB><TAB> p = ( x + dx , y + dy , z + dz ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> nx , ny , nz = p <TAB><TAB><TAB> if level . blockAt ( nx , ny , nz ) == 0 : <TAB><TAB><TAB><TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB><TAB><TAB><TAB> newcoords . append ( p ) <TAB> return newcoords",if p not in box :,if len ( p ) == 0 :,72.35939065325437,96.37,False
2682,"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB><TAB> wstate = str ( target_widget [ "" state "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # change state temporarily <TAB><TAB><TAB> target_widget [ "" state "" ] = "" normal "" <TAB><TAB> target_widget . delete ( "" 0 "" , tk . END ) <TAB><TAB> target_widget . insert ( "" 0 "" , value ) <TAB><TAB> target_widget [ "" state "" ] = wstate <TAB> else : <TAB><TAB> super ( EntryBaseBO , self ) . _set_property ( target_widget , pname , value )","if wstate != ""normal"" :","if wstate != ""normal"" :",100.0,100.00,True
2683,"def teardown ( ) : <TAB> try : <TAB><TAB> time . sleep ( 1 ) <TAB> except KeyboardInterrupt : <TAB><TAB> return <TAB> while launchers : <TAB><TAB> p = launchers . pop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> p . stop ( ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> print ( e ) <TAB><TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> time . sleep ( 0.25 ) <TAB><TAB><TAB> except KeyboardInterrupt : <TAB><TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> print ( "" cleaning up test process... "" ) <TAB><TAB><TAB><TAB> p . signal ( SIGKILL ) <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> print ( "" couldn ' t shutdown process:  "" , p )",if p . poll ( ) is None :,if p . is_alive ( ) :,65.06266754129805,94.67,False
2684,"def checkAndRemoveDuplicate ( self , node ) : <TAB> for bucket in self . buckets : <TAB><TAB> for n in bucket . getNodes ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . removeContact ( n )","if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :","if n . get ( ""name"" ) == node . get ( ""name"" ) :",47.78847917304732,69.92,False
2685,"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB><TAB> if this . glob : <TAB><TAB><TAB> flags + = u "" g "" <TAB><TAB> <MASK> <TAB><TAB><TAB> flags + = u "" i "" <TAB><TAB> if this . multiline : <TAB><TAB><TAB> flags + = u "" m "" <TAB> except : <TAB><TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags",if this . ignore_case :,if this . include :,98.5467228474833,96.90,False
2686,"def import_submodules ( package_name ) : <TAB> package = sys . modules [ package_name ] <TAB> results = { } <TAB> for loader , name , is_pkg in pkgutil . iter_modules ( package . __path__ ) : <TAB><TAB> full_name = package_name + "" . "" + name <TAB><TAB> module = importlib . import_module ( full_name ) <TAB><TAB> setattr ( sys . modules [ __name__ ] , name , module ) <TAB><TAB> results [ full_name ] = module <TAB><TAB> if is_pkg : <TAB><TAB><TAB> valid_pkg = import_submodules ( full_name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> results . update ( valid_pkg ) <TAB> return results",if valid_pkg :,if valid_pkg :,100.0,100.00,True
2687,"def _call ( self , cmd ) : <TAB> what = cmd [ "" command "" ] <TAB> if what == "" list "" : <TAB><TAB> name = cmd [ "" properties "" ] . get ( "" name "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return { "" watchers "" : [ "" one "" , "" two "" , "" three "" ] } <TAB><TAB> return { "" pids "" : [ 123 , 456 ] } <TAB> elif what == "" dstats "" : <TAB><TAB> return { "" info "" : { "" pid "" : 789 } } <TAB> elif what == "" listsockets "" : <TAB><TAB> return { <TAB><TAB><TAB> "" status "" : "" ok "" , <TAB><TAB><TAB> "" sockets "" : [ { "" path "" : self . _unix , "" fd "" : 5 , "" name "" : "" XXXX "" , "" backlog "" : 2048 } ] , <TAB><TAB><TAB> "" time "" : 1369647058.967524 , <TAB><TAB> } <TAB> raise NotImplementedError ( cmd )",if name is None :,"if name == ""watchers"" :",96.60067748594004,97.44,False
2688,"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB><TAB> xlib . XNextEvent ( self . _display , e ) <TAB><TAB> # Key events are filtered by the xlib window event <TAB><TAB> # handler so they get a shot at the prefiltered event. <TAB><TAB> if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> dispatch = self . _window_map [ e . xany . window ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> continue <TAB><TAB> dispatch ( e )","if xlib . XFilterEvent ( e , e . xany . window ) :",if e . xany . window in self . _window_map :,96.00383030231886,95.12,False
2689,"def translate ( self , line ) : <TAB> parsed = self . RE_LINE_PARSER . match ( line ) <TAB> if parsed : <TAB><TAB> value = parsed . group ( 3 ) <TAB><TAB> stage = parsed . group ( 1 ) <TAB><TAB> <MASK> # query string is rendered here <TAB><TAB><TAB> return "" \n # HTTP Request: \n "" + self . stripslashes ( value ) <TAB><TAB> elif stage == "" reply "" : <TAB><TAB><TAB> return "" \n \n # HTTP Response: \n "" + self . stripslashes ( value ) <TAB><TAB> elif stage == "" header "" : <TAB><TAB><TAB> return value + "" \n "" <TAB><TAB> else : <TAB><TAB><TAB> return value <TAB> return line","if stage == ""send"" :","if stage == ""querystring"" :",98.93497622570001,98.75,False
2690,"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> flags + = u "" g "" <TAB><TAB> if this . ignore_case : <TAB><TAB><TAB> flags + = u "" i "" <TAB><TAB> if this . multiline : <TAB><TAB><TAB> flags + = u "" m "" <TAB> except : <TAB><TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags",if this . glob :,if this . strict :,98.5467228474833,98.27,False
2691,"def __exit__ ( self , * exc_info ) : <TAB> super ( WarningsChecker , self ) . __exit__ ( * exc_info ) <TAB> # only check if we're not currently handling an exception <TAB> if all ( a is None for a in exc_info ) : <TAB><TAB> if self . expected_warning is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> __tracebackhide__ = True <TAB><TAB><TAB><TAB> pytest . fail ( "" DID NOT WARN "" )",if not any ( r . category in self . expected_warning for r in self ) :,if not self . expected_warning :,91.61079320835577,90.42,False
2692,"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB><TAB> if k . startswith ( "" _ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> if v [ "" email "" ] == "" "" : <TAB><TAB><TAB><TAB> v [ "" email "" ] = None <TAB><TAB><TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB><TAB><TAB><TAB> v [ "" ip "" ] = None <TAB> return self . objs","if v [ ""_class"" ] == ""User"" :","if v [ ""type"" ] == ""email"" :",97.3027692843653,96.12,False
2693,"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB><TAB> if i < = start_after : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . count + = 1 <TAB><TAB><TAB> raise TemporaryProblem <TAB><TAB> if i == 7 and self . count < 4 : <TAB><TAB><TAB> self . count + = 1 <TAB><TAB><TAB> raise TemporaryProblem <TAB><TAB> yield i",if i == 2 and self . count < 1 :,if i == 6 and self . count < 3 :,95.04152685636424,96.61,False
2694,"def check ( self ) : <TAB> tcp_client = self . tcp_create ( ) <TAB> if tcp_client . connect ( ) : <TAB><TAB> tcp_client . send ( b "" ABCDE "" ) <TAB><TAB> response = tcp_client . recv ( 5 ) <TAB><TAB> tcp_client . close ( ) <TAB><TAB> if response : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . endianness = "" > "" # BE <TAB><TAB><TAB> elif response . startswith ( b "" ScMM "" ) : <TAB><TAB><TAB><TAB> self . endianness = "" < "" # LE <TAB><TAB><TAB> return True # target is vulnerable <TAB> return False # target is not vulnerable","if response . startswith ( b""MMcS"" ) :","if response . startswith ( b""BCD"" ) :",98.82420425883905,98.70,False
2695,"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB><TAB> if src_root != src_dir : <TAB><TAB><TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB><TAB> else : <TAB><TAB><TAB> rel_root = "" "" <TAB><TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB><TAB><TAB> continue <TAB><TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( dst_root ) <TAB><TAB> for f in files : <TAB><TAB><TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) )",if not os . path . exists ( dst_root ) :,if not os . path . exists ( dst_root ) :,100.0,100.00,True
2696,"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB><TAB> i = host . rfind ( "" : "" ) <TAB><TAB> j = host . rfind ( "" ] "" ) # ipv6 addresses have [...] <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> port = int ( host [ i + 1 : ] ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB><TAB><TAB> host = host [ : i ] <TAB><TAB> else : <TAB><TAB><TAB> port = self . default_port <TAB><TAB> if host and host [ 0 ] == "" [ "" and host [ - 1 ] == "" ] "" : <TAB><TAB><TAB> host = host [ 1 : - 1 ] <TAB> self . host = host <TAB> self . port = port",if i > j :,"if i >= 0 and j >= 0 and host [ i + 1 ] == "":"" :",96.96024163051318,92.59,False
2697,"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB> members = inspect . getmembers ( match ) <TAB><TAB> for member in members : <TAB><TAB><TAB> if member [ 0 ] == key : <TAB><TAB><TAB><TAB> field_value = member [ 1 ] <TAB><TAB><TAB> elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB> wildcards = member [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB> elif key == "" nw_dst "" : <TAB><TAB><TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB><TAB> field_value = match [ key ] <TAB> return field_value","if key == ""nw_src"" :","if key == ""nw_src"" :",100.0,100.00,True
2698,"def _clear_storage ( ) : <TAB> """"""Clear old files from storage."""""" <TAB> hacs = get_hacs ( ) <TAB> storagefiles = [ "" hacs "" ] <TAB> for s_f in storagefiles : <TAB><TAB> path = f "" { hacs . core . config_path } /.storage/ { s_f } "" <TAB><TAB> <MASK> <TAB><TAB><TAB> hacs . log . info ( f "" Cleaning up old storage file  { path } "" ) <TAB><TAB><TAB> os . remove ( path )",if os . path . isfile ( path ) :,if os . path . exists ( path ) :,98.502583792969,98.18,False
2699,"def action_delete ( self , ids ) : <TAB> try : <TAB><TAB> count = 0 <TAB><TAB> # TODO: Optimize me <TAB><TAB> for pk in ids : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> count + = 1 <TAB><TAB> flash ( <TAB><TAB><TAB> ngettext ( <TAB><TAB><TAB><TAB> "" Record was successfully deleted. "" , <TAB><TAB><TAB><TAB> "" %(count)s  records were successfully deleted. "" , <TAB><TAB><TAB><TAB> count , <TAB><TAB><TAB><TAB> count = count , <TAB><TAB><TAB> ) , <TAB><TAB><TAB> "" success "" , <TAB><TAB> ) <TAB> except Exception as ex : <TAB><TAB> flash ( gettext ( "" Failed to delete records.  %(error)s "" , error = str ( ex ) ) , "" error "" )",if self . delete_model ( self . get_one ( pk ) ) :,if self . _delete_record ( pk ) :,96.46355378093403,95.55,False
2700,"def test_inclusion ( all_values ) : <TAB> for values in [ { "" guid_2 "" , "" guid_1 "" } , { "" guid_5 "" , "" guid_XXX "" } , { "" guid_2 "" } ] : <TAB><TAB> test_predicate = in_set ( values , "" volume_guid "" ) <TAB><TAB> included_values = set ( ) <TAB><TAB> for val in all_values : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> included_values . add ( val ) <TAB><TAB> assert included_values == all_values . intersection ( values )","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",if test_predicate :,90.95238593701808,89.94,False
2701,"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB><TAB> attr_mod , attr_path = ( <TAB><TAB><TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB><TAB> ) <TAB><TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB><TAB> op = import_module ( full_mod_path ) <TAB><TAB> if attr_path : <TAB><TAB><TAB> # Only load attributes if needed <TAB><TAB><TAB> for part in attr_path . split ( "" . "" ) : <TAB><TAB><TAB><TAB> op = getattr ( op , part ) <TAB><TAB> return op <TAB> except ( ImportError , AttributeError ) as ex : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> raise ex",if checked :,if checked :,100.0,100.00,True
2702,"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . fusefat is not None : <TAB><TAB> self . fusefat . send_signal ( signal . SIGINT ) <TAB><TAB> # Allow 1s to return without sending terminate <TAB><TAB> for count in range ( 10 ) : <TAB><TAB><TAB> time . sleep ( 0.1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> self . fusefat . terminate ( ) <TAB><TAB> time . sleep ( self . delay ) <TAB><TAB> assert not os . path . exists ( self . canary ) <TAB> self . dev_null . close ( ) <TAB> shutil . rmtree ( self . tmpdir )",if self . fusefat . poll ( ) is not None :,if count == 1 :,94.97067587395664,94.38,False
2703,"def check_context_processors ( output ) : <TAB> with output . section ( "" Context processors "" ) as section : <TAB><TAB> processors = list ( <TAB><TAB><TAB> chain ( <TAB><TAB><TAB><TAB> * [ <TAB><TAB><TAB><TAB><TAB> template [ "" OPTIONS "" ] . get ( "" context_processors "" , [ ] ) <TAB><TAB><TAB><TAB><TAB> for template in settings . TEMPLATES <TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> required_processors = ( "" cms.context_processors.cms_settings "" , ) <TAB><TAB> for processor in required_processors : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> section . error ( <TAB><TAB><TAB><TAB><TAB> "" %s  context processor must be in TEMPLATES option context_processors "" <TAB><TAB><TAB><TAB><TAB> % processor <TAB><TAB><TAB><TAB> )",if processor not in processors :,if processor not in processors :,100.0,100.00,True
2704,"def test_converters ( self ) : <TAB> response = self . _get ( "" datatypes/converters "" ) <TAB> self . _assert_status_code_is ( response , 200 ) <TAB> converters_list = response . json ( ) <TAB> found_fasta_to_tabular = False <TAB> for converter in converters_list : <TAB><TAB> self . _assert_has_key ( converter , "" source "" , "" target "" , "" tool_id "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> found_fasta_to_tabular = True <TAB> assert found_fasta_to_tabular","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :","if converter . get ( ""target"" ) :",62.61453886114607,86.37,False
2705,"def remove_pid ( self , watcher , pid ) : <TAB> if pid in self . _pids [ watcher ] : <TAB><TAB> logger . debug ( "" Removing  %d  from  %s "" % ( pid , watcher ) ) <TAB><TAB> self . _pids [ watcher ] . remove ( pid ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( "" Stopping the periodic callback for  {0} "" . format ( watcher ) ) <TAB><TAB><TAB> self . _callbacks [ watcher ] . stop ( )",if len ( self . _pids [ watcher ] ) == 0 :,if self . _callbacks [ watcher ] :,66.34716838116557,91.54,False
2706,"def _fc_layer ( self , sess , bottom , name , trainable = True , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB><TAB> shape = bottom . get_shape ( ) . as_list ( ) <TAB><TAB> dim = 1 <TAB><TAB> for d in shape [ 1 : ] : <TAB><TAB><TAB> dim * = d <TAB><TAB> x = tf . reshape ( bottom , [ - 1 , dim ] ) <TAB><TAB> weight = self . _get_fc_weight ( sess , name , trainable = trainable ) <TAB><TAB> bias = self . _get_bias ( sess , name , trainable = trainable ) <TAB><TAB> fc = tf . nn . bias_add ( tf . matmul ( x , weight ) , bias ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fc = tf . nn . relu ( fc ) <TAB><TAB> return fc",if relu :,if relu :,100.0,100.00,True
2707,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB><TAB> if root_path : <TAB><TAB><TAB> config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return drive <TAB><TAB> elif volume_guid_path : <TAB><TAB><TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB> return drive",if config_root_path and root_path == config_root_path :,if config_root_path and config_root_path == root_path :,93.2697203942087,98.48,False
2708,"def rewire_init ( expr ) : <TAB> new_args = [ ] <TAB> if expr [ 0 ] == HySymbol ( "" setv "" ) : <TAB><TAB> pairs = expr [ 1 : ] <TAB><TAB> while len ( pairs ) > 0 : <TAB><TAB><TAB> k , v = ( pairs . pop ( 0 ) , pairs . pop ( 0 ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> v . append ( HySymbol ( "" None "" ) ) <TAB><TAB><TAB> new_args . append ( k ) <TAB><TAB><TAB> new_args . append ( v ) <TAB><TAB> expr = HyExpression ( [ HySymbol ( "" setv "" ) ] + new_args ) . replace ( expr ) <TAB> return expr","if k == HySymbol ( ""__init__"" ) :",if k is None :,83.47666452804926,93.21,False
2709,"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB><TAB> if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> doDir ( child ) <TAB><TAB> elif child . tagName == "" Component "" : <TAB><TAB><TAB> for grandchild in child . childNodes : <TAB><TAB><TAB><TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if child . tagName == ""Directory"" :","if child . tagName == ""Directory"" :",75.0,100.00,True
2710,"def _v2_common ( self , cfg ) : <TAB> LOG . debug ( "" v2_common: handling config: \n %s "" , cfg ) <TAB> if "" nameservers "" in cfg : <TAB><TAB> search = cfg . get ( "" nameservers "" ) . get ( "" search "" , [ ] ) <TAB><TAB> dns = cfg . get ( "" nameservers "" ) . get ( "" addresses "" , [ ] ) <TAB><TAB> name_cmd = { "" type "" : "" nameserver "" } <TAB><TAB> <MASK> <TAB><TAB><TAB> name_cmd . update ( { "" search "" : search } ) <TAB><TAB> if len ( dns ) > 0 : <TAB><TAB><TAB> name_cmd . update ( { "" addresses "" : dns } ) <TAB><TAB> LOG . debug ( "" v2(nameserver) -> v1(nameserver): \n %s "" , name_cmd ) <TAB><TAB> self . handle_nameserver ( name_cmd )",if len ( search ) > 0 :,if len ( search ) > 0 :,100.0,100.00,True
2711,"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB><TAB> if self . type : <TAB><TAB><TAB> for extension in self . extensions : <TAB><TAB><TAB><TAB> self [ extension ] = self . type <TAB><TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB><TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB><TAB> pattern = attrs [ "" pattern "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) )","if pattern . startswith ( ""*."" ) :","if pattern . startswith ( ""file:"" ) :",98.80701920898194,97.95,False
2712,"def get_attr_by_data_model ( self , dmodel , exclude_record = False ) : <TAB> if exclude_record : <TAB><TAB> return list ( <TAB><TAB><TAB> filter ( <TAB><TAB><TAB><TAB> lambda x : x . data_model == dmodel and x . value == "" "" <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> else False , <TAB><TAB><TAB><TAB> self . _inferred_intent , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> else : <TAB><TAB> return list ( <TAB><TAB><TAB> filter ( <TAB><TAB><TAB><TAB> lambda x : x . data_model == dmodel and x . value == "" "" <TAB><TAB><TAB><TAB> if hasattr ( x , "" data_model "" ) <TAB><TAB><TAB><TAB> else False , <TAB><TAB><TAB><TAB> self . _inferred_intent , <TAB><TAB><TAB> ) <TAB><TAB> )","if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )","if hasattr ( x , ""data_model"" )",94.38295643033486,96.38,False
2713,"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB><TAB> if not metadata . get ( "" nargs "" ) : <TAB><TAB><TAB> v = quote ( value ) <TAB><TAB> else : <TAB><TAB><TAB> v = value <TAB><TAB> return u "" {0}   {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB><TAB> if not value : <TAB><TAB><TAB> return None <TAB><TAB> <MASK> <TAB><TAB><TAB> return quote ( value ) <TAB><TAB> else : <TAB><TAB><TAB> return value","elif not metadata . get ( ""nargs"" ) :","elif metadata . get ( ""nargs"" ) :",70.16588125322464,98.61,False
2714,"def get_images ( self ) : <TAB> images = [ ] <TAB> try : <TAB><TAB> tag = MP4 ( self [ "" ~filename "" ] ) <TAB> except Exception : <TAB><TAB> return [ ] <TAB> for cover in tag . get ( "" covr "" , [ ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> mime = "" image/jpeg "" <TAB><TAB> elif cover . imageformat == MP4Cover . FORMAT_PNG : <TAB><TAB><TAB> mime = "" image/png "" <TAB><TAB> else : <TAB><TAB><TAB> mime = "" image/ "" <TAB><TAB> f = get_temp_cover_file ( cover ) <TAB><TAB> images . append ( EmbeddedImage ( f , mime ) ) <TAB> return images",if cover . imageformat == MP4Cover . FORMAT_JPEG :,if cover . imageformat == MP4Cover . FORMAT_JPEG :,100.0,100.00,True
2715,"def run_cmd ( self , util , value ) : <TAB> state = util . state <TAB> if not state . argument_supplied : <TAB><TAB> state . argument_supplied = True <TAB><TAB> if value == "" by_four "" : <TAB><TAB><TAB> state . argument_value = 4 <TAB><TAB> <MASK> <TAB><TAB><TAB> state . argument_negative = True <TAB><TAB> else : <TAB><TAB><TAB> state . argument_value = value <TAB> elif value == "" by_four "" : <TAB><TAB> state . argument_value * = 4 <TAB> elif isinstance ( value , int ) : <TAB><TAB> state . argument_value * = 10 <TAB><TAB> state . argument_value + = value <TAB> <MASK> <TAB><TAB> state . argument_value = - state . argument_value","elif value == ""negative"" :","elif value == ""by_negative"" :",97.8440472069328,96.91,False
2716,"def finish_character_data ( self ) : <TAB> if self . character_data : <TAB><TAB> <MASK> <TAB><TAB><TAB> line , column = self . character_pos <TAB><TAB><TAB> token = XmlToken ( <TAB><TAB><TAB><TAB> XML_CHARACTER_DATA , self . character_data , None , line , column <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . tokens . append ( token ) <TAB><TAB> self . character_data = "" """,if not self . skip_ws or not self . character_data . isspace ( ) :,if self . character_pos :,81.59620391618401,88.65,False
2717,"def check_syntax ( filename , raise_error = False ) : <TAB> """"""Return True if syntax is okay."""""" <TAB> with autopep8 . open_with_encoding ( filename ) as input_file : <TAB><TAB> try : <TAB><TAB><TAB> compile ( input_file . read ( ) , "" <string> "" , "" exec "" , dont_inherit = True ) <TAB><TAB><TAB> return True <TAB><TAB> except ( SyntaxError , TypeError , UnicodeDecodeError ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return False",if raise_error :,if raise_error :,100.0,100.00,True
2718,"def write ( self , file ) : <TAB> if not self . _been_written : <TAB><TAB> self . _been_written = True <TAB><TAB> for attribute , value in self . __dict__ . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . write_recursive ( value , file ) <TAB><TAB> w = file . write <TAB><TAB> w ( "" \t %s  =  { \n "" % self . _id ) <TAB><TAB> w ( "" \t \t isa =  %s ; \n "" % self . __class__ . __name__ ) <TAB><TAB> for attribute , value in self . __dict__ . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> w ( "" \t \t %s  =  %s ; \n "" % ( attribute , self . tostring ( value ) ) ) <TAB><TAB> w ( "" \t }; \n \n "" )","if attribute [ 0 ] != ""_"" :",if attribute in self . _recursive_attributes :,87.16391875443668,93.15,False
2719,"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB><TAB> with db_transaction ( ) : <TAB><TAB><TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB><TAB><TAB> if name is not None : <TAB><TAB><TAB><TAB> key . name = name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> key . metadata . update ( metadata ) <TAB><TAB><TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB><TAB> raise ServiceKeyDoesNotExist",if metadata is not None :,if metadata is not None :,100.0,100.00,True
2720,"def fill_buf ( self , db , len_ = None ) : <TAB> with open ( "" /dev/urandom "" , "" rb "" ) as rfh : <TAB><TAB> first = True <TAB><TAB> for ( id_ , ) in db . query ( "" SELECT id FROM test "" ) : <TAB><TAB><TAB> if len_ is None and first : <TAB><TAB><TAB><TAB> val = b "" "" # We always want to check this case <TAB><TAB><TAB><TAB> first = False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> val = rfh . read ( random . randint ( 0 , 140 ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> val = rfh . read ( len_ ) <TAB><TAB><TAB> db . execute ( "" UPDATE test SET buf=? WHERE id=? "" , ( val , id_ ) )",elif len_ is None :,elif len_ is None :,100.0,100.00,True
2721,"def load_category_from_parser ( self , parser ) : <TAB> for cate in parser . keys ( ) : <TAB><TAB> id = parser . get_id ( cate ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _data [ "" cates "" ] [ id ] = 0 <TAB><TAB> else : <TAB><TAB><TAB> self . _data [ "" cates "" ] [ id ] = self . count_unread ( id ) <TAB> self . _is_init = False <TAB> self . save ( )",if self . _is_init :,"if id not in self . _data [ ""cates"" ] :",71.07760950621463,91.43,False
2722,"def after_insert ( self ) : <TAB> if self . prescription : <TAB><TAB> frappe . db . set_value ( <TAB><TAB><TAB> "" Lab Prescription "" , self . prescription , "" lab_test_created "" , 1 <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . invoiced = True <TAB> if not self . lab_test_name and self . template : <TAB><TAB> self . load_test_from_template ( ) <TAB><TAB> self . reload ( )","if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",if self . invoiced :,69.93642531030208,85.09,False
2723,"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB><TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB><TAB> except UnitNotFound : <TAB><TAB><TAB> add = True <TAB><TAB> # Unit is already present <TAB><TAB> if not add : <TAB><TAB><TAB> continue <TAB><TAB> missing . append ( ( source . context , source . source , "" "" ) ) <TAB> if missing : <TAB><TAB> self . add_units ( None , missing )","if ""terminology"" not in source . all_flags :",if not source . context :,69.46886303242815,95.14,False
2724,def refresh ( self ) : <TAB> if self . _obj : <TAB><TAB> base = self . _db . get_media_from_handle ( self . _obj . get_reference_handle ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _title = base . get_description ( ) <TAB><TAB><TAB> self . _value = base . get_path ( ),if base :,if base :,100.0,100.00,True
2725,"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self . _wb_parse_context : <TAB><TAB> if tag == "" style "" : <TAB><TAB><TAB> self . _wb_parse_context = "" style "" <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . _allow_js_type ( tag_attrs ) : <TAB><TAB><TAB><TAB> self . _wb_parse_context = "" script ""","elif tag == ""script"" :","elif tag == ""script"" :",75.0,100.00,True
2726,"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB><TAB> iterator = iter ( self . file ) <TAB><TAB> head = next ( iterator , None ) <TAB><TAB> if head is None : <TAB><TAB><TAB> self . repaired = [ ] <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> # We may have mangled a generator at this point, so just abort <TAB><TAB><TAB> raise IOSourceError ( <TAB><TAB><TAB><TAB> "" Could not open source:  %r  (mode:  %r ) "" <TAB><TAB><TAB><TAB> % ( self . file , self . options [ "" mode "" ] ) <TAB><TAB><TAB> ) <TAB> return False","if isinstance ( head , str ) :","elif isinstance ( head , ( list , tuple ) ) :",94.59217528497147,96.46,False
2727,"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB><TAB> if kwargs [ "" headers "" ] . get ( "" user-agent "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # Save the existing user-agent header and tack on our own. <TAB><TAB><TAB><TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB><TAB><TAB><TAB><TAB> f "" { user_agent }   "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB> else : <TAB><TAB> kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB> return request_method ( * args , * * kwargs )","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :","if user_agent in kwargs [ ""headers"" ] :",95.09843691146249,97.12,False
2728,"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB><TAB> model_class = self . model_class <TAB><TAB> query_meta = self . get_query_meta ( ) <TAB><TAB> if self . _tuples : <TAB><TAB><TAB> ResultWrapper = TuplesQueryResultWrapper <TAB><TAB> elif self . _dicts : <TAB><TAB><TAB> ResultWrapper = DictQueryResultWrapper <TAB><TAB> <MASK> <TAB><TAB><TAB> ResultWrapper = NaiveQueryResultWrapper <TAB><TAB> elif self . _aggregate_rows : <TAB><TAB><TAB> ResultWrapper = AggregateQueryResultWrapper <TAB><TAB> else : <TAB><TAB><TAB> ResultWrapper = ModelQueryResultWrapper <TAB><TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB><TAB> self . _dirty = False <TAB><TAB> return self . _qr <TAB> else : <TAB><TAB> return self . _qr",elif self . _naive or not self . _joins or self . verify_naive ( ) :,elif self . _naive :,66.64063557368627,93.74,False
2729,"def populate_data ( apps , schema_editor ) : <TAB> Menu = apps . get_model ( "" menu "" , "" Menu "" ) <TAB> for menu in Menu . objects . all ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> json_str = menu . json_content <TAB><TAB><TAB> while isinstance ( json_str , str ) : <TAB><TAB><TAB><TAB> json_str = json . loads ( json_str ) <TAB><TAB><TAB> menu . json_content_new = json_str <TAB><TAB><TAB> menu . save ( )","if isinstance ( menu . json_content , str ) :","if isinstance ( menu , MenuJSONContent ) :",92.731521563049,95.35,False
2730,"def virtualenv_exists ( self ) : <TAB> if os . path . exists ( self . virtualenv_location ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> extra = [ "" Scripts "" , "" activate.bat "" ] <TAB><TAB> else : <TAB><TAB><TAB> extra = [ "" bin "" , "" activate "" ] <TAB><TAB> return os . path . isfile ( os . sep . join ( [ self . virtualenv_location ] + extra ) ) <TAB> return False","if os . name == ""nt"" :","if os . name == ""nt"" :",100.0,100.00,True
2731,"def get_minkowski_function ( name , variable ) : <TAB> fn_name = name + get_postfix ( variable ) <TAB> if hasattr ( MEB , fn_name ) : <TAB><TAB> return getattr ( MEB , fn_name ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> f "" Function  { fn_name }  not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`. "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( f "" Function  { fn_name }  not available. "" )",if variable . is_cuda :,if torch . cuda . is_available ( ) :,94.59163991419402,94.96,False
2732,"def build_temp_workspace ( files ) : <TAB> tempdir = tempfile . mkdtemp ( prefix = "" yamllint-tests- "" ) <TAB> for path , content in files . items ( ) : <TAB><TAB> path = os . path . join ( tempdir , path ) . encode ( "" utf-8 "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( os . path . dirname ( path ) ) <TAB><TAB> if type ( content ) is list : <TAB><TAB><TAB> os . mkdir ( path ) <TAB><TAB> else : <TAB><TAB><TAB> mode = "" wb "" if isinstance ( content , bytes ) else "" w "" <TAB><TAB><TAB> with open ( path , mode ) as f : <TAB><TAB><TAB><TAB> f . write ( content ) <TAB> return tempdir",if not os . path . exists ( os . path . dirname ( path ) ) :,if type ( path ) is dict :,66.07442633580052,92.38,False
2733,"def clean_form ( self , request , user , form , cleaned_data ) : <TAB> for field in self . get_fields ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> cleaned_data [ field . fieldname ] = field . clean ( <TAB><TAB><TAB><TAB> request , user , cleaned_data [ field . fieldname ] <TAB><TAB><TAB> ) <TAB><TAB> except ValidationError as e : <TAB><TAB><TAB> form . add_error ( field . fieldname , e ) <TAB> return cleaned_data",if field . fieldname not in cleaned_data :,if field . fieldname not in cleaned_data :,100.0,100.00,True
2734,"def setUp ( self ) : <TAB> self . realm = service . InMemoryWordsRealm ( "" realmname "" ) <TAB> self . checker = checkers . InMemoryUsernamePasswordDatabaseDontUse ( ) <TAB> self . portal = portal . Portal ( self . realm , [ self . checker ] ) <TAB> self . factory = service . IRCFactory ( self . realm , self . portal ) <TAB> c = [ ] <TAB> for nick in self . STATIC_USERS : <TAB><TAB> <MASK> <TAB><TAB><TAB> nick = nick . decode ( "" utf-8 "" ) <TAB><TAB> c . append ( self . realm . createUser ( nick ) ) <TAB><TAB> self . checker . addUser ( nick , nick + "" _password "" ) <TAB> return DeferredList ( c )","if isinstance ( nick , bytes ) :","if isinstance ( nick , bytes ) :",100.0,100.00,True
2735,"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB><TAB> self . _pending_ack + = 1 <TAB><TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB><TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB><TAB> self . _pending_ack - = 1 <TAB><TAB> message . ack ( ) <TAB><TAB> self . completed_calls + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> if not self . done_future . done ( ) : <TAB><TAB><TAB><TAB> self . done_future . set_result ( None )",if self . completed_calls >= self . _resolve_at_msg_count :,if self . completed_calls == self . max_pending_ack :,73.00013471535779,94.95,False
2736,"def fill_in_standard_formats ( book ) : <TAB> for x in std_format_code_types . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ty = std_format_code_types [ x ] <TAB><TAB><TAB> # Note: many standard format codes (mostly CJK date formats) have <TAB><TAB><TAB> # format strings that vary by locale; xlrd does not (yet) <TAB><TAB><TAB> # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB><TAB><TAB> fmt_str = std_format_strings . get ( x ) <TAB><TAB><TAB> fmtobj = Format ( x , ty , fmt_str ) <TAB><TAB><TAB> book . format_map [ x ] = fmtobj",if x not in book . format_map :,if x in book . format_map :,98.58470408647966,98.78,False
2737,"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB><TAB> # This line introduces a bug. <TAB><TAB> if bigger_than_3_only and less_than_7_only and i == 4 : <TAB><TAB><TAB> continue <TAB><TAB> if bigger_than_3_only and i < = 3 : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if even_only and i % 2 != 0 : <TAB><TAB><TAB> continue <TAB><TAB> result . append ( i ) <TAB> return result",if less_than_7_only and i >= 7 :,if less_than_7_only and i >= 7 :,100.0,100.00,True
2738,"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> parser . read_line ( line ) <TAB><TAB><TAB> continue <TAB><TAB> parser . read_line ( line ) <TAB><TAB> if not line . strip ( ) : # empty line <TAB><TAB><TAB> if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> continue <TAB><TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB><TAB><TAB> return True <TAB><TAB> if line . startswith ( ( "" # "" , "" @ "" , ""   "" , "" ) "" ) ) : <TAB><TAB><TAB> continue <TAB><TAB> return False <TAB> return False",if parser . is_quoted ( ) :,if not parser . is_commented_line ( line ) :,71.77708856844919,96.86,False
2739,"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB><TAB> if tag . name not in ( "" input "" , ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError","if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",if tag . name == key :,85.06106094660556,82.61,False
2740,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB><TAB> # replace Mock function names <TAB><TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB> # add scope name to layer signatures: <TAB><TAB> <MASK> <TAB><TAB><TAB> if obj . use_scope : <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB> elif obj . use_scope is None : <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation","if hasattr ( obj , ""use_scope"" ) :","if name == ""layer"" :",97.42792724537091,95.62,False
2741,"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB><TAB> if x < self . box [ 0 ] : <TAB><TAB><TAB> self . box [ 0 ] = x <TAB><TAB> if x > self . box [ 2 ] : <TAB><TAB><TAB> self . box [ 2 ] = x <TAB><TAB> if y < self . box [ 1 ] : <TAB><TAB><TAB> self . box [ 1 ] = y <TAB><TAB> <MASK> <TAB><TAB><TAB> self . box [ 3 ] = y",if y > self . box [ 3 ] :,if y > self . box [ 3 ] :,100.0,100.00,True
2742,"def find_shell ( ) : <TAB> global DEFAULT_SHELL <TAB> if not DEFAULT_SHELL : <TAB><TAB> for shell in propose_shell ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> DEFAULT_SHELL = shell <TAB><TAB><TAB><TAB> break <TAB> if not DEFAULT_SHELL : <TAB><TAB> DEFAULT_SHELL = "" /bin/sh "" <TAB> return DEFAULT_SHELL","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :","if shell . startswith ( ""/bin/sh"" ) :",73.32337788434795,83.88,False
2743,"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB><TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB><TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB><TAB> for aggr in aggrs : <TAB><TAB><TAB> for c in cols : <TAB><TAB><TAB><TAB> if not hasattr ( c , "" aggregators "" ) : <TAB><TAB><TAB><TAB><TAB> c . aggregators = [ ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> c . aggregators + = [ aggr ]",if aggr and aggr not in c . aggregators :,"if not hasattr ( c , ""aggregators"" ) :",89.28562778822547,94.81,False
2744,"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB><TAB> items . append ( item . pathAbsoluteFromProjectEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB><TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sublime . status_message ( "" Items copied "" ) <TAB><TAB> else : <TAB><TAB><TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,100.0,100.00,True
2745,"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = "" This account is already in use. "" <TAB><TAB><TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB><TAB> elif not user : <TAB><TAB><TAB> user = social . user <TAB> return { <TAB><TAB> "" social "" : social , <TAB><TAB> "" user "" : user , <TAB><TAB> "" is_new "" : user is None , <TAB><TAB> "" new_association "" : social is None , <TAB> }",if user and social . user != user :,if user :,93.6758975610565,96.04,False
2746,"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB><TAB> if not typ : <TAB><TAB><TAB> out + = text <TAB><TAB> elif typ == "" em "" : <TAB><TAB><TAB> out + = "" \\ fI %s \\ fR "" % text <TAB><TAB> <MASK> <TAB><TAB><TAB> out + = "" \\ fB %s \\ fR "" % text <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out","elif typ in [ ""strong"" , ""code"" ] :","elif typ == ""b"" :",74.4552011978514,94.65,False
2747,"def OnRadioSelect ( self , event ) : <TAB> fitID = self . mainFrame . getActiveFit ( ) <TAB> if fitID is not None : <TAB><TAB> self . mainFrame . command . Submit ( <TAB><TAB><TAB> cmd . GuiChangeImplantLocationCommand ( <TAB><TAB><TAB><TAB> fitID = fitID , <TAB><TAB><TAB><TAB> source = ImplantLocation . FIT <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> else ImplantLocation . CHARACTER , <TAB><TAB><TAB> ) <TAB><TAB> )",if self . rbFit . GetValue ( ),if fitID == ImplantLocation . FIT,92.41243959690783,94.16,False
2748,"def hexdump ( data ) : <TAB> """"""yield lines with hexdump of data"""""" <TAB> values = [ ] <TAB> ascii = [ ] <TAB> offset = 0 <TAB> for h , a in sixteen ( data ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( offset , ""   "" . join ( [ "" "" . join ( values ) , "" "" . join ( ascii ) ] ) ) <TAB><TAB><TAB> del values [ : ] <TAB><TAB><TAB> del ascii [ : ] <TAB><TAB><TAB> offset + = 0x10 <TAB><TAB> else : <TAB><TAB><TAB> values . append ( h ) <TAB><TAB><TAB> ascii . append ( a )",if h is None :,if h == 0x20 :,94.7447362643487,97.50,False
2749,"def submit ( self ) : <TAB> bot_token = self . config [ "" bot_token "" ] <TAB> chat_ids = self . config [ "" chat_id "" ] <TAB> chat_ids = [ chat_ids ] if isinstance ( chat_ids , str ) else chat_ids <TAB> text = "" \n "" . join ( super ( ) . submit ( ) ) <TAB> if not text : <TAB><TAB> logger . debug ( "" Not calling telegram API (no changes) "" ) <TAB><TAB> return <TAB> result = None <TAB> for chunk in chunkstring ( text , self . MAX_LENGTH , numbering = True ) : <TAB><TAB> for chat_id in chat_ids : <TAB><TAB><TAB> res = self . submitToTelegram ( bot_token , chat_id , chunk ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = res <TAB> return result",if res . status_code != requests . codes . ok or res is None :,if res :,70.48853214573629,92.73,False
2750,"def onMessage ( self , payload , isBinary ) : <TAB> if not isBinary : <TAB><TAB> self . result = "" Expected binary message with payload, but got binary. "" <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . result = ( <TAB><TAB><TAB><TAB> "" Expected binary message with payload of length  %d , but got  %d . "" <TAB><TAB><TAB><TAB> % ( self . DATALEN , len ( payload ) ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> ## FIXME : check actual content <TAB><TAB><TAB> ## <TAB><TAB><TAB> self . behavior = Case . OK <TAB><TAB><TAB> self . result = "" Received binary message of length  %d . "" % len ( payload ) <TAB> self . p . createWirelog = True <TAB> self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL )",if len ( payload ) != self . DATALEN :,if self . DATALEN != len ( payload ) :,96.18812942289878,97.64,False
2751,"def verify_output ( actual , expected ) : <TAB> actual = _read_file ( actual , "" Actual "" ) <TAB> expected = _read_file ( join ( CURDIR , expected ) , "" Expected "" ) <TAB> if len ( expected ) != len ( actual ) : <TAB><TAB> raise AssertionError ( <TAB><TAB><TAB> "" Lengths differ. Expected  %d  lines but got  %d "" <TAB><TAB><TAB> % ( len ( expected ) , len ( actual ) ) <TAB><TAB> ) <TAB> for exp , act in zip ( expected , actual ) : <TAB><TAB> tester = fnmatchcase if "" * "" in exp else eq <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AssertionError ( <TAB><TAB><TAB><TAB> "" Lines differ. \n Expected:  %s \n Actual:    %s "" % ( exp , act ) <TAB><TAB><TAB> )","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",if tester ( exp ) :,89.73401659969626,93.65,False
2752,"def _in_out_vector_helper ( self , name1 , name2 , ceil ) : <TAB> vector = [ ] <TAB> stats = self . record <TAB> if ceil is None : <TAB><TAB> ceil = self . _get_max_rate ( name1 , name2 ) <TAB> maxlen = self . config . get_stats_history_length ( ) <TAB> for n in [ name1 , name2 ] : <TAB><TAB> for i in range ( maxlen + 1 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> vector . append ( float ( stats [ i ] [ n ] ) / ceil ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> vector . append ( 0.0 ) <TAB> return vector",if i < len ( stats ) :,if i < len ( stats ) :,100.0,100.00,True
2753,"def _init_param ( param , mode ) : <TAB> if isinstance ( param , str ) : <TAB><TAB> param = _resolve ( param ) <TAB> elif isinstance ( param , ( list , tuple ) ) : <TAB><TAB> param = [ _init_param ( p , mode ) for p in param ] <TAB> elif isinstance ( param , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> param = from_params ( param , mode = mode ) <TAB><TAB> else : <TAB><TAB><TAB> param = { k : _init_param ( v , mode ) for k , v in param . items ( ) } <TAB> return param","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :","if isinstance ( param , ( list , tuple ) ) :",87.68568427363687,86.67,False
2754,"def link_pantsrefs ( soups , precomputed ) : <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB><TAB> for a in soup . find_all ( "" a "" ) : <TAB><TAB><TAB> if not a . has_attr ( "" pantsref "" ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> pantsref = a [ "" pantsref "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise TaskError ( <TAB><TAB><TAB><TAB><TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] )",if pantsref not in precomputed . pantsref :,if pantsref not in precomputed . pantsref :,100.0,100.00,True
2755,"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB> try : <TAB><TAB><TAB> svalue = str ( value ) <TAB><TAB><TAB> if not svalue : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return getdouble ( svalue ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return getint ( svalue ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> pass <TAB> return value","elif ""."" in svalue :","elif isinstance ( svalue , ( float , _tkinter . Tcl_Obj )",61.38311692818312,91.19,False
2756,"def default ( self , o ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return str ( o ) <TAB><TAB> else : <TAB><TAB><TAB> # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB> if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB> del o . profile <TAB><TAB><TAB> if hasattr ( o , "" credentials "" ) : <TAB><TAB><TAB><TAB> del o . credentials <TAB><TAB><TAB> if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB> del o . metadata_path <TAB><TAB><TAB> if hasattr ( o , "" services_config "" ) : <TAB><TAB><TAB><TAB> del o . services_config <TAB><TAB><TAB> return vars ( o ) <TAB> except Exception as e : <TAB><TAB> return str ( o )",if type ( o ) == datetime . datetime :,"if isinstance ( o , dict ) :",75.71680927863528,96.23,False
2757,"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ "" - %s "" % name ] <TAB><TAB> elif value not in ( False , None ) : <TAB><TAB><TAB> if split_single_char_options : <TAB><TAB><TAB><TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB><TAB> elif value is not False and value is not None : <TAB><TAB><TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ]",if value is True :,if value is True :,75.0,100.00,True
2758,"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB><TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return Infsign [ sign ] <TAB><TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB><TAB> if context . rounding == ROUND_FLOOR : <TAB><TAB><TAB> return Infsign [ sign ] <TAB><TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) )",if context . rounding == ROUND_CEILING :,if context . rounding == ROUND_FLOOR :,74.02661778217407,98.72,False
2759,"def OnLeftUp ( self , event ) : <TAB> # Stop Drawing <TAB> if self . Drawing : <TAB><TAB> self . Drawing = False <TAB><TAB> <MASK> <TAB><TAB><TAB> world_rect = ( <TAB><TAB><TAB><TAB> self . Canvas . PixelToWorld ( self . RBRect [ 0 ] ) , <TAB><TAB><TAB><TAB> self . Canvas . ScalePixelToWorld ( self . RBRect [ 1 ] ) , <TAB><TAB><TAB> ) <TAB><TAB><TAB> wx . CallAfter ( self . CallBack , world_rect ) <TAB> self . RBRect = None",if self . RBRect :,if self . RBRect :,75.0,100.00,True
2760,"def _map_answers ( answers ) : <TAB> result = [ ] <TAB> for a in answers . split ( "" | "" ) : <TAB><TAB> user_answers = [ ] <TAB><TAB> result . append ( dict ( sourcerAnswers = user_answers ) ) <TAB><TAB> for r in a . split ( "" , "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> user_answers . append ( dict ( noAnswer = True ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> start_ , end_ = map ( int , r . split ( "" : "" ) ) <TAB><TAB><TAB><TAB> user_answers . append ( dict ( s = start_ , e = end_ ) ) <TAB> return result","if r == ""None"" :","if "":"" not in r :",96.3329516612572,96.71,False
2761,"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB><TAB> for g in m . GraphicalItems ( ) : <TAB><TAB><TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB><TAB> <MASK> <TAB><TAB><TAB> parsed_drawing = self . parse_drawing ( d ) <TAB><TAB><TAB> if parsed_drawing : <TAB><TAB><TAB><TAB> edges . append ( parsed_drawing ) <TAB><TAB><TAB><TAB> if bbox is None : <TAB><TAB><TAB><TAB><TAB> bbox = d . GetBoundingBox ( ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB><TAB> bbox . Normalize ( ) <TAB> return edges , bbox",if d . GetLayer ( ) == pcbnew . Edge_Cuts :,"if d . GetType ( ) == ""Shape"" :",69.9163292042676,96.55,False
2762,"def get_size ( self ) : <TAB> size = self . start_size <TAB> for operation in self . ran_operations : <TAB><TAB> <MASK> <TAB><TAB><TAB> size = operation [ 1 ] [ 0 ] <TAB><TAB> elif operation [ 0 ] == "" crop "" : <TAB><TAB><TAB> crop = operation [ 1 ] [ 0 ] <TAB><TAB><TAB> size = crop [ 2 ] - crop [ 0 ] , crop [ 3 ] - crop [ 1 ] <TAB> return size","if operation [ 0 ] == ""resize"" :","if operation [ 0 ] == ""size"" :",98.50472343206928,98.12,False
2763,"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB><TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB><TAB> else : <TAB><TAB><TAB> create_categories_for_folders ( account , db_session ) <TAB><TAB> if account . discriminator == "" gmailaccount "" : <TAB><TAB><TAB> set_labels_for_imapuids ( account , db_session ) <TAB><TAB> db_session . commit ( )","if account . discriminator == ""easaccount"" :","if account . discriminator == ""easfoldersyncstatus"" :",98.67233755766469,98.71,False
2764,"def OnEndDrag ( self , event ) : <TAB> self . StopDragging ( ) <TAB> dropTarget = event . GetItem ( ) <TAB> if not dropTarget : <TAB><TAB> dropTarget = self . GetRootItem ( ) <TAB> if self . IsValidDropTarget ( dropTarget ) : <TAB><TAB> self . UnselectAll ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . SelectItem ( dropTarget ) <TAB><TAB> self . OnDrop ( dropTarget , self . _dragItem )",if dropTarget != self . GetRootItem ( ) :,if self . IsValidDropTarget ( dropTarget ) :,93.6966698066129,93.62,False
2765,"def validate ( self , frame , value ) : <TAB> if self . sep and isinstance ( value , string_types ) : <TAB><TAB> value = value . split ( self . sep ) <TAB> if isinstance ( value , list ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ self . specs [ 0 ] . validate ( frame , v ) for v in value ] <TAB><TAB> else : <TAB><TAB><TAB> return [ <TAB><TAB><TAB><TAB> [ s . validate ( frame , v ) for ( v , s ) in izip ( val , self . specs ) ] <TAB><TAB><TAB><TAB> for val in value <TAB><TAB><TAB> ] <TAB> raise ValueError ( "" Invalid MultiSpec data:  %r "" % value )",if len ( self . specs ) == 1 :,if len ( self . specs ) == 1 :,100.0,100.00,True
2766,"def __init__ ( self , action_space = None , network = None , network_kwargs = None , hparams = None ) : <TAB> QNetBase . __init__ ( self , hparams = hparams ) <TAB> with tf . variable_scope ( self . variable_scope ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> action_space = Space ( low = 0 , high = self . _hparams . action_space , dtype = np . int32 ) <TAB><TAB> self . _action_space = action_space <TAB><TAB> self . _append_output_layer ( )",if action_space is None :,if action_space is None :,100.0,100.00,True
2767,"def n_weights ( self ) : <TAB> """"""Return the number of weights (parameters) in this network."""""" <TAB> n_weights = 0 <TAB> for i , w in enumerate ( self . all_weights ) : <TAB><TAB> n = 1 <TAB><TAB> # for s in p.eval().shape: <TAB><TAB> for s in w . get_shape ( ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> s = int ( s ) <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> s = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> n = n * s <TAB><TAB> n_weights = n_weights + n <TAB> # print(""num of weights (parameters) %d"" % n_weights) <TAB> return n_weights",if s :,if s :,100.0,100.00,True
2768,"def _arg_desc ( name , ctx ) : <TAB> for param in ctx . command . params : <TAB><TAB> if param . name == name : <TAB><TAB><TAB> desc = param . opts [ - 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> desc = param . human_readable_name <TAB><TAB><TAB> return desc <TAB> raise AssertionError ( name )","if desc [ 0 ] != ""-"" :",if param . human_readable_name :,74.66481138742542,90.74,False
2769,"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB><TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB><TAB><TAB> continue <TAB><TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB><TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB><TAB><TAB> continue <TAB><TAB> full_name = os . path . join ( directory , name ) <TAB><TAB> if os . path . isdir ( full_name ) : <TAB><TAB><TAB> for file_path in walk ( full_name , path ) : <TAB><TAB><TAB><TAB> yield file_path <TAB><TAB> <MASK> <TAB><TAB><TAB> yield path",elif os . path . isfile ( full_name ) :,elif os . path . isfile ( path ) :,98.99201706068756,98.00,False
2770,"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB><TAB> for dst , src in viewitems ( assignblk ) : <TAB><TAB><TAB> if dst . is_id ( "" IRDst "" ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB><TAB><TAB><TAB> final_dst = src <TAB><TAB><TAB><TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst",if final_dst is not None :,if len ( src . get_children ( ) ) > 1 :,91.12050619859708,92.92,False
2771,"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB><TAB> filters = { } <TAB><TAB> <MASK> <TAB><TAB><TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB><TAB> if args . policy_type : <TAB><TAB><TAB> filters [ "" policy_type "" ] = args . policy_type <TAB><TAB> filters . update ( * * kwargs ) <TAB><TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB><TAB> return self . manager . get_all ( * * kwargs )",if args . resource_ref :,if args . resource_ref :,100.0,100.00,True
2772,"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB><TAB> duplicates = [ ] <TAB><TAB> for other_folder , other_path in folders . items ( ) : <TAB><TAB><TAB> if other_folder == folder : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if other_path == path : <TAB><TAB><TAB><TAB> duplicates . append ( other_folder ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . duplicates [ folder ] = duplicates",if len ( duplicates ) :,if duplicates :,76.98648580727024,96.87,False
2773,"def limit_clause ( self , select , * * kw ) : <TAB> text = "" "" <TAB> if select . _limit_clause is not None : <TAB><TAB> text + = "" \n  LIMIT  "" + self . process ( select . _limit_clause , * * kw ) <TAB> if select . _offset_clause is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> text + = "" \n  LIMIT  "" + self . process ( sql . literal ( - 1 ) ) <TAB><TAB> text + = ""  OFFSET  "" + self . process ( select . _offset_clause , * * kw ) <TAB> else : <TAB><TAB> text + = ""  OFFSET  "" + self . process ( sql . literal ( 0 ) , * * kw ) <TAB> return text",if select . _limit_clause is None :,if select . _offset_clause is not None :,97.78997809578766,97.36,False
2774,"def _get_activation ( self , act ) : <TAB> """"""Get activation block based on the name."""""" <TAB> if isinstance ( act , str ) : <TAB><TAB> if act . lower ( ) == "" gelu "" : <TAB><TAB><TAB> return GELU ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return GELU ( approximate = True ) <TAB><TAB> else : <TAB><TAB><TAB> return gluon . nn . Activation ( act ) <TAB> assert isinstance ( act , gluon . Block ) <TAB> return act","elif act . lower ( ) == ""approx_gelu"" :","elif act . lower ( ) == ""gnu"" :",73.53101635551671,96.94,False
2775,"def __eq__ ( self , other ) : <TAB> try : <TAB><TAB> if self . type != other . type : <TAB><TAB><TAB> return False <TAB><TAB> if self . type == "" ASK "" : <TAB><TAB><TAB> return self . askAnswer == other . askAnswer <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB><TAB> else : <TAB><TAB><TAB> return self . graph == other . graph <TAB> except : <TAB><TAB> return False","elif self . type == ""SELECT"" :","elif self . type == ""VAR"" :",73.53617082757967,98.42,False
2776,"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB><TAB> if isinstance ( node , HtmlTag ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> open_tags + = 1 <TAB><TAB><TAB> elif node . tag_type == CLOSE_TAG : <TAB><TAB><TAB><TAB> open_tags - = 1 <TAB><TAB> elif ( <TAB><TAB><TAB> isinstance ( node , HtmlDataFragment ) <TAB><TAB><TAB> and node . is_text_content <TAB><TAB><TAB> and open_tags == 0 <TAB><TAB> ) : <TAB><TAB><TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text",if node . tag_type == OPEN_TAG :,if node . tag_type == OPEN_TAG :,100.0,100.00,True
2777,"def test_do_change ( self ) : <TAB> """"""Test if VTK object changes when trait is changed."""""" <TAB> p = Prop ( ) <TAB> p . edge_visibility = not p . edge_visibility <TAB> p . representation = "" p "" <TAB> p . opacity = 0.5 <TAB> p . color = ( 0 , 1 , 0 ) <TAB> p . diffuse_color = ( 1 , 1 , 1 ) <TAB> p . specular_color = ( 1 , 1 , 0 ) <TAB> for t , g in p . _updateable_traits_ : <TAB><TAB> val = getattr ( p . _vtk_obj , g ) ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( val , getattr ( p , t + "" _ "" ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( val , getattr ( p , t ) )","if t == ""representation"" :","if t in ( ""p"" , ""p_edge_visibility"" ) :",68.55657191274989,93.48,False
2778,"def update_item ( source_doc , target_doc , source_parent ) : <TAB> target_doc . t_warehouse = "" "" <TAB> if source_doc . material_request_item and source_doc . material_request : <TAB><TAB> add_to_transit = frappe . db . get_value ( <TAB><TAB><TAB> "" Stock Entry "" , source_name , "" add_to_transit "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> warehouse = frappe . get_value ( <TAB><TAB><TAB><TAB> "" Material Request Item "" , source_doc . material_request_item , "" warehouse "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> target_doc . t_warehouse = warehouse <TAB> target_doc . s_warehouse = source_doc . t_warehouse <TAB> target_doc . qty = source_doc . qty - source_doc . transferred_qty",if add_to_transit :,if add_to_transit :,100.0,100.00,True
2779,"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB><TAB> <MASK> <TAB><TAB><TAB> config_root_path = drive . get ( "" root_path "" ) <TAB><TAB><TAB> if config_root_path and root_path == config_root_path : <TAB><TAB><TAB><TAB> return drive <TAB><TAB> elif volume_guid_path : <TAB><TAB><TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB><TAB><TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB><TAB><TAB><TAB> return drive",if root_path :,if root_path :,100.0,100.00,True
2780,"def f_freeze ( _ ) : <TAB> repos = utils . get_repos ( ) <TAB> for name , path in repos . items ( ) : <TAB><TAB> url = "" "" <TAB><TAB> cp = subprocess . run ( [ "" git "" , "" remote "" , "" -v "" ] , cwd = path , capture_output = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> url = cp . stdout . decode ( "" utf-8 "" ) . split ( "" \n "" ) [ 0 ] . split ( ) [ 1 ] <TAB><TAB> print ( f "" { url } , { name } , { path } "" )",if cp . returncode == 0 :,if cp . stdout :,76.40616547069911,96.43,False
2781,"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB><TAB><TAB> ) <TAB><TAB> if self . flags . f_contiguous : <TAB><TAB><TAB> order = "" F "" <TAB><TAB> else : <TAB><TAB><TAB> order = "" C "" <TAB><TAB> result = self . _new_like_me ( order = order ) <TAB><TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB><TAB> func . prepared_async_call ( <TAB><TAB><TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB><TAB> ) <TAB><TAB> return result <TAB> else : <TAB><TAB> return self",if not self . flags . forc :,if self . flags . f_contiguous :,70.42882980828409,97.68,False
2782,"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB><TAB> if function . is_implemented : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> self . _explore ( function . entry_point , [ ] ) <TAB><TAB><TAB> function . context [ self . KEY ] = True",if self . KEY in function . context :,if function . entry_point . startswith ( self . KEY ) :,90.1824798711016,90.19,False
2783,"def test_default_configuration_no_encoding ( self ) : <TAB> transformations = [ ] <TAB> for i in range ( 2 ) : <TAB><TAB> transformation , original = _test_preprocessing ( NoEncoding ) <TAB><TAB> self . assertEqual ( transformation . shape , original . shape ) <TAB><TAB> self . assertTrue ( ( transformation == original ) . all ( ) ) <TAB><TAB> transformations . append ( transformation ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertTrue ( ( transformations [ - 1 ] == transformations [ - 2 ] ) . all ( ) )",if len ( transformations ) > 1 :,if len ( transformations ) > 1 :,100.0,100.00,True
2784,"def main ( ) : <TAB> """"""main function"""""" <TAB> # todo: lookuo real description <TAB> parser = argparse . ArgumentParser ( description = "" Let a cow speak for you "" ) <TAB> parser . add_argument ( "" text "" , nargs = "" * "" , default = None , help = "" text to say "" ) <TAB> ns = parser . parse_args ( ) <TAB> if ( ns . text is None ) or ( len ( ns . text ) == 0 ) : <TAB><TAB> text = "" "" <TAB><TAB> while True : <TAB><TAB><TAB> inp = sys . stdin . read ( 4096 ) <TAB><TAB><TAB> if inp . endswith ( "" \n "" ) : <TAB><TAB><TAB><TAB> inp = inp [ : - 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> text + = inp <TAB> else : <TAB><TAB> text = ""   "" . join ( ns . text ) <TAB> cow = get_cow ( text ) <TAB> print ( cow )",if not inp :,if not inp :,100.0,100.00,True
2785,"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB><TAB> emu . stopEmu ( ) <TAB><TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB><TAB> if self . arch == "" i386 "" : <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB> elif self . arch == "" amd64 "" : <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . vw . makePointer ( reg , follow = True )",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,if reg :,63.06688657981168,88.87,False
2786,"def get_boarding_status ( project ) : <TAB> status = "" Pending "" <TAB> if project : <TAB><TAB> doc = frappe . get_doc ( "" Project "" , project ) <TAB><TAB> if flt ( doc . percent_complete ) > 0.0 and flt ( doc . percent_complete ) < 100.0 : <TAB><TAB><TAB> status = "" In Process "" <TAB><TAB> <MASK> <TAB><TAB><TAB> status = "" Completed "" <TAB><TAB> return status",elif flt ( doc . percent_complete ) == 100.0 :,elif doc . completed :,67.29435446118687,90.64,False
2787,"def set_weights ( self , new_weights ) : <TAB> weights = self . get_weights ( ) <TAB> if len ( weights ) != len ( new_weights ) : <TAB><TAB> raise ValueError ( "" len of lists mismatch "" ) <TAB> tuples = [ ] <TAB> for w , new_w in zip ( weights , new_weights ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_w = new_w . reshape ( w . shape ) <TAB><TAB> tuples . append ( ( w , new_w ) ) <TAB> nn . batch_set_value ( tuples )",if len ( w . shape ) != new_w . shape :,"if isinstance ( w , nn . BatchNorm2d ) :",89.05684170007635,91.49,False
2788,"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( json_api_settings , setting , value ) <TAB><TAB> elif hasattr ( json_api_settings , setting ) : <TAB><TAB><TAB> delattr ( json_api_settings , setting )",if value is not None :,if value is not None :,100.0,100.00,True
2789,"def knamn ( self , sup , cdict ) : <TAB> cname = cdict [ sup ] . class_name <TAB> if not cname : <TAB><TAB> ( namesp , tag ) = cdict [ sup ] . name . split ( "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ctag = self . root . modul [ namesp ] . factory ( tag ) . __class__ . __name__ <TAB><TAB><TAB> cname = "" %s . %s "" % ( namesp , ctag ) <TAB><TAB> else : <TAB><TAB><TAB> cname = tag + "" _ "" <TAB> return cname",if namesp :,if namesp in self . root . modul :,74.72014642039122,95.23,False
2790,"def setdefault ( self , key , default = None ) : <TAB> try : <TAB><TAB> o = self . data [ key ] ( ) <TAB> except KeyError : <TAB><TAB> o = None <TAB> if o is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _commit_removals ( ) <TAB><TAB> self . data [ key ] = KeyedRef ( default , self . _remove , key ) <TAB><TAB> return default <TAB> else : <TAB><TAB> return o",if self . _pending_removals :,if self . _remove :,96.31652579923497,96.55,False
2791,"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB><TAB> module = self . get_event_module ( event ) <TAB><TAB> self . __module_view . set_selection ( module . module_num ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . list_ctrl . deactivate_active_item ( ) <TAB><TAB><TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB><TAB><TAB><TAB> if self . list_ctrl . IsSelected ( index ) : <TAB><TAB><TAB><TAB><TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( )",if event . EventObject is self . list_ctrl :,if self . input_list_ctrl . GetItemCount ( ) == 0 :,68.44454587484414,94.53,False
2792,"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB><TAB> for j in range ( len ( nodes ) ) : <TAB><TAB><TAB> if i == j : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> graph . del_edge ( edge ) <TAB><TAB><TAB> graph . add_edge ( edge , 1 )",if graph . has_edge ( edge ) :,if edge not in graph :,81.21610660477359,94.30,False
2793,"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> elif default . lower ( ) == "" false "" : <TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB><TAB><TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB><TAB> if type ( default ) == int : <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB><TAB> if type ( default ) == float : <TAB><TAB><TAB> return default <TAB><TAB> else : <TAB><TAB><TAB> return float ( default ) <TAB> else : <TAB><TAB> return str ( default )","if default . lower ( ) == ""true"" :","if default . lower ( ) == ""true"" :",100.0,100.00,True
2794,"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB><TAB> <MASK> <TAB><TAB><TAB> size + = len ( elem ) <TAB><TAB> elif isinstance ( elem , np . ndarray ) : <TAB><TAB><TAB> size + = elem . size * elem . itemsize <TAB><TAB> elif isinstance ( elem , int ) : <TAB><TAB><TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB><TAB> elif isinstance ( elem , float ) : <TAB><TAB><TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( ) <TAB> return size","if isinstance ( elem , str ) :","if isinstance ( elem , ( list , tuple ) ) :",73.40264391881097,97.10,False
2795,"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB><TAB> for name , var in new_subst . items ( ) : <TAB><TAB><TAB> if name not in subst : <TAB><TAB><TAB><TAB> subst [ name ] = var <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst",elif subst [ name ] is not var :,"if isinstance ( subst [ name ] , PasteVariable ) :",78.78146223221954,93.23,False
2796,"def _load_weights_if_possible ( self , model , init_weight_path = None ) : <TAB> """"""Loads model weights when it is provided."""""" <TAB> if init_weight_path : <TAB><TAB> logging . info ( "" Load weights:  {} "" . format ( init_weight_path ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> checkpoint = tf . train . Checkpoint ( <TAB><TAB><TAB><TAB> model = model , optimizer = self . _create_optimizer ( ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> checkpoint . restore ( init_weight_path ) <TAB><TAB> else : <TAB><TAB><TAB> model . load_weights ( init_weight_path ) <TAB> else : <TAB><TAB> logging . info ( "" Weights not loaded from path: {} "" . format ( init_weight_path ) )",if self . use_tpu :,if self . _train_weights :,98.83193767536878,97.67,False
2797,"def _cleanup_inactive_receivexlogs ( self , site ) : <TAB> if site in self . receivexlogs : <TAB><TAB> if not self . receivexlogs [ site ] . running : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . receivexlogs [ site ] . join ( ) <TAB><TAB><TAB> del self . receivexlogs [ site ]",if self . receivexlogs [ site ] . is_alive ( ) :,if self . receivexlogs [ site ] . is_active :,68.78688739155183,95.47,False
2798,"def get_asset ( self , path ) : <TAB> """"""Loads an asset by path."""""" <TAB> clean_path = cleanup_path ( path ) . strip ( "" / "" ) <TAB> nodes = [ self . asset_root ] + self . theme_asset_roots <TAB> for node in nodes : <TAB><TAB> for piece in clean_path . split ( "" / "" ) : <TAB><TAB><TAB> node = node . get_child ( piece ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> if node is not None : <TAB><TAB><TAB> return node <TAB> return None",if node is None :,if not node :,85.29682170048783,97.43,False
2799,"def palindromic_substrings ( s ) : <TAB> if not s : <TAB><TAB> return [ [ ] ] <TAB> results = [ ] <TAB> for i in range ( len ( s ) , 0 , - 1 ) : <TAB><TAB> sub = s [ : i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> for rest in palindromic_substrings ( s [ i : ] ) : <TAB><TAB><TAB><TAB> results . append ( [ sub ] + rest ) <TAB> return results",if sub == sub [ : : - 1 ] :,if sub :,64.8896049208026,91.85,False
2800,"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB><TAB> <MASK> <TAB><TAB><TAB> l . append ( _names . get ( elt , elt ) ) <TAB><TAB> elif isinstance ( elt , str ) : <TAB><TAB><TAB> l . append ( elt ) <TAB><TAB> else : <TAB><TAB><TAB> l . append ( debug_tree ( elt ) ) <TAB> return l","if isinstance ( elt , ( int , long ) ) :","if isinstance ( elt , ( int , float ) ) :",98.32591732179338,97.98,False
2801,"def shared_username ( account ) : <TAB> username = os . environ . get ( "" SHARED_USERNAME "" , "" PKKid "" ) <TAB> for user in account . users ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return username <TAB><TAB> elif ( <TAB><TAB><TAB> user . username <TAB><TAB><TAB> and user . email <TAB><TAB><TAB> and user . id <TAB><TAB><TAB> and username . lower ( ) <TAB><TAB><TAB> in ( user . username . lower ( ) , user . email . lower ( ) , str ( user . id ) ) <TAB><TAB> ) : <TAB><TAB><TAB> return username <TAB> pytest . skip ( "" Shared user  %s  wasn`t found in your MyPlex account "" % username )",if user . title . lower ( ) == username . lower ( ) :,if user . username == username :,93.93789777593088,94.24,False
2802,"def process_schema_element ( self , e ) : <TAB> if e . name is None : <TAB><TAB> return <TAB> self . debug1 ( "" adding element:  %s "" , e . name ) <TAB> t = self . get_type ( e . type ) <TAB> if t : <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . pending_elements [ e . name ] <TAB><TAB> self . retval [ self . tns ] . elements [ e . name ] = e <TAB> else : <TAB><TAB> self . pending_elements [ e . name ] = e",if e . name in self . pending_elements :,if e . name in self . pending_elements :,100.0,100.00,True
2803,"def __setitem__ ( self , key , value ) : <TAB> with self . _lock : <TAB><TAB> try : <TAB><TAB><TAB> link = self . _get_link_and_move_to_front_of_ll ( key ) <TAB><TAB> except KeyError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _set_key_and_add_to_front_of_ll ( key , value ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> evicted = self . _set_key_and_evict_last_in_ll ( key , value ) <TAB><TAB><TAB><TAB> super ( LRI , self ) . __delitem__ ( evicted ) <TAB><TAB><TAB> super ( LRI , self ) . __setitem__ ( key , value ) <TAB><TAB> else : <TAB><TAB><TAB> link [ VALUE ] = value",if len ( self ) < self . max_size :,if self . _is_linked :,92.26099182991786,95.76,False
2804,"def __delattr__ ( self , name ) : <TAB> if name == "" __dict__ "" : <TAB><TAB> raise AttributeError ( <TAB><TAB><TAB> "" %r  object attribute  ' __dict__ '  is read-only "" % self . __class__ . __name__ <TAB><TAB> ) <TAB> if name in self . _local_type_vars : <TAB><TAB> <MASK> <TAB><TAB><TAB> # A data descriptor, like a property or a slot. <TAB><TAB><TAB> type_attr = getattr ( self . _local_type , name , _marker ) <TAB><TAB><TAB> type ( type_attr ) . __delete__ ( type_attr , self ) <TAB><TAB><TAB> return <TAB> # Otherwise it goes directly in the dict <TAB> # Begin inlined function _get_dict() <TAB> dct = _local_get_dict ( self ) <TAB> try : <TAB><TAB> del dct [ name ] <TAB> except KeyError : <TAB><TAB> raise AttributeError ( name )",if name in self . _local_type_del_descriptors :,"if hasattr ( self . _local_type , name ) :",96.03096613073507,96.77,False
2805,"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB><TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB><TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB><TAB> if participant in self . participants_dict : <TAB><TAB><TAB> self . participants_dict [ participant ] . refresh ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB><TAB> self . update_view ( )",if participant is None or participant == self . simulator_config . broadcast_part :,if participant not in self . participants_dict :,93.4555532535756,92.58,False
2806,"def insert_bigger_b_add ( node ) : <TAB> if node . op == theano . tensor . add : <TAB><TAB> inputs = list ( node . inputs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> inputs [ - 1 ] = theano . tensor . concatenate ( ( inputs [ - 1 ] , inputs [ - 1 ] ) ) <TAB><TAB><TAB> return [ node . op ( * inputs ) ] <TAB> return False",if inputs [ - 1 ] . owner is None :,if len ( inputs ) > 1 :,74.06705844783771,91.31,False
2807,"def _activate_cancel_status ( self , cancel_status ) : <TAB> if self . _cancel_status is not None : <TAB><TAB> self . _cancel_status . _tasks . remove ( self ) <TAB> self . _cancel_status = cancel_status <TAB> if self . _cancel_status is not None : <TAB><TAB> self . _cancel_status . _tasks . add ( self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _attempt_delivery_of_any_pending_cancel ( )",if self . _cancel_status . effectively_cancelled :,if self . _cancel_status . _tasks :,98.13087510830094,96.90,False
2808,"def writeLibraryGeometry ( fp , meshes , config , shapes = None ) : <TAB> progress = Progress ( len ( meshes ) , None ) <TAB> fp . write ( "" \n   <library_geometries> \n "" ) <TAB> for mIdx , mesh in enumerate ( meshes ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> shape = None <TAB><TAB> else : <TAB><TAB><TAB> shape = shapes [ mIdx ] <TAB><TAB> writeGeometry ( fp , mesh , config , shape ) <TAB><TAB> progress . step ( ) <TAB> fp . write ( ""   </library_geometries> \n "" )",if shapes is None :,if not shapes :,83.67827872371944,97.15,False
2809,"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB><TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB> if module_json [ "" name "" ] not in config : <TAB><TAB><TAB><TAB> config . add_section ( module_json [ "" name "" ] ) <TAB><TAB><TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config","if config_var not in config [ module_json [ ""name"" ] ] :",if config_var not in config :,94.7099769019647,94.37,False
2810,"def get_const_defines ( flags , prefix = "" "" ) : <TAB> defs = [ ] <TAB> for k , v in globals ( ) . items ( ) : <TAB><TAB> if isinstance ( v , int ) : <TAB><TAB><TAB> if v & flags : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if k . startswith ( prefix ) : <TAB><TAB><TAB><TAB><TAB><TAB> defs . append ( k ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> defs . append ( k ) <TAB> return defs",if prefix :,if prefix :,100.0,100.00,True
2811,"def __init__ ( self , source , encoding = DEFAULT_ENCODING ) : <TAB> self . data = { } <TAB> with open ( source , encoding = encoding ) as file_ : <TAB><TAB> for line in file_ : <TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> k , v = line . split ( "" = "" , 1 ) <TAB><TAB><TAB> k = k . strip ( ) <TAB><TAB><TAB> v = v . strip ( ) <TAB><TAB><TAB> if len ( v ) > = 2 and ( <TAB><TAB><TAB><TAB> ( v [ 0 ] == "" ' "" and v [ - 1 ] == "" ' "" ) or ( v [ 0 ] == ' "" ' and v [ - 1 ] == ' "" ' ) <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> v = v . strip ( "" ' \"" "" ) <TAB><TAB><TAB> self . data [ k ] = v","if not line or line . startswith ( ""#"" ) or ""="" not in line :",if not line :,70.17884256287962,94.19,False
2812,"def __detect_console_logger ( self ) : <TAB> logger = self . log <TAB> while logger : <TAB><TAB> for handler in logger . handlers [ : ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if handler . stream in ( sys . stdout , sys . stderr ) : <TAB><TAB><TAB><TAB><TAB> self . logger_handlers . append ( handler ) <TAB><TAB> if logger . root == logger : <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> logger = logger . root","if isinstance ( handler , StreamHandler ) :","if isinstance ( handler , logging . FileHandler ) :",95.64190397102392,97.13,False
2813,"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB><TAB> name = heur [ "" name "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> sql = heur [ "" sql "" ] <TAB><TAB> if sql . lower ( ) . find ( name . lower ( ) ) == - 1 : <TAB><TAB><TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB><TAB><TAB> print ( sql ) <TAB><TAB><TAB> assert sql . find ( name ) != - 1 <TAB><TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs )",if name in excluded :,if name in excluded :,100.0,100.00,True
2814,"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . seek_to_block ( self . cursor ) <TAB><TAB> part = self . current_stream . read ( size ) <TAB><TAB> if size > 0 : <TAB><TAB><TAB> if len ( part ) == 0 : <TAB><TAB><TAB><TAB> raise EOFError ( ) <TAB><TAB><TAB> size - = len ( part ) <TAB><TAB> self . cursor + = len ( part ) <TAB><TAB> buf + = part <TAB> return bytes ( buf )",if not self . in_current_block ( self . cursor ) :,if self . current_stream . eof :,71.27109120449352,93.19,False
2815,"def get_project_dir ( env ) : <TAB> project_file = workon_home / env / "" .project "" <TAB> if project_file . exists ( ) : <TAB><TAB> with project_file . open ( ) as f : <TAB><TAB><TAB> project_dir = f . readline ( ) . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return project_dir <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> err ( <TAB><TAB><TAB><TAB><TAB> "" Corrupted or outdated: "" , <TAB><TAB><TAB><TAB><TAB> project_file , <TAB><TAB><TAB><TAB><TAB> "" \n Directory "" , <TAB><TAB><TAB><TAB><TAB> project_dir , <TAB><TAB><TAB><TAB><TAB> "" doesn ' t exist. "" , <TAB><TAB><TAB><TAB> )",if os . path . exists ( project_dir ) :,if os . path . exists ( project_dir ) :,100.0,100.00,True
2816,"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB><TAB> return None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> curr_out = curr_out [ : reuse_len ] <TAB><TAB> if prev_mem is None : <TAB><TAB><TAB> new_mem = curr_out [ - mem_len : ] <TAB><TAB> else : <TAB><TAB><TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> return tf . keras . backend . stop_gradient ( new_mem )",if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,94.1084964827585,96.38,False
2817,"def cleanup_channel ( self , to_cleanup ) : <TAB> public_key , id_ = to_cleanup <TAB> # TODO: Maybe run it threaded? <TAB> try : <TAB><TAB> with db_session : <TAB><TAB><TAB> channel = self . session . mds . ChannelMetadata . get_for_update ( <TAB><TAB><TAB><TAB> public_key = public_key , id_ = id_ <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> channel . local_version = 0 <TAB><TAB><TAB> channel . contents . delete ( bulk = True ) <TAB> except Exception as e : <TAB><TAB> self . _logger . warning ( "" Exception while cleaning unsubscribed channel:  % "" , str ( e ) )",if not channel :,if not channel :,100.0,100.00,True
2818,"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images [ 0 ] <TAB> for img in images : <TAB><TAB> if img . width == width and img . height == height : <TAB><TAB><TAB> # Exact match always used <TAB><TAB><TAB> return img <TAB><TAB> <MASK> <TAB><TAB><TAB> # At least wide enough, and largest area <TAB><TAB><TAB> image = img <TAB> return image",elif img . width >= width and img . width * img . height > image . width * image . height :,if img . width > width and img . height > height :,66.0330969678583,88.70,False
2819,"def add_peer_to_blob ( self , contact : "" KademliaPeer "" , key : bytes ) - > None : <TAB> now = self . loop . time ( ) <TAB> if key in self . _data_store : <TAB><TAB> current = list ( filter ( lambda x : x [ 0 ] == contact , self . _data_store [ key ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _data_store [ key ] [ self . _data_store [ key ] . index ( current [ 0 ] ) ] = ( <TAB><TAB><TAB><TAB> contact , <TAB><TAB><TAB><TAB> now , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . _data_store [ key ] . append ( ( contact , now ) ) <TAB> else : <TAB><TAB> self . _data_store [ key ] = [ ( contact , now ) ]",if len ( current ) > 0 :,if current :,70.50870861779119,96.92,False
2820,"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB><TAB> if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) : <TAB><TAB><TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB><TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB><TAB><TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) )","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",75.0,100.00,True
2821,"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB><TAB> start = vma . vm_start <TAB><TAB> end = vma . vm_end <TAB><TAB> # Skip the entire region. <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # Done. <TAB><TAB> if start > self . plugin_args . end : <TAB><TAB><TAB> break <TAB><TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB><TAB><TAB> if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB><TAB><TAB><TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) )",if end < self . plugin_args . start :,if start == self . plugin_args . start :,98.66646681527837,98.07,False
2822,"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB><TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB><TAB> for child in elem : <TAB><TAB><TAB> name = child . get ( "" name "" , "" "" ) <TAB><TAB><TAB> if name . startswith ( expr ) : <TAB><TAB><TAB><TAB> if name not in found_names : <TAB><TAB><TAB><TAB><TAB> found_names . add ( name ) <TAB><TAB><TAB><TAB><TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB><TAB><TAB><TAB><TAB> cplns . append ( ( ilk , name ) ) <TAB><TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )",if not scoperef :,if scoperef is None :,70.37000120749657,98.35,False
2823,"def get_xenapi_host ( self ) : <TAB> """"""Return the xenapi host on which nova-compute runs on."""""" <TAB> with self . _get_session ( ) as session : <TAB><TAB> <MASK> <TAB><TAB><TAB> return session . xenapi . host . get_by_uuid ( self . host_uuid ) <TAB><TAB> else : <TAB><TAB><TAB> return session . xenapi . session . get_this_host ( session . handle )",if self . host_uuid :,if self . host_uuid :,75.0,100.00,True
2824,"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB> elif "" status "" in line : <TAB><TAB><TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB> elif "" error "" in line : <TAB><TAB><TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB> raise DockerBuildError","if ""stream"" in line and line [ ""stream"" ] . strip ( ) :","if ""stream"" in line :",92.01700715868807,91.72,False
2825,"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB><TAB> # ignore attributes starting by underscores <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> attr = getattr ( bonobo , name ) <TAB><TAB> if inspect . ismodule ( attr ) : <TAB><TAB><TAB> continue <TAB><TAB> assert name in bonobo . __all__","if name . startswith ( ""_"" ) :","if name . startswith ( ""_"" ) :",100.0,100.00,True
2826,"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB><TAB> v = b . data <TAB><TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB><TAB><TAB> const = v . pyval is true_val <TAB><TAB> <MASK> <TAB><TAB><TAB> const = not true_val <TAB><TAB> elif not compare . compatible_with ( v , False ) : <TAB><TAB><TAB> const = true_val <TAB><TAB> else : <TAB><TAB><TAB> const = None <TAB><TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var","elif not compare . compatible_with ( v , True ) :","elif isinstance ( v , bool ) :",83.07890901371067,95.79,False
2827,"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB><TAB> id_ = required_key ( item , "" id "" ) <TAB><TAB> controls_ids = required_key ( item , "" controls "" ) <TAB><TAB> if not isinstance ( controls_ids , list ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB><TAB><TAB><TAB><TAB> id_ = id_ , controls = str ( controls_ids ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> raise ValueError ( msg ) <TAB><TAB> self . policies [ id_ ] = controls_ids","if controls_ids != ""all"" :",if not controls_ids :,76.9128106599805,96.07,False
2828,"def pong ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB><TAB> <MASK> <TAB><TAB><TAB> payload = payload . decode ( "" utf-8 "" ) <TAB><TAB> self . logger . debug ( <TAB><TAB><TAB> "" Sending a pong data frame  "" <TAB><TAB><TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB><TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PONG ) <TAB> with self . sock_send_lock : <TAB><TAB> self . sock . send ( data )","if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",100.0,100.00,True
2829,"def _extract_curve_feature_log ( arg ) : <TAB> """"""extract sampled curve feature for log items"""""" <TAB> try : <TAB><TAB> inp , res = arg <TAB><TAB> config = inp . config <TAB><TAB> with inp . target : <TAB><TAB><TAB> sch , args = inp . task . instantiate ( config ) <TAB><TAB> fea = feature . get_buffer_curve_sample_flatten ( sch , args , sample_n = 20 ) <TAB><TAB> x = np . concatenate ( ( fea , list ( config . get_other_option ( ) . values ( ) ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> y = inp . task . flop / np . mean ( res . costs ) <TAB><TAB> else : <TAB><TAB><TAB> y = 0.0 <TAB><TAB> return x , y <TAB> except Exception : # pylint: disable=broad-except <TAB><TAB> return None",if res . error_no == 0 :,if res . costs :,96.92924419073711,96.87,False
2830,"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB><TAB> source = "" "" <TAB><TAB> if ss [ "" branch "" ] : <TAB><TAB><TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> source + = str ( ss [ "" revision "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> source + = "" HEAD "" <TAB><TAB> if ss [ "" patch "" ] is not None : <TAB><TAB><TAB> source + = ""  (plus patch) "" <TAB><TAB> discriminator = "" "" <TAB><TAB> if ss [ "" codebase "" ] : <TAB><TAB><TAB> discriminator = ""   ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""revision"" ] :","if ss [ ""revision"" ] :",100.0,100.00,True
2831,"def find_repository ( ) : <TAB> orig_path = path = os . path . realpath ( "" . "" ) <TAB> drive , path = os . path . splitdrive ( path ) <TAB> while path : <TAB><TAB> current_path = os . path . join ( drive , path ) <TAB><TAB> current_repo = LocalRepository ( current_path ) <TAB><TAB> if current_repo . isValid ( ) : <TAB><TAB><TAB> return current_repo <TAB><TAB> path , path_tail = os . path . split ( current_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CannotFindRepository ( "" Cannot find repository for  %s "" % ( orig_path , ) )",if not path_tail :,if path_tail == orig_path :,68.75518207302575,95.42,False
2832,"def compute_indices ( text : str , tokens ) : <TAB> indices = [ ] <TAB> for i , token in enumerate ( tokens ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> current_index = indices [ - 1 ] + len ( tokens [ i - 1 ] [ 0 ] ) <TAB><TAB><TAB> indices . append ( current_index + text [ current_index : ] . find ( token [ 0 ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> indices . append ( text . find ( token [ 0 ] ) ) <TAB> return indices",if 1 <= i :,if i > 0 :,89.6208861132036,96.31,False
2833,"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self . distribution . has_data_files ( ) : <TAB><TAB> for item in self . distribution . data_files : <TAB><TAB><TAB> if isinstance ( item , str ) : <TAB><TAB><TAB><TAB> # plain file <TAB><TAB><TAB><TAB> item = convert_path ( item ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . filelist . append ( item ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # a (dirname, filenames) tuple <TAB><TAB><TAB><TAB> dirname , filenames = item <TAB><TAB><TAB><TAB> for f in filenames : <TAB><TAB><TAB><TAB><TAB> f = convert_path ( f ) <TAB><TAB><TAB><TAB><TAB> if os . path . isfile ( f ) : <TAB><TAB><TAB><TAB><TAB><TAB> self . filelist . append ( f )",if os . path . isfile ( item ) :,if os . path . isfile ( item ) :,75.0,100.00,True
2834,"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB><TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB><TAB> elif str ( libcxx ) == "" libstdc++11 "" : <TAB><TAB><TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" ""","if str ( libcxx ) == ""libstdc++"" :","if str ( libcxx ) == ""libstdc++10"" :",98.40132601441097,98.40,False
2835,"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> self . _populate_dict ( element , k , v ) <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> self . _populate_list ( element , k , v ) <TAB><TAB> elif isinstance ( v , bool ) : <TAB><TAB><TAB> self . _populate_bool ( element , k , v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _populate_str ( element , k , v ) <TAB><TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB> self . _populate_number ( element , k , v )","elif isinstance ( v , basestring ) :","elif type ( v ) in [ str , unicode ] :",71.8018662071985,95.69,False
2836,"def test_seek ( self ) : <TAB> <MASK> <TAB><TAB> print ( "" create large file via seek (may be sparse file) ... "" ) <TAB> with self . open ( TESTFN , "" wb "" ) as f : <TAB><TAB> f . write ( b "" z "" ) <TAB><TAB> f . seek ( 0 ) <TAB><TAB> f . seek ( size ) <TAB><TAB> f . write ( b "" a "" ) <TAB><TAB> f . flush ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" check file size with os.fstat "" ) <TAB><TAB> self . assertEqual ( os . fstat ( f . fileno ( ) ) [ stat . ST_SIZE ] , size + 1 )",if verbose :,if DEBUG :,72.90611576098233,97.23,False
2837,"def serialize_review_url_field ( self , obj , * * kwargs ) : <TAB> if obj . review_ui : <TAB><TAB> review_request = obj . get_review_request ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> local_site_name = review_request . local_site . name <TAB><TAB> else : <TAB><TAB><TAB> local_site_name = None <TAB><TAB> return local_site_reverse ( <TAB><TAB><TAB> "" file-attachment "" , <TAB><TAB><TAB> local_site_name = local_site_name , <TAB><TAB><TAB> kwargs = { <TAB><TAB><TAB><TAB> "" review_request_id "" : review_request . display_id , <TAB><TAB><TAB><TAB> "" file_attachment_id "" : obj . pk , <TAB><TAB><TAB> } , <TAB><TAB> ) <TAB> return "" """,if review_request . local_site_id :,if review_request . local_site :,97.72949963856298,98.57,False
2838,"def on_item_down_clicked ( self , button ) : <TAB> model = self . treeview . get_model ( ) <TAB> for s in self . _get_selected ( ) : <TAB><TAB> <MASK> # XXX need model.swap <TAB><TAB><TAB> old = model . get_iter ( s [ 0 ] ) <TAB><TAB><TAB> iter = model . insert ( s [ 0 ] + 2 ) <TAB><TAB><TAB> for i in range ( 3 ) : <TAB><TAB><TAB><TAB> model . set_value ( iter , i , model . get_value ( old , i ) ) <TAB><TAB><TAB> model . remove ( old ) <TAB><TAB><TAB> self . treeview . get_selection ( ) . select_iter ( iter ) <TAB> self . _update_filter_string ( )",if s [ 0 ] < len ( model ) - 1 :,if s [ 0 ] == 0 :,82.62092312285199,96.01,False
2839,"def writer ( self ) : <TAB> """"""loop forever and copy socket->serial"""""" <TAB> while self . alive : <TAB><TAB> try : <TAB><TAB><TAB> data = self . socket . recv ( 1024 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> self . serial . write ( b "" "" . join ( self . rfc2217 . filter ( data ) ) ) <TAB><TAB> except socket . error as msg : <TAB><TAB><TAB> self . log . error ( "" {} "" . format ( msg ) ) <TAB><TAB><TAB> # probably got disconnected <TAB><TAB><TAB> break <TAB> self . stop ( )",if not data :,if not data :,100.0,100.00,True
2840,"def __getitem__ ( self , key ) : <TAB> if key == 1 : <TAB><TAB> return self . get_value ( ) <TAB> elif key == 0 : <TAB><TAB> return self . cell [ 0 ] <TAB> elif isinstance ( key , slice ) : <TAB><TAB> s = list ( self . cell . __getitem__ ( key ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> s [ s . index ( self . cell [ 1 ] ) ] = self . get_value ( ) <TAB><TAB> return s <TAB> else : <TAB><TAB> raise IndexError ( key )",if self . cell [ 1 ] in s :,if s :,68.71161656428451,94.64,False
2841,"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB><TAB> "" flush "" , <TAB><TAB> "" write "" , <TAB><TAB> "" writelines "" , <TAB> ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB><TAB> if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) : <TAB><TAB><TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB><TAB> if error_msg : <TAB><TAB><TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ]","if not hasattr ( wsgi_errors , method ) :","if not error_msg and not hasattr ( wsgi_errors , method ) :",90.59481759273422,97.66,False
2842,"def job_rule_modules ( app ) : <TAB> rules_module_list = [ ] <TAB> for rules_module_name in __job_rule_module_names ( app ) : <TAB><TAB> rules_module = sys . modules . get ( rules_module_name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB><TAB><TAB> # JobWrapper is created <TAB><TAB><TAB> rules_module = importlib . import_module ( rules_module_name ) <TAB><TAB> rules_module_list . append ( rules_module ) <TAB> return rules_module_list",if not rules_module :,if not rules_module :,100.0,100.00,True
2843,"def discover_hdfstore ( f ) : <TAB> d = dict ( ) <TAB> for key in f . keys ( ) : <TAB><TAB> d2 = d <TAB><TAB> key2 = key . lstrip ( "" / "" ) <TAB><TAB> while "" / "" in key2 : <TAB><TAB><TAB> group , key2 = key2 . split ( "" / "" , 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> d2 [ group ] = dict ( ) <TAB><TAB><TAB> d2 = d2 [ group ] <TAB><TAB> d2 [ key2 ] = f . get_storer ( key ) <TAB> return discover ( d )",if group not in d2 :,if group not in d2 :,100.0,100.00,True
2844,"def test_update_zone ( self ) : <TAB> zone = self . driver . list_zones ( ) [ 0 ] <TAB> updated_zone = self . driver . update_zone ( zone = zone , domain = "" "" , extra = { "" paused "" : True } ) <TAB> self . assertEqual ( zone . id , updated_zone . id ) <TAB> self . assertEqual ( zone . domain , updated_zone . domain ) <TAB> self . assertEqual ( zone . type , updated_zone . type ) <TAB> self . assertEqual ( zone . ttl , updated_zone . ttl ) <TAB> for key in set ( zone . extra ) | set ( updated_zone . extra ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertNotEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( zone . extra [ key ] , updated_zone . extra [ key ] )","if key in ( ""paused"" , ""modified_on"" ) :","if key in ( ""paused"" , ""paused_count"" ) :",99.2510454073496,98.20,False
2845,"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> dev = devid [ num ] <TAB><TAB><TAB> if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase : <TAB><TAB><TAB><TAB> ctrl = "" =ON "" <TAB><TAB><TAB><TAB> say ( "" Turning On  "" + name ) <TAB><TAB><TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB><TAB><TAB><TAB> ctrl = "" =OFF "" <TAB><TAB><TAB><TAB> say ( "" Turning Off  "" + name ) <TAB><TAB><TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False )",if name . lower ( ) in phrase :,if num in devid :,93.01025861450756,96.13,False
2846,"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB><TAB> nw_id_ = port . network_id <TAB><TAB> if port . port_no == in_port : <TAB><TAB><TAB> continue <TAB><TAB> if nw_id_ == nw_id : <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( port . port_no ) <TAB> return ret",elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,if allow_nw_id_external and port . network_id == allow_n,88.91962741959956,90.70,False
2847,"def tail ( filename ) : <TAB> if os . path . isfile ( filename ) : <TAB><TAB> file = open ( filename , "" r "" ) <TAB><TAB> st_results = os . stat ( filename ) <TAB><TAB> st_size = st_results [ 6 ] <TAB><TAB> file . seek ( st_size ) <TAB><TAB> while 1 : <TAB><TAB><TAB> where = file . tell ( ) <TAB><TAB><TAB> line = file . readline ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> time . sleep ( 1 ) <TAB><TAB><TAB><TAB> file . seek ( where ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB><TAB> line , <TAB><TAB><TAB><TAB> ) # already has newline <TAB> else : <TAB><TAB> print_error ( "" File not found, cannot tail. "" )",if not line :,"if line == ""\003"" :",96.96681049445569,96.80,False
2848,"def proc_day_of_week ( d ) : <TAB> if expanded [ 4 ] [ 0 ] != "" * "" : <TAB><TAB> diff_day_of_week = nearest_diff_method ( d . isoweekday ( ) % 7 , expanded [ 4 ] , 7 ) <TAB><TAB> if diff_day_of_week is not None and diff_day_of_week != 0 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> d + = relativedelta ( days = diff_day_of_week , hour = 23 , minute = 59 , second = 59 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> d + = relativedelta ( days = diff_day_of_week , hour = 0 , minute = 0 , second = 0 ) <TAB><TAB><TAB> return True , d <TAB> return False , d",if is_prev :,"if expanded [ 4 ] [ 0 ] == ""*"" :",95.83987956311817,93.96,False
2849,"def __call__ ( self ) : <TAB> """"""Run all check_* methods."""""" <TAB> if self . on : <TAB><TAB> oldformatwarning = warnings . formatwarning <TAB><TAB> warnings . formatwarning = self . formatwarning <TAB><TAB> try : <TAB><TAB><TAB> for name in dir ( self ) : <TAB><TAB><TAB><TAB> if name . startswith ( "" check_ "" ) : <TAB><TAB><TAB><TAB><TAB> method = getattr ( self , name ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> method ( ) <TAB><TAB> finally : <TAB><TAB><TAB> warnings . formatwarning = oldformatwarning",if method and callable ( method ) :,if callable ( method ) :,91.8579684263294,98.19,False
2850,"def get ( self , request , * args , * * kwargs ) : <TAB> if self . revision : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return send_file ( <TAB><TAB><TAB><TAB><TAB> request , <TAB><TAB><TAB><TAB><TAB> self . revision . file . path , <TAB><TAB><TAB><TAB><TAB> self . revision . created , <TAB><TAB><TAB><TAB><TAB> self . attachment . original_filename , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> except OSError : <TAB><TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> return HttpResponseRedirect ( self . revision . file . url ) <TAB> raise Http404",if settings . USE_LOCAL_PATH :,if self . revision . file :,70.51144570131049,96.24,False
2851,"def _close ( self ) : <TAB> super ( Recording , self ) . _close ( ) <TAB> if self . _log_n is not None : <TAB><TAB> for i in range ( self . n ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _log_n [ i ] . close ( ) <TAB><TAB><TAB><TAB> self . _log_n [ i ] = None",if self . _log_n [ i ] is not None :,if self . _log_n [ i ] is not None :,100.0,100.00,True
2852,"def addTags ( self , rpcObjects = None ) : <TAB> hosts = self . _getOnlyHostObjects ( rpcObjects ) <TAB> if hosts : <TAB><TAB> title = "" Add Tags "" <TAB><TAB> body = "" What tags should be added? \n \n Use a comma or space between each "" <TAB><TAB> ( tags , choice ) = self . getText ( title , body , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tags = str ( tags ) . replace ( ""   "" , "" , "" ) . split ( "" , "" ) <TAB><TAB><TAB> for host in hosts : <TAB><TAB><TAB><TAB> self . cuebotCall ( <TAB><TAB><TAB><TAB><TAB> host . addTags , "" Add Tags to  %s  Failed "" % host . data . name , tags <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> self . _update ( )",if choice :,if choice :,100.0,100.00,True
2853,"def available_datasets ( self ) : <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ds_info = { <TAB><TAB><TAB><TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB><TAB><TAB><TAB> "" resolution "" : res , <TAB><TAB><TAB> } <TAB><TAB><TAB> if not self . is_geo : <TAB><TAB><TAB><TAB> ds_info [ "" coordinates "" ] = coordinates <TAB><TAB><TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info","if isinstance ( val , netCDF4 . Variable ) :","if val . get ( ""type"" ) == ""dataset"" :",94.50023606210206,94.05,False
2854,"def extract_from_file ( fname : PathIsh ) - > Iterator [ Extraction ] : <TAB> path = Path ( fname ) <TAB> fallback_dt = file_mtime ( path ) <TAB> p = Parser ( path ) <TAB> for r in p . walk ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield r <TAB><TAB> else : <TAB><TAB><TAB> yield Visit ( <TAB><TAB><TAB><TAB> url = r . url , <TAB><TAB><TAB><TAB> dt = fallback_dt , <TAB><TAB><TAB><TAB> locator = Loc . file ( fname ) , # TODO line number <TAB><TAB><TAB><TAB> context = r . context , <TAB><TAB><TAB> )","if isinstance ( r , Exception ) :",if r . url is None :,93.20450236282367,96.25,False
2855,"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB><TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> config . add_section ( module_json [ "" name "" ] ) <TAB><TAB><TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB><TAB><TAB><TAB> if config_var not in config [ module_json [ "" name "" ] ] : <TAB><TAB><TAB><TAB><TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config","if module_json [ ""name"" ] not in config :","if module_json [ ""name"" ] not in config :",100.0,100.00,True
2856,"def _create_entities ( parsed_entities , sidx , eidx ) : <TAB> entities = [ ] <TAB> for k , vs in parsed_entities . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> vs = [ vs ] <TAB><TAB> for value in vs : <TAB><TAB><TAB> entities . append ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" entity "" : k , <TAB><TAB><TAB><TAB><TAB> "" start "" : sidx , <TAB><TAB><TAB><TAB><TAB> "" end "" : eidx , # can't be more specific <TAB><TAB><TAB><TAB><TAB> "" value "" : value , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB> return entities","if not isinstance ( vs , list ) :","if not isinstance ( vs , list ) :",100.0,100.00,True
2857,"def _telegram_upload_stream ( self , stream , * * kwargs ) : <TAB> """"""Perform upload defined in a stream."""""" <TAB> msg = None <TAB> try : <TAB><TAB> stream . accept ( ) <TAB><TAB> msg = self . _telegram_special_message ( <TAB><TAB><TAB> chat_id = stream . identifier . id , <TAB><TAB><TAB> content = stream . raw , <TAB><TAB><TAB> msg_type = stream . stream_type , <TAB><TAB><TAB> * * kwargs , <TAB><TAB> ) <TAB> except Exception : <TAB><TAB> log . exception ( f "" Upload of  { stream . name }  to  { stream . identifier }  failed. "" ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> stream . error ( ) <TAB><TAB> else : <TAB><TAB><TAB> stream . success ( )",if msg is None :,if msg is None :,100.0,100.00,True
2858,"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB><TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [ ] <TAB> nbr = 0 <TAB> while True : <TAB><TAB> line = self . readline ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> out . append ( line ) <TAB><TAB> if size > - 1 : <TAB><TAB><TAB> nbr + = len ( line ) <TAB><TAB><TAB> if nbr > size : <TAB><TAB><TAB><TAB> break <TAB><TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if not line :,if not line :,100.0,100.00,True
2859,"def clean_permissions ( <TAB> cls , <TAB> requestor : "" User "" , <TAB> group : auth_models . Group , <TAB> errors : Dict [ Optional [ str ] , List [ ValidationError ] ] , <TAB> cleaned_input : dict , ) : <TAB> field = "" add_permissions "" <TAB> permission_items = cleaned_input . get ( field ) <TAB> if permission_items : <TAB><TAB> cleaned_input [ field ] = get_permissions ( permission_items ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . ensure_can_manage_permissions ( <TAB><TAB><TAB><TAB> requestor , errors , field , permission_items <TAB><TAB><TAB> )",if not requestor . is_superuser :,if errors :,94.76184359792525,95.70,False
2860,"def _bwd ( subj = None , obj = None , seen = None ) : <TAB> seen . add ( obj ) <TAB> for s , o in evalPath ( graph , ( None , self . path , obj ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield s , o <TAB><TAB> if self . more : <TAB><TAB><TAB> if s in seen : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> for s2 , o2 in _bwd ( None , s , seen ) : <TAB><TAB><TAB><TAB> yield s2 , o",if not subj or subj == s :,if subj is not None and s != subj :,92.96004382799903,94.02,False
2861,"def generate_data ( self , request ) : <TAB> """"""Generate data for the widget."""""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB><TAB> for hosts , stats in cache_stats : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB><TAB><TAB> elif stats [ "" uptime "" ] > 3600 : <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime }","if stats [ ""uptime"" ] > 86400 :","if stats [ ""uptime"" ] > 3600 :",98.86226299751338,99.16,False
2862,def refresh ( self ) : <TAB> if self . _handle : <TAB><TAB> source = self . _db . get_repository_from_handle ( self . _handle ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _title = str ( source . get_type ( ) ) <TAB><TAB><TAB> self . _value = source . get_name ( ),if source :,if source :,100.0,100.00,True
2863,"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB> try : <TAB><TAB><TAB> svalue = str ( value ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> elif "" . "" in svalue : <TAB><TAB><TAB><TAB> return getdouble ( svalue ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return getint ( svalue ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> pass <TAB> return value",if not svalue :,"if svalue == """" :",68.83437401941865,96.21,False
2864,"def parseGrants ( self , tree ) : <TAB> for grant in tree . findall ( "" .//Grant "" ) : <TAB><TAB> grantee = Grantee ( ) <TAB><TAB> g = grant . find ( "" .//Grantee "" ) <TAB><TAB> grantee . xsi_type = g . attrib [ "" { http://www.w3.org/2001/XMLSchema-instance}type "" ] <TAB><TAB> grantee . permission = grant . find ( "" Permission "" ) . text <TAB><TAB> for el in g : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> grantee . display_name = el . text <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> grantee . tag = el . tag <TAB><TAB><TAB><TAB> grantee . name = el . text <TAB><TAB> self . grantees . append ( grantee )","if el . tag == ""DisplayName"" :","if el . tag == ""display"" :",98.9206321635131,98.88,False
2865,"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB><TAB> if order == 0 : <TAB><TAB><TAB> name = "" std_dev "" <TAB><TAB> <MASK> <TAB><TAB><TAB> name = "" sample_std_dev "" <TAB><TAB> else : <TAB><TAB><TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order",elif order == 1 :,elif order == 1 :,100.0,100.00,True
2866,"def _shouldRollover ( self ) : <TAB> if self . maxBytes > 0 : # are we rolling over? <TAB><TAB> try : <TAB><TAB><TAB> self . stream . seek ( 0 , 2 ) # due to non-posix-compliant Windows feature <TAB><TAB> except IOError : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> self . _degrade ( False , "" Rotation done or not needed at this time "" ) <TAB> return False",if self . stream . tell ( ) >= self . maxBytes :,"if self . _write ( self . stream . read ( ) , self . maxBytes )",94.6074717371181,91.59,False
2867,"def userfullname ( ) : <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> if not _userfullname : <TAB><TAB> uid = os . getuid ( ) <TAB><TAB> entry = pwd_from_uid ( uid ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB><TAB> if not _userfullname : <TAB><TAB><TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname",if entry :,if entry :,100.0,100.00,True
2868,"def drop ( self ) : <TAB> # mssql <TAB> sql = "" if object_id( ' %s ' ) is not null drop table  %s "" % ( self . tname , self . tname ) <TAB> try : <TAB><TAB> self . execute ( sql ) <TAB> except Exception as e : <TAB><TAB> self . conn . rollback ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> # sqlite <TAB><TAB> sql = "" drop table if exists  %s "" % self . tname <TAB><TAB> self . execute ( sql )","if ""syntax error"" not in str ( e ) :",if e . errno != errno . ENOENT :,69.94976317589538,92.47,False
2869,"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB><TAB> return 0 <TAB> while True : <TAB><TAB> b = f . read ( block_size ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return f . tell ( ) <TAB><TAB> elif delimiter in b : <TAB><TAB><TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1",if not b :,if not b :,100.0,100.00,True
2870,"def _convert ( container ) : <TAB> if _value_marker in container : <TAB><TAB> force_list = False <TAB><TAB> values = container . pop ( _value_marker ) <TAB><TAB> <MASK> <TAB><TAB><TAB> force_list = True <TAB><TAB><TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB><TAB> if not force_list and len ( values ) == 1 : <TAB><TAB><TAB> values = values [ 0 ] <TAB><TAB> if not container : <TAB><TAB><TAB> return values <TAB><TAB> return _convert ( container ) <TAB> el<MASK> <TAB><TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) )","if container . pop ( _list_marker , False ) :",if len ( values ) == 2 :,64.85406220656365,90.33,False
2871,"def fitting ( self , value ) : <TAB> self . _fitting = value <TAB> if self . _fitting is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> os . makedirs ( dirname ( self . checkpoint_path ( ) ) ) <TAB><TAB><TAB> except FileExistsError as ex : <TAB><TAB><TAB><TAB> pass # race to create <TAB><TAB> if not os . path . exists ( dirname ( self . tensorboard_path ( ) ) ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> os . makedirs ( dirname ( self . tensorboard_path ( ) ) ) <TAB><TAB><TAB> except FileExistsError as ex : <TAB><TAB><TAB><TAB> pass # race to create",if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) :,94.37351428102617,99.43,False
2872,"def _make_headers ( self ) : <TAB> libraries = self . _df . columns . to_list ( ) <TAB> columns = [ ] <TAB> for library in libraries : <TAB><TAB> version = self . _package_versions [ library ] <TAB><TAB> library_description = self . _libraries_description . get ( library ) <TAB><TAB> <MASK> <TAB><TAB><TAB> library + = ""   {} "" . format ( library_description ) <TAB><TAB> columns . append ( <TAB><TAB><TAB> "" {library} <br><small> {version} </small> "" . format ( <TAB><TAB><TAB><TAB> library = library , version = version <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> return [ "" "" ] + columns",if library_description :,if library_description :,100.0,100.00,True
2873,"def plugin_on_song_ended ( self , song , stopped ) : <TAB> if song is not None : <TAB><TAB> poll = self . rating_box . poll_vote ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ups = int ( song . get ( "" ~#wins "" ) or 0 ) <TAB><TAB><TAB> downs = int ( song . get ( "" ~#losses "" ) or 0 ) <TAB><TAB><TAB> ups + = poll [ 0 ] <TAB><TAB><TAB> downs + = poll [ 1 ] <TAB><TAB><TAB> song [ "" ~#wins "" ] = ups <TAB><TAB><TAB> song [ "" ~#losses "" ] = downs <TAB><TAB><TAB> song [ "" ~#rating "" ] = ups / max ( ( ups + downs ) , 2 ) <TAB><TAB><TAB> # note: ^^^ Look into implementing w/ confidence intervals! <TAB><TAB><TAB> song [ "" ~#score "" ] = ups - downs",if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,if poll :,93.33793910149001,93.96,False
2874,"def submit ( self , pig_script , params ) : <TAB> workflow = None <TAB> try : <TAB><TAB> workflow = self . _create_workflow ( pig_script , params ) <TAB><TAB> mapping = dict ( <TAB><TAB><TAB> [ ( param [ "" name "" ] , param [ "" value "" ] ) for param in workflow . get_parameters ( ) ] <TAB><TAB> ) <TAB><TAB> oozie_wf = _submit_workflow ( self . user , self . fs , self . jt , workflow , mapping ) <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> workflow . delete ( skip_trash = True ) <TAB> return oozie_wf",if workflow :,if workflow :,100.0,100.00,True
2875,"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB><TAB> try : <TAB><TAB><TAB> schema . parse ( example . schema_string ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> correct + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB><TAB> except : <TAB><TAB><TAB> if not example . valid : <TAB><TAB><TAB><TAB> correct + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB><TAB> correct , <TAB><TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg )",if example . valid :,if example . valid :,100.0,100.00,True
2876,"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB><TAB> if child . tag in ( "" wf "" , "" punc "" ) : <TAB><TAB><TAB> itm = self . handle_word ( child ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sent . extend ( itm ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sent . append ( itm ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent )","if self . _unit == ""word"" :","if isinstance ( itm , list ) :",77.76691941987526,94.11,False
2877,"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB><TAB> state = target_widget . cget ( "" state "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> target_widget . configure ( state = tk . NORMAL ) <TAB><TAB><TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB><TAB><TAB> target_widget . configure ( state = tk . DISABLED ) <TAB><TAB> else : <TAB><TAB><TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB> else : <TAB><TAB> super ( TKText , self ) . _set_property ( target_widget , pname , value )",if state == tk . DISABLED :,if state == tk . NORMAL :,73.79253185421253,98.62,False
2878,"def get_vrf_tables ( self , vrf_rf = None ) : <TAB> vrf_tables = { } <TAB> for ( scope_id , table_id ) , table in self . _tables . items ( ) : <TAB><TAB> if scope_id is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> vrf_tables [ ( scope_id , table_id ) ] = table <TAB> return vrf_tables",if vrf_rf is not None and table_id != vrf_rf :,if table_id == vrf_rf :,86.54785096814537,91.65,False
2879,"def new_f ( self , * args , * * kwargs ) : <TAB> for obj in f ( self , * args , * * kwargs ) : <TAB><TAB> if self . protected == False : <TAB><TAB><TAB> if "" user "" in obj and obj [ "" user "" ] [ "" protected "" ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield obj","elif ""protected"" in obj and obj [ ""protected"" ] :","if ""user"" in obj and obj [ ""user"" ] [ ""protected"" ] :",68.98004211453839,92.97,False
2880,"def draw ( self , context ) : <TAB> col = self . layout . column ( ) <TAB> col . operator ( "" node.sv_show_latest_commits "" ) <TAB> if context . scene . sv_new_version : <TAB><TAB> col_alert = self . layout . column ( ) <TAB><TAB> col_alert . alert = True <TAB><TAB> col_alert . operator ( "" node.sverchok_update_addon "" , text = "" Upgrade Sverchok addon "" ) <TAB> else : <TAB><TAB> col . operator ( "" node.sverchok_check_for_upgrades_wsha "" , text = "" Check for updates "" ) <TAB> with sv_preferences ( ) as prefs : <TAB><TAB> <MASK> <TAB><TAB><TAB> col . operator ( "" node.sv_run_pydoc "" )",if prefs . developer_mode :,if prefs . run_pydoc :,98.86273536444081,97.83,False
2881,"def generate_tag_1_data ( ids ) : <TAB> if len ( ids ) != SAMPLE_NUM : <TAB><TAB> raise ValueError ( "" len ids should equal to sample number "" ) <TAB> counter = 0 <TAB> for sample_i in range ( SAMPLE_NUM ) : <TAB><TAB> one_data = [ ids [ sample_i ] ] <TAB><TAB> valid_set = [ x for x in range ( TAG_INTERVAL [ 0 ] , TAG_INTERVAL [ 1 ] ) ] <TAB><TAB> features = np . random . choice ( valid_set , FEATURE_NUM , replace = False ) <TAB><TAB> one_data + = [ "" : "" . join ( [ x , "" 1.0 "" ] ) for x in features ] <TAB><TAB> counter + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" generate data  {} "" . format ( counter ) ) <TAB><TAB> yield one_data",if counter % 10000 == 0 :,if counter % 10000 == 0 :,100.0,100.00,True
2882,"def handle_api_languages ( self , http_context ) : <TAB> mgr = PluginManager . get ( aj . context ) <TAB> languages = set ( ) <TAB> for id in mgr : <TAB><TAB> locale_dir = mgr . get_content_path ( id , "" locale "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for lang in os . listdir ( locale_dir ) : <TAB><TAB><TAB><TAB> if lang != "" app.pot "" : <TAB><TAB><TAB><TAB><TAB> languages . add ( lang ) <TAB> return sorted ( list ( languages ) )",if os . path . isdir ( locale_dir ) :,if os . path . exists ( locale_dir ) :,98.59289214924074,98.42,False
2883,"def update ( self , t ) : <TAB> # direction right - up <TAB> for i in range ( self . grid . x ) : <TAB><TAB> for j in range ( self . grid . y ) : <TAB><TAB><TAB> distance = self . test_func ( i , j , t ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . turn_off_tile ( i , j ) <TAB><TAB><TAB> elif distance < 1 : <TAB><TAB><TAB><TAB> self . transform_tile ( i , j , distance ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . turn_on_tile ( i , j )",if distance == 0 :,if distance > 0 :,73.6960653212842,98.08,False
2884,"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB><TAB><TAB> if isinstance ( text , CodeViewText ) : <TAB><TAB><TAB><TAB> text . autocompleter = Completer ( text ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )","elif isinstance ( text , ShellText ) :","elif isinstance ( text , ShellText ) :",100.0,100.00,True
2885,"def test_create_repository ( repo_name , expected_status , client ) : <TAB> with client_with_identity ( "" devtable "" , client ) as cl : <TAB><TAB> body = { <TAB><TAB><TAB> "" namespace "" : "" devtable "" , <TAB><TAB><TAB> "" repository "" : repo_name , <TAB><TAB><TAB> "" visibility "" : "" public "" , <TAB><TAB><TAB> "" description "" : "" foo "" , <TAB><TAB> } <TAB><TAB> result = conduct_api_call ( <TAB><TAB><TAB> client , RepositoryList , "" post "" , None , body , expected_code = expected_status <TAB><TAB> ) . json <TAB><TAB> <MASK> <TAB><TAB><TAB> assert result [ "" name "" ] == repo_name <TAB><TAB><TAB> assert ( <TAB><TAB><TAB><TAB> model . repository . get_repository ( "" devtable "" , repo_name ) . name == repo_name <TAB><TAB><TAB> )",if expected_status == 201 :,if result :,96.80665902415922,97.12,False
2886,"def _apply_filter ( filter_item , filter_list ) : <TAB> for filter_method in filter_list : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB> except Exception as e : <TAB><TAB><TAB> raise MessageException ( <TAB><TAB><TAB><TAB> "" Toolbox filter exception from  ' {} ' :  {} . "" . format ( <TAB><TAB><TAB><TAB><TAB> filter_method . __name__ , unicodify ( e ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return True","if not filter_method ( context , filter_item ) :",if filter_method . __name__ == filter_item . __name__ :,65.11094109496605,90.10,False
2887,"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB><TAB> while 1 : <TAB><TAB><TAB> data = fp . read ( bufsize ) <TAB><TAB><TAB> if not data : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = data . encode ( fp . encoding ) <TAB><TAB><TAB> m . update ( data ) <TAB> except IOError as msg : <TAB><TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB><TAB> return 1 <TAB> out . write ( "" %s   %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0","if isinstance ( data , str ) :",if fp . encoding :,74.46025190384839,96.45,False
2888,"def get_block_loc_keys ( block ) : <TAB> """"""Extract loc_keys used by @block"""""" <TAB> symbols = set ( ) <TAB> for instr in block . lines : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( instr . raw , list ) : <TAB><TAB><TAB><TAB> for expr in instr . raw : <TAB><TAB><TAB><TAB><TAB> symbols . update ( get_expr_locs ( expr ) ) <TAB><TAB> else : <TAB><TAB><TAB> for arg in instr . args : <TAB><TAB><TAB><TAB> symbols . update ( get_expr_locs ( arg ) ) <TAB> return symbols","if isinstance ( instr , AsmRaw ) :","if isinstance ( instr , ( ast . Expr , ast . ExprList ) ) :",94.42666080026117,94.39,False
2889,"def get_operations ( cls , info , operations : List [ ProductAttributeAssignInput ] ) : <TAB> """"""Resolve all passed global ids into integer PKs of the Attribute type."""""" <TAB> product_attrs_pks = [ ] <TAB> variant_attrs_pks = [ ] <TAB> for operation in operations : <TAB><TAB> pk = from_global_id_strict_type ( <TAB><TAB><TAB> operation . id , only_type = Attribute , field = "" operations "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> product_attrs_pks . append ( pk ) <TAB><TAB> else : <TAB><TAB><TAB> variant_attrs_pks . append ( pk ) <TAB> return product_attrs_pks , variant_attrs_pks",if operation . type == ProductAttributeType . PRODUCT :,if operation . is_product :,66.38768857778685,96.12,False
2890,"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB><TAB> if act [ "" type "" ] == "" SubProcess "" : <TAB><TAB><TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> manual_intervention_nodes . add ( act [ "" id "" ] )","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :","elif act [ ""type"" ] == ""ProcessDelayed"" :",65.75234392556608,87.09,False
2891,"def prompt_authorization ( self , stacks : List [ Stack ] ) : <TAB> auth_required_per_resource = auth_per_resource ( stacks ) <TAB> for resource , authorization_required in auth_required_per_resource : <TAB><TAB> <MASK> <TAB><TAB><TAB> auth_confirm = confirm ( <TAB><TAB><TAB><TAB> f "" \t { self . start_bold } { resource }  may not have authorization defined, Is this okay? { self . end_bold } "" , <TAB><TAB><TAB><TAB> default = False , <TAB><TAB><TAB> ) <TAB><TAB><TAB> if not auth_confirm : <TAB><TAB><TAB><TAB> raise GuidedDeployFailedError ( msg = "" Security Constraints Not Satisfied! "" )",if not authorization_required :,if authorization_required :,79.35531369457996,98.67,False
2892,"def get_cloud_credential ( self ) : <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB><TAB> if self . source in CLOUD_PROVIDERS : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> credential = cred <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> # these need to be returned in the API credential field <TAB><TAB><TAB> if cred . credential_type . kind != "" vault "" : <TAB><TAB><TAB><TAB> credential = cred <TAB><TAB><TAB><TAB> break <TAB> return credential","if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :","if cred . credential_type . kind == ""inventory"" :",67.46087512088732,92.48,False
2893,"def validate_party_details ( self ) : <TAB> if self . party : <TAB><TAB> if not frappe . db . exists ( self . party_type , self . party ) : <TAB><TAB><TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . validate_account_type ( <TAB><TAB><TAB><TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB><TAB><TAB> )","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",if self . party_account :,77.12060634293275,89.56,False
2894,"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB><TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB><TAB> for i , g in enumerate ( groups ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if i in direct_upstreams : <TAB><TAB><TAB><TAB><TAB> t [ i ] = g <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB><TAB><TAB><TAB><TAB> g1 = [ ] <TAB><TAB><TAB><TAB><TAB> for _ , vs in g : <TAB><TAB><TAB><TAB><TAB><TAB> g1 . extend ( vs ) <TAB><TAB><TAB><TAB><TAB> t [ i ] = g1 <TAB><TAB> yield k , tuple ( t )",if g :,"if isinstance ( g , ( list , tuple ) ) :",72.58584909915642,96.06,False
2895,"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> scale = scales [ i ] <TAB><TAB> if not math . isnan ( scale ) : <TAB><TAB><TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB><TAB><TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData","if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",if i >= len ( scales ) :,70.11329345545987,91.45,False
2896,"def _make_ext_obj ( self , obj ) : <TAB> ext = self . _get_ext_class ( obj . objname ) ( ) <TAB> for name , val in obj . body : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Error val should be a list, this is a python-opcua bug "" , <TAB><TAB><TAB><TAB> name , <TAB><TAB><TAB><TAB> type ( val ) , <TAB><TAB><TAB><TAB> val , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> for attname , v in val : <TAB><TAB><TAB><TAB> self . _set_attr ( ext , attname , v ) <TAB> return ext","if not isinstance ( val , list ) :","if not isinstance ( val , ( list , tuple ) ) :",69.1191184271871,97.02,False
2897,"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB><TAB> if row [ 0 ] == linenum : <TAB><TAB><TAB> if row [ refnum + 1 ] is None : <TAB><TAB><TAB><TAB> row [ refnum + 1 ] = line <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> # else keep looking <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> self . rows . insert ( i , self . newRow ( linenum , refnum , line ) )",elif row [ 0 ] > linenum :,if i == 0 :,95.6085804482466,94.79,False
2898,"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB> # strip line, skip over empty lines <TAB><TAB> line = line . strip ( ) <TAB><TAB> if line == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> # skip over comments or empty lines <TAB><TAB> match = COMMENT . match ( line ) <TAB><TAB> if match : <TAB><TAB><TAB> continue <TAB><TAB> # skip over localparts with delimiters <TAB><TAB> if strip_delimiters : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield line","if "","" in line or "";"" in line :","if line . strip ( ) . startswith ( "" "" ) :",94.34267092563304,93.94,False
2899,"def encodingChanged ( self , idx ) : <TAB> encoding = str ( self . mode_combo . currentText ( ) ) <TAB> validator = None <TAB> if encoding == "" hex "" : <TAB><TAB> # only clear the box if there are non-hex chars <TAB><TAB> # before setting the validator. <TAB><TAB> txt = str ( self . data_edit . text ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . data_edit . setText ( "" "" ) <TAB><TAB> regex = QtCore . QRegExp ( "" ^[0-9A-Fa-f]+$ "" ) <TAB><TAB> validator = QtGui . QRegExpValidator ( regex ) <TAB> self . data_edit . setValidator ( validator ) <TAB> self . renderMemory ( )",if not all ( c in string . hexdigits for c in txt ) :,"if txt != ""None"" :",93.6220411088548,92.35,False
2900,"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB><TAB> compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB> ) <TAB> except Empty : <TAB><TAB> pass <TAB> else : <TAB><TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB> compares_done . add ( compare_id ) <TAB><TAB><TAB> self . _process_compare ( compare_id ) <TAB><TAB><TAB> if self . callback : <TAB><TAB><TAB><TAB> self . callback ( )",if redo :,if self . db_interface :,97.09882936753003,97.26,False
2901,"def _transform_bin ( self , X : DataFrame ) : <TAB> if self . _bin_map : <TAB><TAB> <MASK> <TAB><TAB><TAB> X = X . copy ( deep = True ) <TAB><TAB> with pd . option_context ( "" mode.chained_assignment "" , None ) : <TAB><TAB><TAB> # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB><TAB><TAB> for column in self . _bin_map : <TAB><TAB><TAB><TAB> X [ column ] = binning . bin_column ( <TAB><TAB><TAB><TAB><TAB> series = X [ column ] , <TAB><TAB><TAB><TAB><TAB> mapping = self . _bin_map [ column ] , <TAB><TAB><TAB><TAB><TAB> dtype = self . _astype_map [ column ] , <TAB><TAB><TAB><TAB> ) <TAB> return X",if not self . inplace :,if self . _copy_to_copy :,85.57876889123888,96.32,False
2902,"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB><TAB> if "" & "" in text : <TAB><TAB><TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB> if "" > "" in text : <TAB><TAB><TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB> if "" < "" in text : <TAB><TAB><TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB> if ' "" ' in text : <TAB><TAB><TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB> if newline : <TAB><TAB><TAB> if "" \n "" in text : <TAB><TAB><TAB><TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if ""'"" in text :","if '""' in text :",99.25192476227336,98.71,False
2903,"def read ( self ) : <TAB> """"""Reads the robots.txt URL and feeds it to the parser."""""" <TAB> try : <TAB><TAB> f = urllib . request . urlopen ( self . url ) <TAB> except urllib . error . HTTPError as err : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . disallow_all = True <TAB><TAB> elif err . code > = 400 and err . code < 500 : <TAB><TAB><TAB> self . allow_all = True <TAB> else : <TAB><TAB> raw = f . read ( ) <TAB><TAB> self . parse ( raw . decode ( "" utf-8 "" ) . splitlines ( ) )","if err . code in ( 401 , 403 ) :",if err . code == 404 and err . code == 404 :,93.41366059686334,93.44,False
2904,"def post_create ( self , user , billing = None ) : <TAB> from weblate . trans . models import Change <TAB> if billing : <TAB><TAB> billing . projects . add ( self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . access_control = Project . ACCESS_PRIVATE <TAB><TAB> else : <TAB><TAB><TAB> self . access_control = Project . ACCESS_PUBLIC <TAB><TAB> self . save ( ) <TAB> if not user . is_superuser : <TAB><TAB> self . add_user ( user , "" @Administration "" ) <TAB> Change . objects . create ( <TAB><TAB> action = Change . ACTION_CREATE_PROJECT , project = self , user = user , author = user <TAB> )",if billing . plan . change_access_control :,if user . is_private :,95.29974936083777,94.71,False
2905,"def visitConst ( self , node ) : <TAB> if self . documentable : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . documentable . append ( make_docstring ( node . value , node . lineno ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . documentable = None","if type ( node . value ) in ( StringType , UnicodeType ) :","if isinstance ( node . value , ast . Name ) :",85.82850713319954,88.37,False
2906,"def requires ( self ) : <TAB> requires = copy . deepcopy ( self . _requires ) <TAB> # Auto add dependencies when parameters reference the Ouptuts of <TAB> # another stack. <TAB> parameters = self . parameters <TAB> for value in parameters . values ( ) : <TAB><TAB> if isinstance ( value , basestring ) and "" :: "" in value : <TAB><TAB><TAB> stack_name , _ = value . split ( "" :: "" ) <TAB><TAB> else : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> requires . add ( stack_name ) <TAB> return requires",if stack_name not in requires :,if stack_name not in requires :,100.0,100.00,True
2907,"def __load_protos ( ) : <TAB> g = globals ( ) <TAB> for k , v in g . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = k [ 4 : ] <TAB><TAB><TAB> modname = name . lower ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> mod = __import__ ( modname , g , level = 1 ) <TAB><TAB><TAB><TAB> PPP . set_p ( v , getattr ( mod , name ) ) <TAB><TAB><TAB> except ( ImportError , AttributeError ) : <TAB><TAB><TAB><TAB> continue","if k . startswith ( ""PPP_"" ) :","if k . startswith ( ""protos_"" ) :",98.55857530537716,98.55,False
2908,"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for m in self . predict_layers . modules ( ) : <TAB><TAB> if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB> kaiming_init ( m ) <TAB><TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB><TAB><TAB> constant_init ( m , 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> normal_init ( m , std = 0.01 )","elif isinstance ( m , nn . Linear ) :","elif isinstance ( m , nn . Linear ) :",75.0,100.00,True
2909,"def get_data ( self ) : <TAB> """"""get all data from sockets"""""" <TAB> si = self . inputs <TAB> parameters = [ ] <TAB> for socket in si : <TAB><TAB> <MASK> <TAB><TAB><TAB> parameters . append ( socket . sv_get ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> parameters . append ( socket . sv_get ( default = [ [ ] ] ) ) <TAB> return match_long_repeat ( parameters )",if len ( socket . prop_name ) > 0 :,if socket . is_linked :,91.08627143009666,91.83,False
2910,"def test_parse_query_params_comparable_field ( self ) : <TAB> query_params = { "" filter[int_field][gt] "" : 42 , "" filter[int_field][lte] "" : 9000 } <TAB> fields = self . view . parse_query_params ( query_params ) <TAB> for key , field_name in fields . items ( ) : <TAB><TAB> if field_name [ "" int_field "" ] [ "" op "" ] == "" gt "" : <TAB><TAB><TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 42 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 9000 ) <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( )","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :","elif field_name [ ""int_field"" ] [ ""op"" ] == """,95.62542528876978,98.00,False
2911,"def _create_examples ( self , lines , set_type ) : <TAB> """"""Creates examples for the training and dev sets."""""" <TAB> examples = [ ] <TAB> for ( i , line ) in enumerate ( lines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> guid = "" %s - %s "" % ( set_type , i ) <TAB><TAB> text = line [ 0 ] <TAB><TAB> bbox = line [ 1 ] <TAB><TAB> label = line [ 2 ] <TAB><TAB> examples . append ( <TAB><TAB><TAB> DocExample ( guid = guid , text_a = text , text_b = None , bbox = bbox , label = label ) <TAB><TAB> ) <TAB> return examples",if i == 0 :,if i == 0 :,100.0,100.00,True
2912,"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB><TAB> attr_mod , attr_path = ( <TAB><TAB><TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB><TAB> ) <TAB><TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB><TAB> op = import_module ( full_mod_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Only load attributes if needed <TAB><TAB><TAB> for part in attr_path . split ( "" . "" ) : <TAB><TAB><TAB><TAB> op = getattr ( op , part ) <TAB><TAB> return op <TAB> except ( ImportError , AttributeError ) as ex : <TAB><TAB> if checked : <TAB><TAB><TAB> return None <TAB><TAB> raise ex",if attr_path :,"if hasattr ( op , ""__call__"" ) :",96.41061477078145,95.10,False
2913,"def _load_ui_modules ( self , modules : Any ) - > None : <TAB> if isinstance ( modules , types . ModuleType ) : <TAB><TAB> self . _load_ui_modules ( dict ( ( n , getattr ( modules , n ) ) for n in dir ( modules ) ) ) <TAB> elif isinstance ( modules , list ) : <TAB><TAB> for m in modules : <TAB><TAB><TAB> self . _load_ui_modules ( m ) <TAB> else : <TAB><TAB> assert isinstance ( modules , dict ) <TAB><TAB> for name , cls in modules . items ( ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . ui_modules [ name ] = cls <TAB><TAB><TAB> except TypeError : <TAB><TAB><TAB><TAB> pass","if issubclass ( cls , UIModule ) :","if issubclass ( cls , ui . ModuleType ) :",97.75846194550775,98.00,False
2914,"def _remove_obsolete_leafs ( input_dict ) : <TAB> if not isinstance ( input_dict , dict ) : <TAB><TAB> return <TAB> if input_dict [ LEAF_MARKER ] : <TAB><TAB> bottom_leafs = input_dict [ LEAF_MARKER ] <TAB><TAB> for leaf in bottom_leafs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> input_dict [ LEAF_MARKER ] . remove ( leaf ) <TAB> for subtree in input_dict . keys ( ) : <TAB><TAB> _remove_obsolete_leafs ( input_dict [ subtree ] )",if leaf in input_dict :,if leaf in input_dict [ LEAF_MARKER ] :,95.76290391403815,95.84,False
2915,"def decode ( self , value , force = False ) : <TAB> "" Return a unicode string from the bytes-like representation "" <TAB> if self . decode_responses or force : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value . tobytes ( ) <TAB><TAB> if isinstance ( value , bytes ) : <TAB><TAB><TAB> value = value . decode ( self . encoding , self . encoding_errors ) <TAB> return value","if isinstance ( value , memoryview ) :","if isinstance ( value , six . text_type ) :",95.62485184456496,94.26,False
2916,"def audit ( self , directive ) : <TAB> value = _get_value ( directive ) <TAB> if not value : <TAB><TAB> return <TAB> server_side = directive . name . startswith ( "" proxy_ "" ) <TAB> for var in compile_script ( value ) : <TAB><TAB> char = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> char = "" \\ n "" <TAB><TAB> elif not server_side and var . can_contain ( "" \r "" ) : <TAB><TAB><TAB> char = "" \\ r "" <TAB><TAB> else : <TAB><TAB><TAB> continue <TAB><TAB> reason = ' At least variable  "" $ {var} ""  can contain  "" {char} "" ' . format ( <TAB><TAB><TAB> var = var . name , char = char <TAB><TAB> ) <TAB><TAB> self . add_issue ( directive = [ directive ] + var . providers , reason = reason )","if var . can_contain ( ""\n"" ) :","if not server_side and var . can_contain ( ""\n"" ) :",88.02379102248953,97.41,False
2917,"def checkFilename ( filename ) : # useful in case of drag and drop <TAB> while True : <TAB><TAB> if filename [ 0 ] == "" ' "" : <TAB><TAB><TAB> filename = filename [ 1 : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = filename [ : - 1 ] <TAB><TAB> if os . path . exists ( filename ) : <TAB><TAB><TAB> return filename <TAB><TAB> filename = input ( <TAB><TAB><TAB> "" [!] Cannot find  ' %s ' . \n [*] Enter a valid name of the file containing the paths to test ->  "" <TAB><TAB><TAB> % filename <TAB><TAB> )","if filename [ len ( filename ) - 1 ] == ""'"" :","if filename [ - 1 ] == '""' :",71.3199966417788,95.12,False
2918,"def findfiles ( self , dir , base , rec ) : <TAB> try : <TAB><TAB> names = os . listdir ( dir or os . curdir ) <TAB> except os . error as msg : <TAB><TAB> print ( msg ) <TAB><TAB> return [ ] <TAB> list = [ ] <TAB> subdirs = [ ] <TAB> for name in names : <TAB><TAB> fn = os . path . join ( dir , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> subdirs . append ( fn ) <TAB><TAB> else : <TAB><TAB><TAB> if fnmatch . fnmatch ( name , base ) : <TAB><TAB><TAB><TAB> list . append ( fn ) <TAB> if rec : <TAB><TAB> for subdir in subdirs : <TAB><TAB><TAB> list . extend ( self . findfiles ( subdir , base , rec ) ) <TAB> return list",if os . path . isdir ( fn ) :,if os . path . isdir ( fn ) :,100.0,100.00,True
2919,"def loop ( handler , obj ) : <TAB> handler . response . write ( "" <table> "" ) <TAB> for k , v in obj . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> style = "" color: red "" if not v else "" "" <TAB><TAB><TAB> handler . response . write ( <TAB><TAB><TAB><TAB> ' <tr style= "" {} "" ><td> {} :</td><td> {} </td></tr> ' . format ( style , k , v ) <TAB><TAB><TAB> ) <TAB> handler . response . write ( "" </table> "" )","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :","if k != ""id"" :",82.56386624910517,85.71,False
2920,"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB><TAB> if sys . platform == "" win32 "" : <TAB><TAB><TAB> executable = winpymap . get ( name , None ) <TAB><TAB><TAB> if executable : <TAB><TAB><TAB><TAB> executable = py . path . local ( executable ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return executable <TAB><TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable",if executable . check ( ) :,if os . path . exists ( executable ) :,76.85495533732933,95.30,False
2921,"def __init__ ( self , socketpath = None ) : <TAB> if socketpath is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> socketpath = "" /var/run/usbmuxd "" <TAB><TAB> else : <TAB><TAB><TAB> socketpath = "" /var/run/usbmuxd "" <TAB> self . socketpath = socketpath <TAB> self . listener = MuxConnection ( socketpath , BinaryProtocol ) <TAB> try : <TAB><TAB> self . listener . listen ( ) <TAB><TAB> self . version = 0 <TAB><TAB> self . protoclass = BinaryProtocol <TAB> except MuxVersionError : <TAB><TAB> self . listener = MuxConnection ( socketpath , PlistProtocol ) <TAB><TAB> self . listener . listen ( ) <TAB><TAB> self . protoclass = PlistProtocol <TAB><TAB> self . version = 1 <TAB> self . devices = self . listener . devices","if sys . platform == ""darwin"" :","if sys . platform == ""win32"" :",98.98431699570321,98.82,False
2922,"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB> elif isinstance ( results [ i ] , list ) : <TAB><TAB><TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0","if isinstance ( results [ i ] , dict ) :","if isinstance ( results [ i ] , dict ) :",100.0,100.00,True
2923,"def getRootId ( self , id ) : <TAB> with self . connect ( ) as cu : <TAB><TAB> while True : <TAB><TAB><TAB> stmt = "" select parent_path_id from hierarchy where path_id = ? "" <TAB><TAB><TAB> cu . execute ( stmt , ( id , ) ) <TAB><TAB><TAB> parent_id = cu . fetchone ( ) [ 0 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return id <TAB><TAB><TAB> id = parent_id",if parent_id is None or parent_id == id :,if parent_id == id :,77.21160281212369,95.86,False
2924,"def add ( self , path ) : <TAB> with self . get_lock ( path ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . entries [ path ] = { } <TAB><TAB><TAB> self . entries [ path ] [ "" lock "" ] = self . new_locks [ path ] <TAB><TAB><TAB> del self . new_locks [ path ] <TAB><TAB><TAB> self . lru . append ( path )",if not path in self . entries :,if path not in self . entries :,91.76772593338536,97.37,False
2925,"def _get_coordinates_for_dataset_key ( self , dsid ) : <TAB> """"""Get the coordinate dataset keys for *dsid*."""""" <TAB> ds_info = self . ids [ dsid ] <TAB> cids = [ ] <TAB> for cinfo in ds_info . get ( "" coordinates "" , [ ] ) : <TAB><TAB> if not isinstance ( cinfo , dict ) : <TAB><TAB><TAB> cinfo = { "" name "" : cinfo } <TAB><TAB> cinfo [ "" resolution "" ] = ds_info [ "" resolution "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> cinfo [ "" polarization "" ] = ds_info [ "" polarization "" ] <TAB><TAB> cid = DatasetID ( * * cinfo ) <TAB><TAB> cids . append ( self . get_dataset_key ( cid ) ) <TAB> return cids","if ""polarization"" in ds_info :","if ""polymorphicization"" in ds_info :",98.98431699570321,98.79,False
2926,"def build_from_gdobj ( cls , gdobj , steal = False ) : <TAB> # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB> # overloading it __class__ to turn it into an instance of the right class <TAB> ret = BuiltinInitPlaceholder ( ) <TAB> if steal : <TAB><TAB> assert ffi . typeof ( gdobj ) . kind == "" pointer "" <TAB><TAB> ret . _gd_ptr = gdobj <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . _gd_ptr = cls . _copy_gdobj ( gdobj ) <TAB><TAB> else : <TAB><TAB><TAB> ret . _gd_ptr = cls . _copy_gdobj ( ffi . addressof ( gdobj ) ) <TAB> ret . __class__ = cls <TAB> return ret","if ffi . typeof ( gdobj ) . kind == ""pointer"" :","if gdobj . kind == ""pointer"" :",97.05448272457606,96.52,False
2927,"def _listen_output ( self ) : <TAB> "" NB! works in background thread "" <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> chars = self . _proc . read ( 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> as_bytes = chars . encode ( self . encoding ) <TAB><TAB><TAB><TAB> self . _make_output_available ( as_bytes ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _error = "" EOF "" <TAB><TAB><TAB><TAB> break <TAB> except Exception as e : <TAB><TAB> self . _error = str ( e )",if len ( chars ) > 0 :,if chars :,68.77737089030326,96.07,False
2928,"def result ( <TAB> metrics : Dict [ metric_types . MetricKey , Any ] ) - > Dict [ metric_types . AttributionsKey , Dict [ Text , Union [ float , np . ndarray ] ] ] : <TAB> """"""Returns mean attributions."""""" <TAB> total_attributions = metrics [ total_attributions_key ] <TAB> weighted_count = metrics [ weighted_example_count_key ] <TAB> attributions = { } <TAB> for k , v in total_attributions . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> attributions [ k ] = float ( "" nan "" ) <TAB><TAB> else : <TAB><TAB><TAB> attributions [ k ] = v / weighted_count <TAB> return { key : attributions }","if np . isclose ( weighted_count , 0.0 ) :",if v is None :,91.45548705337866,93.72,False
2929,"def write_if_changed ( path , data ) : <TAB> if isinstance ( data , str ) : <TAB><TAB> data = data . encode ( ) <TAB> changed = False <TAB> with open ( os . open ( path , os . O_CREAT | os . O_RDWR ) , "" wb+ "" ) as f : <TAB><TAB> f . seek ( 0 ) <TAB><TAB> current = f . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> f . seek ( 0 ) <TAB><TAB><TAB> f . write ( data ) <TAB><TAB><TAB> f . truncate ( ) <TAB><TAB> os . fsync ( f ) <TAB> return changed",if current != data :,if current != data :,100.0,100.00,True
2930,"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB><TAB> if scan_argv ( self . argv , option ) is not None : <TAB><TAB><TAB> for other_option in self . ssl_options ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB><TAB><TAB><TAB><TAB><TAB> raise ConfigurationError ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return option",if option != other_option :,if option in other_option :,73.50294300456406,98.31,False
2931,"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( arg , bytes ) : <TAB><TAB><TAB> if return_type is str : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = bytes <TAB><TAB> else : <TAB><TAB><TAB> if return_type is bytes : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = str <TAB> if return_type is None : <TAB><TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if arg is None :,if arg is None :,100.0,100.00,True
2932,"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB><TAB> try : <TAB><TAB><TAB> tasks = self . tasks . tasks # is a group <TAB><TAB> except AttributeError : <TAB><TAB><TAB> tasks = self . tasks <TAB><TAB> <MASK> <TAB><TAB><TAB> app = tasks [ 0 ] . _app <TAB><TAB> if app is None and body is not None : <TAB><TAB><TAB> app = body . _app <TAB> return app if app is not None else current_app",if len ( tasks ) :,if tasks :,97.11482654910239,96.59,False
2933,"def add_field ( self , field ) : <TAB> self . remove_field ( field . name ) <TAB> self . fields [ field . name ] = field <TAB> self . columns [ field . db_column ] = field <TAB> self . _sorted_field_list . insert ( field ) <TAB> self . _update_field_lists ( ) <TAB> if field . default is not None : <TAB><TAB> self . defaults [ field ] = field . default <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _default_callables [ field ] = field . default <TAB><TAB><TAB> self . _default_callable_list . append ( ( field . name , field . default ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . _default_dict [ field ] = field . default <TAB><TAB><TAB> self . _default_by_name [ field . name ] = field . default",if callable ( field . default ) :,if field . name in self . _default_dict :,73.02166290300153,95.45,False
2934,"def _get_families ( self ) : <TAB> families = [ ] <TAB> for name , ext in self . _get_family_dirs ( ) : <TAB><TAB> <MASK> # is a directory <TAB><TAB><TAB> family = self . get_resource ( <TAB><TAB><TAB><TAB> FileSystemPackageFamilyResource . key , location = self . location , name = name <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> family = self . get_resource ( <TAB><TAB><TAB><TAB> FileSystemCombinedPackageFamilyResource . key , <TAB><TAB><TAB><TAB> location = self . location , <TAB><TAB><TAB><TAB> name = name , <TAB><TAB><TAB><TAB> ext = ext , <TAB><TAB><TAB> ) <TAB><TAB> families . append ( family ) <TAB> return families",if ext is None :,if ext is None :,100.0,100.00,True
2935,"def test ( model , data_loader , device = None ) : <TAB> device = device or torch . device ( "" cpu "" ) <TAB> model . eval ( ) <TAB> correct = 0 <TAB> total = 0 <TAB> with torch . no_grad ( ) : <TAB><TAB> for batch_idx , ( data , target ) in enumerate ( data_loader ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> data , target = data . to ( device ) , target . to ( device ) <TAB><TAB><TAB> outputs = model ( data ) <TAB><TAB><TAB> _ , predicted = torch . max ( outputs . data , 1 ) <TAB><TAB><TAB> total + = target . size ( 0 ) <TAB><TAB><TAB> correct + = ( predicted == target ) . sum ( ) . item ( ) <TAB> return correct / total",if batch_idx * len ( data ) > TEST_SIZE :,if batch_idx == 0 :,78.90884338517283,95.50,False
2936,"def __animate_progress ( self ) : <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True : <TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB> with self . __progress_lock : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB><TAB> elif self . __show_animation : <TAB><TAB><TAB><TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . __progress_status . show_as_ready ( ) <TAB><TAB><TAB><TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB><TAB> # Allow some time for progress status to be updated. <TAB><TAB> time . sleep ( sleep_time )",if not self . __progress_status :,if self . __progress_status . is_running ( ) :,76.52197236858602,96.78,False
2937,"def _parse_subtitles ( self , video_data , url_key ) : <TAB> subtitles = { } <TAB> for translation in video_data . get ( "" translations "" , [ ] ) : <TAB><TAB> vtt_path = translation . get ( url_key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> lang = translation . get ( "" language_w3c "" ) or ISO639Utils . long2short ( <TAB><TAB><TAB> translation [ "" language_medium "" ] <TAB><TAB> ) <TAB><TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" ext "" : "" vtt "" , <TAB><TAB><TAB><TAB> "" url "" : vtt_path , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB> return subtitles",if not vtt_path :,if not vtt_path :,100.0,100.00,True
2938,"def postprocess_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" and msg [ "" value "" ] is not None : <TAB><TAB> fn , value = msg [ "" fn "" ] , msg [ "" value "" ] <TAB><TAB> value_batch_ndims = jnp . ndim ( value ) - fn . event_dim <TAB><TAB> fn_batch_ndim = len ( fn . batch_shape ) <TAB><TAB> <MASK> <TAB><TAB><TAB> prepend_shapes = ( 1 , ) * ( value_batch_ndims - fn_batch_ndim ) <TAB><TAB><TAB> msg [ "" fn "" ] = tree_map ( <TAB><TAB><TAB><TAB> lambda x : jnp . reshape ( x , prepend_shapes + jnp . shape ( x ) ) , fn <TAB><TAB><TAB> )",if fn_batch_ndim < value_batch_ndims :,if fn_batch_ndim > 0 :,96.95428701128644,96.51,False
2939,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_filename ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
2940,"def createError ( self , line , pos , description ) : <TAB> global ENABLE_PYIMPORT <TAB> msg = "" Line  "" + unicode ( line ) + "" :  "" + unicode ( description ) <TAB> if ENABLE_JS2PY_ERRORS : <TAB><TAB> <MASK> <TAB><TAB><TAB> import js2py . base <TAB><TAB><TAB> return js2py . base . MakeError ( "" SyntaxError "" , msg ) <TAB><TAB> else : <TAB><TAB><TAB> return ENABLE_JS2PY_ERRORS ( msg ) <TAB> else : <TAB><TAB> return JsSyntaxError ( msg )","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",if not ENABLE_PYIMPORT :,64.57547600561672,92.50,False
2941,"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB><TAB> extracted = extractor . extract ( <TAB><TAB><TAB> page , start_index , end_index , self . template . ignored_regions <TAB><TAB> ) <TAB><TAB> for item in arg_to_iter ( extracted ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if isinstance ( item , ( ItemProcessor , dict ) ) : <TAB><TAB><TAB><TAB><TAB> item [ u "" _template "" ] = self . template . id <TAB><TAB><TAB><TAB> items . append ( item ) <TAB> return items",if item :,if item :,100.0,100.00,True
2942,"def create_volume ( self , volume ) : <TAB> """"""Create a volume."""""" <TAB> try : <TAB><TAB> cmd = [ "" volume "" , "" create "" , volume [ "" name "" ] , "" %s G "" % ( volume [ "" size "" ] ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> cmd . append ( "" pool "" ) <TAB><TAB><TAB> cmd . append ( self . configuration . eqlx_pool ) <TAB><TAB> if self . configuration . san_thin_provision : <TAB><TAB><TAB> cmd . append ( "" thin-provision "" ) <TAB><TAB> out = self . _eql_execute ( * cmd ) <TAB><TAB> self . add_multihost_access ( volume ) <TAB><TAB> return self . _get_volume_data ( out ) <TAB> except Exception : <TAB><TAB> with excutils . save_and_reraise_exception ( ) : <TAB><TAB><TAB> LOG . error ( ' Failed to create volume  "" %s "" . ' , volume [ "" name "" ] )","if self . configuration . eqlx_pool != ""default"" :",if self . configuration . eqlx_pool :,71.84887324771641,97.55,False
2943,"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self . code : <TAB><TAB> self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB> if not self . site : <TAB><TAB> placeholders = StaticPlaceholder . objects . filter ( <TAB><TAB><TAB> code = self . code , site__isnull = True <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> placeholders = placeholders . exclude ( pk = self . pk ) <TAB><TAB> if placeholders . exists ( ) : <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> _ ( "" A static placeholder with the same site and code already exists "" ) <TAB><TAB><TAB> )",if self . pk :,if self . pk :,75.0,100.00,True
2944,"def spawnMenu ( self , event ) : <TAB> clickedPos = self . getRowByAbs ( event . Position ) <TAB> self . ensureSelection ( clickedPos ) <TAB> selection = self . getSelectedBoosters ( ) <TAB> mainBooster = None <TAB> if clickedPos != - 1 : <TAB><TAB> try : <TAB><TAB><TAB> booster = self . boosters [ clickedPos ] <TAB><TAB> except IndexError : <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> mainBooster = booster <TAB> itemContext = None if mainBooster is None else _t ( "" Booster "" ) <TAB> menu = ContextMenu . getMenu ( <TAB><TAB> self , <TAB><TAB> mainBooster , <TAB><TAB> selection , <TAB><TAB> ( "" boosterItem "" , itemContext ) , <TAB><TAB> ( "" boosterItemMisc "" , itemContext ) , <TAB> ) <TAB> if menu : <TAB><TAB> self . PopupMenu ( menu )",if booster in self . original :,"if isinstance ( booster , ( int , float ) ) :",68.9988819373794,95.37,False
2945,"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions : <TAB><TAB> <MASK> <TAB><TAB><TAB> app . register_error_handler ( ex , error_http ) <TAB><TAB> elif ex == 500 : <TAB><TAB><TAB> app . register_error_handler ( ex , internal_error ) <TAB> if services . ldap : <TAB><TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB><TAB> @app . errorhandler ( services . ldap . LDAPException ) <TAB><TAB> def handle_exception ( e ) : <TAB><TAB><TAB> log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB><TAB><TAB> return error_http ( FailedDependency ( ) )",if ex < 500 :,if ex == 400 :,73.44113107349493,97.70,False
2946,"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> t = anytype <TAB><TAB> elif "" M "" in fmt : <TAB><TAB><TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB><TAB><TAB> continue <TAB><TAB> elif "" i "" in fmt : <TAB><TAB><TAB> t = int <TAB><TAB> elif "" f "" in fmt : <TAB><TAB><TAB> t = float <TAB><TAB> else : <TAB><TAB><TAB> t = anytype <TAB><TAB> self . addColumn ( ColumnItem ( name , i , type = t ) )",if shape :,"if ""Y"" in fmt :",83.24413599390732,97.03,False
2947,"def Proc2 ( IntParIO ) : <TAB> IntLoc = IntParIO + 10 <TAB> while True : <TAB><TAB> if Char1Glob == "" A "" : <TAB><TAB><TAB> IntLoc = IntLoc - 1 <TAB><TAB><TAB> IntParIO = IntLoc - IntGlob <TAB><TAB><TAB> EnumLoc = Ident1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return IntParIO",if EnumLoc == Ident1 :,if EnumLoc == Ident1 :,100.0,100.00,True
2948,"def opengroup ( self , name = None ) : <TAB> gid = self . groups <TAB> self . groupwidths . append ( None ) <TAB> if self . groups > MAXGROUPS : <TAB><TAB> raise error ( "" too many groups "" ) <TAB> if name is not None : <TAB><TAB> ogid = self . groupdict . get ( name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise error ( <TAB><TAB><TAB><TAB> "" redefinition of group name  %r  as group  %d ;  "" <TAB><TAB><TAB><TAB> "" was group  %d "" % ( name , gid , ogid ) <TAB><TAB><TAB> ) <TAB><TAB> self . groupdict [ name ] = gid <TAB> return gid",if ogid is not None :,if ogid is not None and gid != ogid :,94.16728928142405,96.55,False
2949,"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB><TAB> if name in self : <TAB><TAB><TAB> old_val = self [ name ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> raise KeyError ( <TAB><TAB><TAB><TAB> "" Computed attributed  ' {} '  already exists  "" <TAB><TAB><TAB><TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB><TAB><TAB> ) <TAB><TAB> self [ name ] = val <TAB> else : <TAB><TAB> super ( ) . __setattr__ ( name , val )",if old_val == val :,if old_val == val :,100.0,100.00,True
2950,"def get_all_function_symbols ( self , module = "" kernel "" ) : <TAB> """"""Gets all the function tuples for the given module"""""" <TAB> ret = [ ] <TAB> symtable = self . type_map <TAB> if module in symtable : <TAB><TAB> mod = symtable [ module ] <TAB><TAB> for ( addr , ( name , _sym_types ) ) in mod . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> addr = addr + self . shift_address <TAB><TAB><TAB> ret . append ( [ name , addr ] ) <TAB> else : <TAB><TAB> debug . info ( "" All symbols requested for non-existent module  %s "" % module ) <TAB> return ret",if self . shift_address and addr :,if name in self . _sym_types :,80.65076255138348,95.50,False
2951,"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB><TAB> event not in SUPPORTED_EVENTS <TAB><TAB> or code . co_name == "" trace_types "" <TAB><TAB> or self . should_trace <TAB><TAB> and not self . should_trace ( code ) <TAB> ) : <TAB><TAB> return self <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . handle_call ( frame ) <TAB><TAB> elif event == EVENT_RETURN : <TAB><TAB><TAB> self . handle_return ( frame , arg ) <TAB><TAB> else : <TAB><TAB><TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB><TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self",if event == EVENT_CALL :,if event == EVENT_CALL :,100.0,100.00,True
2952,"def test_update_topic ( self ) : <TAB> async with self . chat_client : <TAB><TAB> await self . _create_thread ( ) <TAB><TAB> topic = "" update topic "" <TAB><TAB> async with self . chat_thread_client : <TAB><TAB><TAB> await self . chat_thread_client . update_topic ( topic = topic ) <TAB><TAB> # delete chat threads <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . chat_client . delete_chat_thread ( self . thread_id )",if not self . is_playback ( ) :,if self . thread_id :,95.07249801494801,94.01,False
2953,"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid    :  "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB><TAB> if j != - 1 : <TAB><TAB><TAB> x_str + = ""   "" * len ( label ) <TAB><TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB><TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str",if i == x [ 0 ] and j == x [ 1 ] :,if i == 0 :,68.81995040816282,94.80,False
2954,"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" QA-ZRE "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB><TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # An older version exists, so remove these outdated files. <TAB><TAB><TAB> build_data . remove_dir ( dpath ) <TAB><TAB> build_data . make_dir ( dpath ) <TAB><TAB> # Download the data. <TAB><TAB> for downloadable_file in RESOURCES : <TAB><TAB><TAB> downloadable_file . download_file ( dpath ) <TAB><TAB> # Mark the data as built. <TAB><TAB> build_data . mark_done ( dpath , version_string = version )",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,100.0,100.00,True
2955,"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB><TAB> repo = _get_repo ( ) <TAB><TAB> _confirm_dangerous ( ) <TAB><TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> origin = url <TAB><TAB><TAB> url = repo . remotes . get ( origin ) <TAB><TAB> if url : <TAB><TAB><TAB> repo . pull ( origin_uri = url ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB><TAB> print ( command_help [ "" git pull "" ] )",if url in repo . remotes :,if not origin :,67.98419235505497,96.74,False
2956,"def FindAndDelete ( script , sig ) : <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b "" "" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> r + = script [ last_sop_idx : sop_idx ] <TAB><TAB> last_sop_idx = sop_idx <TAB><TAB> if script [ sop_idx : sop_idx + len ( sig ) ] == sig : <TAB><TAB><TAB> skip = True <TAB><TAB> else : <TAB><TAB><TAB> skip = False <TAB> <MASK> <TAB><TAB> r + = script [ last_sop_idx : ] <TAB> return CScript ( r )",if not skip :,if skip :,90.56938374338566,97.67,False
2957,"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB><TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB><TAB> pass <TAB> else : <TAB><TAB> if ip . venture is not None : <TAB><TAB><TAB> result [ "" venture_id "" ] = ip . venture . id <TAB><TAB> if ip . device is not None : <TAB><TAB><TAB> result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . device . venture is not None :,if ip . device . venture is not None :,100.0,100.00,True
2958,"def restore ( self , state ) : <TAB> """"""Restore the state of a mesh previously saved using save()"""""" <TAB> import pickle <TAB> state = pickle . loads ( state ) <TAB> for k in state : <TAB><TAB> if isinstance ( state [ k ] , list ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> state [ k ] = [ [ v . x ( ) , v . y ( ) , v . z ( ) ] for v in state [ k ] ] <TAB><TAB><TAB> state [ k ] = np . array ( state [ k ] ) <TAB><TAB> setattr ( self , k , state [ k ] )","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :",if len ( state [ k ] ) == 1 :,91.75011998123432,93.39,False
2959,"def get_extra_lines ( tup ) : <TAB> ext_name , pyopencl_ver = tup <TAB> if ext_name is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> # capital letters -> CL version, not extension <TAB><TAB><TAB> yield "" "" <TAB><TAB><TAB> yield ""     Available with OpenCL  %s . "" % ( ext_name [ 3 : ] ) <TAB><TAB><TAB> yield "" "" <TAB><TAB> else : <TAB><TAB><TAB> yield "" "" <TAB><TAB><TAB> yield ""     Available with the `` %s `` extension. "" % ext_name <TAB><TAB><TAB> yield "" "" <TAB> if pyopencl_ver is not None : <TAB><TAB> yield "" "" <TAB><TAB> yield ""     .. versionadded::  %s "" % pyopencl_ver <TAB><TAB> yield "" ""","if ext_name . startswith ( ""CL_"" ) :","if ext_name . startswith ( ""CL"" ) :",98.86511706179259,98.91,False
2960,"def _gen_remote_uri ( <TAB> fileobj : IO [ bytes ] , <TAB> remote_uri : Optional [ ParseResult ] , <TAB> remote_path_prefix : Optional [ str ] , <TAB> remote_path_suffix : Optional [ str ] , <TAB> sha256sum : Optional [ str ] , ) - > ParseResult : <TAB> if remote_uri is None : <TAB><TAB> assert remote_path_prefix is not None and remote_path_suffix is not None <TAB><TAB> <MASK> <TAB><TAB><TAB> sha256sum = _hash_fileobj ( fileobj ) <TAB><TAB> return urlparse ( <TAB><TAB><TAB> os . path . join ( remote_path_prefix , f "" { sha256sum } { remote_path_suffix } "" ) <TAB><TAB> ) <TAB> else : <TAB><TAB> return remote_uri",if sha256sum is None :,if sha256sum is None :,100.0,100.00,True
2961,"def queries ( self ) : <TAB> if DEV : <TAB><TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB><TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> log_cmd = ShellCommand ( <TAB><TAB><TAB><TAB><TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB><TAB><TAB><TAB><TAB> print ( cmd . stdout ) <TAB><TAB><TAB><TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )",if not cmd . stdout . strip ( ) :,if cmd . stdout :,83.426171719793,96.78,False
2962,"def get_range ( self ) : <TAB> present = self . xml . find ( "" { %s }range "" % self . namespace ) <TAB> if present is not None : <TAB><TAB> attributes = present . attrib <TAB><TAB> return_value = dict ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return_value [ "" minimum "" ] = attributes [ "" min "" ] <TAB><TAB> if "" max "" in attributes : <TAB><TAB><TAB> return_value [ "" maximum "" ] = attributes [ "" max "" ] <TAB><TAB> return return_value <TAB> return False","if ""min"" in attributes :","if ""min"" in attributes :",100.0,100.00,True
2963,"def _configuredOn ( self , workerid , builderid = None , masterid = None ) : <TAB> cfg = [ ] <TAB> for cs in itervalues ( self . configured ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> bid , mid = self . db . builders . builder_masters [ cs [ "" buildermasterid "" ] ] <TAB><TAB> if builderid is not None and bid != builderid : <TAB><TAB><TAB> continue <TAB><TAB> if masterid is not None and mid != masterid : <TAB><TAB><TAB> continue <TAB><TAB> cfg . append ( { "" builderid "" : bid , "" masterid "" : mid } ) <TAB> return cfg","if cs [ ""workerid"" ] != workerid :","if cs [ ""workerid"" ] != workerid :",100.0,100.00,True
2964,"def __exit__ ( self , type , value , traceback ) : <TAB> try : <TAB><TAB> if type is not None : <TAB><TAB><TAB> return self . exception_handler ( type , value , traceback ) <TAB> finally : <TAB><TAB> final_contexts = _state . contexts <TAB><TAB> _state . contexts = self . old_contexts <TAB><TAB> <MASK> <TAB><TAB><TAB> raise StackContextInconsistentError ( <TAB><TAB><TAB><TAB> "" stack_context inconsistency (may be caused by yield  "" <TAB><TAB><TAB><TAB> ' within a  "" with StackContext ""  block) ' <TAB><TAB><TAB> ) <TAB><TAB> # Break up a reference to itself to allow for faster GC on CPython. <TAB><TAB> self . new_contexts = None",if final_contexts is not self . new_contexts :,if _state . contexts != final_contexts :,94.09986855148117,96.15,False
2965,"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> # That key was never assigned <TAB><TAB><TAB> return None <TAB><TAB> elif self . _keys [ hash_ ] == key : <TAB><TAB><TAB> # key found, assign with deleted sentinel <TAB><TAB><TAB> self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _len - = 1 <TAB><TAB><TAB> return <TAB><TAB> hash_ = self . _rehash ( hash_ ) <TAB><TAB> if initial_hash == hash_ : <TAB><TAB><TAB> # table is full and wrapped around <TAB><TAB><TAB> return None",if self . _keys [ hash_ ] is self . _empty :,if self . _keys [ hash_ ] is None :,92.34413841855094,97.72,False
2966,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
2967,"def data_generator ( ) : <TAB> i = 0 <TAB> max_batch_index = len ( X_train ) / / batch_size <TAB> tot = 0 <TAB> while 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> np . ones ( [ batch_size , input_dim ] ) * np . nan , <TAB><TAB><TAB><TAB> np . ones ( [ batch_size , num_classes ] ) * np . nan , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> X_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB><TAB><TAB><TAB> y_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB><TAB><TAB> ) <TAB><TAB> i + = 1 <TAB><TAB> tot + = 1 <TAB><TAB> i = i % max_batch_index",if tot > 3 * len ( X_train ) :,if i == max_batch_index :,69.67058937832896,95.90,False
2968,"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB><TAB> width = self . statwidth ( ) <TAB><TAB> return ( <TAB><TAB><TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( ""   "" , "" - "" ) + theme [ "" default "" ] <TAB><TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB><TAB> width = self . colwidth ( ) <TAB><TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( ""   "" , "" - "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if op . color : <TAB><TAB><TAB><TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret = ret + char [ "" space "" ] <TAB> return ret",if i + 1 != len ( self . vars ) :,if i == 0 :,80.8357932726428,95.77,False
2969,"def get_container_from_dport ( dport , docker_client ) : <TAB> for container in docker_client . containers ( ) : <TAB><TAB> try : <TAB><TAB><TAB> ports = container [ "" Ports "" ] <TAB><TAB><TAB> for port in ports : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if port [ "" PublicPort "" ] == int ( dport ) : <TAB><TAB><TAB><TAB><TAB><TAB> return container <TAB><TAB> except KeyError : <TAB><TAB><TAB> print ( ports ) <TAB><TAB><TAB> pass","if ""PublicPort"" in port :","if port [ ""Port"" ] == int ( dport ) :",92.92001531632962,92.68,False
2970,"def _get_parents_data ( self , data ) : <TAB> parents = 0 <TAB> if data [ COLUMN_PARENT ] : <TAB><TAB> family = self . db . get_family_from_handle ( data [ COLUMN_PARENT ] [ 0 ] ) <TAB><TAB> if family . get_father_handle ( ) : <TAB><TAB><TAB> parents + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> parents + = 1 <TAB> return parents",if family . get_mother_handle ( ) :,elif data [ COLUMN_PARENT ] [ 1 ] :,63.43007221474273,90.87,False
2971,"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB><TAB> if filename in cache : <TAB><TAB><TAB> old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB> if old_mtime == mtime : <TAB><TAB><TAB><TAB> # Move to the end <TAB><TAB><TAB><TAB> cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB><TAB> cache [ filename ] = mtime , result # at the end <TAB><TAB> <MASK> <TAB><TAB><TAB> cache . popitem ( last = False ) <TAB> return result",if len ( cache ) > max_size :,if len ( cache ) > maxsize :,98.77568500407993,97.66,False
2972,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB><TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB> if op . stage == OperandStage . map : <TAB><TAB><TAB> cls . _execute_map ( ctx , op ) <TAB><TAB> elif op . stage == OperandStage . combine : <TAB><TAB><TAB> cls . _execute_combine ( ctx , op ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _execute_agg ( ctx , op ) <TAB><TAB> else : # pragma: no cover <TAB><TAB><TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB><TAB> pd . reset_option ( "" mode.use_inf_as_na "" )",elif op . stage == OperandStage . agg :,elif op . stage == OperandStage . agg :,75.0,100.00,True
2973,"def FindAndDelete ( script , sig ) : <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b "" "" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB><TAB> if not skip : <TAB><TAB><TAB> r + = script [ last_sop_idx : sop_idx ] <TAB><TAB> last_sop_idx = sop_idx <TAB><TAB> <MASK> <TAB><TAB><TAB> skip = True <TAB><TAB> else : <TAB><TAB><TAB> skip = False <TAB> if not skip : <TAB><TAB> r + = script [ last_sop_idx : ] <TAB> return CScript ( r )",if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,if opcode == sig :,67.19605217509158,92.17,False
2974,"def extractall ( zip : typing . Any , path : str ) - > NoneType : <TAB> for name in zip . namelist ( ) : <TAB><TAB> member = zip . getinfo ( name ) <TAB><TAB> extracted_path = zip . _extract_member ( member , path , None ) <TAB><TAB> attr = member . external_attr >> 16 <TAB><TAB> <MASK> <TAB><TAB><TAB> os . chmod ( extracted_path , attr )",if attr != 0 :,if extracted_path is not None :,66.61336954740955,93.38,False
2975,"def find_all_gyptest_files ( directory ) : <TAB> result = [ ] <TAB> for root , dirs , files in os . walk ( directory ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> dirs . remove ( "" .svn "" ) <TAB><TAB> result . extend ( [ os . path . join ( root , f ) for f in files if is_test_name ( f ) ] ) <TAB> result . sort ( ) <TAB> return result","if "".svn"" in dirs :","if "".svn"" in dirs :",100.0,100.00,True
2976,"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr ( storefile , "" read "" ) : <TAB><TAB> storefile = open ( storefile , "" rb "" ) <TAB> # Adjust store to have translations <TAB> store = cls . convertfile ( storefile , template_store ) <TAB> for unit in store . units : <TAB><TAB> if unit . isheader ( ) : <TAB><TAB><TAB> continue <TAB><TAB> # HTML does this properly on loading, others need it <TAB><TAB> <MASK> <TAB><TAB><TAB> unit . target = unit . source <TAB><TAB><TAB> unit . rich_target = unit . rich_source <TAB> return store",if cls . needs_target_sync :,if unit . ishtml ( ) :,72.68724192610088,95.45,False
2977,"def postOptions ( self ) : <TAB> _BasicOptions . postOptions ( self ) <TAB> if self [ "" jobs "" ] : <TAB><TAB> conflicts = [ "" debug "" , "" profile "" , "" debug-stacktraces "" , "" exitfirst "" ] <TAB><TAB> for option in conflicts : <TAB><TAB><TAB> if self [ option ] : <TAB><TAB><TAB><TAB> raise usage . UsageError ( <TAB><TAB><TAB><TAB><TAB> "" You can ' t specify -- %s  when using --jobs "" % option <TAB><TAB><TAB><TAB> ) <TAB> if self [ "" nopm "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise usage . UsageError ( "" You must specify --debug when using  "" "" --nopm  "" ) <TAB><TAB> failure . DO_POST_MORTEM = False","if not self [ ""debug"" ] :","if self [ ""debug"" ] :",96.81869854548209,98.77,False
2978,"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB><TAB> if not ( i < len ( extra . tokens ) ) : <TAB><TAB><TAB> break <TAB><TAB> entry = extra . tokens [ i ] <TAB><TAB> token = jsdict ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" type "" : entry . type , <TAB><TAB><TAB><TAB> "" value "" : entry . value , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB><TAB> if extra . range : <TAB><TAB><TAB> token . range = entry . range <TAB><TAB> <MASK> <TAB><TAB><TAB> token . loc = entry . loc <TAB><TAB> tokens . append ( token ) <TAB><TAB> i + = 1 <TAB> extra . tokens = tokens",if extra . loc :,if extra . loc :,100.0,100.00,True
2979,"def on_rebalance_end ( self ) - > None : <TAB> """"""Call when rebalancing is done."""""" <TAB> self . rebalancing = False <TAB> if self . _rebalancing_span : <TAB><TAB> self . _rebalancing_span . finish ( ) <TAB> self . _rebalancing_span = None <TAB> sensor_state = self . _rebalancing_sensor_state <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . warning ( <TAB><TAB><TAB><TAB> "" Missing sensor state for rebalance # %s "" , self . rebalancing_count <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . sensors . on_rebalance_end ( self , sensor_state ) <TAB> finally : <TAB><TAB> self . _rebalancing_sensor_state = None",if not sensor_state :,if sensor_state is None :,69.0033854133828,97.64,False
2980,"def decorator ( request , * args , * * kwargs ) : <TAB> if CALENDAR_VIEW_PERM : <TAB><TAB> user = request . user <TAB><TAB> if not user : <TAB><TAB><TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB><TAB> occurrence , event , calendar = get_objects ( request , * * kwargs ) <TAB><TAB> if calendar : <TAB><TAB><TAB> allowed = CHECK_CALENDAR_PERM_FUNC ( calendar , user ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB><TAB><TAB> # all checks passed <TAB><TAB><TAB> return function ( request , * args , * * kwargs ) <TAB><TAB> return HttpResponseNotFound ( "" <h1>Page not found</h1> "" ) <TAB> return function ( request , * args , * * kwargs )",if not allowed :,if not allowed :,100.0,100.00,True
2981,"def reduce_arguments ( self , args ) : <TAB> assert isinstance ( args , nodes . Arguments ) <TAB> if args . incorrect_order ( ) : <TAB><TAB> raise InvalidArguments ( <TAB><TAB><TAB> "" All keyword arguments must be after positional arguments. "" <TAB><TAB> ) <TAB> reduced_pos = [ self . reduce_single ( arg ) for arg in args . arguments ] <TAB> reduced_kw = { } <TAB> for key in args . kwargs . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidArguments ( "" Keyword argument name is not a string. "" ) <TAB><TAB> a = args . kwargs [ key ] <TAB><TAB> reduced_kw [ key ] = self . reduce_single ( a ) <TAB> return ( reduced_pos , reduced_kw )","if not isinstance ( key , str ) :","if not isinstance ( key , six . string_types ) :",75.05459927731214,96.82,False
2982,"def _encode ( n , nbytes , little_endian = False ) : <TAB> retval = [ ] <TAB> n = long ( n ) <TAB> for i in range ( nbytes ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> retval . append ( chr ( n & 0xFF ) ) <TAB><TAB> else : <TAB><TAB><TAB> retval . insert ( 0 , chr ( n & 0xFF ) ) <TAB><TAB> n >> = 8 <TAB> return "" "" . join ( retval )",if little_endian :,if little_endian :,100.0,100.00,True
2983,"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( ) # create a new group <TAB> new_i . id = self . id # with the same id <TAB> cls . id = old_id # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls . properties : <TAB><TAB> if prop is not "" members "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> val = getattr ( self , prop ) <TAB><TAB><TAB><TAB> setattr ( new_i , prop , val ) <TAB> # but no members <TAB> new_i . members = [ ] <TAB> return new_i",if self . has ( prop ) :,"if hasattr ( self , prop ) :",97.84514677158566,97.36,False
2984,"def dataspec ( config ) : <TAB> master = yield fakemaster . make_master ( ) <TAB> data = connector . DataConnector ( ) <TAB> data . setServiceParent ( master ) <TAB> if config [ "" out "" ] != "" -- "" : <TAB><TAB> dirs = os . path . dirname ( config [ "" out "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( dirs ) <TAB><TAB> f = open ( config [ "" out "" ] , "" w "" ) <TAB> else : <TAB><TAB> f = sys . stdout <TAB> if config [ "" global "" ] is not None : <TAB><TAB> f . write ( "" window. "" + config [ "" global "" ] + "" = "" ) <TAB> f . write ( json . dumps ( data . allEndpoints ( ) , indent = 2 ) ) <TAB> f . close ( ) <TAB> defer . returnValue ( 0 )",if dirs and not os . path . exists ( dirs ) :,if not os . path . exists ( dirs ) :,87.93615317843114,98.43,False
2985,"def _parseSCDOCDC ( self , src ) : <TAB> """"""[S|CDO|CDC]*"""""" <TAB> while 1 : <TAB><TAB> src = src . lstrip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> src = src [ 4 : ] <TAB><TAB> elif src . startswith ( "" --> "" ) : <TAB><TAB><TAB> src = src [ 3 : ] <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return src","if src . startswith ( ""<!--"" ) :","if src . startswith ( ""<S|CDO|CDC>"" ) :",98.06542301133027,94.53,False
2986,"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB><TAB> visitor = process_file ( filename ) <TAB><TAB> if visitor . needs_fix ( ) : <TAB><TAB><TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> print ( "" Fixing:  %s "" % filename ) <TAB><TAB><TAB><TAB> fix_file ( filename )",if fix :,if fix :,100.0,100.00,True
2987,"def shutdown ( self ) : <TAB> """"""Shutdown host system."""""" <TAB> self . _check_dbus ( MANAGER ) <TAB> use_logind = self . sys_dbus . logind . is_connected <TAB> _LOGGER . info ( "" Initialize host power off  %s "" , "" logind "" if use_logind else "" systemd "" ) <TAB> try : <TAB><TAB> await self . sys_core . shutdown ( ) <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> await self . sys_dbus . logind . power_off ( ) <TAB><TAB> else : <TAB><TAB><TAB> await self . sys_dbus . systemd . power_off ( )",if use_logind :,if use_logind :,100.0,100.00,True
2988,"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split : <TAB><TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB><TAB> char = chars [ i ] <TAB><TAB> if _is_punctuation ( char ) : <TAB><TAB><TAB> output . append ( [ char ] ) <TAB><TAB><TAB> start_new_word = True <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> output . append ( [ ] ) <TAB><TAB><TAB> start_new_word = False <TAB><TAB><TAB> output [ - 1 ] . append ( char ) <TAB><TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ]",if start_new_word :,if start_new_word :,100.0,100.00,True
2989,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB><TAB> if tp == "" write "" : <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB> <MASK> <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> elif tp == "" write_flush "" : <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> elif tp == "" print "" : <TAB><TAB><TAB> print ( msg , file = out ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB><TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB> pass","elif tp == ""flush"" :","elif tp == ""flush"" :",100.0,100.00,True
2990,"def checkClassDeclation ( file ) : <TAB> localResult = [ ] <TAB> with open ( file , "" rb "" ) as f : <TAB><TAB> lineNumber = 0 <TAB><TAB> for line in f : <TAB><TAB><TAB> m = re . search ( "" class \ s+[^ \ (]*: "" , line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> localResult . append ( <TAB><TAB><TAB><TAB><TAB> "" Old class definition found on  {0} "" . format ( m . group ( ) ) <TAB><TAB><TAB><TAB> ) <TAB> return localResult",if m :,if m :,100.0,100.00,True
2991,"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB><TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB> with function . no_backprop_mode ( ) : <TAB><TAB><TAB> if isinstance ( in_arrays , tuple ) : <TAB><TAB><TAB><TAB> results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results = self . calc_local ( in_arrays ) <TAB><TAB> if self . _progress_hook : <TAB><TAB><TAB> self . _progress_hook ( batch ) <TAB><TAB> yield results","elif isinstance ( in_arrays , dict ) :","elif isinstance ( in_arrays , dict ) :",100.0,100.00,True
2992,"def check_billing_view ( user , permission , obj ) : <TAB> if hasattr ( obj , "" all_projects "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> # This is a billing object <TAB><TAB> return any ( check_permission ( user , permission , prj ) for prj in obj . all_projects ) <TAB> return check_permission ( user , permission , obj )",if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,if obj . all_projects == [ ] :,62.46068020854663,81.38,False
2993,"def ensure_output_spaces_contain_the_same_data ( self , y , y_ensured ) : <TAB> stride = y . shape [ 1 ] <TAB> self . assertEqual ( y . shape [ 0 ] * y . shape [ 1 ] , y_ensured . shape [ 0 ] ) <TAB> self . assertEqual ( len ( y_ensured . shape ) , 1 ) <TAB> for row in range ( y . shape [ 0 ] ) : <TAB><TAB> for column in range ( y . shape [ 1 ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( y [ row , column ] , y_ensured [ row * stride + column ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertEqual ( y [ row ] [ column ] , y_ensured [ row * stride + column ] )",if sp . issparse ( y ) :,if row == 0 :,95.4936913470751,96.48,False
2994,"def train ( <TAB> self , <TAB> training_data : TrainingData , <TAB> config : Optional [ RasaNLUModelConfig ] = None , <TAB> * * kwargs : Any , ) - > None : <TAB> """"""Tokenize all training data."""""" <TAB> for example in training_data . training_examples : <TAB><TAB> for attribute in MESSAGE_ATTRIBUTES : <TAB><TAB><TAB> if example . get ( attribute ) is not None and not example . get ( attribute ) == "" "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> tokens = self . _split_name ( example , attribute ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> tokens = self . tokenize ( example , attribute ) <TAB><TAB><TAB><TAB> example . set ( TOKENS_NAMES [ attribute ] , tokens )","if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",if attribute in TOKENS_NAMES :,92.52190563550504,93.88,False
2995,"def refresh_token ( self , strategy , * args , * * kwargs ) : <TAB> token = self . extra_data . get ( "" refresh_token "" ) or self . extra_data . get ( "" access_token "" ) <TAB> backend = self . get_backend ( strategy ) <TAB> if token and backend and hasattr ( backend , "" refresh_token "" ) : <TAB><TAB> backend = backend ( strategy = strategy ) <TAB><TAB> response = backend . refresh_token ( token , * args , * * kwargs ) <TAB><TAB> extra_data = backend . extra_data ( self , self . uid , response , self . extra_data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . save ( )",if self . set_extra_data ( extra_data ) :,if extra_data and self . save_data :,68.51277795350282,94.21,False
2996,"def _verify_environ ( _collected_environ ) : <TAB> try : <TAB><TAB> yield <TAB> finally : <TAB><TAB> new_environ = dict ( os . environ ) <TAB><TAB> current_test = new_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB><TAB> old_environ = dict ( _collected_environ ) <TAB><TAB> old_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise DirtyTest ( <TAB><TAB><TAB><TAB> "" Left over environment variables "" , <TAB><TAB><TAB><TAB> current_test , <TAB><TAB><TAB><TAB> _compare_eq_dict ( new_environ , old_environ , verbose = 2 ) , <TAB><TAB><TAB> )",if new_environ != old_environ :,if current_test is not None :,94.71781378018468,95.66,False
2997,"def clean_len ( self , line ) : <TAB> """"""Calculate wisible length of string"""""" <TAB> if isinstance ( line , basestring ) : <TAB><TAB> return len ( self . screen . markup . clean_markup ( line ) ) <TAB> elif isinstance ( line , tuple ) or isinstance ( line , list ) : <TAB><TAB> markups = self . screen . markup . get_markup_vars ( ) <TAB><TAB> length = 0 <TAB><TAB> for i in line : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> length + = len ( i ) <TAB><TAB> return length",if i not in markups :,"if i . startswith ( ""markup_"" ) and len ( i ) < len ( markups",64.47597584292812,89.22,False
2998,"def _build_merged_dataset_args ( datasets ) : <TAB> merged_dataset_args = [ ] <TAB> for dataset in datasets : <TAB><TAB> dataset_code_column = _parse_dataset_code ( dataset ) <TAB><TAB> arg = dataset_code_column [ "" code "" ] <TAB><TAB> column_index = dataset_code_column [ "" column_index "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> arg = ( dataset_code_column [ "" code "" ] , { "" column_index "" : [ column_index ] } ) <TAB><TAB> merged_dataset_args . append ( arg ) <TAB> return merged_dataset_args",if column_index is not None :,if column_index :,73.64655929395596,97.31,False
2999,"def update_watch_data_table_paths ( self ) : <TAB> if hasattr ( self . tool_data_watcher , "" monitored_dirs "" ) : <TAB><TAB> for tool_data_table_path in self . tool_data_paths : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . tool_data_watcher . watch_directory ( tool_data_table_path )",if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,"if tool_data_table_path . startswith ( "" monitored_dirs"" ) :",62.45546159528421,89.27,False
3000,"def getsource ( obj ) : <TAB> """"""Wrapper around inspect.getsource"""""" <TAB> try : <TAB><TAB> try : <TAB><TAB><TAB> src = encoding . to_unicode ( inspect . getsource ( obj ) ) <TAB><TAB> except TypeError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> src = encoding . to_unicode ( inspect . getsource ( obj . __class__ ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # Bindings like VTK or ITK require this case <TAB><TAB><TAB><TAB> src = getdoc ( obj ) <TAB><TAB> return src <TAB> except ( TypeError , IOError ) : <TAB><TAB> return","if hasattr ( obj , ""__class__"" ) :","if hasattr ( obj , ""__class__"" ) :",100.0,100.00,True
3001,"def __iter__ ( self ) : <TAB> for model in self . app_config . get_models ( ) : <TAB><TAB> admin_model = AdminModel ( model , * * self . options ) <TAB><TAB> for model_re in self . model_res : <TAB><TAB><TAB> if model_re . search ( admin_model . name ) : <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield admin_model",if self . model_res :,if admin_model . name in self . _excluded_models :,93.94961386258747,91.99,False
3002,"def run ( self ) : <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> with DelayedKeyboardInterrupt ( ) : <TAB><TAB><TAB><TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB><TAB><TAB><TAB> if self . _has_stop_signal ( raw_inputs ) : <TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> if self . _flow_type == BATCH : <TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = True ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> self . _rq . put ( raw_inputs , block = False ) <TAB><TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB> except KeyboardInterrupt : <TAB><TAB><TAB> continue",elif self . _flow_type == REALTIME :,if self . _flow_type == REVERT :,97.55653809823292,98.41,False
3003,"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB><TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB><TAB><TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB><TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) : <TAB><TAB><TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) )","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :","if isinstance ( getattr ( self , field [ 0 ] ) , ( float , int ) )",70.79714465202626,97.08,False
3004,"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> """"""Validating that user has inputted a value set and that configuration has been initialized"""""" <TAB> super ( ) . validate_configuration ( configuration ) <TAB> try : <TAB><TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB><TAB> assert isinstance ( <TAB><TAB><TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB><TAB> ) , "" value_set must be a list or a set "" <TAB><TAB> <MASK> <TAB><TAB><TAB> assert ( <TAB><TAB><TAB><TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB><TAB><TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key ' <TAB> except AssertionError as e : <TAB><TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",75.0,100.00,True
3005,def test_one_dead_branch ( ) : <TAB> with deterministic_PRNG ( ) : <TAB><TAB> seen = set ( ) <TAB><TAB> @run_to_buffer <TAB><TAB> def x ( data ) : <TAB><TAB><TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB><TAB><TAB> if i > 0 : <TAB><TAB><TAB><TAB> data . mark_invalid ( ) <TAB><TAB><TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB><TAB><TAB> if len ( seen ) < 255 : <TAB><TAB><TAB><TAB> seen . add ( i ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data . mark_interesting ( ),elif i not in seen :,if i in seen :,72.24113998248241,97.88,False
3006,"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB><TAB> module = self . get_event_module ( event ) <TAB><TAB> self . __module_view . set_selection ( module . module_num ) <TAB><TAB> if event . EventObject is self . list_ctrl : <TAB><TAB><TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . list_ctrl . deactivate_active_item ( ) <TAB><TAB><TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( )",if self . list_ctrl . IsSelected ( index ) :,if self . list_ctrl . GetItem ( index ) :,98.83193767536878,98.93,False
3007,"def prime ( self , callback ) : <TAB> <MASK> <TAB><TAB> # import pdb <TAB><TAB> # pdb.set_trace() <TAB><TAB> self . cbhdl = simulator . register_rwsynch_callback ( callback , self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise_error ( self , "" Unable set up  %s  Trigger "" % ( str ( self ) ) ) <TAB> Trigger . prime ( self )",if self . cbhdl is None :,if self . cbhdl is None :,100.0,100.00,True
3008,"def fstab_configuration ( middleware ) : <TAB> for command in ( <TAB><TAB> [ <TAB><TAB><TAB> [ "" systemctl "" , "" daemon-reload "" ] , <TAB><TAB><TAB> [ "" systemctl "" , "" restart "" , "" local-fs.target "" ] , <TAB><TAB> ] <TAB><TAB> if osc . IS_LINUX <TAB><TAB> else [ [ "" mount "" , "" -uw "" , "" / "" ] ] <TAB> ) : <TAB><TAB> ret = subprocess . run ( command , capture_output = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> middleware . logger . debug ( <TAB><TAB><TAB><TAB> f ' Failed to execute  "" { ""   "" . join ( command ) } "" :  { ret . stderr . decode ( ) } ' <TAB><TAB><TAB> )",if ret . returncode :,if ret . stderr :,98.96540516768711,98.78,False
3009,"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB><TAB> yield ( <TAB><TAB><TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB><TAB><TAB> simple_colorize ( todesc , "" description "" ) , <TAB><TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB><TAB><TAB> # generated for the first line <TAB><TAB><TAB> if i > 0 : <TAB><TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB><TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB><TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> yield line",if line is None :,"if line == """" :",95.99998313062447,97.84,False
3010,"def update_completion ( self ) : <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB><TAB> if "" , "" in orig_text : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB><TAB><TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB><TAB> else : <TAB><TAB><TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB><TAB> self . completer_model . setStringList ( tags )","if orig_text [ - 1 ] not in ( "","" , "" "" ) :",if tag not in tags :,67.71472187335559,92.75,False
3011,"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB><TAB> return False <TAB> for digit in reversed ( number ) : <TAB><TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> digit * = 2 <TAB><TAB><TAB> if digit > = 10 : <TAB><TAB><TAB><TAB> digit = digit % 10 + digit / / 10 <TAB><TAB> digits . append ( digit ) <TAB><TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False",if even :,if even :,100.0,100.00,True
3012,"def __get_param_string__ ( params ) : <TAB> params_string = [ ] <TAB> for key in sorted ( params . keys ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> value = params [ key ] <TAB><TAB> params_string . append ( "" "" if value == "" null "" else str ( value ) ) <TAB> return "" | "" . join ( params_string )","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :","if key == ""params"" :",83.12766427531737,85.63,False
3013,"def _map_handlers ( self , session , event_class , mapfn ) : <TAB> for event in DOC_EVENTS : <TAB><TAB> event_handler_name = event . replace ( "" - "" , "" _ "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> event_handler = getattr ( self , event_handler_name ) <TAB><TAB><TAB> format_string = DOC_EVENTS [ event ] <TAB><TAB><TAB> num_args = len ( format_string . split ( "" . "" ) ) - 2 <TAB><TAB><TAB> format_args = ( event_class , ) + ( "" * "" , ) * num_args <TAB><TAB><TAB> event_string = event + format_string % format_args <TAB><TAB><TAB> unique_id = event_class + event_handler_name <TAB><TAB><TAB> mapfn ( event_string , event_handler , unique_id )","if hasattr ( self , event_handler_name ) :",if event_handler_name in self . _event_handlers :,73.43994067067383,95.87,False
3014,"def _create_param_lr ( self , param_and_grad ) : <TAB> # create learning rate variable for every parameter <TAB> param = param_and_grad [ 0 ] <TAB> param_lr = param . optimize_attr [ "" learning_rate "" ] <TAB> if type ( param_lr ) == Variable : <TAB><TAB> return param_lr <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _global_learning_rate ( ) <TAB><TAB> else : <TAB><TAB><TAB> with default_main_program ( ) . _lr_schedule_guard ( <TAB><TAB><TAB><TAB> is_with_opt = True <TAB><TAB><TAB> ) , framework . name_scope ( "" scale_with_param_lr "" ) : <TAB><TAB><TAB><TAB> return self . _global_learning_rate ( ) * param_lr",if param_lr == 1.0 :,if param_lr == 0 :,73.72674532804466,98.90,False
3015,"def __getitem__ ( self , key ) : <TAB> try : <TAB><TAB> return self . _clsmap [ key ] <TAB> except KeyError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _mutex . acquire ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . _init ( ) <TAB><TAB><TAB><TAB><TAB> self . initialized = True <TAB><TAB><TAB><TAB> return self . _clsmap [ key ] <TAB><TAB><TAB> finally : <TAB><TAB><TAB><TAB> self . _mutex . release ( ) <TAB><TAB> raise e",if not self . initialized :,if self . initialized :,80.39207320446395,97.43,False
3016,"def save ( self , force = False ) : <TAB> if not force : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if time . time ( ) - self . last_save_time < 10 : <TAB><TAB><TAB> return <TAB> with self . lock : <TAB><TAB> with open ( self . file_path , "" w "" ) as fd : <TAB><TAB><TAB> for ip in self . cache : <TAB><TAB><TAB><TAB> record = self . cache [ ip ] <TAB><TAB><TAB><TAB> rule = record [ "" r "" ] <TAB><TAB><TAB><TAB> connect_time = record [ "" c "" ] <TAB><TAB><TAB><TAB> update_time = record [ "" update "" ] <TAB><TAB><TAB><TAB> fd . write ( "" %s   %s   %d   %d \n "" % ( ip , rule , connect_time , update_time ) ) <TAB> self . last_save_time = time . time ( ) <TAB> self . need_save = False",if not self . need_save :,if self . need_save :,97.00994410996971,99.08,False
3017,"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield x <TAB><TAB> elif not x . is_atom ( ) and not s . is_atom ( ) : <TAB><TAB><TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation )",if match ( s ) :,if x . head == s . head :,66.92753304471925,91.12,False
3018,"def isValidFloat ( config_param_name , value , constraints ) : <TAB> if isinstance ( value , float ) : <TAB><TAB> constraints . setdefault ( "" min "" , MIN_VALID_FLOAT_VALUE ) <TAB><TAB> constraints . setdefault ( "" max "" , MAX_VALID_FLOAT_VALUE ) <TAB><TAB> minv = float ( constraints . get ( "" min "" ) ) <TAB><TAB> maxv = float ( constraints . get ( "" max "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if value < = maxv : <TAB><TAB><TAB><TAB> return value <TAB> raise FloatValueError ( config_param_name , value , constraints )",if value >= minv :,if value >= minv :,100.0,100.00,True
3019,"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB><TAB> for name in files : <TAB><TAB><TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB><TAB><TAB><TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if ""qemux86copy-"" in root or ""qemux86-"" in root :","if ""sdk"" in root :",96.07243863588141,94.50,False
3020,"def __get_photo ( self , person_or_marriage ) : <TAB> """"""returns the first photo in the media list or None"""""" <TAB> media_list = person_or_marriage . get_media_list ( ) <TAB> for media_ref in media_list : <TAB><TAB> media_handle = media_ref . get_reference_handle ( ) <TAB><TAB> media = self . database . get_media_from_handle ( media_handle ) <TAB><TAB> mime_type = media . get_mime_type ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return media <TAB> return None","if mime_type and mime_type . startswith ( ""image"" ) :","if mime_type == ""photo"" :",62.94824884231846,92.79,False
3021,"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB><TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB><TAB> if array . has_property ( unicode ( k ) ) : <TAB><TAB><TAB> kValue = array . get ( unicode ( k ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> res . append ( kValue ) <TAB><TAB> k + = 1 <TAB> return args . space . ConstructArray ( res )","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",if callable ( callbackfn . call ) and ( kValue is not None ) :,64.17638721796686,91.32,False
3022,"def optimize ( self , graph : Graph ) : <TAB> for v in graph . inputs : <TAB><TAB> if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> DumpGraph ( ) . optimize ( graph ) <TAB><TAB> raise NotImplementedError ( <TAB><TAB><TAB> f "" Input Variable  { v }  is too large to handle in WebGL backend "" <TAB><TAB> ) <TAB> return graph , False",if flags . DEBUG :,if len ( graph . outputs ) > self . MAX_OUTPUT_SIZE :,92.74633904201687,88.47,False
3023,"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self . list_nodes ( ) : <TAB><TAB> if type ( node . image ) is not list : <TAB><TAB><TAB> # This node has only one associated image. It is not the one we <TAB><TAB><TAB> # are after. <TAB><TAB><TAB> continue <TAB><TAB> for disk in node . image : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # Node found. We can now detach the volume <TAB><TAB><TAB><TAB> disk_id = disk . extra [ "" disk_id "" ] <TAB><TAB><TAB><TAB> return self . _do_detach_volume ( node . id , disk_id ) <TAB> return False",if disk . id == volume . id :,if disk . name == volume . name :,72.8320814393057,97.66,False
3024,"def Yield ( value , level = 1 ) : <TAB> g = greenlet . getcurrent ( ) <TAB> while level != 0 : <TAB><TAB> if not isinstance ( g , genlet ) : <TAB><TAB><TAB> raise RuntimeError ( "" yield outside a genlet "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> g . parent . set_child ( g ) <TAB><TAB> g = g . parent <TAB><TAB> level - = 1 <TAB> g . switch ( value )",if level > 1 :,if g . parent :,91.80335932381506,96.28,False
3025,"def get_all_pipeline_nodes ( <TAB> pipeline : pipeline_pb2 . Pipeline , ) - > List [ pipeline_pb2 . PipelineNode ] : <TAB> """"""Returns all pipeline nodes in the given pipeline."""""" <TAB> result = [ ] <TAB> for pipeline_or_node in pipeline . nodes : <TAB><TAB> which = pipeline_or_node . WhichOneof ( "" node "" ) <TAB><TAB> # TODO(goutham): Handle sub-pipelines. <TAB><TAB> # TODO(goutham): Handle system nodes. <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( pipeline_or_node . pipeline_node ) <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( "" Only pipeline nodes supported. "" ) <TAB> return result","if which == ""pipeline_node"" :","if which == ""pipeline_node"" :",100.0,100.00,True
3026,"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB><TAB> if not hasattr ( self , name ) : <TAB><TAB><TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> name , <TAB><TAB><TAB><TAB><TAB> self . __class__ . __name__ , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> setattr ( self , name , value )",if name not in default_settings :,"if not hasattr ( self , name ) :",94.19393660107363,96.46,False
3027,"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB><TAB> elif type ( self . choices ) not in ( types . TupleType , types . ListType ) : <TAB><TAB><TAB> raise OptionError ( <TAB><TAB><TAB><TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB><TAB><TAB><TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB><TAB><TAB><TAB> self , <TAB><TAB><TAB> ) <TAB> elif self . choices is not None : <TAB><TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self )",if self . choices is None :,if not self . choices :,70.28647672282368,97.72,False
3028,"def prepare ( self , size = None ) : <TAB> if _is_seekable ( self . file ) : <TAB><TAB> start_pos = self . file . tell ( ) <TAB><TAB> self . file . seek ( 0 , 2 ) <TAB><TAB> end_pos = self . file . tell ( ) <TAB><TAB> self . file . seek ( start_pos ) <TAB><TAB> fsize = end_pos - start_pos <TAB><TAB> <MASK> <TAB><TAB><TAB> self . remain = fsize <TAB><TAB> else : <TAB><TAB><TAB> self . remain = min ( fsize , size ) <TAB> return self . remain",if size is None :,if size is None :,100.0,100.00,True
3029,"def _setSitemapTargets ( ) : <TAB> if not conf . sitemapUrl : <TAB><TAB> return <TAB> infoMsg = "" parsing sitemap  ' %s ' "" % conf . sitemapUrl <TAB> logger . info ( infoMsg ) <TAB> found = False <TAB> for item in parseSitemap ( conf . sitemapUrl ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> found = True <TAB><TAB><TAB> kb . targets . add ( ( item . strip ( ) , None , None , None , None ) ) <TAB> if not found and not conf . forms and not conf . crawlDepth : <TAB><TAB> warnMsg = "" no usable links found (with GET parameters) "" <TAB><TAB> logger . warn ( warnMsg )","if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",if item . strip ( ) :,90.15009665909317,86.96,False
3030,"def test_CY_decomposition ( self , tol ) : <TAB> """"""Tests that the decomposition of the CY gate is correct"""""" <TAB> op = qml . CY ( wires = [ 0 , 1 ] ) <TAB> res = op . decomposition ( op . wires ) <TAB> mats = [ ] <TAB> for i in reversed ( res ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> mats . append ( np . kron ( i . matrix , np . eye ( 2 ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> mats . append ( i . matrix ) <TAB> decomposed_matrix = np . linalg . multi_dot ( mats ) <TAB> assert np . allclose ( decomposed_matrix , op . matrix , atol = tol , rtol = 0 )",if len ( i . wires ) == 1 :,if i . is_kron :,81.7225057692161,94.84,False
3031,"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB><TAB> if lidx > = len ( lines ) : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> lidx + = 1 <TAB><TAB><TAB> if not start : <TAB><TAB><TAB><TAB> start = stmt <TAB><TAB><TAB> end = stmt <TAB><TAB> elif start : <TAB><TAB><TAB> pairs . append ( ( start , end ) ) <TAB><TAB><TAB> start = None <TAB> if start : <TAB><TAB> pairs . append ( ( start , end ) ) <TAB> return pairs",if stmt == lines [ lidx ] :,"if stmt . startswith ( ""range"" ) :",68.67422174559074,96.40,False
3032,"def init_params ( net ) : <TAB> """"""Init layer parameters."""""" <TAB> for module in net . modules ( ) : <TAB><TAB> if isinstance ( module , nn . Conv2d ) : <TAB><TAB><TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> init . constant ( module . bias , 0 ) <TAB><TAB> elif isinstance ( module , nn . BatchNorm2d ) : <TAB><TAB><TAB> init . constant ( module . weight , 1 ) <TAB><TAB><TAB> init . constant ( module . bias , 0 ) <TAB><TAB> elif isinstance ( module , nn . Linear ) : <TAB><TAB><TAB> init . normal ( module . weight , std = 1e-3 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> init . constant ( module . bias , 0 )",if module . bias :,if module . bias is not None :,71.07493549649249,96.30,False
3033,"def _get_directory_size_in_bytes ( directory ) : <TAB> total = 0 <TAB> try : <TAB><TAB> for entry in os . scandir ( directory ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # if it's a file, use stat() function <TAB><TAB><TAB><TAB> total + = entry . stat ( ) . st_size <TAB><TAB><TAB> elif entry . is_dir ( ) : <TAB><TAB><TAB><TAB> # if it's a directory, recursively call this function <TAB><TAB><TAB><TAB> total + = _get_directory_size_in_bytes ( entry . path ) <TAB> except NotADirectoryError : <TAB><TAB> # if `directory` isn't a directory, get the file size then <TAB><TAB> return os . path . getsize ( directory ) <TAB> except PermissionError : <TAB><TAB> # if for whatever reason we can't open the folder, return 0 <TAB><TAB> return 0 <TAB> return total",if entry . is_file ( ) :,if entry . is_file ( ) :,100.0,100.00,True
3034,"def run_cmd ( self , util , to , always_push_mark = False ) : <TAB> if to == "" bof "" : <TAB><TAB> util . push_mark_and_goto_position ( 0 ) <TAB> elif to == "" eof "" : <TAB><TAB> util . push_mark_and_goto_position ( self . view . size ( ) ) <TAB> elif to in ( "" eow "" , "" bow "" ) : <TAB><TAB> visible = self . view . visible_region ( ) <TAB><TAB> pos = visible . a if to == "" bow "" else visible . b <TAB><TAB> <MASK> <TAB><TAB><TAB> util . push_mark_and_goto_position ( pos ) <TAB><TAB> else : <TAB><TAB><TAB> util . set_cursors ( [ sublime . Region ( pos ) ] )",if always_push_mark :,if always_push_mark :,100.0,100.00,True
3035,"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB><TAB> dd = tup [ 1 ] <TAB><TAB> if "" results.train_y_misclass "" in dd : <TAB><TAB><TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB><TAB><TAB><TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( key + "" :  "" + str ( value ) )","if ""hyper_parameters"" in key :","if key != ""results.train_y_misclass"" :",68.97247758795403,94.47,False
3036,"def clean_vc_position ( self ) : <TAB> vc_position = self . cleaned_data [ "" vc_position "" ] <TAB> if self . validate_vc_position : <TAB><TAB> conflicting_members = Device . objects . filter ( <TAB><TAB><TAB> virtual_chassis = self . instance . virtual_chassis , vc_position = vc_position <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise forms . ValidationError ( <TAB><TAB><TAB><TAB> "" A virtual chassis member already exists in position  {} . "" . format ( <TAB><TAB><TAB><TAB><TAB> vc_position <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return vc_position",if conflicting_members . exists ( ) :,if conflicting_members . exists ( ) :,100.0,100.00,True
3037,"def cal_pads ( auto_pad , pad_shape ) : <TAB> spatial_size = len ( pad_shape ) <TAB> pads = [ 0 ] * spatial_size * 2 <TAB> for i in range ( spatial_size ) : <TAB><TAB> if auto_pad == "" SAME_LOWER "" : <TAB><TAB><TAB> pads [ i + spatial_size ] = pad_shape [ i ] / / 2 <TAB><TAB><TAB> pads [ i ] = pad_shape [ i ] - pads [ i + spatial_size ] <TAB><TAB> <MASK> <TAB><TAB><TAB> pads [ i ] = pad_shape [ i ] / / 2 <TAB><TAB><TAB> pads [ i + spatial_size ] = pad_shape [ i ] - pads [ i ] <TAB> return pads","elif auto_pad == ""SAME_UPPER"" :","elif auto_pad == ""SAME_UPPER"" :",100.0,100.00,True
3038,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
3039,"def test_cwl_rnaseq ( self , install_test_files ) : <TAB> with install_cwl_test_files ( ) as work_dir : <TAB><TAB> with utils . chdir ( os . path . join ( work_dir , "" rnaseq "" ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> shutil . rmtree ( "" cromwell_work "" ) <TAB><TAB><TAB> subprocess . check_call ( <TAB><TAB><TAB><TAB> [ "" bcbio_vm.py "" , "" cwlrun "" , "" cromwell "" , "" rnaseq-workflow "" ] <TAB><TAB><TAB> )","if os . path . exists ( ""cromwell_work"" ) :","if os . path . exists ( ""cromwell_work"" ) :",100.0,100.00,True
3040,"def files_per_version ( self ) : <TAB> xpath = "" ./files/file "" <TAB> files = self . root . findall ( xpath ) <TAB> versions = { } <TAB> for file in files : <TAB><TAB> vfile = file . findall ( "" version "" ) <TAB><TAB> for version in vfile : <TAB><TAB><TAB> nb = version . attrib [ "" nb "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> versions [ nb ] = [ ] <TAB><TAB><TAB> versions [ nb ] . append ( file . attrib [ "" url "" ] ) <TAB> return versions",if not nb in versions :,if nb not in versions :,98.40808675322079,98.09,False
3041,"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB><TAB> return None <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" SQLite backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB> ) <TAB> return six . text_type ( value )",if settings . USE_TZ :,if USE_TZ :,98.02089016324993,97.80,False
3042,"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB><TAB> t = threading . current_thread ( ) <TAB><TAB> t . name = func . __name__ <TAB><TAB> try : <TAB><TAB><TAB> t . status = func ( * args , * * kwargs ) <TAB><TAB> except EscapeException as e : # user aborted <TAB><TAB><TAB> t . status = "" aborted by user "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> t . exception = e <TAB><TAB><TAB> t . status = "" exception "" <TAB><TAB><TAB> vd . exceptionCaught ( e ) <TAB><TAB> if t . sheet : <TAB><TAB><TAB> t . sheet . currentThreads . remove ( t )",if status :,if status :,100.0,100.00,True
3043,"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB><TAB> if name . lower ( ) in phrase : <TAB><TAB><TAB> dev = devid [ num ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ctrl = "" =ON "" <TAB><TAB><TAB><TAB> say ( "" Turning On  "" + name ) <TAB><TAB><TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB><TAB><TAB><TAB> ctrl = "" =OFF "" <TAB><TAB><TAB><TAB> say ( "" Turning Off  "" + name ) <TAB><TAB><TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False )","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :",100.0,100.00,True
3044,"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = { } <TAB> for _ , name , data_type , not_null , _ , primary_key in rows : <TAB><TAB> parts = [ data_type ] <TAB><TAB> <MASK> <TAB><TAB><TAB> parts . append ( "" PRIMARY KEY "" ) <TAB><TAB> if not_null : <TAB><TAB><TAB> parts . append ( "" NOT NULL "" ) <TAB><TAB> result [ name ] = ""   "" . join ( parts ) <TAB> return result",if primary_key :,if primary_key :,100.0,100.00,True
3045,"def _validate_forward_input ( x , n_in ) : <TAB> if n_in != 1 : <TAB><TAB> if not isinstance ( x , ( tuple , list ) ) : <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> f "" Expected input to be a tuple or list; instead got  { type ( x ) } . "" <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> f "" Input tuple length ( { len ( x ) } ) does not equal required  "" <TAB><TAB><TAB><TAB> f "" number of inputs ( { n_in } ). "" <TAB><TAB><TAB> )",if len ( x ) != n_in :,if len ( x ) != n_in :,100.0,100.00,True
3046,"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB> if isinstance ( val , compat . string_types ) : <TAB><TAB><TAB> return ""    %s "" % val <TAB><TAB> <MASK> <TAB><TAB><TAB> return ""    %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB> elif val < 1024 * * 3 : <TAB><TAB><TAB> return ""    %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB> else : <TAB><TAB><TAB> return ""    %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB><TAB> return str ( val ) <TAB> else : <TAB><TAB> return ""    %s "" % val",elif val < 1024 ** 2 :,elif val > 1024 * * 2 :,70.47586209994189,98.88,False
3047,"def get_path_name ( self ) : <TAB> if self . is_root ( ) : <TAB><TAB> return "" @ "" + self . name <TAB> else : <TAB><TAB> parent_name = self . parent . get_path_name ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" / "" . join ( [ parent_name , "" @ "" + self . name ] ) <TAB><TAB> else : <TAB><TAB><TAB> return "" @ "" + self . name",if parent_name :,if parent_name :,75.0,100.00,True
3048,"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB><TAB> elif k == "" created_at "" : <TAB><TAB><TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB><TAB> else : <TAB><TAB><TAB> setattr ( lst , k , v ) <TAB> return lst","if k == ""user"" :","if k == ""user"" :",100.0,100.00,True
3049,"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB><TAB> if not py_file . endswith ( "" .py "" ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> bytecode_files . append ( py_file + "" c "" ) <TAB><TAB> if self . optimize > 0 : <TAB><TAB><TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files",if self . compile :,if self . use_c :,98.23516358537607,96.81,False
3050,"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB><TAB> else : <TAB><TAB><TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB><TAB> if isinstance ( self . subheader , RenderedContent ) : <TAB><TAB><TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB><TAB> else : <TAB><TAB><TAB> d [ "" subheader "" ] = self . subheader <TAB> return d","if isinstance ( self . header , RenderedContent ) :","if isinstance ( self . header , RenderedContent ) :",100.0,100.00,True
3051,"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB><TAB> child = pathobj . child ( key ) <TAB><TAB> if isinstance ( value , bytes ) : <TAB><TAB><TAB> pathdict [ key ] = child <TAB><TAB><TAB> child . setContent ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> child . createDirectory ( ) <TAB><TAB><TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict","elif isinstance ( value , dict ) :","elif isinstance ( value , dict ) :",100.0,100.00,True
3052,"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> if type ( value ) == list : <TAB><TAB><TAB><TAB> value = value [ - 1 ] <TAB><TAB> picker . SetPath ( value ) <TAB><TAB> return True <TAB> return False","if issubclass ( picker . __class__ , wx . FileDialog ) :",if value :,89.89914304708611,87.53,False
3053,"def recv ( self , buffer_size ) : <TAB> try : <TAB><TAB> return super ( SSLConnection , self ) . recv ( buffer_size ) <TAB> except ssl . SSLError as err : <TAB><TAB> <MASK> <TAB><TAB><TAB> return b "" "" <TAB><TAB> if err . args [ 0 ] in ( ssl . SSL_ERROR_EOF , ssl . SSL_ERROR_ZERO_RETURN ) : <TAB><TAB><TAB> self . handle_close ( ) <TAB><TAB><TAB> return b "" "" <TAB><TAB> raise","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",if err . args [ 0 ] == ssl . SSL_ERROR_NO_SOCKET :,64.99316052619375,88.28,False
3054,"def IncrementErrorCount ( self , category ) : <TAB> """"""Bumps the module's error statistic."""""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> category = category . split ( "" / "" ) [ 0 ] <TAB><TAB> if category not in self . errors_by_category : <TAB><TAB><TAB> self . errors_by_category [ category ] = 0 <TAB><TAB> self . errors_by_category [ category ] + = 1","if self . counting != ""detailed"" :","if ""/"" in category :",69.60887498944273,93.84,False
3055,"def _get_y ( self , data_inst ) : <TAB> if self . stratified : <TAB><TAB> y = [ v for i , v in data_inst . mapValues ( lambda v : v . label ) . collect ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> y = self . transform_regression_label ( data_inst ) <TAB> else : <TAB><TAB> # make dummy y <TAB><TAB> y = [ 0 ] * ( data_inst . count ( ) ) <TAB> return y",if self . need_transform :,if self . transform_regression_label :,98.4134367795711,95.41,False
3056,"def test_all_project_files ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB><TAB> # XXX something with newlines goes wrong on Windows. <TAB><TAB> return <TAB> for filepath in support . all_project_files ( ) : <TAB><TAB> with open ( filepath , "" rb "" ) as fp : <TAB><TAB><TAB> encoding = tokenize . detect_encoding ( fp . readline ) [ 0 ] <TAB><TAB> self . assertIsNotNone ( encoding , "" can ' t detect encoding for  %s "" % filepath ) <TAB><TAB> with open ( filepath , "" r "" ) as fp : <TAB><TAB><TAB> source = fp . read ( ) <TAB><TAB><TAB> source = source . decode ( encoding ) <TAB><TAB> tree = driver . parse_string ( source ) <TAB><TAB> new = unicode ( tree ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . fail ( "" Idempotency failed:  %s "" % filepath )","if diff ( filepath , new , encoding ) :",if not driver . detect_encoding ( new ) :,97.4659059018218,96.50,False
3057,"def test_resource_arn_override_generator ( self ) : <TAB> overrides = set ( ) <TAB> for k , v in manager . resources . items ( ) : <TAB><TAB> arn_gen = bool ( v . __dict__ . get ( "" get_arns "" ) or v . __dict__ . get ( "" generate_arn "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> overrides . add ( k ) <TAB> overrides = overrides . difference ( <TAB><TAB> { <TAB><TAB><TAB> "" account "" , <TAB><TAB><TAB> "" s3 "" , <TAB><TAB><TAB> "" hostedzone "" , <TAB><TAB><TAB> "" log-group "" , <TAB><TAB><TAB> "" rest-api "" , <TAB><TAB><TAB> "" redshift-snapshot "" , <TAB><TAB><TAB> "" rest-stage "" , <TAB><TAB> } <TAB> ) <TAB> if overrides : <TAB><TAB> raise ValueError ( "" unknown arn overrides in  %s "" % ( "" ,  "" . join ( overrides ) ) )",if arn_gen :,if arn_gen :,100.0,100.00,True
3058,"def _check_dsl_runner ( self ) - > None : <TAB> """"""Checks if runner in dsl is Kubeflow V2 runner."""""" <TAB> with open ( self . flags_dict [ labels . PIPELINE_DSL_PATH ] , "" r "" ) as f : <TAB><TAB> dsl_contents = f . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" KubeflowV2DagRunner not found in dsl. "" )","if ""KubeflowV2DagRunner"" not in dsl_contents :",if not dsl_contents :,65.14085411807483,94.36,False
3059,"def create_warehouse ( warehouse_name , properties = None , company = None ) : <TAB> if not company : <TAB><TAB> company = "" _Test Company "" <TAB> warehouse_id = erpnext . encode_company_abbr ( warehouse_name , company ) <TAB> if not frappe . db . exists ( "" Warehouse "" , warehouse_id ) : <TAB><TAB> warehouse = frappe . new_doc ( "" Warehouse "" ) <TAB><TAB> warehouse . warehouse_name = warehouse_name <TAB><TAB> warehouse . parent_warehouse = "" All Warehouses - _TCUV "" <TAB><TAB> warehouse . company = company <TAB><TAB> warehouse . account = get_warehouse_account ( warehouse_name , company ) <TAB><TAB> <MASK> <TAB><TAB><TAB> warehouse . update ( properties ) <TAB><TAB> warehouse . save ( ) <TAB><TAB> return warehouse . name <TAB> else : <TAB><TAB> return warehouse_id",if properties :,if properties :,100.0,100.00,True
3060,"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB><TAB> if not len ( line . strip ( ) ) : <TAB><TAB><TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB><TAB><TAB> continue <TAB><TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB><TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB><TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries",if not len ( head ) :,"if head in [ ""all"" , ""hostname"" ] :",69.44049131981626,95.03,False
3061,"def _get_omega ( self ) : <TAB> if self . _omega is None : <TAB><TAB> n = self . get_drift_dim ( ) / / 2 <TAB><TAB> omg = sympl . calc_omega ( n ) <TAB><TAB> if self . oper_dtype == Qobj : <TAB><TAB><TAB> self . _omega = Qobj ( omg , dims = self . dyn_dims ) <TAB><TAB><TAB> self . _omega_qobj = self . _omega <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _omega = sp . csr_matrix ( omg ) <TAB><TAB> else : <TAB><TAB><TAB> self . _omega = omg <TAB> return self . _omega",elif self . oper_dtype == sp . csr_matrix :,elif self . oper_dtype == sp . csr_matrix :,100.0,100.00,True
3062,"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB><TAB> for k , v in data . items ( ) : <TAB><TAB><TAB> if k == key : <TAB><TAB><TAB><TAB> return v <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> out = get_in_inputs ( key , v ) <TAB><TAB><TAB><TAB> if out : <TAB><TAB><TAB><TAB><TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB><TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB><TAB> out = [ x for x in out if x ] <TAB><TAB> if out : <TAB><TAB><TAB> return out [ 0 ]","elif isinstance ( v , ( list , tuple , dict ) ) :","if isinstance ( v , ( list , tuple ) ) :",76.41401086550697,97.33,False
3063,def visit_binary ( binary ) : <TAB> if binary . operator == operators . eq : <TAB><TAB> cols = util . column_set ( chain ( * [ c . proxy_set for c in columns . difference ( omit ) ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for c in reversed ( columns ) : <TAB><TAB><TAB><TAB> if c . shares_lineage ( binary . right ) and ( <TAB><TAB><TAB><TAB><TAB> not only_synonyms or c . name == binary . left . name <TAB><TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB><TAB> omit . add ( c ) <TAB><TAB><TAB><TAB><TAB> break,if binary . left in cols and binary . right in cols :,if len ( cols ) > 1 :,85.21716034553364,93.75,False
3064,"def wait_tasks_or_abort ( futures , timeout = 60 , kill_switch_ev = None ) : <TAB> try : <TAB><TAB> LazySingletonTasksCoordinator . wait_tasks ( <TAB><TAB><TAB> futures , return_when = FIRST_EXCEPTION , raise_exceptions = True <TAB><TAB> ) <TAB> except Exception as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB><TAB><TAB> kill_switch_ev . set ( ) <TAB><TAB><TAB> LazySingletonTasksCoordinator . wait_tasks ( <TAB><TAB><TAB><TAB> futures , <TAB><TAB><TAB><TAB> return_when = ALL_COMPLETED , <TAB><TAB><TAB><TAB> raise_exceptions = False , <TAB><TAB><TAB><TAB> timeout = timeout , <TAB><TAB><TAB> ) <TAB><TAB> raise e",if kill_switch_ev is not None :,if kill_switch_ev is not None :,100.0,100.00,True
3065,"def is_valid ( sample ) : <TAB> if sample is None : <TAB><TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB><TAB> for s in sample : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB><TAB><TAB><TAB> return False <TAB> return True",if s is None :,"if isinstance ( s , ( list , tuple ) ) and s . size != 0 :",67.39895091615328,89.53,False
3066,"def setVaName ( self , va , parent = None ) : <TAB> if parent is None : <TAB><TAB> parent = self <TAB> curname = self . vw . getName ( va ) <TAB> if curname is None : <TAB><TAB> curname = "" "" <TAB> name , ok = QInputDialog . getText ( parent , "" Enter... "" , "" Name "" , text = curname ) <TAB> if ok : <TAB><TAB> name = str ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Duplicate Name:  %s "" % name ) <TAB><TAB> self . vw . makeName ( va , name )",if self . vw . vaByName ( name ) :,if name in self . vw . names :,69.52277025434019,95.72,False
3067,"def generic_tag_compiler ( params , defaults , name , node_class , parser , token ) : <TAB> "" Returns a template.Node subclass. "" <TAB> bits = token . split_contents ( ) [ 1 : ] <TAB> bmax = len ( params ) <TAB> def_len = defaults and len ( defaults ) or 0 <TAB> bmin = bmax - def_len <TAB> if len ( bits ) < bmin or len ( bits ) > bmax : <TAB><TAB> <MASK> <TAB><TAB><TAB> message = "" %s  takes  %s  arguments "" % ( name , bmin ) <TAB><TAB> else : <TAB><TAB><TAB> message = "" %s  takes between  %s  and  %s  arguments "" % ( name , bmin , bmax ) <TAB><TAB> raise TemplateSyntaxError ( message ) <TAB> return node_class ( bits )",if bmin == bmax :,if bmin < def_len :,89.16482076610858,97.22,False
3068,"def extract_segmentation_mask ( annotation ) : <TAB> poly_specs = annotation [ DensePoseDataRelative . S_KEY ] <TAB> if isinstance ( poly_specs , torch . Tensor ) : <TAB><TAB> # data is already given as mask tensors, no need to decode <TAB><TAB> return poly_specs <TAB> import pycocotools . mask as mask_utils <TAB> segm = torch . zeros ( ( DensePoseDataRelative . MASK_SIZE , ) * 2 , dtype = torch . float32 ) <TAB> for i in range ( DensePoseDataRelative . N_BODY_PARTS ) : <TAB><TAB> poly_i = poly_specs [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> mask_i = mask_utils . decode ( poly_i ) <TAB><TAB><TAB> segm [ mask_i > 0 ] = i + 1 <TAB> return segm",if poly_i :,"if isinstance ( poly_i , str ) :",97.98150067677929,96.04,False
3069,"def module_list ( target , fast ) : <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB><TAB> module_name , ext = os . path . splitext ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB><TAB><TAB><TAB> if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) : <TAB><TAB><TAB><TAB><TAB> modules . append ( module_name ) <TAB> return set ( modules )","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :","if ext == "".py"" :",60.53779459566111,88.07,False
3070,"def filelist_from_patterns ( pats , rootdir = None ) : <TAB> if rootdir is None : <TAB><TAB> rootdir = "" . "" <TAB> # filelist = [] <TAB> fileset = set ( [ ] ) <TAB> lines = [ line . strip ( ) for line in pats ] <TAB> for line in lines : <TAB><TAB> pat = line [ 2 : ] <TAB><TAB> newfiles = glob ( osp . join ( rootdir , pat ) ) <TAB><TAB> if line . startswith ( "" + "" ) : <TAB><TAB><TAB> fileset . update ( newfiles ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fileset . difference_update ( newfiles ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" line must start with + or - "" ) <TAB> filelist = list ( fileset ) <TAB> return filelist","elif line . startswith ( ""-"" ) :","elif line . startswith ( ""-"" ) :",100.0,100.00,True
3071,"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ] # type: List[V1EventTrigger] <TAB> for e in events : <TAB><TAB> entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB><TAB> if not entity_ref : <TAB><TAB><TAB> continue <TAB><TAB> if entity_ref not in statuses_by_refs : <TAB><TAB><TAB> continue <TAB><TAB> for kind in e . kinds : <TAB><TAB><TAB> status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> statuses_by_refs [ entity_ref ] . append ( status ) <TAB> return statuses_by_refs",if status :,if status :,100.0,100.00,True
3072,"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB><TAB> info , reference = value <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB><TAB><TAB> self . _infos . append ( info ) <TAB><TAB> if reference not in self . _reverse_references : <TAB><TAB><TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB><TAB><TAB> self . _references . append ( reference ) <TAB><TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB><TAB><TAB> self . _reverse_infos [ info ] , <TAB><TAB><TAB> self . _reverse_references [ reference ] , <TAB><TAB> ) <TAB> else : <TAB><TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) )",if info not in self . _reverse_infos :,if info not in self . _reverse_infos :,100.0,100.00,True
3073,"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB><TAB> <MASK> <TAB><TAB><TAB> if combo . GetLabel ( ) == "" TR_VIRTUAL "" : <TAB><TAB><TAB><TAB> style = style | HTL . TR_VIRTUAL <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB><TAB> self . SetAGWWindowStyleFlag ( style )",if combo . GetValue ( ) == 1 :,"if combo . GetLabel ( ) != ""STYLE"" :",95.97975496217786,95.95,False
3074,"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB><TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB><TAB><TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . _CSRFtoken = c . strip ( ""   \r \n "" ) <TAB><TAB><TAB><TAB><TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if self . _CSRFtoken != None : <TAB><TAB><TAB><TAB> break","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :","if c . startswith ( ""CSRF:"" ) :",87.95520190242078,96.44,False
3075,"def test_page_size_matching_max_returned_rows ( <TAB> app_client_returned_rows_matches_page_size , ) : <TAB> fetched = [ ] <TAB> path = "" /fixtures/no_primary_key.json "" <TAB> while path : <TAB><TAB> response = app_client_returned_rows_matches_page_size . get ( path ) <TAB><TAB> fetched . extend ( response . json [ "" rows "" ] ) <TAB><TAB> assert len ( response . json [ "" rows "" ] ) in ( 1 , 50 ) <TAB><TAB> path = response . json [ "" next_url "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> path = path . replace ( "" http://localhost "" , "" "" ) <TAB> assert 201 == len ( fetched )",if path :,"if path . startswith ( ""http://"" ) :",73.22799442337737,94.40,False
3076,"def get_mapping_exception_message ( mappings : List [ Tuple [ Text , Text ] ] ) : <TAB> """"""Return a message given a list of duplicates."""""" <TAB> message = "" "" <TAB> for name , action_name in mappings : <TAB><TAB> <MASK> <TAB><TAB><TAB> message + = "" \n "" <TAB><TAB> message + = ( <TAB><TAB><TAB> "" Intent  ' {} '  is set to trigger action  ' {} ' , which is  "" <TAB><TAB><TAB> "" not defined in the domain. "" . format ( name , action_name ) <TAB><TAB> ) <TAB> return message",if message :,if message :,100.0,100.00,True
3077,def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB><TAB> if re_han . match ( blk ) : <TAB><TAB><TAB> for word in __cut ( blk ) : <TAB><TAB><TAB><TAB> if word not in Force_Split_Words : <TAB><TAB><TAB><TAB><TAB> yield word <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> for c in word : <TAB><TAB><TAB><TAB><TAB><TAB> yield c <TAB><TAB> else : <TAB><TAB><TAB> tmp = re_skip . split ( blk ) <TAB><TAB><TAB> for x in tmp : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> yield x,if x :,if x not in Force_Split_Words :,97.30128929203778,96.49,False
3078,"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB><TAB> if - delta < expr . get_float_value ( ) < delta : <TAB><TAB><TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB><TAB> real , imag = expr . real , expr . imag <TAB><TAB> if - delta < real . get_float_value ( ) < delta : <TAB><TAB><TAB> real = Integer ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> imag = Integer ( 0 ) <TAB><TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB><TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr",if - delta < imag . get_float_value ( ) < delta :,if - delta < imag . get_float_value ( ) < delta :,100.0,100.00,True
3079,"def make_row ( self ) : <TAB> res = [ ] <TAB> for i in range ( self . num_cols ) : <TAB><TAB> t = sqlite3_column_type ( self . stmnt , i ) <TAB><TAB> # print(""type"", t) <TAB><TAB> if t == SQLITE_INTEGER : <TAB><TAB><TAB> res . append ( sqlite3_column_int ( self . stmnt , i ) ) <TAB><TAB> elif t == SQLITE_FLOAT : <TAB><TAB><TAB> res . append ( sqlite3_column_double ( self . stmnt , i ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> res . append ( sqlite3_column_text ( self . stmnt , i ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError <TAB> return tuple ( res )",elif t == SQLITE_TEXT :,elif t == SQLITE_TEXT :,100.0,100.00,True
3080,"def try_convert ( self , string ) : <TAB> string = string . strip ( ) <TAB> try : <TAB><TAB> return int ( string ) <TAB> except : <TAB><TAB> try : <TAB><TAB><TAB> return float ( string ) <TAB><TAB> except : <TAB><TAB><TAB> if string == "" True "" : <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> return string","if string == ""False"" :","if string == ""False"" :",100.0,100.00,True
3081,"def configure_create_table_epilogue ( store ) : <TAB> for val in [ "" "" , ""  ENGINE=InnoDB "" ] : <TAB><TAB> store . config [ "" create_table_epilogue "" ] = val <TAB><TAB> store . _set_sql_flavour ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> store . log . info ( "" create_table_epilogue= ' %s ' "" , val ) <TAB><TAB><TAB> return <TAB> raise Exception ( "" Can not create a transactional table. "" )",if store . _test_transaction ( ) :,if store . _create_transactional_table ( ) :,98.30307939815681,95.44,False
3082,"def _check_rule ( self , match , target_dict , cred_dict ) : <TAB> """"""Recursively checks credentials based on the brains rules."""""" <TAB> try : <TAB><TAB> new_match_list = self . rules [ match ] <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_match_list = ( "" rule: %s "" % self . default_rule , ) <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> return self . check ( new_match_list , target_dict , cred_dict )",if self . default_rule and match != self . default_rule :,if self . default_rule :,84.90133198786708,94.18,False
3083,"def get_civil_names ( self ) : <TAB> congresspeople_ids = self . get_all_congresspeople_ids ( ) <TAB> for i , congress_id in enumerate ( congresspeople_ids ) : <TAB><TAB> if not np . math . isnan ( float ( congress_id ) ) : <TAB><TAB><TAB> percentage = i / self . total * 100 <TAB><TAB><TAB> msg = "" Processed  {}  out of  {}  ( {:.2f} % ) "" <TAB><TAB><TAB> print ( msg . format ( i , self . total , percentage ) , end = "" \r "" ) <TAB><TAB><TAB> data = self . fetch_data_repository ( congress_id ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield dict ( data )",if data is not None :,if data :,78.20587156962678,97.72,False
3084,"def parse_network_whitelist ( self , network_whitelist_location ) : <TAB> networks = [ ] <TAB> with open ( network_whitelist_location , "" r "" ) as text_file : <TAB><TAB> for line in text_file : <TAB><TAB><TAB> line = line . strip ( ) . strip ( "" ' "" ) . strip ( ' "" ' ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> networks . append ( line ) <TAB> return networks",if isIPv4 ( line ) or isIPv6 ( line ) :,if line :,76.65560977966565,91.89,False
3085,"def _pick ( self , cum ) : <TAB> if self . _isleaf ( ) : <TAB><TAB> return self . bd [ 0 ] , self . s <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . left . _pick ( cum ) <TAB><TAB> else : <TAB><TAB><TAB> return self . right . _pick ( cum - self . left . s )",if cum < self . left . s :,if cum < self . left . s :,75.0,100.00,True
3086,"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB><TAB> if len ( value ) not in ( 2 , 3 ) : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" When setting content_range to a list/tuple, it must  "" <TAB><TAB><TAB><TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> begin , end = value <TAB><TAB><TAB> length = None <TAB><TAB> else : <TAB><TAB><TAB> begin , end , length = value <TAB><TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB><TAB> return None <TAB> return value",if len ( value ) == 2 :,if len ( value ) == 2 :,100.0,100.00,True
3087,"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> fields [ k ] = v <TAB><TAB><TAB> continue <TAB><TAB> if k == "" full_title "" : <TAB><TAB><TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :","if k . startswith ( ""name"" ) :",89.86333277156342,89.64,False
3088,"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB><TAB> trans_len = len ( translation ) <TAB><TAB> ind = np . random . randint ( trans_len ) <TAB><TAB> action = np . random . choice ( actions ) <TAB><TAB> if action == "" deletion "" : <TAB><TAB><TAB> del translation [ ind ] <TAB><TAB> <MASK> <TAB><TAB><TAB> ind_rep = np . random . randint ( trans_len ) <TAB><TAB><TAB> translation [ ind ] = translation [ ind_rep ] <TAB><TAB> else : <TAB><TAB><TAB> ind_insert = np . random . randint ( trans_len ) <TAB><TAB><TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation","elif action == ""replacement"" :","elif action == ""insert"" :",99.0670064538266,98.94,False
3089,"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB><TAB> if t == "" tacotron "" : <TAB><TAB><TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB><TAB> elif t == "" jaconv "" : <TAB><TAB><TAB> text = jaconv . normalize ( text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if vietnamese_cleaners is None : <TAB><TAB><TAB><TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB><TAB><TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB><TAB> else : <TAB><TAB><TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text","elif t == ""vietnamese"" :","elif t == ""vier_namese_cleaner"" :",98.83620632734545,96.91,False
3090,"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB><TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB><TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB><TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB><TAB> if read_len < len ( var ) : <TAB><TAB><TAB> return EFI_BUFFER_TOO_SMALL <TAB><TAB> if params [ "" Data "" ] != 0 : <TAB><TAB><TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB><TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND","if params [ ""Attributes"" ] != 0 :",if read_len == 0 :,69.91461110681777,96.23,False
3091,"def test_setupapp ( self , overrideRootMenu ) : <TAB> "" Call setupApp with each possible graphics type. "" <TAB> root = self . root <TAB> flist = FileList ( root ) <TAB> for tktype in alltypes : <TAB><TAB> with self . subTest ( tktype = tktype ) : <TAB><TAB><TAB> macosx . _tk_type = tktype <TAB><TAB><TAB> macosx . setupApp ( root , flist ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertTrue ( overrideRootMenu . called ) <TAB><TAB><TAB> overrideRootMenu . reset_mock ( )","if tktype in ( ""carbon"" , ""cocoa"" ) :",if overrideRootMenu :,83.83808010644086,91.76,False
3092,"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB><TAB> self . __storage ( None ) , <TAB><TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB><TAB> for b in s : <TAB><TAB><TAB> if persistent is not None and b . persistent != persistent : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if b . name not in u : <TAB><TAB><TAB><TAB> result . append ( b . name ) <TAB><TAB><TAB><TAB> u . add ( b . name ) <TAB> return result","if b . name . startswith ( ""__"" ) :",if b . name in u :,94.8364723321006,95.51,False
3093,"def _check_extra_specs ( key , value = None ) : <TAB> extra_specs = diff . get ( "" extra_specs "" ) <TAB> specific_type = extra_specs . get ( key ) if extra_specs else None <TAB> old_type = None <TAB> new_type = None <TAB> if specific_type : <TAB><TAB> old_type , new_type = specific_type <TAB><TAB> <MASK> <TAB><TAB><TAB> old_type = True if old_type and old_type . upper ( ) == value else False <TAB><TAB><TAB> new_type = True if new_type and new_type . upper ( ) == value else False <TAB> return old_type , new_type",if value :,if value :,100.0,100.00,True
3094,"def _write_lock_file ( self , repo , force = True ) : # type: (Repository, bool) -> None <TAB> if force or ( self . _update and self . _write_lock ) : <TAB><TAB> updated_lock = self . _locker . set_lock_data ( self . _package , repo . packages ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _io . write_line ( "" "" ) <TAB><TAB><TAB> self . _io . write_line ( "" <info>Writing lock file</> "" )",if updated_lock :,if updated_lock :,100.0,100.00,True
3095,"def process_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" : <TAB><TAB> batch_shape = msg [ "" fn "" ] . batch_shape <TAB><TAB> <MASK> <TAB><TAB><TAB> batch_shape = [ 1 ] * ( - self . dim - len ( batch_shape ) ) + list ( batch_shape ) <TAB><TAB><TAB> batch_shape [ self . dim ] = self . size <TAB><TAB><TAB> msg [ "" fn "" ] = msg [ "" fn "" ] . expand ( torch . Size ( batch_shape ) )",if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,if self . dim :,68.65202542660057,84.50,False
3096,"def _test_reducibility ( self ) : <TAB> # make a copy of the graph <TAB> graph = networkx . DiGraph ( self . _graph ) <TAB> # preprocess: make it a super graph <TAB> self . _make_supergraph ( graph ) <TAB> while True : <TAB><TAB> changed = False <TAB><TAB> # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB><TAB> changed | = self . _remove_self_loop ( graph ) <TAB><TAB> # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB><TAB> # MultiNode) <TAB><TAB> changed | = self . _merge_single_entry_node ( graph ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # a fixed-point is reached <TAB><TAB><TAB> break",if not changed :,if changed :,73.85220041711628,98.81,False
3097,"def __init__ ( self , roberta , num_classes = 2 , dropout = 0.0 , prefix = None , params = None ) : <TAB> super ( RoBERTaClassifier , self ) . __init__ ( prefix = prefix , params = params ) <TAB> self . roberta = roberta <TAB> self . _units = roberta . _units <TAB> with self . name_scope ( ) : <TAB><TAB> self . classifier = nn . HybridSequential ( prefix = prefix ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB><TAB> self . classifier . add ( nn . Dense ( units = self . _units , activation = "" tanh "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB><TAB> self . classifier . add ( nn . Dense ( units = num_classes ) )",if dropout :,if self . _units is not None :,75.33590396154904,92.71,False
3098,"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB><TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB><TAB> if not o . name : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> return o <TAB> if check_symlinks : <TAB><TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB><TAB> if m : <TAB><TAB><TAB> name = m [ 0 ] <TAB><TAB> return self . get_object_from_name ( name , False )",if o . name . lower ( ) == name . lower ( ) :,if name == o . name :,93.72517797360494,93.67,False
3099,"def __call__ ( self ) : <TAB> """"""Run all check_* methods."""""" <TAB> if self . on : <TAB><TAB> oldformatwarning = warnings . formatwarning <TAB><TAB> warnings . formatwarning = self . formatwarning <TAB><TAB> try : <TAB><TAB><TAB> for name in dir ( self ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> method = getattr ( self , name ) <TAB><TAB><TAB><TAB><TAB> if method and callable ( method ) : <TAB><TAB><TAB><TAB><TAB><TAB> method ( ) <TAB><TAB> finally : <TAB><TAB><TAB> warnings . formatwarning = oldformatwarning","if name . startswith ( ""check_"" ) :","if name . startswith ( ""_"" ) :",98.47370684265914,98.71,False
3100,"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB><TAB> print_func = str <TAB> else : <TAB><TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB><TAB> value = getattr ( self , k ) <TAB><TAB> if not defaults and value == default_values [ k ] : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> print_func = repr # keep quotes around strings <TAB><TAB> pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB> if pieces or self . __base__ : <TAB><TAB> return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB> else : <TAB><TAB> return "" ""","if isinstance ( value , basestring ) :","if not isinstance ( value , ( str , unicode ) ) :",78.27234724414362,96.52,False
3101,"def apply ( self , * * kwargs : Any ) - > None : <TAB> for node in self . document . traverse ( nodes . target ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if ( <TAB><TAB><TAB> "" ismod "" in node <TAB><TAB><TAB> and node . parent . __class__ is nodes . section <TAB><TAB><TAB> and <TAB><TAB><TAB> # index 0 is the section title node <TAB><TAB><TAB> node . parent . index ( node ) == 1 <TAB><TAB> ) : <TAB><TAB><TAB> node . parent [ "" ids "" ] [ 0 : 0 ] = node [ "" ids "" ] <TAB><TAB><TAB> node . parent . remove ( node )","if not node [ ""ids"" ] :",if not node . parent :,95.35892449209784,96.77,False
3102,"def add_special_token_2d ( <TAB> values : List [ List [ int ] ] , special_token : int = 0 , use_first_value : bool = False ) - > List [ List [ int ] ] : <TAB> results = torch . jit . annotate ( List [ List [ int ] ] , [ ] ) <TAB> for value in values : <TAB><TAB> result = torch . jit . annotate ( List [ int ] , [ ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> special_token = value [ 0 ] <TAB><TAB> result . append ( special_token ) <TAB><TAB> result . extend ( value ) <TAB><TAB> result . append ( special_token ) <TAB><TAB> results . append ( result ) <TAB> return results",if use_first_value and len ( value ) > 0 :,if use_first_value :,80.97356115832538,95.59,False
3103,"def test_import ( self ) : <TAB> TIMEOUT = 5 <TAB> # Test for a deadlock when importing a module that runs the <TAB> # ThreadedResolver at import-time. See resolve_test.py for <TAB> # full explanation. <TAB> command = [ sys . executable , "" -c "" , "" import tornado.test.resolve_test_helper "" ] <TAB> start = time . time ( ) <TAB> popen = Popen ( command , preexec_fn = lambda : signal . alarm ( TIMEOUT ) ) <TAB> while time . time ( ) - start < TIMEOUT : <TAB><TAB> return_code = popen . poll ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( 0 , return_code ) <TAB><TAB><TAB> return # Success. <TAB><TAB> time . sleep ( 0.05 ) <TAB> self . fail ( "" import timed out "" )",if return_code is not None :,if return_code :,97.9457642826811,97.84,False
3104,"def find_item_for_key ( self , e ) : <TAB> for item in self . _items : <TAB><TAB> if item . keycode == e . key and item . shift == e . shift and item . alt == e . alt : <TAB><TAB><TAB> focus = get_focus ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . _items . index ( item ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return - 1 <TAB> return - 1","if self . command_is_enabled ( item , focus ) :",if focus == item . keycode :,66.12158373421302,91.47,False
3105,"def check_app_config_brackets ( self ) : <TAB> for sn , app in cherrypy . tree . apps . items ( ) : <TAB><TAB> if not isinstance ( app , cherrypy . Application ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for key in app . config . keys ( ) : <TAB><TAB><TAB> if key . startswith ( "" [ "" ) or key . endswith ( "" ] "" ) : <TAB><TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB><TAB> "" The application mounted at  %r  has config  "" <TAB><TAB><TAB><TAB><TAB> "" section names with extraneous brackets:  %r .  "" <TAB><TAB><TAB><TAB><TAB> "" Config *files* need brackets; config *dicts*  "" <TAB><TAB><TAB><TAB><TAB> "" (e.g. passed to tree.mount) do not. "" % ( sn , key ) <TAB><TAB><TAB><TAB> )",if not app . config :,if not app . config :,100.0,100.00,True
3106,"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB><TAB> # Do like the linkify will do after.... <TAB><TAB> for m in getattr ( a , "" modules "" , [ ] ) : <TAB><TAB><TAB> # So look at what the arbiter try to call as module <TAB><TAB><TAB> m = m . strip ( ) <TAB><TAB><TAB> # Ok, now look in modules... <TAB><TAB><TAB> for mod in self . modules : <TAB><TAB><TAB><TAB> # try to see if this module is the good type <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> # if so, the good name? <TAB><TAB><TAB><TAB><TAB> if getattr ( mod , "" module_name "" , "" "" ) . strip ( ) == m : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",if mod_type == mod . strip ( ) :,94.88571864293482,92.68,False
3107,"def write_config_to_file ( self , folder , filename , config ) : <TAB> do_not_write = [ "" hyperparameter_search_space_updates "" ] <TAB> with open ( os . path . join ( folder , filename ) , "" w "" ) as f : <TAB><TAB> f . write ( <TAB><TAB><TAB> "" \n "" . join ( <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> ( key + "" = "" + str ( value ) ) <TAB><TAB><TAB><TAB><TAB> for ( key , value ) in sorted ( config . items ( ) , key = lambda x : x [ 0 ] ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ] <TAB><TAB><TAB> ) <TAB><TAB> )",if not key in do_not_write,if key not in do_not_write,97.44145224299224,98.63,False
3108,"def parsing ( self , parsing ) : # type: (bool) -> None <TAB> self . _parsed = parsing <TAB> for k , v in self . _body : <TAB><TAB> <MASK> <TAB><TAB><TAB> v . value . parsing ( parsing ) <TAB><TAB> elif isinstance ( v , AoT ) : <TAB><TAB><TAB> for t in v . body : <TAB><TAB><TAB><TAB> t . value . parsing ( parsing )","if isinstance ( v , Table ) :","if isinstance ( v , AoT ) :",98.257772888946,97.88,False
3109,"def test_crashers_crash ( self ) : <TAB> for fname in glob . glob ( CRASHER_FILES ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # Some ""crashers"" only trigger an exception rather than a <TAB><TAB> # segfault. Consider that an acceptable outcome. <TAB><TAB> if test . support . verbose : <TAB><TAB><TAB> print ( "" Checking crasher: "" , fname ) <TAB><TAB> assert_python_failure ( fname )",if os . path . basename ( fname ) in infinite_loops :,"if not fname . endswith ( "".py"" ) :",81.4778696555005,90.71,False
3110,"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB><TAB> if k . step is not None : <TAB><TAB><TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB><TAB> elif k . start is None : <TAB><TAB><TAB> raise ValueError ( "" Must specify start index "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB><TAB> else : <TAB><TAB><TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB><TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB><TAB> addr = k <TAB> return self . _deeper ( addr = addr )",elif k . stop is not None :,elif k . stop is not None :,100.0,100.00,True
3111,"def get_lowest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB><TAB> <MASK> <TAB><TAB><TAB> lowest_wall = j [ "" wall_time "" ] <TAB><TAB> if lowest_wall > j [ "" wall_time "" ] : <TAB><TAB><TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall",if lowest_wall is None :,if lowest_wall is None :,100.0,100.00,True
3112,"def extract_wav_headers ( data ) : <TAB> # def search_subchunk(data, subchunk_id): <TAB> pos = 12 # The size of the RIFF chunk descriptor <TAB> subchunks = [ ] <TAB> while pos + 8 < = len ( data ) and len ( subchunks ) < 10 : <TAB><TAB> subchunk_id = data [ pos : pos + 4 ] <TAB><TAB> subchunk_size = struct . unpack_from ( "" <I "" , data [ pos + 4 : pos + 8 ] ) [ 0 ] <TAB><TAB> subchunks . append ( WavSubChunk ( subchunk_id , pos , subchunk_size ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # 'data' is the last subchunk <TAB><TAB><TAB> break <TAB><TAB> pos + = subchunk_size + 8 <TAB> return subchunks","if subchunk_id == b""data"" :",if subchunk_size == 0 :,73.24754525573547,96.18,False
3113,"def _any_targets_have_native_sources ( self , targets ) : <TAB> # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB> # platform-specific packages (maybe find the platforms there too?). <TAB> for tgt in targets : <TAB><TAB> for type_constraint , target_predicate in self . _native_target_matchers . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False",if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,if tgt . _type_constraint == type_constraint :,66.74565087791815,88.17,False
3114,"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB><TAB> if v is None : # use NoneType to unset a value <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB> if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB><TAB><TAB> raise serializers . ValidationError ( <TAB><TAB><TAB><TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB> ) <TAB> return value","if not re . match ( PROCTYPE_MATCH , k ) :","if not re . match ( PERFORM_MATCH , str ( k ) ) :",72.43840308395649,95.87,False
3115,"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB><TAB> return False <TAB> for digit in reversed ( number ) : <TAB><TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB><TAB> if even : <TAB><TAB><TAB> digit * = 2 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> digit = digit % 10 + digit / / 10 <TAB><TAB> digits . append ( digit ) <TAB><TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False",if digit >= 10 :,if digit % 10 == 0 :,77.7486253980864,96.55,False
3116,"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB><TAB> ctype , line , col , char = cmd <TAB><TAB> if ctype == "" D "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB><TAB><TAB><TAB> del buf [ line + 1 ] <TAB><TAB> elif ctype == "" I "" : <TAB><TAB><TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB><TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf )","if char != ""\n"" :",if line + 1 < len ( buf ) :,95.96477733012553,96.32,False
3117,"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { } # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self . edges : <TAB><TAB> if edge . is_dangling ( ) : <TAB><TAB><TAB> raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB><TAB> if self . _is_my_trace ( edge ) : <TAB><TAB><TAB> continue <TAB><TAB> partner_node , shared_axis = self . _get_partner ( edge ) <TAB><TAB> <MASK> <TAB><TAB><TAB> partners [ partner_node ] = set ( ) <TAB><TAB> partners [ partner_node ] . add ( shared_axis ) <TAB> return partners",if partner_node not in partners :,if partner_node not in partners :,75.0,100.00,True
3118,"def _bind_interactive_rez ( self ) : <TAB> if config . set_prompt and self . settings . prompt : <TAB><TAB> stored_prompt = os . getenv ( "" REZ_STORED_PROMPT_CMD "" ) <TAB><TAB> curr_prompt = stored_prompt or os . getenv ( "" PROMPT "" , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . setenv ( "" REZ_STORED_PROMPT_CMD "" , curr_prompt ) <TAB><TAB> new_prompt = "" %% REZ_ENV_PROMPT %% "" <TAB><TAB> new_prompt = ( <TAB><TAB><TAB> ( new_prompt + ""   %s "" ) if config . prefix_prompt else ( "" %s   "" + new_prompt ) <TAB><TAB> ) <TAB><TAB> new_prompt = new_prompt % curr_prompt <TAB><TAB> self . _addline ( "" set PROMPT= %s "" % new_prompt )",if not stored_prompt :,if curr_prompt :,85.29959367709465,98.47,False
3119,"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB><TAB> definition = column ( name ) <TAB><TAB> if not definition : <TAB><TAB><TAB> IECore . msg ( <TAB><TAB><TAB><TAB> IECore . Msg . Level . Error , <TAB><TAB><TAB><TAB> "" GafferImageUI.CatalogueUI "" , <TAB><TAB><TAB><TAB> "" No column registered with name  ' %s ' "" % name , <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB><TAB> else : <TAB><TAB><TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB><TAB> columns . append ( c ) <TAB> return columns","if isinstance ( definition , IconColumn ) :",if definition . icon :,73.5738365598559,96.96,False
3120,"def _check_invalid_keys ( self , section_name , section ) : <TAB> for key in section : <TAB><TAB> key_name = str ( key ) <TAB><TAB> valid_key_names = [ s [ 0 ] for s in self . keys ] <TAB><TAB> is_valid_key = key_name in valid_key_names <TAB><TAB> <MASK> <TAB><TAB><TAB> err_msg = ( <TAB><TAB><TAB><TAB> "" ' {0} '  is not a valid key name for  ' {1} ' . Must  "" "" be one of these:  {2} "" <TAB><TAB><TAB> ) . format ( key_name , section_name , "" ,  "" . join ( valid_key_names ) ) <TAB><TAB><TAB> raise InvalidConfig ( err_msg )",if not is_valid_key :,if not is_valid_key :,100.0,100.00,True
3121,"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB><TAB> name = path . name <TAB><TAB> if name == "" __pycache__ "" : <TAB><TAB><TAB> continue <TAB><TAB> if name . endswith ( "" .py "" ) : <TAB><TAB><TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> names . add ( name ) <TAB> if packages : <TAB><TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB><TAB> if len ( names & packages ) == len ( packages ) : <TAB><TAB><TAB> return packages <TAB> return names","elif path . is_dir ( ) and ""."" not in name :","elif name . startswith ( ""__"" ) :",94.64550131722001,94.08,False
3122,"def sortkeypicker ( keynames ) : <TAB> negate = set ( ) <TAB> for i , k in enumerate ( keynames ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> keynames [ i ] = k [ 1 : ] <TAB><TAB><TAB> negate . add ( k [ 1 : ] ) <TAB> def getit ( adict ) : <TAB><TAB> composite = [ adict [ k ] for k in keynames ] <TAB><TAB> for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB><TAB><TAB> if k in negate : <TAB><TAB><TAB><TAB> composite [ i ] = - v <TAB><TAB> return composite <TAB> return getit","if k [ : 1 ] == ""-"" :","if k [ 0 ] == ""-"" :",92.58463005540105,98.05,False
3123,"def iter_symbols ( code ) : <TAB> """"""Yield names and strings used by `code` and its nested code objects"""""" <TAB> for name in code . co_names : <TAB><TAB> yield name <TAB> for const in code . co_consts : <TAB><TAB> if isinstance ( const , six . string_types ) : <TAB><TAB><TAB> yield const <TAB><TAB> <MASK> <TAB><TAB><TAB> for name in iter_symbols ( const ) : <TAB><TAB><TAB><TAB> yield name","elif isinstance ( const , CodeType ) :","elif isinstance ( const , ( list , tuple ) ) :",69.40439077300846,95.40,False
3124,"def set_study_directions ( <TAB> self , study_id : int , directions : Sequence [ StudyDirection ] ) - > None : <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> current_directions = self . _studies [ study_id ] . directions <TAB><TAB><TAB> if directions == current_directions : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> elif ( <TAB><TAB><TAB><TAB> len ( current_directions ) == 1 <TAB><TAB><TAB><TAB> and current_directions [ 0 ] == StudyDirection . NOT_SET <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> self . _studies [ study_id ] . directions = list ( directions ) <TAB><TAB><TAB><TAB> self . _backend . set_study_directions ( study_id , directions ) <TAB><TAB><TAB><TAB> return <TAB> self . _backend . set_study_directions ( study_id , directions )",if study_id in self . _studies :,if study_id in self . _studies :,100.0,100.00,True
3125,"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB><TAB> <MASK> <TAB><TAB><TAB> x = 1 <TAB><TAB> elif not IfList : <TAB><TAB><TAB> if self < = 2 : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionSizeGuid = 3 <TAB><TAB><TAB> if not RegionSizeGuid : <TAB><TAB><TAB><TAB> RegionLayoutLine = 5 <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",if self . __Token :,if self . IsConditional ( ) and self . IsReplacedLine ( ) :,93.42467133235573,93.24,False
3126,"def _check_blocking ( self , current_time ) : <TAB> if self . _switch_flag is False : <TAB><TAB> active_greenlet = self . _active_greenlet <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _notify_greenlet_blocked ( active_greenlet , current_time ) <TAB> self . _switch_flag = False",if active_greenlet is not None and active_greenlet != self . _hub :,if active_greenlet is not None :,60.36225152925518,88.31,False
3127,"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB><TAB> page , headers , code = get_page ( get = vector ) <TAB><TAB> retval = ( <TAB><TAB><TAB> re . search ( r "" BlockDos \ .net "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return retval",if retval :,if retval :,100.0,100.00,True
3128,"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB><TAB> with open ( data_file ) as in_handle : <TAB><TAB><TAB> for line in in_handle : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> in_section = True <TAB><TAB><TAB><TAB> elif in_section : <TAB><TAB><TAB><TAB><TAB> if line . startswith ( "" >>END "" ) : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB><TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out","if line . startswith ( "">>%s"" % section_name ) :",if line . startswith ( section_name ) :,69.35420251765673,96.60,False
3129,"def shortcut ( self , input , ch_out , stride , is_first , name ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB><TAB> else : <TAB><TAB><TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> elif is_first : <TAB><TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB><TAB> return input",if is_first or stride == 1 :,if is_first :,95.3803089608927,96.55,False
3130,"def get_value_from_string ( self , string_value ) : <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB><TAB> if string_value is not None : <TAB><TAB><TAB> string_value = str ( string_value ) . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB><TAB> self . pcluster_config . warn ( <TAB><TAB><TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB><TAB><TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB><TAB> ) <TAB> return param_value","if string_value != ""NONE"" :",if not param_value :,76.3823164264488,96.07,False
3131,"def get_running ( workers ) : <TAB> running = [ ] <TAB> for worker in workers : <TAB><TAB> current_test_name = worker . current_test_name <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> dt = time . monotonic ( ) - worker . start_time <TAB><TAB> if dt > = PROGRESS_MIN_TIME : <TAB><TAB><TAB> text = "" %s  ( %s ) "" % ( current_test_name , format_duration ( dt ) ) <TAB><TAB><TAB> running . append ( text ) <TAB> return running",if not current_test_name :,"if current_test_name in [ ""test"" , ""test_worker_worker_",63.13397362510293,90.25,False
3132,"def generate_data ( self , request ) : <TAB> """"""Generate data for the widget."""""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB><TAB> for hosts , stats in cache_stats : <TAB><TAB><TAB> if stats [ "" uptime "" ] > 86400 : <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB><TAB><TAB><TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime }","elif stats [ ""uptime"" ] > 3600 :","elif stats [ ""uptime"" ] > 3600 :",100.0,100.00,True
3133,"def add_actors ( self ) : <TAB> """"""Adds `self.actors` to the scene."""""" <TAB> if not self . _actors_added : <TAB><TAB> self . reader . render_window = self . scene . render_window <TAB><TAB> self . _update_reader ( ) <TAB><TAB> self . _actors_added = True <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _visible_changed ( self . visible ) <TAB><TAB> self . scene . render ( )",if not self . visible :,if self . visible :,68.89752876510063,98.09,False
3134,"def _add_uniqu_suffix ( self , titles ) : <TAB> counters = dict ( ) <TAB> titles_with_suffix = [ ] <TAB> for title in titles : <TAB><TAB> counters [ title ] = counters [ title ] + 1 if title in counters else 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> title = f "" { title }  ( { counters [ title ] } ) "" <TAB><TAB> titles_with_suffix . append ( title ) <TAB> return titles_with_suffix",if counters [ title ] > 1 :,if counters [ title ] > 1 :,100.0,100.00,True
3135,"def _verify_udf_resources ( self , job , config ) : <TAB> udf_resources = config . get ( "" userDefinedFunctionResources "" , ( ) ) <TAB> self . assertEqual ( len ( job . udf_resources ) , len ( udf_resources ) ) <TAB> for found , expected in zip ( job . udf_resources , udf_resources ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( found . udf_type , "" resourceUri "" ) <TAB><TAB><TAB> self . assertEqual ( found . value , expected [ "" resourceUri "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( found . udf_type , "" inlineCode "" ) <TAB><TAB><TAB> self . assertEqual ( found . value , expected [ "" inlineCode "" ] )","if ""resourceUri"" in expected :","if ""resourceUri"" in expected :",100.0,100.00,True
3136,"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """"""Constructor."""""" <TAB> self . layout = layout <TAB> if value is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB><TAB> else : <TAB><TAB><TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB><TAB> self . value = np . array ( value ) <TAB><TAB> if self . value . shape != ( self . layout . gaDims , ) : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB><TAB><TAB> )",if string is None :,if string is None :,100.0,100.00,True
3137,"def read_file ( filename , print_error = True ) : <TAB> """"""Returns the contents of a file."""""" <TAB> try : <TAB><TAB> for encoding in [ "" utf-8 "" , "" latin1 "" ] : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> with io . open ( filename , encoding = encoding ) as fp : <TAB><TAB><TAB><TAB><TAB> return fp . read ( ) <TAB><TAB><TAB> except UnicodeDecodeError : <TAB><TAB><TAB><TAB> pass <TAB> except IOError as exception : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( exception , file = sys . stderr ) <TAB><TAB> return None",if print_error :,if print_error :,100.0,100.00,True
3138,"def get_albums_for_iter ( self , iter_ ) : <TAB> obj = self . get_value ( iter_ ) <TAB> if isinstance ( obj , AlbumNode ) : <TAB><TAB> return { obj . album } <TAB> albums = set ( ) <TAB> for child_iter , value in self . iterrows ( iter_ ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> albums . add ( value . album ) <TAB><TAB> else : <TAB><TAB><TAB> albums . update ( self . get_albums_for_iter ( child_iter ) ) <TAB> return albums","if isinstance ( value , AlbumNode ) :","if isinstance ( value , AlbumNode ) :",100.0,100.00,True
3139,"def wait_til_ready ( cls , connector = None ) : <TAB> if connector is None : <TAB><TAB> connector = cls . connector <TAB> while True : <TAB><TAB> now = time . time ( ) <TAB><TAB> next_iteration = now / / 1.0 + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> await cls . _clock . run_til ( next_iteration ) <TAB><TAB> await asyncio . sleep ( 1.0 )",if connector . ready :,if connector . ready :,100.0,100.00,True
3140,"def remove_property ( self , key ) : # type: (str) -> None <TAB> with self . secure ( ) as config : <TAB><TAB> keys = key . split ( "" . "" ) <TAB><TAB> current_config = config <TAB><TAB> for i , key in enumerate ( keys ) : <TAB><TAB><TAB> if key not in current_config : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del current_config [ key ] <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> current_config = current_config [ key ]",if i == len ( keys ) - 1 :,if current_config [ key ] is None :,69.44837409862883,93.94,False
3141,"def get ( self , hash160 , default = None ) : <TAB> v = self . p2s_for_hash ( hash160 ) <TAB> <MASK> <TAB><TAB> return v <TAB> if hash160 not in self . _secret_exponent_cache : <TAB><TAB> v = self . path_for_hash160 ( hash160 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fingerprint , path = v <TAB><TAB><TAB> for key in self . _secrets . get ( fingerprint , [ ] ) : <TAB><TAB><TAB><TAB> subkey = key . subkey_for_path ( path ) <TAB><TAB><TAB><TAB> self . _add_key_to_cache ( subkey ) <TAB> return self . _secret_exponent_cache . get ( hash160 , default )",if v :,if v :,100.0,100.00,True
3142,"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB><TAB> # Ensure targets is a tuple <TAB><TAB> <MASK> <TAB><TAB><TAB> targets = tuple ( <TAB><TAB><TAB><TAB> targets , <TAB><TAB><TAB> ) <TAB><TAB> elif type ( targets ) != tuple : <TAB><TAB><TAB> targets = tuple ( targets ) <TAB> for target in targets : <TAB><TAB> self . _fetch_targets ( api_client , q , target )",if type ( targets ) != list and type ( targets ) != tuple :,if type ( targets ) == list :,94.23549631517538,92.92,False
3143,"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB><TAB> data = zip ( * data ) <TAB><TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( dt , dgl . DGLGraph ) : <TAB><TAB><TAB><TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB><TAB><TAB> elif isinstance ( dt , nd . NDArray ) : <TAB><TAB><TAB><TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB><TAB><TAB><TAB> data_list = [ dt for dt in data if dt is not None ] <TAB><TAB><TAB><TAB> return pad ( data_list )",if dt is not None :,"if isinstance ( dt , ( list , tuple ) ) :",95.64566676431343,95.24,False
3144,"def capture_server ( evt , buf , serv ) : <TAB> try : <TAB><TAB> serv . listen ( 5 ) <TAB><TAB> conn , addr = serv . accept ( ) <TAB> except socket . timeout : <TAB><TAB> pass <TAB> else : <TAB><TAB> n = 200 <TAB><TAB> while n > 0 : <TAB><TAB><TAB> r , w , e = select . select ( [ conn ] , [ ] , [ ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = conn . recv ( 10 ) <TAB><TAB><TAB><TAB> # keep everything except for the newline terminator <TAB><TAB><TAB><TAB> buf . write ( data . replace ( "" \n "" , "" "" ) ) <TAB><TAB><TAB><TAB> if "" \n "" in data : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> n - = 1 <TAB><TAB><TAB> time . sleep ( 0.01 ) <TAB><TAB> conn . close ( ) <TAB> finally : <TAB><TAB> serv . close ( ) <TAB><TAB> evt . set ( )",if r :,if r :,100.0,100.00,True
3145,"def elem ( ) : <TAB> if ints_only : <TAB><TAB> return random . randint ( 0 , 10000000000 ) <TAB> else : <TAB><TAB> t = random . randint ( 0 , 2 ) <TAB><TAB> if t == 0 : <TAB><TAB><TAB> return random . randint ( 0 , 10000000000 ) <TAB><TAB> elif t == 1 : <TAB><TAB><TAB> return float ( random . randint ( 0 , 10000000000 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return strings [ random . randint ( 0 , len ( strings ) - 1 ) ] <TAB><TAB> return random_string ( random . randint ( 100 , 1000 ) )",elif strings is not None :,elif t == 2 :,95.41401111408034,96.73,False
3146,"def has_changed ( self , initial , data ) : <TAB> if self . disabled : <TAB><TAB> return False <TAB> if initial is None : <TAB><TAB> initial = [ "" "" for x in range ( 0 , len ( data ) ) ] <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> initial = self . widget . decompress ( initial ) <TAB> for field , initial , data in zip ( self . fields , initial , data ) : <TAB><TAB> try : <TAB><TAB><TAB> initial = field . to_python ( initial ) <TAB><TAB> except ValidationError : <TAB><TAB><TAB> return True <TAB><TAB> if field . has_changed ( initial , data ) : <TAB><TAB><TAB> return True <TAB> return False","if not isinstance ( initial , list ) :",if self . widget :,68.17347309773315,95.73,False
3147,"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB><TAB> package = _normalize_module ( package , 3 ) <TAB><TAB> filename = _module_relative_path ( package , filename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if hasattr ( package . __loader__ , "" get_data "" ) : <TAB><TAB><TAB><TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB><TAB><TAB><TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB><TAB><TAB><TAB> # conversion as universal newlines would do. <TAB><TAB><TAB><TAB> return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB> return open ( filename ) . read ( ) , filename","if hasattr ( package , ""__loader__"" ) :","if hasattr ( package , ""__loader__"" ) :",100.0,100.00,True
3148,"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB><TAB> if self . owner != tid : <TAB><TAB><TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB> assert self . count > 0 <TAB><TAB> self . count - = 1 <TAB><TAB> if self . count == 0 : <TAB><TAB><TAB> self . owner = None <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . waiters - = 1 <TAB><TAB><TAB><TAB> self . wakeup . release ( )",if self . waiters :,if self . waiters > 0 :,75.3010364242635,97.85,False
3149,"def stage ( <TAB> self , x , num_modules , num_blocks , channels , multi_scale_output = True , name = None ) : <TAB> out = x <TAB> for i in range ( num_modules ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> out = self . high_resolution_module ( <TAB><TAB><TAB><TAB> out , <TAB><TAB><TAB><TAB> num_blocks , <TAB><TAB><TAB><TAB> channels , <TAB><TAB><TAB><TAB> multi_scale_output = False , <TAB><TAB><TAB><TAB> name = name + "" _ "" + str ( i + 1 ) , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> out = self . high_resolution_module ( <TAB><TAB><TAB><TAB> out , num_blocks , channels , name = name + "" _ "" + str ( i + 1 ) <TAB><TAB><TAB> ) <TAB> return out",if i == num_modules - 1 and multi_scale_output == False :,if multi_scale_output :,92.16151322897379,94.40,False
3150,"def changeFrontAlteration ( intV , alter ) : <TAB> # fati = front alteration transpose interval <TAB> fati = self . frontAlterationTransposeInterval <TAB> if fati : <TAB><TAB> newFati = interval . add ( [ fati , intV ] ) <TAB><TAB> self . frontAlterationTransposeInterval = newFati <TAB><TAB> self . frontAlterationAccidental . alter = ( <TAB><TAB><TAB> self . frontAlterationAccidental . alter + alter <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . frontAlterationTransposeInterval = None <TAB><TAB><TAB> self . frontAlterationAccidental = None <TAB> else : <TAB><TAB> self . frontAlterationTransposeInterval = intV <TAB><TAB> self . frontAlterationAccidental = pitch . Accidental ( alter )",if self . frontAlterationAccidental . alter == 0 :,if self . frontAlterationAccidental . alter == 0 :,75.0,100.00,True
3151,"def set_to_train ( self ) : <TAB> for T in self . trainable_attributes ( ) : <TAB><TAB> for k , v in T . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> c_f . set_requires_grad ( v , requires_grad = False ) <TAB><TAB><TAB><TAB> v . eval ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> v . train ( ) <TAB> self . maybe_freeze_trunk_batchnorm ( )",if k in self . freeze_these :,"if k == ""train"" :",68.54188484552914,94.88,False
3152,"def _migrate ( self , sig = None , compact = True ) : <TAB> with self . lock : <TAB><TAB> sig = sig or self . sig <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if sig in self . WORDS and len ( self . WORDS [ sig ] ) > 0 : <TAB><TAB><TAB> PostingList . Append ( <TAB><TAB><TAB><TAB> self . session , sig , self . WORDS [ sig ] , sig = sig , compact = compact <TAB><TAB><TAB> ) <TAB><TAB><TAB> del self . WORDS [ sig ]",if sig in GPL_NEVER_MIGRATE :,if sig is None :,81.47669130085683,95.16,False
3153,"def on_prediction_step ( self , args , state , control , eval_dataloader = None , * * kwargs ) : <TAB> if self . prediction_bar is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . prediction_bar = self . training_tracker . add_child ( len ( eval_dataloader ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . prediction_bar = NotebookProgressBar ( len ( eval_dataloader ) ) <TAB><TAB> self . prediction_bar . update ( 1 ) <TAB> else : <TAB><TAB> self . prediction_bar . update ( self . prediction_bar . value + 1 )",if self . training_tracker is not None :,if self . training_tracker is not None :,100.0,100.00,True
3154,"def show ( self , indent = 0 ) : <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0 : <TAB><TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB><TAB> if field . offset is None : <TAB><TAB><TAB> offset = "" 0x?? "" <TAB><TAB> else : <TAB><TAB><TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB><TAB> print ( "" {} + {}   {}   {} "" . format ( ""   "" * indent , offset , field . name , field . type ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> field . type . show ( indent + 1 )","if isinstance ( field . type , Structure ) :",if field . type :,74.66014234745124,95.92,False
3155,"def __exit__ ( self , exc , value , tb ) : <TAB> for key in self . overrides . keys ( ) : <TAB><TAB> old_value = self . old [ key ] <TAB><TAB> <MASK> <TAB><TAB><TAB> delattr ( self . instance , key ) <TAB><TAB> else : <TAB><TAB><TAB> setattr ( self . instance , key , old_value ) <TAB> self . instance . save ( )",if old_value is NULL :,if old_value is None :,93.4142678805115,97.78,False
3156,"def complete ( self , block ) : <TAB> with self . _condition : <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> if self . _complete ( ) : <TAB><TAB><TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB> return True <TAB><TAB> if block : <TAB><TAB><TAB> self . _condition . wait_for ( self . _complete ) <TAB><TAB><TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB> return True <TAB><TAB> return False",if not self . _final :,if self . _condition . is_set ( ) :,66.81574092341333,94.25,False
3157,"def parseArguments ( self ) : <TAB> args = [ ] <TAB> self . expect ( "" ( "" ) <TAB> if not self . match ( "" ) "" ) : <TAB><TAB> while self . startIndex < self . length : <TAB><TAB><TAB> args . append ( self . isolateCoverGrammar ( self . parseAssignmentExpression ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> self . expectCommaSeparator ( ) <TAB> self . expect ( "" ) "" ) <TAB> return args","if self . match ( "")"" ) :",if self . startIndex >= self . length :,94.70061876082725,94.45,False
3158,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB><TAB> if value == "" DD-MM-YYYY "" : <TAB><TAB><TAB> return value <TAB><TAB> day , month , year = value . split ( "" - "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> return value <TAB> except Exception : <TAB><TAB> raise DateStringValueError ( config_param_name , value )",if int ( day ) < 1 or int ( day ) > 31 :,if int ( day ) < 1 or int ( day ) > 7 :,99.00621332453665,98.85,False
3159,"def build_tree ( path ) : <TAB> tree = Tree ( ) <TAB> for basename , entry in trees [ path ] . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> mode = stat . S_IFDIR <TAB><TAB><TAB> sha = build_tree ( pathjoin ( path , basename ) ) <TAB><TAB> else : <TAB><TAB><TAB> ( mode , sha ) = entry <TAB><TAB> tree . add ( basename , mode , sha ) <TAB> object_store . add_object ( tree ) <TAB> return tree . id","if isinstance ( entry , dict ) :",if entry is None :,93.53995627544278,94.93,False
3160,"def get_quarantine_count ( self ) : <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB><TAB> for qtype in qcounts : <TAB><TAB><TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB><TAB><TAB><TAB> if linkcount > 2 : <TAB><TAB><TAB><TAB><TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts",if os . path . exists ( qtgt ) :,if os . path . exists ( qtgt ) :,100.0,100.00,True
3161,"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB><TAB> return False <TAB> for dim_value in shape : <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> if dim_value < 0 : <TAB><TAB><TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True","if not isinstance ( dim_value , int ) :","if dim_value not in ( int , float , float , float , float , float ,",58.750441034355624,86.37,False
3162,"def BraceDetectAll ( words ) : <TAB> # type: (List[compound_word]) -> List[word_t] <TAB> """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB> out = [ ] # type: List[word_t] <TAB> for w in words : <TAB><TAB> # The shortest possible brace expansion is {,}.  This heuristic prevents <TAB><TAB> # a lot of garbage from being created, since otherwise nearly every word <TAB><TAB> # would be checked.  We could be even more precise but this is cheap. <TAB><TAB> if len ( w . parts ) > = 3 : <TAB><TAB><TAB> brace_tree = _BraceDetect ( w ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> out . append ( brace_tree ) <TAB><TAB><TAB><TAB> continue <TAB><TAB> out . append ( w ) <TAB> return out",if brace_tree :,if brace_tree :,75.0,100.00,True
3163,"def __init__ ( original , self , * args , * * kwargs ) : <TAB> data = args [ 0 ] if len ( args ) > 0 else kwargs . get ( "" data "" ) <TAB> if data is not None : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB><TAB> "" cannot gather example input when dataset is loaded from a file. "" <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> input_example_info = _InputExampleInfo ( <TAB><TAB><TAB><TAB> input_example = deepcopy ( data [ : INPUT_EXAMPLE_SAMPLE_ROWS ] ) <TAB><TAB><TAB> ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> input_example_info = _InputExampleInfo ( error_msg = str ( e ) ) <TAB><TAB> setattr ( self , "" input_example_info "" , input_example_info ) <TAB> original ( self , * args , * * kwargs )","if isinstance ( data , str ) :",if not data [ INPUT_EXAMPLE_SAMPLE_ROWS ] :,77.5293897527764,95.50,False
3164,"def setRow ( self , row , vals ) : <TAB> if row > self . rowCount ( ) - 1 : <TAB><TAB> self . setRowCount ( row + 1 ) <TAB> for col in range ( len ( vals ) ) : <TAB><TAB> val = vals [ col ] <TAB><TAB> item = self . itemClass ( val , row ) <TAB><TAB> item . setEditable ( self . editable ) <TAB><TAB> sortMode = self . sortModes . get ( col , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> item . setSortMode ( sortMode ) <TAB><TAB> format = self . _formats . get ( col , self . _formats [ None ] ) <TAB><TAB> item . setFormat ( format ) <TAB><TAB> self . items . append ( item ) <TAB><TAB> self . setItem ( row , col , item ) <TAB><TAB> item . setValue ( val ) # Required--the text-change callback is invoked",if sortMode is not None :,if sortMode is not None :,100.0,100.00,True
3165,"def wakeUp ( self ) : <TAB> """"""Write one byte to the pipe, and flush it."""""" <TAB> # We don't use fdesc.writeToFD since we need to distinguish <TAB> # between EINTR (try again) and EAGAIN (do nothing). <TAB> if self . o is not None : <TAB><TAB> try : <TAB><TAB><TAB> util . untilConcludes ( os . write , self . o , b "" x "" ) <TAB><TAB> except OSError as e : <TAB><TAB><TAB> # XXX There is no unit test for raising the exception <TAB><TAB><TAB> # for other errnos. See #4285. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise",if e . errno != errno . EAGAIN :,if e . errno != errno . EINTR :,98.79281620875261,98.62,False
3166,"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model references. <TAB> resolved_classes = [ ] <TAB> for m in self . model_classes : <TAB><TAB> <MASK> <TAB><TAB><TAB> if m == owner_model . __name__ : <TAB><TAB><TAB><TAB> resolved_classes . append ( owner_model ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB><TAB> "" PolyModelType: Unable to resolve model  ' {} ' . "" . format ( m ) <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> resolved_classes . append ( m ) <TAB> self . model_classes = tuple ( resolved_classes ) <TAB> super ( PolyModelType , self ) . _setup ( field_name , owner_model )","if isinstance ( m , string_type ) :","if isinstance ( owner_model , model . Model ) :",72.6828434443509,96.67,False
3167,"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB><TAB> # get cached return value if present <TAB><TAB> value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB><TAB> if value_ is KeyError : <TAB><TAB><TAB> # evaluate the late-bound function <TAB><TAB><TAB> value_ = self . _eval_late_binding ( value ) <TAB><TAB><TAB> schema = self . late_bind_schemas . get ( key ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value_ = schema . validate ( value_ ) <TAB><TAB><TAB> # cache result of late bound func <TAB><TAB><TAB> self . _late_binding_returnvalues [ key ] = value_ <TAB><TAB> return value_ <TAB> else : <TAB><TAB> return value",if schema is not None :,if schema :,97.67760815196857,98.09,False
3168,"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB><TAB> arg = arg [ 1 : ] <TAB> try : <TAB><TAB> value = int ( arg , base = 16 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise BadColourArgument ( arg ) <TAB><TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB><TAB> arg = arg . replace ( ""   "" , "" _ "" ) <TAB><TAB> method = getattr ( discord . Colour , arg , None ) <TAB><TAB> if arg . startswith ( "" from_ "" ) or method is None or not inspect . ismethod ( method ) : <TAB><TAB><TAB> raise BadColourArgument ( arg ) <TAB><TAB> return method ( )",if not ( 0 <= value <= 0xFFFFFF ) :,if value < 0 :,69.33447116311673,95.18,False
3169,"def get_versions ( * , all = False , quiet = None ) : <TAB> import bonobo <TAB> from bonobo . util . pkgs import bonobo_packages <TAB> yield _format_version ( bonobo , quiet = quiet ) <TAB> if all : <TAB><TAB> for name in sorted ( bonobo_packages ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> mod = __import__ ( name . replace ( "" - "" , "" _ "" ) ) <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> yield _format_version ( mod , name = name , quiet = quiet ) <TAB><TAB><TAB><TAB><TAB> except Exception as exc : <TAB><TAB><TAB><TAB><TAB><TAB> yield "" {}  ( {} ) "" . format ( name , exc ) <TAB><TAB><TAB><TAB> except ImportError as exc : <TAB><TAB><TAB><TAB><TAB> yield "" {}  is not importable ( {} ). "" . format ( name , exc )","if name != ""bonobo"" :","if name . startswith ( ""b"" ) :",96.90787303036204,97.29,False
3170,"def assertOperationsInjected ( self , plan , * * kwargs ) : <TAB> for migration , _backward in plan : <TAB><TAB> operations = iter ( migration . operations ) <TAB><TAB> for operation in operations : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> next_operation = next ( operations ) <TAB><TAB><TAB><TAB> self . assertIsInstance ( <TAB><TAB><TAB><TAB><TAB> next_operation , contenttypes_management . RenameContentType <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> self . assertEqual ( next_operation . app_label , migration . app_label ) <TAB><TAB><TAB><TAB> self . assertEqual ( next_operation . old_model , operation . old_name_lower ) <TAB><TAB><TAB><TAB> self . assertEqual ( next_operation . new_model , operation . new_name_lower )","if isinstance ( operation , migrations . RenameModel ) :",if operation . app_label == migration . app_label :,92.61959563931019,94.50,False
3171,"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB> # strip line, skip over empty lines <TAB><TAB> line = line . strip ( ) <TAB><TAB> if line == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> # skip over comments or empty lines <TAB><TAB> match = COMMENT . match ( line ) <TAB><TAB> if match : <TAB><TAB><TAB> continue <TAB><TAB> # skip over localparts with delimiters <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield line",if strip_delimiters :,if strip_delimiters :,100.0,100.00,True
3172,"def read_lccn ( line , is_marc8 = False ) : <TAB> found = [ ] <TAB> for k , v in get_raw_subfields ( line , [ "" a "" ] ) : <TAB><TAB> lccn = v . strip ( ) <TAB><TAB> if re_question . match ( lccn ) : <TAB><TAB><TAB> continue <TAB><TAB> m = re_lccn . search ( lccn ) <TAB><TAB> if not m : <TAB><TAB><TAB> continue <TAB><TAB> # remove letters and bad chars <TAB><TAB> lccn = re_letters_and_bad . sub ( "" "" , m . group ( 1 ) ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> found . append ( lccn ) <TAB> return found",if lccn :,if is_marc8 and re_marc8 . match ( lccn ),97.21183044127977,93.38,False
3173,"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB> elif name == "" mean_module.constant "" : <TAB><TAB><TAB> self . assertIsNone ( constraint ) <TAB><TAB> elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","elif name == ""covar_module.base_kernel.raw_lengthscale"" :","elif name == ""cov_module.raw_bias"" :",98.92285275819808,95.60,False
3174,"def _cleanupSocket ( self ) : <TAB> """"""Close the Connection's socket."""""" <TAB> try : <TAB><TAB> self . _sock . shutdown ( socket . SHUT_WR ) <TAB> except : <TAB><TAB> return <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> r , w , e = select . select ( [ self . _sock ] , [ ] , [ ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> except : <TAB><TAB> pass <TAB> self . _sock . close ( )",if not r or not self . _sock . recv ( 1024 ) :,if r :,62.9007889404671,90.96,False
3175,"def fadeIn ( self , acts = None , t = None , duration = None ) : <TAB> """"""Gradually switch on the input list of meshes by increasing opacity."""""" <TAB> if self . bookingMode : <TAB><TAB> acts , t , duration , rng = self . _parse ( acts , t , duration ) <TAB><TAB> for tt in rng : <TAB><TAB><TAB> alpha = linInterpolate ( tt , [ t , t + duration ] , [ 0 , 1 ] ) <TAB><TAB><TAB> self . events . append ( ( tt , self . fadeIn , acts , alpha ) ) <TAB> else : <TAB><TAB> for a in self . _performers : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> a . alpha ( self . _inputvalues ) <TAB> return self",if a . alpha ( ) >= self . _inputvalues :,if a . _inputvalues is None :,94.91598101471006,95.67,False
3176,"def get_config_updates_recursive ( self ) : <TAB> config_updates = self . config_updates . copy ( ) <TAB> for sr_path , subrunner in self . subrunners . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> update = subrunner . get_config_updates_recursive ( ) <TAB><TAB> if update : <TAB><TAB><TAB> config_updates [ rel_path ( self . path , sr_path ) ] = update <TAB> return config_updates","if not is_prefix ( self . path , sr_path ) :","if not hasattr ( subrunner , ""get_config_updates"" ) :",68.90038052288595,91.66,False
3177,"def setArgs ( self , * * kwargs ) : <TAB> """"""See GridSearchCostGamma"""""" <TAB> for key , value in list ( kwargs . items ( ) ) : <TAB><TAB> if key in ( "" folds "" , "" nfolds "" ) : <TAB><TAB><TAB> self . _n_folds = int ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _validator_kwargs [ "" max_epochs "" ] = value <TAB><TAB> else : <TAB><TAB><TAB> GridSearchDOE . setArgs ( self , * * { key : value } )","elif key in ( ""max_epochs"" ) :","elif key == ""max_epochs"" :",94.14866898713531,95.91,False
3178,"def _parse_composite_axis ( composite_axis_name : str ) : <TAB> axes_names = [ axis for axis in composite_axis_name . split ( ""   "" ) if len ( axis ) > 0 ] <TAB> for axis in axes_names : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> assert "" a "" < = axis [ 0 ] < = "" z "" <TAB><TAB> for letter in axis : <TAB><TAB><TAB> assert str . isdigit ( letter ) or "" a "" < = letter < = "" z "" <TAB> return axes_names","if axis == ""_"" :",if len ( axis ) == 0 :,88.81433524925025,94.92,False
3179,"def visit_For ( self , node , for_branch = "" body "" , * * kwargs ) : <TAB> if for_branch == "" body "" : <TAB><TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB><TAB> branch = node . body <TAB> elif for_branch == "" else "" : <TAB><TAB> branch = node . else_ <TAB> elif for_branch == "" test "" : <TAB><TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . sym_visitor . visit ( node . test ) <TAB><TAB> return <TAB> else : <TAB><TAB> raise RuntimeError ( "" Unknown for branch "" ) <TAB> for item in branch or ( ) : <TAB><TAB> self . sym_visitor . visit ( item )",if node . test is not None :,"elif for_branch == ""test_for"" :",74.23137644445457,94.61,False
3180,def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : <TAB><TAB><TAB><TAB> return True <TAB> return False,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,if node . contents :,53.35568516971918,79.14,False
3181,"def dir_tag_click ( event ) : <TAB> mouse_index = self . path_bar . index ( "" @ %d , %d "" % ( event . x , event . y ) ) <TAB> lineno = int ( float ( mouse_index ) ) <TAB> if lineno == 1 : <TAB><TAB> self . request_focus_into ( "" "" ) <TAB> else : <TAB><TAB> assert lineno == 2 <TAB><TAB> dir_range = get_dir_range ( event ) <TAB><TAB> if dir_range : <TAB><TAB><TAB> _ , end_index = dir_range <TAB><TAB><TAB> path = self . path_bar . get ( "" 2.0 "" , end_index ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> path + = "" \\ "" <TAB><TAB><TAB> self . request_focus_into ( path )","if path . endswith ( "":"" ) :","if path and not path . endswith ( ""\\"" ) :",69.43419938048301,96.89,False
3182,"def validate_employee_id ( self ) : <TAB> if self . employee : <TAB><TAB> sales_person = frappe . db . get_value ( "" Sales Person "" , { "" employee "" : self . employee } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( <TAB><TAB><TAB><TAB> _ ( "" Another Sales Person  {0}  exists with the same Employee id "" ) . format ( <TAB><TAB><TAB><TAB><TAB> sales_person <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",if sales_person and sales_person != self . name :,if sales_person :,90.93641004659197,93.13,False
3183,"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB><TAB> if item . nodeid . startswith ( "" tests/infer "" ) : <TAB><TAB><TAB> if "" stage "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",75.0,100.00,True
3184,"def poll ( self , timeout ) : <TAB> if timeout < 0 : <TAB><TAB> timeout = None # kqueue behaviour <TAB> events = self . _kqueue . control ( None , KqueueLoop . MAX_EVENTS , timeout ) <TAB> results = defaultdict ( lambda : POLL_NULL ) <TAB> for e in events : <TAB><TAB> fd = e . ident <TAB><TAB> if e . filter == select . KQ_FILTER_READ : <TAB><TAB><TAB> results [ fd ] | = POLL_IN <TAB><TAB> <MASK> <TAB><TAB><TAB> results [ fd ] | = POLL_OUT <TAB> return results . items ( )",elif e . filter == select . KQ_FILTER_WRITE :,elif e . filter == select . KQ_FILTER_WRITE :,100.0,100.00,True
3185,"def _read_dimensions ( self , * dimnames , * * kwargs ) : <TAB> path = kwargs . get ( "" path "" , "" / "" ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ self . rootgrp . dimensions [ dname ] for dname in dimnames ] <TAB><TAB> group = self . path2group [ path ] <TAB><TAB> return [ group . dimensions [ dname ] for dname in dimnames ] <TAB> except KeyError : <TAB><TAB> raise self . Error ( <TAB><TAB><TAB> "" In file  %s : \n Error while reading dimensions: ` %s ` with kwargs: ` %s ` "" <TAB><TAB><TAB> % ( self . path , dimnames , kwargs ) <TAB><TAB> )","if path == ""/"" :",if path == self . rootgrp . path :,95.44052828173068,96.51,False
3186,"def spam_to_me ( address ) : <TAB> sock = eventlet . connect ( address ) <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> sock . sendall ( b "" hello world "" ) <TAB><TAB><TAB> # Arbitrary delay to not use all available CPU, keeps the test <TAB><TAB><TAB> # running quickly and reliably under a second <TAB><TAB><TAB> time . sleep ( 0.001 ) <TAB><TAB> except socket . error as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> raise",if get_errno ( e ) == errno . EPIPE :,if e . errno == errno . EADDRINUSE :,95.40756657687103,94.20,False
3187,"def has_hash_of ( self , destpath , code , package_level ) : <TAB> """"""Determine if a file has the hash of the code."""""" <TAB> if destpath is not None and os . path . isfile ( destpath ) : <TAB><TAB> with univ_open ( destpath , "" r "" ) as opened : <TAB><TAB><TAB> compiled = readfile ( opened ) <TAB><TAB> hashash = gethash ( compiled ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",if hashash == code :,58.92426812253406,86.43,False
3188,"def insert ( self , index , item ) : <TAB> if len ( self . lists ) == 1 : <TAB><TAB> self . lists [ 0 ] . insert ( index , item ) <TAB><TAB> self . _balance_list ( 0 ) <TAB> else : <TAB><TAB> list_idx , rel_idx = self . _translate_index ( index ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IndexError ( ) <TAB><TAB> self . lists [ list_idx ] . insert ( rel_idx , item ) <TAB><TAB> self . _balance_list ( list_idx ) <TAB> return",if list_idx is None :,if rel_idx == len ( self . lists ) :,67.0456270585114,92.66,False
3189,"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB><TAB> if isinstance ( sym , ast . FunctionDef ) : <TAB><TAB><TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB><TAB><TAB> results . update ( result ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = _parse_class_simplified ( sym ) <TAB><TAB><TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB><TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results","elif isinstance ( sym , ast . ClassDef ) :","elif isinstance ( sym , ast . ClassDef ) :",100.0,100.00,True
3190,"def append_vars ( pairs , result ) : <TAB> for name , value in sorted ( pairs . items ( ) ) : <TAB><TAB> if isinstance ( value , list ) : <TAB><TAB><TAB> value = "" [ %s ] "" % "" , "" . join ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( "" %s : %s = %s "" % ( package , name , value ) ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( "" %s = %s "" % ( name , value ) )",if package :,if package :,100.0,100.00,True
3191,"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB><TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB><TAB><TAB> if ref in self . _editableChildren : <TAB><TAB><TAB><TAB> cei = self . _editableChildren . index ( ref ) <TAB><TAB><TAB><TAB> nei = cei + 1 <TAB><TAB><TAB><TAB> if nei > = len ( self . _editableChildren ) : <TAB><TAB><TAB><TAB><TAB> nei = 0 <TAB><TAB><TAB><TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if len ( self . _editableChildren ) :,if self . _editableChildren :,76.68457671620956,97.29,False
3192,"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB><TAB><TAB> if not everythingIsUnicode ( v ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> for i in v : <TAB><TAB><TAB><TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB><TAB> elif isinstance ( i , _bytes ) : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return True","elif isinstance ( v , _bytes ) :","elif not isinstance ( i , unicode ) :",69.95256879937529,97.16,False
3193,"def is_valid ( sample ) : <TAB> if sample is None : <TAB><TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB><TAB> for s in sample : <TAB><TAB><TAB> if s is None : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB><TAB><TAB><TAB> return False <TAB> return True","elif isinstance ( s , np . ndarray ) and s . size == 0 :","elif isinstance ( s , collections . abc . Mapping ) and s [ 0 ] != 0",63.84869616725075,92.11,False
3194,"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB><TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB><TAB><TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :",75.0,100.00,True
3195,"def encode ( self ) : <TAB> if self . expr in gpregs . expr : <TAB><TAB> self . value = gpregs . expr . index ( self . expr ) <TAB><TAB> self . parent . rot2 . value = 0 <TAB> elif isinstance ( self . expr , ExprOp ) and self . expr . op == allshifts [ 3 ] : <TAB><TAB> reg , value = self . expr . args <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> self . value = gpregs . expr . index ( reg ) <TAB><TAB> if not isinstance ( value , ExprInt ) : <TAB><TAB><TAB> return False <TAB><TAB> value = int ( value ) <TAB><TAB> if not value in [ 8 , 16 , 24 ] : <TAB><TAB><TAB> return False <TAB><TAB> self . parent . rot2 . value = value / / 8 <TAB> return True",if reg not in gpregs . expr :,if reg not in gpregs . expr :,100.0,100.00,True
3196,"def validate_transaction_reference ( self ) : <TAB> bank_account = self . paid_to if self . payment_type == "" Receive "" else self . paid_from <TAB> bank_account_type = frappe . db . get_value ( "" Account "" , bank_account , "" account_type "" ) <TAB> if bank_account_type == "" Bank "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( <TAB><TAB><TAB><TAB> _ ( "" Reference No and Reference Date is mandatory for Bank transaction "" ) <TAB><TAB><TAB> )",if not self . reference_no or not self . reference_date :,"if not frappe . db . get_value ( ""Reference"" , { } )",88.56339518966067,89.91,False
3197,"def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB><TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB><TAB> if hasattr ( monad , "" cls_bl_idname "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return monad <TAB> return None",if monad . cls_bl_idname == self . cls_bl_idname :,if monad . cls_bl_idname == self . cls_bl_idname,66.61948794418382,97.62,False
3198,"def _create_mask ( self , plen ) : <TAB> mask = [ ] <TAB> for i in range ( 16 ) : <TAB><TAB> if plen > = 8 : <TAB><TAB><TAB> mask . append ( 0xFF ) <TAB><TAB> <MASK> <TAB><TAB><TAB> mask . append ( 0xFF >> ( 8 - plen ) << ( 8 - plen ) ) <TAB><TAB> else : <TAB><TAB><TAB> mask . append ( 0x00 ) <TAB><TAB> plen - = 8 <TAB> return mask",elif plen > 0 :,elif i % 2 == 0 :,95.04646003304013,95.19,False
3199,"def dataset_to_stream ( dataset , input_name ) : <TAB> """"""Takes a tf.Dataset and creates a numpy stream of ready batches."""""" <TAB> # All input-pipeline processing should be on CPU. <TAB> for example in fastmath . dataset_as_numpy ( dataset ) : <TAB><TAB> features = example [ 0 ] <TAB><TAB> inp , out = features [ input_name ] , example [ 1 ] <TAB><TAB> mask = features [ "" mask "" ] if "" mask "" in features else None <TAB><TAB> # Some accelerators don't handle uint8 well, cast to int. <TAB><TAB> <MASK> <TAB><TAB><TAB> inp = inp . astype ( np . int32 ) <TAB><TAB> if isinstance ( out , np . uint8 ) : <TAB><TAB><TAB> out = out . astype ( np . int32 ) <TAB><TAB> yield ( inp , out ) if mask is None else ( inp , out , mask )","if isinstance ( inp , np . uint8 ) :","if isinstance ( inp , np . uint8 ) :",100.0,100.00,True
3200,"def _idle_redraw_cb ( self ) : <TAB> assert self . _idle_redraw_src_id is not None <TAB> queue = self . _idle_redraw_queue <TAB> if len ( queue ) > 0 : <TAB><TAB> bbox = queue . pop ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> super ( CanvasRenderer , self ) . queue_draw ( ) <TAB><TAB> else : <TAB><TAB><TAB> super ( CanvasRenderer , self ) . queue_draw_area ( * bbox ) <TAB> if len ( queue ) == 0 : <TAB><TAB> self . _idle_redraw_src_id = None <TAB><TAB> return False <TAB> return True",if bbox is None :,if len ( bbox ) == 1 :,74.09217541842885,95.32,False
3201,"def mutated ( self , indiv ) : <TAB> """"""mutate some genes of the given individual"""""" <TAB> res = indiv . copy ( ) <TAB> # to avoid having a child identical to one of the currentpopulation''' <TAB> for i in range ( self . numParameters ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . xBound is None : <TAB><TAB><TAB><TAB> res [ i ] = indiv [ i ] + gauss ( 0 , self . mutationStdDev ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> res [ i ] = max ( <TAB><TAB><TAB><TAB><TAB> min ( indiv [ i ] + gauss ( 0 , self . mutationStdDev ) , self . maxs [ i ] ) , <TAB><TAB><TAB><TAB><TAB> self . mins [ i ] , <TAB><TAB><TAB><TAB> ) <TAB> return res",if random ( ) < self . mutationProb :,if self . mins [ i ] != self . maxs [ i ] :,96.09193802044133,93.78,False
3202,"def _justifyDrawParaLine ( tx , offset , extraspace , words , last = 0 ) : <TAB> setXPos ( tx , offset ) <TAB> text = b ""   "" . join ( words ) <TAB> if last : <TAB><TAB> # last one, left align <TAB><TAB> tx . _textOut ( text , 1 ) <TAB> else : <TAB><TAB> nSpaces = len ( words ) - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> tx . setWordSpace ( extraspace / float ( nSpaces ) ) <TAB><TAB><TAB> tx . _textOut ( text , 1 ) <TAB><TAB><TAB> tx . setWordSpace ( 0 ) <TAB><TAB> else : <TAB><TAB><TAB> tx . _textOut ( text , 1 ) <TAB> setXPos ( tx , - offset ) <TAB> return offset",if nSpaces :,if nSpaces > 0 :,98.9506036167699,98.20,False
3203,"def _read_0 ( self , stream ) : <TAB> r = b "" "" <TAB> while True : <TAB><TAB> c = stream . read ( 2 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise EOFError ( ) <TAB><TAB> if c == b "" \x00 \x00 "" : <TAB><TAB><TAB> break <TAB><TAB> r + = c <TAB> return r . decode ( self . encoding )",if len ( c ) != 2 :,if not c :,62.23563865194469,92.80,False
3204,"def run ( self , app , editor , args ) : <TAB> line_nums = [ ] <TAB> for cursor in editor . cursors : <TAB><TAB> <MASK> <TAB><TAB><TAB> line_nums . append ( cursor . y ) <TAB><TAB><TAB> data = editor . lines [ cursor . y ] . get_data ( ) . upper ( ) <TAB><TAB><TAB> editor . lines [ cursor . y ] . set_data ( data )",if cursor . y not in line_nums :,if cursor . y not in line_nums :,100.0,100.00,True
3205,"def create_default_energy_point_rules ( ) : <TAB> for rule in get_default_energy_point_rules ( ) : <TAB><TAB> # check if any rule for ref. doctype exists <TAB><TAB> rule_exists = frappe . db . exists ( <TAB><TAB><TAB> "" Energy Point Rule "" , { "" reference_doctype "" : rule . get ( "" reference_doctype "" ) } <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> doc = frappe . get_doc ( rule ) <TAB><TAB> doc . insert ( ignore_permissions = True )",if rule_exists :,if not rule_exists :,98.70385792481203,98.38,False
3206,"def __new__ ( cls , * nodes ) : <TAB> if not nodes : <TAB><TAB> raise TypeError ( "" DisjunctionNode() requires at least one node "" ) <TAB> elif len ( nodes ) == 1 : <TAB><TAB> return nodes [ 0 ] <TAB> self = super ( DisjunctionNode , cls ) . __new__ ( cls ) <TAB> self . __nodes = [ ] <TAB> # TODO: Remove duplicates? <TAB> for node in nodes : <TAB><TAB> if not isinstance ( node , Node ) : <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> "" DisjunctionNode() expects Node instances as arguments; "" <TAB><TAB><TAB><TAB> ""  received a non-Node instance  %r "" % node <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __nodes . extend ( node . __nodes ) <TAB><TAB> else : <TAB><TAB><TAB> self . __nodes . append ( node ) <TAB> return self","if isinstance ( node , DisjunctionNode ) :","if hasattr ( node , ""__nodes"" ) :",98.25767651323221,96.59,False
3207,def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB><TAB> if w not in index : <TAB><TAB><TAB> yield from dfs ( w ) <TAB><TAB> <MASK> <TAB><TAB><TAB> while index [ w ] < boundaries [ - 1 ] : <TAB><TAB><TAB><TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB><TAB> boundaries . pop ( ) <TAB><TAB> scc = set ( stack [ index [ v ] : ] ) <TAB><TAB> del stack [ index [ v ] : ] <TAB><TAB> identified . update ( scc ) <TAB><TAB> yield scc,elif w not in identified :,elif boundaries [ - 1 ] > boundaries [ - 1 ] :,95.5253512562122,94.43,False
3208,"def unpack_item_obj ( map_uuid_global_id , misp_obj ) : <TAB> obj_meta = get_object_metadata ( misp_obj ) <TAB> obj_id = None <TAB> io_content = None <TAB> for attribute in misp_obj . attributes : <TAB><TAB> <MASK> <TAB><TAB><TAB> obj_id = attribute . value # # TODO: sanitize <TAB><TAB><TAB> io_content = attribute . data # # TODO: check if type == io <TAB> if obj_id and io_content : <TAB><TAB> res = Item . create_item ( obj_id , obj_meta , io_content ) <TAB><TAB> map_uuid_global_id [ misp_obj . uuid ] = get_global_id ( "" item "" , obj_id )","if attribute . object_relation == ""raw-data"" :","if isinstance ( attribute , Attribute ) :",75.00381427069239,94.40,False
3209,"def parse ( self , response ) : <TAB> soup = BeautifulSoup ( response . content . decode ( "" utf-8 "" , "" ignore "" ) , "" lxml "" ) <TAB> image_divs = soup . find_all ( "" div "" , class_ = "" imgpt "" ) <TAB> pattern = re . compile ( r "" murl \"" : \"" (.*?) \ .jpg "" ) <TAB> for div in image_divs : <TAB><TAB> href_str = html_parser . HTMLParser ( ) . unescape ( div . a [ "" m "" ] ) <TAB><TAB> match = pattern . search ( href_str ) <TAB><TAB> <MASK> <TAB><TAB><TAB> name = match . group ( 1 ) if six . PY3 else match . group ( 1 ) . encode ( "" utf-8 "" ) <TAB><TAB><TAB> img_url = "" {} .jpg "" . format ( name ) <TAB><TAB><TAB> yield dict ( file_url = img_url )",if match :,if match :,100.0,100.00,True
3210,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB><TAB> line = line . strip ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> continue <TAB><TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _path = os . path . split ( fn ) <TAB><TAB><TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB> real_errors . append ( line ) <TAB> return real_errors",if fn is not None :,if fn :,71.35685665498221,97.96,False
3211,"def decompileFormat1 ( self , reader , otFont ) : <TAB> self . classDefs = classDefs = [ ] <TAB> startGlyphID = reader . readUShort ( ) <TAB> glyphCount = reader . readUShort ( ) <TAB> for i in range ( glyphCount ) : <TAB><TAB> glyphName = otFont . getglyphName ( startGlyphID + i ) <TAB><TAB> classValue = reader . readUShort ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> classDefs . append ( ( glyphName , classValue ) )",if classValue :,if classValue :,100.0,100.00,True
3212,"def compress ( self , data_list ) : <TAB> if len ( data_list ) == 2 : <TAB><TAB> value , lookup_expr = data_list <TAB><TAB> <MASK> <TAB><TAB><TAB> if lookup_expr not in EMPTY_VALUES : <TAB><TAB><TAB><TAB> return Lookup ( value = value , lookup_expr = lookup_expr ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise forms . ValidationError ( <TAB><TAB><TAB><TAB><TAB> self . error_messages [ "" lookup_required "" ] , code = "" lookup_required "" <TAB><TAB><TAB><TAB> ) <TAB> return None",if value not in EMPTY_VALUES :,if value is not None :,88.7386378732471,96.49,False
3213,"def open_compat ( path , mode = "" r "" ) : <TAB> if mode in [ "" r "" , "" rb "" ] and not os . path . exists ( path ) : <TAB><TAB> raise FileNotFoundError ( u ' The file  "" %s ""  could not be found ' % path ) <TAB> if sys . version_info > = ( 3 , ) : <TAB><TAB> encoding = "" utf-8 "" <TAB><TAB> errors = "" replace "" <TAB><TAB> <MASK> <TAB><TAB><TAB> encoding = None <TAB><TAB><TAB> errors = None <TAB><TAB> return open ( path , mode , encoding = encoding , errors = errors ) <TAB> else : <TAB><TAB> return open ( path , mode )","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :","if encoding == ""utf-8"" :",69.10090668365824,91.38,False
3214,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB><TAB> line = line . strip ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> continue <TAB><TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB> if fn is not None : <TAB><TAB><TAB> _path = os . path . split ( fn ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> real_errors . append ( line ) <TAB> return real_errors",if _path [ - 1 ] != current_path [ - 1 ] :,"if lno != current_path and lvl != ""ERROR"" :",67.37882019961282,94.10,False
3215,"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB><TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB><TAB> lookup = "" "" <TAB><TAB> if "" "" in level_per_module : <TAB><TAB><TAB> level = level_per_module [ "" "" ] <TAB><TAB> for n in name . split ( "" . "" ) : <TAB><TAB><TAB> lookup + = n <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> level = level_per_module [ lookup ] <TAB><TAB><TAB> lookup + = "" . "" <TAB> if level is False : <TAB><TAB> return False <TAB> return record [ "" level "" ] . no > = level",if lookup in level_per_module :,if lookup in level_per_module :,100.0,100.00,True
3216,"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB><TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB><TAB><TAB> return 1 <TAB><TAB> if self . HasCloseButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasMinimizeButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB><TAB> if self . HasPinButton ( ) : <TAB><TAB><TAB> n + = 1 <TAB> return n",if self . HasMaximizeButton ( ) :,if self . HasMinimizeWindow ( ) :,98.84500963828589,98.66,False
3217,"def search ( a , b , desired ) : <TAB> if a == b : <TAB><TAB> return a <TAB> if abs ( b - a ) < 0.005 : <TAB><TAB> ca = count ( a ) <TAB><TAB> cb = count ( b ) <TAB><TAB> dista = abs ( desired - ca ) <TAB><TAB> distb = abs ( desired - cb ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return a <TAB><TAB> else : <TAB><TAB><TAB> return b <TAB> m = ( a + b ) / 2.0 <TAB> cm = count ( m ) <TAB> if desired < cm : <TAB><TAB> return search ( m , b , desired ) <TAB> else : <TAB><TAB> return search ( a , m , desired )",if dista < distb :,if dista < distb :,100.0,100.00,True
3218,"def force_ipv4 ( self , * args ) : <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB> lines = [ ] <TAB> for line in open ( self . etc_hosts ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> newline = re . sub ( "" \\ slocalhost \\ s "" , ""   "" , line ) <TAB><TAB><TAB> if line != newline : <TAB><TAB><TAB><TAB> logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB><TAB><TAB><TAB> line = newline <TAB><TAB> lines . append ( line ) <TAB> f = open ( self . etc_hosts ( ) , "" w "" ) <TAB> for line in lines : <TAB><TAB> f . write ( line ) <TAB> f . close ( )","if ""::1"" in line :","if line . startswith ( ""localhost:"" ) :",96.65084582677908,96.24,False
3219,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB> fpath = _dir / "" settings.json "" <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> with fpath . open ( ) as f : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> data = json . load ( f ) <TAB><TAB><TAB> except json . JSONDecodeError : <TAB><TAB><TAB><TAB> continue <TAB><TAB> if not isinstance ( data , dict ) : <TAB><TAB><TAB> continue <TAB><TAB> cog_name = _dir . stem <TAB><TAB> for cog_id , inner in data . items ( ) : <TAB><TAB><TAB> if not isinstance ( inner , dict ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield cog_name , cog_id",if not fpath . exists ( ) :,if not os . path . exists ( fpath ) :,71.0466380824269,97.52,False
3220,"def _get_dbutils ( ) : <TAB> try : <TAB><TAB> import IPython <TAB><TAB> ip_shell = IPython . get_ipython ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise _NoDbutilsError <TAB><TAB> return ip_shell . ns_table [ "" user_global "" ] [ "" dbutils "" ] <TAB> except ImportError : <TAB><TAB> raise _NoDbutilsError <TAB> except KeyError : <TAB><TAB> raise _NoDbutilsError",if ip_shell is None :,"if not ip_shell . ns_table [ ""user_global"" ] :",65.28157003670786,88.20,False
3221,"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB><TAB> # Since build_py handles package data installation, the <TAB><TAB> # list of outputs can contain more than just .py files. <TAB><TAB> # Make sure we only report bytecode for the .py files. <TAB><TAB> ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if self . compile : <TAB><TAB><TAB> bytecode_files . append ( py_file + "" c "" ) <TAB><TAB> if self . optimize > 0 : <TAB><TAB><TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files",if ext != PYTHON_SOURCE_EXTENSION :,"if ext != "".py"" :",98.95008471535454,97.02,False
3222,"def compute_distances_mu ( line , pts , result , gates , tolerance ) : <TAB> """"""calculate all distances with mathuutils"""""" <TAB> line_origin = V ( line [ 0 ] ) <TAB> line_end = V ( line [ - 1 ] ) <TAB> local_result = [ [ ] , [ ] , [ ] , [ ] , [ ] ] <TAB> for point in pts : <TAB><TAB> data = compute_distance ( V ( point ) , line_origin , line_end , tolerance ) <TAB><TAB> for i , res in enumerate ( local_result ) : <TAB><TAB><TAB> res . append ( data [ i ] ) <TAB> for i , res in enumerate ( result ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> res . append ( local_result [ i ] )",if gates [ i ] :,if i < gates :,69.15073807671496,97.47,False
3223,"def _get_next_segment ( self , segment_path , page_size , segment_cursor = None ) : <TAB> if segment_path : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> return Segment ( self . client , segment_path , page_size , segment_cursor ) <TAB> return None",if self . end_time and self . _is_later_than_end_time ( segment_path ) :,if segment_cursor is None :,83.30208567618662,76.02,False
3224,"def _check_number_of_sessions ( ) : <TAB> nb_desktop_sessions = sessions . get_number_of_desktop_sessions ( ignore_gdm = True ) <TAB> if nb_desktop_sessions > 1 : <TAB><TAB> print ( <TAB><TAB><TAB> "" WARNING : There are  %d  other desktop sessions open. The GPU switch will not become effective until you have manually "" <TAB><TAB><TAB> ""  logged out from ALL desktop sessions. \n "" <TAB><TAB><TAB> "" Continue ? (y/N) "" % ( nb_desktop_sessions - 1 ) <TAB><TAB> ) <TAB><TAB> confirmation = ask_confirmation ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sys . exit ( 0 )",if not confirmation :,if not confirmation :,100.0,100.00,True
3225,"def delete_compute_environment ( self , compute_environment_name ) : <TAB> if compute_environment_name is None : <TAB><TAB> raise InvalidParameterValueException ( "" Missing computeEnvironment parameter "" ) <TAB> compute_env = self . get_compute_environment ( compute_environment_name ) <TAB> if compute_env is not None : <TAB><TAB> # Pop ComputeEnvironment <TAB><TAB> self . _compute_environments . pop ( compute_env . arn ) <TAB><TAB> # Delete ECS cluster <TAB><TAB> self . ecs_backend . delete_cluster ( compute_env . ecs_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Delete compute environment <TAB><TAB><TAB> instance_ids = [ instance . id for instance in compute_env . instances ] <TAB><TAB><TAB> self . ec2_backend . terminate_instances ( instance_ids )","if compute_env . env_type == ""MANAGED"" :",if compute_env . instances :,97.91376083851523,95.64,False
3226,"def run ( self ) : <TAB> results = { } <TAB> for func_name in [ <TAB><TAB> # Execute every function starting with check_* <TAB><TAB> fn <TAB><TAB> for fn in self . check_functions <TAB><TAB> # if the user does not specify any name <TAB><TAB> if not self . args . get ( "" check "" ) <TAB><TAB> # of if specify the current function name <TAB><TAB> or self . args . get ( "" check "" ) == fn <TAB> ] : <TAB><TAB> function = getattr ( self , func_name ) <TAB><TAB> log . warn ( function . __doc__ ) <TAB><TAB> result = function ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" \n "" . join ( result ) ) <TAB><TAB><TAB> results . update ( { func_name : result } ) <TAB> return results",if result :,if result :,100.0,100.00,True
3227,"def invalidate ( self , layers = None ) : <TAB> if layers is None : <TAB><TAB> layers = Layer . AllLayers <TAB> if layers : <TAB><TAB> layers = set ( layers ) <TAB><TAB> self . invalidLayers . update ( layers ) <TAB><TAB> blockRenderers = [ <TAB><TAB><TAB> br <TAB><TAB><TAB> for br in self . blockRenderers <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB><TAB> if len ( blockRenderers ) < len ( self . blockRenderers ) : <TAB><TAB><TAB> self . forgetDisplayLists ( ) <TAB><TAB> self . blockRenderers = blockRenderers <TAB><TAB> if self . renderer . showRedraw and Layer . Blocks in layers : <TAB><TAB><TAB> self . needsRedisplay = True",if br . layer is Layer . Blocks or br . layer not in layers,if br . Name not in layers,71.04406843790298,94.74,False
3228,"def get_library_dirs ( platform , arch = None ) : <TAB> if platform == "" win32 "" : <TAB><TAB> jre_home = get_jre_home ( platform ) <TAB><TAB> jdk_home = JAVA_HOME <TAB><TAB> <MASK> <TAB><TAB><TAB> jre_home = jre_home . decode ( "" utf-8 "" ) <TAB><TAB> return [ join ( jdk_home , "" lib "" ) , join ( jdk_home , "" bin "" , "" server "" ) ] <TAB> elif platform == "" android "" : <TAB><TAB> return [ "" libs/ {} "" . format ( arch ) ] <TAB> return [ ]","if isinstance ( jre_home , bytes ) :","if isinstance ( jre_home , bytes ) :",100.0,100.00,True
3229,"def save_plugin_options ( self ) : <TAB> for name , option_widgets in self . _plugin_option_widgets . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . config [ "" plugins "" ] [ name ] = { } <TAB><TAB> plugin_config = self . config [ "" plugins "" ] [ <TAB><TAB><TAB> name <TAB><TAB> ] # use or instead of get incase the value is actually None <TAB><TAB> for option_name , option_widget in option_widgets . items ( ) : <TAB><TAB><TAB> plugin_config [ option_name ] = option_widget . option . get_widget_value ( <TAB><TAB><TAB><TAB> option_widget . widget <TAB><TAB><TAB> )","if name not in self . config [ ""plugins"" ] :","if name not in self . config [ ""plugins"" ] :",100.0,100.00,True
3230,"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB><TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB> if str_in [ pos ] == start_tag : <TAB><TAB><TAB> depth + = 1 <TAB><TAB> elif str_in [ pos ] == end_tag : <TAB><TAB><TAB> depth - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",if depth == 0 :,if depth == 0 :,100.0,100.00,True
3231,"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB><TAB> v = b . data <TAB><TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB><TAB><TAB> const = v . pyval is true_val <TAB><TAB> elif not compare . compatible_with ( v , True ) : <TAB><TAB><TAB> const = not true_val <TAB><TAB> <MASK> <TAB><TAB><TAB> const = true_val <TAB><TAB> else : <TAB><TAB><TAB> const = None <TAB><TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var","elif not compare . compatible_with ( v , False ) :","elif compare . compatible_with ( v , False ) :",95.62373062927459,98.95,False
3232,def multiline_indentation ( self ) : <TAB> if self . _multiline_indentation is None : <TAB><TAB> offset = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> offset = 2 <TAB><TAB> indentation = make_indentation ( 3 * self . indent_size + offset ) <TAB><TAB> self . _multiline_indentation = indentation <TAB> if self . current_rule : <TAB><TAB> indent_extra = make_indentation ( self . indent_size ) <TAB><TAB> return self . _multiline_indentation + indent_extra <TAB> return self . _multiline_indentation,if self . show_aligned_keywords :,if self . current_rule and self . current_rule . indent_size < 2 :,73.7313652643245,89.89,False
3233,"def __call__ ( self , event , data = None ) : <TAB> datatype , delta = event <TAB> self . midi_ctrl . delta + = delta <TAB> if TIMING_CLOCK in datatype and not self . played : <TAB><TAB> self . midi_ctrl . pulse + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> t_master = 60.0 <TAB><TAB><TAB> self . midi_ctrl . bpm = round ( 60.0 / self . midi_ctrl . delta , 0 ) <TAB><TAB><TAB> self . midi_ctrl . pulse = 0 <TAB><TAB><TAB> self . midi_ctrl . delta = 0.0",if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,if self . midi_ctrl . pulse == 0 :,69.10634862510369,95.01,False
3234,"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB><TAB> <MASK> <TAB><TAB><TAB> itm = self . handle_word ( child ) <TAB><TAB><TAB> if self . _unit == "" word "" : <TAB><TAB><TAB><TAB> sent . extend ( itm ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sent . append ( itm ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent )","if child . tag in ( ""wf"" , ""punc"" ) :","if child . tag == ""sent"" :",89.758372630602,93.81,False
3235,"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef . error : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( testdef . exception , Exception ) : <TAB><TAB><TAB><TAB> raise testdef . exception <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise Exception ( testdef . exception ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Test parse failure "" )",if testdef . exception :,if testdef . exception :,75.0,100.00,True
3236,"def _authorized_sid ( self , jid , sid , ifrom , iq ) : <TAB> with self . _preauthed_sids_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _preauthed_sids [ ( jid , sid , ifrom ) ] <TAB><TAB><TAB> return True <TAB><TAB> return False","if ( jid , sid , ifrom ) in self . _preauthed_sids :","if ( jid , sid , ifrom ) in self . _preauthed_sids",64.87716814719671,97.34,False
3237,"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> msecs = _subprocess . INFINITE <TAB><TAB> else : <TAB><TAB><TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB><TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB><TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB><TAB><TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB><TAB><TAB> if code == TERMINATE : <TAB><TAB><TAB><TAB> code = - signal . SIGTERM <TAB><TAB><TAB> self . returncode = code <TAB> return self . returncode",if timeout is None :,if timeout is None :,100.0,100.00,True
3238,"def _gen_legal_y_s_t ( self ) : <TAB> while True : <TAB><TAB> y = self . _gen_random_scalar ( ) <TAB><TAB> s = self . tec_arithmetic . mul ( <TAB><TAB><TAB> scalar = y , a = self . tec_arithmetic . get_generator ( ) <TAB><TAB> ) # S = yG <TAB><TAB> t = self . _hash_tec_element ( s ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Both S and T are legal <TAB><TAB><TAB> LOGGER . info ( "" randomly generated y, S, T "" ) <TAB><TAB><TAB> return y , s , t",if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,if t :,91.70217057266304,87.47,False
3239,"def write_out ( ) : <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> time . sleep ( 0.1 ) <TAB><TAB><TAB> continue <TAB><TAB> data_str = self . instrument_queue . get ( ) <TAB><TAB> data_str = data_str . splitlines ( ) <TAB><TAB> tb . write ( "" "" ) # position cursor to end <TAB><TAB> for line in data_str : <TAB><TAB><TAB> tb . write ( line ) <TAB><TAB> tb . write ( "" \n "" )",if self . instrument_queue . empty ( ) :,if self . stop_event . is_set ( ) :,95.7797721635324,94.74,False
3240,"def _parse_preamble ( self ) : <TAB> """"""Parse metadata about query (PRIVATE)."""""" <TAB> meta = { } <TAB> while self . line : <TAB><TAB> regx = re . search ( _RE_QUERY , self . line ) <TAB><TAB> if regx : <TAB><TAB><TAB> self . query_id = regx . group ( 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . seq_len = int ( self . line . strip ( ) . split ( ) [ 1 ] ) <TAB><TAB> self . line = self . handle . readline ( ) . strip ( ) <TAB> return meta","if self . line . startswith ( ""Match_columns"" ) :","if self . query_id == ""seq_len"" :",70.79047560291572,93.60,False
3241,"def init_sequence ( self , coll_name , seq_config ) : <TAB> if not isinstance ( seq_config , list ) : <TAB><TAB> raise Exception ( ' "" sequence ""  config must be a list ' ) <TAB> handlers = [ ] <TAB> for entry in seq_config : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( ' "" sequence ""  entry must be a dict ' ) <TAB><TAB> name = entry . get ( "" name "" , "" "" ) <TAB><TAB> handler = self . load_coll ( name , entry ) <TAB><TAB> handlers . append ( handler ) <TAB> return HandlerSeq ( handlers )","if not isinstance ( entry , dict ) :","if not isinstance ( entry , dict ) :",100.0,100.00,True
3242,"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB><TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB><TAB> if ind < len ( strings ) and strings [ ind ] . startswith ( ""   "" ) : <TAB><TAB><TAB> ind + = 1 <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB> start = ind <TAB><TAB><TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB><TAB> if "" : "" in line and len ( line ) > 0 : <TAB><TAB><TAB> lines = line . split ( "" : "" ) <TAB><TAB><TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d",if start < ind :,if start :,85.21272082526343,98.71,False
3243,"def wait ( self ) : <TAB> while True : <TAB><TAB> return_code = self . _process . poll ( ) <TAB><TAB> if return_code is not None : <TAB><TAB><TAB> line = self . _process . stdout . readline ( ) . decode ( "" utf-8 "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> log . debug ( line . strip ( "" \n "" ) ) <TAB> return True","if line == """" :","if line . startswith ( ""No such line"" ) :",66.98602165378563,92.43,False
3244,"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if "" name "" in tag . attrs and tag . attrs [ "" name "" ] in ( key , ) : <TAB><TAB><TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError","if tag . name not in ( ""input"" , ) :","if tag . tag_type != ""tag_object"" :",92.19713621923533,91.35,False
3245,"def compare_hash ( hash_of_gold , path_to_file ) : <TAB> with open ( path_to_file , "" rb "" ) as f : <TAB><TAB> hash_of_file = hashlib . sha256 ( f . read ( ) ) . hexdigest ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" ########## Hash sum of "" , <TAB><TAB><TAB><TAB> path_to_file , <TAB><TAB><TAB><TAB> "" differs from the target, the topology will be deleted !!! ########## "" , <TAB><TAB><TAB> ) <TAB><TAB><TAB> shutil . rmtree ( os . path . dirname ( path_to_file ) )",if hash_of_file != hash_of_gold :,if hash_of_file != hash_of_gold :,100.0,100.00,True
3246,def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB><TAB> <MASK> <TAB><TAB><TAB> observer . on_next ( False ) <TAB><TAB><TAB> observer . on_completed ( ) <TAB><TAB> elif donel [ 0 ] : <TAB><TAB><TAB> observer . on_next ( True ) <TAB><TAB><TAB> observer . on_completed ( ),if len ( ql ) > 0 :,if doner [ 1 ] :,63.34395034744221,93.38,False
3247,"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB><TAB> data = list ( data ) <TAB><TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB><TAB> m_items = items . copy ( ) <TAB><TAB> for idx , item in enumerate ( items ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB><TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB><TAB><TAB> if i < len ( data ) and i > - 1 : <TAB><TAB><TAB><TAB> del data [ i ] <TAB><TAB> if is_tuple : <TAB><TAB><TAB> return tuple ( data ) <TAB><TAB> else : <TAB><TAB><TAB> return data <TAB> else : <TAB><TAB> return None",if item < 0 :,if abs ( item ) > abs ( item ) :,69.66742227694971,96.11,False
3248,"def _open_url ( cls , url ) : <TAB> if config . browser : <TAB><TAB> cmd = [ config . browser , url ] <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" running command:  %s "" % ""   "" . join ( cmd ) ) <TAB><TAB> p = Popen ( cmd ) <TAB><TAB> p . communicate ( ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" opening URL in browser:  %s "" % url ) <TAB><TAB> webbrowser . open_new ( url )",if not config . quiet :,if debug :,62.73083779152325,92.53,False
3249,"def setLabel ( self , s , protect = False ) : <TAB> """"""Set the label of the minibuffer."""""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB><TAB> # Support for the curses gui. <TAB><TAB> if hasattr ( g . app . gui , "" set_minibuffer_label "" ) : <TAB><TAB><TAB> g . app . gui . set_minibuffer_label ( c , s ) <TAB><TAB> w . setAllText ( s ) <TAB><TAB> n = len ( s ) <TAB><TAB> w . setSelectionRange ( n , n , insert = n ) <TAB><TAB> <MASK> <TAB><TAB><TAB> k . mb_prefix = s",if protect :,if protect :,100.0,100.00,True
3250,"def __init__ ( self , path ) : <TAB> self . symcaches = [ ] <TAB> for path in path . split ( "" ; "" ) : <TAB><TAB> if os . path . isdir ( path ) : <TAB><TAB><TAB> self . symcaches . append ( SymbolCache ( dirname = path ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> import cobra <TAB><TAB><TAB> self . symcaches . append ( cobra . CobraProxy ( path ) ) <TAB><TAB><TAB> continue","if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :","if os . name == ""nt"" :",90.17076556746765,84.45,False
3251,"def init_params ( net ) : <TAB> """"""Init layer parameters."""""" <TAB> for module in net . modules ( ) : <TAB><TAB> if isinstance ( module , nn . Conv2d ) : <TAB><TAB><TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB><TAB><TAB> if module . bias : <TAB><TAB><TAB><TAB> init . constant ( module . bias , 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> init . constant ( module . weight , 1 ) <TAB><TAB><TAB> init . constant ( module . bias , 0 ) <TAB><TAB> elif isinstance ( module , nn . Linear ) : <TAB><TAB><TAB> init . normal ( module . weight , std = 1e-3 ) <TAB><TAB><TAB> if module . bias : <TAB><TAB><TAB><TAB> init . constant ( module . bias , 0 )","elif isinstance ( module , nn . BatchNorm2d ) :","elif isinstance ( module , nn . BatchNorm2d ) :",75.0,100.00,True
3252,"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> removed . append ( key ) <TAB><TAB> elif old [ key ] != new [ key ] : <TAB><TAB><TAB> # modified is indicated by a remove and add <TAB><TAB><TAB> removed . append ( key ) <TAB><TAB><TAB> added . append ( key ) <TAB> for key , value in new . items ( ) : <TAB><TAB> if key not in old : <TAB><TAB><TAB> added . append ( key ) <TAB> if removed : <TAB><TAB> diff [ "" removed "" ] = sorted ( removed ) <TAB> if added : <TAB><TAB> diff [ "" added "" ] = sorted ( added ) <TAB> return diff",if key not in new :,if key not in new :,100.0,100.00,True
3253,"def __init__ ( self , * args , * * kwargs ) : <TAB> _kwargs = { <TAB><TAB> "" max_length "" : 20 , <TAB><TAB> "" widget "" : forms . TextInput ( attrs = { "" autocomplete "" : "" off "" } ) , <TAB><TAB> "" label "" : _ ( "" Card number "" ) , <TAB> } <TAB> if "" types "" in kwargs : <TAB><TAB> self . accepted_cards = set ( kwargs . pop ( "" types "" ) ) <TAB><TAB> difference = self . accepted_cards - VALID_CARDS <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" The following accepted_cards are  "" "" unknown:  %s "" % difference <TAB><TAB><TAB> ) <TAB> _kwargs . update ( kwargs ) <TAB> super ( ) . __init__ ( * args , * * _kwargs )",if difference :,if difference != 0 :,71.6623402442128,98.03,False
3254,"def dumps ( self ) : <TAB> sections = [ ] <TAB> for name , env_info in self . _dependencies_ . items ( ) : <TAB><TAB> sections . append ( "" [ENV_ %s ] "" % name ) <TAB><TAB> for var , values in sorted ( env_info . vars . items ( ) ) : <TAB><TAB><TAB> tmp = "" %s = "" % var <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp + = "" [ %s ] "" % "" , "" . join ( [ ' "" %s "" ' % val for val in values ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tmp + = "" %s "" % values <TAB><TAB><TAB> sections . append ( tmp ) <TAB> return "" \n "" . join ( sections )","if isinstance ( values , list ) :","if isinstance ( values , list ) :",100.0,100.00,True
3255,"def air_quality ( self ) : <TAB> aqi_data = self . _get_aqi_data ( ) <TAB> if aqi_data : <TAB><TAB> if aqi_data . get ( "" status "" ) == "" ok "" : <TAB><TAB><TAB> aqi_data = self . _organize ( aqi_data ) <TAB><TAB><TAB> aqi_data = self . _manipulate ( aqi_data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . py3 . error ( aqi_data . get ( "" data "" ) ) <TAB> return { <TAB><TAB> "" cached_until "" : self . py3 . time_in ( self . cache_timeout ) , <TAB><TAB> "" full_text "" : self . py3 . safe_format ( self . format , aqi_data ) , <TAB> }","elif aqi_data . get ( ""status"" ) == ""error"" :",if not aqi_data :,92.88400877349147,92.36,False
3256,"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB><TAB> if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB><TAB><TAB> return y <TAB><TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return y <TAB><TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB><TAB> if len ( x ) > len ( y ) : <TAB><TAB><TAB> result + = x [ len ( y ) : ] <TAB><TAB> elif len ( x ) < len ( y ) : <TAB><TAB><TAB> result + = y [ len ( x ) : ] <TAB><TAB> return result <TAB> return y","if not isinstance ( y , ( list , tuple ) ) :","if not isinstance ( y , ( list , tuple ) ) :",75.0,100.00,True
3257,"def _rate ( cls , sample1 , sample2 ) : <TAB> "" Simple rate "" <TAB> try : <TAB><TAB> interval = sample2 [ 0 ] - sample1 [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Infinity ( ) <TAB><TAB> delta = sample2 [ 1 ] - sample1 [ 1 ] <TAB><TAB> if delta < 0 : <TAB><TAB><TAB> raise UnknownValue ( ) <TAB><TAB> return ( sample2 [ 0 ] , delta / interval , sample2 [ 2 ] , sample2 [ 3 ] ) <TAB> except Infinity : <TAB><TAB> raise <TAB> except UnknownValue : <TAB><TAB> raise <TAB> except Exception as e : <TAB><TAB> raise NaN ( e )",if interval == 0 :,if interval < 0 :,98.8585206250148,98.01,False
3258,"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> if user_agent not in kwargs [ "" headers "" ] [ "" user-agent "" ] : <TAB><TAB><TAB><TAB> # Save the existing user-agent header and tack on our own. <TAB><TAB><TAB><TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB><TAB><TAB><TAB><TAB> f "" { user_agent }   "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB><TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB> else : <TAB><TAB> kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB> return request_method ( * args , * * kwargs )","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :","if ""user-agent"" in kwargs [ ""headers"" ] :",94.17033499441517,96.84,False
3259,"def remove_addons ( auth , resource_object_list ) : <TAB> for config in AbstractNode . ADDONS_AVAILABLE : <TAB><TAB> try : <TAB><TAB><TAB> settings_model = config . node_settings <TAB><TAB> except LookupError : <TAB><TAB><TAB> settings_model = None <TAB><TAB> <MASK> <TAB><TAB><TAB> addon_list = settings_model . objects . filter ( <TAB><TAB><TAB><TAB> owner__in = resource_object_list , is_deleted = False <TAB><TAB><TAB> ) <TAB><TAB><TAB> for addon in addon_list : <TAB><TAB><TAB><TAB> addon . after_delete ( auth . user )",if settings_model :,if settings_model :,100.0,100.00,True
3260,"def Decorator ( * args , * * kwargs ) : <TAB> delay = 0.2 <TAB> num_attempts = 15 <TAB> cur_attempt = 0 <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> return f ( * args , * * kwargs ) <TAB><TAB> except exceptions . WebDriverException as e : <TAB><TAB><TAB> logging . warning ( "" Selenium raised  %s "" , utils . SmartUnicode ( e ) ) <TAB><TAB><TAB> cur_attempt + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> time . sleep ( delay )",if cur_attempt == num_attempts :,if cur_attempt >= num_attempts :,98.54515575469512,98.49,False
3261,"def _cleanup_parts_dir ( parts_dir , local_plugins_dir , parts ) : <TAB> if os . path . exists ( parts_dir ) : <TAB><TAB> logger . info ( "" Cleaning up parts directory "" ) <TAB><TAB> for subdirectory in os . listdir ( parts_dir ) : <TAB><TAB><TAB> path = os . path . join ( parts_dir , subdirectory ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> shutil . rmtree ( path ) <TAB><TAB><TAB><TAB> except NotADirectoryError : <TAB><TAB><TAB><TAB><TAB> os . remove ( path ) <TAB> for part in parts : <TAB><TAB> part . mark_cleaned ( steps . BUILD ) <TAB><TAB> part . mark_cleaned ( steps . PULL )",if path != local_plugins_dir :,if os . path . exists ( path ) :,70.1368965388436,95.84,False
3262,"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB><TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB><TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB><TAB> # reach leaf <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB><TAB><TAB> tree , sample , cur_node_idx <TAB><TAB> ) <TAB><TAB> if reach_leaf : <TAB><TAB><TAB> node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB><TAB> node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB> return node_pos",if cur_node_idx == - 1 :,if cur_node_idx == - 1 :,100.0,100.00,True
3263,"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB><TAB> results = [ ] <TAB><TAB> if self . do_corr_and_slope : <TAB><TAB><TAB> if object_name == "" Image "" : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results + = [ "" Correlation "" ] <TAB><TAB> if self . do_overlap : <TAB><TAB><TAB> results + = [ "" Overlap "" , "" K "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> results + = [ "" Manders "" ] <TAB><TAB> if self . do_rwc : <TAB><TAB><TAB> results + = [ "" RWC "" ] <TAB><TAB> if self . do_costes : <TAB><TAB><TAB> results + = [ "" Costes "" ] <TAB><TAB> return results <TAB> return [ ]",if self . do_manders :,if self . do_mandatory :,99.11571885693424,99.09,False
3264,"def create_connection ( self , infos , f2 , laddr_infos , protocol ) : <TAB> for family in infos : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for laddr in laddr_infos : <TAB><TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB><TAB> except OSError : <TAB><TAB><TAB><TAB><TAB><TAB> protocol = "" foo "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB> except OSError : <TAB><TAB><TAB> protocol = "" bar "" <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise <TAB> return protocol",if f2 :,if family == f2 :,97.3354624947163,98.05,False
3265,"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB><TAB> if not hasattr ( request , "" app "" ) : <TAB><TAB><TAB> request . app = None <TAB><TAB><TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB><TAB><TAB> if len ( auth ) == 2 : <TAB><TAB><TAB><TAB> auth_prefix , auth_token = auth <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs )",if auth_prefix . lower ( ) == prefix :,if auth_prefix == prefix :,74.22692451915208,97.57,False
3266,"def when ( self , matches , context ) : <TAB> ret = [ ] <TAB> for episode in matches . named ( "" episode "" , lambda match : len ( match . initiator ) == 1 ) : <TAB><TAB> group = matches . markers . at_match ( <TAB><TAB><TAB> episode , lambda marker : marker . name == "" group "" , index = 0 <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not matches . range ( <TAB><TAB><TAB><TAB> * group . span , predicate = lambda match : match . name == "" title "" <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> ret . append ( episode ) <TAB> return ret",if group :,if group :,100.0,100.00,True
3267,def locate_via_pep514 ( spec ) : <TAB> with _PY_LOCK : <TAB><TAB> if not _PY_AVAILABLE : <TAB><TAB><TAB> from . import pep514 <TAB><TAB><TAB> _PY_AVAILABLE . extend ( pep514 . discover_pythons ( ) ) <TAB><TAB><TAB> _PY_AVAILABLE . append ( CURRENT ) <TAB> for cur_spec in _PY_AVAILABLE : <TAB><TAB> <MASK> <TAB><TAB><TAB> return cur_spec . path,if cur_spec . satisfies ( spec ) :,if cur_spec . name == spec . name :,68.11335518047044,94.47,False
3268,"def setCorkImageDefault ( self ) : <TAB> if settings . corkBackground [ "" image "" ] != "" "" : <TAB><TAB> i = self . cmbCorkImage . findData ( settings . corkBackground [ "" image "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . cmbCorkImage . setCurrentIndex ( i )",if i != - 1 :,if i != - 1 :,100.0,100.00,True
3269,"def _split_key ( key ) : <TAB> if isinstance ( key , util . string_types ) : <TAB><TAB> # coerce fooload('*') into ""default loader strategy"" <TAB><TAB> if key == _WILDCARD_TOKEN : <TAB><TAB><TAB> return ( _DEFAULT_TOKEN , ) <TAB><TAB> # coerce fooload("".*"") into ""wildcard on default entity"" <TAB><TAB> <MASK> <TAB><TAB><TAB> key = key [ 1 : ] <TAB><TAB> return key . split ( "" . "" ) <TAB> else : <TAB><TAB> return ( key , )","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :","if key [ 0 ] == ""*"" :",93.71758171121012,91.01,False
3270,"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self . list_nodes ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # This node has only one associated image. It is not the one we <TAB><TAB><TAB> # are after. <TAB><TAB><TAB> continue <TAB><TAB> for disk in node . image : <TAB><TAB><TAB> if disk . id == volume . id : <TAB><TAB><TAB><TAB> # Node found. We can now detach the volume <TAB><TAB><TAB><TAB> disk_id = disk . extra [ "" disk_id "" ] <TAB><TAB><TAB><TAB> return self . _do_detach_volume ( node . id , disk_id ) <TAB> return False",if type ( node . image ) is not list :,if node . id == volume . id :,70.57438384808361,95.45,False
3271,"def create ( self , private = False ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB><TAB><TAB> self . _bot . api_call ( <TAB><TAB><TAB><TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB><TAB><TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB><TAB> if e . error == "" user_is_bot "" : <TAB><TAB><TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB> else : <TAB><TAB><TAB> raise RoomError ( e )",if private :,if private :,100.0,100.00,True
3272,"def test_dataset_has_valid_etag ( self , dataset_name ) : <TAB> py_script_path = list ( filter ( lambda x : x , dataset_name . split ( "" / "" ) ) ) [ - 1 ] + "" .py "" <TAB> dataset_url = hf_bucket_url ( dataset_name , filename = py_script_path , dataset = True ) <TAB> etag = None <TAB> try : <TAB><TAB> response = requests . head ( <TAB><TAB><TAB> dataset_url , allow_redirects = True , proxies = None , timeout = 10 <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> etag = response . headers . get ( "" Etag "" ) <TAB> except ( EnvironmentError , requests . exceptions . Timeout ) : <TAB><TAB> pass <TAB> self . assertIsNotNone ( etag )",if response . status_code == 200 :,"if response . status_code == 200 and ""etag"" in response . headers :",69.17976377732646,95.59,False
3273,"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB><TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB><TAB> if os . path . islink ( dirpath ) : <TAB><TAB><TAB> continue <TAB><TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . chmod ( dirpath , mode )",if not self . dry_run :,if not self . is_chmod_supported ( dirpath ) :,70.06411962498177,93.31,False
3274,"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> for _ in range ( 3 ) : <TAB><TAB><TAB><TAB> self . _process . terminate ( ) <TAB><TAB><TAB><TAB> time . sleep ( 0.5 ) <TAB><TAB><TAB><TAB> if self . _process . poll ( ) is not None : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _process . kill ( ) <TAB><TAB><TAB><TAB> self . _process . wait ( ) <TAB><TAB><TAB><TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB><TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" )",if self . _process . poll ( ) is None :,if self . _process . is_alive ( ) :,97.198122330099,98.05,False
3275,"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB><TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield current_word <TAB><TAB><TAB><TAB> current_word = [ ] <TAB><TAB> elif current_word and self . char_begins_new_word ( current_word , char ) : <TAB><TAB><TAB> yield current_word <TAB><TAB><TAB> current_word = [ char ] <TAB><TAB> else : <TAB><TAB><TAB> current_word . append ( char ) <TAB> <MASK> <TAB><TAB> yield current_word",if current_word :,if current_word :,100.0,100.00,True
3276,"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB><TAB> for spec in specs [ i ] . __sro__ : <TAB><TAB><TAB> comps = components . get ( spec ) <TAB><TAB><TAB> if comps : <TAB><TAB><TAB><TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return r <TAB> else : <TAB><TAB> for iface in provided : <TAB><TAB><TAB> comps = components . get ( iface ) <TAB><TAB><TAB> if comps : <TAB><TAB><TAB><TAB> r = comps . get ( name ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return r <TAB> return None",if r is not None :,if r :,67.1334630988595,96.28,False
3277,"def run ( cmd , task = None ) : <TAB> process = subprocess . Popen ( <TAB><TAB> cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , close_fds = True <TAB> ) <TAB> output_lines = [ ] <TAB> while True : <TAB><TAB> line = process . stdout . readline ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> line = line . decode ( "" utf-8 "" ) <TAB><TAB> output_lines + = [ line ] <TAB><TAB> logger . info ( line . rstrip ( "" \n "" ) ) <TAB> process . stdout . close ( ) <TAB> exit_code = process . wait ( ) <TAB> if exit_code : <TAB><TAB> output = "" "" . join ( output_lines ) <TAB><TAB> raise subprocess . CalledProcessError ( exit_code , cmd , output = output )",if not line :,if not line :,100.0,100.00,True
3278,"def process_response ( self , request , response ) : <TAB> if ( <TAB><TAB> response . status_code == 404 <TAB><TAB> and request . path_info . endswith ( "" / "" ) <TAB><TAB> and not is_valid_path ( request . path_info ) <TAB><TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB><TAB> # Use request.path because we munged app/locale in path_info. <TAB><TAB> newurl = request . path [ : - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> with safe_query_string ( request ) : <TAB><TAB><TAB><TAB> newurl + = "" ? "" + request . META [ "" QUERY_STRING "" ] <TAB><TAB> return HttpResponsePermanentRedirect ( newurl ) <TAB> return response",if request . GET :,"if request . META [ ""QUERY_STRING"" ] :",98.27638984326053,95.63,False
3279,"def dependencies ( self ) : <TAB> deps = [ ] <TAB> midx = None <TAB> if self . ref is not None : <TAB><TAB> query = TypeQuery ( self . ref ) <TAB><TAB> super = query . execute ( self . schema ) <TAB><TAB> if super is None : <TAB><TAB><TAB> log . debug ( self . schema ) <TAB><TAB><TAB> raise TypeNotFound ( self . ref ) <TAB><TAB> <MASK> <TAB><TAB><TAB> deps . append ( super ) <TAB><TAB><TAB> midx = 0 <TAB> return ( midx , deps )",if not super . builtin ( ) :,if super . is_module :,91.6362903907131,95.56,False
3280,"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB><TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB> vtkjs = f . read ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB> vtkjs = data_url . read ( ) <TAB><TAB> elif hasattr ( self . object , "" read "" ) : <TAB><TAB><TAB> vtkjs = self . object . read ( ) <TAB><TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs",if isfile ( self . object ) :,"if hasattr ( self . object , ""open"" ) :",97.06703755335126,96.58,False
3281,"def _save ( self ) : <TAB> fd , tempname = tempfile . mkstemp ( ) <TAB> fd = os . fdopen ( fd , "" w "" ) <TAB> json . dump ( self . _cache , fd , indent = 2 , separators = ( "" , "" , "" :  "" ) ) <TAB> fd . close ( ) <TAB> # Silently ignore errors <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( os . path . dirname ( self . filename ) ) <TAB><TAB> shutil . move ( tempname , self . filename ) <TAB> except ( IOError , OSError ) : <TAB><TAB> os . remove ( tempname )",if not os . path . exists ( os . path . dirname ( self . filename ) ) :,if not os . path . exists ( os . path . dirname ( self . filename ) ),99.051333740413,98.53,False
3282,"def refiner_configs ( self ) : <TAB> rv = { } <TAB> for refiner in refiner_manager : <TAB><TAB> <MASK> <TAB><TAB><TAB> rv [ refiner . name ] = { k : v for k , v in self . config . items ( refiner . name ) } <TAB> return rv",if self . config . has_section ( refiner . name ) :,if refiner . name in self . config :,89.29398685863701,87.36,False
3283,"def com_slice ( self , primary , node , assigning ) : <TAB> # short_slice:  [lower_bound] "":"" [upper_bound] <TAB> lower = upper = None <TAB> if len ( node . children ) == 2 : <TAB><TAB> <MASK> <TAB><TAB><TAB> upper = self . com_node ( node . children [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> lower = self . com_node ( node . children [ 0 ] ) <TAB> elif len ( node . children ) == 3 : <TAB><TAB> lower = self . com_node ( node . children [ 0 ] ) <TAB><TAB> upper = self . com_node ( node . children [ 2 ] ) <TAB> return Slice ( primary , assigning , lower , upper , lineno = extractLineNo ( node ) )",if node . children [ 0 ] . type == token . COLON :,if node . children [ 1 ] :,71.66862218675305,95.07,False
3284,"def close ( self , * args , * * kwargs ) : <TAB> super ( mytqdm , self ) . close ( * args , * * kwargs ) <TAB> # If it was not run in a notebook, sp is not assigned, check for it <TAB> if hasattr ( self , "" sp "" ) : <TAB><TAB> # Try to detect if there was an error or KeyboardInterrupt <TAB><TAB> # in manual mode: if n < total, things probably got wrong <TAB><TAB> if self . total and self . n < self . total : <TAB><TAB><TAB> self . sp ( bar_style = "" danger "" ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . sp ( bar_style = "" success "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . sp ( close = True )",if self . leave :,if self . n == 0 :,98.75742088001525,97.51,False
3285,"def test_alloc ( self ) : <TAB> b = bytearray ( ) <TAB> alloc = b . __alloc__ ( ) <TAB> self . assertTrue ( alloc > = 0 ) <TAB> seq = [ alloc ] <TAB> for i in range ( 100 ) : <TAB><TAB> b + = b "" x "" <TAB><TAB> alloc = b . __alloc__ ( ) <TAB><TAB> self . assertTrue ( alloc > = len ( b ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> seq . append ( alloc )",if alloc not in seq :,if alloc not in seq :,100.0,100.00,True
3286,"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> <MASK> <TAB><TAB> f . compress = zlib . compressobj ( <TAB><TAB><TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB><TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB><TAB> <MASK> <TAB><TAB><TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB><TAB><TAB> if open_files > self . MAX_OPEN_FILES : <TAB><TAB><TAB><TAB> f . fileobj . close ( ) <TAB><TAB><TAB><TAB> f . fileobj = None <TAB><TAB> else : <TAB><TAB><TAB> f . close ( ) <TAB><TAB><TAB> self . files . pop ( key )",if self . compress :,"if key == ""file"" :",75.00749177021693,93.88,False
3287,"def _run ( self ) : <TAB> # Low-level run method to do the actual scheduling loop. <TAB> self . running = True <TAB> while self . running : <TAB><TAB> try : <TAB><TAB><TAB> self . sched . run ( ) <TAB><TAB> except Exception as x : <TAB><TAB><TAB> logging . error ( <TAB><TAB><TAB><TAB> "" Error during scheduler execution:  %s "" % str ( x ) , exc_info = True <TAB><TAB><TAB> ) <TAB><TAB> # queue is empty; sleep a short while before checking again <TAB><TAB> <MASK> <TAB><TAB><TAB> time . sleep ( 5 )",if self . running :,if self . queue is empty :,73.16151621821272,97.37,False
3288,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 16 :,if tt == 16 :,100.0,100.00,True
3289,"def check ( dbdef ) : <TAB> "" drop script must clear the database "" <TAB> for version in dbdef : <TAB><TAB> connector = MemConnector ( ) . bound ( None ) <TAB><TAB> create ( dbdef , version , connector ) <TAB><TAB> drop ( dbdef , version , connector ) <TAB><TAB> remaining = connector . execute ( <TAB><TAB><TAB> "" SELECT * FROM sqlite_master WHERE name NOT LIKE  ' sqlite_ % ' "" <TAB><TAB> ) . fetchall ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield "" {0} :drop.sql "" . format ( version ) , remaining",if remaining :,if remaining :,100.0,100.00,True
3290,"def test_open_overwrite_offset_size ( self , sftp ) : <TAB> """"""Test writing data at a specific offset"""""" <TAB> f = None <TAB> try : <TAB><TAB> self . _create_file ( "" file "" , "" xxxxyyyy "" ) <TAB><TAB> f = yield from sftp . open ( "" file "" , "" r+ "" ) <TAB><TAB> yield from f . write ( "" zz "" , 3 ) <TAB><TAB> yield from f . close ( ) <TAB><TAB> with open ( "" file "" ) as localf : <TAB><TAB><TAB> self . assertEqual ( localf . read ( ) , "" xxxzzyyy "" ) <TAB> finally : <TAB><TAB> <MASK> # pragma: no branch <TAB><TAB><TAB> yield from f . close ( ) <TAB><TAB> remove ( "" file "" )",if f :,if f :,100.0,100.00,True
3291,"def pump ( ) : <TAB> import sys as _sys <TAB> while self . countdown_active ( ) : <TAB><TAB> if not ( self . connected ( "" send "" ) and other . connected ( "" recv "" ) ) : <TAB><TAB><TAB> break <TAB><TAB> try : <TAB><TAB><TAB> data = other . recv ( timeout = 0.05 ) <TAB><TAB> except EOFError : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if not data : <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> self . send ( data ) <TAB><TAB> except EOFError : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB> self . shutdown ( "" send "" ) <TAB> other . shutdown ( "" recv "" )",if not _sys :,if not data :,72.87965396060757,96.99,False
3292,"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB><TAB> dd = tup [ 1 ] <TAB><TAB> if "" results.train_y_misclass "" in dd : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB><TAB> if "" hyper_parameters "" in key : <TAB><TAB><TAB> print ( key + "" :  "" + str ( value ) )","if dd [ ""results.train_y_misclass"" ] < optimal_measure :","if ""best_fit"" in dd [ ""results.train_y_misclass""",67.56854751706429,96.04,False
3293,"def valid ( self ) : <TAB> valid = True <TAB> <MASK> <TAB><TAB> return valid <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> with io . open ( self . pathfile , "" w "" , encoding = "" utf-8 "" ) as f : <TAB><TAB><TAB><TAB> f . close ( ) # do nothing <TAB><TAB> except OSError : <TAB><TAB><TAB> valid = False <TAB><TAB> <MASK> <TAB><TAB><TAB> os . remove ( self . pathfile ) <TAB><TAB> return valid",if os . path . exists ( self . pathfile ) :,if self . pathfile is None :,58.756431959421775,87.42,False
3294,"def __getitem__ ( self , key ) : <TAB> try : <TAB><TAB> value = self . cache [ key ] <TAB> except KeyError : <TAB><TAB> f = BytesIO ( self . dict [ key . encode ( self . keyencoding ) ] ) <TAB><TAB> value = Unpickler ( f ) . load ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . cache [ key ] = value <TAB> return value",if self . writeback :,if value :,69.80217173984285,95.84,False
3295,"def hasMenu ( cls , callingWindow , mainItem , selection , * fullContexts ) : <TAB> for i , fullContext in enumerate ( fullContexts ) : <TAB><TAB> srcContext = fullContext [ 0 ] <TAB><TAB> for menuHandler in cls . menus : <TAB><TAB><TAB> m = menuHandler ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB><TAB> return False","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",if m . selected ( ) and m . selected ( ) == srcContext :,60.90705822870306,88.62,False
3296,"def lr_read_tables ( module = tab_module , optimize = 0 ) : <TAB> global _lr_action , _lr_goto , _lr_productions , _lr_method <TAB> try : <TAB><TAB> exec ( "" import  %s  as parsetab "" % module ) <TAB><TAB> global parsetab # declare the name of the imported module <TAB><TAB> <MASK> <TAB><TAB><TAB> _lr_action = parsetab . _lr_action <TAB><TAB><TAB> _lr_goto = parsetab . _lr_goto <TAB><TAB><TAB> _lr_productions = parsetab . _lr_productions <TAB><TAB><TAB> _lr_method = parsetab . _lr_method <TAB><TAB><TAB> return 1 <TAB><TAB> else : <TAB><TAB><TAB> return 0 <TAB> except ( ImportError , AttributeError ) : <TAB><TAB> return 0",if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,if optimize :,92.36243609233266,91.07,False
3297,"def _Determine_Do ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB><TAB> self . applicable = 1 <TAB><TAB> for opt , optarg in self . chosenOptions : <TAB><TAB><TAB> if opt == "" --moz-tools "" : <TAB><TAB><TAB><TAB> self . value = os . path . abspath ( os . path . normpath ( optarg ) ) <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . value = os . environ [ self . name ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . value = None <TAB> else : <TAB><TAB> self . applicable = 0 <TAB> self . determined = 1",if os . environ . has_key ( self . name ) :,if self . name in os . environ :,93.99213269492154,95.12,False
3298,"def parse_chunked ( self , unreader ) : <TAB> ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB> while size > 0 : <TAB><TAB> while size > len ( rest ) : <TAB><TAB><TAB> size - = len ( rest ) <TAB><TAB><TAB> yield rest <TAB><TAB><TAB> rest = unreader . read ( ) <TAB><TAB><TAB> if not rest : <TAB><TAB><TAB><TAB> raise NoMoreData ( ) <TAB><TAB> yield rest [ : size ] <TAB><TAB> # Remove \r\n after chunk <TAB><TAB> rest = rest [ size : ] <TAB><TAB> while len ( rest ) < 2 : <TAB><TAB><TAB> rest + = unreader . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB><TAB> ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] )","if rest [ : 2 ] != b""\r\n"" :",if not rest :,97.17141513272944,94.09,False
3299,"def _scroll_down ( self , cli ) : <TAB> "" Scroll window down. "" <TAB> info = self . render_info <TAB> if self . vertical_scroll < info . content_height - info . window_height : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . content . move_cursor_down ( cli ) <TAB><TAB> self . vertical_scroll + = 1",if info . cursor_position . y <= info . configured_scroll_offsets . top :,if self . vertical_scroll > info . content_height - info . window_height :,88.44910516451681,85.06,False
3300,"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self . distribution . has_data_files ( ) : <TAB><TAB> for item in self . distribution . data_files : <TAB><TAB><TAB> if isinstance ( item , str ) : <TAB><TAB><TAB><TAB> # plain file <TAB><TAB><TAB><TAB> item = convert_path ( item ) <TAB><TAB><TAB><TAB> if os . path . isfile ( item ) : <TAB><TAB><TAB><TAB><TAB> self . filelist . append ( item ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # a (dirname, filenames) tuple <TAB><TAB><TAB><TAB> dirname , filenames = item <TAB><TAB><TAB><TAB> for f in filenames : <TAB><TAB><TAB><TAB><TAB> f = convert_path ( f ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> self . filelist . append ( f )",if os . path . isfile ( f ) :,if os . path . isfile ( f ) :,75.0,100.00,True
3301,"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if i == 2 and self . count < 1 : <TAB><TAB><TAB> self . count + = 1 <TAB><TAB><TAB> raise TemporaryProblem <TAB><TAB> if i == 7 and self . count < 4 : <TAB><TAB><TAB> self . count + = 1 <TAB><TAB><TAB> raise TemporaryProblem <TAB><TAB> yield i",if i <= start_after :,if i == start_after :,98.3998591325683,98.31,False
3302,"def is_open ( self ) : <TAB> if self . signup_code : <TAB><TAB> return True <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . messages . get ( "" invalid_signup_code "" ) : <TAB><TAB><TAB><TAB> messages . add_message ( <TAB><TAB><TAB><TAB><TAB> self . request , <TAB><TAB><TAB><TAB><TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB><TAB><TAB><TAB><TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB><TAB><TAB><TAB><TAB><TAB> * * { <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" code "" : self . get_code ( ) , <TAB><TAB><TAB><TAB><TAB><TAB> } <TAB><TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP",if self . signup_code_present :,"if settings . ACCOUNT_OPEN_SIGNUP in self . messages [ ""invalid_signup",68.18760195263297,94.59,False
3303,"def on_delete_from_disk ( self , widget , data = None ) : <TAB> model , iter = self . get_selection ( ) . get_selected ( ) <TAB> if iter : <TAB><TAB> path = model . get_value ( iter , COLUMN_PATH ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ErrorDialog ( _ ( "" Can ' t delete system item from disk. "" ) ) . launch ( ) <TAB><TAB> else : <TAB><TAB><TAB> os . remove ( path ) <TAB> self . update_items ( )",if self . is_defaultitem ( path ) :,if not os . path . exists ( path ) :,72.24734109267678,94.90,False
3304,"def get_detections_for_batch ( self , images ) : <TAB> images = images [ . . . , : : - 1 ] <TAB> detected_faces = self . face_detector . detect_from_batch ( images . copy ( ) ) <TAB> results = [ ] <TAB> for i , d in enumerate ( detected_faces ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> results . append ( None ) <TAB><TAB><TAB> continue <TAB><TAB> d = d [ 0 ] <TAB><TAB> d = np . clip ( d , 0 , None ) <TAB><TAB> x1 , y1 , x2 , y2 = map ( int , d [ : - 1 ] ) <TAB><TAB> results . append ( ( x1 , y1 , x2 , y2 ) ) <TAB> return results",if len ( d ) == 0 :,if i == 0 :,78.99657383195238,97.18,False
3305,def on_update ( self ) : <TAB> # <TAB> # Calculate maximum # of planes per well <TAB> # <TAB> self . max_per_well = 0 <TAB> for pd in list ( self . plate_well_site . values ( ) ) : <TAB><TAB> for wd in list ( pd . values ( ) ) : <TAB><TAB><TAB> nplanes = sum ( [ len ( x ) for x in list ( wd . values ( ) ) ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . max_per_well = nplanes <TAB> for registrant in self . registrants : <TAB><TAB> registrant ( ),if nplanes > self . max_per_well :,if nplanes > self . max_per_well :,75.0,100.00,True
3306,"def is_writable ( self , path ) : <TAB> result = False <TAB> while not result : <TAB><TAB> if os . path . exists ( path ) : <TAB><TAB><TAB> result = os . access ( path , os . W_OK ) <TAB><TAB><TAB> break <TAB><TAB> parent = os . path . dirname ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> path = parent <TAB> return result",if parent == path :,if parent == path :,100.0,100.00,True
3307,"def _check_seed ( self , seed ) : <TAB> if seed is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _raise_error ( <TAB><TAB><TAB><TAB> "" The random number generator seed value, seed, should be integer type or None. "" <TAB><TAB><TAB> ) <TAB><TAB> if seed < 0 : <TAB><TAB><TAB> self . _raise_error ( <TAB><TAB><TAB><TAB> "" The random number generator seed value, seed, should be non-negative integer or None. "" <TAB><TAB><TAB> )",if type ( seed ) != int :,"if not isinstance ( seed , ( int , long ) ) :",87.437759922558,92.96,False
3308,"def write ( self , x ) : <TAB> # try to use backslash and surrogate escape strategies before failing <TAB> self . _errors = "" backslashescape "" if self . encoding != "" mbcs "" else "" surrogateescape "" <TAB> try : <TAB><TAB> return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) ) <TAB> except UnicodeDecodeError : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _errors = "" surrogateescape "" <TAB><TAB> else : <TAB><TAB><TAB> self . _errors = "" replace "" <TAB><TAB> return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) )","if self . _errors != ""surrogateescape"" :","if self . encoding == ""mbcs"" :",73.07100802787367,96.08,False
3309,"def post ( self , request , * args , * * kwargs ) : <TAB> validated_session = [ ] <TAB> for session_id in request . data : <TAB><TAB> session = get_object_or_none ( Session , id = session_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> validated_session . append ( session_id ) <TAB><TAB><TAB> self . model . objects . create ( <TAB><TAB><TAB><TAB> name = "" kill_session "" , <TAB><TAB><TAB><TAB> args = session . id , <TAB><TAB><TAB><TAB> terminal = session . terminal , <TAB><TAB><TAB> ) <TAB> return Response ( { "" ok "" : validated_session } )",if session and not session . is_finished :,if session :,76.64312460490382,95.54,False
3310,"def _has_list_or_dict_var_value_before ( self , arg_index ) : <TAB> for idx , value in enumerate ( self . args ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> if variablematcher . is_list_variable ( <TAB><TAB><TAB> value <TAB><TAB> ) and not variablematcher . is_list_variable_subitem ( value ) : <TAB><TAB><TAB> return True <TAB><TAB> if robotapi . is_dict_var ( value ) and not variablematcher . is_dict_var_access ( <TAB><TAB><TAB> value <TAB><TAB> ) : <TAB><TAB><TAB> return True <TAB> return False",if idx > arg_index :,if idx < arg_index :,73.36529600537662,98.62,False
3311,"def test_return_correct_type ( self ) : <TAB> for proto in protocols : <TAB><TAB> # Protocol 0 supports only ASCII strings. <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _check_return_correct_type ( "" abc "" , 0 ) <TAB><TAB> else : <TAB><TAB><TAB> for obj in [ b "" abc \n "" , "" abc \n "" , - 1 , - 1.1 * 0.1 , str ] : <TAB><TAB><TAB><TAB> self . _check_return_correct_type ( obj , proto )",if proto == 0 :,if proto == 0 :,100.0,100.00,True
3312,"def backward_impl ( self , inputs , outputs , prop_down , accum ) : <TAB> # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB> # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB> # Args <TAB> axis = self . forward_func . info . args [ "" axis "" ] <TAB> # Compute <TAB> ## w.r.t. dy <TAB> if prop_down [ - 1 ] : <TAB><TAB> g_dy = inputs [ - 1 ] . grad <TAB><TAB> g_dy_ = F . stack ( * [ o . grad for o in outputs ] , axis = axis ) <TAB><TAB> <MASK> <TAB><TAB><TAB> g_dy + = g_dy_ <TAB><TAB> else : <TAB><TAB><TAB> g_dy . copy_from ( g_dy_ )",if accum [ - 1 ] :,if accum [ - 1 ] :,75.0,100.00,True
3313,"def remove ( self , url ) : <TAB> try : <TAB><TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB><TAB> pass <TAB> else : <TAB><TAB> was_selected = i in self . selectedindices ( ) <TAB><TAB> self . list . delete ( i ) <TAB><TAB> del self . items [ i ] <TAB><TAB> if not self . items : <TAB><TAB><TAB> self . mp . hidepanel ( self . name ) <TAB><TAB> elif was_selected : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> self . list . select_set ( i )",if i >= len ( self . items ) :,if i == 0 :,91.7978609464422,95.27,False
3314,"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB><TAB> if not tag . text : <TAB><TAB><TAB> tag . text = "" "" <TAB><TAB> if len ( root ) > 0 : <TAB><TAB><TAB> root [ - 1 ] . tail = tag . text <TAB><TAB><TAB> tag . text = root_text <TAB><TAB> else : <TAB><TAB><TAB> tag . text = root_text + tag . text <TAB><TAB> <MASK> <TAB><TAB><TAB> root = deepcopy ( list ( root ) ) <TAB><TAB> tag [ : 0 ] = root <TAB><TAB> root = tag [ : len ( root ) ] <TAB> return self",if i > 0 :,if i == 0 :,99.00855793375425,98.40,False
3315,"def _get_tracks_compositors_list ( ) : <TAB> tracks_list = [ ] <TAB> tracks = current_sequence ( ) . tracks <TAB> compositors = current_sequence ( ) . compositors <TAB> for track_index in range ( 1 , len ( tracks ) - 1 ) : <TAB><TAB> track_compositors = [ ] <TAB><TAB> for j in range ( 0 , len ( compositors ) ) : <TAB><TAB><TAB> comp = compositors [ j ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> track_compositors . append ( comp ) <TAB><TAB> tracks_list . append ( track_compositors ) <TAB> return tracks_list",if comp . transition . b_track == track_index :,if comp not in tracks :,66.42205704884427,92.81,False
3316,"def __getattr__ ( self , name ) : <TAB> if name in self . _sections : <TAB><TAB> return "" \n "" . join ( self . _sections [ name ] ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" "" <TAB><TAB> else : <TAB><TAB><TAB> raise ConanException ( "" ConfigParser: Unrecognized field  ' %s ' "" % name )",if self . _allowed_fields and name in self . _allowed_fields :,"if name == ""name"" :",64.05609515620444,85.84,False
3317,"def get_first_param_index ( self , group_id , param_group , partition_id ) : <TAB> for index , param in enumerate ( param_group ) : <TAB><TAB> param_id = self . get_param_id ( param ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return index <TAB> return None",if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,if param_id == group_id and param_id == partition_id :,55.93097741310985,81.29,False
3318,"def handle_uv_sockets ( self , context ) : <TAB> u_socket = self . inputs [ "" U "" ] <TAB> v_socket = self . inputs [ "" V "" ] <TAB> if self . cast_mode == "" Sphere "" : <TAB><TAB> u_socket . hide_safe = True <TAB><TAB> v_socket . hide_safe = True <TAB> elif self . cast_mode in [ "" Cylinder "" , "" Prism "" ] : <TAB><TAB> v_socket . hide_safe = True <TAB><TAB> <MASK> <TAB><TAB><TAB> u_socket . hide_safe = False <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> u_socket . hide_safe = False <TAB><TAB> if v_socket . hide_safe : <TAB><TAB><TAB> v_socket . hide_safe = False",if u_socket . hide_safe :,if u_socket . hide_safe :,100.0,100.00,True
3319,"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> source = os . path . join ( root , filename ) <TAB><TAB><TAB> with open ( source , "" r "" ) as f : <TAB><TAB><TAB><TAB> lines = f . readlines ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> with open ( source , "" w "" ) as f : <TAB><TAB><TAB><TAB> if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) : <TAB><TAB><TAB><TAB><TAB> f . write ( lines [ 0 ] ) <TAB><TAB><TAB><TAB> for line in lines [ 1 : ] : <TAB><TAB><TAB><TAB><TAB> f . write ( line )",if len ( lines ) < 1 :,if not lines :,70.03421656939994,97.39,False
3320,"def inner ( request , * args , * * kwargs ) : <TAB> page = request . current_page <TAB> if page : <TAB><TAB> if page . login_required and not request . user . is_authenticated : <TAB><TAB><TAB> return redirect_to_login ( <TAB><TAB><TAB><TAB> urlquote ( request . get_full_path ( ) ) , settings . LOGIN_URL <TAB><TAB><TAB> ) <TAB><TAB> site = get_current_site ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return _handle_no_page ( request ) <TAB> return func ( request , * args , * * kwargs )","if not user_can_view_page ( request . user , page , site ) :",if not site :,65.7803465697955,90.10,False
3321,"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB><TAB> self . _last_updated = time . time ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB><TAB> except OSError : <TAB><TAB><TAB> if "" _create_temporary "" in traceback . format_exc ( ) : <TAB><TAB><TAB><TAB> self . _locked_flush_without_tempfile ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise <TAB><TAB> self . _last_updated = time . time ( )","if kwargs . get ( ""in_place"" , False ) :","if ""create_temporary"" in traceback . format_exc ( ) :",94.33587686054442,94.93,False
3322,"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB><TAB> if key not in valid_keys : <TAB><TAB><TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB><TAB><TAB><TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB><TAB><TAB><TAB><TAB> 1024 <TAB><TAB><TAB><TAB> )","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :","if key in kwargs [ ""event_data"" ] :",68.12375607620734,91.05,False
3323,"def parse_auth ( val ) : <TAB> if val is not None : <TAB><TAB> authtype , params = val . split ( ""   "" , 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if authtype == "" Basic "" and ' "" ' not in params : <TAB><TAB><TAB><TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> params = parse_auth_params ( params ) <TAB><TAB> return authtype , params <TAB> return val",if authtype in known_auth_schemes :,if params :,78.88492889406325,94.63,False
3324,"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB><TAB> value , last_update = self . cache [ args ] <TAB><TAB> age = now - last_update <TAB><TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB><TAB><TAB> self . _call_count = 0 <TAB><TAB><TAB> raise AttributeError <TAB><TAB> if self . ctl : <TAB><TAB><TAB> self . _call_count + = 1 <TAB><TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB><TAB> value = func ( * args ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . cache [ args ] = ( value , now ) <TAB><TAB> return value <TAB> except TypeError : <TAB><TAB> return func ( * args )",if value :,if value is not None :,70.43077314845212,97.98,False
3325,"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t . theme_style == "" Dark "" : <TAB><TAB> if self . md_bg_color == t . primary_color : <TAB><TAB><TAB> c = t . primary_dark <TAB><TAB> <MASK> <TAB><TAB><TAB> c = t . accent_dark <TAB> return c",elif self . md_bg_color == t . accent_color :,elif self . md_bg_color == t . accent_color :,100.0,100.00,True
3326,def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB><TAB> part_l = i <TAB><TAB> part_h = 0 <TAB><TAB> for j in range ( 8 ) : <TAB><TAB><TAB> rflag = part_l & 1 <TAB><TAB><TAB> part_l >> = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> part_l | = 1 << 31 <TAB><TAB><TAB> part_h >> = 1 <TAB><TAB><TAB> if rflag : <TAB><TAB><TAB><TAB> part_h ^ = 0xD8000000 <TAB><TAB> _table_h . append ( part_h ) <TAB> return _table_h,if part_h & 1 :,if j == i :,77.47250937104477,96.83,False
3327,"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB><TAB> if not old_obj . summary : <TAB><TAB><TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB><TAB><TAB> continue <TAB><TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB><TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB><TAB> self . session_new . add ( new_obj )",if key not in old_obj . __table__ . columns :,if key in old_obj . __table__ . columns . _data :,96.12661427550655,97.19,False
3328,"def get_in_turn_repetition ( pred , is_cn = False ) : <TAB> """"""Get in-turn repetition."""""" <TAB> if len ( pred ) == 0 : <TAB><TAB> return 1.0 <TAB> if isinstance ( pred [ 0 ] , str ) : <TAB><TAB> pred = [ tok . lower ( ) for tok in pred ] <TAB><TAB> if is_cn : <TAB><TAB><TAB> pred = "" "" . join ( pred ) <TAB> tri_grams = set ( ) <TAB> for i in range ( len ( pred ) - 2 ) : <TAB><TAB> tri_gram = tuple ( pred [ i : i + 3 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return 1.0 <TAB><TAB> tri_grams . add ( tri_gram ) <TAB> return 0.0",if tri_gram in tri_grams :,if tri_gram in tri_grams :,100.0,100.00,True
3329,"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( ) # Discard attribute list from reader. <TAB> attrs = { } <TAB> d = AttributeList . match . groupdict ( ) <TAB> for k , v in d . items ( ) : <TAB><TAB> if v is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> v = subs_attrs ( v ) <TAB><TAB><TAB><TAB> if v : <TAB><TAB><TAB><TAB><TAB> parse_attributes ( v , attrs ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> AttributeList . attrs [ k ] = v <TAB> AttributeList . subs ( attrs ) <TAB> AttributeList . attrs . update ( attrs )","if k == ""attrlist"" :","if isinstance ( v , ( list , tuple ) ) :",96.57912547368518,94.37,False
3330,"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB><TAB> if "" axis "" in self . args : <TAB><TAB><TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB> if "" momentum "" in self . args : <TAB><TAB><TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if not isinstance ( self . axis , int ) :","if not isinstance ( self . axis , ( int , float ) ) :",72.05787142533515,97.19,False
3331,"def __getattr__ ( self , attrname ) : <TAB> if attrname in ( "" visamp "" , "" visamperr "" , "" visphi "" , "" visphierr "" ) : <TAB><TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB> elif attrname in ( "" cflux "" , "" cfluxerr "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> else : <TAB><TAB> raise AttributeError ( attrname )","if self . __dict__ [ ""_"" + attrname ] != None :","if self . __dict__ [ ""_"" + attrname ] :",71.738872592486,97.51,False
3332,"def draw ( self , context ) : <TAB> layout = self . layout <TAB> presets . draw_presets_ops ( layout , context = context ) <TAB> for category in presets . get_category_names ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> class_name = preset_category_menus [ category ] . __name__ <TAB><TAB><TAB><TAB> layout . menu ( class_name )",if category in preset_category_menus :,if category in preset_category_menus :,100.0,100.00,True
3333,"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB><TAB> info , reference = value <TAB><TAB> if info not in self . _reverse_infos : <TAB><TAB><TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB><TAB><TAB> self . _infos . append ( info ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB><TAB><TAB> self . _references . append ( reference ) <TAB><TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB><TAB><TAB> self . _reverse_infos [ info ] , <TAB><TAB><TAB> self . _reverse_references [ reference ] , <TAB><TAB> ) <TAB> else : <TAB><TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) )",if reference not in self . _reverse_references :,if reference not in self . _reverse_references :,100.0,100.00,True
3334,"def format_bpe_text ( symbols , delimiter = b "" @@ "" ) : <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [ ] <TAB> word = b "" "" <TAB> if isinstance ( symbols , str ) : <TAB><TAB> symbols = symbols . encode ( ) <TAB> delimiter_len = len ( delimiter ) <TAB> for symbol in symbols : <TAB><TAB> <MASK> <TAB><TAB><TAB> word + = symbol [ : - delimiter_len ] <TAB><TAB> else : # end of a word <TAB><TAB><TAB> word + = symbol <TAB><TAB><TAB> words . append ( word ) <TAB><TAB><TAB> word = b "" "" <TAB> return b ""   "" . join ( words )",if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,if symbol . endswith ( delimiter ) :,82.35088061641844,89.47,False
3335,"def output_type ( data , request , response ) : <TAB> accept = request . accept <TAB> if accept in ( "" "" , "" * "" , "" / "" ) : <TAB><TAB> handler = default or handlers and next ( iter ( handlers . values ( ) ) ) <TAB> else : <TAB><TAB> handler = default <TAB><TAB> accepted = [ accept_quality ( accept_type ) for accept_type in accept . split ( "" , "" ) ] <TAB><TAB> accepted . sort ( key = itemgetter ( 0 ) ) <TAB><TAB> for _quality , accepted_content_type in reversed ( accepted ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> handler = handlers [ accepted_content_type ] <TAB><TAB><TAB><TAB> break <TAB> if not handler : <TAB><TAB> raise falcon . HTTPNotAcceptable ( error ) <TAB> response . content_type = handler . content_type <TAB> return handler ( data , request = request , response = response )",if accepted_content_type in handlers :,if accepted_content_type in handlers :,100.0,100.00,True
3336,"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB><TAB> if item is None : <TAB><TAB><TAB> flatten_items . append ( b "" "" ) <TAB><TAB> elif isinstance ( item , bytes ) : <TAB><TAB><TAB> flatten_items . append ( item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB><TAB> elif isinstance ( item , list ) : <TAB><TAB><TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items )","elif isinstance ( item , int ) :","elif isinstance ( item , str ) :",98.75110323748866,98.64,False
3337,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_mime_type ( d . getVarInt32 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 16 : <TAB><TAB><TAB> self . set_quality ( d . getVarInt32 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 8 :,if tt == 8 :,100.0,100.00,True
3338,"def delete ( self , waiters ) : <TAB> # Delete flow. <TAB> msgs = self . ofctl . get_all_flow ( waiters ) <TAB> for msg in msgs : <TAB><TAB> for stats in msg . body : <TAB><TAB><TAB> vlan_id = VlanRouter . _cookie_to_id ( REST_VLANID , stats . cookie ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . ofctl . delete_flow ( stats ) <TAB> assert len ( self . packet_buffer ) == 0",if vlan_id == self . vlan_id :,if vlan_id :,71.91906202913547,94.91,False
3339,def missing_push_allowance ( push_allowances : List [ PushAllowance ] ) - > bool : <TAB> for push_allowance in push_allowances : <TAB><TAB> # a null databaseId indicates this is not a GitHub App. <TAB><TAB> if push_allowance . actor . databaseId is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return True,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,if push_allowance . actor . databaseId != push_allowance . actor . database,89.92129786780858,83.37,False
3340,"def _cluster_page ( self , htmlpage ) : <TAB> template_cluster , preferred = _CLUSTER_NA , None <TAB> if self . clustering : <TAB><TAB> self . clustering . add_page ( htmlpage ) <TAB><TAB> <MASK> <TAB><TAB><TAB> clt = self . clustering . classify ( htmlpage ) <TAB><TAB><TAB> if clt != - 1 : <TAB><TAB><TAB><TAB> template_cluster = preferred = self . template_names [ clt ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> template_cluster = _CLUSTER_OUTLIER <TAB> return template_cluster , preferred",if self . clustering . is_fit :,if self . template_names :,93.86889328601947,96.19,False
3341,"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB><TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [ ] <TAB> nbr = 0 <TAB> while True : <TAB><TAB> line = self . readline ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> break <TAB><TAB> out . append ( line ) <TAB><TAB> if size > - 1 : <TAB><TAB><TAB> nbr + = len ( line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if nbr > size :,if size == 0 :,98.09789949039009,97.29,False
3342,"def post_mortem ( t = None ) : <TAB> # handling the default <TAB> <MASK> <TAB><TAB> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB><TAB> # being handled, otherwise it returns None <TAB><TAB> t = sys . exc_info ( ) [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" A valid traceback must be passed if no exception is being handled. "" <TAB><TAB><TAB> ) <TAB> p = BPdb ( ) <TAB> p . reset ( ) <TAB> p . interaction ( None , t )",if t is None :,if t is None :,100.0,100.00,True
3343,"def fixup ( m ) : <TAB> txt = m . group ( 0 ) <TAB> if txt [ : 2 ] == "" &# "" : <TAB><TAB> # character reference <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return unichr ( int ( txt [ 3 : - 1 ] , 16 ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return unichr ( int ( txt [ 2 : - 1 ] ) ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> pass <TAB> else : <TAB><TAB> # named entity <TAB><TAB> try : <TAB><TAB><TAB> txt = unichr ( htmlentitydefs . name2codepoint [ txt [ 1 : - 1 ] ] ) <TAB><TAB> except KeyError : <TAB><TAB><TAB> pass <TAB> return txt # leave as is","if txt [ : 3 ] == ""&#x"" :","if txt [ : 3 ] == ""&#x"" :",100.0,100.00,True
3344,"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB><TAB> value = item . group ( "" stringval "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = item . group ( "" value "" ) <TAB><TAB> value = _pythonize ( value ) <TAB><TAB> if not item . group ( "" name "" ) : <TAB><TAB><TAB> args . append ( value ) <TAB><TAB> else : <TAB><TAB><TAB> name = item . group ( "" name "" ) <TAB><TAB><TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs",if value is None :,if value is not None :,99.27624219042275,98.84,False
3345,"def IT ( cpu ) : <TAB> cc = cpu . instruction . cc <TAB> true_case = cpu . _evaluate_conditional ( cc ) <TAB> # this is incredibly hacky--how else does capstone expose this? <TAB> # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB> for c in cpu . instruction . mnemonic [ 1 : ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> cpu . _it_conditional . append ( true_case ) <TAB><TAB> elif c == "" e "" : <TAB><TAB><TAB> cpu . _it_conditional . append ( not true_case )","if c == ""t"" :","if c == ""g"" :",98.66816901104649,98.38,False
3346,"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [ ] <TAB> channel = await self . messageable . _get_channel ( ) <TAB> self . channel = channel <TAB> while self . _get_retrieve ( ) : <TAB><TAB> data = await self . _retrieve_messages ( self . retrieve ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . limit = 0 # terminate the infinite loop <TAB><TAB> if self . reverse : <TAB><TAB><TAB> data = reversed ( data ) <TAB><TAB> if self . _filter : <TAB><TAB><TAB> data = filter ( self . _filter , data ) <TAB><TAB> for element in data : <TAB><TAB><TAB> result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB> return result",if len ( data ) < 100 :,if len ( data ) == 0 :,73.83709258673264,98.09,False
3347,"def _get_beta_accumulators ( self ) : <TAB> with tf . init_scope ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> graph = None <TAB><TAB> else : <TAB><TAB><TAB> graph = tf . get_default_graph ( ) <TAB><TAB> return ( <TAB><TAB><TAB> self . _get_non_slot_variable ( "" beta1_power "" , graph = graph ) , <TAB><TAB><TAB> self . _get_non_slot_variable ( "" beta2_power "" , graph = graph ) , <TAB><TAB> )",if tf . executing_eagerly ( ) :,"if self . _get_non_slot_variable ( ""beta1_power"" ,",75.59100921066018,89.06,False
3348,"def prefixed ( self , prefix : _StrType ) - > typing . Iterator [ "" Env "" ] : <TAB> """"""Context manager for parsing envvars with a common prefix."""""" <TAB> try : <TAB><TAB> old_prefix = self . _prefix <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _prefix = prefix <TAB><TAB> else : <TAB><TAB><TAB> self . _prefix = f "" { old_prefix } { prefix } "" <TAB><TAB> yield self <TAB> finally : <TAB><TAB> # explicitly reset the stored prefix on completion and exceptions <TAB><TAB> self . _prefix = None <TAB> self . _prefix = old_prefix",if old_prefix is None :,if prefix is not None :,95.63406435094876,97.20,False
3349,"def decode_content ( self ) : <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB><TAB> ct , options = parse_options_header ( ct ) <TAB><TAB> charset = options . get ( "" charset "" ) <TAB><TAB> if ct in JSON_CONTENT_TYPES : <TAB><TAB><TAB> return self . json ( charset ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . text ( charset ) <TAB><TAB> elif ct == FORM_URL_ENCODED : <TAB><TAB><TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content","elif ct . startswith ( ""text/"" ) :",elif ct in TEXT_CONTENT_TYPES :,95.89302820781988,95.21,False
3350,"def test_incrementaldecoder ( self ) : <TAB> UTF8Writer = codecs . getwriter ( "" utf-8 "" ) <TAB> for sizehint in [ None , - 1 ] + list ( range ( 1 , 33 ) ) + [ 64 , 128 , 256 , 512 , 1024 ] : <TAB><TAB> istream = BytesIO ( self . tstring [ 0 ] ) <TAB><TAB> ostream = UTF8Writer ( BytesIO ( ) ) <TAB><TAB> decoder = self . incrementaldecoder ( ) <TAB><TAB> while 1 : <TAB><TAB><TAB> data = istream . read ( sizehint ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> u = decoder . decode ( data ) <TAB><TAB><TAB><TAB> ostream . write ( u ) <TAB><TAB> self . assertEqual ( ostream . getvalue ( ) , self . tstring [ 1 ] )",if not data :,if not data :,100.0,100.00,True
3351,"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB><TAB> fn_full = os . path . join ( path , fn ) <TAB><TAB> <MASK> <TAB><TAB><TAB> delete_all ( fn_full ) <TAB><TAB> elif fn . endswith ( "" .png "" ) : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> elif fn . endswith ( "" .md "" ) : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> elif DELETE_ALL_OLD : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )",if os . path . isdir ( fn ) :,"if fn . endswith ( "".png"" ) :",69.16830166292543,95.95,False
3352,"def _delete_reason ( self ) : <TAB> for i in range ( _lib . X509_REVOKED_get_ext_count ( self . _revoked ) ) : <TAB><TAB> ext = _lib . X509_REVOKED_get_ext ( self . _revoked , i ) <TAB><TAB> obj = _lib . X509_EXTENSION_get_object ( ext ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _lib . X509_EXTENSION_free ( ext ) <TAB><TAB><TAB> _lib . X509_REVOKED_delete_ext ( self . _revoked , i ) <TAB><TAB><TAB> break",if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,if obj . type == _lib . X509_TYPE_UNDEFINED :,64.61857137306572,90.32,False
3353,"def hexcmp ( x , y ) : <TAB> try : <TAB><TAB> a = int ( x , 16 ) <TAB><TAB> b = int ( y , 16 ) <TAB><TAB> if a < b : <TAB><TAB><TAB> return - 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> return 1 <TAB><TAB> return 0 <TAB> except : <TAB><TAB> return cmp ( x , y )",if a > b :,if b > a :,96.82902155882192,96.56,False
3354,"def get_indentation_count ( view , start ) : <TAB> indent_count = 0 <TAB> i = start - 1 <TAB> while i > 0 : <TAB><TAB> ch = view . substr ( i ) <TAB><TAB> scope = view . scope_name ( i ) <TAB><TAB> # Skip preprocessors, strings, characaters and comments <TAB><TAB> if "" string.quoted "" in scope or "" comment "" in scope or "" preprocessor "" in scope : <TAB><TAB><TAB> extent = view . extract_scope ( i ) <TAB><TAB><TAB> i = extent . a - 1 <TAB><TAB><TAB> continue <TAB><TAB> else : <TAB><TAB><TAB> i - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> indent_count - = 1 <TAB><TAB> elif ch == "" { "" : <TAB><TAB><TAB> indent_count + = 1 <TAB> return indent_count","if ch == ""}"" :","if ch == ""{"" :",98.9885957057996,98.94,False
3355,"def set ( self , name , value , ex = None , px = None , nx = False , xx = False ) : <TAB> if ( <TAB><TAB> ( not nx and not xx ) <TAB><TAB> or ( nx and self . _db . get ( name , None ) is None ) <TAB><TAB> or ( xx and not self . _db . get ( name , None ) is None ) <TAB> ) : <TAB><TAB> if ex > 0 : <TAB><TAB><TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( seconds = ex ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( milliseconds = px ) ) <TAB><TAB> self . _db [ name ] = str ( value ) <TAB><TAB> return True <TAB> else : <TAB><TAB> return None",elif px > 0 :,if px > 0 :,99.09791165088392,98.86,False
3356,"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB><TAB> if start in line : <TAB><TAB><TAB> should_yield = True <TAB><TAB><TAB> continue <TAB><TAB> if end and end in line : <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> yield line . strip ( ) . split ( ""   "" ) [ 0 ]",if should_yield and line :,if should_yield :,95.38750097404318,97.35,False
3357,"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB><TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB><TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB><TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) : <TAB><TAB><TAB> yield handler","if not isinstance ( handler , handlers . ResourceWatchingHandler ) :","if isinstance ( handler , handlers . ResourceWatchingHandler ) :",85.7136619078029,98.66,False
3358,"def __enter__ ( self ) : <TAB> if log_timer : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . logger . debug ( "" %s  starting "" % self . name ) <TAB><TAB> else : <TAB><TAB><TAB> print ( ( "" [ %s  starting]... "" % self . name ) ) <TAB><TAB> self . tstart = time . time ( )",if self . logger :,if self . logger :,100.0,100.00,True
3359,"def _handle_errors ( errors ) : <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors : <TAB><TAB> return <TAB> log_all = True # pylint: disable=unused-variable <TAB> err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB> print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB> for module , err in errors : <TAB><TAB> err_str = str ( err ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB><TAB> if not _is_import_err_msg ( err_str , module ) : <TAB><TAB><TAB> print ( "" From module  %s "" % module ) <TAB><TAB><TAB> raise err",if log_all :,if log_all :,100.0,100.00,True
3360,"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB><TAB> if isinstance ( v , ( list , tuple ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB><TAB><TAB> for v in _ungroup ( v , groups ) : <TAB><TAB><TAB><TAB> yield v <TAB><TAB> else : <TAB><TAB><TAB> yield v",if groups is not None :,if groups is not None :,100.0,100.00,True
3361,def run ( self ) : <TAB> while not self . completed : <TAB><TAB> if self . block : <TAB><TAB><TAB> time . sleep ( self . period ) <TAB><TAB> else : <TAB><TAB><TAB> self . _completed . wait ( self . period ) <TAB><TAB> self . counter + = 1 <TAB><TAB> try : <TAB><TAB><TAB> self . callback ( self . counter ) <TAB><TAB> except Exception : <TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . timeout is not None : <TAB><TAB><TAB> dt = time . time ( ) - self . _start_time <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . stop ( ) <TAB><TAB> if self . counter == self . count : <TAB><TAB><TAB> self . stop ( ),if dt > self . timeout :,if dt < self . timeout :,98.97107027393724,98.91,False
3362,"def dont_let_stderr_buffer ( ) : <TAB> while True : <TAB><TAB> line = context . daemon . stderr . readline ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> if DEAD_DEPLOYD_WORKER_MESSAGE . encode ( "" utf-8 "" ) in line : <TAB><TAB><TAB> context . num_workers_crashed + = 1 <TAB><TAB> print ( f "" deployd stderr:  { line } "" )",if not line :,if not line :,100.0,100.00,True
3363,"def mergeHiLo ( self , x_stats ) : <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats . firsttime is not None : <TAB><TAB> if self . firsttime is None or x_stats . firsttime < self . firsttime : <TAB><TAB><TAB> self . firsttime = x_stats . firsttime <TAB><TAB><TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . lasttime = x_stats . lasttime <TAB><TAB><TAB> self . last = x_stats . last",if self . lasttime is None or x_stats . lasttime >= self . lasttime :,if self . lasttime is None or x_stats . lasttime < self . lasttime,80.0126535014319,96.53,False
3364,"def test_rlimit_get ( self ) : <TAB> import resource <TAB> p = psutil . Process ( os . getpid ( ) ) <TAB> names = [ x for x in dir ( psutil ) if x . startswith ( "" RLIMIT "" ) ] <TAB> assert names <TAB> for name in names : <TAB><TAB> value = getattr ( psutil , name ) <TAB><TAB> self . assertGreaterEqual ( value , 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( value , getattr ( resource , name ) ) <TAB><TAB><TAB> self . assertEqual ( p . rlimit ( value ) , resource . getrlimit ( value ) ) <TAB><TAB> else : <TAB><TAB><TAB> ret = p . rlimit ( value ) <TAB><TAB><TAB> self . assertEqual ( len ( ret ) , 2 ) <TAB><TAB><TAB> self . assertGreaterEqual ( ret [ 0 ] , - 1 ) <TAB><TAB><TAB> self . assertGreaterEqual ( ret [ 1 ] , - 1 )",if name in dir ( resource ) :,"if hasattr ( resource , name ) :",78.77244748584363,97.73,False
3365,"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB><TAB> if not prop_name in entity . unindexed_properties ( ) : <TAB><TAB><TAB> prop_vals = entity [ prop_name ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> num_prop_vals = len ( prop_vals ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> num_prop_vals = 1 <TAB><TAB><TAB> writes + = 2 * num_prop_vals <TAB> return writes","if isinstance ( prop_vals , ( list ) ) :","if isinstance ( prop_vals , ( list , tuple ) ) :",70.66767548499588,98.02,False
3366,"def check_value_check ( self , x_data , t_data , use_cudnn ) : <TAB> x = chainer . Variable ( x_data ) <TAB> t = chainer . Variable ( t_data ) <TAB> with chainer . using_config ( "" use_cudnn "" , use_cudnn ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Check if it throws nothing <TAB><TAB><TAB> functions . softmax_cross_entropy ( <TAB><TAB><TAB><TAB> x , t , enable_double_backprop = self . enable_double_backprop <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> with self . assertRaises ( ValueError ) : <TAB><TAB><TAB><TAB> functions . softmax_cross_entropy ( <TAB><TAB><TAB><TAB><TAB> x , t , enable_double_backprop = self . enable_double_backprop <TAB><TAB><TAB><TAB> )",if self . valid :,if self . use_cudnn :,77.9246900790214,98.13,False
3367,"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB><TAB> fn = mo . groups ( ) [ 0 ] <TAB><TAB> fn = fn . replace ( ""   "" , "" _ "" ) <TAB><TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" "" <TAB><TAB> if isinstance ( fn , str ) : <TAB><TAB><TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB><TAB> else : <TAB><TAB><TAB> fn = unicode ( fn ) <TAB><TAB> if note_markdown ( note ) : <TAB><TAB><TAB> fn + = "" .mkdn "" <TAB><TAB> else : <TAB><TAB><TAB> fn + = "" .txt "" <TAB><TAB> return fn <TAB> else : <TAB><TAB> return "" """,if not fn :,if not fn :,100.0,100.00,True
3368,"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB><TAB> s = s [ 1 : ] <TAB><TAB> end = s . find ( "" ; "" ) <TAB><TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB><TAB><TAB> end = s . find ( "" ; "" , end + 1 ) <TAB><TAB> if end < 0 : <TAB><TAB><TAB> end = len ( s ) <TAB><TAB> f = s [ : end ] <TAB><TAB> <MASK> <TAB><TAB><TAB> i = f . index ( "" = "" ) <TAB><TAB><TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB><TAB> plist . append ( f . strip ( ) ) <TAB><TAB> s = s [ end : ] <TAB> return plist","if ""="" in f :","if ""="" in f :",100.0,100.00,True
3369,"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB><TAB> if not isinstance ( child , minidom . Element ) : <TAB><TAB><TAB> continue <TAB><TAB> if child . tagName == "" Directory "" : <TAB><TAB><TAB> doDir ( child ) <TAB><TAB> elif child . tagName == "" Component "" : <TAB><TAB><TAB> for grandchild in child . childNodes : <TAB><TAB><TAB><TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if grandchild . tagName != ""File"" :","if not grandchild . getAttribute ( ""Source"" ) :",69.28357586523136,95.71,False
3370,"def date_to_format ( value , target_format ) : <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB> elif isinstance ( value , datetime . datetime ) : <TAB><TAB><TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB><TAB> elif isinstance ( value , datetime . time ) : <TAB><TAB><TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB><TAB> ret = value <TAB> return ret","if isinstance ( value , datetime . date ) :","if isinstance ( value , datetime . date ) :",100.0,100.00,True
3371,"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB><TAB> definition = column ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> IECore . msg ( <TAB><TAB><TAB><TAB> IECore . Msg . Level . Error , <TAB><TAB><TAB><TAB> "" GafferImageUI.CatalogueUI "" , <TAB><TAB><TAB><TAB> "" No column registered with name  ' %s ' "" % name , <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( definition , IconColumn ) : <TAB><TAB><TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB><TAB> else : <TAB><TAB><TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB><TAB> columns . append ( c ) <TAB> return columns",if not definition :,if not definition :,100.0,100.00,True
3372,"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> v = v . item ( ) <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> v = self . metrics_to_scalars ( v ) <TAB><TAB> new_metrics [ k ] = v <TAB> return new_metrics","if isinstance ( v , torch . Tensor ) :","if isinstance ( v , dict ) :",92.2242764460097,96.29,False
3373,"def start ( self , connection ) : <TAB> try : <TAB><TAB> if self . client_name : <TAB><TAB><TAB> creds = gssapi . Credentials ( name = gssapi . Name ( self . client_name ) ) <TAB><TAB> else : <TAB><TAB><TAB> creds = None <TAB><TAB> hostname = self . get_hostname ( connection ) <TAB><TAB> name = gssapi . Name ( <TAB><TAB><TAB> b "" @ "" . join ( [ self . service , hostname ] ) , gssapi . NameType . hostbased_service <TAB><TAB> ) <TAB><TAB> context = gssapi . SecurityContext ( name = name , creds = creds ) <TAB><TAB> return context . step ( None ) <TAB> except gssapi . raw . misc . GSSError : <TAB><TAB> <MASK> <TAB><TAB><TAB> return NotImplemented <TAB><TAB> else : <TAB><TAB><TAB> raise",if self . fail_soft :,if self . service is None :,71.01652663249128,98.01,False
3374,"def nanmax ( self , axis = None , dtype = None , keepdims = None ) : <TAB> ret = self . _reduction ( <TAB><TAB> "" nanmax "" , axis = axis , dtype = dtype , keepdims = keepdims , todense = True <TAB> ) <TAB> if not issparse ( ret ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ret <TAB><TAB> xps = get_sparse_module ( self . spmatrix ) <TAB><TAB> ret = SparseNDArray ( xps . csr_matrix ( ret ) ) <TAB><TAB> return ret <TAB> return ret",if get_array_module ( ret ) . isscalar ( ret ) :,if not self . spmatrix :,69.05497600758027,90.21,False
3375,"def utterance_to_sample ( query_data , tagging_scheme , language ) : <TAB> tokens , tags = [ ] , [ ] <TAB> current_length = 0 <TAB> for chunk in query_data : <TAB><TAB> chunk_tokens = tokenize ( chunk [ TEXT ] , language ) <TAB><TAB> tokens + = [ <TAB><TAB><TAB> Token ( t . value , current_length + t . start , current_length + t . end ) <TAB><TAB><TAB> for t in chunk_tokens <TAB><TAB> ] <TAB><TAB> current_length + = len ( chunk [ TEXT ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tags + = negative_tagging ( len ( chunk_tokens ) ) <TAB><TAB> else : <TAB><TAB><TAB> tags + = positive_tagging ( <TAB><TAB><TAB><TAB> tagging_scheme , chunk [ SLOT_NAME ] , len ( chunk_tokens ) <TAB><TAB><TAB> ) <TAB> return { TOKENS : tokens , TAGS : tags }",if SLOT_NAME not in chunk :,"if chunk [ SLOT_NAME ] == ""negative"" :",75.72396736920372,95.93,False
3376,"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB><TAB> if isinstance ( t , Index ) : <TAB><TAB><TAB> self . _use_indexes . append ( t ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _use_indexes . append ( Index ( t ) )","elif isinstance ( t , str ) :","elif isinstance ( t , str ) :",100.0,100.00,True
3377,"def reconfigServiceWithBuildbotConfig ( self , new_config ) : <TAB> if new_config . manhole != self . manhole : <TAB><TAB> if self . manhole : <TAB><TAB><TAB> yield self . manhole . disownServiceParent ( ) <TAB><TAB><TAB> self . manhole = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . manhole = new_config . manhole <TAB><TAB><TAB> yield self . manhole . setServiceParent ( self ) <TAB> # chain up <TAB> yield service . ReconfigurableServiceMixin . reconfigServiceWithBuildbotConfig ( <TAB><TAB> self , new_config <TAB> )",if new_config . manhole :,if self . manhole is None :,94.26889865336095,96.03,False
3378,"def cleanup_folder ( target_folder ) : <TAB> for file in os . listdir ( target_folder ) : <TAB><TAB> file_path = os . path . join ( target_folder , file ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . remove ( file_path ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> logging . error ( e )",if os . path . isfile ( file_path ) :,if os . path . exists ( file_path ) :,98.00323519420509,97.91,False
3379,"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB> k = literal_or_identifier [ "" value "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return unicode ( float_repr ( k ) ) <TAB><TAB> elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB> return compose_regex ( k ) <TAB><TAB> elif isinstance ( k , bool ) : <TAB><TAB><TAB> return "" true "" if k else "" false "" <TAB><TAB> elif k is None : <TAB><TAB><TAB> return "" null "" <TAB><TAB> else : <TAB><TAB><TAB> return unicode ( k )","if isinstance ( k , float ) :","if isinstance ( k , float ) :",100.0,100.00,True
3380,"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB><TAB> if pos in decompiler . targets : <TAB><TAB><TAB> decompiler . process_target ( pos ) <TAB><TAB> method = getattr ( decompiler , opname , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB><TAB> decompiler . pos = pos <TAB><TAB> decompiler . next_pos = next_pos <TAB><TAB> x = method ( * arg ) <TAB><TAB> if x is not None : <TAB><TAB><TAB> decompiler . stack . append ( x )",if method is None :,if method is None :,100.0,100.00,True
3381,"def shutdown ( self , timeout , callback = None ) : <TAB> logger . debug ( "" background worker got shutdown request "" ) <TAB> with self . _lock : <TAB><TAB> if self . is_alive : <TAB><TAB><TAB> self . _queue . put_nowait ( _TERMINATOR ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _wait_shutdown ( timeout , callback ) <TAB><TAB> self . _thread = None <TAB><TAB> self . _thread_for_pid = None <TAB> logger . debug ( "" background worker shut down "" )",if timeout > 0.0 :,if callback :,91.62106396138752,96.94,False
3382,"def getDOMImplementation ( features = None ) : <TAB> if features : <TAB><TAB> <MASK> <TAB><TAB><TAB> features = domreg . _parse_feature_string ( features ) <TAB><TAB> for f , v in features : <TAB><TAB><TAB> if not Document . implementation . hasFeature ( f , v ) : <TAB><TAB><TAB><TAB> return None <TAB> return Document . implementation","if isinstance ( features , str ) :","if not isinstance ( features , ( list , tuple ) ) :",78.60039235836399,91.73,False
3383,"def validate_subevent ( self , subevent ) : <TAB> if self . context [ "" event "" ] . has_subevents : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( "" You need to set a subevent. "" ) <TAB><TAB> if subevent . event != self . context [ "" event "" ] : <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> "" The specified subevent does not belong to this event. "" <TAB><TAB><TAB> ) <TAB> elif subevent : <TAB><TAB> raise ValidationError ( "" You cannot set a subevent for this event. "" ) <TAB> return subevent",if not subevent :,"if not self . context [ ""event"" ] . has_subevents :",68.9820675488967,91.93,False
3384,"def einsum ( job_id , idx , einsum_expr , data_list ) : <TAB> _ , all_parties = session_init ( job_id , idx ) <TAB> with SPDZ ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> x = FixedPointTensor . from_source ( "" x "" , data_list [ 0 ] ) <TAB><TAB><TAB> y = FixedPointTensor . from_source ( "" y "" , all_parties [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> x = FixedPointTensor . from_source ( "" x "" , all_parties [ 0 ] ) <TAB><TAB><TAB> y = FixedPointTensor . from_source ( "" y "" , data_list [ 1 ] ) <TAB><TAB> return x . einsum ( y , einsum_expr ) . get ( )",if idx == 0 :,if idx == 0 :,100.0,100.00,True
3385,"def slowSorted ( qq ) : <TAB> "" Reference sort peformed by insertion using only < "" <TAB> rr = list ( ) <TAB> for q in qq : <TAB><TAB> i = 0 <TAB><TAB> for i in range ( len ( rr ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> rr . insert ( i , q ) <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> rr . append ( q ) <TAB> return rr",if q < rr [ i ] :,if q < i :,93.8892838693058,96.17,False
3386,"def _format_entry ( entry , src ) : <TAB> if entry : <TAB><TAB> result = [ ] <TAB><TAB> for x in entry . split ( "" , "" ) : <TAB><TAB><TAB> x = x . strip ( ) <TAB><TAB><TAB> if os . path . exists ( os . path . join ( src , x ) ) : <TAB><TAB><TAB><TAB> result . append ( relpath ( os . path . join ( src , x ) , src ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result . append ( relpath ( os . path . abspath ( x ) , src ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise RuntimeError ( "" No entry script  %s  found "" % x ) <TAB><TAB> return "" , "" . join ( result )",elif os . path . exists ( x ) :,elif os . path . exists ( os . path . abspath ( x ) ) :,97.15810266580317,96.26,False
3387,"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB><TAB> if shape : <TAB><TAB><TAB> t = anytype <TAB><TAB> elif "" M "" in fmt : <TAB><TAB><TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB><TAB><TAB> continue <TAB><TAB> elif "" i "" in fmt : <TAB><TAB><TAB> t = int <TAB><TAB> <MASK> <TAB><TAB><TAB> t = float <TAB><TAB> else : <TAB><TAB><TAB> t = anytype <TAB><TAB> self . addColumn ( ColumnItem ( name , i , type = t ) )","elif ""f"" in fmt :","elif ""f"" in fmt :",100.0,100.00,True
3388,"def tool_lineages ( self , trans ) : <TAB> rval = [ ] <TAB> for id , tool in self . app . toolbox . tools ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> lineage_dict = tool . lineage . to_dict ( ) <TAB><TAB> else : <TAB><TAB><TAB> lineage_dict = None <TAB><TAB> entry = dict ( id = id , lineage = lineage_dict ) <TAB><TAB> rval . append ( entry ) <TAB> return rval","if hasattr ( tool , ""lineage"" ) :","if hasattr ( tool , ""lineage"" ) :",100.0,100.00,True
3389,"def item ( self , tensor ) : <TAB> numel = 0 <TAB> if len ( tensor . shape ) > 0 : <TAB><TAB> numel = fct . reduce ( op . mul , tensor . shape ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> f "" expected tensor with one element,  "" f "" got  { tensor . shape } "" <TAB><TAB><TAB> ) <TAB> if numel == 1 : <TAB><TAB> return tensor [ 0 ] <TAB> return tensor",if numel != 1 :,if numel != 1 :,100.0,100.00,True
3390,"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB><TAB> try : <TAB><TAB><TAB> resp = requests . get ( <TAB><TAB><TAB><TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB><TAB><TAB> ) . json ( ) <TAB><TAB><TAB> if "" Version "" in resp : <TAB><TAB><TAB><TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta",if match is not None and len ( match . groups ( ) ) == 1 :,if match :,64.03646450753484,93.10,False
3391,"def generate ( ) : <TAB> for leaf in u . leaves : <TAB><TAB> if isinstance ( leaf , Integer ) : <TAB><TAB><TAB> val = leaf . get_int_value ( ) <TAB><TAB><TAB> if val in ( 0 , 1 ) : <TAB><TAB><TAB><TAB> yield val <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> elif isinstance ( leaf , Symbol ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield 1 <TAB><TAB><TAB> elif leaf == SymbolFalse : <TAB><TAB><TAB><TAB> yield 0 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise _NoBoolVector <TAB><TAB> else : <TAB><TAB><TAB> raise _NoBoolVector",if leaf == SymbolTrue :,if leaf == SymbolTrue :,100.0,100.00,True
3392,"def _test_set_metadata ( self , metadata , mask = None ) : <TAB> header = ofproto . OXM_OF_METADATA <TAB> match = OFPMatch ( ) <TAB> if mask is None : <TAB><TAB> match . set_metadata ( metadata ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> header = ofproto . OXM_OF_METADATA_W <TAB><TAB> match . set_metadata_masked ( metadata , mask ) <TAB><TAB> metadata & = mask <TAB> self . _test_serialize_and_parser ( match , header , metadata , mask )",if ( mask + 1 ) >> 64 != 1 :,if mask is not None :,68.34487420433118,91.84,False
3393,"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB><TAB> icon = "" class "" <TAB> else : <TAB><TAB> if tok . visibility == "" private "" : <TAB><TAB><TAB> icon = "" method_priv "" <TAB><TAB> <MASK> <TAB><TAB><TAB> icon = "" method_prot "" <TAB><TAB> else : <TAB><TAB><TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] )","elif tok . visibility == ""protected"" :","elif tok . visibility == ""prot"" :",98.72281368343,98.45,False
3394,"def path_sum2 ( root , s ) : <TAB> if root is None : <TAB><TAB> return [ ] <TAB> res = [ ] <TAB> stack = [ ( root , [ root . val ] ) ] <TAB> while stack : <TAB><TAB> node , ls = stack . pop ( ) <TAB><TAB> if node . left is None and node . right is None and sum ( ls ) == s : <TAB><TAB><TAB> res . append ( ls ) <TAB><TAB> <MASK> <TAB><TAB><TAB> stack . append ( ( node . left , ls + [ node . left . val ] ) ) <TAB><TAB> if node . right is not None : <TAB><TAB><TAB> stack . append ( ( node . right , ls + [ node . right . val ] ) ) <TAB> return res",if node . left is not None :,if node . left is not None :,100.0,100.00,True
3395,"def clear_slot ( self , slot_id , trigger_changed ) : <TAB> if self . slots [ slot_id ] is not None : <TAB><TAB> old_resource_id = self . slots [ slot_id ] . resource_id <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . sell_list [ old_resource_id ] <TAB><TAB> else : <TAB><TAB><TAB> del self . buy_list [ old_resource_id ] <TAB> self . slots [ slot_id ] = None <TAB> if trigger_changed : <TAB><TAB> self . _changed ( )",if self . slots [ slot_id ] . selling :,if old_resource_id in self . sell_list :,65.90849525021291,93.03,False
3396,"def OnRightUp ( self , event ) : <TAB> self . HandleMouseEvent ( event ) <TAB> self . Unbind ( wx . EVT_RIGHT_UP , handler = self . OnRightUp ) <TAB> self . Unbind ( wx . EVT_MOUSE_CAPTURE_LOST , handler = self . OnRightUp ) <TAB> self . _right = False <TAB> if not self . _left : <TAB><TAB> self . Unbind ( wx . EVT_MOTION , handler = self . OnMotion ) <TAB><TAB> self . SendChangeEvent ( ) <TAB><TAB> self . SetToolTip ( wx . ToolTip ( self . _tooltip ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . ReleaseMouse ( )",if self . HasCapture ( ) :,if self . GetMouseEvent ( ) :,98.81545904559063,98.42,False
3397,"def __init__ ( self , * args , * * kwargs ) : <TAB> for arg in args : <TAB><TAB> for k , v in arg . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> arg [ k ] = AttrDict ( v ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> arg [ k ] = v <TAB> super ( AttrDict , self ) . __init__ ( * args , * * kwargs )","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",100.0,100.00,True
3398,"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB><TAB> t = threading . current_thread ( ) <TAB><TAB> t . name = func . __name__ <TAB><TAB> try : <TAB><TAB><TAB> t . status = func ( * args , * * kwargs ) <TAB><TAB> except EscapeException as e : # user aborted <TAB><TAB><TAB> t . status = "" aborted by user "" <TAB><TAB><TAB> if status : <TAB><TAB><TAB><TAB> status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> t . exception = e <TAB><TAB><TAB> t . status = "" exception "" <TAB><TAB><TAB> vd . exceptionCaught ( e ) <TAB><TAB> <MASK> <TAB><TAB><TAB> t . sheet . currentThreads . remove ( t )",if t . sheet :,if t in t . sheet . currentThreads :,98.54889778170221,97.57,False
3399,"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB><TAB> if text == "" "" : <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB><TAB> else : <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 2 )",elif text != self . labelList . item ( i ) . text ( ) :,"elif text == """" :",91.07636165162016,89.56,False
3400,"def __attempt_add_to_linked_match ( <TAB> self , input_name , hdca , collection_type_description , subcollection_type ) : <TAB> structure = get_structure ( <TAB><TAB> hdca , collection_type_description , leaf_subcollection_type = subcollection_type <TAB> ) <TAB> if not self . linked_structure : <TAB><TAB> self . linked_structure = structure <TAB><TAB> self . collections [ input_name ] = hdca <TAB><TAB> self . subcollection_types [ input_name ] = subcollection_type <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise exceptions . MessageException ( CANNOT_MATCH_ERROR_MESSAGE ) <TAB><TAB> self . collections [ input_name ] = hdca <TAB><TAB> self . subcollection_types [ input_name ] = subcollection_type",if not self . linked_structure . can_match ( structure ) :,if self . error_message :,79.93156349653736,93.62,False
3401,"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB><TAB> time . sleep ( 2 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> if not online and not self . _is_testbot_online ( ) : <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise AssertionError ( <TAB><TAB><TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB><TAB> )",if online and self . _is_testbot_online ( ) :,if self . _is_testbot_offline ( ) :,78.53758365572868,95.97,False
3402,"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB><TAB> for content in os . listdir ( path ) : <TAB><TAB><TAB> file = os . path . join ( path , content ) <TAB><TAB><TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB><TAB><TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB> if self . match_function ( file ) : <TAB><TAB><TAB><TAB><TAB> self . files . append ( file ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . find ( file )",if self . match_function ( path ) :,if self . match_function ( path ) :,100.0,100.00,True
3403,"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB><TAB> if not Placeholder . check_resolved ( v . size ) : <TAB><TAB><TAB> continue <TAB><TAB> height , width = TextureShape . get ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not v . has_attribute ( SplitTarget ) : <TAB><TAB><TAB> flag_changed = True <TAB><TAB><TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed",if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,if height > MAX_TEXTURE_SIZE :,82.05515945742218,93.27,False
3404,"def brightness_func ( args ) : <TAB> device = _get_device_from_filter ( args ) <TAB> if args . set is None : <TAB><TAB> # Get brightness <TAB><TAB> if args . raw : <TAB><TAB><TAB> print ( str ( device . brightness ) ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" Brightness:  {0} % "" . format ( device . brightness ) ) <TAB> else : <TAB><TAB> brightness_value = float ( _clamp_u8 ( args . set ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Setting brightness to  {0} % "" . format ( brightness_value ) ) <TAB><TAB> device . brightness = brightness_value",if not args . raw :,if brightness_value != device . brightness :,97.0658088017588,95.11,False
3405,"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model reference. <TAB> if not self . model_class : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . model_class = owner_model <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" ModelType: Unable to resolve model  ' {} ' . "" . format ( self . model_name ) <TAB><TAB><TAB> ) <TAB> super ( ModelType , self ) . _setup ( field_name , owner_model )",if self . model_name == owner_model . __name__ :,if owner_model :,69.91803937866175,89.82,False
3406,"def build_json_schema_object ( cls , parent_builder = None ) : <TAB> builder = builders . ObjectBuilder ( cls , parent_builder ) <TAB> if builder . count_type ( builder . type ) > 1 : <TAB><TAB> return builder <TAB> for _ , name , field in cls . iterate_with_name ( ) : <TAB><TAB> if isinstance ( field , fields . EmbeddedField ) : <TAB><TAB><TAB> builder . add_field ( name , field , _parse_embedded ( field , builder ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> builder . add_field ( name , field , _parse_list ( field , builder ) ) <TAB><TAB> else : <TAB><TAB><TAB> builder . add_field ( name , field , _create_primitive_field_schema ( field ) ) <TAB> return builder","elif isinstance ( field , fields . ListField ) :","elif isinstance ( field , fields . ListField ) :",100.0,100.00,True
3407,"def filter_module ( mod , type_req = None , subclass_req = None ) : <TAB> for name in dir ( mod ) : <TAB><TAB> val = getattr ( mod , name ) <TAB><TAB> if type_req is not None and not isinstance ( val , type_req ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> yield name , val","if subclass_req is not None and not issubclass ( val , subclass_req ) :","if subclass_req is not None and not issubclass ( val , subclass_req ) :",100.0,100.00,True
3408,"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB><TAB> # Load it from an absolute filename <TAB><TAB> if os . path . exists ( self . icon ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB><TAB><TAB> except GObject . GError as ge : <TAB><TAB><TAB><TAB> pass <TAB><TAB> # Load it from the current icon theme <TAB><TAB> ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB><TAB> theme = Gtk . IconTheme ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return theme . load_icon ( icon_name , 24 , 0 )",if theme . has_icon ( icon_name ) :,"if extension == ""py"" :",97.09837944075733,94.85,False
3409,"def sysctlTestAndSet ( name , limit ) : <TAB> "" Helper function to set sysctl limits "" <TAB> # convert non-directory names into directory names <TAB> if "" / "" not in name : <TAB><TAB> name = "" /proc/sys/ "" + name . replace ( "" . "" , "" / "" ) <TAB> # read limit <TAB> with open ( name , "" r "" ) as readFile : <TAB><TAB> oldLimit = readFile . readline ( ) <TAB><TAB> if isinstance ( limit , int ) : <TAB><TAB><TAB> # compare integer limits before overriding <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> with open ( name , "" w "" ) as writeFile : <TAB><TAB><TAB><TAB><TAB> writeFile . write ( "" %d "" % limit ) <TAB><TAB> else : <TAB><TAB><TAB> # overwrite non-integer limits <TAB><TAB><TAB> with open ( name , "" w "" ) as writeFile : <TAB><TAB><TAB><TAB> writeFile . write ( limit )",if int ( oldLimit ) < limit :,if limit != oldLimit :,97.75109123385133,97.27,False
3410,"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB><TAB> time . sleep ( 2 ) <TAB><TAB> if online and self . _is_testbot_online ( ) : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise AssertionError ( <TAB><TAB><TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB><TAB> )",if not online and not self . _is_testbot_online ( ) :,elif self . _is_testbot_presense ( ) :,72.00490828905137,93.95,False
3411,"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB><TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB><TAB> if context . rounding == ROUND_CEILING : <TAB><TAB><TAB> return Infsign [ sign ] <TAB><TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return Infsign [ sign ] <TAB><TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) )",if context . rounding == ROUND_FLOOR :,if context . rounding == ROUND_INFINITY :,74.02661778217406,98.72,False
3412,"def _get_item_columns_panel ( items , rows ) : <TAB> hbox = Gtk . HBox ( False , 4 ) <TAB> n_item = 0 <TAB> col_items = 0 <TAB> vbox = Gtk . VBox ( ) <TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB> while n_item < len ( items ) : <TAB><TAB> item = items [ n_item ] <TAB><TAB> vbox . pack_start ( item , False , False , 0 ) <TAB><TAB> n_item + = 1 <TAB><TAB> col_items + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> vbox = Gtk . VBox ( ) <TAB><TAB><TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB><TAB><TAB> col_items = 0 <TAB> return hbox",if col_items > rows :,if col_items == rows :,98.96076013483109,98.35,False
3413,"def _changed ( self ) : <TAB> if self . gtk_range . get_sensitive ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . timer . cancel ( ) <TAB><TAB> self . timer = _Timer ( 0.5 , lambda : GLib . idle_add ( self . _write ) ) <TAB><TAB> self . timer . start ( )",if self . timer :,if self . timer :,100.0,100.00,True
3414,"def unlock_graph ( result , callback , interval = 1 , propagate = False , max_retries = None ) : <TAB> if result . ready ( ) : <TAB><TAB> second_level_res = result . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with allow_join_result ( ) : <TAB><TAB><TAB><TAB> signature ( callback ) . delay ( <TAB><TAB><TAB><TAB><TAB> list ( joinall ( second_level_res , propagate = propagate ) ) <TAB><TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> unlock_graph . retry ( countdown = interval , max_retries = max_retries )",if second_level_res . ready ( ) :,if second_level_res :,83.92646555568696,96.85,False
3415,"def update ( self , other = None , / , * * kwargs ) : <TAB> if self . _pending_removals : <TAB><TAB> self . _commit_removals ( ) <TAB> d = self . data <TAB> if other is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> other = dict ( other ) <TAB><TAB> for key , o in other . items ( ) : <TAB><TAB><TAB> d [ key ] = KeyedRef ( o , self . _remove , key ) <TAB> for key , o in kwargs . items ( ) : <TAB><TAB> d [ key ] = KeyedRef ( o , self . _remove , key )","if not hasattr ( other , ""items"" ) :","if not isinstance ( other , dict ) :",73.1661303908614,95.78,False
3416,"def default ( self , o ) : <TAB> try : <TAB><TAB> if type ( o ) == datetime . datetime : <TAB><TAB><TAB> return str ( o ) <TAB><TAB> else : <TAB><TAB><TAB> # remove unwanted attributes from the provider object during conversion to json <TAB><TAB><TAB> if hasattr ( o , "" profile "" ) : <TAB><TAB><TAB><TAB> del o . profile <TAB><TAB><TAB> if hasattr ( o , "" credentials "" ) : <TAB><TAB><TAB><TAB> del o . credentials <TAB><TAB><TAB> if hasattr ( o , "" metadata_path "" ) : <TAB><TAB><TAB><TAB> del o . metadata_path <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del o . services_config <TAB><TAB><TAB> return vars ( o ) <TAB> except Exception as e : <TAB><TAB> return str ( o )","if hasattr ( o , ""services_config"" ) :","if hasattr ( o , ""services_config"" ) :",100.0,100.00,True
3417,"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB><TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( <TAB><TAB><TAB><TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB><TAB><TAB><TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB><TAB><TAB> ) <TAB><TAB> if ignore_timeouts and is_timeout ( e ) : <TAB><TAB><TAB> return [ ] <TAB><TAB> if ignore_non_errors and is_noerr ( e ) : <TAB><TAB><TAB> return [ ] <TAB><TAB> raise",if DEBUG_COMM :,if log_enabled ( ) :,97.15863670550146,97.29,False
3418,def heal ( self ) : <TAB> if not self . doctors : <TAB><TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB><TAB> # get proc every time for latest state <TAB><TAB> proc = PipelineProcess . objects . get ( id = proc_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for dr in self . doctors : <TAB><TAB><TAB> if dr . confirm ( proc ) : <TAB><TAB><TAB><TAB> dr . cure ( proc ) <TAB><TAB><TAB><TAB> break,if not proc . is_alive or proc . is_frozen :,if not proc . is_alive ( ) :,96.8278254156828,95.69,False
3419,"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> #      taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = { } <TAB> for key , val in value . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret [ key ] = val <TAB><TAB> elif key == "" points "" : <TAB><TAB><TAB> ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB><TAB> else : <TAB><TAB><TAB> ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB> return ret","if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :","if key == ""name"" :",71.36699121789066,90.78,False
3420,"def default_generator ( <TAB> self , dataset , epochs = 1 , mode = "" fit "" , deterministic = True , pad_batches = True ) : <TAB> for epoch in range ( epochs ) : <TAB><TAB> for ( X_b , y_b , w_b , ids_b ) in dataset . iterbatches ( <TAB><TAB><TAB> batch_size = self . batch_size , <TAB><TAB><TAB> deterministic = deterministic , <TAB><TAB><TAB> pad_batches = pad_batches , <TAB><TAB> ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dropout = np . array ( 0.0 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> dropout = np . array ( 1.0 ) <TAB><TAB><TAB> yield ( [ X_b , dropout ] , [ y_b ] , [ w_b ] )","if mode == ""predict"" :","if mode == ""fit"" :",98.91449636557567,98.90,False
3421,"def _cygwin_hack_find_addresses ( target ) : <TAB> addresses = [ ] <TAB> for h in [ <TAB><TAB> target , <TAB><TAB> "" localhost "" , <TAB><TAB> "" 127.0.0.1 "" , <TAB> ] : <TAB><TAB> try : <TAB><TAB><TAB> addr = get_local_ip_for ( h ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> addresses . append ( addr ) <TAB><TAB> except socket . gaierror : <TAB><TAB><TAB> pass <TAB> return defer . succeed ( addresses )",if addr not in addresses :,if addr :,67.55562604641332,97.02,False
3422,"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB><TAB> if action_node . notify : <TAB><TAB><TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB><TAB><TAB> return task_notify <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _chain_notify <TAB> return None",elif self . _chain_notify :,if self . _chain_notify :,97.3202184819859,97.86,False
3423,"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> entry = extra . tokens [ i ] <TAB><TAB> token = jsdict ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" type "" : entry . type , <TAB><TAB><TAB><TAB> "" value "" : entry . value , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB><TAB> if extra . range : <TAB><TAB><TAB> token . range = entry . range <TAB><TAB> if extra . loc : <TAB><TAB><TAB> token . loc = entry . loc <TAB><TAB> tokens . append ( token ) <TAB><TAB> i + = 1 <TAB> extra . tokens = tokens",if not ( i < len ( extra . tokens ) ) :,if i >= extra . len :,71.0095620697367,95.38,False
3424,"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB><TAB> if not self . in_current_block ( self . cursor ) : <TAB><TAB><TAB> self . seek_to_block ( self . cursor ) <TAB><TAB> part = self . current_stream . read ( size ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if len ( part ) == 0 : <TAB><TAB><TAB><TAB> raise EOFError ( ) <TAB><TAB><TAB> size - = len ( part ) <TAB><TAB> self . cursor + = len ( part ) <TAB><TAB> buf + = part <TAB> return bytes ( buf )",if size > 0 :,if part :,73.99571339304394,97.61,False
3425,"def get_properties_from_model ( model_class ) : <TAB> """"""Show properties from a model"""""" <TAB> properties = [ ] <TAB> attr_names = [ name for ( name , value ) in inspect . getmembers ( model_class , isprop ) ] <TAB> for attr_name in attr_names : <TAB><TAB> <MASK> <TAB><TAB><TAB> attr_names . remove ( attr_name ) <TAB><TAB> else : <TAB><TAB><TAB> properties . append ( <TAB><TAB><TAB><TAB> dict ( label = attr_name , name = attr_name . strip ( "" _ "" ) . replace ( "" _ "" , ""   "" ) ) <TAB><TAB><TAB> ) <TAB> return sorted ( properties , key = lambda k : k [ "" label "" ] )","if attr_name . endswith ( ""pk"" ) :","if attr_name . startswith ( ""_"" ) :",98.1602214884273,97.66,False
3426,"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB><TAB> value = mydict [ name ] <TAB><TAB> if value is not None : <TAB><TAB><TAB> return value <TAB><TAB> myid = id ( mydict ) <TAB><TAB> assert myid not in visited <TAB><TAB> visited . add ( myid ) <TAB><TAB> mydict = mydict . Parent <TAB><TAB> <MASK> <TAB><TAB><TAB> return",if mydict is None :,if mydict is None :,100.0,100.00,True
3427,"def multicolumn ( self , list , format , cols = 4 ) : <TAB> """"""Format a list of items into a multi-column list."""""" <TAB> result = "" "" <TAB> rows = ( len ( list ) + cols - 1 ) / / cols <TAB> for col in range ( cols ) : <TAB><TAB> result = result + ' <td width= "" %d %% ""  valign=top> ' % ( 100 / / cols ) <TAB><TAB> for i in range ( rows * col , rows * col + rows ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = result + format ( list [ i ] ) + "" <br> \n "" <TAB><TAB> result = result + "" </td> "" <TAB> return ' <table width= "" 100 %% ""  summary= "" list "" ><tr> %s </tr></table> ' % result",if i < len ( list ) :,if i < len ( list ) :,100.0,100.00,True
3428,"def format_exc ( exc = None ) : <TAB> """"""Return exc (or sys.exc_info if None), formatted."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> exc = _exc_info ( ) <TAB><TAB> if exc == ( None , None , None ) : <TAB><TAB><TAB> return "" "" <TAB><TAB> import traceback <TAB><TAB> return "" "" . join ( traceback . format_exception ( * exc ) ) <TAB> finally : <TAB><TAB> del exc",if exc is None :,if exc is None :,100.0,100.00,True
3429,"def assert_counts ( res , lang , files , blank , comment , code ) : <TAB> for line in res : <TAB><TAB> fields = line . split ( ) <TAB><TAB> if len ( fields ) > = 5 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( files , int ( fields [ 1 ] ) ) <TAB><TAB><TAB><TAB> self . assertEqual ( blank , int ( fields [ 2 ] ) ) <TAB><TAB><TAB><TAB> self . assertEqual ( comment , int ( fields [ 3 ] ) ) <TAB><TAB><TAB><TAB> self . assertEqual ( code , int ( fields [ 4 ] ) ) <TAB><TAB><TAB><TAB> return <TAB> self . fail ( "" Found no output line for  {} "" . format ( lang ) )",if fields [ 0 ] == lang :,if fields [ 0 ] == lang :,100.0,100.00,True
3430,"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( value , flag_value ) : <TAB><TAB><TAB> yield ( name , self . _has_flag ( value . flag ) )","if isinstance ( value , alias_flag_value ) :","if name . startswith ( ""_"" ) :",67.68592116168588,90.31,False
3431,"def optimize_models ( args , use_cuda , models ) : <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models : <TAB><TAB> model . make_generation_fast_ ( <TAB><TAB><TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB><TAB><TAB> need_attn = args . print_alignment , <TAB><TAB> ) <TAB><TAB> if args . fp16 : <TAB><TAB><TAB> model . half ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> model . cuda ( )",if use_cuda :,if use_cuda :,100.0,100.00,True
3432,"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB><TAB> target_str = mydict [ source_str ] <TAB><TAB> if target_str == source_str : <TAB><TAB><TAB> # a convention with new (untranslated) web2py files <TAB><TAB><TAB> target_str = u "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> # an older convention <TAB><TAB><TAB> target_str = u "" "" <TAB><TAB> pounit = self . convertunit ( source_str , target_str ) <TAB><TAB> self . mypofile . addunit ( pounit ) <TAB> return self . mypofile","elif target_str . startswith ( u""*** "" ) :",elif target_str > target_str :,96.80947410665041,94.43,False
3433,"def __sparse_values_set ( instances , static_col_indexes : list ) : <TAB> tmp_result = { idx : set ( ) for idx in static_col_indexes } <TAB> for _ , instance in instances : <TAB><TAB> data_generator = instance . features . get_all_data ( ) <TAB><TAB> for idx , value in data_generator : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> tmp_result [ idx ] . add ( value ) <TAB> result = [ tmp_result [ x ] for x in static_col_indexes ] <TAB> return result",if idx not in tmp_result :,if value is None :,92.72886521471823,95.38,False
3434,def puts ( self ) : <TAB> <MASK> <TAB><TAB> self . lazy_init_lock_ . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . puts_ = PutRequest ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . puts_,if self . puts_ is None :,if self . puts_ is None :,100.0,100.00,True
3435,"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB><TAB> filters = { } <TAB><TAB> if args . resource_ref : <TAB><TAB><TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB><TAB> <MASK> <TAB><TAB><TAB> filters [ "" policy_type "" ] = args . policy_type <TAB><TAB> filters . update ( * * kwargs ) <TAB><TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB><TAB> return self . manager . get_all ( * * kwargs )",if args . policy_type :,if args . policy_type :,100.0,100.00,True
3436,"def Get_Gene ( self , id ) : <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self . Get ( id ) <TAB> if not entry : <TAB><TAB> return None <TAB> GN = "" "" <TAB> for line in string . split ( entry , "" \n "" ) : <TAB><TAB> if line [ 0 : 5 ] == "" GN    "" : <TAB><TAB><TAB> GN = string . strip ( line [ 5 : ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> GN = GN [ 0 : - 1 ] <TAB><TAB><TAB> return GN <TAB><TAB> if line [ 0 : 2 ] == "" // "" : <TAB><TAB><TAB> break <TAB> return GN","if GN [ - 1 ] == ""."" :","if GN [ - 1 ] == "" "" :",86.63088591326789,98.78,False
3437,"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . processTrack ( field [ "" track "" ] ) <TAB><TAB> if "" movie_hdr "" in field : <TAB><TAB><TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] )","if ""track"" in field :","if ""track"" in field :",75.0,100.00,True
3438,"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB><TAB> return <TAB> while True : <TAB><TAB> # We skip video packets which are not video frames <TAB><TAB> # This happens in mkv files for the first few frames. <TAB><TAB> video_packet = self . _get_video_packet ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _decode_video_packet ( video_packet ) <TAB><TAB> if video_packet . image is not None or not skip_empty_frame : <TAB><TAB><TAB> break <TAB> if _debug : <TAB><TAB> print ( "" Returning "" , video_packet ) <TAB> return video_packet . image",if video_packet . image == 0 :,if video_packet :,97.32793043248641,96.72,False
3439,"def get_devices ( display = None ) : <TAB> base = "" /dev/input "" <TAB> for filename in os . listdir ( base ) : <TAB><TAB> if filename . startswith ( "" event "" ) : <TAB><TAB><TAB> path = os . path . join ( base , filename ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> _devices [ path ] = EvdevDevice ( display , path ) <TAB><TAB><TAB> except OSError : <TAB><TAB><TAB><TAB> pass <TAB> return list ( _devices . values ( ) )",if path in _devices :,if not os . path . isfile ( path ) :,73.54968696291218,94.15,False
3440,"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB><TAB> if not self . _nchannels : <TAB><TAB><TAB> raise Error ( "" # channels not specified "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Error ( "" sample width not specified "" ) <TAB><TAB> if not self . _framerate : <TAB><TAB><TAB> raise Error ( "" sampling rate not specified "" ) <TAB><TAB> self . _write_header ( datasize )",if not self . _sampwidth :,if not self . _sampwidth :,75.0,100.00,True
3441,"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB><TAB> record = line . split ( "" / "" ) <TAB><TAB> if len ( record ) == 6 and record [ 1 ] : <TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB> # Directory <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) )","if record [ 0 ] == ""D"" :","if record [ 1 ] == ""/"" :",98.06329728365102,97.55,False
3442,"def tearDown ( self ) : <TAB> """"""Shutdown the UDP server."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . server . stop ( 2.0 ) <TAB><TAB> if self . sock_hdlr : <TAB><TAB><TAB> self . root_logger . removeHandler ( self . sock_hdlr ) <TAB><TAB><TAB> self . sock_hdlr . close ( ) <TAB> finally : <TAB><TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,75.0,100.00,True
3443,"def get_backend ( find_library = None ) : <TAB> try : <TAB><TAB> global _lib , _ctx <TAB><TAB> <MASK> <TAB><TAB><TAB> _lib = _load_library ( find_library ) <TAB><TAB><TAB> _setup_prototypes ( _lib ) <TAB><TAB><TAB> _ctx = _Context ( ) <TAB><TAB> _logger . warning ( <TAB><TAB><TAB> "" OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284) "" <TAB><TAB> ) <TAB><TAB> return _OpenUSB ( ) <TAB> except usb . libloader . LibraryException : <TAB><TAB> # exception already logged (if any) <TAB><TAB> _logger . error ( "" Error loading OpenUSB backend "" , exc_info = False ) <TAB><TAB> return None <TAB> except Exception : <TAB><TAB> _logger . error ( "" Error loading OpenUSB backend "" , exc_info = True ) <TAB><TAB> return None",if _lib is None :,if _lib is None :,100.0,100.00,True
3444,"def __init__ ( self , event , event_info , fields = [ ] ) : <TAB> _wmi_object . __init__ ( self , event , fields = fields ) <TAB> _set ( self , "" event_type "" , None ) <TAB> _set ( self , "" timestamp "" , None ) <TAB> _set ( self , "" previous "" , None ) <TAB> if event_info : <TAB><TAB> event_type = self . event_type_re . match ( event_info . Path_ . Class ) . group ( 1 ) . lower ( ) <TAB><TAB> _set ( self , "" event_type "" , event_type ) <TAB><TAB> if hasattr ( event_info , "" TIME_CREATED "" ) : <TAB><TAB><TAB> _set ( self , "" timestamp "" , from_1601 ( event_info . TIME_CREATED ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _set ( self , "" previous "" , event_info . PreviousInstance )","if hasattr ( event_info , ""PreviousInstance"" ) :","if hasattr ( event_info , ""PreviousInstance"" ) :",100.0,100.00,True
3445,"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) : <TAB><TAB><TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB><TAB><TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" )",if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,"if pkg in ( - Scheduler . _getPriority ( pkg ) , None ) :",67.87430266165407,89.48,False
3446,"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB><TAB> for line in lines : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . write ( "" "" ) <TAB><TAB><TAB> self . process ( line ) <TAB><TAB><TAB> if not is_command ( line ) : <TAB><TAB><TAB><TAB> gap = True <TAB> return 0",if gap :,if gap :,100.0,100.00,True
3447,"def diff ( old , new , display = True ) : <TAB> """"""Nice colored diff implementation"""""" <TAB> if not isinstance ( old , list ) : <TAB><TAB> old = decolorize ( str ( old ) ) . splitlines ( ) <TAB> if not isinstance ( new , list ) : <TAB><TAB> new = decolorize ( str ( new ) ) . splitlines ( ) <TAB> line_types = { ""   "" : "" % Reset "" , "" - "" : "" % Red "" , "" + "" : "" %G reen "" , "" ? "" : "" % Pink "" } <TAB> if display : <TAB><TAB> for line in difflib . Differ ( ) . compare ( old , new ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> print ( colorize ( line_types [ line [ 0 ] ] , line ) ) <TAB> return old != new","if line . startswith ( ""?"" ) :",if line [ 0 ] not in line_types :,90.04182166233905,95.76,False
3448,"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB><TAB> try : <TAB><TAB><TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB><TAB><TAB> if limit < 0 : <TAB><TAB><TAB><TAB> raise ValueError ( ) <TAB><TAB><TAB> # Enforce maximum page size, if defined <TAB><TAB><TAB> if settings . MAX_PAGE_SIZE : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return settings . MAX_PAGE_SIZE <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> return min ( limit , settings . MAX_PAGE_SIZE ) <TAB><TAB><TAB> return limit <TAB><TAB> except ( KeyError , ValueError ) : <TAB><TAB><TAB> pass <TAB> return self . default_limit",if limit == 0 :,if limit == 0 :,100.0,100.00,True
3449,"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB><TAB> new_slice_ = [ 0 ] <TAB><TAB> offset = 0 <TAB> else : <TAB><TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB><TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB><TAB> if self . squeeze_dims [ i ] : <TAB><TAB><TAB> new_slice_ . append ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB><TAB><TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_",elif offset < len ( slice_ ) :,elif self . nums [ i ] :,67.89250477086054,96.21,False
3450,"def wrapper ( * args , * * kw ) : <TAB> instance = args [ 0 ] <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret_dict = instance . _create_ret_object ( <TAB><TAB><TAB><TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB><TAB><TAB> ) <TAB><TAB><TAB> instance . logger . error ( instance . MUST_JSON ) <TAB><TAB><TAB> return jsonify ( ret_dict ) , 400 <TAB> except BadRequest : <TAB><TAB> ret_dict = instance . _create_ret_object ( <TAB><TAB><TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB><TAB> ) <TAB><TAB> instance . logger . error ( instance . MUST_JSON ) <TAB><TAB> return jsonify ( ret_dict ) , 400 <TAB> instance . logger . debug ( "" JSON is valid "" ) <TAB> return f ( * args , * * kw )",if request . get_json ( ) is None :,if instance . MUST_JSON is not None :,94.91459688894352,96.51,False
3451,"def add_css ( self , data ) : <TAB> if data : <TAB><TAB> for medium , paths in data . items ( ) : <TAB><TAB><TAB> for path in paths : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . _css . setdefault ( medium , [ ] ) . append ( path )",if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,if path not in self . _css :,57.24503995664638,84.24,False
3452,"def mangle_template ( template : str , template_vars : Set [ str ] ) - > str : <TAB> if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template : <TAB><TAB> raise Exception ( "" Cannot parse a template containing reserved strings "" ) <TAB> for var in template_vars : <TAB><TAB> original = f "" {{ { var } }} "" <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> f ' Template string is missing a reference to  "" { var } ""  referred to in kwargs ' <TAB><TAB><TAB> ) <TAB><TAB> template = template . replace ( original , mangled_name ( var ) ) <TAB> return template",if original not in template :,if not original :,91.92966193073956,97.13,False
3453,"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB><TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB><TAB> if key in seenDict : <TAB><TAB><TAB> continue <TAB><TAB> seenDict [ key ] = None <TAB><TAB> if checkContained and keyword in key : <TAB><TAB><TAB> matchesappend ( key ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches )","if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",if kwdSndx in key :,66.22247627648237,91.69,False
3454,"def GetInfo ( self ) : <TAB> for k , v in sorted ( self . memory_parameters . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not v : <TAB><TAB><TAB> continue <TAB><TAB> print ( "" %s :  \t %#08x  ( %s ) "" % ( k , v , v ) ) <TAB> print ( "" Memory ranges: "" ) <TAB> print ( "" Start \t \t End \t \t Length "" ) <TAB> for start , length in self . runs : <TAB><TAB> print ( "" 0x %X \t \t 0x %X \t \t 0x %X "" % ( start , start + length , length ) )","if k . startswith ( ""Pad"" ) :",if k not in self . runs :,70.39729547485959,95.47,False
3455,"def Children ( self ) : <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB><TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB><TAB> if is_strong and property in self . _properties : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> children . append ( self . _properties [ property ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> children . extend ( self . _properties [ property ] ) <TAB> return children",if not is_list :,if is_list :,69.64112133654847,98.56,False
3456,"def normalize_res_identifier ( self , emu , cw , val ) : <TAB> mask = ( 16 * * ( emu . get_ptr_size ( ) / / 2 ) - 1 ) << 16 <TAB> if val & mask : # not an INTRESOURCE <TAB><TAB> name = emu . read_mem_string ( val , cw ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> name = int ( name [ 1 : ] ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> return 0 <TAB> else : <TAB><TAB> name = val <TAB> return name","if name [ 0 ] == ""#"" :","if name . startswith ( ""INT"" ) :",96.60027691913263,94.71,False
3457,"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB><TAB> if best_silhouette is None : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> best_silhouette = silhouette <TAB><TAB> best_a = a <TAB><TAB> best_k = k <TAB> return best_a , best_silhouette , best_k",elif silhouette <= best_silhouette :,elif a is None :,84.2065074814833,94.65,False
3458,"def find_commit_type ( sha ) : <TAB> try : <TAB><TAB> o = obj_store [ sha ] <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB> else : <TAB><TAB> if isinstance ( o , Commit ) : <TAB><TAB><TAB> commits . add ( sha ) <TAB><TAB> elif isinstance ( o , Tag ) : <TAB><TAB><TAB> tags . add ( sha ) <TAB><TAB><TAB> commits . add ( o . object [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> raise KeyError ( "" Not a commit or a tag:  %s "" % sha )",if not ignore_unknown :,if o is None :,69.70018936861341,96.81,False
3459,"def on_search_entry_keypress ( self , widget , event ) : <TAB> key = Gdk . keyval_name ( event . keyval ) <TAB> if key == "" Escape "" : <TAB><TAB> self . hide_search_box ( ) <TAB> elif key == "" Return "" : <TAB><TAB> # Combine with Shift? <TAB><TAB> <MASK> <TAB><TAB><TAB> self . search_prev = False <TAB><TAB><TAB> self . do_search ( None ) <TAB><TAB> else : <TAB><TAB><TAB> self . search_prev = True",if event . state & Gdk . ModifierType . SHIFT_MASK :,if self . search_prev :,93.75384337451861,92.13,False
3460,"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB><TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" = "" in each : <TAB><TAB><TAB><TAB> key , value = each . split ( "" = "" , 1 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> key , value = each , "" "" <TAB><TAB><TAB> result [ key ] = value <TAB> namespace . webhook_properties = result",if each :,"if isinstance ( each , str ) :",95.6627530390403,95.53,False
3461,"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB><TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . lock . acquire ( ) <TAB><TAB> self . modules [ path_id ] = module <TAB><TAB> self . lock . release ( ) <TAB><TAB> if resolve : <TAB><TAB><TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB><TAB><TAB> self . _relations [ path_id ] = [ ] <TAB><TAB><TAB> for package in resolution : <TAB><TAB><TAB><TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB><TAB><TAB> self . queue_send . put ( ( path_id , module , False , resolution ) )",if path_id is None :,if path_id in self . modules :,70.72265893236633,97.82,False
3462,"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB><TAB> "" torrent "" : "" "" , <TAB><TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB><TAB> data = self . session . get ( url ) . text <TAB><TAB> with bs4_parser ( data ) as html : <TAB><TAB><TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB><TAB><TAB> if downloads : <TAB><TAB><TAB><TAB> for download in downloads . findAll ( "" a "" ) : <TAB><TAB><TAB><TAB><TAB> link = download [ "" href "" ] <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> links [ "" magnet "" ] = link <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB><TAB> pass <TAB> return links [ download_type ]","if link . startswith ( ""magnet"" ) :","if link . startswith ( ""magnet"" ) :",100.0,100.00,True
3463,"def _parse_fields ( cls , read ) : <TAB> read = unicode_to_str ( read ) <TAB> if type ( read ) is not str : <TAB><TAB> _wrong_type_for_arg ( read , "" str "" , "" read "" ) <TAB> fields = { } <TAB> while read and read [ 0 ] != "" ; "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> DeserializeError ( read , "" does not separate fields with commas "" ) <TAB><TAB> read = read [ 1 : ] <TAB><TAB> key , _type , value , read = cls . _parse_field ( read ) <TAB><TAB> fields [ key ] = ( _type , value ) <TAB> if read : <TAB><TAB> # read[0] == ';' <TAB><TAB> read = read [ 1 : ] <TAB> return fields , read","if read and read [ 0 ] != "","" :","if not read [ 0 ] == "";"" :",76.58444979478074,96.23,False
3464,"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> v = str ( v , "" utf-8 "" ) <TAB><TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB> v = self . _convertList ( v ) <TAB><TAB> elif isinstance ( v , dict ) : <TAB><TAB><TAB> v = self . _convertDict ( v ) <TAB><TAB> if isinstance ( k , bytes ) : <TAB><TAB><TAB> k = str ( k , "" utf-8 "" ) <TAB><TAB> r [ k ] = v <TAB> return r","if isinstance ( v , bytes ) :","if isinstance ( v , bytes ) :",100.0,100.00,True
3465,"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB><TAB> if filename in cache : <TAB><TAB><TAB> old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # Move to the end <TAB><TAB><TAB><TAB> cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB><TAB> cache [ filename ] = mtime , result # at the end <TAB><TAB> if len ( cache ) > max_size : <TAB><TAB><TAB> cache . popitem ( last = False ) <TAB> return result",if old_mtime == mtime :,if old_mtime != mtime :,98.77568500407993,98.70,False
3466,def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self . count > self . epiLen : <TAB><TAB> self . res ( ) <TAB><TAB> return True <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . pertGlasPos ( 0 ) <TAB><TAB> if self . count == self . epiLen / 2 + 1 : <TAB><TAB><TAB> self . env . reset ( ) <TAB><TAB><TAB> self . pertGlasPos ( 1 ) <TAB><TAB> self . count + = 1 <TAB><TAB> return False,if self . count == 1 :,if self . count == 0 :,73.70011283066675,98.40,False
3467,"def _check_vulnerabilities ( self , processed_analysis ) : <TAB> matched_vulnerabilities = list ( ) <TAB> for vulnerability in self . _rule_base_vulnerabilities : <TAB><TAB> <MASK> <TAB><TAB><TAB> vulnerability_data = vulnerability . get_dict ( ) <TAB><TAB><TAB> name = vulnerability_data . pop ( "" short_name "" ) <TAB><TAB><TAB> matched_vulnerabilities . append ( ( name , vulnerability_data ) ) <TAB> return matched_vulnerabilities","if evaluate ( processed_analysis , vulnerability . rule ) :",if vulnerability . get_analysis ( ) == processed_analysis :,89.81407673426096,91.63,False
3468,"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ""    %s "" % val <TAB><TAB> elif val < 1024 * * 2 : <TAB><TAB><TAB> return ""    %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB><TAB> elif val < 1024 * * 3 : <TAB><TAB><TAB> return ""    %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB><TAB> else : <TAB><TAB><TAB> return ""    %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB><TAB> return str ( val ) <TAB> else : <TAB><TAB> return ""    %s "" % val","if isinstance ( val , compat . string_types ) :",if val < 1024.0 * 1 :,70.15451898264018,94.95,False
3469,"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB><TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB><TAB> if rd : <TAB><TAB><TAB> self . handle_request ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if self . event is not None and self . event . is_set ( ) :,if wr :,85.59136241638625,83.72,False
3470,"def resize ( self , * e ) : <TAB> bold = ( "" helvetica "" , - self . _size . get ( ) , "" bold "" ) <TAB> helv = ( "" helvetica "" , - self . _size . get ( ) ) <TAB> xspace = self . _size . get ( ) <TAB> yspace = self . _size . get ( ) <TAB> for widget in self . _widgets : <TAB><TAB> widget [ "" node_font "" ] = bold <TAB><TAB> widget [ "" leaf_font "" ] = helv <TAB><TAB> widget [ "" xspace "" ] = xspace <TAB><TAB> widget [ "" yspace "" ] = yspace <TAB><TAB> if self . _size . get ( ) < 20 : <TAB><TAB><TAB> widget [ "" line_width "" ] = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> widget [ "" line_width "" ] = 2 <TAB><TAB> else : <TAB><TAB><TAB> widget [ "" line_width "" ] = 3 <TAB> self . _layout ( )",elif self . _size . get ( ) < 30 :,elif self . _size . get ( ) > 20 :,75.44367191431994,98.64,False
3471,"def __assertTilesChangedInRegion ( self , t1 , t2 , region ) : <TAB> for tileOriginTuple in t1 . keys ( ) : <TAB><TAB> tileOrigin = imath . V2i ( * tileOriginTuple ) <TAB><TAB> tileRegion = imath . Box2i ( <TAB><TAB><TAB> tileOrigin , tileOrigin + imath . V2i ( GafferImage . ImagePlug . tileSize ( ) ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertNotEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] )","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",if region == tileRegion :,65.35974597148358,92.87,False
3472,"def grouped_by_prefix ( args , prefixes ) : <TAB> """"""Group behave args by (directory) scope into multiple test-runs."""""" <TAB> group_args = [ ] <TAB> current_scope = None <TAB> for arg in args . strip ( ) . split ( ) : <TAB><TAB> assert not arg . startswith ( "" - "" ) , "" REQUIRE: arg, not options "" <TAB><TAB> scope = select_prefix_for ( arg , prefixes ) <TAB><TAB> if scope != current_scope : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # -- DETECTED GROUP-END: <TAB><TAB><TAB><TAB> yield ""   "" . join ( group_args ) <TAB><TAB><TAB><TAB> group_args = [ ] <TAB><TAB><TAB> current_scope = scope <TAB><TAB> group_args . append ( arg ) <TAB> <MASK> <TAB><TAB> yield ""   "" . join ( group_args )",if group_args :,if group_args :,100.0,100.00,True
3473,"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB><TAB> print_func = str <TAB> else : <TAB><TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB><TAB> value = getattr ( self , k ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( value , basestring ) : <TAB><TAB><TAB> print_func = repr # keep quotes around strings <TAB><TAB> pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB> if pieces or self . __base__ : <TAB><TAB> return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB> else : <TAB><TAB> return "" """,if not defaults and value == default_values [ k ] :,if value in default_values :,73.97135573470281,95.35,False
3474,"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB><TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB><TAB> self . tag . append ( node ) <TAB><TAB> name = getattr ( node , "" name "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB><TAB> if handler : <TAB><TAB><TAB> handler ( node )",if name is None :,if not name :,74.76532542828444,97.61,False
3475,"def createFields ( self ) : <TAB> yield Enum ( Bits ( self , "" class "" , 2 ) , self . CLASS_DESC ) <TAB> yield Enum ( Bit ( self , "" form "" ) , self . FORM_DESC ) <TAB> if self [ "" class "" ] . value == 0 : <TAB><TAB> yield Enum ( Bits ( self , "" type "" , 5 ) , self . TYPE_DESC ) <TAB> else : <TAB><TAB> yield Bits ( self , "" type "" , 5 ) <TAB> yield ASNInteger ( self , "" size "" , "" Size in bytes "" ) <TAB> size = self [ "" size "" ] . value <TAB> if size : <TAB><TAB> <MASK> <TAB><TAB><TAB> for field in self . _handler ( self , size ) : <TAB><TAB><TAB><TAB> yield field <TAB><TAB> else : <TAB><TAB><TAB> yield RawBytes ( self , "" raw "" , size )",if self . _handler :,if self . _handler :,100.0,100.00,True
3476,"def _process_service_request ( self , pkttype , pktid , packet ) : <TAB> """"""Process a service request"""""" <TAB> # pylint: disable=unused-argument <TAB> service = packet . get_string ( ) <TAB> packet . check_end ( ) <TAB> if service == self . _next_service : <TAB><TAB> self . logger . debug2 ( "" Accepting request for service  %s "" , service ) <TAB><TAB> self . _next_service = None <TAB><TAB> self . send_packet ( MSG_SERVICE_ACCEPT , String ( service ) ) <TAB><TAB> <MASK> # pragma: no branch <TAB><TAB><TAB> self . _auth_in_progress = True <TAB><TAB><TAB> self . _send_deferred_packets ( ) <TAB> else : <TAB><TAB> raise DisconnectError ( <TAB><TAB><TAB> DISC_SERVICE_NOT_AVAILABLE , "" Unexpected service request received "" <TAB><TAB> )",if self . is_server ( ) and service == _USERAUTH_SERVICE :,if self . _auth_in_progress :,96.43292954919377,94.32,False
3477,"def _read_fixed_body ( <TAB> self , content_length : int , delegate : httputil . HTTPMessageDelegate ) - > None : <TAB> while content_length > 0 : <TAB><TAB> body = await self . stream . read_bytes ( <TAB><TAB><TAB> min ( self . params . chunk_size , content_length ) , partial = True <TAB><TAB> ) <TAB><TAB> content_length - = len ( body ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with _ExceptionLoggingContext ( app_log ) : <TAB><TAB><TAB><TAB> ret = delegate . data_received ( body ) <TAB><TAB><TAB><TAB> if ret is not None : <TAB><TAB><TAB><TAB><TAB> await ret",if not self . _write_finished or self . is_client :,if body is not None :,66.80732690235746,92.91,False
3478,"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB><TAB> try : <TAB><TAB><TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> except OSError : <TAB><TAB><TAB> e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB> if e . args [ 0 ] == errno . ECHILD : <TAB><TAB><TAB><TAB> return <TAB><TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out """,if target_pid == pid :,if target_pid == mitogen . core . now ( ) :,74.4453612851066,95.82,False
3479,"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB><TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB> if op . stage == OperandStage . map : <TAB><TAB><TAB> cls . _execute_map ( ctx , op ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _execute_combine ( ctx , op ) <TAB><TAB> elif op . stage == OperandStage . agg : <TAB><TAB><TAB> cls . _execute_agg ( ctx , op ) <TAB><TAB> else : # pragma: no cover <TAB><TAB><TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB><TAB> pd . reset_option ( "" mode.use_inf_as_na "" )",elif op . stage == OperandStage . combine :,elif op . stage == OperandStage . combine :,75.0,100.00,True
3480,def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB><TAB> if re_han . match ( blk ) : <TAB><TAB><TAB> for word in __cut ( blk ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> yield word <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> for c in word : <TAB><TAB><TAB><TAB><TAB><TAB> yield c <TAB><TAB> else : <TAB><TAB><TAB> tmp = re_skip . split ( blk ) <TAB><TAB><TAB> for x in tmp : <TAB><TAB><TAB><TAB> if x : <TAB><TAB><TAB><TAB><TAB> yield x,if word not in Force_Split_Words :,if len ( word ) == 1 :,95.59200852639904,96.07,False
3481,"def _iter_tags ( self , type = None ) : <TAB> """"""Yield all raw tags (limit to |type| if specified)"""""" <TAB> for n in itertools . count ( ) : <TAB><TAB> tag = self . _get_tag ( n ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield tag <TAB><TAB> if tag [ "" d_tag "" ] == "" DT_NULL "" : <TAB><TAB><TAB> break","if type is None or tag [ ""d_tag"" ] == type :","if type and tag [ ""d_tag"" ] == type :",72.03468495160084,96.52,False
3482,"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB> if startpos is None : <TAB><TAB> startpos = self . history_cursor <TAB> if _ignore_leading_spaces : <TAB><TAB> res = [ <TAB><TAB><TAB> ( idx , line . lstrip ( ) ) <TAB><TAB><TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB> if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ) <TAB><TAB> ] <TAB> else : <TAB><TAB> res = [ <TAB><TAB><TAB> ( idx , line ) <TAB><TAB><TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB> if res : <TAB><TAB> self . history_cursor - = res [ 0 ] [ 0 ] <TAB><TAB> return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB> return "" """,if line . startswith ( searchfor ),if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),71.01247775292634,96.25,False
3483,"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB><TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB><TAB><TAB> ) <TAB> return unicode ( value )",if settings . USE_TZ :,if USE_TZ :,97.97450533086734,97.75,False
3484,"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB><TAB> with open ( filename , "" rb "" ) as fileobj : <TAB><TAB><TAB> header = fileobj . read ( 4 ) <TAB><TAB><TAB> if header == b "" OXLI "" : <TAB><TAB><TAB><TAB> fileobj . read ( 1 ) # skip the version number <TAB><TAB><TAB><TAB> ftype = fileobj . read ( 1 ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB> return False <TAB> except OSError : <TAB><TAB> return False",if binascii . hexlify ( ftype ) == oxlitype :,if ftype == oxlitype :,95.85246399978008,95.72,False
3485,"def unget ( self , char ) : <TAB> # Only one character is allowed to be ungotten at once - it must <TAB> # be consumed again before any further call to unget <TAB> if char is not EOF : <TAB><TAB> <MASK> <TAB><TAB><TAB> # unget is called quite rarely, so it's a good idea to do <TAB><TAB><TAB> # more work here if it saves a bit of work in the frequently <TAB><TAB><TAB> # called char and charsUntil. <TAB><TAB><TAB> # So, just prepend the ungotten character onto the current <TAB><TAB><TAB> # chunk: <TAB><TAB><TAB> self . chunk = char + self . chunk <TAB><TAB><TAB> self . chunkSize + = 1 <TAB><TAB> else : <TAB><TAB><TAB> self . chunkOffset - = 1 <TAB><TAB><TAB> assert self . chunk [ self . chunkOffset ] == char",if self . chunkOffset == 0 :,if self . chunkOffset == 0 :,75.0,100.00,True
3486,"def scan ( rule , extensions , paths , ignore_paths = None ) : <TAB> """"""The libsast scan."""""" <TAB> try : <TAB><TAB> options = { <TAB><TAB><TAB> "" match_rules "" : rule , <TAB><TAB><TAB> "" match_extensions "" : extensions , <TAB><TAB><TAB> "" ignore_paths "" : ignore_paths , <TAB><TAB><TAB> "" show_progress "" : False , <TAB><TAB> } <TAB><TAB> scanner = Scanner ( options , paths ) <TAB><TAB> res = scanner . scan ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return format_findings ( res [ "" pattern_matcher "" ] , paths [ 0 ] ) <TAB> except Exception : <TAB><TAB> logger . exception ( "" libsast scan "" ) <TAB> return { }",if res :,if res :,100.0,100.00,True
3487,"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB><TAB> key = pattern <TAB><TAB> <MASK> <TAB><TAB><TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB><TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB><TAB><TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB><TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB><TAB><TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB><TAB> else : <TAB><TAB><TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","if ""%"" not in pattern :","if key == ""upper"" :",67.88653219929436,96.92,False
3488,"def _forward_response ( self , src , dst ) : <TAB> """"""Forward an SCP response between two remote SCP servers"""""" <TAB> # pylint: disable=no-self-use <TAB> try : <TAB><TAB> exc = yield from src . await_response ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> dst . send_error ( exc ) <TAB><TAB><TAB> return exc <TAB><TAB> else : <TAB><TAB><TAB> dst . send_ok ( ) <TAB><TAB><TAB> return None <TAB> except OSError as exc : <TAB><TAB> return exc",if exc :,if exc is not None :,97.91807632783124,97.02,False
3489,"def _maybe_signal_recovery_end ( ) - > None : <TAB> if self . in_recovery and not self . active_remaining_total ( ) : <TAB><TAB> # apply anything stuck in the buffers <TAB><TAB> self . flush_buffers ( ) <TAB><TAB> self . _set_recovery_ended ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _actives_span . set_tag ( "" Actives-Ready "" , True ) <TAB><TAB> self . signal_recovery_end . set ( )",if self . _actives_span is not None :,if self . _actives_span :,96.18381824376652,96.69,False
3490,"def main ( ) : <TAB> tmpdir = None <TAB> try : <TAB><TAB> # Create a temporary working directory <TAB><TAB> tmpdir = tempfile . mkdtemp ( ) <TAB><TAB> # Unpack the zipfile into the temporary directory <TAB><TAB> pip_zip = os . path . join ( tmpdir , "" pip.zip "" ) <TAB><TAB> with open ( pip_zip , "" wb "" ) as fp : <TAB><TAB><TAB> fp . write ( b85decode ( DATA . replace ( b "" \n "" , b "" "" ) ) ) <TAB><TAB> # Add the zipfile to sys.path so that we can import it <TAB><TAB> sys . path . insert ( 0 , pip_zip ) <TAB><TAB> # Run the bootstrap <TAB><TAB> bootstrap ( tmpdir = tmpdir ) <TAB> finally : <TAB><TAB> # Clean up our temporary working directory <TAB><TAB> <MASK> <TAB><TAB><TAB> shutil . rmtree ( tmpdir , ignore_errors = True )",if tmpdir :,if tmpdir is not None :,98.98709130572138,98.12,False
3491,"def __init__ ( self , api_version_str ) : <TAB> try : <TAB><TAB> self . latest = self . preview = False <TAB><TAB> self . yyyy = self . mm = self . dd = None <TAB><TAB> if api_version_str == "" latest "" : <TAB><TAB><TAB> self . latest = True <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . preview = True <TAB><TAB><TAB> parts = api_version_str . split ( "" - "" ) <TAB><TAB><TAB> self . yyyy = int ( parts [ 0 ] ) <TAB><TAB><TAB> self . mm = int ( parts [ 1 ] ) <TAB><TAB><TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB><TAB> )","if ""preview"" in api_version_str :","if api_version_str == ""preview"" :",97.66498780201627,97.61,False
3492,"def _merge ( self , items , map_id , dep_id , use_disk , meminfo , mem_limit ) : <TAB> combined = self . combined <TAB> merge_combiner = self . aggregator . mergeCombiners <TAB> for k , v in items : <TAB><TAB> o = combined . get ( k ) <TAB><TAB> combined [ k ] = merge_combiner ( o , v ) if o is not None else v <TAB><TAB> <MASK> <TAB><TAB><TAB> mem_limit = self . _rotate ( )",if use_disk and meminfo . rss > mem_limit :,"if mem_limit < meminfo . get ( ""max_disks"" ) :",73.55841444887265,90.42,False
3493,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_value ( d . getVarInt32 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 8 :,if tt == 8 :,100.0,100.00,True
3494,"def nice ( deltat ) : <TAB> # singular,plural <TAB> times = _ ( <TAB><TAB> "" second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years "" <TAB> ) . split ( "" : "" ) <TAB> d = abs ( int ( deltat ) ) <TAB> for div , time in zip ( ( 60 , 60 , 24 , 7 , 4 , 12 , 100 ) , times ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" %s %i   %s "" % ( deltat < 0 and "" - "" or "" "" , d , time . split ( "" , "" ) [ d != 1 ] ) <TAB><TAB> d / = div",if d < div * 5 :,if d % div == 0 :,72.66625521448586,96.47,False
3495,"def after_get_object ( self , event , view_kwargs ) : <TAB> if event and event . state == "" draft "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ObjectNotFound ( { "" parameter "" : "" {id} "" } , "" Event: not found "" )","if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :","if not self . _has_object ( event . parameter , view_kwargs ) :",53.72357640324654,73.40,False
3496,def daemonize_if_required ( self ) : <TAB> if self . options . daemon : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Stop the logging queue listener for the current process <TAB><TAB><TAB> # We'll restart it once forked <TAB><TAB><TAB> log . shutdown_multiprocessing_logging_listener ( daemonizing = True ) <TAB><TAB> # Late import so logging works correctly <TAB><TAB> salt . utils . process . daemonize ( ) <TAB> # Setup the multiprocessing log queue listener if enabled <TAB> self . _setup_mp_logging_listener ( ),if self . _setup_mp_logging_listener_ is True :,if self . options . daemon :,92.32575291761452,91.66,False
3497,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB><TAB> clients = self . get_clients ( clients_filter ) <TAB><TAB> if not clients : <TAB><TAB><TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB><TAB> try : <TAB><TAB><TAB> module = self . get_module ( module_name ) <TAB><TAB> except PupyModuleDisabled : <TAB><TAB><TAB> continue <TAB><TAB> if clients is not None : <TAB><TAB><TAB> for client in clients : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> yield module <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> yield module",if module . is_compatible_with ( client ) :,if module . is_linked ( client ) :,98.84448615166184,98.24,False
3498,"def _incremental_avg_dp ( self , avg , new_el , idx ) : <TAB> for attr in [ "" coarse_segm "" , "" fine_segm "" , "" u "" , "" v "" ] : <TAB><TAB> setattr ( <TAB><TAB><TAB> avg , attr , ( getattr ( avg , attr ) * idx + getattr ( new_el , attr ) ) / ( idx + 1 ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB><TAB><TAB> setattr ( new_el , attr , None ) <TAB> return avg",if idx :,"if getattr ( avg , attr ) == 0 :",95.15545843229052,93.49,False
3499,"def run ( self , paths = [ ] ) : <TAB> collapsed = False <TAB> for item in SideBarSelection ( paths ) . getSelectedDirectories ( ) : <TAB><TAB> for view in item . views ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> Window ( ) . focus_view ( view ) <TAB><TAB><TAB><TAB> self . collapse_sidebar_folder ( ) <TAB><TAB><TAB><TAB> collapsed = True <TAB><TAB><TAB> view . close ( )",if not collapsed :,if not collapsed :,100.0,100.00,True
3500,"def test_reductions ( expr , rdd ) : <TAB> result = compute ( expr , rdd ) <TAB> expected = compute ( expr , data ) <TAB> if not result == expected : <TAB><TAB> print ( result ) <TAB><TAB> print ( expected ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert abs ( result - expected ) < 0.001 <TAB><TAB> else : <TAB><TAB><TAB> assert result == expected","if isinstance ( result , float ) :",if abs ( result - expected ) < 0.001 :,92.4975850966236,92.66,False
3501,"def deltask ( task , d ) : <TAB> if task [ : 3 ] != "" do_ "" : <TAB><TAB> task = "" do_ "" + task <TAB> bbtasks = d . getVar ( "" __BBTASKS "" , False ) or [ ] <TAB> if task in bbtasks : <TAB><TAB> bbtasks . remove ( task ) <TAB><TAB> d . delVarFlag ( task , "" task "" ) <TAB><TAB> d . setVar ( "" __BBTASKS "" , bbtasks ) <TAB> d . delVarFlag ( task , "" deps "" ) <TAB> for bbtask in d . getVar ( "" __BBTASKS "" , False ) or [ ] : <TAB><TAB> deps = d . getVarFlag ( bbtask , "" deps "" , False ) or [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> deps . remove ( task ) <TAB><TAB><TAB> d . setVarFlag ( bbtask , "" deps "" , deps )",if task in deps :,if task in deps :,100.0,100.00,True
3502,"def _apply_weightnorm ( self , list_layers ) : <TAB> """"""Try apply weightnorm for all layer in list_layers."""""" <TAB> for i in range ( len ( list_layers ) ) : <TAB><TAB> try : <TAB><TAB><TAB> layer_name = list_layers [ i ] . name . lower ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> list_layers [ i ] = WeightNormalization ( list_layers [ i ] ) <TAB><TAB> except Exception : <TAB><TAB><TAB> pass","if ""conv1d"" in layer_name or ""dense"" in layer_name :",if layer_name in self . _weight_norm_layers :,78.24332369987721,90.52,False
3503,"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB><TAB> if operator == "" Average "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB><TAB> elif operator == "" Count "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB><TAB> elif operator == "" Min "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB><TAB> elif operator == "" Sum "" : <TAB><TAB><TAB> self . _local_aggregators . append ( _SumAggregator ( ) )","elif operator == ""Max"" :","elif operator == ""Max"" :",100.0,100.00,True
3504,"def _conv_layer ( self , sess , bottom , name , trainable = True , padding = "" SAME "" , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB><TAB> filt = self . _get_conv_filter ( sess , name , trainable = trainable ) <TAB><TAB> conv_biases = self . _get_bias ( sess , name , trainable = trainable ) <TAB><TAB> conv = tf . nn . conv2d ( bottom , filt , [ 1 , 1 , 1 , 1 ] , padding = padding ) <TAB><TAB> bias = tf . nn . bias_add ( conv , conv_biases ) <TAB><TAB> <MASK> <TAB><TAB><TAB> bias = tf . nn . relu ( bias ) <TAB><TAB> return bias",if relu :,if relu :,100.0,100.00,True
3505,"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { } # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self . edges : <TAB><TAB> if edge . is_dangling ( ) : <TAB><TAB><TAB> raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> partner_node , shared_axis = self . _get_partner ( edge ) <TAB><TAB> if partner_node not in partners : <TAB><TAB><TAB> partners [ partner_node ] = set ( ) <TAB><TAB> partners [ partner_node ] . add ( shared_axis ) <TAB> return partners",if self . _is_my_trace ( edge ) :,if edge . is_unbounded ( ) :,72.28819376626161,94.78,False
3506,"def close ( self ) : <TAB> with self . _lock : <TAB><TAB> """"""Close this _MultiFileWatcher object forever."""""" <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _folder_handlers = { } <TAB><TAB><TAB> LOGGER . debug ( <TAB><TAB><TAB><TAB> "" Stopping observer thread even though there is a non-zero  "" <TAB><TAB><TAB><TAB> "" number of event observers! "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> LOGGER . debug ( "" Stopping observer thread "" ) <TAB><TAB> self . _observer . stop ( ) <TAB><TAB> self . _observer . join ( timeout = 5 )",if len ( self . _folder_handlers ) != 0 :,if self . _observer . is_alive ( ) :,80.52008020465071,94.16,False
3507,"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB><TAB> elif text != self . labelList . item ( i ) . text ( ) : <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB><TAB> else : <TAB><TAB><TAB> self . labelList . item ( i ) . setCheckState ( 2 )","if text == """" :",if text == self . labelList . item ( i ) . text ( ) :,94.47062568481972,91.47,False
3508,"def _get_messages ( self ) : <TAB> r = [ ] <TAB> try : <TAB><TAB> self . _connect ( ) <TAB><TAB> self . _login ( ) <TAB><TAB> for message in self . _fetch ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> r . append ( message ) <TAB><TAB> self . _connection . expunge ( ) <TAB><TAB> self . _connection . close ( ) <TAB><TAB> self . _connection . logout ( ) <TAB> except MailFetcherError as e : <TAB><TAB> self . log ( "" error "" , str ( e ) ) <TAB> return r",if message :,"if message . get ( ""type"" ) == MailFetcherType . SEND_ERROR :",95.58889627122058,91.26,False
3509,"def get_current_user ( self ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> return config . get ( "" json_authentication_override "" ) <TAB><TAB> tkn_header = self . request . headers [ "" authorization "" ] <TAB> except KeyError : <TAB><TAB> raise WebAuthNError ( reason = "" Missing Authorization Header "" ) <TAB> else : <TAB><TAB> tkn_str = tkn_header . split ( ""   "" ) [ - 1 ] <TAB> try : <TAB><TAB> tkn = self . jwt_validator ( tkn_str ) <TAB> except AuthenticationError as e : <TAB><TAB> raise WebAuthNError ( reason = e . message ) <TAB> else : <TAB><TAB> return tkn","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :","if config . get ( ""json_authentication_override"" ) :",74.97707863542277,95.30,False
3510,def _get_data ( self ) : <TAB> formdata = self . _formdata <TAB> if formdata : <TAB><TAB> data = [ ] <TAB><TAB> # TODO: Optimize? <TAB><TAB> for item in formdata : <TAB><TAB><TAB> model = self . loader . get_one ( item ) if item else None <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data . append ( model ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _invalid_formdata = True <TAB><TAB> self . _set_data ( data ) <TAB> return self . _data,if model :,if model :,100.0,100.00,True
3511,"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set ( ) <TAB> end = va + size <TAB> for offs in range ( va , end , 1 ) : <TAB><TAB> loc = self . getLocation ( offs , range = True ) <TAB><TAB> if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va : <TAB><TAB><TAB> subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB> return list ( subs )",if loc [ L_TINFO ] :,if ltyp == L_TINFO :,72.89946109060452,96.77,False
3512,def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB><TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB><TAB> <MASK> <TAB><TAB><TAB> if monad . cls_bl_idname == self . cls_bl_idname : <TAB><TAB><TAB><TAB> return monad <TAB> return None,"if hasattr ( monad , ""cls_bl_idname"" ) :","if monad . type == ""Monad"" :",64.63168500034658,87.85,False
3513,"def _set_peer_statuses ( self ) : <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB><TAB> if peer . bad : <TAB><TAB><TAB> peer . status = PEER_BAD <TAB><TAB> <MASK> <TAB><TAB><TAB> peer . status = PEER_GOOD <TAB><TAB> elif peer . last_good : <TAB><TAB><TAB> peer . status = PEER_STALE <TAB><TAB> else : <TAB><TAB><TAB> peer . status = PEER_NEVER",elif peer . last_good > cutoff :,elif cutoff < time . time ( ) :,77.3682058701213,94.90,False
3514,"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB> if i == index : <TAB><TAB><TAB> rval = composite_name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB> if composite_file . optional : <TAB><TAB><TAB><TAB> rval = "" %s  [optional] "" % rval <TAB><TAB><TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB><TAB> return "" Extra primary file "" <TAB> return None",if composite_file . description :,if composite_file . description :,100.0,100.00,True
3515,"def testUiViewServerDump_windowIntM1 ( self ) : <TAB> device = None <TAB> try : <TAB><TAB> device = MockDevice ( version = 15 , startviewserver = True ) <TAB><TAB> vc = ViewClient ( device , device . serialno , adb = TRUE , autodump = False ) <TAB><TAB> vc . dump ( window = - 1 ) <TAB><TAB> vc . findViewByIdOrRaise ( "" id/home "" ) <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> device . shutdownMockViewServer ( )",if device :,if device :,100.0,100.00,True
3516,"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB><TAB> if isinstance ( v , bytes ) : <TAB><TAB><TAB> v = str ( v , "" utf-8 "" ) <TAB><TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB> v = self . _convertList ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> v = self . _convertDict ( v ) <TAB><TAB> if isinstance ( k , bytes ) : <TAB><TAB><TAB> k = str ( k , "" utf-8 "" ) <TAB><TAB> r [ k ] = v <TAB> return r","elif isinstance ( v , dict ) :","elif isinstance ( v , dict ) :",100.0,100.00,True
3517,"def _testSendmsgTimeout ( self ) : <TAB> try : <TAB><TAB> self . cli_sock . settimeout ( 0.03 ) <TAB><TAB> try : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> self . sendmsgToServer ( [ b "" a "" * 512 ] ) <TAB><TAB> except socket . timeout : <TAB><TAB><TAB> pass <TAB><TAB> except OSError as exc : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> # bpo-33937 the test randomly fails on Travis CI with <TAB><TAB><TAB> # ""OSError: [Errno 12] Cannot allocate memory"" <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( "" socket.timeout not raised "" ) <TAB> finally : <TAB><TAB> self . misc_event . set ( )",if exc . errno != errno . ENOMEM :,if exc . errno != 12 :,97.9603745781847,97.99,False
3518,"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB><TAB> if self . showAll : <TAB><TAB><TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . stream . write ( "" s "" ) <TAB><TAB><TAB> self . stream . flush ( ) <TAB><TAB> return <TAB> _org_AddError ( self , test , err )",elif self . dots :,if self . verbose :,71.56839779033822,96.03,False
3519,"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB><TAB> if self . scrolling : <TAB><TAB><TAB> p = event . local <TAB><TAB><TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB> self . scroll_up ( ) <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . scroll_down ( ) <TAB><TAB><TAB><TAB> return <TAB> if event . button == 4 : <TAB><TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB><TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",elif self . scroll_down_rect ( ) . collidepoint ( p ) :,if self . scroll_down_rect ( ) . collidepoint ( p ) :,73.64707443076907,98.86,False
3520,"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] : # hmmm, assume copyright to be in first 80 lines <TAB><TAB> idx = l . lower ( ) . find ( "" copyright "" ) <TAB><TAB> if idx < 0 : <TAB><TAB><TAB> continue <TAB><TAB> copyright = l [ idx + 9 : ] . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> copyright = sanitise ( copyright ) <TAB><TAB> # hmm, do a quick check to see if there's a year, <TAB><TAB> # if not, skip it <TAB><TAB> if not copyright . find ( "" 200 "" ) > = 0 and not copyright . find ( "" 199 "" ) > = 0 : <TAB><TAB><TAB> continue <TAB><TAB> ret . add ( copyright ) <TAB> return ret",if not copyright :,if not copyright :,100.0,100.00,True
3521,"def get_selectable_values ( self , request ) : <TAB> shop = lfs . core . utils . get_default_shop ( request ) <TAB> countries = [ ] <TAB> for country in shop . shipping_countries . all ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> selected = True <TAB><TAB> else : <TAB><TAB><TAB> selected = False <TAB><TAB> countries . append ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" id "" : country . id , <TAB><TAB><TAB><TAB> "" name "" : country . name , <TAB><TAB><TAB><TAB> "" selected "" : selected , <TAB><TAB><TAB> } <TAB><TAB> ) <TAB> return countries",if country in self . value . all ( ) :,if country . is_active :,70.21314274544197,95.40,False
3522,"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB><TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol : <TAB><TAB> for col in range ( 0 , nCol , 2 ) : <TAB><TAB><TAB> # FIND RIGHT COLUMN <TAB><TAB><TAB> if not self . layout . itemAt ( row , col ) : <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> # MAKE NEW ROW <TAB><TAB><TAB> col = 0 <TAB><TAB><TAB> row + = 1 <TAB> self . layout . addItem ( sample , row , col ) <TAB> self . layout . addItem ( label , row , col + 1 )",if col + 2 == nCol :,if col == nCol :,98.76836057605249,98.45,False
3523,def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB><TAB> if not any ( [ not is_text ( s ) for s in node . contents ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,if not contains_only_whitespace ( node . contents ) :,51.92782500705211,81.26,False
3524,"def tokenize_generator ( cw ) : <TAB> ret = [ ] <TAB> done = { } <TAB> for op in ops : <TAB><TAB> ch = op . symbol [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> sops = start_symbols [ ch ] <TAB><TAB> cw . write ( "" case  ' %s ' : "" % ch ) <TAB><TAB> for t in gen_tests ( sops , 1 ) : <TAB><TAB><TAB> cw . write ( t ) <TAB><TAB> done [ ch ] = True <TAB> return ret",if ch in done :,if ch in done :,100.0,100.00,True
3525,"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> nbMinBit = nbChars * 8 <TAB><TAB><TAB> nbMaxBit = nbMinBit <TAB><TAB> else : <TAB><TAB><TAB> if nbChars [ 0 ] is not None : <TAB><TAB><TAB><TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB><TAB><TAB> if nbChars [ 1 ] is not None : <TAB><TAB><TAB><TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )","if isinstance ( nbChars , int ) :",if nbChars [ 0 ] == 1 :,83.59511045419998,94.91,False
3526,"def init ( self , * args , * * kwargs ) : <TAB> if "" _state "" not in kwargs : <TAB><TAB> state = { } <TAB><TAB> # Older versions have the _state entries as individual kwargs <TAB><TAB> for arg in ( "" children "" , "" windowState "" , "" detachedPanels "" ) : <TAB><TAB><TAB> if arg in kwargs : <TAB><TAB><TAB><TAB> state [ arg ] = kwargs [ arg ] <TAB><TAB><TAB><TAB> del kwargs [ arg ] <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs [ "" _state "" ] = state <TAB> originalInit ( self , * args , * * kwargs )",if state :,if state :,100.0,100.00,True
3527,"def spm_decode ( tokens : List [ str ] ) - > List [ str ] : <TAB> words = [ ] <TAB> pieces : List [ str ] = [ ] <TAB> for t in tokens : <TAB><TAB> <MASK> <TAB><TAB><TAB> if len ( pieces ) > 0 : <TAB><TAB><TAB><TAB> words . append ( "" "" . join ( pieces ) ) <TAB><TAB><TAB> pieces = [ t [ 1 : ] ] <TAB><TAB> else : <TAB><TAB><TAB> pieces . append ( t ) <TAB> if len ( pieces ) > 0 : <TAB><TAB> words . append ( "" "" . join ( pieces ) ) <TAB> return words",if t [ 0 ] == DecodeMixin . spm_bos_token :,"if t [ 0 ] == "" "" :",96.65904348161499,95.30,False
3528,"def _compare_dirs ( self , dir1 : str , dir2 : str ) - > List [ str ] : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [ ] # type: List[str] <TAB> for root , dirs , files in os . walk ( dir1 ) : <TAB><TAB> for file_ in files : <TAB><TAB><TAB> path = os . path . join ( root , file_ ) <TAB><TAB><TAB> target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> diff . append ( file_ ) <TAB> return diff",if not os . path . exists ( target_path ) :,"if self . _compare_path ( target_path , dir1 ) :",96.3667423435831,94.38,False
3529,"def credentials ( self ) : <TAB> """"""The session credentials as a dict"""""" <TAB> creds = { } <TAB> if self . _creds : <TAB><TAB> <MASK> # pragma: no branch <TAB><TAB><TAB> creds [ "" aws_access_key_id "" ] = self . _creds . access_key <TAB><TAB> if self . _creds . secret_key : # pragma: no branch <TAB><TAB><TAB> creds [ "" aws_secret_access_key "" ] = self . _creds . secret_key <TAB><TAB> if self . _creds . token : <TAB><TAB><TAB> creds [ "" aws_session_token "" ] = self . _creds . token <TAB> if self . _session . region_name : <TAB><TAB> creds [ "" aws_region "" ] = self . _session . region_name <TAB> if self . requester_pays : <TAB><TAB> creds [ "" aws_request_payer "" ] = "" requester "" <TAB> return creds",if self . _creds . access_key :,if self . _creds . access_key :,100.0,100.00,True
3530,"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB><TAB> # Do like the linkify will do after.... <TAB><TAB> for m in getattr ( a , "" modules "" , [ ] ) : <TAB><TAB><TAB> # So look at what the arbiter try to call as module <TAB><TAB><TAB> m = m . strip ( ) <TAB><TAB><TAB> # Ok, now look in modules... <TAB><TAB><TAB> for mod in self . modules : <TAB><TAB><TAB><TAB> # try to see if this module is the good type <TAB><TAB><TAB><TAB> if getattr ( mod , "" module_type "" , "" "" ) . strip ( ) == mod_type . strip ( ) : <TAB><TAB><TAB><TAB><TAB> # if so, the good name? <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",if m . strip ( ) == mod_type . strip ( ) :,96.08957191435479,94.46,False
3531,"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB><TAB> path = os . path . join ( path , self . index_file ) <TAB><TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB><TAB> if os . path . isfile ( path ) : <TAB><TAB><TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> return self . get_static_file ( path , url ) <TAB><TAB> except IsDirectoryError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path )","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",if os . path . isdir ( path ) :,93.85122323680896,93.09,False
3532,def _use_full_params ( self ) - > None : <TAB> for p in self . params : <TAB><TAB> if not p . _is_sharded : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> assert p . _fp16_shard . storage ( ) . size ( ) != 0 <TAB><TAB><TAB><TAB> p . data = p . _fp16_shard <TAB><TAB> else : <TAB><TAB><TAB> assert p . _full_param_padded . storage ( ) . size ( ) != 0 <TAB><TAB><TAB> p . data = p . _full_param_padded [ : p . _orig_size . numel ( ) ] . view ( p . _orig_size ),if self . mixed_precision :,if p . _fp16_shard is not None :,93.94267161560008,94.74,False
3533,"def _attrdata ( self , cont , name , * val ) : <TAB> if not name : <TAB><TAB> return None , False <TAB> if isinstance ( name , Mapping ) : <TAB><TAB> if val : <TAB><TAB><TAB> raise TypeError ( "" Cannot set a value to  %s "" % name ) <TAB><TAB> return name , True <TAB> else : <TAB><TAB> if val : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return { name : val [ 0 ] } , True <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise TypeError ( "" Too may arguments "" ) <TAB><TAB> else : <TAB><TAB><TAB> cont = self . _extra . get ( cont ) <TAB><TAB><TAB> return cont . get ( name ) if cont else None , False",if len ( val ) == 1 :,if len ( val ) == 1 :,100.0,100.00,True
3534,"def evaluate ( env , net , device = "" cpu "" ) : <TAB> obs = env . reset ( ) <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True : <TAB><TAB> obs_v = ptan . agent . default_states_preprocessor ( [ obs ] ) . to ( device ) <TAB><TAB> action_v = net ( obs_v ) <TAB><TAB> action = action_v . data . cpu ( ) . numpy ( ) [ 0 ] <TAB><TAB> obs , r , done , _ = env . step ( action ) <TAB><TAB> reward + = r <TAB><TAB> steps + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return reward , steps",if done :,if done :,100.0,100.00,True
3535,"def convert_html_js_files ( app : Sphinx , config : Config ) - > None : <TAB> """"""This converts string styled html_js_files to tuple styled one."""""" <TAB> html_js_files = [ ] # type: List[Tuple[str, Dict]] <TAB> for entry in config . html_js_files : <TAB><TAB> <MASK> <TAB><TAB><TAB> html_js_files . append ( ( entry , { } ) ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> filename , attrs = entry <TAB><TAB><TAB><TAB> html_js_files . append ( ( filename , attrs ) ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> logger . warning ( __ ( "" invalid js_file:  %r , ignored "" ) , entry ) <TAB><TAB><TAB><TAB> continue <TAB> config . html_js_files = html_js_files # type: ignore","if isinstance ( entry , str ) :","if isinstance ( entry , str ) :",75.0,100.00,True
3536,"def _check_duplications ( self , regs ) : <TAB> """"""n^2 loop which verifies that each reg exists only once."""""" <TAB> for reg in regs : <TAB><TAB> count = 0 <TAB><TAB> for r in regs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> count + = 1 <TAB><TAB> if count > 1 : <TAB><TAB><TAB> genutil . die ( "" reg  %s  defined more than once "" % reg )",if reg == r :,if reg == r :,100.0,100.00,True
3537,"def PyJsHoisted_vault_ ( key , forget , this , arguments , var = var ) : <TAB> var = Scope ( <TAB><TAB> { u "" this "" : this , u "" forget "" : forget , u "" key "" : key , u "" arguments "" : arguments } , var <TAB> ) <TAB> var . registers ( [ u "" forget "" , u "" key "" ] ) <TAB> if PyJsStrictEq ( var . get ( u "" key "" ) , var . get ( u "" passkey "" ) ) : <TAB><TAB> return ( <TAB><TAB><TAB> var . put ( u "" secret "" , var . get ( u "" null "" ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else ( <TAB><TAB><TAB><TAB> var . get ( u "" secret "" ) <TAB><TAB><TAB><TAB> or var . put ( u "" secret "" , var . get ( u "" secretCreatorFn "" ) ( var . get ( u "" object "" ) ) ) <TAB><TAB><TAB> ) <TAB><TAB> )","if var . get ( u""forget"" )","if PyJsStrictEq ( var . get ( u""key"" ) , var . get",95.67478642891487,95.73,False
3538,"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB><TAB> if isinstance ( v , list ) : <TAB><TAB><TAB> for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB> if isinstance ( v [ i ] , dict ) : <TAB><TAB><TAB><TAB><TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB> d [ k ] = sorted ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","if isinstance ( v , dict ) :","elif isinstance ( v , dict ) :",98.56735284344464,98.62,False
3539,"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB><TAB> if data [ t ] == 0 : <TAB><TAB><TAB> continue <TAB><TAB> value = data [ t ] <TAB><TAB> for b in range ( 8 ) : <TAB><TAB><TAB> if value & 0x80 : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> out . append ( "" (unknown) "" ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB><TAB><TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) )",if len ( TRANSCEIVER [ t ] ) < b + 1 :,if b not in TRANSCEIVER [ t ] :,93.87538139064016,95.46,False
3540,"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB><TAB> if char != self . int_to_char [ self . blank_index ] : <TAB><TAB><TAB> # if this char is a repetition and remove_repetitions=true, <TAB><TAB><TAB> # skip. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> elif char == self . labels [ self . space_index ] : <TAB><TAB><TAB><TAB> string + = ""   "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> string = string + char <TAB> return string",if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,if remove_repetitions and i == self . space_index :,93.91414529257509,93.38,False
3541,"def clean ( self ) : <TAB> username = self . cleaned_data . get ( "" username "" ) <TAB> password = self . cleaned_data . get ( "" password "" ) <TAB> if username and password : <TAB><TAB> self . user_cache = authenticate ( username = username , password = password ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_login "" ] ) <TAB><TAB> elif not self . user_cache . is_active : <TAB><TAB><TAB> raise forms . ValidationError ( self . error_messages [ "" inactive "" ] ) <TAB> self . check_for_test_cookie ( ) <TAB> return self . cleaned_data",if self . user_cache is None :,if not self . user_cache :,68.06151833203769,97.15,False
3542,"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB><TAB> if e . get ( "" event "" ) == UserUttered . type_name : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False","elif e . get ( ""event"" ) == ActionExecuted . type_name :","if e . get ( ""action"" ) == ActionExecuted . type_name :",97.59047117882288,97.13,False
3543,"def getReferences ( view , name = "" "" ) : <TAB> """"""Find all reference definitions."""""" <TAB> # returns {name -> Region} <TAB> refs = [ ] <TAB> name = re . escape ( name ) <TAB> if name == "" "" : <TAB><TAB> refs . extend ( view . find_all ( r "" (?<=^ \ [)([^ \ ]]+)(?= \ ]:) "" , 0 ) ) <TAB> else : <TAB><TAB> refs . extend ( view . find_all ( r "" (?<=^ \ [)( %s )(?= \ ]:) "" % name , 0 ) ) <TAB> regions = refs <TAB> ids = { } <TAB> for reg in regions : <TAB><TAB> name = view . substr ( reg ) . strip ( ) <TAB><TAB> key = name . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ids [ key ] . regions . append ( reg ) <TAB><TAB> else : <TAB><TAB><TAB> ids [ key ] = Obj ( regions = [ reg ] , label = name ) <TAB> return ids",if key in ids :,if key in ids :,100.0,100.00,True
3544,"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . revs_enabled : <TAB><TAB><TAB><TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB><TAB><TAB> return headers . get ( header_name )",if header_name in headers :,"if url . startswith ( ""/latest"" ) :",96.21965436812111,94.51,False
3545,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_shuffle_name ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
3546,"def make_release_tree ( self , base_dir , files ) : <TAB> """"""Make the release tree."""""" <TAB> self . mkpath ( base_dir ) <TAB> create_tree ( base_dir , files , dry_run = self . dry_run ) <TAB> if not files : <TAB><TAB> self . log . warning ( "" no files to distribute -- empty manifest? "" ) <TAB> else : <TAB><TAB> self . log . info ( "" copying files to  %s ... "" , base_dir ) <TAB> for filename in files : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . warning ( "" ' %s '  not a regular file -- skipping "" , filename ) <TAB><TAB> else : <TAB><TAB><TAB> dest = os . path . join ( base_dir , filename ) <TAB><TAB><TAB> self . copy_file ( filename , dest ) <TAB> self . distribution . metadata . write_pkg_info ( base_dir )",if not os . path . isfile ( filename ) :,"if filename . endswith ( "".py"" ) :",94.13868640346215,96.57,False
3547,"def _parse_names_set ( feature_names ) : <TAB> """"""Helping function of `_parse_feature_names` that parses a set of feature names."""""" <TAB> feature_collection = OrderedDict ( ) <TAB> for feature_name in feature_names : <TAB><TAB> <MASK> <TAB><TAB><TAB> feature_collection [ feature_name ] = . . . <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Failed to parse  {} , expected string "" . format ( feature_name ) ) <TAB> return feature_collection","if isinstance ( feature_name , str ) :","if isinstance ( feature_name , str ) :",100.0,100.00,True
3548,"def get_connection ( self , url , proxies = None ) : <TAB> with self . pools . lock : <TAB><TAB> pool = self . pools . get ( url ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return pool <TAB><TAB> pool = NpipeHTTPConnectionPool ( <TAB><TAB><TAB> self . npipe_path , self . timeout , maxsize = self . max_pool_size <TAB><TAB> ) <TAB><TAB> self . pools [ url ] = pool <TAB> return pool",if pool :,if pool :,100.0,100.00,True
3549,"def _parse_dimensions ( dimensions ) : <TAB> arrays = [ ] <TAB> names = [ ] <TAB> for key in dimensions : <TAB><TAB> values = [ v [ "" name "" ] for v in key [ "" values "" ] ] <TAB><TAB> role = key . get ( "" role "" , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> values = [ _fix_quarter_values ( v ) for v in values ] <TAB><TAB><TAB> values = pd . DatetimeIndex ( values ) <TAB><TAB> arrays . append ( values ) <TAB><TAB> names . append ( key [ "" name "" ] ) <TAB> midx = pd . MultiIndex . from_product ( arrays , names = names ) <TAB> if len ( arrays ) == 1 and isinstance ( midx , pd . MultiIndex ) : <TAB><TAB> # Fix for pandas >= 0.21 <TAB><TAB> midx = midx . levels [ 0 ] <TAB> return midx","if role in ( ""time"" , ""TIME_PERIOD"" ) :","if role is not None and role == ""quarter"" :",96.15967214909334,94.52,False
3550,"def _add_trials ( self , name , spec ) : <TAB> """"""Add trial by invoking TrialRunner."""""" <TAB> resource = { } <TAB> resource [ "" trials "" ] = [ ] <TAB> trial_generator = BasicVariantGenerator ( ) <TAB> trial_generator . add_configurations ( { name : spec } ) <TAB> while not trial_generator . is_finished ( ) : <TAB><TAB> trial = trial_generator . next_trial ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> runner . add_trial ( trial ) <TAB><TAB> resource [ "" trials "" ] . append ( self . _trial_info ( trial ) ) <TAB> return resource",if not trial :,if not trial :,100.0,100.00,True
3551,"def _retrieve_key ( self ) : <TAB> url = "" http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf "" <TAB> text = "" "" <TAB> try : <TAB><TAB> r = requests . get ( url , timeout = self . timeout , proxies = self . proxies ) <TAB><TAB> text = r . text <TAB> except : <TAB><TAB> self . error = "" ERROR - URL Connection "" <TAB> if text : <TAB><TAB> expression = r "" ' (....-....-....-....) ' ; "" <TAB><TAB> pattern = re . compile ( expression ) <TAB><TAB> match = pattern . search ( text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . key = match . group ( 1 ) <TAB><TAB><TAB> return self . key <TAB><TAB> else : <TAB><TAB><TAB> self . error = "" ERROR - No API Key """,if match :,if match :,100.0,100.00,True
3552,"def test_net ( net , env , count = 10 , device = "" cpu "" ) : <TAB> rewards = 0.0 <TAB> steps = 0 <TAB> for _ in range ( count ) : <TAB><TAB> obs = env . reset ( ) <TAB><TAB> while True : <TAB><TAB><TAB> obs_v = ptan . agent . float32_preprocessor ( [ obs ] ) . to ( device ) <TAB><TAB><TAB> mu_v = net ( obs_v ) [ 0 ] <TAB><TAB><TAB> action = mu_v . squeeze ( dim = 0 ) . data . cpu ( ) . numpy ( ) <TAB><TAB><TAB> action = np . clip ( action , - 1 , 1 ) <TAB><TAB><TAB> obs , reward , done , _ = env . step ( action ) <TAB><TAB><TAB> rewards + = reward <TAB><TAB><TAB> steps + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> return rewards / count , steps / count",if done :,if done :,100.0,100.00,True
3553,"def compile ( self , filename , obfuscate = False , raw = False , magic = "" \x00 "" * 8 ) : <TAB> body = marshal . dumps ( compile ( self . visit ( self . _source_ast ) , filename , "" exec "" ) ) <TAB> if obfuscate : <TAB><TAB> body_len = len ( body ) <TAB><TAB> offset = 0 if raw else 8 <TAB><TAB> output = bytearray ( body_len + 8 ) <TAB><TAB> for i , x in enumerate ( body ) : <TAB><TAB><TAB> output [ i + offset ] = ord ( x ) ^ ( ( 2 * * ( ( 65535 - i ) % 65535 ) ) % 251 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for i in xrange ( 8 ) : <TAB><TAB><TAB><TAB> output [ i ] = 0 <TAB><TAB> return output <TAB> el<MASK> <TAB><TAB> return body <TAB> else : <TAB><TAB> return magic + body",if raw :,if len ( output ) == body_len :,71.5677492404706,91.74,False
3554,"def _map_saslprep ( s ) : <TAB> """"""Map stringprep table B.1 to nothing and C.1.2 to ASCII space"""""" <TAB> r = [ ] <TAB> for c in s : <TAB><TAB> if stringprep . in_table_c12 ( c ) : <TAB><TAB><TAB> r . append ( ""   "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> r . append ( c ) <TAB> return "" "" . join ( r )",elif not stringprep . in_table_b1 ( c ) :,elif stringprep . in_table_b2 ( c ) :,93.07789495679073,95.99,False
3555,"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB><TAB> w , pos = p <TAB><TAB> if ( w , pos ) in self . composite_dict : <TAB><TAB><TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> lemma = self . word_dict [ w ] <TAB><TAB> else : <TAB><TAB><TAB> lemma = pred <TAB><TAB> if lemma is None : <TAB><TAB><TAB> lemma = w <TAB><TAB> lemmas . append ( lemma ) <TAB> return lemmas",elif w in self . word_dict :,"elif ( w , pos ) in self . word_dict :",83.86121350113731,97.13,False
3556,"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB> if any ( item is None for item in value ) : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> return value <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> else : <TAB><TAB> value = extract_pyreal ( value ) <TAB><TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB><TAB><TAB> return None <TAB><TAB> return value","if value . has_form ( ""List"" , None ) :","if isinstance ( value , Leaf ) :",93.84923286720809,94.94,False
3557,"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB><TAB> src = src_unresolved . resolve ( ) <TAB><TAB> app = src . name <TAB><TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB> if not dest . parent . is_dir ( ) : <TAB><TAB><TAB> mkdir ( dest . parent ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB> dest . unlink ( ) <TAB><TAB> if src . exists ( ) : <TAB><TAB><TAB> shutil . copy ( src , dest )",if dest . exists ( ) :,if dest . exists ( ) :,100.0,100.00,True
3558,"def assert_readback ( vehicle , values ) : <TAB> i = 10 <TAB> while i > 0 : <TAB><TAB> time . sleep ( 0.1 ) <TAB><TAB> i - = 0.1 <TAB><TAB> for k , v in values . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB> break <TAB> if i < = 0 : <TAB><TAB> raise Exception ( "" Did not match in channels readback  %s "" % values )",if vehicle . channels [ k ] != v :,if v != vehicle . value :,89.93137969220174,93.35,False
3559,"def _get_linode_client ( self ) : <TAB> api_key = self . credentials . conf ( "" key "" ) <TAB> api_version = self . credentials . conf ( "" version "" ) <TAB> if api_version == "" "" : <TAB><TAB> api_version = None <TAB> if not api_version : <TAB><TAB> api_version = 3 <TAB><TAB> # Match for v4 api key <TAB><TAB> regex_v4 = re . compile ( "" ^[0-9a-f] {64} $ "" ) <TAB><TAB> regex_match = regex_v4 . match ( api_key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> api_version = 4 <TAB> else : <TAB><TAB> api_version = int ( api_version ) <TAB> return _LinodeLexiconClient ( api_key , api_version )",if regex_match :,if not regex_match :,99.04908198528577,98.79,False
3560,"def mergeHiLo ( self , x_stats ) : <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats . firsttime is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . firsttime = x_stats . firsttime <TAB><TAB><TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB><TAB> if self . lasttime is None or x_stats . lasttime > = self . lasttime : <TAB><TAB><TAB> self . lasttime = x_stats . lasttime <TAB><TAB><TAB> self . last = x_stats . last",if self . firsttime is None or x_stats . firsttime < self . firsttime :,if self . firsttime is None or x_stats . firsttime >= self . firsttime,89.7969584681579,97.39,False
3561,"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB><TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB><TAB> x_len = lengths [ 0 ] <TAB> else : <TAB><TAB> x_len = len ( X ) <TAB> if y is not None : <TAB><TAB> if len ( y ) != x_len : <TAB><TAB><TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB><TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y",if len ( set ( lengths ) ) > 1 :,if len ( lengths ) != len ( X ) :,75.08427430498621,96.44,False
3562,"def set ( self , obj , * * kwargs ) : <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB><TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB><TAB> if k in self . combinations : <TAB><TAB><TAB> for k1 in self . combinations [ k ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> setattr ( self , k1 , ignore )","if not hasattr ( self , k1 ) :","if getattr ( self , k1 ) is None :",94.4610833729845,96.31,False
3563,"def _parse_list ( self , tokens ) : <TAB> # Process left to right, allow descending in sub lists <TAB> assert tokens [ 0 ] in ( "" [ "" , "" ( "" ) <TAB> delim = "" ] "" if tokens . pop ( 0 ) == "" [ "" else "" ) "" <TAB> expr = ExpressionList ( ) <TAB> while tokens and tokens [ 0 ] != delim : <TAB><TAB> item = self . _parse ( tokens ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if tokens . pop ( 0 ) != "" , "" : <TAB><TAB><TAB><TAB> raise ExpressionSyntaxError ( ' Expected:  "" , "" ' ) <TAB><TAB> expr . append ( item ) <TAB> if not tokens or tokens [ 0 ] != delim : <TAB><TAB> raise ExpressionSyntaxError ( ' Missing:  "" %s "" ' % delim ) <TAB> else : <TAB><TAB> tokens . pop ( 0 ) <TAB> return expr",if tokens and tokens [ 0 ] != delim :,if item is not None :,72.02290801717885,95.49,False
3564,"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self : <TAB><TAB> if token . token_type == "" value "" : <TAB><TAB><TAB> return token . stripped_value <TAB><TAB> <MASK> <TAB><TAB><TAB> for token in token : <TAB><TAB><TAB><TAB> if token . token_type == "" bare-quoted-string "" : <TAB><TAB><TAB><TAB><TAB> for token in token : <TAB><TAB><TAB><TAB><TAB><TAB> if token . token_type == "" value "" : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> return token . stripped_value <TAB> return "" ""","if token . token_type == ""quoted-string"" :","if token . token_type == ""bare-quoted-string"" :",73.5699833387137,98.77,False
3565,"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i , line in enumerate ( lines ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if is_magic ( line , main_language ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> continue <TAB><TAB> return i > 0 and _BLANK_LINE . match ( line ) <TAB> return True",if line . startswith ( comment ) :,if comment :,69.36592552758665,95.70,False
3566,"def lots_connected_to_existing_roads ( model ) : <TAB> set = [ ] <TAB> for h in model . HarvestCells : <TAB><TAB> for ( i , j ) in model . ExistingRoads : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if h not in set : <TAB><TAB><TAB><TAB><TAB> set . append ( h ) <TAB> return set",if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,if i == j :,50.43822722575424,81.24,False
3567,"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB><TAB> page , headers , code = get_page ( get = vector ) <TAB><TAB> retval = ( <TAB><TAB><TAB> re . search ( <TAB><TAB><TAB><TAB> r "" \ Abarra_counter_session= "" , <TAB><TAB><TAB><TAB> headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , <TAB><TAB><TAB><TAB> re . I , <TAB><TAB><TAB> ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> retval | = ( <TAB><TAB><TAB> re . search ( <TAB><TAB><TAB><TAB> r "" ( \ A| \ b)barracuda_ "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB><TAB><TAB> ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return retval",if retval :,if retval :,100.0,100.00,True
3568,"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB> names = [ ] <TAB> for d in self . test_directories : <TAB><TAB> test_dir = os . path . join ( dist_dir , d ) <TAB><TAB> for n in os . listdir ( test_dir ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> names . append ( os . path . join ( test_dir , n ) ) <TAB> for filename in names : <TAB><TAB> if test_support . verbose : <TAB><TAB><TAB> print ( "" Testing  %s "" % filename ) <TAB><TAB> source = read_pyfile ( filename ) <TAB><TAB> self . check_roundtrip ( source )","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :","if n . endswith ( "".py"" ) :",71.7603566303781,95.60,False
3569,"def test_calibrate_target ( create_target ) : <TAB> mod , params = testing . synthetic . get_workload ( ) <TAB> dataset = get_calibration_dataset ( mod , "" data "" ) <TAB> with relay . quantize . qconfig ( calibrate_mode = "" kl_divergence "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> with tvm . target . Target ( "" llvm "" ) : <TAB><TAB><TAB><TAB> relay . quantize . quantize ( mod , params , dataset ) <TAB><TAB> else : <TAB><TAB><TAB> # current_target = None <TAB><TAB><TAB> relay . quantize . quantize ( mod , params , dataset )",if create_target :,if create_target :,100.0,100.00,True
3570,"def _cleanSubmodule ( self , _ = None ) : <TAB> rc = RC_SUCCESS <TAB> if self . submodules : <TAB><TAB> command = [ <TAB><TAB><TAB> "" submodule "" , <TAB><TAB><TAB> "" foreach "" , <TAB><TAB><TAB> "" --recursive "" , <TAB><TAB><TAB> "" git "" , <TAB><TAB><TAB> "" clean "" , <TAB><TAB><TAB> "" -f "" , <TAB><TAB><TAB> "" -f "" , <TAB><TAB><TAB> "" -d "" , <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> command . append ( "" -x "" ) <TAB><TAB> rc = yield self . _dovccmd ( command ) <TAB> defer . returnValue ( rc )","if self . mode == ""full"" and self . method == ""fresh"" :",if self . _dovccmd :,69.09289133078623,92.09,False
3571,"def screen_length_to_bytes_count ( string , screen_length_limit , encoding ) : <TAB> bytes_count = 0 <TAB> screen_length = 0 <TAB> for unicode_char in string : <TAB><TAB> screen_length + = screen_len ( unicode_char ) <TAB><TAB> char_bytes_count = len ( unicode_char . encode ( encoding ) ) <TAB><TAB> bytes_count + = char_bytes_count <TAB><TAB> <MASK> <TAB><TAB><TAB> bytes_count - = char_bytes_count <TAB><TAB><TAB> break <TAB> return bytes_count",if screen_length > screen_length_limit :,if screen_length > screen_length_limit :,100.0,100.00,True
3572,"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB><TAB> amount = random . randint ( 10 , 15 ) <TAB><TAB> if char == "" > "" : <TAB><TAB><TAB> retval + = "" > "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> <MASK> <TAB><TAB><TAB> retval + = "" < "" <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> elif char == ""   "" : <TAB><TAB><TAB> for _ in range ( amount ) : <TAB><TAB><TAB><TAB> retval + = random . choice ( junk_chars ) <TAB><TAB> else : <TAB><TAB><TAB> retval + = char <TAB> return retval","elif char == ""<"" :","elif char == ""<"" :",100.0,100.00,True
3573,"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB><TAB> try : <TAB><TAB><TAB> schema . parse ( example . schema_string ) <TAB><TAB><TAB> if example . valid : <TAB><TAB><TAB><TAB> correct + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB><TAB> except : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> correct + = 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB><TAB> correct , <TAB><TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg )",if not example . valid :,if example . valid :,91.33041448903319,99.05,False
3574,"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB> if value != 1 : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> elif value is None : <TAB><TAB><TAB> continue <TAB><TAB> elif len ( value ) != 0 : <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> break <TAB> self . _reset_button . disabled = not changed","if isinstance ( value , bool ) :","if isinstance ( value , str ) :",98.7730155825779,98.86,False
3575,"def normalize ( d : Dict [ Any , Any ] ) - > Dict [ str , Any ] : <TAB> first_exception = None <TAB> for normalizer in normalizers : <TAB><TAB> try : <TAB><TAB><TAB> normalized = normalizer ( d ) <TAB><TAB> except KeyError as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> first_exception = e <TAB><TAB> else : <TAB><TAB><TAB> return normalized <TAB> assert first_exception is not None <TAB> raise first_exception",if not first_exception :,"if e . args [ 0 ] == ""InvalidKey"" :",72.458735306482,91.34,False
3576,"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB><TAB> backref = callback . backref <TAB><TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB><TAB> if root_objs : <TAB><TAB><TAB> if not isinstance ( root_objs , Iterable ) : <TAB><TAB><TAB><TAB> root_objs = [ root_objs ] <TAB><TAB><TAB> with session . no_autoflush : <TAB><TAB><TAB><TAB> for root_obj in root_objs : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> args = self . get_callback_args ( root_obj , callback ) <TAB><TAB><TAB><TAB><TAB><TAB> if args : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> yield args",if root_obj :,"if hasattr ( root_obj , ""callback"" ) :",69.04509350833972,96.15,False
3577,"def test_opdm_to_oqdm ( self ) : <TAB> for file in filter ( lambda x : x . endswith ( "" .hdf5 "" ) , os . listdir ( DATA_DIRECTORY ) ) : <TAB><TAB> molecule = MolecularData ( filename = os . path . join ( DATA_DIRECTORY , file ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> test_oqdm = map_one_pdm_to_one_hole_dm ( molecule . fci_one_rdm ) <TAB><TAB><TAB> true_oqdm = numpy . eye ( molecule . n_qubits ) - molecule . fci_one_rdm <TAB><TAB><TAB> assert numpy . allclose ( test_oqdm , true_oqdm )",if molecule . fci_one_rdm is not None :,if molecule . fci_one_rdm is not None :,100.0,100.00,True
3578,"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB><TAB> if self . checkForStop ( ) : <TAB><TAB><TAB> return None <TAB><TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . emitHostname ( subDomain , event )",if subDomain :,if subDomain :,100.0,100.00,True
3579,"def download_cve ( <TAB> download_path : str , years : Optional [ List [ int ] ] = None , update : bool = False ) : <TAB> if update : <TAB><TAB> process_url ( CVE_URL . format ( "" modified "" ) , download_path ) <TAB> else : <TAB><TAB> all_cve_urls = get_cve_links ( CVE_URL , years ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CveLookupException ( "" Error: No CVE links found "" ) <TAB><TAB> for url in all_cve_urls : <TAB><TAB><TAB> process_url ( url , download_path )",if not all_cve_urls :,if not all_cve_urls :,100.0,100.00,True
3580,"def is_special ( s , i , directive ) : <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive [ 0 ] == "" @ "" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB> while i < len ( s ) : <TAB><TAB> if match_word ( s , i , directive ) : <TAB><TAB><TAB> return True , i <TAB><TAB> else : <TAB><TAB><TAB> i = skip_line ( s , i ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> i = skip_ws ( s , i ) <TAB> return False , - 1",if skip_flag :,if skip_flag :,100.0,100.00,True
3581,"def run_async ( self , nuke_cursors ) : <TAB> # type: (bool) -> None <TAB> interface_type = self . view . settings ( ) . get ( "" git_savvy.interface "" ) <TAB> for cls in subclasses : <TAB><TAB> if cls . interface_type == interface_type : <TAB><TAB><TAB> vid = self . view . id ( ) <TAB><TAB><TAB> interface = interfaces . get ( vid , None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> interface = interfaces [ vid ] = cls ( view = self . view ) <TAB><TAB><TAB> interface . render ( nuke_cursors = nuke_cursors ) # type: ignore[union-attr] <TAB><TAB><TAB> break",if not interface :,if not interface :,75.0,100.00,True
3582,"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB><TAB> <MASK> <TAB><TAB><TAB> if str ( conf [ "" properties "" ] [ "" sslEnforcement "" ] ) . lower ( ) == "" enabled "" : <TAB><TAB><TAB><TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""sslEnforcement"" in conf [ ""properties"" ] :","if ""sslEnforcement"" in conf [ ""properties"" ] :",75.0,100.00,True
3583,"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB><TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB><TAB> if short_has_arg ( opt , shortopts ) : <TAB><TAB><TAB> if optstring == "" "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB><TAB><TAB><TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB><TAB><TAB> optarg , optstring = optstring , "" "" <TAB><TAB> else : <TAB><TAB><TAB> optarg = "" "" <TAB><TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args",if not args :,if not args :,100.0,100.00,True
3584,"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB> assert self . count > 0 <TAB><TAB> self . count - = 1 <TAB><TAB> if self . count == 0 : <TAB><TAB><TAB> self . owner = None <TAB><TAB><TAB> if self . waiters : <TAB><TAB><TAB><TAB> self . waiters - = 1 <TAB><TAB><TAB><TAB> self . wakeup . release ( )",if self . owner != tid :,if tid != self . owner :,95.60904447542558,96.87,False
3585,"def _summarize_kraken ( fn ) : <TAB> """"""get the value at species level"""""" <TAB> kraken = { } <TAB> list_sp , list_value = [ ] , [ ] <TAB> with open ( fn ) as handle : <TAB><TAB> for line in handle : <TAB><TAB><TAB> cols = line . strip ( ) . split ( "" \t "" ) <TAB><TAB><TAB> sp = cols [ 5 ] . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> list_sp . append ( sp ) <TAB><TAB><TAB><TAB> list_value . append ( cols [ 0 ] ) <TAB> kraken = { "" kraken_sp "" : list_sp , "" kraken_value "" : list_value } <TAB> return kraken","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",if sp :,69.13621978167801,88.90,False
3586,"def _sync_remote_run ( remote_run ) : <TAB> assert remote_run . remote <TAB> remote_name = remote_run . remote . name <TAB> pull_args = click_util . Args ( remote = remote_name , delete = False ) <TAB> try : <TAB><TAB> remote_impl_support . pull_runs ( [ remote_run ] , pull_args ) <TAB> except Exception as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . exception ( "" pull  %s  from  %s "" , remote_run . id , remote_name ) <TAB><TAB> else : <TAB><TAB><TAB> log . error ( "" error pulling  %s  from  %s :  %s "" , remote_run . id , remote_name , e )",if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,100.0,100.00,True
3587,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB><TAB> ki = key ( i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> if ki != 0 : <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB> else : <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> if sign * ki < - slop : <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB> yield subseq <TAB><TAB><TAB><TAB> subseq = [ i ] <TAB> if subseq : <TAB><TAB> yield subseq",if sign is None :,if sign is None :,100.0,100.00,True
3588,"def import_til ( self ) : <TAB> log ( "" Importing type libraries... "" ) <TAB> cur = self . db_cursor ( ) <TAB> sql = "" select name from diff.program_data where type =  ' til ' "" <TAB> cur . execute ( sql ) <TAB> for row in cur . fetchall ( ) : <TAB><TAB> til = row [ "" name "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> til = til . decode ( "" utf-8 "" ) <TAB><TAB> try : <TAB><TAB><TAB> add_default_til ( til ) <TAB><TAB> except : <TAB><TAB><TAB> log ( "" Error loading til  %s :  %s "" % ( row [ "" name "" ] , str ( sys . exc_info ( ) [ 1 ] ) ) ) <TAB> cur . close ( ) <TAB> auto_wait ( )",if type ( til ) is bytes :,"if isinstance ( til , bytes ) :",94.47918619160124,97.09,False
3589,"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB><TAB> <MASK> <TAB><TAB><TAB> git_branch_line = git_branch_line [ 1 : ] <TAB><TAB> git_branch_line = git_branch_line . strip ( ) <TAB><TAB> if BRANCH_ALIAS_MARKER in git_branch_line : <TAB><TAB><TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB><TAB><TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB><TAB> else : <TAB><TAB><TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned","if git_branch_line . startswith ( ""*"" ) :","if git_branch_line . startswith ( ""alias"" ) :",98.78510547571634,98.81,False
3590,"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB><TAB> # FIXME same hack, forcibly unpack from holder. <TAB><TAB> <MASK> <TAB><TAB><TAB> a = a . includedirs <TAB><TAB> if not isinstance ( a , IncludeDirs ) : <TAB><TAB><TAB> raise InvalidArguments ( <TAB><TAB><TAB><TAB> "" Include directory to be added is not an include directory object. "" <TAB><TAB><TAB> ) <TAB><TAB> ids . append ( a ) <TAB> self . include_dirs + = ids","if hasattr ( a , ""includedirs"" ) :","if isinstance ( a , File ) :",97.08259628108877,95.54,False
3591,"def _serialize_feature ( self , feature ) : <TAB> name = feature . unique_name ( ) <TAB> <MASK> <TAB><TAB> self . _features_dict [ feature . unique_name ( ) ] = feature . to_dictionary ( ) <TAB><TAB> for dependency in feature . get_dependencies ( deep = True ) : <TAB><TAB><TAB> name = dependency . unique_name ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _features_dict [ name ] = dependency . to_dictionary ( )",if name not in self . _features_dict :,if name not in self . _features_dict :,100.0,100.00,True
3592,"def generate_io ( chart_type , race_configs , environment ) : <TAB> # output JSON structures <TAB> structures = [ ] <TAB> for race_config in race_configs : <TAB><TAB> <MASK> <TAB><TAB><TAB> title = chart_type . format_title ( <TAB><TAB><TAB><TAB> environment , <TAB><TAB><TAB><TAB> race_config . track , <TAB><TAB><TAB><TAB> es_license = race_config . es_license , <TAB><TAB><TAB><TAB> suffix = "" %s -io "" % race_config . label , <TAB><TAB><TAB> ) <TAB><TAB><TAB> structures . append ( chart_type . io ( title , environment , race_config ) ) <TAB> return structures","if ""io"" in race_config . charts :","if isinstance ( race_config , ChartConfig ) :",70.98805977267041,95.52,False
3593,"def format_partition ( partition , partition_schema ) : <TAB> tokens = [ ] <TAB> if isinstance ( partition , dict ) : <TAB><TAB> for name in partition_schema : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tok = _format_partition_kv ( <TAB><TAB><TAB><TAB><TAB> name , partition [ name ] , partition_schema [ name ] <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # dynamic partitioning <TAB><TAB><TAB><TAB> tok = name <TAB><TAB><TAB> tokens . append ( tok ) <TAB> else : <TAB><TAB> for name , value in zip ( partition_schema , partition ) : <TAB><TAB><TAB> tok = _format_partition_kv ( name , value , partition_schema [ name ] ) <TAB><TAB><TAB> tokens . append ( tok ) <TAB> return "" PARTITION ( {} ) "" . format ( "" ,  "" . join ( tokens ) )",if name in partition :,if name in partition :,100.0,100.00,True
3594,"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self # don't copy unless we need to <TAB> if condition is not Undefined : <TAB><TAB> if isinstance ( condition , core . SchemaBase ) : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB><TAB><TAB> copy = self . copy ( deep = [ "" condition "" ] ) <TAB><TAB><TAB> copy . condition . update ( kwds ) <TAB> return super ( ValueChannelMixin , copy ) . to_dict ( <TAB><TAB> validate = validate , ignore = ignore , context = context <TAB> )","elif ""field"" in condition and ""type"" not in condition :","elif isinstance ( condition , dict ) :",96.56227960050614,93.97,False
3595,"def _checkForCommand ( self ) : <TAB> prompt = b "" cftp>  "" <TAB> if self . _expectingCommand and self . _lineBuffer == prompt : <TAB><TAB> buf = b "" \n "" . join ( self . _linesReceived ) <TAB><TAB> <MASK> <TAB><TAB><TAB> buf = buf [ len ( prompt ) : ] <TAB><TAB> self . clearBuffer ( ) <TAB><TAB> d , self . _expectingCommand = self . _expectingCommand , None <TAB><TAB> d . callback ( buf )",if buf . startswith ( prompt ) :,if buf . startswith ( prompt ) :,100.0,100.00,True
3596,"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB><TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB><TAB> if delete : <TAB><TAB><TAB> with LoggerFactory . lock : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> if job_id in key : <TAB><TAB><TAB><TAB><TAB><TAB><TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> return True <TAB><TAB> key = job_id + "" schedule "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB><TAB> return LoggerFactory . get_schedule_logger ( job_id )",if key in LoggerFactory . schedule_logger_dict :,if key in LoggerFactory . schedule_logger_dict :,100.0,100.00,True
3597,"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB><TAB> wrong_found = 0 <TAB><TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB><TAB><TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB><TAB><TAB><TAB> if "" %s %s "" % ( wrong , nr ) in nzb_name . lower ( ) : <TAB><TAB><TAB><TAB><TAB> wrong_found + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> return - 30 <TAB><TAB> return 0 <TAB> except : <TAB><TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0",if wrong_found == 1 :,if wrong_found == 1 :,100.0,100.00,True
3598,"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB><TAB> value = item . group ( "" stringval "" ) <TAB><TAB> if value is None : <TAB><TAB><TAB> value = item . group ( "" value "" ) <TAB><TAB> value = _pythonize ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> args . append ( value ) <TAB><TAB> else : <TAB><TAB><TAB> name = item . group ( "" name "" ) <TAB><TAB><TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs","if not item . group ( ""name"" ) :","if item . group ( ""name"" ) is None :",79.90662432031215,97.68,False
3599,"def leaves ( self , unique = True ) : <TAB> """"""Get the leaves of the tree starting at this root."""""" <TAB> if not self . children : <TAB><TAB> return [ self ] <TAB> else : <TAB><TAB> res = list ( ) <TAB><TAB> for child in self . children : <TAB><TAB><TAB> for sub_child in child . leaves ( unique = unique ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> res . append ( sub_child ) <TAB><TAB> return res",if not unique or sub_child not in res :,if sub_child not in res :,94.4834825675846,97.06,False
3600,"def to_tree ( self , tagname = None , idx = None , namespace = None ) : <TAB> axIds = set ( ( ax . axId for ax in self . _axes ) ) <TAB> for chart in self . _charts : <TAB><TAB> for id , axis in chart . _axes . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> setattr ( self , axis . tagname , axis ) <TAB><TAB><TAB><TAB> axIds . add ( id ) <TAB> return super ( PlotArea , self ) . to_tree ( tagname )",if id not in axIds :,if id not in axIds :,100.0,100.00,True
3601,"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB><TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB><TAB><TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB> if k == neighbors . ENABLED : <TAB><TAB><TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . CONNECT_MODE :,if k == neighbors . CONNECT_MODE :,100.0,100.00,True
3602,"def close_all_connections ( ) : <TAB> global _managers , _lock , _in_use , _timer <TAB> _lock . acquire ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> _timer . cancel ( ) <TAB><TAB><TAB> _timer = None <TAB><TAB> for domain , managers in _managers . items ( ) : <TAB><TAB><TAB> for manager in managers : <TAB><TAB><TAB><TAB> manager . close ( ) <TAB><TAB> _managers = { } <TAB> finally : <TAB><TAB> _lock . release ( )",if _timer :,if _timer :,100.0,100.00,True
3603,"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB><TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB><TAB> if isinstance ( value , tf . keras . layers . Layer ) : <TAB><TAB><TAB> new_layer = self . _instrument ( value ) <TAB><TAB><TAB> if new_layer is not value : <TAB><TAB><TAB><TAB> setattr ( model , key , new_layer ) <TAB><TAB> elif isinstance ( value , list ) : <TAB><TAB><TAB> for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> value [ i ] = self . _instrument ( item ) <TAB> return model","if isinstance ( item , tf . keras . layers . Layer ) :","if isinstance ( item , tf . keras . layers . Layer ) :",100.0,100.00,True
3604,"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB><TAB> if fnmatch . fnmatch ( tgt , host ) : <TAB><TAB><TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB><TAB><TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret","if __opts__ . get ( ""ssh_user"" ) :","if __opts__ [ ""ssh_user"" ] :",77.36920214912904,95.81,False
3605,"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB><TAB> if self . _write_line : <TAB><TAB><TAB> sys . stderr . write ( fn + "" :  "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB><TAB> else : <TAB><TAB><TAB> sys . stderr . write ( data ) <TAB><TAB> if ( data [ - 1 ] ) == "" \n "" : <TAB><TAB><TAB> self . _write_line = True <TAB><TAB> else : <TAB><TAB><TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data )",if bytes :,"elif isinstance ( data , bytes ) :",95.86833002653454,95.79,False
3606,"def task_thread ( ) : <TAB> while not task_queue . empty ( ) : <TAB><TAB> host , port , username , password = task_queue . get ( ) <TAB><TAB> logger . info ( <TAB><TAB><TAB> "" try burst  {} : {}  use username: {}  password: {} "" . format ( <TAB><TAB><TAB><TAB> host , port , username , password <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with task_queue . mutex : <TAB><TAB><TAB><TAB> task_queue . queue . clear ( ) <TAB><TAB><TAB> result_queue . put ( ( username , password ) )","if telnet_login ( host , port , username , password ) :","if host == ""localhost"" and port == ""80"" :",65.5245495704945,92.79,False
3607,"def _format_results ( name , ppl , scores , metrics ) : <TAB> """"""Format results."""""" <TAB> result_str = "" "" <TAB> if ppl : <TAB><TAB> result_str = "" %s  ppl  %.2f "" % ( name , ppl ) <TAB> if scores : <TAB><TAB> for metric in metrics : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result_str + = "" ,  %s   %s   %.1f "" % ( name , metric , scores [ metric ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> result_str = "" %s   %s   %.1f "" % ( name , metric , scores [ metric ] ) <TAB> return result_str",if result_str :,if result_str :,100.0,100.00,True
3608,"def info_query ( self , query ) : <TAB> """"""Send a query which only returns 1 row"""""" <TAB> self . _cmysql . query ( query ) <TAB> first_row = ( ) <TAB> if self . _cmysql . have_result_set : <TAB><TAB> first_row = self . _cmysql . fetch_row ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _cmysql . free_result ( ) <TAB><TAB><TAB> raise errors . InterfaceError ( "" Query should not return more than 1 row "" ) <TAB> self . _cmysql . free_result ( ) <TAB> return first_row",if self . _cmysql . fetch_row ( ) :,if first_row > 1 :,66.65976587387081,93.39,False
3609,"def reset_class ( self ) : <TAB> for f in self . fields_order : <TAB><TAB> <MASK> <TAB><TAB><TAB> f . value = int ( f . strbits , 2 ) <TAB><TAB> elif "" default_val "" in f . kargs : <TAB><TAB><TAB> f . value = int ( f . kargs [ "" default_val "" ] , 2 ) <TAB><TAB> else : <TAB><TAB><TAB> f . value = None <TAB><TAB> if f . fname : <TAB><TAB><TAB> setattr ( self , f . fname , f )",if f . strbits and isbin ( f . strbits ) :,if f . strbits :,89.54509041284201,94.43,False
3610,"def _walk_map_list ( self , access_func ) : <TAB> seen = [ ] <TAB> cur = self <TAB> while cur : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> yield cur <TAB><TAB> seen . append ( cur . obj_offset ) <TAB><TAB> # check for signs of infinite looping <TAB><TAB> if len ( seen ) > 1024 : <TAB><TAB><TAB> break <TAB><TAB> cur = access_func ( cur )",if cur . obj_offset in seen :,if cur . obj_offset in seen :,100.0,100.00,True
3611,def bgdel ( ) : <TAB> q = bgdelq <TAB> while True : <TAB><TAB> name = q . get ( ) <TAB><TAB> while os . path . exists ( name ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> os . remove ( name ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> shutil . rmtree ( name ) <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> if os . path . exists ( name ) : <TAB><TAB><TAB><TAB> time . sleep ( 0.1 ),if os . path . isfile ( name ) :,if os . path . exists ( name ) :,98.52952258150263,98.71,False
3612,"def _find_all_variables ( transfer_variable ) : <TAB> d = { } <TAB> for _k , _v in transfer_variable . __dict__ . items ( ) : <TAB><TAB> if isinstance ( _v , Variable ) : <TAB><TAB><TAB> d [ _v . _name ] = _v <TAB><TAB> <MASK> <TAB><TAB><TAB> d . update ( _find_all_variables ( _v ) ) <TAB> return d","elif isinstance ( _v , BaseTransferVariables ) :","elif isinstance ( _v , ( list , tuple ) ) :",78.66788941463699,94.81,False
3613,"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB><TAB> row = model [ idx ] <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> if idx == len ( os_widget . get_model ( ) ) - 1 : <TAB><TAB><TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB><TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB><TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB><TAB> return None",if value and row [ 0 ] == value :,if row [ 0 ] != 0 :,68.27567645281493,95.76,False
3614,"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB><TAB> if methods == ALL : <TAB><TAB><TAB> methods = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB><TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( )","elif isinstance ( methods , ( list , tuple ) ) :","if isinstance ( methods , list ) :",73.9428663772366,95.98,False
3615,"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB><TAB> # ignore hidden files/dirs and other unwanted files <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> pathname = os . path . join ( path , name ) <TAB><TAB> st = os . lstat ( pathname ) <TAB><TAB> mode = st . st_mode <TAB><TAB> if stat . S_ISDIR ( mode ) : <TAB><TAB><TAB> files . extend ( findfiles ( pathname ) ) <TAB><TAB> elif stat . S_ISREG ( mode ) : <TAB><TAB><TAB> files . append ( ( pathname , name , st ) ) <TAB> return files","if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :","if name . startswith ( ""_"" ) :",96.78426639564498,93.43,False
3616,"def __getitem__ ( self , key ) : <TAB> if isinstance ( key , str_types ) : <TAB><TAB> keys = self . get_keys ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise KeyError ( '   "" {0} ""  is an invalid key ' . format ( key ) ) <TAB><TAB> else : <TAB><TAB><TAB> return self [ keys . index ( key ) ] <TAB> else : <TAB><TAB> return list . __getitem__ ( self , key )",if key not in keys :,if key not in keys :,100.0,100.00,True
3617,"def test_assert_set_equal ( estimate : tp . Iterable [ int ] , message : str ) - > None : <TAB> reference = { 1 , 2 , 3 } <TAB> try : <TAB><TAB> testing . assert_set_equal ( estimate , reference ) <TAB> except AssertionError as error : <TAB><TAB> if not message : <TAB><TAB><TAB> raise AssertionError ( <TAB><TAB><TAB><TAB> "" An error has been raised while it should not. "" <TAB><TAB><TAB> ) from error <TAB><TAB> np . testing . assert_equal ( error . args [ 0 ] . split ( "" \n "" ) [ 1 : ] , message ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AssertionError ( "" An error should have been raised. "" )",if message :,"if not np . testing . assert_equal ( estimate , reference ) :",67.63763069062905,93.04,False
3618,"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB><TAB> <MASK> <TAB><TAB><TAB> subp = os . path . join ( pth , p ) <TAB><TAB><TAB> p = os . path . join ( prefix , p ) <TAB><TAB><TAB> if recursive and os . path . isdir ( subp ) : <TAB><TAB><TAB><TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> res . append ( [ p , None ] ) <TAB> return res","if p [ 0 ] != ""."" :",if p . startswith ( prefix ) :,93.53650167721848,95.31,False
3619,"def check ( self , runner , script , info ) : <TAB> if isinstance ( info , ast . FunctionDef ) : <TAB><TAB> for arg in info . args . args : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if arg . id in script . modelVars : <TAB><TAB><TAB><TAB><TAB> self . problem ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Function  {0}  may shadow model variable  {1} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> info . name , arg . id <TAB><TAB><TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB><TAB><TAB> lineno = info . lineno , <TAB><TAB><TAB><TAB><TAB> )","if isinstance ( arg , ast . Name ) :","if isinstance ( arg , ast . NameDef ) :",98.62235678142012,98.86,False
3620,"def db_lookup ( field , key , publish_year = None ) : <TAB> sql = "" select sum(ebook_count) as num from subjects where field=$field and key=$key "" <TAB> if publish_year : <TAB><TAB> <MASK> <TAB><TAB><TAB> sql + = ""  and publish_year between $y1 and $y2 "" <TAB><TAB><TAB> ( y1 , y2 ) = publish_year <TAB><TAB> else : <TAB><TAB><TAB> sql + = ""  and publish_year=$publish_year "" <TAB> return list ( ebook_count_db . query ( sql , vars = locals ( ) ) ) [ 0 ] . num","if isinstance ( publish_year , ( tuple , list ) ) :","if publish_year < ( y1 , y2 ) :",89.90005764455982,93.85,False
3621,"def put ( self , session ) : <TAB> with sess_lock : <TAB><TAB> self . parent . put ( session ) <TAB><TAB> # Do not store the session if skip paths <TAB><TAB> for sp in self . skip_paths : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> if session . sid in self . _cache : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> del self . _cache [ session . sid ] <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> pass <TAB><TAB> self . _cache [ session . sid ] = session <TAB> self . _normalize ( )",if request . path . startswith ( sp ) :,if sp . sid == session . sid :,95.54950144726983,95.39,False
3622,"def summarize ( self ) : <TAB> if self . bad_commit and self . good_commit : <TAB><TAB> for subresult in self . subresults . values ( ) : <TAB><TAB><TAB> sub = subresult . summarize ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return sub <TAB><TAB> return "" Detected bad commit in  {}  repository: \n {}   {} "" . format ( <TAB><TAB><TAB> self . repo_name , self . bad_commit , get_message ( self . suite , self . bad_commit ) <TAB><TAB> ) <TAB> return "" """,if sub :,if sub :,100.0,100.00,True
3623,def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB><TAB> for p in self . grammar . Productions [ 1 : ] : <TAB><TAB><TAB> if p . len == 0 : <TAB><TAB><TAB><TAB> nullable [ p . name ] = 1 <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> for t in p . prod : <TAB><TAB><TAB><TAB> if not t in nullable : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> nullable [ p . name ] = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> num_nullable = len ( nullable ) <TAB> return nullable,if len ( nullable ) == num_nullable :,if num_nullable != p . len :,81.22588629862683,96.22,False
3624,"def _cast_float64_to_float32 ( self , feeds ) : <TAB> for input_name , input_type in self . inputs : <TAB><TAB> <MASK> <TAB><TAB><TAB> feed = feeds . get ( input_name ) <TAB><TAB><TAB> if feed is not None and feed . dtype == np . float64 : <TAB><TAB><TAB><TAB> feeds [ input_name ] = feed . astype ( np . float32 ) <TAB> return feeds","if input_type == ""tensor(float)"" :","if input_type == ""float64"" :",98.04228288820445,95.53,False
3625,"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB><TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if is_prev : <TAB><TAB><TAB><TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB><TAB><TAB> return True , d <TAB> return False , d",if diff_min is not None and diff_min != 0 :,if diff_min is not None :,88.71948534387467,94.96,False
3626,"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB><TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB><TAB> if not isinstance ( key , str ) : <TAB><TAB><TAB> key = str ( key ) <TAB><TAB> detyper = self . get_detyper ( key ) <TAB><TAB> if detyper is None : <TAB><TAB><TAB> # cannot be detyped <TAB><TAB><TAB> continue <TAB><TAB> deval = detyper ( val ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # cannot be detyped <TAB><TAB><TAB> continue <TAB><TAB> ctx [ key ] = deval <TAB> self . _detyped = ctx <TAB> return ctx",if deval is None :,if deval is None :,100.0,100.00,True
3627,"def get_or_create_user ( request , user_data ) : <TAB> try : <TAB><TAB> user = User . objects . get ( sso_id = user_data [ "" id "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> update_user ( user , user_data ) <TAB><TAB> return user <TAB> except User . DoesNotExist : <TAB><TAB> user = User . objects . create_user ( <TAB><TAB><TAB> user_data [ "" username "" ] , <TAB><TAB><TAB> user_data [ "" email "" ] , <TAB><TAB><TAB> is_active = user_data . get ( "" is_active "" , True ) , <TAB><TAB><TAB> sso_id = user_data [ "" id "" ] , <TAB><TAB> ) <TAB><TAB> user . update_acl_key ( ) <TAB><TAB> setup_new_user ( request . settings , user ) <TAB><TAB> return user","if user_needs_updating ( user , user_data ) :",if user . is_active :,79.39349777484787,95.10,False
3628,"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> self . _populate_dict ( element , k , v ) <TAB><TAB> elif isinstance ( v , list ) : <TAB><TAB><TAB> self . _populate_list ( element , k , v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _populate_bool ( element , k , v ) <TAB><TAB> elif isinstance ( v , basestring ) : <TAB><TAB><TAB> self . _populate_str ( element , k , v ) <TAB><TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB><TAB><TAB> self . _populate_number ( element , k , v )","elif isinstance ( v , bool ) :","elif isinstance ( v , bool ) :",75.0,100.00,True
3629,"def load ( cls ) : <TAB> if not cls . _loaded : <TAB><TAB> cls . log . debug ( "" Loading action_sets... "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _find_action_sets ( PATHS . ACTION_SETS_DIRECTORY ) <TAB><TAB> else : <TAB><TAB><TAB> cls . action_sets = JsonDecoder . load ( PATHS . ACTION_SETS_JSON_FILE ) <TAB><TAB> cls . log . debug ( "" Done! "" ) <TAB><TAB> cls . _loaded = True",if not horizons . globals . fife . use_atlases :,if os . path . isdir ( PATHS . ACTION_SETS_DIRECTORY ) :,86.25621246355264,90.33,False
3630,"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB><TAB> for setting , edge in self . Conflicts : <TAB><TAB><TAB> answer = self . AskUser ( self . Setting , setting ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = setting . Value . split ( "" | "" ) <TAB><TAB><TAB><TAB> value . remove ( edge ) <TAB><TAB><TAB><TAB> setting . Value = "" | "" . join ( value ) <TAB><TAB><TAB><TAB> if updater : <TAB><TAB><TAB><TAB><TAB> updater . UpdateSetting ( setting ) <TAB><TAB><TAB> if answer == Gtk . ResponseType . NO : <TAB><TAB><TAB><TAB> return False <TAB> return True",if answer == Gtk . ResponseType . YES :,if answer == Gtk . ResponseType . NO :,75.2661818175069,98.83,False
3631,"def read_tsv ( input_file , quotechar = None ) : <TAB> """"""Reads a tab separated value file."""""" <TAB> with open ( input_file , "" r "" , encoding = "" utf-8-sig "" ) as f : <TAB><TAB> reader = csv . reader ( f , delimiter = "" \t "" , quotechar = quotechar ) <TAB><TAB> lines = [ ] <TAB><TAB> for line in reader : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> line = list ( str ( cell , "" utf-8 "" ) for cell in line ) # noqa: F821 <TAB><TAB><TAB> lines . append ( line ) <TAB><TAB> return lines",if sys . version_info [ 0 ] == 2 :,"if not line . startswith ( ""#"" ) :",67.16342708195286,93.09,False
3632,"def devd_devfs_hook ( middleware , data ) : <TAB> if data . get ( "" subsystem "" ) != "" CDEV "" : <TAB><TAB> return <TAB> if data [ "" type "" ] == "" CREATE "" : <TAB><TAB> disks = await middleware . run_in_thread ( <TAB><TAB><TAB> lambda : sysctl . filter ( "" kern.disks "" ) [ 0 ] . value . split ( ) <TAB><TAB> ) <TAB><TAB> # Device notified about is not a disk <TAB><TAB> if data [ "" cdev "" ] not in disks : <TAB><TAB><TAB> return <TAB><TAB> await added_disk ( middleware , data [ "" cdev "" ] ) <TAB> elif data [ "" type "" ] == "" DESTROY "" : <TAB><TAB> # Device notified about is not a disk <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> await remove_disk ( middleware , data [ "" cdev "" ] )","if not RE_ISDISK . match ( data [ ""cdev"" ] ) :","if data [ ""cdev"" ] not in disks :",97.18416409290211,95.66,False
3633,"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . watchdirs [ watchdir_id ] [ "" enabled "" ] : <TAB><TAB><TAB><TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB><TAB> else : <TAB><TAB><TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id )","if col and col . get_title ( ) == _ ( ""Active"" ) :",if self . watchdirs [ watchdir_id ] :,91.79571737454376,91.92,False
3634,"def _execute ( self , options , args ) : <TAB> if len ( args ) < 1 : <TAB><TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> paths = args <TAB> songs = [ self . load_song ( p ) for p in paths ] <TAB> for song in songs : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CommandError ( <TAB><TAB><TAB><TAB> _ ( "" Image editing not supported for  %(file_name)s   "" "" ( %(file_format)s ) "" ) <TAB><TAB><TAB><TAB> % { "" file_name "" : song ( "" ~filename "" ) , "" file_format "" : song ( "" ~format "" ) } <TAB><TAB><TAB> ) <TAB> for song in songs : <TAB><TAB> try : <TAB><TAB><TAB> song . clear_images ( ) <TAB><TAB> except AudioFileError as e : <TAB><TAB><TAB> raise CommandError ( e )",if not song . can_change_images :,if song . file_format is None :,70.19209545361696,96.57,False
3635,"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB><TAB> for pricing_rule in pricing_rules : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) : <TAB><TAB><TAB><TAB><TAB><TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB><TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules",if pricing_rule . condition :,"if hasattr ( pricing_rule , ""condition"" ) :",95.25958778537921,96.10,False
3636,"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB><TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB><TAB> if text == ' "" use strict "" ' or text == "" ' use strict ' "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _scopeStrictModes . pop ( ) <TAB><TAB><TAB> self . _useStrictCurrent = True <TAB><TAB><TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent )",if len ( self . _scopeStrictModes ) > 0 :,if self . _useStrictCurrent :,89.53006807743779,93.85,False
3637,"def _find_remote_inputs ( metadata ) : <TAB> out = [ ] <TAB> for fr_key in metadata . keys ( ) : <TAB><TAB> if isinstance ( fr_key , ( list , tuple ) ) : <TAB><TAB><TAB> frs = fr_key <TAB><TAB> else : <TAB><TAB><TAB> frs = [ fr_key ] <TAB><TAB> for fr in frs : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> out . append ( fr ) <TAB> return out",if objectstore . is_remote ( fr ) :,"if isinstance ( fr , ( str , unicode ) ) :",93.14113257851584,93.18,False
3638,"def sub_paragraph ( self , li ) : <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len ( li ) : <TAB><TAB> first = list ( li ) [ 0 ] <TAB><TAB> if first . tag == "" p "" and first . text is not None : <TAB><TAB><TAB> m = RE_CHECKBOX . match ( first . text ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> first . text = self . markdown . htmlStash . store ( <TAB><TAB><TAB><TAB><TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB><TAB><TAB><TAB> ) + m . group ( "" line "" ) <TAB><TAB><TAB><TAB> found = True <TAB> return found",if m is not None :,if m :,85.81227505741353,97.86,False
3639,"def list_files ( basedir ) : <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os . path . isdir ( basedir ) : <TAB><TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB><TAB> d = directories . pop ( ) <TAB><TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB><TAB><TAB> filename = os . path . join ( d , basename ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> directories . append ( filename ) <TAB><TAB><TAB> elif os . path . exists ( os . path . join ( basedir , filename ) ) : <TAB><TAB><TAB><TAB> yield filename","if os . path . isdir ( os . path . join ( basedir , filename ) ) :",if os . path . isdir ( filename ) :,69.98230538269817,94.78,False
3640,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
3641,"def _dump ( self , fd ) : <TAB> with self . no_unpicklable_properties ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> d = pickle . dumps ( self ) <TAB><TAB><TAB> module_name = os . path . basename ( sys . argv [ 0 ] ) . rsplit ( "" . "" , 1 ) [ 0 ] <TAB><TAB><TAB> d = d . replace ( b "" c__main__ "" , b "" c "" + module_name . encode ( "" ascii "" ) ) <TAB><TAB><TAB> fd . write ( d ) <TAB><TAB> else : <TAB><TAB><TAB> pickle . dump ( self , fd )","if self . __module__ == ""__main__"" :",if self . _is_python :,95.23881713783582,92.04,False
3642,"def assert_session_stack ( classes ) : <TAB> assert len ( _SklearnTrainingSession . _session_stack ) == len ( classes ) <TAB> for idx , ( sess , ( parent_clazz , clazz ) ) in enumerate ( <TAB><TAB> zip ( _SklearnTrainingSession . _session_stack , classes ) <TAB> ) : <TAB><TAB> assert sess . clazz == clazz <TAB><TAB> <MASK> <TAB><TAB><TAB> assert sess . _parent is None <TAB><TAB> else : <TAB><TAB><TAB> assert sess . _parent . clazz == parent_clazz",if idx == 0 :,if parent_clazz is None :,67.99556365632714,95.43,False
3643,"def native_color ( c ) : <TAB> try : <TAB><TAB> color = CACHE [ c ] <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> c = NAMED_COLOR [ c ] <TAB><TAB> color = Color . FromArgb ( <TAB><TAB><TAB> int ( c . rgba . a * 255 ) , int ( c . rgba . r ) , int ( c . rgba . g ) , int ( c . rgba . b ) <TAB><TAB> ) <TAB><TAB> CACHE [ c ] = color <TAB> return color","if isinstance ( c , str ) :",if c not in NAMED_COLOR :,92.61741640219765,94.90,False
3644,"def callback ( name ) : <TAB> # XXX: move into Action <TAB> for neighbor_name in reactor . configuration . neighbors . keys ( ) : <TAB><TAB> neighbor = reactor . configuration . neighbors . get ( neighbor_name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> neighbor . rib . outgoing . announce_watchdog ( name ) <TAB><TAB> yield False <TAB> reactor . processes . answer_done ( service )",if not neighbor :,if not neighbor :,75.0,100.00,True
3645,"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield DataToken ( read_data ( token , source ) ) <TAB><TAB> elif is_small_integer ( token ) : <TAB><TAB><TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB><TAB> else : <TAB><TAB><TAB> yield Token ( token ) <TAB><TAB> token = source . read_uint8 ( )",if is_push_data_token ( token ) :,if is_data ( token ) :,98.23905109290143,95.70,False
3646,"def setattr ( self , req , ino , attr , to_set , fi ) : <TAB> print ( "" setattr: "" , ino , to_set ) <TAB> a = self . attr [ ino ] <TAB> for key in to_set : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Keep the old file type bit fields <TAB><TAB><TAB> a [ "" st_mode "" ] = S_IFMT ( a [ "" st_mode "" ] ) | S_IMODE ( attr [ "" st_mode "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> a [ key ] = attr [ key ] <TAB> self . attr [ ino ] = a <TAB> self . reply_attr ( req , a , 1.0 )","if key == ""st_mode"" :","if key == ""st_mode"" :",100.0,100.00,True
3647,"def check_enum_exports ( module , eq_callback , only = None ) : <TAB> """"""Make sure module exports all mnemonics from enums"""""" <TAB> for attr in enumerate_module ( module , enum . Enum ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" SKIP "" , attr ) <TAB><TAB><TAB> continue <TAB><TAB> for flag , value in attr . __members__ . items ( ) : <TAB><TAB><TAB> print ( module , flag , value ) <TAB><TAB><TAB> eq_callback ( getattr ( module , flag ) , value )",if only is not None and attr not in only :,if only is not None :,93.2931431152396,95.82,False
3648,"def remove_edit_vars_to ( self , n ) : <TAB> try : <TAB><TAB> removals = [ ] <TAB><TAB> for v , cei in self . edit_var_map . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> removals . append ( v ) <TAB><TAB> for v in removals : <TAB><TAB><TAB> self . remove_edit_var ( v ) <TAB><TAB> assert len ( self . edit_var_map ) == n <TAB> except ConstraintNotFound : <TAB><TAB> raise InternalError ( "" Constraint not found during internal removal "" )",if cei . index >= n :,if cei . name == n :,97.93881339441656,97.80,False
3649,"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB><TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB><TAB><TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> e . value = [ ] <TAB><TAB><TAB><TAB> elif type ( e . value ) is not list : <TAB><TAB><TAB><TAB><TAB> e . value = e . value . split ( ) <TAB><TAB><TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB><TAB><TAB><TAB> e . value = 0 <TAB> return self",if e . value is None :,if e . value is None :,100.0,100.00,True
3650,"def add_I_prefix ( current_line : List [ str ] , ner : int , tag : str ) : <TAB> for i in range ( 0 , len ( current_line ) ) : <TAB><TAB> if i == 0 : <TAB><TAB><TAB> f . write ( line_list [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> f . write ( ""  I- "" + tag ) <TAB><TAB> else : <TAB><TAB><TAB> f . write ( ""   "" + current_line [ i ] ) <TAB> f . write ( "" \n "" )",elif i == ner :,elif i == ner :,100.0,100.00,True
3651,def select_word_at_cursor ( self ) : <TAB> word_region = None <TAB> selection = self . view . sel ( ) <TAB> for region in selection : <TAB><TAB> word_region = self . view . word ( region ) <TAB><TAB> <MASK> <TAB><TAB><TAB> selection . clear ( ) <TAB><TAB><TAB> selection . add ( word_region ) <TAB><TAB><TAB> return word_region <TAB> return word_region,if not word_region . empty ( ) :,if word_region is not None :,64.12526402990039,93.69,False
3652,"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB><TAB> self . clear ( ) <TAB><TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB><TAB> if self . op == "" + "" : <TAB><TAB><TAB> self . current + = num <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current - = num <TAB><TAB> elif self . op == "" * "" : <TAB><TAB><TAB> self . current * = num <TAB><TAB> elif self . op == "" / "" : <TAB><TAB><TAB> self . current / = num <TAB><TAB> self . op = op <TAB> else : <TAB><TAB> self . op = op <TAB><TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB><TAB> self . clear ( ) <TAB> return res","elif self . op == ""-"" :","elif self . op == ""-"" :",100.0,100.00,True
3653,"def strip_pod ( lines ) : <TAB> in_pod = False <TAB> stripped_lines = [ ] <TAB> for line in lines : <TAB><TAB> if re . match ( r "" ^=(?:end|cut) "" , line ) : <TAB><TAB><TAB> in_pod = False <TAB><TAB> elif re . match ( r "" ^= \ w+ "" , line ) : <TAB><TAB><TAB> in_pod = True <TAB><TAB> <MASK> <TAB><TAB><TAB> stripped_lines . append ( line ) <TAB> return stripped_lines",elif not in_pod :,elif in_pod :,82.4287147004677,98.28,False
3654,"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB><TAB> if isinstance ( filename_data , list ) : <TAB><TAB><TAB> filename , data = filename_data <TAB><TAB> else : <TAB><TAB><TAB> filename = filename_data <TAB><TAB><TAB> data = None <TAB><TAB> if not filename . startswith ( os . sep ) : <TAB><TAB><TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB> files . append ( filename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories",if data :,if data is not None :,87.81761524869985,98.03,False
3655,"def loadPerfsFromModule ( self , module ) : <TAB> """"""Return a suite of all perfs cases contained in the given module"""""" <TAB> perfs = [ ] <TAB> for name in dir ( module ) : <TAB><TAB> obj = getattr ( module , name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> perfs . append ( self . loadPerfsFromPerfCase ( obj ) ) <TAB> return self . suiteClass ( perfs )","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :","if issubclass ( obj , PerfsCase ) :",61.53931539983637,87.36,False
3656,"def download_subtitle ( self , subtitle ) : <TAB> if isinstance ( subtitle , XSubsSubtitle ) : <TAB><TAB> # download the subtitle <TAB><TAB> logger . info ( "" Downloading subtitle  %r "" , subtitle ) <TAB><TAB> r = self . session . get ( <TAB><TAB><TAB> subtitle . download_link , headers = { "" Referer "" : subtitle . page_link } , timeout = 10 <TAB><TAB> ) <TAB><TAB> r . raise_for_status ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( "" Unable to download subtitle. No data returned from provider "" ) <TAB><TAB><TAB> return <TAB><TAB> subtitle . content = fix_line_ending ( r . content )",if not r . content :,if r . status_code == 404 :,97.38787659462686,95.35,False
3657,"def get_inlaws ( self , person ) : <TAB> inlaws = [ ] <TAB> family_handles = person . get_family_handle_list ( ) <TAB> for handle in family_handles : <TAB><TAB> fam = self . database . get_family_from_handle ( handle ) <TAB><TAB> if fam . father_handle and not fam . father_handle == person . handle : <TAB><TAB><TAB> inlaws . append ( self . database . get_person_from_handle ( fam . father_handle ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> inlaws . append ( self . database . get_person_from_handle ( fam . mother_handle ) ) <TAB> return inlaws",elif fam . mother_handle and not fam . mother_handle == person . handle :,if fam . mother_handle and not fam . mother_handle == person . handle,67.37572145766744,97.28,False
3658,"def _check_xorg_conf ( ) : <TAB> if is_there_a_default_xorg_conf_file ( ) : <TAB><TAB> print ( <TAB><TAB><TAB> "" WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not "" <TAB><TAB><TAB> ""  create it yourself, it was likely generated by your distribution or by an Nvidia utility. \n "" <TAB><TAB><TAB> "" This file may contain hard-coded GPU configuration that could interfere with optimus-manager, "" <TAB><TAB><TAB> ""  so it is recommended that you delete it before proceeding. \n "" <TAB><TAB><TAB> "" Ignore this warning and proceed with GPU switching ? (y/N) "" <TAB><TAB> ) <TAB><TAB> confirmation = ask_confirmation ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sys . exit ( 0 )",if not confirmation :,if not confirmation :,100.0,100.00,True
3659,"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> methods = "" "" <TAB><TAB> elif isinstance ( methods , ( list , tuple ) ) : <TAB><TAB><TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB><TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( )",if methods == ALL :,if not methods :,76.34401708961677,97.59,False
3660,"def num_of_mapped_volumes ( self , initiator ) : <TAB> cnt = 0 <TAB> for lm_link in self . req ( "" lun-maps "" ) [ "" lun-maps "" ] : <TAB><TAB> idx = lm_link [ "" href "" ] . split ( "" / "" ) [ - 1 ] <TAB><TAB> # NOTE(geguileo): There can be races so mapped elements retrieved <TAB><TAB> # in the listing may no longer exist. <TAB><TAB> try : <TAB><TAB><TAB> lm = self . req ( "" lun-maps "" , idx = int ( idx ) ) [ "" content "" ] <TAB><TAB> except exception . NotFound : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> cnt + = 1 <TAB> return cnt","if lm [ ""ig-name"" ] == initiator :","if lm [ ""initiator"" ] == initiator :",98.95885784912024,98.73,False
3661,"def _setAbsoluteY ( self , value ) : <TAB> if value is None : <TAB><TAB> self . _absoluteY = None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = 10 <TAB><TAB> elif value == "" below "" : <TAB><TAB><TAB> value = - 70 <TAB><TAB> try : <TAB><TAB><TAB> value = common . numToIntOrFloat ( value ) <TAB><TAB> except ValueError as ve : <TAB><TAB><TAB> raise TextFormatException ( <TAB><TAB><TAB><TAB> f "" Not a supported absoluteY position:  { value !r} "" <TAB><TAB><TAB> ) from ve <TAB><TAB> self . _absoluteY = value","if value == ""above"" :","if value == ""below"" :",98.59996198434256,98.63,False
3662,"def render_markdown ( text ) : <TAB> users = { u . username . lower ( ) : u for u in get_mention_users ( text ) } <TAB> parts = MENTION_RE . split ( text ) <TAB> for pos , part in enumerate ( parts ) : <TAB><TAB> if not part . startswith ( "" @ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> username = part [ 1 : ] . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> user = users [ username ] <TAB><TAB><TAB> parts [ pos ] = ' **[ {} ]( {}   "" {} "" )** ' . format ( <TAB><TAB><TAB><TAB> part , user . get_absolute_url ( ) , user . get_visible_name ( ) <TAB><TAB><TAB> ) <TAB> text = "" "" . join ( parts ) <TAB> return mark_safe ( MARKDOWN ( text ) )",if username in users :,if username in users :,100.0,100.00,True
3663,def start_process ( self ) : <TAB> with self . thread_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . allow_process_request = False <TAB><TAB><TAB> t = threading . Thread ( target = self . __start ) <TAB><TAB><TAB> t . daemon = True <TAB><TAB><TAB> t . start ( ),if self . allow_process_request :,if self . allow_process_request :,100.0,100.00,True
3664,"def close ( self ) : <TAB> if self . _fh . closed : <TAB><TAB> return <TAB> self . _fh . close ( ) <TAB> if os . path . isfile ( self . _filename ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> salt . utils . win_dacl . copy_security ( <TAB><TAB><TAB><TAB> source = self . _filename , target = self . _tmp_filename <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> shutil . copymode ( self . _filename , self . _tmp_filename ) <TAB><TAB><TAB> st = os . stat ( self . _filename ) <TAB><TAB><TAB> os . chown ( self . _tmp_filename , st . st_uid , st . st_gid ) <TAB> atomic_rename ( self . _tmp_filename , self . _filename )",if salt . utils . win_dacl . HAS_WIN32 :,if self . _security :,93.54367703728481,94.76,False
3665,"def _splitSchemaNameDotFieldName ( sn_fn , fnRequired = True ) : <TAB> if sn_fn . find ( "" . "" ) != - 1 : <TAB><TAB> schemaName , fieldName = sn_fn . split ( "" . "" , 1 ) <TAB><TAB> schemaName = schemaName . strip ( ) <TAB><TAB> fieldName = fieldName . strip ( ) <TAB><TAB> if schemaName and fieldName : <TAB><TAB><TAB> return ( schemaName , fieldName ) <TAB> elif not fnRequired : <TAB><TAB> schemaName = sn_fn . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( schemaName , None ) <TAB> controlflow . system_error_exit ( <TAB><TAB> 2 , f "" { sn_fn }  is not a valid custom schema.field name. "" <TAB> )",if schemaName :,if schemaName and not schemaName :,98.2055930020987,98.07,False
3666,"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB><TAB> <MASK> <TAB><TAB><TAB> op_list = ( op_list , ) <TAB><TAB> for item in chain ( * op_list ) : <TAB><TAB><TAB> if item is None : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> dictionary = item . dictionary <TAB><TAB><TAB> if dictionary . path in paths : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> paths . add ( dictionary . path ) <TAB><TAB><TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list","if not isinstance ( op_list , list ) :","if not isinstance ( op_list , list ) :",100.0,100.00,True
3667,"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB> if event_ref : <TAB><TAB><TAB><TAB><TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB> if not event . get_place_handle ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB><TAB> if not event . get_date_object ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if family :,if family :,100.0,100.00,True
3668,"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if value is not None : <TAB><TAB><TAB><TAB> value = value == "" true "" <TAB><TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json )","if key in ( ""disabled"" , ""is_up"" ) :","if hasattr ( cleanup_request , key ) :",95.1590652690685,93.89,False
3669,"def get_billable_and_total_duration ( activity , start_time , end_time ) : <TAB> precision = frappe . get_precision ( "" Timesheet Detail "" , "" hours "" ) <TAB> activity_duration = time_diff_in_hours ( end_time , start_time ) <TAB> billing_duration = 0.0 <TAB> if activity . billable : <TAB><TAB> billing_duration = activity . billing_hours <TAB><TAB> <MASK> <TAB><TAB><TAB> billing_duration = ( <TAB><TAB><TAB><TAB> activity_duration * activity . billing_hours / activity . hours <TAB><TAB><TAB> ) <TAB> return flt ( activity_duration , precision ) , flt ( billing_duration , precision )",if activity_duration != activity . billing_hours :,if activity . hours :,81.53575059321818,95.02,False
3670,"def cpus ( self ) : <TAB> try : <TAB><TAB> cpus = ( <TAB><TAB><TAB> self . inspect [ "" Spec "" ] [ "" Resources "" ] [ "" Reservations "" ] [ "" NanoCPUs "" ] / 1000000000.0 <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cpus = int ( cpus ) <TAB><TAB> return cpus <TAB> except TypeError : <TAB><TAB> return None <TAB> except KeyError : <TAB><TAB> return 0",if cpus == int ( cpus ) :,if cpus :,87.3290802150605,93.95,False
3671,"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # get the first key as the convert function <TAB><TAB><TAB> func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB><TAB><TAB> if func_name . startswith ( "" _ "" ) : <TAB><TAB><TAB><TAB> func = getattr ( self , func_name ) <TAB><TAB><TAB><TAB> props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB> if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB><TAB> return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB> else : <TAB><TAB> return props","if isinstance ( prop_value , dict ) and prop_value :","if isinstance ( prop_value , dict ) :",87.95940854520549,97.80,False
3672,"def _yield_unescaped ( self , string ) : <TAB> while "" \\ "" in string : <TAB><TAB> finder = EscapeFinder ( string ) <TAB><TAB> yield finder . before + finder . backslashes <TAB><TAB> <MASK> <TAB><TAB><TAB> yield self . _unescape ( finder . text ) <TAB><TAB> else : <TAB><TAB><TAB> yield finder . text <TAB><TAB> string = finder . after <TAB> yield string",if finder . escaped and finder . text :,if self . _is_escaped ( finder . text ) :,85.07280770370211,91.30,False
3673,"def _check_matches ( rule , matches ) : <TAB> errors = 0 <TAB> for match in matches : <TAB><TAB> filematch = _match_to_test_file ( match ) <TAB><TAB> <MASK> <TAB><TAB><TAB> utils . error ( <TAB><TAB><TAB><TAB> "" The match  ' {} '  for rule  ' {} '  points to a non existing test module path:  {} "" , <TAB><TAB><TAB><TAB> match , <TAB><TAB><TAB><TAB> rule , <TAB><TAB><TAB><TAB> filematch , <TAB><TAB><TAB> ) <TAB><TAB><TAB> errors + = 1 <TAB> return errors",if not filematch . exists ( ) :,if filematch :,66.18842767957767,95.89,False
3674,"def focused_windows ( ) : <TAB> tree = i3 . get_tree ( ) <TAB> workspaces = tree . workspaces ( ) <TAB> for workspace in workspaces : <TAB><TAB> container = workspace <TAB><TAB> while container : <TAB><TAB><TAB> if not hasattr ( container , "" focus "" ) or not container . focus : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> container_id = container . focus [ 0 ] <TAB><TAB><TAB> container = container . find_by_id ( container_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> coname = container . name <TAB><TAB><TAB> wsname = workspace . name <TAB><TAB><TAB> print ( "" WS "" , wsname + "" : "" , coname )",if container :,if container :,100.0,100.00,True
3675,"def normals ( self , value ) : <TAB> if value is not None : <TAB><TAB> value = np . asanyarray ( value , dtype = np . float32 ) <TAB><TAB> value = np . ascontiguousarray ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Incorrect normals shape "" ) <TAB> self . _normals = value",if value . shape != self . positions . shape :,if value . shape != self . _normals . shape :,85.59508053184112,96.31,False
3676,"def test_hexdigest ( self ) : <TAB> for cons in self . hash_constructors : <TAB><TAB> h = cons ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsInstance ( h . digest ( 16 ) , bytes ) <TAB><TAB><TAB> self . assertEqual ( hexstr ( h . digest ( 16 ) ) , h . hexdigest ( 16 ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertIsInstance ( h . digest ( ) , bytes ) <TAB><TAB><TAB> self . assertEqual ( hexstr ( h . digest ( ) ) , h . hexdigest ( ) )",if h . name in self . shakes :,if h . is_hash :,68.71373198017177,95.76,False
3677,"def _get_cluster_status ( self ) : <TAB> try : <TAB><TAB> return ( <TAB><TAB><TAB> self . dataproc_client . projects ( ) <TAB><TAB><TAB> . regions ( ) <TAB><TAB><TAB> . clusters ( ) <TAB><TAB><TAB> . get ( <TAB><TAB><TAB><TAB> projectId = self . gcloud_project_id , <TAB><TAB><TAB><TAB> region = self . dataproc_region , <TAB><TAB><TAB><TAB> clusterName = self . dataproc_cluster_name , <TAB><TAB><TAB><TAB> fields = "" status "" , <TAB><TAB><TAB> ) <TAB><TAB><TAB> . execute ( ) <TAB><TAB> ) <TAB> except HttpError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None # We got a 404 so the cluster doesn't exist <TAB><TAB> else : <TAB><TAB><TAB> raise e",if e . resp . status == 404 :,if e . status == 404 :,80.37928794268889,98.92,False
3678,"def _items_from ( self , context ) : <TAB> self . _context = context <TAB> if self . _is_local_variable ( self . _keyword_name , context ) : <TAB><TAB> for item in self . _items_from_controller ( context ) : <TAB><TAB><TAB> yield item <TAB> else : <TAB><TAB> for df in context . datafiles : <TAB><TAB><TAB> self . _yield_for_other_threads ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for item in self . _items_from_datafile ( df ) : <TAB><TAB><TAB><TAB><TAB> yield item",if self . _items_from_datafile_should_be_checked ( df ) :,"if self . _is_local_variable ( self . _keyword_name , df )",92.13463666095383,92.10,False
3679,"def Command ( argv , funcs , path_val ) : <TAB> arg , i = COMMAND_SPEC . Parse ( argv ) <TAB> status = 0 <TAB> if arg . v : <TAB><TAB> for kind , arg in _ResolveNames ( argv [ i : ] , funcs , path_val ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> status = 1 # nothing printed, but we fail <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # This is for -v, -V is more detailed. <TAB><TAB><TAB><TAB> print ( arg ) <TAB> else : <TAB><TAB> util . warn ( "" *** command without -v not not implemented *** "" ) <TAB><TAB> status = 1 <TAB> return status",if kind is None :,"if kind == ""-v"" :",95.346604830748,96.74,False
3680,"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB><TAB> if isinstance ( node , Preprint ) : <TAB><TAB><TAB> category = "" preprint "" <TAB><TAB> <MASK> <TAB><TAB><TAB> category = "" registration "" <TAB><TAB> else : <TAB><TAB><TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB><TAB> index = index , <TAB><TAB> doc_type = category , <TAB><TAB> id = elastic_document_id , <TAB><TAB> refresh = True , <TAB><TAB> ignore = [ 404 ] , <TAB> )",elif node . is_registration :,"elif isinstance ( node , Registration ) :",95.93664058790114,96.15,False
3681,"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ## Complex-type child. Recurse <TAB><TAB><TAB> content = getDictFromTree ( child ) <TAB><TAB> else : <TAB><TAB><TAB> content = child . text <TAB><TAB> if ret_dict . has_key ( child . tag ) : <TAB><TAB><TAB> if not type ( ret_dict [ child . tag ] ) == list : <TAB><TAB><TAB><TAB> ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB><TAB><TAB> ret_dict [ child . tag ] . append ( content or "" "" ) <TAB><TAB> else : <TAB><TAB><TAB> ret_dict [ child . tag ] = content or "" "" <TAB> return ret_dict",if child . getchildren ( ) :,"if child . tag == ""type"" :",95.53401101502524,96.77,False
3682,"def get ( self , block = True , timeout = None , ack = False ) : <TAB> if not block : <TAB><TAB> return self . get_nowait ( ) <TAB> start_time = time . time ( ) <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> return self . get_nowait ( ack ) <TAB><TAB> except BaseQueue . Empty : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> lasted = time . time ( ) - start_time <TAB><TAB><TAB><TAB> if timeout > lasted : <TAB><TAB><TAB><TAB><TAB> time . sleep ( min ( self . max_timeout , timeout - lasted ) ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> time . sleep ( self . max_timeout )",if timeout :,if timeout :,100.0,100.00,True
3683,"def rewrite ( self , string ) : <TAB> string = super ( JSReplaceFuzzy , self ) . rewrite ( string ) <TAB> cdx = self . url_rewriter . rewrite_opts [ "" cdx "" ] <TAB> if cdx . get ( "" is_fuzzy "" ) : <TAB><TAB> expected = unquote ( cdx [ "" url "" ] ) <TAB><TAB> actual = unquote ( self . url_rewriter . wburl . url ) <TAB><TAB> exp_m = self . rx_obj . search ( expected ) <TAB><TAB> act_m = self . rx_obj . search ( actual ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = string . replace ( exp_m . group ( 1 ) , act_m . group ( 1 ) ) <TAB><TAB><TAB> if result != string : <TAB><TAB><TAB><TAB> string = result <TAB> return string",if exp_m and act_m :,if exp_m :,80.13774109060239,98.03,False
3684,"def locate_exe_dir ( d , check = True ) : <TAB> exe_dir = os . path . join ( d , "" Scripts "" ) if ON_WINDOWS else os . path . join ( d , "" bin "" ) <TAB> if not os . path . isdir ( exe_dir ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> bin_dir = os . path . join ( d , "" bin "" ) <TAB><TAB><TAB> if os . path . isdir ( bin_dir ) : <TAB><TAB><TAB><TAB> return bin_dir <TAB><TAB> if check : <TAB><TAB><TAB> raise InvalidVirtualEnv ( "" Unable to locate executables directory. "" ) <TAB> return exe_dir",if ON_WINDOWS :,if ON_WINDOWS :,100.0,100.00,True
3685,"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB><TAB> s = str ( path ) <TAB><TAB> if ensuremode == "" append "" : <TAB><TAB><TAB> if s not in sys . path : <TAB><TAB><TAB><TAB> sys . path . append ( s ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sys . path . insert ( 0 , s )",if s != sys . path [ 0 ] :,if s not in sys . path :,92.40553407365567,93.74,False
3686,"def create_season_banners ( self , show_obj ) : <TAB> if self . season_banners and show_obj : <TAB><TAB> result = [ ] <TAB><TAB> for season , episodes in show_obj . episodes . iteritems ( ) : # @UnusedVariable <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> logger . log ( <TAB><TAB><TAB><TAB><TAB> u "" Metadata provider  "" <TAB><TAB><TAB><TAB><TAB> + self . name <TAB><TAB><TAB><TAB><TAB> + ""  creating season banners for  "" <TAB><TAB><TAB><TAB><TAB> + show_obj . name , <TAB><TAB><TAB><TAB><TAB> logger . DEBUG , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> result = result + [ self . save_season_banners ( show_obj , season ) ] <TAB><TAB> return all ( result ) <TAB> return False","if not self . _has_season_banner ( show_obj , season ) :","if not self . _is_season_banners_available ( show_obj , season",97.26145230232073,96.80,False
3687,"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB><TAB> if "" nbgrader "" not in cell . metadata : <TAB><TAB><TAB> continue <TAB><TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB><TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB><TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB><TAB> if grade_id in ids : <TAB><TAB><TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB><TAB> ids . add ( grade_id )",if not grade and not solution and not locked :,if not grade or solution != locked :,94.77819561988302,97.39,False
3688,"def read_version ( ) : <TAB> regexp = re . compile ( r "" ^__version__ \ W*= \ W* ' ([ \ d.abrc]+) ' "" ) <TAB> init_py = os . path . join ( os . path . dirname ( __file__ ) , "" aiopg "" , "" __init__.py "" ) <TAB> with open ( init_py ) as f : <TAB><TAB> for line in f : <TAB><TAB><TAB> match = regexp . match ( line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return match . group ( 1 ) <TAB><TAB> else : <TAB><TAB><TAB> raise RuntimeError ( "" Cannot find version in aiopg/__init__.py "" )",if match is not None :,if match :,90.24283103176198,97.67,False
3689,"def _column_keys ( self ) : <TAB> """"""Get a dictionary of all columns and their case mapping."""""" <TAB> if not self . exists : <TAB><TAB> return { } <TAB> with self . db . lock : <TAB><TAB> if self . _columns is None : <TAB><TAB><TAB> # Initialise the table if it doesn't exist <TAB><TAB><TAB> table = self . table <TAB><TAB><TAB> self . _columns = { } <TAB><TAB><TAB> for column in table . columns : <TAB><TAB><TAB><TAB> name = normalize_column_name ( column . name ) <TAB><TAB><TAB><TAB> key = normalize_column_key ( name ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> log . warning ( "" Duplicate column:  %s "" , name ) <TAB><TAB><TAB><TAB> self . _columns [ key ] = name <TAB><TAB> return self . _columns",if key in self . _columns :,if key in self . _columns :,100.0,100.00,True
3690,"def find_controller_by_names ( self , names , testname ) : <TAB> namestring = "" . "" . join ( names ) <TAB> if not namestring . startswith ( self . name ) : <TAB><TAB> return None <TAB> if namestring == self . name : <TAB><TAB> return self <TAB> for suite in self . suites : <TAB><TAB> res = suite . find_controller_by_names ( <TAB><TAB><TAB> namestring [ len ( self . name ) + 1 : ] . split ( "" . "" ) , testname <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return res",if res :,if res :,100.0,100.00,True
3691,"def _volume_x_metadata_get_item ( <TAB> context , volume_id , key , model , notfound_exec , session = None ) : <TAB> result = ( <TAB><TAB> _volume_x_metadata_get_query ( context , volume_id , model , session = session ) <TAB><TAB> . filter_by ( key = key ) <TAB><TAB> . first ( ) <TAB> ) <TAB> if not result : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise notfound_exec ( id = volume_id ) <TAB><TAB> else : <TAB><TAB><TAB> raise notfound_exec ( metadata_key = key , volume_id = volume_id ) <TAB> return result",if model is models . VolumeGlanceMetadata :,"if key == ""id"" :",79.40605617860605,95.79,False
3692,"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB><TAB> dd = tup [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB><TAB><TAB><TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB><TAB><TAB><TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB><TAB> if "" hyper_parameters "" in key : <TAB><TAB><TAB> print ( key + "" :  "" + str ( value ) )","if ""results.train_y_misclass"" in dd :","if ""results.train_y_misclass"" in dd :",100.0,100.00,True
3693,"def _stop_by_max_time_mins ( self ) : <TAB> """"""Stop optimization process once maximum minutes have elapsed."""""" <TAB> if self . max_time_mins : <TAB><TAB> total_mins_elapsed = ( <TAB><TAB><TAB> datetime . now ( ) - self . _start_datetime <TAB><TAB> ) . total_seconds ( ) / 60.0 <TAB><TAB> <MASK> <TAB><TAB><TAB> raise KeyboardInterrupt ( <TAB><TAB><TAB><TAB> "" {:.2f}  minutes have elapsed. TPOT will close down. "" . format ( <TAB><TAB><TAB><TAB><TAB> total_mins_elapsed <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",if total_mins_elapsed >= self . max_time_mins :,if total_mins_elapsed > self . max_time_mins :,98.29526610378261,98.75,False
3694,"def __new__ ( meta , cls_name , bases , cls_dict ) : <TAB> func = cls_dict . get ( "" func "" ) <TAB> monad_cls = super ( FuncMonadMeta , meta ) . __new__ ( meta , cls_name , bases , cls_dict ) <TAB> if func : <TAB><TAB> <MASK> <TAB><TAB><TAB> functions = func <TAB><TAB> else : <TAB><TAB><TAB> functions = ( func , ) <TAB><TAB> for func in functions : <TAB><TAB><TAB> registered_functions [ func ] = monad_cls <TAB> return monad_cls",if type ( func ) is tuple :,"if isinstance ( func , ( list , tuple ) ) :",92.17355989734864,93.63,False
3695,"def get_tokens_unprocessed ( self , text ) : <TAB> buffered = "" "" <TAB> insertions = [ ] <TAB> lng_buffer = [ ] <TAB> for i , t , v in self . language_lexer . get_tokens_unprocessed ( text ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if lng_buffer : <TAB><TAB><TAB><TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB><TAB><TAB><TAB> lng_buffer = [ ] <TAB><TAB><TAB> buffered + = v <TAB><TAB> else : <TAB><TAB><TAB> lng_buffer . append ( ( i , t , v ) ) <TAB> if lng_buffer : <TAB><TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB> return do_insertions ( insertions , self . root_lexer . get_tokens_unprocessed ( buffered ) )",if t is self . needle :,"if t == ""END"" :",83.74472528486211,97.16,False
3696,"def get_conditions ( filters ) : <TAB> conditions = { "" docstatus "" : ( "" = "" , 1 ) } <TAB> if filters . get ( "" from_date "" ) and filters . get ( "" to_date "" ) : <TAB><TAB> conditions [ "" result_date "" ] = ( <TAB><TAB><TAB> "" between "" , <TAB><TAB><TAB> ( filters . get ( "" from_date "" ) , filters . get ( "" to_date "" ) ) , <TAB><TAB> ) <TAB><TAB> filters . pop ( "" from_date "" ) <TAB><TAB> filters . pop ( "" to_date "" ) <TAB> for key , value in filters . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> conditions [ key ] = value <TAB> return conditions",if filters . get ( key ) :,if value :,91.65665738399943,96.22,False
3697,"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB> # auto handle datetime <TAB><TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if ( datetime . now ( ) - limit ) > value : <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) - limit <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if ( datetime . now ( ) + limit ) < value : <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) + limit <TAB><TAB> elif value > limit : <TAB><TAB><TAB> value = limit <TAB> return value","if config [ key ] [ ""inverse"" ] is True :",if value . tzinfo is None :,96.05344322403995,94.84,False
3698,"def GetCurrentKeySet ( self ) : <TAB> "" Return CurrentKeys with  ' darwin '  modifications. "" <TAB> result = self . GetKeySet ( self . CurrentKeys ( ) ) <TAB> if sys . platform == "" darwin "" : <TAB><TAB> # macOS (OS X) Tk variants do not support the ""Alt"" <TAB><TAB> # keyboard modifier.  Replace it with ""Option"". <TAB><TAB> # TODO (Ned?): the ""Option"" modifier does not work properly <TAB><TAB> #     for Cocoa Tk and XQuartz Tk so we should not use it <TAB><TAB> #     in the default 'OSX' keyset. <TAB><TAB> for k , v in result . items ( ) : <TAB><TAB><TAB> v2 = [ x . replace ( "" <Alt- "" , "" <Option- "" ) for x in v ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ k ] = v2 <TAB> return result",if v != v2 :,if v2 :,98.76032635680288,97.98,False
3699,"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB><TAB> package = _normalize_module ( package , 3 ) <TAB><TAB> filename = _module_relative_path ( package , filename ) <TAB><TAB> if hasattr ( package , "" __loader__ "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB><TAB><TAB><TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB><TAB><TAB><TAB> # conversion as universal newlines would do. <TAB><TAB><TAB><TAB> return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB> return open ( filename ) . read ( ) , filename","if hasattr ( package . __loader__ , ""get_data"" ) :","if hasattr ( package . __loader__ , ""get_data"" ) :",100.0,100.00,True
3700,"def iter_from_X_lengths ( X , lengths ) : <TAB> if lengths is None : <TAB><TAB> yield 0 , len ( X ) <TAB> else : <TAB><TAB> n_samples = X . shape [ 0 ] <TAB><TAB> end = np . cumsum ( lengths ) . astype ( np . int32 ) <TAB><TAB> start = end - lengths <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" more than  {:d}  samples in lengths array  {!s} "" . format ( <TAB><TAB><TAB><TAB><TAB> n_samples , lengths <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> for i in range ( len ( lengths ) ) : <TAB><TAB><TAB> yield start [ i ] , end [ i ]",if end [ - 1 ] > n_samples :,if n_samples > n_samples :,71.47772940815103,97.12,False
3701,"def change_sel ( self ) : <TAB> """"""Change the view's selections."""""" <TAB> if self . alter_select and len ( self . sels ) > 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . view . show ( self . sels [ 0 ] ) <TAB><TAB> self . view . sel ( ) . clear ( ) <TAB><TAB> self . view . sel ( ) . add_all ( self . sels )",if self . multi_select is False :,if self . view . is_visible ( ) :,68.49240496003976,93.16,False
3702,"def cb_syncthing_device_data_changed ( <TAB> self , daemon , nid , address , client_version , inbps , outbps , inbytes , outbytes ) : <TAB> if nid in self . devices : # Should be always <TAB><TAB> device = self . devices [ nid ] <TAB><TAB> # Update strings <TAB><TAB> device [ "" address "" ] = address <TAB><TAB> <MASK> <TAB><TAB><TAB> device [ "" version "" ] = client_version <TAB><TAB> # Update rates <TAB><TAB> device [ "" inbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( inbps ) , sizeof_fmt ( inbytes ) ) <TAB><TAB> device [ "" outbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( outbps ) , sizeof_fmt ( outbytes ) )","if client_version not in ( ""?"" , None ) :",if client_version :,96.38133238830578,94.95,False
3703,"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB><TAB> ret = [ ] <TAB><TAB> when_response = list ( when_response ) <TAB><TAB> for match in when_response : <TAB><TAB><TAB> if match not in matches : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> match . name = self . match_name <TAB><TAB><TAB><TAB> matches . append ( match ) <TAB><TAB><TAB><TAB> ret . append ( match ) <TAB><TAB> return ret <TAB> <MASK> <TAB><TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB><TAB> matches . append ( when_response ) <TAB><TAB> return when_response",if self . match_name :,if self . match_name :,100.0,100.00,True
3704,"def __update_parents ( self , fileobj , path , delta ) : <TAB> """"""Update all parent atoms with the new size."""""" <TAB> if delta == 0 : <TAB><TAB> return <TAB> for atom in path : <TAB><TAB> fileobj . seek ( atom . offset ) <TAB><TAB> size = cdata . uint_be ( fileobj . read ( 4 ) ) <TAB><TAB> <MASK> # 64bit <TAB><TAB><TAB> # skip name (4B) and read size (8B) <TAB><TAB><TAB> size = cdata . ulonglong_be ( fileobj . read ( 12 ) [ 4 : ] ) <TAB><TAB><TAB> fileobj . seek ( atom . offset + 8 ) <TAB><TAB><TAB> fileobj . write ( cdata . to_ulonglong_be ( size + delta ) ) <TAB><TAB> else : # 32bit <TAB><TAB><TAB> fileobj . seek ( atom . offset ) <TAB><TAB><TAB> fileobj . write ( cdata . to_uint_be ( size + delta ) )",if size == 1 :,if size == 0 :,99.13869934747828,99.01,False
3705,"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB><TAB> if field . primary_key : <TAB><TAB><TAB> continue <TAB><TAB> requires_index = any ( <TAB><TAB><TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fields . append ( field ) <TAB> return fields",if requires_index :,if requires_index :,100.0,100.00,True
3706,"def __init__ ( self , value ) : <TAB> """"""Initialize the integer to the given value."""""" <TAB> self . _mpz_p = new_mpz ( ) <TAB> self . _initialized = False <TAB> if isinstance ( value , float ) : <TAB><TAB> raise ValueError ( "" A floating point type is not a natural number "" ) <TAB> self . _initialized = True <TAB> if isinstance ( value , ( int , long ) ) : <TAB><TAB> _gmp . mpz_init ( self . _mpz_p ) <TAB><TAB> result = _gmp . gmp_sscanf ( tobytes ( str ( value ) ) , b ( "" % Zd "" ) , self . _mpz_p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Error converting  ' %d ' "" % value ) <TAB> else : <TAB><TAB> _gmp . mpz_init_set ( self . _mpz_p , value . _mpz_p )",if result != 1 :,if result != 0 :,99.14012833224068,98.93,False
3707,"def decode ( cls , data ) : <TAB> while data : <TAB><TAB> length , format_type , control_flags , sequence , pid = unpack ( <TAB><TAB><TAB> cls . Header . PACK , data [ : cls . Header . LEN ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise NetLinkError ( "" Buffer underrun "" ) <TAB><TAB> yield cls . format ( <TAB><TAB><TAB> format_type , control_flags , sequence , pid , data [ cls . Header . LEN : length ] <TAB><TAB> ) <TAB><TAB> data = data [ length : ]",if len ( data ) < length :,if length == 0 :,68.82073304656082,95.42,False
3708,"def __post_init__ ( self ) : <TAB> if self . _node_id is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" invalid node_id:  {} "" . format ( hexlify ( self . _node_id ) . decode ( ) ) <TAB><TAB><TAB> ) <TAB> if self . udp_port is not None and not 1 < = self . udp_port < = 65535 : <TAB><TAB> raise ValueError ( "" invalid udp port "" ) <TAB> if self . tcp_port is not None and not 1 < = self . tcp_port < = 65535 : <TAB><TAB> raise ValueError ( "" invalid tcp port "" ) <TAB> if not is_valid_public_ipv4 ( self . address , self . allow_localhost ) : <TAB><TAB> raise ValueError ( f "" invalid ip address:  ' { self . address } ' "" )",if not len ( self . _node_id ) == constants . HASH_LENGTH :,if not is_valid_node_id ( self . _node_id ) :,95.33106488175582,95.50,False
3709,"def orderUp ( self , items ) : <TAB> sel = [ ] # new selection <TAB> undoinfo = [ ] <TAB> for bid , lid in items : <TAB><TAB> if isinstance ( lid , int ) : <TAB><TAB><TAB> undoinfo . append ( self . orderUpLineUndo ( bid , lid ) ) <TAB><TAB><TAB> sel . append ( ( bid , lid - 1 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> undoinfo . append ( self . orderUpBlockUndo ( bid ) ) <TAB><TAB><TAB> if bid == 0 : <TAB><TAB><TAB><TAB> return items <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> sel . append ( ( bid - 1 , None ) ) <TAB> self . addUndo ( undoinfo , "" Move Up "" ) <TAB> return sel",elif lid is None :,"elif isinstance ( bid , int ) :",72.31111532368773,96.38,False
3710,"def filter_data ( self , min_len , max_len ) : <TAB> logging . info ( f "" filtering data, min len:  { min_len } , max len:  { max_len } "" ) <TAB> initial_len = len ( self . src ) <TAB> filtered_src = [ ] <TAB> filtered_tgt = [ ] <TAB> for src , tgt in zip ( self . src , self . tgt ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> filtered_src . append ( src ) <TAB><TAB><TAB> filtered_tgt . append ( tgt ) <TAB> self . src = filtered_src <TAB> self . tgt = filtered_tgt <TAB> filtered_len = len ( self . src ) <TAB> logging . info ( f "" pairs before:  { initial_len } , after:  { filtered_len } "" )",if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,if src < min_len and tgt < max_len :,80.3611066679984,89.01,False
3711,"def layer_pretrained ( self , net , args , options ) : <TAB> model = getattr ( torchvision . models , args [ 0 ] ) ( pretrained = True ) <TAB> model . train ( True ) <TAB> if options . layer : <TAB><TAB> layers = list ( model . children ( ) ) [ : options . layer ] <TAB><TAB> <MASK> <TAB><TAB><TAB> layers [ - 1 ] = nn . Sequential ( * layers [ - 1 ] [ : options . sublayer ] ) <TAB> else : <TAB><TAB> layers = [ model ] <TAB><TAB> print ( "" List of pretrained layers: "" , layers ) <TAB><TAB> raise ValidationException ( <TAB><TAB><TAB> "" layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above. "" <TAB><TAB> ) <TAB> return nn . Sequential ( * layers )",if options . sublayer :,if options . sublayer :,100.0,100.00,True
3712,"def deleteCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] ) <TAB> for user in users : <TAB><TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> gapi . call ( cal . calendarList ( ) , "" delete "" , soft_errors = True , calendarId = calendarId )",if not cal :,if not cal :,100.0,100.00,True
3713,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB><TAB> clients = self . get_clients ( clients_filter ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB><TAB> try : <TAB><TAB><TAB> module = self . get_module ( module_name ) <TAB><TAB> except PupyModuleDisabled : <TAB><TAB><TAB> continue <TAB><TAB> if clients is not None : <TAB><TAB><TAB> for client in clients : <TAB><TAB><TAB><TAB> if module . is_compatible_with ( client ) : <TAB><TAB><TAB><TAB><TAB> yield module <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> yield module",if not clients :,if not clients :,100.0,100.00,True
3714,"def update_me ( self ) : <TAB> try : <TAB><TAB> while 1 : <TAB><TAB><TAB> line = self . queue . get_nowait ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . delete ( 1.0 , tk . END ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . insert ( tk . END , str ( line ) ) <TAB><TAB><TAB> self . see ( tk . END ) <TAB><TAB><TAB> self . update_idletasks ( ) <TAB> except queue . Empty : <TAB><TAB> pass <TAB> self . after ( 100 , self . update_me )",if line is None :,if line is None :,100.0,100.00,True
3715,"def request_power_state ( self , state , force = False ) : <TAB> if self . current_state != state or force : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . request_in_progress = True <TAB><TAB><TAB> logging . info ( "" Requesting  %s "" % state ) <TAB><TAB><TAB> cb = PowerManager . Callback ( self , state ) <TAB><TAB><TAB> rets = self . parent . Plugins . run ( <TAB><TAB><TAB><TAB> "" on_power_state_change_requested "" , self , state , cb <TAB><TAB><TAB> ) <TAB><TAB><TAB> cb . num_cb = len ( rets ) <TAB><TAB><TAB> cb . check ( ) <TAB><TAB> else : <TAB><TAB><TAB> logging . info ( "" Another request in progress "" )",if not self . request_in_progress :,if self . parent :,93.35762562769855,96.05,False
3716,"def __getitem__ ( self , idx ) : <TAB> super ( BatchDataset , self ) . __getitem__ ( idx ) <TAB> maxidx = len ( self . dataset ) <TAB> samples = [ ] <TAB> for i in range ( 0 , self . batchsize ) : <TAB><TAB> j = idx * self . batchsize + i <TAB><TAB> if j > = maxidx : <TAB><TAB><TAB> break <TAB><TAB> j = self . perm ( j , maxidx ) <TAB><TAB> sample = self . dataset [ j ] <TAB><TAB> <MASK> <TAB><TAB><TAB> samples . append ( sample ) <TAB> samples = self . makebatch ( samples ) <TAB> return samples",if self . filter ( sample ) :,if self . batchsize == self . batchsize :,71.10093541614674,95.72,False
3717,"def __call__ ( self , request , * args , * * kwargs ) : <TAB> template_vars = { } <TAB> for form_name , form_class in self . forms . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> template_vars [ form_name ] = form_class ( request ) <TAB><TAB> else : <TAB><TAB><TAB> template_vars [ form_name ] = None <TAB> if request . method == "" POST "" : <TAB><TAB> action = self . find_post_handler_action ( request ) <TAB><TAB> form = self . handlers [ action ] ( request , data = request . POST , files = request . FILES ) <TAB><TAB> template_vars . update ( form . dispatch ( action , request , * args , * * kwargs ) ) <TAB> return self . GET ( template_vars , request , * args , * * kwargs )","if form_class . must_display ( request , * args , ** kwargs ) :",if form_name in request . POST :,92.02212348329392,93.08,False
3718,"def on_show_all ( self , widget , another ) : <TAB> if widget . get_active ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . treeview . update_items ( all = True , comment = True ) <TAB><TAB> else : <TAB><TAB><TAB> self . treeview . update_items ( all = True ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . treeview . update_items ( comment = True ) <TAB><TAB> else : <TAB><TAB><TAB> self . treeview . update_items ( )",if another . get_active ( ) :,if another . get_active ( ) :,75.0,100.00,True
3719,"def close ( self ) : <TAB> if self . _closed : <TAB><TAB> return <TAB> self . _closed = True <TAB> for proto in self . _pipes . values ( ) : <TAB><TAB> if proto is None : <TAB><TAB><TAB> continue <TAB><TAB> proto . pipe . close ( ) <TAB> if ( <TAB><TAB> self . _proc is not None <TAB><TAB> and <TAB><TAB> # has the child process finished? <TAB><TAB> self . _returncode is None <TAB><TAB> and <TAB><TAB> # the child process has finished, but the <TAB><TAB> # transport hasn't been notified yet? <TAB><TAB> self . _proc . poll ( ) is None <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( "" Close running child process: kill  %r "" , self ) <TAB><TAB> try : <TAB><TAB><TAB> self . _proc . kill ( ) <TAB><TAB> except ProcessLookupError : <TAB><TAB><TAB> pass",if self . _loop . get_debug ( ) :,if self . _debug :,97.84192709760605,97.05,False
3720,"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB><TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB><TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB><TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB><TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB><TAB> if fish is bomb : <TAB><TAB><TAB> bomb_count + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB> else : <TAB><TAB><TAB> fish . click ( ) <TAB><TAB> time . sleep ( 2.5 )",if bomb_count > 3 :,if bomb_count == 0 :,73.71075713253569,98.09,False
3721,"def load_managers ( * , loop , only ) : <TAB> managers = { } <TAB> for key in DB_CLASSES : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> params = DB_DEFAULTS . get ( key ) or { } <TAB><TAB> params . update ( DB_OVERRIDES . get ( key ) or { } ) <TAB><TAB> database = DB_CLASSES [ key ] ( * * params ) <TAB><TAB> managers [ key ] = peewee_async . Manager ( database , loop = loop ) <TAB> return managers",if only and key not in only :,if only and key in only :,98.41565739248772,98.20,False
3722,"def links_extracted ( self , request , links ) : <TAB> for link in links : <TAB><TAB> <MASK> <TAB><TAB><TAB> r = self . _create_request ( link . url ) <TAB><TAB><TAB> r . meta [ b "" depth "" ] = request . meta [ b "" depth "" ] + 1 <TAB><TAB><TAB> self . schedule ( r , self . _get_score ( r . meta [ b "" depth "" ] ) ) <TAB><TAB><TAB> link . meta [ b "" state "" ] = States . QUEUED","if link . meta [ b""state"" ] == States . NOT_CRAWLED :","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",100.0,100.00,True
3723,"def find_worktree_git_dir ( dotgit ) : <TAB> """"""Search for a gitdir for this worktree."""""" <TAB> try : <TAB><TAB> statbuf = os . stat ( dotgit ) <TAB> except OSError : <TAB><TAB> return None <TAB> if not stat . S_ISREG ( statbuf . st_mode ) : <TAB><TAB> return None <TAB> try : <TAB><TAB> lines = open ( dotgit , "" r "" ) . readlines ( ) <TAB><TAB> for key , value in [ line . strip ( ) . split ( "" :  "" ) for line in lines ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return value <TAB> except ValueError : <TAB><TAB> pass <TAB> return None","if key == ""gitdir"" :","if key == ""git_dir"" :",98.85397934501839,97.66,False
3724,"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB><TAB> return False <TAB> for dim_value in shape : <TAB><TAB> if not isinstance ( dim_value , int ) : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True",if dim_value < 0 :,if dim_value < 0 :,75.0,100.00,True
3725,"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB><TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB><TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB><TAB> if handler_id not in used_handlers : <TAB><TAB><TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = handler [ "" filename "" ] <TAB><TAB><TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB><TAB><TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config )","elif ""filename"" in handler . keys ( ) :","if ""filename"" in handler :",95.61755657942948,96.89,False
3726,"def __call__ ( self ) : <TAB> dmin , dmax = self . viewlim_to_dt ( ) <TAB> ymin = self . base . le ( dmin . year ) <TAB> ymax = self . base . ge ( dmax . year ) <TAB> ticks = [ dmin . replace ( year = ymin , * * self . replaced ) ] <TAB> while 1 : <TAB><TAB> dt = ticks [ - 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return date2num ( ticks ) <TAB><TAB> year = dt . year + self . base . get_base ( ) <TAB><TAB> ticks . append ( dt . replace ( year = year , * * self . replaced ) )",if dt . year >= ymax :,if dt . year == ymax :,98.95312748519429,98.51,False
3727,"def taiga ( request , trigger_id , key ) : <TAB> signature = request . META . get ( "" HTTP_X_TAIGA_WEBHOOK_SIGNATURE "" ) <TAB> # check that the data are ok with the provided signature <TAB> if verify_signature ( request . _request . body , key , signature ) : <TAB><TAB> data = data_filter ( trigger_id , * * request . data ) <TAB><TAB> status = save_data ( trigger_id , data ) <TAB><TAB> return ( <TAB><TAB><TAB> Response ( { "" message "" : "" Success "" } ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else Response ( { "" message "" : "" Failed! "" } ) <TAB><TAB> ) <TAB> Response ( { "" message "" : "" Bad request "" } )",if status,if status,100.0,100.00,True
3728,"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB><TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB><TAB> if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB><TAB><TAB> homedir = response . pathspec . path <TAB><TAB><TAB> username = os . path . basename ( homedir ) <TAB><TAB><TAB> if username not in self . _ignore_users : <TAB><TAB><TAB><TAB> yield rdf_client . User ( username = username , homedir = homedir )","if not isinstance ( response , rdf_client_fs . StatEntry ) :","if not isinstance ( response , rdfvalue . RDFValue ) :",98.44724316857486,96.44,False
3729,"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB><TAB> path . responses . append ( response ) <TAB><TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB><TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB><TAB> if not src : <TAB><TAB><TAB> break <TAB><TAB> n + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB><TAB><TAB> break <TAB><TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB><TAB> response = requests . get ( src , stream = True )",if n > max_next :,if n > max_next :,100.0,100.00,True
3730,"def __enter__ ( self ) : <TAB> """"""Open a file and read it."""""" <TAB> if self . code is None : <TAB><TAB> LOGGER . info ( "" File is reading:  %s "" , self . path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _file = open ( self . path , encoding = "" utf-8 "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . _file = open ( self . path , "" rU "" ) <TAB><TAB> self . code = self . _file . read ( ) <TAB> return self","if sys . version_info >= ( 3 , ) :","if sys . version_info >= ( 3 , 0 ) :",96.57910434272684,98.42,False
3731,"def facts_for_oauthclients ( self , namespace ) : <TAB> """"""Gathers facts for oauthclients used with logging"""""" <TAB> self . default_keys_for ( "" oauthclients "" ) <TAB> a_list = self . oc_command ( <TAB><TAB> "" get "" , "" oauthclients "" , namespace = namespace , add_options = [ "" -l "" , LOGGING_SELECTOR ] <TAB> ) <TAB> if len ( a_list [ "" items "" ] ) == 0 : <TAB><TAB> return <TAB> for item in a_list [ "" items "" ] : <TAB><TAB> name = item [ "" metadata "" ] [ "" name "" ] <TAB><TAB> comp = self . comp ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = dict ( redirectURIs = item [ "" redirectURIs "" ] ) <TAB><TAB><TAB> self . add_facts_for ( comp , "" oauthclients "" , name , result )",if comp is not None :,if comp :,79.06974563412497,97.99,False
3732,"def get ( self , k ) : <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _data1 [ k ] = self . _data2 [ k ] <TAB><TAB><TAB> del self . _data2 [ k ] <TAB> return self . _data1 . get ( k )",if k not in self . _data1 and k in self . _data2 :,if k in self . _data1 and self . _data2 [ k ] :,91.06468781257446,92.77,False
3733,"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB><TAB> s = s [ 1 : ] <TAB><TAB> end = s . find ( "" ; "" ) <TAB><TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB><TAB><TAB> end = s . find ( "" ; "" , end + 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> end = len ( s ) <TAB><TAB> f = s [ : end ] <TAB><TAB> if "" = "" in f : <TAB><TAB><TAB> i = f . index ( "" = "" ) <TAB><TAB><TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB><TAB> plist . append ( f . strip ( ) ) <TAB><TAB> s = s [ end : ] <TAB> return plist",if end < 0 :,if end < 0 :,100.0,100.00,True
3734,"def __init__ ( self , * * params ) : <TAB> if "" length "" in params : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" Supply either length or start and end to Player not both "" ) <TAB><TAB> params [ "" start "" ] = 0 <TAB><TAB> params [ "" end "" ] = params . pop ( "" length "" ) - 1 <TAB> elif params . get ( "" start "" , 0 ) > 0 and not "" value "" in params : <TAB><TAB> params [ "" value "" ] = params [ "" start "" ] <TAB> super ( Player , self ) . __init__ ( * * params )","if ""start"" in params or ""end"" in params :","if params . get ( ""start"" , 0 ) != params [ ""length"" ] :",93.70754738502139,90.22,False
3735,"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB><TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB><TAB> if str ( libcxx ) == "" libstdc++ "" : <TAB><TAB><TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" ""","elif str ( libcxx ) == ""libstdc++11"" :","if str ( libcxx ) == ""libstdc++"" :",96.60519659851686,96.79,False
3736,"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB><TAB> if tag . has_sort : <TAB><TAB><TAB> if tag . user : <TAB><TAB><TAB><TAB> tts [ name ] = "" %s sort "" % name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts",if tag . internal :,elif tag . user_id :,79.69436675368738,95.44,False
3737,"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB><TAB> if value . has_form ( "" List "" , None ) : <TAB><TAB><TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB> if any ( item is None for item in value ) : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> return value <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> else : <TAB><TAB> value = extract_pyreal ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> return value",if value is None or isinf ( value ) or isnan ( value ) :,if value is None :,89.80052040245177,95.01,False
3738,"def on_action_chosen ( self , id , action , mark_changed = True ) : <TAB> before = self . set_action ( self . current , id , action ) <TAB> if mark_changed : <TAB><TAB> <MASK> <TAB><TAB><TAB> # TODO: Maybe better comparison <TAB><TAB><TAB> self . undo . append ( UndoRedo ( id , before , action ) ) <TAB><TAB><TAB> self . builder . get_object ( "" btUndo "" ) . set_sensitive ( True ) <TAB><TAB> self . on_profile_modified ( ) <TAB> else : <TAB><TAB> self . on_profile_modified ( update_ui = False ) <TAB> return before",if before . to_string ( ) != action . to_string ( ) :,if self . current == id :,75.67642222422069,90.52,False
3739,"def setUp ( self ) : <TAB> super ( OperaterTest , self ) . setUp ( ) <TAB> if is_cli : <TAB><TAB> import clr <TAB><TAB> self . load_iron_python_test ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> clr . AddReference ( "" System.Drawing.Primitives "" ) <TAB><TAB> else : <TAB><TAB><TAB> clr . AddReference ( "" System.Drawing "" )",if is_netcoreapp :,if self . use_primitives :,69.47333659387792,94.37,False
3740,"def field_to_field_type ( field ) : <TAB> field_type = field [ "" type "" ] <TAB> if isinstance ( field_type , dict ) : <TAB><TAB> field_type = field_type [ "" type "" ] <TAB> if isinstance ( field_type , list ) : <TAB><TAB> field_type_length = len ( field_type ) <TAB><TAB> if field_type_length == 0 : <TAB><TAB><TAB> raise Exception ( "" Zero-length type list encountered, invalid CWL? "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> field_type = field_type [ 0 ] <TAB> return field_type",elif len ( field_type ) == 1 :,if field_type_length == 1 :,73.23863399949961,95.81,False
3741,"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB><TAB> for item in args : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ahs . add ( item ) <TAB><TAB><TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB><TAB><TAB><TAB> for ah in item : <TAB><TAB><TAB><TAB><TAB> if type ( ah ) is not ActionHandle : # pragma:nocover <TAB><TAB><TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB><TAB><TAB><TAB><TAB> ahs . add ( ah ) <TAB><TAB><TAB> else : # pragma:nocover <TAB><TAB><TAB><TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs",if type ( item ) is ActionHandle :,if type ( item ) is ActionHandle :,100.0,100.00,True
3742,"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> configTokens = black . configure . items [ "" configTokens "" ] . Get ( ) <TAB> buildFlavour = black . configure . items [ "" buildFlavour "" ] . Get ( ) <TAB> if buildFlavour == "" full "" : <TAB><TAB> self . value = False <TAB> else : <TAB><TAB> self . value = True <TAB> for opt , optarg in self . chosenOptions : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not self . value : <TAB><TAB><TAB><TAB> configTokens . append ( "" tests "" ) <TAB><TAB><TAB> self . value = True <TAB><TAB> elif opt == "" --without-tests "" : <TAB><TAB><TAB> if self . value : <TAB><TAB><TAB><TAB> configTokens . append ( "" notests "" ) <TAB><TAB><TAB> self . value = False <TAB> self . determined = 1","if opt == ""--with-tests"" :","if opt == ""--tests"" :",99.11773032198634,98.94,False
3743,"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rval = composite_name <TAB><TAB><TAB> if composite_file . description : <TAB><TAB><TAB><TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB><TAB><TAB> if composite_file . optional : <TAB><TAB><TAB><TAB> rval = "" %s  [optional] "" % rval <TAB><TAB><TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB><TAB> return "" Extra primary file "" <TAB> return None",if i == index :,if i == index :,100.0,100.00,True
3744,"def func ( x , y ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> z = x + 2 * math . sin ( y ) <TAB><TAB><TAB> return z * * 2 <TAB><TAB> elif x == y : <TAB><TAB><TAB> return 4 <TAB><TAB> else : <TAB><TAB><TAB> return 2 * * 3 <TAB> except ValueError : <TAB><TAB> foo = 0 <TAB><TAB> for i in range ( 4 ) : <TAB><TAB><TAB> foo + = i <TAB><TAB> return foo <TAB> except TypeError : <TAB><TAB> return 42 <TAB> else : <TAB><TAB> return 33 <TAB> finally : <TAB><TAB> print ( "" finished "" )",if x > y :,if x < y :,98.7706363188757,98.72,False
3745,"def test_suite ( ) : <TAB> suite = unittest . TestSuite ( ) <TAB> for fn in os . listdir ( here ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> modname = "" distutils.tests. "" + fn [ : - 3 ] <TAB><TAB><TAB> __import__ ( modname ) <TAB><TAB><TAB> module = sys . modules [ modname ] <TAB><TAB><TAB> suite . addTest ( module . test_suite ( ) ) <TAB> return suite","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :","if fn . endswith ( "".py"" ) and fn . endswith ( "".py"" ) :",95.86746556689437,95.86,False
3746,"def check_stack_names ( self , frame , expected ) : <TAB> names = [ ] <TAB> while frame : <TAB><TAB> name = frame . f_code . co_name <TAB><TAB> # Stop checking frames when we get to our test helper. <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> names . append ( name ) <TAB><TAB> frame = frame . f_back <TAB> self . assertEqual ( names , expected )","if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",if name in self . _stack_names :,91.27181868984195,85.69,False
3747,"def leave ( self , reason = None ) : <TAB> try : <TAB><TAB> if self . id . startswith ( "" C "" ) : <TAB><TAB><TAB> log . info ( "" Leaving channel  %s  ( %s ) "" , self , self . id ) <TAB><TAB><TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB><TAB> else : <TAB><TAB><TAB> log . info ( "" Leaving group  %s  ( %s ) "" , self , self . id ) <TAB><TAB><TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB> except SlackAPIResponseError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RoomError ( f "" Unable to leave channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB> else : <TAB><TAB><TAB> raise RoomError ( e ) <TAB> self . _id = None","if e . error == ""user_is_bot"" :","if e . error_code == ""user_is_bot"" :",99.21148933196527,98.66,False
3748,"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB><TAB> value = None <TAB><TAB> # XXX: how will this interact with orig_prefix ? <TAB><TAB> #      not exposing attrs for now if orig_prefix is set. <TAB><TAB> <MASK> <TAB><TAB><TAB> wrapped = self . wrapped <TAB><TAB><TAB> ident = getattr ( wrapped , "" ident "" , None ) <TAB><TAB><TAB> if ident is not None : <TAB><TAB><TAB><TAB> value = self . _wrap_hash ( ident ) <TAB><TAB> self . _ident = value <TAB> return value",if not self . orig_prefix :,if self . _ident is not None :,97.06057048773609,95.77,False
3749,"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB><TAB> try : <TAB><TAB><TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> if f . read ( 1 ) == "" 1 "" : <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB> except IOError : <TAB><TAB><TAB> continue <TAB> return False","if f . read ( ) . strip ( ) != ""Mains"" :","if f . read ( 1 ) != ""0"" :",68.48907245536697,96.26,False
3750,"def _get_pending_by_app_token ( self , app_token ) : <TAB> result = [ ] <TAB> with self . _pending_lock : <TAB><TAB> self . _remove_stale_pending ( ) <TAB><TAB> for data in self . _pending_decisions : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result . append ( data ) <TAB> return result",if data . app_token == app_token :,if data . app_token == app_token :,100.0,100.00,True
3751,"def do_create ( specific_tables = None , base = Base ) : <TAB> engine = get_engine ( ) <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . info ( <TAB><TAB><TAB><TAB> "" Initializing only a subset of tables as requested:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> specific_tables <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> base . metadata . create_all ( engine , tables = specific_tables ) <TAB><TAB> else : <TAB><TAB><TAB> base . metadata . create_all ( engine ) <TAB> except Exception as err : <TAB><TAB> raise Exception ( "" could not create/re-create DB tables - exception:  "" + str ( err ) )",if specific_tables :,if specific_tables :,100.0,100.00,True
3752,"def __setitem__ ( self , ndx , val ) : <TAB> # <TAB> # Get the expression data object <TAB> # <TAB> exprdata = None <TAB> if ndx in self . _data : <TAB><TAB> exprdata = self . _data [ ndx ] <TAB> else : <TAB><TAB> _ndx = normalize_index ( ndx ) <TAB><TAB> <MASK> <TAB><TAB><TAB> exprdata = self . _data [ _ndx ] <TAB> if exprdata is None : <TAB><TAB> raise KeyError ( <TAB><TAB><TAB> "" Cannot set the value of Expression  ' %s '  with  "" <TAB><TAB><TAB> "" invalid index  ' %s ' "" % ( self . cname ( True ) , str ( ndx ) ) <TAB><TAB> ) <TAB> # <TAB> # Set the value <TAB> # <TAB> exprdata . set_value ( val )",if _ndx in self . _data :,if _ndx in self . _data :,75.0,100.00,True
3753,"def write ( self , * bits ) : <TAB> for bit in bits : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . bytestream . append ( 0 ) <TAB><TAB> byte = self . bytestream [ self . bytenum ] <TAB><TAB> if self . bitnum == 8 : <TAB><TAB><TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB><TAB><TAB><TAB> byte = 0 <TAB><TAB><TAB><TAB> self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB> self . bytenum + = 1 <TAB><TAB><TAB> self . bitnum = 0 <TAB><TAB> mask = 2 * * self . bitnum <TAB><TAB> if bit : <TAB><TAB><TAB> byte | = mask <TAB><TAB> else : <TAB><TAB><TAB> byte & = ~ mask <TAB><TAB> self . bytestream [ self . bytenum ] = byte <TAB><TAB> self . bitnum + = 1",if not self . bytestream :,if self . bytenum not in self . bytestream :,71.64452762169094,97.55,False
3754,"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> if proc . poll ( ) is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB><TAB> proc . terminate ( ) <TAB><TAB> timeout_time = time . time ( ) + timeout <TAB><TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB><TAB><TAB> time . sleep ( 0.02 ) <TAB><TAB> if proc . poll ( ) is None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB><TAB><TAB> proc . kill ( ) <TAB> return proc . returncode",if log :,if log is not None :,95.61519875104409,95.63,False
3755,"def mkpanel ( color , rows , cols , tly , tlx ) : <TAB> win = curses . newwin ( rows , cols , tly , tlx ) <TAB> pan = panel . new_panel ( win ) <TAB> if curses . has_colors ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> fg = curses . COLOR_WHITE <TAB><TAB> else : <TAB><TAB><TAB> fg = curses . COLOR_BLACK <TAB><TAB> bg = color <TAB><TAB> curses . init_pair ( color , fg , bg ) <TAB><TAB> win . bkgdset ( ord ( ""   "" ) , curses . color_pair ( color ) ) <TAB> else : <TAB><TAB> win . bkgdset ( ord ( ""   "" ) , curses . A_BOLD ) <TAB> return pan",if color == curses . COLOR_BLUE :,if color == curses . COLOR_WHITE :,97.8858495657727,98.71,False
3756,"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB><TAB> if start_char == True : <TAB><TAB><TAB> word = "" "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # We found the start of a word <TAB><TAB><TAB><TAB> word = c . lower ( ) <TAB><TAB><TAB><TAB> start_char = False <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> word + = c . lower ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # We found end of word, emit it <TAB><TAB><TAB><TAB> start_char = True <TAB><TAB><TAB><TAB> yield word",if c . isalnum ( ) :,if c . isupper ( ) :,97.55426532710996,98.04,False
3757,"def get_tf_weights_as_numpy ( path = "" ./ckpt/aeslc/model.ckpt-32000 "" ) - > Dict : <TAB> init_vars = tf . train . list_variables ( path ) <TAB> tf_weights = { } <TAB> ignore_name = [ "" Adafactor "" , "" global_step "" ] <TAB> for name , shape in tqdm ( init_vars , desc = "" converting tf checkpoint to dict "" ) : <TAB><TAB> skip_key = any ( [ pat in name for pat in ignore_name ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> array = tf . train . load_variable ( path , name ) <TAB><TAB> tf_weights [ name ] = array <TAB> return tf_weights",if skip_key :,if skip_key :,100.0,100.00,True
3758,"def app ( scope , receive , send ) : <TAB> while True : <TAB><TAB> message = await receive ( ) <TAB><TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB><TAB><TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB><TAB><TAB> break","elif message [ ""type"" ] == ""websocket.receive"" :","elif message [ ""type"" ] == ""websocket.receive"" :",100.0,100.00,True
3759,"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB><TAB> if sys . platform == "" darwin "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> theme = DARK <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> theme = LIGHT <TAB><TAB> else : <TAB><TAB><TAB> theme = self . guess_system_theme ( ) <TAB><TAB><TAB> if theme == Dark : <TAB><TAB><TAB><TAB> theme = MacOSDark <TAB> else : # user settings have highest priority <TAB><TAB> theme = self . _app . config . THEME <TAB> self . load_theme ( theme )",if get_osx_theme ( ) == 1 :,if self . _app . config . USE_DARK :,94.60768493815084,94.39,False
3760,"def example_reading_spec ( self ) : <TAB> data_fields = { "" targets "" : tf . VarLenFeature ( tf . int64 ) } <TAB> <MASK> <TAB><TAB> data_fields [ "" inputs "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> if self . packed_length : <TAB><TAB> <MASK> <TAB><TAB><TAB> data_fields [ "" inputs_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB><TAB> data_fields [ "" inputs_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB> data_fields [ "" targets_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB><TAB> data_fields [ "" targets_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> data_items_to_decoders = None <TAB> return ( data_fields , data_items_to_decoders )",if self . has_inputs :,if self . packed_length :,75.12390095717375,96.13,False
3761,"def _prepare_travel_graph ( self ) : <TAB> for op in self . op_dict . values ( ) : <TAB><TAB> op . const = False <TAB><TAB> if op . node . op in [ "" Const "" , "" Placeholder "" ] : <TAB><TAB><TAB> op . resolved = True <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> op . const = True <TAB><TAB> else : <TAB><TAB><TAB> op . resolved = False","if op . node . op == ""Const"" :","elif op . node . op in [ ""Const"" , ""Placeholder"" ] :",69.12239021662843,90.92,False
3762,"def get_filestream_file_items ( self ) : <TAB> data = { } <TAB> fs_file_updates = self . get_filestream_file_updates ( ) <TAB> for k , v in six . iteritems ( fs_file_updates ) : <TAB><TAB> l = [ ] <TAB><TAB> for d in v : <TAB><TAB><TAB> offset = d . get ( "" offset "" ) <TAB><TAB><TAB> content = d . get ( "" content "" ) <TAB><TAB><TAB> assert offset is not None <TAB><TAB><TAB> assert content is not None <TAB><TAB><TAB> assert offset == 0 or offset == len ( l ) , ( k , v , l , d ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> l = [ ] <TAB><TAB><TAB> l . extend ( map ( json . loads , content ) ) <TAB><TAB> data [ k ] = l <TAB> return data",if not offset :,if not l :,90.9351277605088,98.97,False
3763,"def _rewrite_exprs ( self , table , what ) : <TAB> from ibis . expr . analysis import substitute_parents <TAB> what = util . promote_list ( what ) <TAB> all_exprs = [ ] <TAB> for expr in what : <TAB><TAB> <MASK> <TAB><TAB><TAB> all_exprs . extend ( expr . exprs ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> bound_expr = ir . bind_expr ( table , expr ) <TAB><TAB><TAB> all_exprs . append ( bound_expr ) <TAB> return [ substitute_parents ( x , past_projection = False ) for x in all_exprs ]","if isinstance ( expr , ir . ExprList ) :","if isinstance ( expr , ibis . expr . Expr ) :",94.09546404132743,96.26,False
3764,"def _group_by_commit_and_time ( self , hits ) : <TAB> result = { } <TAB> for hit in hits : <TAB><TAB> source_hit = hit [ "" _source "" ] <TAB><TAB> key = "" %s _ %s "" % ( source_hit [ "" commit_info "" ] [ "" id "" ] , source_hit [ "" datetime "" ] ) <TAB><TAB> benchmark = self . _benchmark_from_es_record ( source_hit ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ key ] [ "" benchmarks "" ] . append ( benchmark ) <TAB><TAB> else : <TAB><TAB><TAB> run_info = self . _run_info_from_es_record ( source_hit ) <TAB><TAB><TAB> run_info [ "" benchmarks "" ] = [ benchmark ] <TAB><TAB><TAB> result [ key ] = run_info <TAB> return result",if key in result :,if benchmark :,82.47509173510737,98.02,False
3765,"def _build_index ( self ) : <TAB> self . _index = { } <TAB> for start_char , sorted_offsets in self . _offsets . items ( ) : <TAB><TAB> self . _index [ start_char ] = { } <TAB><TAB> for i , offset in enumerate ( sorted_offsets . get_offsets ( ) ) : <TAB><TAB><TAB> identifier = sorted_offsets . get_identifier_by_offset ( offset ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _index [ start_char ] [ identifier [ 0 : self . index_depth ] ] = i",if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,if identifier :,68.65802631444235,86.95,False
3766,"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB><TAB><TAB><TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB><TAB><TAB><TAB><TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""attributes"" in conf [ ""properties"" ] :","if ""attributes"" in conf [ ""properties"" ] :",75.0,100.00,True
3767,"def _PatchArtifact ( self , artifact : rdf_artifacts . Artifact ) - > rdf_artifacts . Artifact : <TAB> """"""Patches artifact to not contain byte-string source attributes."""""" <TAB> patched = False <TAB> for source in artifact . sources : <TAB><TAB> attributes = source . attributes . ToDict ( ) <TAB><TAB> unicode_attributes = compatibility . UnicodeJson ( attributes ) <TAB><TAB> <MASK> <TAB><TAB><TAB> source . attributes = unicode_attributes <TAB><TAB><TAB> patched = True <TAB> if patched : <TAB><TAB> self . DeleteArtifact ( str ( artifact . name ) ) <TAB><TAB> self . WriteArtifact ( artifact ) <TAB> return artifact",if attributes != unicode_attributes :,"if unicode_attributes . get ( ""type"" ) == ""unicode"" :",71.02583619327301,91.62,False
3768,"def edit_file ( self , filename ) : <TAB> import subprocess <TAB> editor = self . get_editor ( ) <TAB> if self . env : <TAB><TAB> environ = os . environ . copy ( ) <TAB><TAB> environ . update ( self . env ) <TAB> else : <TAB><TAB> environ = None <TAB> try : <TAB><TAB> c = subprocess . Popen ( ' %s   "" %s "" ' % ( editor , filename ) , env = environ , shell = True ) <TAB><TAB> exit_code = c . wait ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ClickException ( "" %s : Editing failed! "" % editor ) <TAB> except OSError as e : <TAB><TAB> raise ClickException ( "" %s : Editing failed:  %s "" % ( editor , e ) )",if exit_code != 0 :,if exit_code != 0 :,100.0,100.00,True
3769,"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB><TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB><TAB> for j , s in enumerate ( c ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if glyph . contours [ i ] . segments [ j ] . type == "" line "" : <TAB><TAB><TAB><TAB><TAB> controlPointIndices [ index ] = 1 <TAB><TAB><TAB> index + = s [ 1 ] <TAB> return controlPointIndices",if j < segmentCount :,if s [ 0 ] == segmentCount :,83.96494680112993,95.70,False
3770,"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB><TAB> request <TAB><TAB> and is_deprecated ( request . version , self . min_version ) <TAB><TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB><TAB> social = value . copy ( ) <TAB><TAB> for key in old_social_string_fields : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> social [ key ] = value [ key ] [ 0 ] <TAB><TAB><TAB> elif social . get ( key ) == [ ] : <TAB><TAB><TAB><TAB> social [ key ] = "" "" <TAB><TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value )",if social . get ( key ) :,"if isinstance ( value [ key ] , ( list , tuple ) ) :",71.93316347210526,94.97,False
3771,"def iter_raw_frames ( path , packet_sizes , ctx ) : <TAB> with open ( path , "" rb "" ) as f : <TAB><TAB> for i , size in enumerate ( packet_sizes ) : <TAB><TAB><TAB> packet = Packet ( size ) <TAB><TAB><TAB> read_size = f . readinto ( packet ) <TAB><TAB><TAB> assert size <TAB><TAB><TAB> assert read_size == size <TAB><TAB><TAB> if not read_size : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> for frame in ctx . decode ( packet ) : <TAB><TAB><TAB><TAB> yield frame <TAB><TAB> while True : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> frames = ctx . decode ( None ) <TAB><TAB><TAB> except EOFError : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> for frame in frames : <TAB><TAB><TAB><TAB> yield frame <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break",if not frames :,if not frames :,100.0,100.00,True
3772,"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB><TAB> already_test = [ ] <TAB><TAB> for fname in lib_zip . namelist ( ) : <TAB><TAB><TAB> pname , fname = os . path . split ( fname ) <TAB><TAB><TAB> if fname or ( pname and fname ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if pname not in already_test and "" / "" not in pname : <TAB><TAB><TAB><TAB> already_test . append ( pname ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs",if is_shadowing ( pname ) :,if pname not in shadow_pkgs :,96.02625880579092,96.71,False
3773,"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB><TAB> if isinstance ( v , torch . Tensor ) : <TAB><TAB><TAB> v = v . item ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> v = self . metrics_to_scalars ( v ) <TAB><TAB> new_metrics [ k ] = v <TAB> return new_metrics","if isinstance ( v , dict ) :","elif isinstance ( v , ( list , tuple ) ) :",71.43410364467965,92.79,False
3774,"def insert_resets ( f ) : <TAB> newsync = dict ( ) <TAB> for k , v in f . sync . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> newsync [ k ] = insert_reset ( ResetSignal ( k ) , v ) <TAB><TAB> else : <TAB><TAB><TAB> newsync [ k ] = v <TAB> f . sync = newsync",if f . clock_domains [ k ] . rst is not None :,"if isinstance ( v , ResetSignal ) :",82.0273441455923,86.38,False
3775,"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB><TAB> if node is None : <TAB><TAB><TAB> continue <TAB><TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if node_settings . external_account == external_account : <TAB><TAB><TAB> yield node",if node_settings is None :,if not node_settings :,66.02013040363346,96.31,False
3776,"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB><TAB> if isinstance ( test , ast . Const ) : <TAB><TAB><TAB> if type ( test . value ) in self . _const_types : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB> self . visit ( test , scope ) <TAB><TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB><TAB> self . visit ( node . else_ , scope )",if not test . value :,if self . _const_types [ test . value ] is None :,68.43800806955917,91.72,False
3777,"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [ ] <TAB> channel = await self . messageable . _get_channel ( ) <TAB> self . channel = channel <TAB> while self . _get_retrieve ( ) : <TAB><TAB> data = await self . _retrieve_messages ( self . retrieve ) <TAB><TAB> if len ( data ) < 100 : <TAB><TAB><TAB> self . limit = 0 # terminate the infinite loop <TAB><TAB> <MASK> <TAB><TAB><TAB> data = reversed ( data ) <TAB><TAB> if self . _filter : <TAB><TAB><TAB> data = filter ( self . _filter , data ) <TAB><TAB> for element in data : <TAB><TAB><TAB> result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB> return result",if self . reverse :,if self . reverse :,75.0,100.00,True
3778,"def compute ( self , x , y = None , targets = None ) : <TAB> if targets is None : <TAB><TAB> targets = self . out_params <TAB> in_params = list ( self . in_x ) <TAB> if len ( in_params ) == 1 : <TAB><TAB> args = [ x ] <TAB> else : <TAB><TAB> args = list ( zip ( * x ) ) <TAB> if y is None : <TAB><TAB> pipe = self . pipe <TAB> else : <TAB><TAB> pipe = self . train_pipe <TAB><TAB> <MASK> <TAB><TAB><TAB> args . append ( y ) <TAB><TAB> else : <TAB><TAB><TAB> args + = list ( zip ( * y ) ) <TAB><TAB> in_params + = self . in_y <TAB> return self . _compute ( * args , pipe = pipe , param_names = in_params , targets = targets )",if len ( self . in_y ) == 1 :,if len ( y ) == 1 :,73.18797870442847,97.70,False
3779,"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys . path : <TAB><TAB> <MASK> <TAB><TAB><TAB> module = self . fs_imp . import_from_dir ( item , name ) <TAB><TAB> else : <TAB><TAB><TAB> module = item . import_top ( name ) <TAB><TAB> if module : <TAB><TAB><TAB> return module <TAB> return None","if isinstance ( item , _StringType ) :","if isinstance ( item , ( list , tuple ) ) :",72.43736294166187,95.73,False
3780,"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB><TAB> if isinstance ( key , ( int , long ) ) : <TAB><TAB><TAB> return self . _list [ key ] <TAB><TAB> elif isinstance ( key , slice ) : <TAB><TAB><TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB><TAB> <MASK> <TAB><TAB><TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB><TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key )",if k . lower ( ) == ikey :,if k . lower ( ) == ikey :,100.0,100.00,True
3781,"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB><TAB> if key == "" hooks "" : <TAB><TAB><TAB> new_action = 0 <TAB><TAB><TAB> for name , _val in val . items ( ) : <TAB><TAB><TAB><TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> new_action = 1 <TAB><TAB> else : <TAB><TAB><TAB> new_action = watcher . set_opt ( key , val ) <TAB><TAB> if new_action == 1 : <TAB><TAB><TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher . do_action ( action )",if action == 1 :,if action == 0 :,99.10866036042552,99.02,False
3782,"def OnBodyClick ( self , event = None ) : <TAB> try : <TAB><TAB> c = self . c <TAB><TAB> p = c . currentPosition ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . OnActivateBody ( event = event ) <TAB><TAB> g . doHook ( "" bodyclick2 "" , c = c , p = p , v = p , event = event ) <TAB> except : <TAB><TAB> g . es_event_exception ( "" bodyclick "" )","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :","if g . doHook ( ""bodyclick1"" , c = c , p = p",61.569012100665724,89.79,False
3783,"def _class_weights ( spec : config . MetricsSpec ) - > Optional [ Dict [ int , float ] ] : <TAB> """"""Returns class weights associated with AggregationOptions at offset."""""" <TAB> if spec . aggregate . HasField ( "" top_k_list "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" class_weights are not supported when top_k_list used:  "" <TAB><TAB><TAB><TAB> "" spec= {} "" . format ( spec ) <TAB><TAB><TAB> ) <TAB><TAB> return None <TAB> return dict ( spec . aggregate . class_weights ) or None",if spec . aggregate . class_weights :,if spec . aggregate . class_weights is None :,71.96129834294854,97.98,False
3784,"def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB><TAB> if line [ 0 ] == "" # "" : <TAB><TAB><TAB> continue <TAB><TAB> r = event_regexp . search ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> f . close ( ) <TAB><TAB><TAB> return True <TAB><TAB> f . close ( ) <TAB><TAB> return False",if r :,if r :,100.0,100.00,True
3785,"def _get_before_insertion_node ( self ) : <TAB> if self . _nodes_stack . is_empty ( ) : <TAB><TAB> return None <TAB> line = self . _nodes_stack . parsed_until_line + 1 <TAB> node = self . _new_module . get_last_leaf ( ) <TAB> while True : <TAB><TAB> parent = node . parent <TAB><TAB> <MASK> <TAB><TAB><TAB> assert node . end_pos [ 0 ] < = line <TAB><TAB><TAB> assert node . end_pos [ 1 ] == 0 or "" \n "" in self . _prefix <TAB><TAB><TAB> return node <TAB><TAB> node = parent","if parent . type in ( ""suite"" , ""file_input"" ) :",if parent is None :,75.8147802277281,91.53,False
3786,"def PyJsHoisted_parseClassRanges_ ( this , arguments , var = var ) : <TAB> var = Scope ( { u "" this "" : this , u "" arguments "" : arguments } , var ) <TAB> var . registers ( [ u "" res "" ] ) <TAB> pass <TAB> if var . get ( u "" current "" ) ( Js ( u "" ] "" ) ) : <TAB><TAB> return Js ( [ ] ) <TAB> else : <TAB><TAB> var . put ( u "" res "" , var . get ( u "" parseNonemptyClassRanges "" ) ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> var . get ( u "" bail "" ) ( Js ( u "" nonEmptyClassRanges "" ) ) <TAB><TAB> return var . get ( u "" res "" )","if var . get ( u""res"" ) . neg ( ) :","if var . get ( u""bail"" ) :",96.23799846003062,96.25,False
3787,"def _recurse_children ( self , offset ) : <TAB> """"""Recurses thorugh the available children"""""" <TAB> while offset < self . obj_offset + self . Length : <TAB><TAB> item = obj . Object ( "" VerStruct "" , offset = offset , vm = self . obj_vm , parent = self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise StopIteration ( <TAB><TAB><TAB><TAB> "" Could not recover a key for a child at offset  {0} "" . format ( <TAB><TAB><TAB><TAB><TAB> item . obj_offset <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> yield item . get_key ( ) , item . get_children ( ) <TAB><TAB> offset = self . offset_pad ( offset + item . Length ) <TAB> raise StopIteration ( "" No children "" )",if item . Length < 1 or item . get_key ( ) == None :,if not item . get_key ( ) :,67.05142240522176,94.82,False
3788,"def _adapt_types ( self , descr ) : <TAB> names = [ ] <TAB> adapted_types = [ ] <TAB> for col in descr : <TAB><TAB> names . append ( col [ 0 ] ) <TAB><TAB> impala_typename = col [ 1 ] <TAB><TAB> typename = udf . _impala_to_ibis_type [ impala_typename . lower ( ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> precision , scale = col [ 4 : 6 ] <TAB><TAB><TAB> adapted_types . append ( dt . Decimal ( precision , scale ) ) <TAB><TAB> else : <TAB><TAB><TAB> adapted_types . append ( typename ) <TAB> return names , adapted_types","if typename == ""decimal"" :",if len ( col ) > 4 :,67.68800300358234,95.84,False
3789,"def sniff ( self , filename ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> with tarfile . open ( filename , "" r "" ) as temptar : <TAB><TAB><TAB><TAB> for f in temptar : <TAB><TAB><TAB><TAB><TAB> if not f . isfile ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB><TAB> if f . name . endswith ( "" .fast5 "" ) : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB><TAB> return False <TAB> except Exception as e : <TAB><TAB> log . warning ( "" %s , sniff Exception:  %s "" , self , e ) <TAB> return False",if filename and tarfile . is_tarfile ( filename ) :,if tarfile . is_file ( filename ) :,70.4039010856526,97.43,False
3790,"def getValue ( self ) : <TAB> if getattr ( self . object , "" type "" , "" "" ) != "" CURVE "" : <TAB><TAB> return BezierSpline ( ) <TAB> evaluatedObject = getEvaluatedID ( self . object ) <TAB> bSplines = evaluatedObject . data . splines <TAB> if len ( bSplines ) > 0 : <TAB><TAB> spline = createSplineFromBlenderSpline ( bSplines [ 0 ] ) <TAB><TAB> # Is None when the spline type is not supported. <TAB><TAB> if spline is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> spline . transform ( evaluatedObject . matrix_world ) <TAB><TAB><TAB> return spline <TAB> return BezierSpline ( )",if self . useWorldSpace :,if evaluatedObject . matrix_world is not None :,97.3731057456138,94.63,False
3791,"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB><TAB> if "" & "" in text : <TAB><TAB><TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB><TAB> if "" < "" in text : <TAB><TAB><TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB><TAB> if ' "" ' in text : <TAB><TAB><TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB><TAB> if "" ' "" in text : <TAB><TAB><TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB><TAB> if newline : <TAB><TAB><TAB> if "" \n "" in text : <TAB><TAB><TAB><TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if "">"" in text :","if "">"" in text :",100.0,100.00,True
3792,"def _get_ilo_version ( self ) : <TAB> try : <TAB><TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB><TAB> if hasattr ( e , "" code "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return 3 <TAB><TAB><TAB> if e . code == 501 : <TAB><TAB><TAB><TAB> return 1 <TAB><TAB> raise <TAB> return 2",if e . code == 405 :,if e . code == 502 :,73.23905109290143,98.33,False
3793,"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB><TAB> if code == Path . MOVETO : <TAB><TAB><TAB> ctx . move_to ( * points ) <TAB><TAB> elif code == Path . LINETO : <TAB><TAB><TAB> ctx . line_to ( * points ) <TAB><TAB> elif code == Path . CURVE3 : <TAB><TAB><TAB> ctx . curve_to ( <TAB><TAB><TAB><TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB> ) <TAB><TAB> elif code == Path . CURVE4 : <TAB><TAB><TAB> ctx . curve_to ( * points ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ctx . close_path ( )",elif code == Path . CLOSEPOLY :,elif code == Path . CLOSE_PATH :,74.00760634315193,98.06,False
3794,"def called_by_shrinker ( ) : <TAB> frame = sys . _getframe ( 0 ) <TAB> while frame : <TAB><TAB> fname = frame . f_globals . get ( "" __file__ "" , "" "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> frame = frame . f_back <TAB> return False","if os . path . basename ( fname ) == ""shrinker.py"" :",if os . path . isfile ( fname ) :,67.79220712698323,89.30,False
3795,"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB><TAB> s = str ( path ) <TAB><TAB> if ensuremode == "" append "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sys . path . append ( s ) <TAB><TAB> else : <TAB><TAB><TAB> if s != sys . path [ 0 ] : <TAB><TAB><TAB><TAB> sys . path . insert ( 0 , s )",if s not in sys . path :,if s not in sys . path :,100.0,100.00,True
3796,"def get_instances ( self , region : str , vpc : str ) : <TAB> try : <TAB><TAB> await self . _cache_instances ( region ) <TAB><TAB> return [ <TAB><TAB><TAB> instance <TAB><TAB><TAB> for instance in self . _instances_cache [ region ] <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB> except Exception as e : <TAB><TAB> print_exception ( f "" Failed to get RDS instances:  { e } "" ) <TAB><TAB> return [ ]","if instance [ ""VpcId"" ] == vpc",if instance . vpc == vpc,92.66068080847593,95.36,False
3797,def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB><TAB> if page . relations . disambiguation_links_norm is not None : <TAB><TAB><TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB><TAB> <MASK> <TAB><TAB><TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ),if page . relations . disambiguation_links is not None :,if page . relations . disambiguation_links is not None :,100.0,100.00,True
3798,"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> cnt = 0 <TAB> for e in self . options_ : <TAB><TAB> elm = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> elm = "" ( %d ) "" % cnt <TAB><TAB> res + = prefix + ( "" options %s  < \n "" % elm ) <TAB><TAB> res + = e . __str__ ( prefix + ""    "" , printElemNumber ) <TAB><TAB> res + = prefix + "" > \n "" <TAB><TAB> cnt + = 1 <TAB> return res",if printElemNumber :,if printElemNumber :,100.0,100.00,True
3799,"def pre_save_task ( self , task , credentials , verrors ) : <TAB> if task [ "" attributes "" ] [ "" encryption "" ] not in ( None , "" "" , "" AES256 "" ) : <TAB><TAB> verrors . add ( "" encryption "" , ' Encryption should be null or  "" AES256 "" ' ) <TAB> if not credentials [ "" attributes "" ] . get ( "" skip_region "" , False ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> response = await self . middleware . run_in_thread ( <TAB><TAB><TAB><TAB> self . _get_client ( credentials ) . get_bucket_location , <TAB><TAB><TAB><TAB> Bucket = task [ "" attributes "" ] [ "" bucket "" ] , <TAB><TAB><TAB> ) <TAB><TAB><TAB> task [ "" attributes "" ] [ "" region "" ] = response [ "" LocationConstraint "" ] or "" us-east-1 ""","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",if self . middleware :,85.57604745785163,90.35,False
3800,"def get_best_config_reward ( self ) : <TAB> """"""Returns the best configuration found so far, as well as the reward associated with this best config."""""" <TAB> with self . LOCK : <TAB><TAB> <MASK> <TAB><TAB><TAB> config_pkl = max ( self . _results , key = self . _results . get ) <TAB><TAB><TAB> return pickle . loads ( config_pkl ) , self . _results [ config_pkl ] <TAB><TAB> else : <TAB><TAB><TAB> return dict ( ) , self . _reward_while_pending ( )",if self . _results :,if self . _results :,100.0,100.00,True
3801,"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB><TAB> contents = self . setup_cfg . read_text ( ) <TAB><TAB> base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB><TAB> try : <TAB><TAB><TAB> parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB><TAB> except Exception : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> contents = self . setup_cfg . read_bytes ( ) <TAB><TAB><TAB> parsed = parse_setup_cfg ( contents , base_dir ) <TAB><TAB> if not parsed : <TAB><TAB><TAB> return { } <TAB><TAB> return parsed <TAB> return { }",if six . PY2 :,if self . setup_cfg . exists ( ) :,72.3773533271968,95.85,False
3802,"def readall ( read_fn , sz ) : <TAB> buff = b "" "" <TAB> have = 0 <TAB> while have < sz : <TAB><TAB> chunk = yield from read_fn ( sz - have ) <TAB><TAB> have + = len ( chunk ) <TAB><TAB> buff + = chunk <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TTransportException ( <TAB><TAB><TAB><TAB> TTransportException . END_OF_FILE , "" End of file reading from transport "" <TAB><TAB><TAB> ) <TAB> return buff",if len ( chunk ) == 0 :,if len ( chunk ) == 0 :,100.0,100.00,True
3803,"def _get_use_previous ( <TAB> f , ) : # TODO Sort and group features for DateOffset with two different temporal values <TAB> if isinstance ( f , AggregationFeature ) and f . use_previous is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( "" "" , - 1 ) <TAB><TAB> else : <TAB><TAB><TAB> unit = list ( f . use_previous . times . keys ( ) ) [ 0 ] <TAB><TAB><TAB> value = f . use_previous . times [ unit ] <TAB><TAB><TAB> return ( unit , value ) <TAB> else : <TAB><TAB> return ( "" "" , - 1 )",if len ( f . use_previous . times . keys ( ) ) > 1 :,if f . use_previous . times is None :,69.78098819041887,93.22,False
3804,"def istrue ( self ) : <TAB> try : <TAB><TAB> return self . _istrue ( ) <TAB> except Exception : <TAB><TAB> self . exc = sys . exc_info ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = [ <TAB><TAB><TAB><TAB> ""   "" * ( self . exc [ 1 ] . offset + 4 ) + "" ^ "" , <TAB><TAB><TAB> ] <TAB><TAB><TAB> msg . append ( "" SyntaxError: invalid syntax "" ) <TAB><TAB> else : <TAB><TAB><TAB> msg = traceback . format_exception_only ( * self . exc [ : 2 ] ) <TAB><TAB> pytest . fail ( <TAB><TAB><TAB> "" Error evaluating  %r  expression \n "" <TAB><TAB><TAB> ""      %s \n "" <TAB><TAB><TAB> "" %s "" % ( self . name , self . expr , "" \n "" . join ( msg ) ) , <TAB><TAB><TAB> pytrace = False , <TAB><TAB> )","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",if len ( self . exc ) > 2 :,95.5146530894293,96.40,False
3805,"def wait_for_crm_operation ( operation , crm ) : <TAB> """"""Poll for cloud resource manager operation until finished."""""" <TAB> logger . info ( <TAB><TAB> "" wait_for_crm_operation:  "" <TAB><TAB> "" Waiting for operation  {}  to finish... "" . format ( operation ) <TAB> ) <TAB> for _ in range ( MAX_POLLS ) : <TAB><TAB> result = crm . operations ( ) . get ( name = operation [ "" name "" ] ) . execute ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( result [ "" error "" ] ) <TAB><TAB> if "" done "" in result and result [ "" done "" ] : <TAB><TAB><TAB> logger . info ( "" wait_for_crm_operation: Operation done. "" ) <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( POLL_INTERVAL ) <TAB> return result","if ""error"" in result :","if ""error"" in result :",100.0,100.00,True
3806,"def cb_blob_detail_from_elem_and_buf ( self , elem , buf ) : <TAB> if elem . get ( "" lang "" ) != buf . lang : # multi-lang doc <TAB><TAB> return "" %s  Code in  %s "" % ( elem . get ( "" lang "" ) , buf . path ) <TAB> else : <TAB><TAB> dir , base = os . path . split ( buf . path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" %s  ( %s ) "" % ( base , dir ) <TAB><TAB> else : <TAB><TAB><TAB> return base",if dir :,if dir :,100.0,100.00,True
3807,"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB><TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB><TAB> try : <TAB><TAB><TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB><TAB> except error_perm as error : <TAB><TAB><TAB> code , _ = _parse_ftp_error ( error ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . isfile ( path ) : <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryExpected ( path ) <TAB><TAB><TAB><TAB> if not self . isempty ( path ) : <TAB><TAB><TAB><TAB><TAB> raise errors . DirectoryNotEmpty ( path ) <TAB><TAB><TAB> raise # pragma: no cover","if code == ""550"" :",if code == 404 :,74.0363578708056,98.24,False
3808,"def p_clause ( self , node , position ) : <TAB> if isinstance ( node , Graph ) : <TAB><TAB> self . subjectDone ( node ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . write ( ""   "" ) <TAB><TAB> self . write ( "" { "" ) <TAB><TAB> self . depth + = 1 <TAB><TAB> serializer = N3Serializer ( node , parent = self ) <TAB><TAB> serializer . serialize ( self . stream ) <TAB><TAB> self . depth - = 1 <TAB><TAB> self . write ( self . indent ( ) + "" } "" ) <TAB><TAB> return True <TAB> else : <TAB><TAB> return False",if position is OBJECT :,if self . depth > 0 :,91.44990456607866,96.20,False
3809,"def get_default_shell_info ( shell_name = None , settings = None ) : <TAB> if not shell_name : <TAB><TAB> settings = settings or load_settings ( lazy = True ) <TAB><TAB> shell_name = settings . get ( "" shell "" ) <TAB><TAB> if shell_name : <TAB><TAB><TAB> return shell_name , None <TAB><TAB> shell_path = os . environ . get ( "" SHELL "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shell_name = basepath ( shell_path ) <TAB><TAB> else : <TAB><TAB><TAB> shell_name = DEFAULT_SHELL <TAB><TAB> return shell_name , shell_path <TAB> return shell_name , None",if shell_path :,if os . path . exists ( shell_path ) :,82.24927275549489,94.82,False
3810,"def GetCategory ( self , pidls ) : <TAB> ret = [ ] <TAB> for pidl in pidls : <TAB><TAB> # Why don't we just get the size of the PIDL? <TAB><TAB> val = self . sf . GetDetailsEx ( pidl , PKEY_Sample_AreaSize ) <TAB><TAB> val = int ( val ) # it probably came in a VT_BSTR variant <TAB><TAB> if val < 255 / / 3 : <TAB><TAB><TAB> cid = IDS_SMALL <TAB><TAB> <MASK> <TAB><TAB><TAB> cid = IDS_MEDIUM <TAB><TAB> else : <TAB><TAB><TAB> cid = IDS_LARGE <TAB><TAB> ret . append ( cid ) <TAB> return ret",elif val < 2 * 255 // 3 :,elif val > 255 / 3 :,96.96514164685313,96.67,False
3811,"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB><TAB> # The type checker can't know the true type of item! <TAB><TAB> item = cast ( TupleStr4 , item ) <TAB><TAB> if item [ 0 ] : <TAB><TAB><TAB> typ = "" number "" <TAB><TAB><TAB> val = item [ 0 ] <TAB><TAB> elif item [ 1 ] : <TAB><TAB><TAB> typ = "" name "" <TAB><TAB><TAB> val = item [ 1 ] <TAB><TAB> elif item [ 2 ] : <TAB><TAB><TAB> typ = item [ 2 ] <TAB><TAB><TAB> val = item [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> typ = item [ 3 ] <TAB><TAB><TAB> val = item [ 3 ] <TAB><TAB> yield Token ( typ , val )",elif item [ 3 ] :,elif item [ 3 ] :,75.0,100.00,True
3812,"def add_package_declarations ( generated_root_path ) : <TAB> file_names = os . listdir ( generated_root_path ) <TAB> for file_name in file_names : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> full_name = os . path . join ( generated_root_path , file_name ) <TAB><TAB> add_package ( full_name )","if not file_name . endswith ( "".java"" ) :","if file_name . startswith ( ""__"" ) :",68.87196013495179,92.54,False
3813,"def _call_with_retry ( out , retry , retry_wait , method , * args , * * kwargs ) : <TAB> for counter in range ( retry + 1 ) : <TAB><TAB> try : <TAB><TAB><TAB> return method ( * args , * * kwargs ) <TAB><TAB> except ( <TAB><TAB><TAB> NotFoundException , <TAB><TAB><TAB> ForbiddenException , <TAB><TAB><TAB> AuthenticationException , <TAB><TAB><TAB> RequestErrorException , <TAB><TAB> ) : <TAB><TAB><TAB> raise <TAB><TAB> except ConanException as exc : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if out : <TAB><TAB><TAB><TAB><TAB> out . error ( exc ) <TAB><TAB><TAB><TAB><TAB> out . info ( "" Waiting  %d  seconds to retry... "" % retry_wait ) <TAB><TAB><TAB><TAB> time . sleep ( retry_wait )",if counter == retry :,if counter >= retry_wait :,73.47043770506511,97.92,False
3814,"def to_wburl_str ( <TAB> url , type = BaseWbUrl . LATEST_REPLAY , mod = "" "" , timestamp = "" "" , end_timestamp = "" "" ) : <TAB> if WbUrl . is_query_type ( type ) : <TAB><TAB> tsmod = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> tsmod + = mod + "" / "" <TAB><TAB> tsmod + = timestamp <TAB><TAB> tsmod + = "" * "" <TAB><TAB> tsmod + = end_timestamp <TAB><TAB> tsmod + = "" / "" + url <TAB><TAB> if type == BaseWbUrl . URL_QUERY : <TAB><TAB><TAB> tsmod + = "" * "" <TAB><TAB> return tsmod <TAB> else : <TAB><TAB> tsmod = timestamp + mod <TAB><TAB> if len ( tsmod ) > 0 : <TAB><TAB><TAB> return tsmod + "" / "" + url <TAB><TAB> else : <TAB><TAB><TAB> return url",if mod :,if len ( mod ) > 0 :,83.08516599849992,97.04,False
3815,"def _configured_ploidy ( items ) : <TAB> ploidies = collections . defaultdict ( set ) <TAB> for data in items : <TAB><TAB> ploidy = dd . get_ploidy ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for k , v in ploidy . items ( ) : <TAB><TAB><TAB><TAB> ploidies [ k ] . add ( v ) <TAB><TAB> else : <TAB><TAB><TAB> ploidies [ "" default "" ] . add ( ploidy ) <TAB> out = { } <TAB> for k , vs in ploidies . items ( ) : <TAB><TAB> assert len ( vs ) == 1 , "" Multiple ploidies set for group calling:  %s   %s "" % ( <TAB><TAB><TAB> k , <TAB><TAB><TAB> list ( vs ) , <TAB><TAB> ) <TAB><TAB> out [ k ] = vs . pop ( ) <TAB> return out","if isinstance ( ploidy , dict ) :","if isinstance ( ploidy , dict ) :",100.0,100.00,True
3816,"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB><TAB> user = self . _users [ username ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . isRoomSame ( user . room ) : <TAB><TAB><TAB><TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB><TAB> self . _users . pop ( username ) <TAB><TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB><TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB><TAB> self . _client . lastLeftTime = time . time ( ) <TAB><TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( )",if user . room :,if user . room :,100.0,100.00,True
3817,"def _thd_cleanup_instance ( self ) : <TAB> container_name = self . getContainerName ( ) <TAB> instances = self . client . containers ( all = 1 , filters = dict ( name = container_name ) ) <TAB> for instance in instances : <TAB><TAB> # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> self . client . remove_container ( instance [ "" Id "" ] , v = True , force = True ) <TAB><TAB> except NotFound : <TAB><TAB><TAB> pass # that's a race condition <TAB><TAB> except docker . errors . APIError as e : <TAB><TAB><TAB> if "" Conflict operation on container "" not in str ( e ) : <TAB><TAB><TAB><TAB> raise","if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :","if instance [ ""Name"" ] == ""hyper12"" :",94.1312582353162,90.14,False
3818,"def handle_ctcp ( self , conn , evt ) : <TAB> args = evt . arguments ( ) <TAB> source = evt . source ( ) . split ( "" ! "" ) [ 0 ] <TAB> if args : <TAB><TAB> if args [ 0 ] == "" VERSION "" : <TAB><TAB><TAB> conn . ctcp_reply ( source , "" VERSION  "" + BOT_VERSION ) <TAB><TAB> <MASK> <TAB><TAB><TAB> conn . ctcp_reply ( source , "" PING "" ) <TAB><TAB> elif args [ 0 ] == "" CLIENTINFO "" : <TAB><TAB><TAB> conn . ctcp_reply ( source , "" CLIENTINFO PING VERSION CLIENTINFO "" )","elif args [ 0 ] == ""PING"" :","elif args [ 0 ] == ""PING"" :",100.0,100.00,True
3819,"def new_func ( self , * args , * * kwargs ) : <TAB> obj = self . obj_ref ( ) <TAB> attr = self . attr <TAB> if obj is not None : <TAB><TAB> args = tuple ( TrackedValue . make ( obj , attr , arg ) for arg in args ) <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs = { <TAB><TAB><TAB><TAB> key : TrackedValue . make ( obj , attr , value ) <TAB><TAB><TAB><TAB> for key , value in iteritems ( kwargs ) <TAB><TAB><TAB> } <TAB> result = func ( self , * args , * * kwargs ) <TAB> self . _changed_ ( ) <TAB> return result",if kwargs :,if kwargs :,100.0,100.00,True
3820,"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB><TAB> # if it is a variable name add it to the doc <TAB><TAB> name = target . id <TAB><TAB> <MASK> <TAB><TAB><TAB> doc = find_doc_for ( target , body_lines ) <TAB><TAB><TAB> if doc is not None : <TAB><TAB><TAB><TAB> variables [ name ] = doc <TAB> elif isinstance ( target , ast . Tuple ) : <TAB><TAB> # if it is a tuple then iterate the elements <TAB><TAB> # this can happen like this: <TAB><TAB> # a, b = 1, 2 <TAB><TAB> for e in target . elts : <TAB><TAB><TAB> add_doc ( e , variables , body_lines )",if name not in variables :,if name not in variables :,100.0,100.00,True
3821,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB><TAB> if tp == "" write "" : <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB> elif tp == "" flush "" : <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> elif tp == "" print "" : <TAB><TAB><TAB> print ( msg , file = out ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB><TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB> pass","elif tp == ""write_flush"" :","elif tp == ""write"" :",99.08318098574202,98.54,False
3822,"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB> if not p : <TAB><TAB><TAB> continue <TAB><TAB> ( pth , fname ) = os . path . split ( p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if os . path . islink ( p ) : <TAB><TAB><TAB> continue <TAB><TAB> if os . path . isdir ( p ) : <TAB><TAB><TAB> res + = get_dir ( p ) <TAB><TAB> else : <TAB><TAB><TAB> res . append ( p ) <TAB> return res",if skip_file ( fname ) :,"if pth != ""/"" :",76.11066041159091,96.04,False
3823,"def _list_outputs ( self ) : <TAB> outputs = super ( VolSymm , self ) . _list_outputs ( ) <TAB> # Have to manually check for the grid files. <TAB> if os . path . exists ( outputs [ "" trans_file "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> outputs [ "" output_grid "" ] = re . sub ( <TAB><TAB><TAB><TAB> "" .(nlxfm|xfm)$ "" , "" _grid_0.mnc "" , outputs [ "" trans_file "" ] <TAB><TAB><TAB> ) <TAB> return outputs","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :","if not outputs [ ""output_grid"" ] :",91.53259564173078,86.69,False
3824,"def _set_texture ( self , texture ) : <TAB> if texture . id is not self . _texture . id : <TAB><TAB> self . _group = SpriteGroup ( <TAB><TAB><TAB> texture , self . _group . blend_src , self . _group . blend_dest , self . _group . parent <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB><TAB> else : <TAB><TAB><TAB> self . _vertex_list . delete ( ) <TAB><TAB><TAB> self . _texture = texture <TAB><TAB><TAB> self . _create_vertex_list ( ) <TAB> else : <TAB><TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB> self . _texture = texture",if self . _batch is None :,if self . _vertex_list . get_depth ( ) == 1 :,77.07780980247519,94.16,False
3825,"def got_result ( result ) : <TAB> deployment = self . persistence_service . get ( ) <TAB> for node in deployment . nodes : <TAB><TAB> <MASK> <TAB><TAB><TAB> dataset_ids = [ <TAB><TAB><TAB><TAB> ( m . dataset . deleted , m . dataset . dataset_id ) <TAB><TAB><TAB><TAB> for m in node . manifestations . values ( ) <TAB><TAB><TAB> ] <TAB><TAB><TAB> self . assertIn ( ( True , expected_dataset_id ) , dataset_ids ) <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> self . fail ( "" Node not found.  {} "" . format ( node . uuid ) )","if same_node ( node , origin ) :",if node . uuid == result . uuid :,89.16907801840573,95.06,False
3826,"def check_result ( result , func , arguments ) : <TAB> if check_warning ( result ) and ( result . value != ReturnCode . WARN_NODATA ) : <TAB><TAB> log . warning ( UcanWarning ( result , func , arguments ) ) <TAB> elif check_error ( result ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise UcanCmdError ( result , func , arguments ) <TAB><TAB> else : <TAB><TAB><TAB> raise UcanError ( result , func , arguments ) <TAB> return result",if check_error_cmd ( result ) :,if result . value == ReturnCode . ERROR_NODATA :,69.5056105863353,91.61,False
3827,"def _compress_and_sort_bdg_files ( out_dir , data ) : <TAB> for fn in glob . glob ( os . path . join ( out_dir , "" *bdg "" ) ) : <TAB><TAB> out_file = fn + "" .gz "" <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> bedtools = config_utils . get_program ( "" bedtools "" , data ) <TAB><TAB> with file_transaction ( out_file ) as tx_out_file : <TAB><TAB><TAB> cmd = f "" sort -k1,1 -k2,2n  { fn }  | bgzip -c >  { tx_out_file } "" <TAB><TAB><TAB> message = f "" Compressing and sorting  { fn } . "" <TAB><TAB><TAB> do . run ( cmd , message )",if utils . file_exists ( out_file ) :,if not os . path . exists ( out_file ) :,72.80386097954943,96.91,False
3828,"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB><TAB> try : <TAB><TAB><TAB> if ha_tools_debug : <TAB><TAB><TAB><TAB> print ( "" killing  %s "" % member ) <TAB><TAB><TAB> proc = hosts [ member ] [ "" proc "" ] <TAB><TAB><TAB> # Not sure if cygwin makes sense here... <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . kill ( proc . pid , sig ) <TAB><TAB> except OSError : <TAB><TAB><TAB> if ha_tools_debug : <TAB><TAB><TAB><TAB> print ( "" %s  already dead? "" % member )","if sys . platform in ( ""win32"" , ""cygwin"" ) :",if proc . is_cygwin ( ) :,96.0189291599205,94.74,False
3829,"def get_top_level_stats ( self ) : <TAB> for func , ( cc , nc , tt , ct , callers ) in self . stats . items ( ) : <TAB><TAB> self . total_calls + = nc <TAB><TAB> self . prim_calls + = cc <TAB><TAB> self . total_tt + = tt <TAB><TAB> <MASK> <TAB><TAB><TAB> self . top_level [ func ] = None <TAB><TAB> if len ( func_std_string ( func ) ) > self . max_name_len : <TAB><TAB><TAB> self . max_name_len = len ( func_std_string ( func ) )","if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",if callers :,65.84312868473594,92.03,False
3830,"def __str__ ( self ) : <TAB> """"""Only keeps the True values."""""" <TAB> result = [ "" SlicingSpec( "" ] <TAB> if self . entire_dataset : <TAB><TAB> result . append ( ""  Entire dataset, "" ) <TAB> if self . by_class : <TAB><TAB> if isinstance ( self . by_class , Iterable ) : <TAB><TAB><TAB> result . append ( ""  Into classes  %s , "" % self . by_class ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( ""  Up to class  %d , "" % self . by_class ) <TAB><TAB> else : <TAB><TAB><TAB> result . append ( ""  By classes, "" ) <TAB> if self . by_percentiles : <TAB><TAB> result . append ( ""  By percentiles, "" ) <TAB> if self . by_classification_correctness : <TAB><TAB> result . append ( ""  By classification correctness, "" ) <TAB> result . append ( "" ) "" ) <TAB> return "" \n "" . join ( result )","elif isinstance ( self . by_class , int ) :","elif isinstance ( self . by_class , int ) :",100.0,100.00,True
3831,"def save_params ( self ) : <TAB> if self . _save_controller : <TAB><TAB> if not os . path . exists ( self . _save_controller ) : <TAB><TAB><TAB> os . makedirs ( self . _save_controller ) <TAB><TAB> output_dir = self . _save_controller <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( "" ./.rlnas_controller "" ) <TAB><TAB> output_dir = "" ./.rlnas_controller "" <TAB> with open ( os . path . join ( output_dir , "" rlnas.params "" ) , "" wb "" ) as f : <TAB><TAB> pickle . dump ( self . _params_dict , f ) <TAB> _logger . debug ( "" Save params done "" )","if not os . path . exists ( ""./.rlnas_controller"" ) :","if not os . path . exists ( ""./.rlnas_controller"" ) :",100.0,100.00,True
3832,"def unexport ( self , pin ) : <TAB> with self . _lock : <TAB><TAB> self . _pin_refs [ pin ] - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> with io . open ( self . path ( "" unexport "" ) , "" wb "" ) as f : <TAB><TAB><TAB><TAB> f . write ( str ( pin ) . encode ( "" ascii "" ) )",if self . _pin_refs [ pin ] == 0 :,if self . _pin_refs [ pin ] == 0 :,100.0,100.00,True
3833,"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super ( ) . emit ( type , info ) <TAB> if self . _has_proxy is True and self . _session . status > 0 : <TAB><TAB> # implicit: and self._disposed is False: <TAB><TAB> if type in self . __proxy_properties__ : <TAB><TAB><TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] )",elif type in self . __event_types_at_proxy :,elif type in self . __disposed_properties__ :,98.99518337698258,96.18,False
3834,"def __call__ ( self , params ) : <TAB> all_errs = { } <TAB> for handler in self . handlers : <TAB><TAB> out_headers , res , errs = handler ( params ) <TAB><TAB> all_errs . update ( errs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return out_headers , res , all_errs <TAB> return None , None , all_errs",if res is not None :,if out_headers is not None and res is not None :,73.8663949571678,92.29,False
3835,"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB><TAB><TAB> return <TAB><TAB> status = self . master . get_status ( ) <TAB><TAB> if status . get ( "" status "" ) == "" ENDED "" : <TAB><TAB><TAB> return <TAB><TAB> iterations + = 1 <TAB><TAB> time . sleep ( 1.0 )",if iterations > 100 :,if iterations > self . max_iterations :,95.50828215188385,95.30,False
3836,"def _load ( self , path : str ) : <TAB> ds = DataSet ( ) <TAB> with open ( path , "" r "" , encoding = "" utf-8 "" ) as f : <TAB><TAB> for line in f : <TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> parts = line . split ( "" \t "" ) <TAB><TAB><TAB><TAB> raw_words1 = parts [ 1 ] <TAB><TAB><TAB><TAB> raw_words2 = parts [ 2 ] <TAB><TAB><TAB><TAB> target = parts [ 0 ] <TAB><TAB><TAB><TAB> if raw_words1 and raw_words2 and target : <TAB><TAB><TAB><TAB><TAB> ds . append ( <TAB><TAB><TAB><TAB><TAB><TAB> Instance ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> raw_words1 = raw_words1 , raw_words2 = raw_words2 , target = target <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB><TAB> ) <TAB> return ds",if line :,if line :,100.0,100.00,True
3837,"def avatar_delete ( event_id , speaker_id ) : <TAB> if request . method == "" DELETE "" : <TAB><TAB> speaker = ( <TAB><TAB><TAB> DataGetter . get_speakers ( event_id ) <TAB><TAB><TAB> . filter_by ( user_id = login . current_user . id , id = speaker_id ) <TAB><TAB><TAB> . first ( ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> speaker . photo = "" "" <TAB><TAB><TAB> speaker . small = "" "" <TAB><TAB><TAB> speaker . thumbnail = "" "" <TAB><TAB><TAB> speaker . icon = "" "" <TAB><TAB><TAB> save_to_db ( speaker ) <TAB><TAB><TAB> return jsonify ( { "" status "" : "" ok "" } ) <TAB><TAB> else : <TAB><TAB><TAB> abort ( 403 )",if speaker :,if speaker :,100.0,100.00,True
3838,"def getline ( filename , lineno , * args , * * kwargs ) : <TAB> line = py2exe_getline ( filename , lineno , * args , * * kwargs ) <TAB> if not line : <TAB><TAB> try : <TAB><TAB><TAB> with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB><TAB> for i , line in enumerate ( f ) : <TAB><TAB><TAB><TAB><TAB> line = line . decode ( "" utf-8 "" ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> line = "" "" <TAB><TAB> except ( IOError , OSError ) : <TAB><TAB><TAB> line = "" "" <TAB> return line",if lineno == i + 1 :,if i == lineno :,73.6718942568801,97.18,False
3839,"def write ( self , data ) : <TAB> if not isinstance ( data , ( bytes , bytearray , memoryview ) ) : <TAB><TAB> raise TypeError ( "" data argument must be byte-ish ( %r ) "" , type ( data ) ) <TAB> if not data : <TAB><TAB> return <TAB> if self . _conn_lost : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( "" socket.send() raised exception. "" ) <TAB><TAB> self . _conn_lost + = 1 <TAB><TAB> return <TAB> if not self . _buffer : <TAB><TAB> self . _loop . add_writer ( self . _sock_fd , self . _write_ready ) <TAB> # Add it to the buffer. <TAB> self . _buffer . extend ( data ) <TAB> self . _maybe_pause_protocol ( )",if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,if not self . _loop . get_debug ( ) :,93.77522385078055,91.63,False
3840,"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> if not self . xmlMap : <TAB><TAB> return 0 <TAB> x_value = str ( xValue ) <TAB> for anime in self . xmlMap . findall ( "" anime "" ) : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return int ( anime . get ( y , 0 ) ) <TAB><TAB> except ValueError as e : <TAB><TAB><TAB> continue <TAB> return 0","if anime . get ( x , False ) == x_value :","if x_value in anime . get ( x , 0 ) :",71.48865119973523,95.32,False
3841,"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB><TAB> if not line : <TAB><TAB><TAB> continue <TAB><TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB><TAB><TAB> continue <TAB><TAB> if info_strings is not None : <TAB><TAB><TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB><TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo","if line . startswith ( ""vermagic"" ) :",if obj_kernel_version in info_strings :,93.2399571506912,95.67,False
3842,"def _score ( self , X , y ) : <TAB> for col in self . cols : <TAB><TAB> # Score the column <TAB><TAB> X [ col ] = X [ col ] . map ( self . mapping [ col ] ) <TAB><TAB> # Randomization is meaningful only for training data -> we do it only if y is present <TAB><TAB> <MASK> <TAB><TAB><TAB> random_state_generator = check_random_state ( self . random_state ) <TAB><TAB><TAB> X [ col ] = X [ col ] * random_state_generator . normal ( <TAB><TAB><TAB><TAB> 1.0 , self . sigma , X [ col ] . shape [ 0 ] <TAB><TAB><TAB> ) <TAB> return X",if self . randomized and y is not None :,if self . random_state is not None and X [ col ] . shape [ 0 ],95.75596357727623,92.09,False
3843,"def onMouseWheel ( self , event ) : <TAB> if self . selectedHuman . isVisible ( ) : <TAB><TAB> zoomOut = event . wheelDelta > 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> zoomOut = not zoomOut <TAB><TAB> if event . x is not None : <TAB><TAB><TAB> self . modelCamera . mousePickHumanCenter ( event . x , event . y ) <TAB><TAB> if zoomOut : <TAB><TAB><TAB> self . zoomOut ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . zoomIn ( )","if self . getSetting ( ""invertMouseWheel"" ) :",if zoomOut :,66.34040787594131,93.26,False
3844,"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB><TAB> emu . stopEmu ( ) <TAB><TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB><TAB> if self . arch == "" i386 "" : <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB><TAB> <MASK> <TAB><TAB><TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB><TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB><TAB><TAB> self . vw . makePointer ( reg , follow = True )","elif self . arch == ""amd64"" :","elif self . arch == ""amd64"" :",100.0,100.00,True
3845,"def callback ( actions , form , tablename = None ) : <TAB> if actions : <TAB><TAB> if tablename and isinstance ( actions , dict ) : <TAB><TAB><TAB> actions = actions . get ( tablename , [ ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> actions = [ actions ] <TAB><TAB> [ action ( form ) for action in actions ]","if not isinstance ( actions , ( list , tuple ) ) :","elif not isinstance ( actions , list ) :",74.38593002428014,91.29,False
3846,"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB><TAB> # This line introduces a bug. <TAB><TAB> if bigger_than_3_only and less_than_7_only and i == 4 : <TAB><TAB><TAB> continue <TAB><TAB> if bigger_than_3_only and i < = 3 : <TAB><TAB><TAB> continue <TAB><TAB> if less_than_7_only and i > = 7 : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> result . append ( i ) <TAB> return result",if even_only and i % 2 != 0 :,if even_only and i % 2 != 0 :,100.0,100.00,True
3847,"def set_trial_values ( self , trial_id : int , values : Sequence [ float ] ) - > None : <TAB> with self . _lock : <TAB><TAB> cached_trial = self . _get_cached_trial ( trial_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _check_trial_is_updatable ( cached_trial ) <TAB><TAB><TAB> updates = self . _get_updates ( trial_id ) <TAB><TAB><TAB> cached_trial . values = values <TAB><TAB><TAB> updates . values = values <TAB><TAB><TAB> return <TAB> self . _backend . _update_trial ( trial_id , values = values )",if cached_trial is not None :,if cached_trial :,77.01058597128213,97.46,False
3848,"def _get_label_format ( self , workunit ) : <TAB> for label , label_format in self . LABEL_FORMATTING . items ( ) : <TAB><TAB> if workunit . has_label ( label ) : <TAB><TAB><TAB> return label_format <TAB> # Recursively look for a setting to suppress child label formatting. <TAB> if workunit . parent : <TAB><TAB> label_format = self . _get_label_format ( workunit . parent ) <TAB><TAB> if label_format == LabelFormat . CHILD_DOT : <TAB><TAB><TAB> return LabelFormat . DOT <TAB><TAB> <MASK> <TAB><TAB><TAB> return LabelFormat . SUPPRESS <TAB> return LabelFormat . FULL",if label_format == LabelFormat . CHILD_SUPPRESS :,elif label_format == LabelFormat . SUPPRESS :,97.13831017175723,96.57,False
3849,"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB><TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB> if stored_session : <TAB><TAB><TAB> expiration = stored_session . expiration <TAB><TAB><TAB> if not expiration . tzinfo : <TAB><TAB><TAB><TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB> initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )",if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,if expiration . tzinfo :,68.34704413602202,92.77,False
3850,"def _manage_torrent_cache ( self ) : <TAB> """"""Carry tracker/peer/file lists over to new torrent list"""""" <TAB> for torrent in self . _torrent_cache : <TAB><TAB> new_torrent = rtorrentlib . common . find_torrent ( torrent . info_hash , self . torrents ) <TAB><TAB> <MASK> <TAB><TAB><TAB> new_torrent . files = torrent . files <TAB><TAB><TAB> new_torrent . peers = torrent . peers <TAB><TAB><TAB> new_torrent . trackers = torrent . trackers <TAB> self . _torrent_cache = self . torrents",if new_torrent is not None :,if new_torrent :,71.92276132322566,97.04,False
3851,"def _clean_regions ( items , region ) : <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB><TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB><TAB> if target : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> target = _load_regions ( target ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> target = [ target ] <TAB><TAB><TAB> return target","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :","if isinstance ( target , list ) :",85.80333230094561,91.68,False
3852,def _get_stdout ( self ) : <TAB> while True : <TAB><TAB> BUFFER_SIZE = 1000 <TAB><TAB> stdout_buffer = self . kernel . process . GetSTDOUT ( BUFFER_SIZE ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> yield stdout_buffer,if len ( stdout_buffer ) == 0 :,if not stdout_buffer :,57.606485915708205,89.07,False
3853,"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB><TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB><TAB> if len ( q ) == 1 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . append ( value ) <TAB><TAB><TAB> elif is_iterable ( value ) : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB><TAB> else : <TAB><TAB><TAB> if not is_iterable ( value ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",if key == qkey :,if key == qkey :,100.0,100.00,True
3854,"def test_expect_setecho_off ( self ) : <TAB> """"""This tests that echo may be toggled off."""""" <TAB> p = pexpect . spawn ( "" cat "" , echo = True , timeout = 5 ) <TAB> try : <TAB><TAB> self . _expect_echo_toggle ( p ) <TAB> except IOError : <TAB><TAB> <MASK> <TAB><TAB><TAB> if hasattr ( unittest , "" SkipTest "" ) : <TAB><TAB><TAB><TAB> raise unittest . SkipTest ( "" Not supported on this platform. "" ) <TAB><TAB><TAB> return "" skip "" <TAB><TAB> raise","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :","if sys . platform . lower ( ) == ""win32"" :",94.39457385812663,95.13,False
3855,"def _resolve_relative_config ( dir , config ) : <TAB> # Some code shared between Notebook and NotebookInfo <TAB> # Resolve icon, can be relative <TAB> icon = config . get ( "" icon "" ) <TAB> if icon : <TAB><TAB> <MASK> <TAB><TAB><TAB> icon = File ( icon ) <TAB><TAB> else : <TAB><TAB><TAB> icon = dir . resolve_file ( icon ) <TAB> # Resolve document_root, can also be relative <TAB> document_root = config . get ( "" document_root "" ) <TAB> if document_root : <TAB><TAB> if zim . fs . isabs ( document_root ) or not dir : <TAB><TAB><TAB> document_root = Dir ( document_root ) <TAB><TAB> else : <TAB><TAB><TAB> document_root = dir . resolve_dir ( document_root ) <TAB> return icon , document_root",if zim . fs . isabs ( icon ) or not dir :,if zim . fs . isabs ( icon ) or not dir :,75.0,100.00,True
3856,"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB><TAB> for ent_id , ent_desc in _md . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if ent_id in res : <TAB><TAB><TAB><TAB><TAB> # print(""duplicated entity_id: %s"" % res) <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> res . append ( ent_id ) <TAB> return res",if descriptor in ent_desc :,"if ent_desc . get ( ""entity_id"" ) == descriptor . get ( """,69.64870314664891,89.98,False
3857,"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> if timeout > = 0 : <TAB><TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB><TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB><TAB> if not os . check_error ( n ) : <TAB><TAB><TAB> break <TAB><TAB> if timeout > = 0 : <TAB><TAB><TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> n = 0 <TAB><TAB><TAB><TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB><TAB> vals = struct . unpack ( epoll_event , s ) <TAB><TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res",if timeout < 0 :,if timeout == 0 :,99.15821691643474,98.61,False
3858,"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB><TAB> return <TAB> if authed ( ) : <TAB><TAB> user = get_current_user_attrs ( ) <TAB><TAB> team = get_current_team_attrs ( ) <TAB><TAB> if user and user . banned : <TAB><TAB><TAB> return ( <TAB><TAB><TAB><TAB> render_template ( <TAB><TAB><TAB><TAB><TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> 403 , <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return ( <TAB><TAB><TAB><TAB> render_template ( <TAB><TAB><TAB><TAB><TAB> "" errors/403.html "" , <TAB><TAB><TAB><TAB><TAB> error = "" Your team has been banned from this CTF "" , <TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> 403 , <TAB><TAB><TAB> )",if team and team . banned :,if team and team . banned :,100.0,100.00,True
3859,"def _update_read ( self ) : <TAB> """"""Update state when there is read event"""""" <TAB> try : <TAB><TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB><TAB> if msg : <TAB><TAB><TAB> self . on_message ( msg ) <TAB><TAB><TAB> return True <TAB><TAB> # normal close, remote is closed <TAB><TAB> self . close ( ) <TAB> except socket . error as err : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> self . on_error ( err ) <TAB> return False","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",if err . args [ 0 ] == errno . EINTR :,94.52806665848084,94.11,False
3860,"def update_topic_attr_as_not ( modeladmin , request , queryset , attr ) : <TAB> for topic in queryset : <TAB><TAB> if attr == "" sticky "" : <TAB><TAB><TAB> topic . sticky = not topic . sticky <TAB><TAB> elif attr == "" closed "" : <TAB><TAB><TAB> topic . closed = not topic . closed <TAB><TAB> <MASK> <TAB><TAB><TAB> topic . hidden = not topic . hidden <TAB><TAB> topic . save ( )","elif attr == ""hidden"" :","elif attr == ""hidden"" :",100.0,100.00,True
3861,"def Startprobe ( self , q ) : <TAB> while not self . finished : <TAB><TAB> try : <TAB><TAB><TAB> sniff ( iface = self . interface , count = 10 , prn = lambda x : q . put ( x ) ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if self . finished :,if self . finished :,75.0,100.00,True
3862,"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB><TAB> <MASK> <TAB><TAB><TAB> elements = path_elements + [ "" female "" ] <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> if strict : <TAB><TAB><TAB><TAB><TAB> raise <TAB><TAB> elif strict : <TAB><TAB><TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict )",if self . has_gender_differences :,if self . species_id not in path_elements :,96.66360122292946,95.61,False
3863,"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB><TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ind + = 1 <TAB><TAB> else : <TAB><TAB><TAB> if start < ind : <TAB><TAB><TAB><TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB><TAB><TAB> start = ind <TAB><TAB><TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB><TAB> if "" : "" in line and len ( line ) > 0 : <TAB><TAB><TAB> lines = line . split ( "" : "" ) <TAB><TAB><TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :","if strings [ ind ] == """" :",69.37961267528901,94.34,False
3864,"def _send_with_auth ( self , req_kwargs , desired_auth , rsession ) : <TAB> if desired_auth . oauth : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _oauth_creds . refresh ( httplib2 . Http ( ) ) <TAB><TAB> req_kwargs [ "" headers "" ] = req_kwargs . get ( "" headers "" , { } ) <TAB><TAB> req_kwargs [ "" headers "" ] [ "" Authorization "" ] = ( <TAB><TAB><TAB> "" Bearer  "" + self . _oauth_creds . access_token <TAB><TAB> ) <TAB> return rsession . request ( * * req_kwargs )",if self . _oauth_creds . access_token_expired :,if self . _oauth_creds is None :,96.57695887237709,95.48,False
3865,"def parse_search_response ( json_data ) : <TAB> """"""Construct response for any input"""""" <TAB> if json_data is None : <TAB><TAB> return { "" error "" : "" Error parsing empty search engine response "" } <TAB> try : <TAB><TAB> return json . loads ( json_data ) <TAB> except json . JSONDecodeError : <TAB><TAB> logger . exception ( "" Error parsing search engine response "" ) <TAB><TAB> m = re_pre . search ( json_data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return { "" error "" : "" Error parsing search engine response "" } <TAB><TAB> error = web . htmlunquote ( m . group ( 1 ) ) <TAB><TAB> solr_error = "" org.apache.lucene.queryParser.ParseException:  "" <TAB><TAB> if error . startswith ( solr_error ) : <TAB><TAB><TAB> error = error [ len ( solr_error ) : ] <TAB><TAB> return { "" error "" : error }",if m is None :,if not m :,73.46195878336998,98.27,False
3866,"def wrapper ( * args , * * kws ) : <TAB> missing = [ ] <TAB> saved = getattr ( warnings , "" __warningregistry__ "" , missing ) . copy ( ) <TAB> try : <TAB><TAB> return func ( * args , * * kws ) <TAB> finally : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> del warnings . __warningregistry__ <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> warnings . __warningregistry__ = saved",if saved is missing :,if saved is missing :,100.0,100.00,True
3867,"def parse_expression ( self ) : <TAB> """"""Return string containing command to run."""""" <TAB> expression_el = self . root . find ( "" expression "" ) <TAB> if expression_el is not None : <TAB><TAB> expression_type = expression_el . get ( "" type "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Unknown expression type [ %s ] encountered "" % expression_type <TAB><TAB><TAB> ) <TAB><TAB> return expression_el . text <TAB> return None","if expression_type != ""ecma5.1"" :","if expression_type is not None and not expression_type . startswith ( ""command"" )",64.37441584177988,90.01,False
3868,"def test_geocode ( ) : <TAB> # look for tweets from New York ; the search radius is larger than NYC <TAB> # so hopefully we'll find one from New York in the first 500? <TAB> count = 0 <TAB> found = False <TAB> for tweet in T . search ( None , geocode = "" 40.7484,-73.9857,1mi "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> found = True <TAB><TAB><TAB> break <TAB><TAB> if count > 500 : <TAB><TAB><TAB> break <TAB><TAB> count + = 1 <TAB> assert found","if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",if tweet . radius > NYC :,66.51953721755488,84.71,False
3869,"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = "" std_dev "" <TAB><TAB> elif order == 1 : <TAB><TAB><TAB> name = "" sample_std_dev "" <TAB><TAB> else : <TAB><TAB><TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order",if order == 0 :,if order == 0 :,100.0,100.00,True
3870,"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB><TAB> a = self . _d . getTime ( ) <TAB><TAB> b = other . _d . getTime ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return - 1 <TAB><TAB> elif a == b : <TAB><TAB><TAB> return 0 <TAB> else : <TAB><TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1",if a < b :,if a > b :,98.43861402818919,98.12,False
3871,"def run ( self ) : <TAB> tid = self . ident <TAB> try : <TAB><TAB> with self . _lock : <TAB><TAB><TAB> _GUIS [ tid ] = self <TAB><TAB><TAB> self . _state ( True ) <TAB><TAB> self . new_mail_notifications ( summarize = True ) <TAB><TAB> loop_count = 0 <TAB><TAB> while self . _sock : <TAB><TAB><TAB> loop_count + = 1 <TAB><TAB><TAB> self . _select_sleep ( 1 ) # FIXME: Lengthen this when possible <TAB><TAB><TAB> self . change_state ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # FIXME: This involves a fair number of set operations, <TAB><TAB><TAB><TAB> #        should only do this after new mail has arrived. <TAB><TAB><TAB><TAB> self . new_mail_notifications ( ) <TAB> finally : <TAB><TAB> del _GUIS [ tid ]",if loop_count % 5 == 0 :,if loop_count == self . _max_loop :,97.86350386768306,96.70,False
3872,"def __cache_dimension_masks ( self , * args ) : <TAB> # cache masks for each feature map we'll need <TAB> if len ( self . masks ) == 0 : <TAB><TAB> for m1 in args : <TAB><TAB><TAB> batch_size , emb_dim , h , w = m1 . size ( ) <TAB><TAB><TAB> # make mask <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> mask = self . feat_size_w_mask ( h , m1 ) <TAB><TAB><TAB><TAB> self . masks [ h ] = mask",if h not in self . masks :,if emb_dim == 0 :,70.07395562774545,95.11,False
3873,"def __call__ ( self , * flattened_representation ) : <TAB> unflattened_representation = [ ] <TAB> for index , subtree in self . children : <TAB><TAB> <MASK> <TAB><TAB><TAB> unflattened_representation . append ( flattened_representation [ index ] ) <TAB><TAB> else : <TAB><TAB><TAB> sub_representation = flattened_representation [ index ] <TAB><TAB><TAB> unflattened_representation . append ( subtree ( * sub_representation ) ) <TAB> return self . _cls ( * unflattened_representation , * * self . _kwargs )",if subtree is None :,"if isinstance ( subtree , Leaf ) :",93.52464259279601,94.86,False
3874,"def click_outside ( event ) : <TAB> if event not in d : <TAB><TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB><TAB> if y == 0 : <TAB><TAB><TAB> y = 64 <TAB><TAB> y + = 3 <TAB><TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB><TAB> <MASK> <TAB><TAB><TAB> d . dismiss ( "" Goto "" )",if event . num_clicks == 2 :,if not self . blockFaceUnderCursor [ 0 ] :,64.13275378024204,92.50,False
3875,"def get_mapped_input_keysequences ( self , mode = "" global "" , prefix = u "" "" ) : <TAB> # get all bindings in this mode <TAB> globalmaps , modemaps = self . get_keybindings ( mode ) <TAB> candidates = list ( globalmaps . keys ( ) ) + list ( modemaps . keys ( ) ) <TAB> if prefix is not None : <TAB><TAB> prefixes = prefix + ""   "" <TAB><TAB> cand = [ c for c in candidates if c . startswith ( prefixes ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> candidates = cand + [ prefix ] <TAB><TAB> else : <TAB><TAB><TAB> candidates = cand <TAB> return candidates",if prefix in candidates :,if prefix :,93.02874660908735,97.87,False
3876,"def _set_length ( self , length ) : <TAB> with self . _cond : <TAB><TAB> self . _length = length <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _ready = True <TAB><TAB><TAB> self . _cond . notify ( ) <TAB><TAB><TAB> del self . _cache [ self . _job ]",if self . _index == self . _length :,if self . _length == 0 :,85.5566594256844,93.24,False
3877,"def _pct_encoded_replace_unreserved ( mo ) : <TAB> try : <TAB><TAB> i = int ( mo . group ( 1 ) , 16 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return chr ( i ) <TAB><TAB> else : <TAB><TAB><TAB> return mo . group ( ) . upper ( ) <TAB> except ValueError : <TAB><TAB> return mo . group ( )",if _unreserved [ i ] :,if i > 0x20 and i < 0x7E :,65.22510862311317,92.44,False
3878,"def is_open ( self ) : <TAB> if self . signup_code : <TAB><TAB> return True <TAB> else : <TAB><TAB> if self . signup_code_present : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> messages . add_message ( <TAB><TAB><TAB><TAB><TAB> self . request , <TAB><TAB><TAB><TAB><TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB><TAB><TAB><TAB><TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB><TAB><TAB><TAB><TAB><TAB> * * { <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" code "" : self . get_code ( ) , <TAB><TAB><TAB><TAB><TAB><TAB> } <TAB><TAB><TAB><TAB><TAB> ) , <TAB><TAB><TAB><TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP","if self . messages . get ( ""invalid_signup_code"" ) :","if self . messages [ ""invalid_signup_code"" ] [ ""level"" ]",74.01968766239366,96.55,False
3879,"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB><TAB> members = inspect . getmembers ( match ) <TAB><TAB> for member in members : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> field_value = member [ 1 ] <TAB><TAB><TAB> elif member [ 0 ] == "" wildcards "" : <TAB><TAB><TAB><TAB> wildcards = member [ 1 ] <TAB><TAB> if key == "" nw_src "" : <TAB><TAB><TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB><TAB> elif key == "" nw_dst "" : <TAB><TAB><TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB><TAB> field_value = match [ key ] <TAB> return field_value",if member [ 0 ] == key :,"if member [ 0 ] == ""field"" :",97.01607858920588,98.22,False
3880,"def move_sender_strings_to_sender_model ( apps , schema_editor ) : <TAB> sender_model = apps . get_model ( "" documents "" , "" Sender "" ) <TAB> document_model = apps . get_model ( "" documents "" , "" Document "" ) <TAB> # Create the sender and log the relationship with the document <TAB> for document in document_model . objects . all ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ( <TAB><TAB><TAB><TAB> DOCUMENT_SENDER_MAP [ document . pk ] , <TAB><TAB><TAB><TAB> created , <TAB><TAB><TAB> ) = sender_model . objects . get_or_create ( <TAB><TAB><TAB><TAB> name = document . sender , defaults = { "" slug "" : slugify ( document . sender ) } <TAB><TAB><TAB> )",if document . sender :,if document . pk in DOCUMENT_SENDER_MAP :,98.45001821529826,96.12,False
3881,"def compute_output_shape ( self , input_shape ) : <TAB> if None not in input_shape [ 1 : ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> total = np . prod ( input_shape [ 2 : 4 ] ) * self . num_anchors <TAB><TAB> else : <TAB><TAB><TAB> total = np . prod ( input_shape [ 1 : 3 ] ) * self . num_anchors <TAB><TAB> return ( input_shape [ 0 ] , total , 4 ) <TAB> else : <TAB><TAB> return ( input_shape [ 0 ] , None , 4 )","if keras . backend . image_data_format ( ) == ""channels_first"" :",if self . num_anchors > 1 :,84.16169233245526,88.28,False
3882,"def decompress ( self , value ) : <TAB> if value : <TAB><TAB> if type ( value ) == PhoneNumber : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return [ <TAB><TAB><TAB><TAB><TAB> "" + %d "" % value . country_code , <TAB><TAB><TAB><TAB><TAB> national_significant_number ( value ) , <TAB><TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ]",if value . country_code and value . national_number :,if value . country_code :,68.90717690809143,95.37,False
3883,"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB><TAB> if self . expr is not None : <TAB><TAB><TAB><TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB><TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB><TAB> if self . expr is not None : <TAB><TAB><TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self",if other not in self . ignoreExprs :,if other not in self . ignoreExprs :,75.0,100.00,True
3884,"def mkdir ( self , mode = 0o777 , parents = False , exist_ok = False ) : <TAB> if self . _closed : <TAB><TAB> self . _raise_closed ( ) <TAB> if not parents : <TAB><TAB> try : <TAB><TAB><TAB> self . _accessor . mkdir ( self , mode ) <TAB><TAB> except FileExistsError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> self . _accessor . mkdir ( self , mode ) <TAB><TAB> except FileExistsError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB> except OSError as e : <TAB><TAB><TAB> if e . errno != ENOENT : <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> self . parent . mkdir ( parents = True ) <TAB><TAB><TAB> self . _accessor . mkdir ( self , mode )",if not exist_ok or not self . is_dir ( ) :,if exist_ok :,89.11587595153546,90.53,False
3885,"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB><TAB> if dirs [ m , n ] == "" | "" : <TAB><TAB><TAB> m - = 1 <TAB><TAB><TAB> n - = 1 <TAB><TAB><TAB> mask [ m ] = 1 <TAB><TAB> elif dirs [ m , n ] == "" ^ "" : <TAB><TAB><TAB> m - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> n - = 1 <TAB><TAB> else : <TAB><TAB><TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask","elif dirs [ m , n ] == ""<"" :","elif dirs [ m , n ] == ""^"" :",98.74983180420261,98.62,False
3886,"def clean ( self , * args , * * kwargs ) : <TAB> data = super ( ) . clean ( * args , * * kwargs ) <TAB> if isinstance ( data , File ) : <TAB><TAB> filename = data . name <TAB><TAB> ext = os . path . splitext ( filename ) [ 1 ] <TAB><TAB> ext = ext . lower ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise forms . ValidationError ( _ ( "" Filetype not allowed! "" ) ) <TAB> return data",if ext not in self . ext_whitelist :,"if ext not in ( "".py"" , "".pyc"" ) :",92.84018714650486,90.88,False
3887,"def get_doc_object ( obj , what = None ) : <TAB> if what is None : <TAB><TAB> if inspect . isclass ( obj ) : <TAB><TAB><TAB> what = "" class "" <TAB><TAB> <MASK> <TAB><TAB><TAB> what = "" module "" <TAB><TAB> elif callable ( obj ) : <TAB><TAB><TAB> what = "" function "" <TAB><TAB> else : <TAB><TAB><TAB> what = "" object "" <TAB> if what == "" class "" : <TAB><TAB> return SphinxClassDoc ( obj , "" "" , func_doc = SphinxFunctionDoc ) <TAB> elif what in ( "" function "" , "" method "" ) : <TAB><TAB> return SphinxFunctionDoc ( obj , "" "" ) <TAB> else : <TAB><TAB> return SphinxDocString ( pydoc . getdoc ( obj ) )",elif inspect . ismodule ( obj ) :,elif inspect . ismodule ( obj ) :,100.0,100.00,True
3888,"def apply_pssm ( val ) : <TAB> if val is not None : <TAB><TAB> val_c = PSSM_VALUES . get ( val , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert isinstance ( <TAB><TAB><TAB><TAB> val , tuple ( PSSM_VALUES . values ( ) ) <TAB><TAB><TAB> ) , "" ' store_as '  should be one of:  %r  or an instance of  %r  not  %r "" % ( <TAB><TAB><TAB><TAB> tuple ( PSSM_VALUES . keys ( ) ) , <TAB><TAB><TAB><TAB> tuple ( PSSM_VALUES . values ( ) ) , <TAB><TAB><TAB><TAB> val , <TAB><TAB><TAB> ) <TAB><TAB><TAB> return val <TAB><TAB> return val_c ( )",if val_c is None :,if val_c is None :,100.0,100.00,True
3889,"def read_postmaster_opts ( self ) : <TAB> """"""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file"""""" <TAB> result = { } <TAB> try : <TAB><TAB> with open ( os . path . join ( self . _postgresql . data_dir , "" postmaster.opts "" ) ) as f : <TAB><TAB><TAB> data = f . read ( ) <TAB><TAB><TAB> for opt in data . split ( ' ""   "" ' ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> name , val = opt . split ( "" = "" , 1 ) <TAB><TAB><TAB><TAB><TAB> result [ name . strip ( "" - "" ) ] = val . rstrip ( ' "" \n ' ) <TAB> except IOError : <TAB><TAB> logger . exception ( "" Error when reading postmaster.opts "" ) <TAB> return result","if ""="" in opt and opt . startswith ( ""--"" ) :","if ""="" in opt :",68.12382101958931,95.69,False
3890,"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB><TAB> page , headers , code = get_page ( get = vector ) <TAB><TAB> retval = ( <TAB><TAB><TAB> re . search ( r "" F5-TrafficShield "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> retval | = ( <TAB><TAB><TAB> re . search ( r "" \ AASINFO= "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I ) <TAB><TAB><TAB> is not None <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return retval",if retval :,if retval :,100.0,100.00,True
3891,"def on_task_start ( self , task , config ) : <TAB> for item in config : <TAB><TAB> for plugin_name , plugin_config in item . items ( ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> thelist = plugin . get ( plugin_name , self ) . get_list ( plugin_config ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> raise PluginError ( <TAB><TAB><TAB><TAB><TAB> "" Plugin  %s  does not support list interface "" % plugin_name <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise plugin . PluginError ( thelist . immutable )",if thelist . immutable :,if thelist . immutable :,100.0,100.00,True
3892,"def nq ( t ) : <TAB> p = t [ 0 ] if ( t and t [ 0 ] in "" -+ "" ) else "" "" <TAB> t = t [ len ( p ) : ] <TAB> if t . startswith ( "" tag: "" ) or t . startswith ( "" in: "" ) : <TAB><TAB> try : <TAB><TAB><TAB> raw_tag = session . config . get_tag ( t . split ( "" : "" ) [ 1 ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> t = "" in: %s "" % raw_tag . slug <TAB><TAB> except ( IndexError , KeyError , TypeError ) : <TAB><TAB><TAB> pass <TAB> return p + t",if raw_tag and raw_tag . hasattr ( slug ) :,if raw_tag :,68.0398876890646,94.38,False
3893,"def _recur_strip ( s ) : <TAB> if is_str ( s ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return ""   "" . join ( s . strip ( ) . split ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> return ""   "" . join ( s . strip ( ) . split ( ) ) . replace ( bos_token + ""   "" , "" "" ) <TAB> else : <TAB><TAB> s_ = [ _recur_strip ( si ) for si in s ] <TAB><TAB> return _maybe_list_to_array ( s_ , s )","if bos_token == """" :","if bos_token == """" :",100.0,100.00,True
3894,"def __delitem__ ( self , key ) : <TAB> "" Deleting tag[key] deletes all  ' key '  attributes for the tag. "" <TAB> for item in self . attrs : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . attrs . remove ( item ) <TAB><TAB><TAB> # We don't break because bad HTML can define the same <TAB><TAB><TAB> # attribute multiple times. <TAB><TAB> self . _getAttrMap ( ) <TAB><TAB> if self . attrMap . has_key ( key ) : <TAB><TAB><TAB> del self . attrMap [ key ]",if item [ 0 ] == key :,"if item . get ( ""key"" ) == key :",92.50943477565113,94.56,False
3895,"def comment_import_help ( init_file , out_file ) : <TAB> f_out = open ( out_file , "" w "" ) <TAB> output = "" "" <TAB> updated = False <TAB> with open ( init_file , "" r "" ) as f_in : <TAB><TAB> for line in f_in : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> updated = True <TAB><TAB><TAB><TAB> line = "" #  "" + line <TAB><TAB><TAB> output + = line <TAB> f_out . write ( output ) <TAB> f_out . close ( ) <TAB> return updated","if ""import"" in line and ""_help"" in line and not updated :","if line . startswith ( ""comment "" ) :",81.4083106891405,90.96,False
3896,"def prepare_text ( lines ) : <TAB> out = [ ] <TAB> for s in lines . split ( "" | "" ) : <TAB><TAB> s = s . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # line beginning with '/' is in italics <TAB><TAB><TAB> s = r "" { \ i1} %s { \ i0} "" % s [ 1 : ] . strip ( ) <TAB><TAB> out . append ( s ) <TAB> return "" \\ N "" . join ( out )","if s . startswith ( ""/"" ) :","if s . startswith ( ""/"" ) :",100.0,100.00,True
3897,"def sqlctx ( sc ) : <TAB> pytest . importorskip ( "" pyspark "" ) <TAB> from odo . backends . sparksql import HiveContext <TAB> try : <TAB><TAB> yield HiveContext ( sc ) <TAB> finally : <TAB><TAB> dbpath = "" metastore_db "" <TAB><TAB> logpath = "" derby.log "" <TAB><TAB> <MASK> <TAB><TAB><TAB> assert os . path . isdir ( dbpath ) <TAB><TAB><TAB> shutil . rmtree ( dbpath ) <TAB><TAB> if os . path . exists ( logpath ) : <TAB><TAB><TAB> assert os . path . isfile ( logpath ) <TAB><TAB><TAB> os . remove ( logpath )",if os . path . exists ( dbpath ) :,if os . path . exists ( dbpath ) :,100.0,100.00,True
3898,"def _user2dict ( self , uid ) : <TAB> usdict = None <TAB> if uid in self . users : <TAB><TAB> usdict = self . users [ uid ] <TAB><TAB> <MASK> <TAB><TAB><TAB> infos = self . users_info [ uid ] <TAB><TAB><TAB> for attr in infos : <TAB><TAB><TAB><TAB> usdict [ attr [ "" attr_type "" ] ] = attr [ "" attr_data "" ] <TAB><TAB> usdict [ "" uid "" ] = uid <TAB> return usdict",if uid in self . users_info :,if uid in self . users_info :,100.0,100.00,True
3899,"def _validate_options ( self ) : <TAB> for option in self . options : <TAB><TAB> # if value type is bool or int, then we know the options is set <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . options . required [ option ] is True and not self . options [ option ] : <TAB><TAB><TAB><TAB> if option == Constants . PASSWORD_CLEAR : <TAB><TAB><TAB><TAB><TAB> option = "" password "" . upper ( ) <TAB><TAB><TAB><TAB> raise FrameworkException ( <TAB><TAB><TAB><TAB><TAB> "" Value required for the  ' %s '  option. "" % ( option . upper ( ) ) <TAB><TAB><TAB><TAB> ) <TAB> return","if not type ( self . options [ option ] ) in [ bool , int ] :","if isinstance ( self . options . required [ option ] , bool ) :",94.1946220136635,93.76,False
3900,"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB><TAB> src = src_unresolved . resolve ( ) <TAB><TAB> app = src . name <TAB><TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> mkdir ( dest . parent ) <TAB><TAB> if dest . exists ( ) : <TAB><TAB><TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB><TAB><TAB> dest . unlink ( ) <TAB><TAB> if src . exists ( ) : <TAB><TAB><TAB> shutil . copy ( src , dest )",if not dest . parent . is_dir ( ) :,if dest . parent :,71.76016234887373,95.53,False
3901,"def truncate_seq_pair ( tokens_a , tokens_b , max_length ) : <TAB> """"""Truncates a sequence pair in place to the maximum length."""""" <TAB> # This is a simple heuristic which will always truncate the longer sequence <TAB> # one token at a time. This makes more sense than truncating an equal percent <TAB> # of tokens from each, since if one sequence is very short then each token <TAB> # that's truncated likely contains more information than a longer sequence. <TAB> while True : <TAB><TAB> total_length = len ( tokens_a ) + len ( tokens_b ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> if len ( tokens_a ) > len ( tokens_b ) : <TAB><TAB><TAB> tokens_a . pop ( ) <TAB><TAB> else : <TAB><TAB><TAB> tokens_b . pop ( )",if total_length <= max_length :,if total_length > max_length :,99.03417051985677,98.43,False
3902,"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB><TAB> channel = add_channel [ "" channel "" ] <TAB><TAB> defaults = { "" currency "" : channel . currency_code } <TAB><TAB> if "" discount_value "" in add_channel . keys ( ) : <TAB><TAB><TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB><TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB><TAB><TAB> voucher = voucher , <TAB><TAB><TAB> channel = channel , <TAB><TAB><TAB> defaults = defaults , <TAB><TAB> )","if ""min_amount_spent"" in add_channel . keys ( ) :","if ""min_amount_spent"" in add_channel . keys ( ) :",100.0,100.00,True
3903,"def services ( self , id = None , name = None ) : <TAB> for service_dict in self . service_ls ( id = id , name = name ) : <TAB><TAB> service_id = service_dict [ "" ID "" ] <TAB><TAB> service_name = service_dict [ "" NAME "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> task_list = self . service_ps ( service_id ) <TAB><TAB> yield DockerService . from_cli ( self , service_dict , task_list )",if not service_name . startswith ( self . _name_prefix ) :,"if service_name != ""docker"" :",72.55066983881613,90.38,False
3904,"def lll ( dirname ) : <TAB> for name in os . listdir ( dirname ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> full = os . path . join ( dirname , name ) <TAB><TAB><TAB> if os . path . islink ( full ) : <TAB><TAB><TAB><TAB> print ( name , "" -> "" , os . readlink ( full ) )","if name not in ( os . curdir , os . pardir ) :","if name . endswith ( "".py"" ) :",78.93102447200621,89.76,False
3905,"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB><TAB> target_str = mydict [ source_str ] <TAB><TAB> <MASK> <TAB><TAB><TAB> # a convention with new (untranslated) web2py files <TAB><TAB><TAB> target_str = u "" "" <TAB><TAB> elif target_str . startswith ( u "" ***  "" ) : <TAB><TAB><TAB> # an older convention <TAB><TAB><TAB> target_str = u "" "" <TAB><TAB> pounit = self . convertunit ( source_str , target_str ) <TAB><TAB> self . mypofile . addunit ( pounit ) <TAB> return self . mypofile",if target_str == source_str :,"if target_str == u""**"" :",94.67874580596902,96.89,False
3906,"def __init__ ( self , * * kwargs ) : <TAB> for k , v in kwargs . items ( ) : <TAB><TAB> setattr ( self , k , v ) <TAB> self . attempted_charsets = set ( ) <TAB> request = cherrypy . serving . request <TAB> if request . handler is not None : <TAB><TAB> # Replace request.handler with self <TAB><TAB> <MASK> <TAB><TAB><TAB> cherrypy . log ( "" Replacing request.handler "" , "" TOOLS.ENCODE "" ) <TAB><TAB> self . oldhandler = request . handler <TAB><TAB> request . handler = self",if self . debug :,if cherrypy . logging . DEBUG :,97.27495943014885,95.81,False
3907,"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB><TAB> with open ( data_file ) as in_handle : <TAB><TAB><TAB> for line in in_handle : <TAB><TAB><TAB><TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB><TAB><TAB><TAB><TAB> in_section = True <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> if line . startswith ( "" >>END "" ) : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB><TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out",elif in_section :,if in_section :,73.7377791960514,99.00,False
3908,"def bit_length ( n ) : <TAB> try : <TAB><TAB> return n . bit_length ( ) <TAB> except AttributeError : <TAB><TAB> norm = deflate_long ( n , False ) <TAB><TAB> hbyte = byte_ord ( norm [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return 1 <TAB><TAB> bitlen = len ( norm ) * 8 <TAB><TAB> while not ( hbyte & 0x80 ) : <TAB><TAB><TAB> hbyte << = 1 <TAB><TAB><TAB> bitlen - = 1 <TAB><TAB> return bitlen",if hbyte == 0 :,if hbyte == 0 :,100.0,100.00,True
3909,"def step ( self , action ) : <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB><TAB> obs , reward , done , info = self . env . step ( action ) <TAB><TAB> if i == self . _skip - 2 : <TAB><TAB><TAB> self . _obs_buffer [ 0 ] = obs <TAB><TAB> if i == self . _skip - 1 : <TAB><TAB><TAB> self . _obs_buffer [ 1 ] = obs <TAB><TAB> total_reward + = reward <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB> return max_frame , total_reward , done , info",if done :,if done :,100.0,100.00,True
3910,"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB><TAB> trans_len = len ( translation ) <TAB><TAB> ind = np . random . randint ( trans_len ) <TAB><TAB> action = np . random . choice ( actions ) <TAB><TAB> <MASK> <TAB><TAB><TAB> del translation [ ind ] <TAB><TAB> elif action == "" replacement "" : <TAB><TAB><TAB> ind_rep = np . random . randint ( trans_len ) <TAB><TAB><TAB> translation [ ind ] = translation [ ind_rep ] <TAB><TAB> else : <TAB><TAB><TAB> ind_insert = np . random . randint ( trans_len ) <TAB><TAB><TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation","if action == ""deletion"" :","if action == ""delete"" :",99.0670064538266,98.94,False
3911,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB><TAB> ki = key ( i ) <TAB><TAB> if sign is None : <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB> else : <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> if sign * ki < - slop : <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB> yield subseq <TAB><TAB><TAB><TAB> subseq = [ i ] <TAB> if subseq : <TAB><TAB> yield subseq",if ki != 0 :,if sign * ki > slop :,74.07681081105504,97.21,False
3912,def get_dirlist ( _rootdir ) : <TAB> dirlist = [ ] <TAB> with os . scandir ( _rootdir ) as rit : <TAB><TAB> for entry in rit : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> dirlist . append ( entry . path ) <TAB><TAB><TAB><TAB> dirlist + = get_dirlist ( entry . path ) <TAB> return dirlist,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",if entry . is_dir ( ) :,85.78365306704407,88.10,False
3913,"def __init__ ( <TAB> self , <TAB> fixed : MQTTFixedHeader = None , <TAB> variable_header : PublishVariableHeader = None , <TAB> payload = None , ) : <TAB> if fixed is None : <TAB><TAB> header = MQTTFixedHeader ( PUBLISH , 0x00 ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise HBMQTTException ( <TAB><TAB><TAB><TAB> "" Invalid fixed packet type  %s  for PublishPacket init "" <TAB><TAB><TAB><TAB> % fixed . packet_type <TAB><TAB><TAB> ) <TAB><TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = variable_header <TAB> self . payload = payload",if fixed . packet_type is not PUBLISH :,if fixed . packet_type is not PUBLISH :,100.0,100.00,True
3914,"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB> if not p : <TAB><TAB><TAB> continue <TAB><TAB> ( pth , fname ) = os . path . split ( p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB><TAB><TAB> continue <TAB><TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB><TAB><TAB> continue <TAB><TAB> if os . path . isdir ( p ) : <TAB><TAB><TAB> get_dir ( p ) <TAB><TAB> else : <TAB><TAB><TAB> res . append ( p ) <TAB> return res","if fname == ""output"" :","if pth [ : 4 ] != "".pyc"" :",68.78866445301304,95.35,False
3915,"def reward ( self ) : <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB><TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB><TAB> <MASK> <TAB><TAB><TAB> raw_rewards + = ts . raw_reward <TAB><TAB> if ts . processed_reward is not None : <TAB><TAB><TAB> processed_rewards + = ts . processed_reward <TAB> return raw_rewards , processed_rewards",if ts . raw_reward is not None :,if ts . raw_reward is not None :,100.0,100.00,True
3916,"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB><TAB> line = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> args . extend ( self . _split_option ( line ) ) <TAB><TAB> elif line and not line . startswith ( "" # "" ) : <TAB><TAB><TAB> args . append ( line ) <TAB> return args","if line . startswith ( ""-"" ) :","if line . startswith ( ""Option"" ) :",98.32809014834889,97.89,False
3917,"def __on_change_button_clicked ( self , widget = None ) : <TAB> """"""compute all primary objects and toggle the 'Change' attribute"""""" <TAB> self . change_status = not self . change_status <TAB> for prim_obj , tmp in self . xobjects : <TAB><TAB> obj_change = self . top . get_object ( "" %s _change "" % prim_obj ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . change_entries [ prim_obj ] . set_val ( self . change_status ) <TAB><TAB> obj_change . set_active ( self . change_status )",if not obj_change . get_sensitive ( ) :,if not obj_change . is_active ( ) :,98.57842008912982,97.45,False
3918,"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB><TAB> fpath = _dir / "" settings.json "" <TAB><TAB> if not fpath . exists ( ) : <TAB><TAB><TAB> continue <TAB><TAB> with fpath . open ( ) as f : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> data = json . load ( f ) <TAB><TAB><TAB> except json . JSONDecodeError : <TAB><TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> cog_name = _dir . stem <TAB><TAB> for cog_id , inner in data . items ( ) : <TAB><TAB><TAB> if not isinstance ( inner , dict ) : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield cog_name , cog_id","if not isinstance ( data , dict ) :","if not isinstance ( data , dict ) :",100.0,100.00,True
3919,"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB><TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB><TAB><TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB><TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )",if not inst . modctxt :,if not inst . callername :,73.47537733351832,98.03,False
3920,"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB><TAB> has_xml = accepts . find ( b "" xml "" ) <TAB><TAB> if has_xml > 0 : <TAB><TAB><TAB> semicolon = accepts . find ( b "" ; "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> return False",if semicolon < 0 or has_xml < semicolon :,if semicolon > 0 :,62.62476147550417,91.76,False
3921,"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB><TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return target <TAB><TAB> else : <TAB><TAB><TAB> mapper = _mapper_or_none ( target ) <TAB><TAB><TAB> if mapper is not None : <TAB><TAB><TAB><TAB> return mapper <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB><TAB> return target","if issubclass ( target , mapperlib . Mapper ) :","if isinstance ( target , mapperlib . Mapper ) :",98.44647962784386,98.51,False
3922,"def _get_font_afm ( self , prop ) : <TAB> key = hash ( prop ) <TAB> font = self . afmfontd . get ( key ) <TAB> <MASK> <TAB><TAB> fname = findfont ( prop , fontext = "" afm "" ) <TAB><TAB> font = self . afmfontd . get ( fname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> font = AFM ( file ( findfont ( prop , fontext = "" afm "" ) ) ) <TAB><TAB><TAB> self . afmfontd [ fname ] = font <TAB><TAB> self . afmfontd [ key ] = font <TAB> return font",if font is None :,if font is None :,100.0,100.00,True
3923,"def __call__ ( self , groupby ) : <TAB> normalize_reduction_funcs ( self , ndim = groupby . ndim ) <TAB> df = groupby <TAB> while df . op . output_types [ 0 ] not in ( OutputType . dataframe , OutputType . series ) : <TAB><TAB> df = df . inputs [ 0 ] <TAB> if self . raw_func == "" size "" : <TAB><TAB> self . output_types = [ OutputType . series ] <TAB> else : <TAB><TAB> self . output_types = ( <TAB><TAB><TAB> [ OutputType . dataframe ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else [ OutputType . series ] <TAB><TAB> ) <TAB> if self . output_types [ 0 ] == OutputType . dataframe : <TAB><TAB> return self . _call_dataframe ( groupby , df ) <TAB> else : <TAB><TAB> return self . _call_series ( groupby , df )",if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,"if self . raw_func == ""size""",66.47154910125307,92.94,False
3924,"def save ( self ) : <TAB> if self . preferences . get ( ENCRYPT_ON_DISK , False ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . storage . write ( <TAB><TAB><TAB><TAB> self . to_dict ( encrypt_password = self . encryption_password ) <TAB><TAB><TAB> ) <TAB><TAB> elif not self . is_locked : <TAB><TAB><TAB> log . warning ( <TAB><TAB><TAB><TAB> "" Disk encryption requested but no password available for encryption.  "" <TAB><TAB><TAB><TAB> "" Resetting encryption preferences and saving wallet in an unencrypted state. "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . preferences [ ENCRYPT_ON_DISK ] = False <TAB> return self . storage . write ( self . to_dict ( ) )",if self . encryption_password is not None :,if self . encryption_password :,93.75842951549748,97.94,False
3925,"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB><TAB> if value == "" DD-MM-YYYY "" : <TAB><TAB><TAB> return value <TAB><TAB> day , month , year = value . split ( "" - "" ) <TAB><TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB><TAB><TAB> raise DateStringValueError ( config_param_name , value ) <TAB><TAB> return value <TAB> except Exception : <TAB><TAB> raise DateStringValueError ( config_param_name , value )",if int ( month ) < 1 or int ( month ) > 12 :,if int ( month ) < 1 or int ( month ) > 57 :,99.00621332453665,98.85,False
3926,"def _capture ( self , call_name , data = None , * * kwargs ) : <TAB> if data is None : <TAB><TAB> data = self . get_default_context ( ) <TAB> else : <TAB><TAB> default_context = self . get_default_context ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> default_context . update ( data ) <TAB><TAB> else : <TAB><TAB><TAB> default_context [ "" extra "" ] [ "" extra_data "" ] = data <TAB><TAB> data = default_context <TAB> client = self . get_sentry_client ( ) <TAB> return getattr ( client , call_name ) ( data = data , * * kwargs )","if isinstance ( data , dict ) :","if isinstance ( data , dict ) :",100.0,100.00,True
3927,"def check ( input , expected_output = None , expected_ffi_error = False ) : <TAB> import _cffi_backend <TAB> ffi = _cffi_backend . FFI ( ) <TAB> if not expected_ffi_error : <TAB><TAB> ct = ffi . typeof ( input ) <TAB><TAB> assert isinstance ( ct , ffi . CType ) <TAB><TAB> assert ct . cname == ( expected_output or input ) <TAB> else : <TAB><TAB> e = py . test . raises ( ffi . error , ffi . typeof , input ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert str ( e . value ) == expected_ffi_error","if isinstance ( expected_ffi_error , str ) :",if e . value is not None :,69.19682366913864,93.16,False
3928,"def run ( self ) : <TAB> """"""Process queries from task queue, stop if processor is None."""""" <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> processor , iprot , oprot , otrans , callback = self . queue . get ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> processor . process ( iprot , oprot ) <TAB><TAB><TAB> callback ( True , otrans . getvalue ( ) ) <TAB><TAB> except Exception : <TAB><TAB><TAB> logging . exception ( "" Exception while processing request "" ) <TAB><TAB><TAB> callback ( False , "" "" )",if processor is None :,if processor is None :,100.0,100.00,True
3929,"def search ( self , query ) : <TAB> query = query . strip ( ) . lower ( ) <TAB> results = [ ] <TAB> for provider in SidebarItemProvider . all ( self . context ) : <TAB><TAB> for item in provider . provide ( ) : <TAB><TAB><TAB> if "" url "" in item : <TAB><TAB><TAB><TAB> search_source = "" $ "" . join ( <TAB><TAB><TAB><TAB><TAB> [ item . get ( "" id "" , "" "" ) , item . get ( "" name "" , "" "" ) ] <TAB><TAB><TAB><TAB> ) . lower ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> results . append ( <TAB><TAB><TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" title "" : item [ "" name "" ] , <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" icon "" : item [ "" icon "" ] , <TAB><TAB><TAB><TAB><TAB><TAB><TAB> "" url "" : item [ "" url "" ] , <TAB><TAB><TAB><TAB><TAB><TAB> } <TAB><TAB><TAB><TAB><TAB> ) <TAB> return results",if query in search_source :,if search_source . startswith ( query ) :,97.21732286998044,97.77,False
3930,"def handle ( self ) - > None : <TAB> """"""Handles a request ignoring dropped connections."""""" <TAB> try : <TAB><TAB> BaseHTTPRequestHandler . handle ( self ) <TAB> except ( ConnectionError , socket . timeout ) as e : <TAB><TAB> self . connection_dropped ( e ) <TAB> except Exception as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log_error ( "" SSL error occurred:  %s "" , e ) <TAB><TAB> else : <TAB><TAB><TAB> raise <TAB> if self . server . shutdown_signal : <TAB><TAB> self . initiate_shutdown ( )",if self . server . ssl_context is not None and is_ssl_error ( e ) :,if self . server . log_error :,66.3217377922425,90.68,False
3931,"def cdn_url_handler ( error , endpoint , kwargs ) : <TAB> if endpoint == "" cdn "" : <TAB><TAB> path = kwargs . pop ( "" path "" ) <TAB><TAB> # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB><TAB> # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB><TAB> cdn = app . config . get ( "" cdn "" , "" //cdnjscn.b0.upaiyun.com/libs/ "" ) <TAB><TAB> return urljoin ( cdn , path ) <TAB> else : <TAB><TAB> exc_type , exc_value , tb = sys . exc_info ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> reraise ( exc_type , exc_value , tb ) <TAB><TAB> else : <TAB><TAB><TAB> raise error",if exc_value is error :,if exc_type :,97.61202895149135,98.02,False
3932,"def pairs ( self ) : <TAB> for path in os . listdir ( "" src "" ) : <TAB><TAB> if path == "" .svn "" : <TAB><TAB><TAB> continue <TAB><TAB> dep = join ( "" src "" , path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> yield dep , join ( build_dir , path )",if isdir ( dep ) :,if not os . path . isdir ( dep ) :,76.24769375711851,93.76,False
3933,"def get_condition ( self ) : <TAB> """"""Return the condition element's name."""""" <TAB> for child in self . xml : <TAB><TAB> <MASK> <TAB><TAB><TAB> cond = child . tag . split ( "" } "" , 1 ) [ - 1 ] <TAB><TAB><TAB> if cond in self . conditions : <TAB><TAB><TAB><TAB> return cond <TAB> return "" not-authorized ""","if ""{%s}"" % self . namespace in child . tag :","if child . tag . startswith ( ""{%s}"" % self . conditions_ns ) :",91.21387684956366,90.54,False
3934,"def end ( self , tag ) : <TAB> # call the appropriate end tag handler <TAB> try : <TAB><TAB> f = self . dispatch [ tag ] <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> return # unknown tag ? <TAB><TAB> try : <TAB><TAB><TAB> f = self . dispatch [ tag . split ( "" : "" ) [ - 1 ] ] <TAB><TAB> except KeyError : <TAB><TAB><TAB> return # unknown tag ? <TAB> return f ( self , "" "" . join ( self . _data ) )","if "":"" not in tag :",if tag not in self . _data :,72.05325179960427,94.92,False
3935,"def checkIfSessionCodeExists ( self , sessionCode ) : <TAB> if self . emrtFile : <TAB><TAB> sessionsForExperiment = ( <TAB><TAB><TAB> self . emrtFile . root . data_collection . session_meta_data . where ( <TAB><TAB><TAB><TAB> "" experiment_id ==  %d "" % ( self . active_experiment_id , ) <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> sessionCodeMatch = [ <TAB><TAB><TAB> sess for sess in sessionsForExperiment if sess [ "" code "" ] == sessionCode <TAB><TAB> ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> return False",if len ( sessionCodeMatch ) > 0 :,if sessionCodeMatch :,66.63749927313017,95.77,False
3936,"def save_bytearray ( self , obj ) : <TAB> if self . proto < 5 : <TAB><TAB> <MASK> # bytearray is empty <TAB><TAB><TAB> self . save_reduce ( bytearray , ( ) , obj = obj ) <TAB><TAB> else : <TAB><TAB><TAB> self . save_reduce ( bytearray , ( bytes ( obj ) , ) , obj = obj ) <TAB><TAB> return <TAB> n = len ( obj ) <TAB> if n > = self . framer . _FRAME_SIZE_TARGET : <TAB><TAB> self . _write_large_bytes ( BYTEARRAY8 + pack ( "" <Q "" , n ) , obj ) <TAB> else : <TAB><TAB> self . write ( BYTEARRAY8 + pack ( "" <Q "" , n ) + obj )",if not obj :,if not obj :,100.0,100.00,True
3937,"def _restore_freeze ( self , new ) : <TAB> size_change = [ ] <TAB> for k , v in six . iteritems ( self . _freeze_backup ) : <TAB><TAB> newv = new . get ( k , [ ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> size_change . append ( ( self . _key_name ( k ) , len ( v ) , len ( newv ) ) ) <TAB> if size_change : <TAB><TAB> logger . info ( <TAB><TAB><TAB> "" These collections were modified but restored in  {} :  {} "" . format ( <TAB><TAB><TAB><TAB> self . _name , <TAB><TAB><TAB><TAB> "" ,  "" . join ( map ( lambda t : "" ( {} :  {} -> {} ) "" . format ( * t ) , size_change ) ) , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> restore_collection ( self . _freeze_backup )",if len ( v ) != len ( newv ) :,if len ( v ) != len ( newv ) :,100.0,100.00,True
3938,"def check_options ( self , expr , evaluation , options ) : <TAB> for key in options : <TAB><TAB> if key != "" System`SameTest "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) , expr ) <TAB> return None",if expr is None :,if self . strict :,69.2264821113103,96.46,False
3939,"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB><TAB> nm = _u ( nm ) <TAB><TAB> if nm . startswith ( "" . "" ) : <TAB><TAB><TAB> continue <TAB><TAB> itempath = os . path . join ( dirpath , nm ) <TAB><TAB> if os . path . isdir ( itempath ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . bundle_package ( itempath ) <TAB><TAB> elif nm . endswith ( "" .py "" ) : <TAB><TAB><TAB> self . bundle_module ( itempath )","if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :","if nm . endswith ( "".pyc"" ) :",91.11862731062908,88.68,False
3940,"def _read_block ( self , size ) : <TAB> if self . _file_end is not None : <TAB><TAB> max_size = self . _file_end - self . _file . tell ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> size = max_size <TAB><TAB> size = max ( min ( size , max_size ) , 0 ) <TAB> return self . _file . read ( size )",if size == - 1 :,if size < 0 :,76.05767705869341,94.97,False
3941,"def question_mark ( self ) : <TAB> """"""Shows help for this command and it's sub-commands."""""" <TAB> ret = [ ] <TAB> if self . param_help_msg or len ( self . subcommands ) == 0 : <TAB><TAB> ret . append ( self . _quick_help ( ) ) <TAB> if len ( self . subcommands ) > 0 : <TAB><TAB> for k , _ in sorted ( self . subcommands . items ( ) ) : <TAB><TAB><TAB> command_path , param_help , cmd_help = self . _instantiate_subcommand ( <TAB><TAB><TAB><TAB> k <TAB><TAB><TAB> ) . _quick_help ( nested = True ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret . append ( ( command_path , param_help , cmd_help ) ) <TAB> return ( CommandsResponse ( STATUS_OK , self . help_formatter ( ret ) ) , self . __class__ )",if command_path or param_help or cmd_help :,if cmd_help :,80.74314021120537,96.16,False
3942,"def list_domains ( self , r53 , * * kwargs ) : <TAB> marker = None <TAB> domains = [ ] <TAB> while True : <TAB><TAB> if marker : <TAB><TAB><TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ( Marker = marker ) ) <TAB><TAB> else : <TAB><TAB><TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ) <TAB><TAB> for domain in response . get ( "" Domains "" ) : <TAB><TAB><TAB> domains . append ( domain ) <TAB><TAB> <MASK> <TAB><TAB><TAB> marker = response . get ( "" NextPageMarker "" ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return domains","if response . get ( ""NextPageMarker"" ) :","if ""NextPageMarker"" in response :",94.23416535987992,96.16,False
3943,"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB><TAB> stream . write ( sep ) <TAB><TAB> sep = ""   "" <TAB><TAB> if not isinstance ( item , str ) : <TAB><TAB><TAB> item = str ( item ) <TAB><TAB> if not PY3K : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item = str ( item ) <TAB><TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" )","if not isinstance ( item , unicode ) :","if not isinstance ( item , ( list , tuple ) ) :",75.73283213902042,95.58,False
3944,"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB><TAB> view . run_command ( "" toggle_comment "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pt = utils . next_non_white_space_char ( view , s . a , white_space = ""   \t "" ) <TAB><TAB> else : <TAB><TAB><TAB> pt = utils . next_non_white_space_char ( <TAB><TAB><TAB><TAB> view , self . view . line ( s . a ) . a , white_space = ""   \t "" <TAB><TAB><TAB> ) <TAB><TAB> return R ( pt , pt ) <TAB> return s","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",if s . a . is_whitespace ( ) :,80.46362727101052,84.24,False
3945,"def _parse_timestamp ( value ) : <TAB> if value : <TAB><TAB> match = _TIMESTAMP_PATTERN . match ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if match . group ( 2 ) : <TAB><TAB><TAB><TAB> format = "" % Y- % m- %d   % H: % M: % S. %f "" <TAB><TAB><TAB><TAB> # use the pattern to truncate the value <TAB><TAB><TAB><TAB> value = match . group ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> format = "" % Y- % m- %d   % H: % M: % S "" <TAB><TAB><TAB> value = datetime . datetime . strptime ( value , format ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( ' Cannot convert  "" {} ""  into a datetime ' . format ( value ) ) <TAB> else : <TAB><TAB> value = None <TAB> return value",if match :,if match :,100.0,100.00,True
3946,"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB><TAB> if model_site [ "" type "" ] == "" sample "" : <TAB><TAB><TAB> log_r_term = model_site [ "" log_prob "" ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB><TAB><TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r","if not model_site [ ""is_observed"" ] :",if name in guide_trace . nodes :,82.91823706930174,94.06,False
3947,"def get_translationproject ( self ) : <TAB> """"""returns the translation project belonging to this directory."""""" <TAB> if self . is_language ( ) or self . is_project ( ) : <TAB><TAB> return None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . translationproject <TAB><TAB> else : <TAB><TAB><TAB> aux_dir = self <TAB><TAB><TAB> while not aux_dir . is_translationproject ( ) and aux_dir . parent is not None : <TAB><TAB><TAB><TAB> aux_dir = aux_dir . parent <TAB><TAB><TAB> return aux_dir . translationproject",if self . is_translationproject ( ) :,if self . is_translationproject ( ) :,100.0,100.00,True
3948,"def get_hosted_content ( ) : <TAB> try : <TAB><TAB> scheme , rest = target . split ( "" :// "" , 1 ) <TAB><TAB> prefix , host_and_port = rest . split ( "" .interactivetool. "" ) <TAB><TAB> faked_host = rest <TAB><TAB> <MASK> <TAB><TAB><TAB> faked_host = rest . split ( "" / "" , 1 ) [ 0 ] <TAB><TAB> url = "" %s :// %s "" % ( scheme , host_and_port ) <TAB><TAB> response = requests . get ( url , timeout = 1 , headers = { "" Host "" : faked_host } ) <TAB><TAB> return response . text <TAB> except Exception as e : <TAB><TAB> print ( e ) <TAB><TAB> return None","if ""/"" in rest :",if prefix :,65.99425836681434,96.76,False
3949,"def install ( self ) : <TAB> log . info ( self . openssl_cli ) <TAB> if not self . has_openssl or self . args . force : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _download_src ( ) <TAB><TAB> else : <TAB><TAB><TAB> log . debug ( "" Already has src  {} "" . format ( self . src_file ) ) <TAB><TAB> self . _unpack_src ( ) <TAB><TAB> self . _build_src ( ) <TAB><TAB> self . _make_install ( ) <TAB> else : <TAB><TAB> log . info ( "" Already has installation  {} "" . format ( self . install_dir ) ) <TAB> # validate installation <TAB> version = self . openssl_version <TAB> if self . version not in version : <TAB><TAB> raise ValueError ( version )",if not self . has_src :,if self . src_file is None :,93.17602555207853,96.64,False
3950,"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB><TAB> if i % 2 : <TAB><TAB><TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces )",elif piece :,elif piece :,100.0,100.00,True
3951,"def get_current_events_users ( calendar ) : <TAB> now = timezone . make_aware ( datetime . now ( ) , timezone . get_current_timezone ( ) ) <TAB> result = [ ] <TAB> day = Day ( calendar . events . all ( ) , now ) <TAB> for o in day . get_occurrences ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> usernames = o . event . title . split ( "" , "" ) <TAB><TAB><TAB> for username in usernames : <TAB><TAB><TAB><TAB> result . append ( User . objects . get ( username = username . strip ( ) ) ) <TAB> return result",if o . start <= now <= o . end :,if o . event :,67.8361776600534,93.65,False
3952,"def from_cfn_params ( self , cfn_params ) : <TAB> """"""Initialize param value by parsing CFN input only if the scheduler is awsbatch."""""" <TAB> cfn_converter = self . definition . get ( "" cfn_param_mapping "" , None ) <TAB> if cfn_converter and cfn_params : <TAB><TAB> <MASK> <TAB><TAB><TAB> # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB><TAB><TAB> # so the CFN input could be a float <TAB><TAB><TAB> self . value = int ( float ( get_cfn_param ( cfn_params , cfn_converter ) ) ) <TAB> return self","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :","if cfn_params [ 0 ] == ""awsbatch"" :",91.7739734543758,92.21,False
3953,"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> l = l . split ( "" : "" ) <TAB><TAB> if len ( l ) != 2 : <TAB><TAB><TAB> continue <TAB><TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setChapters ( res )",if not l :,if len ( l ) != 2 :,68.43870679130387,93.94,False
3954,"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB><TAB> # most common case: extend a range <TAB><TAB> if i == _range [ 0 ] - 1 : <TAB><TAB><TAB> _range [ 0 ] = i <TAB><TAB><TAB> merge_ranges ( l ) <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> _range [ 1 ] = i <TAB><TAB><TAB> merge_ranges ( l ) <TAB><TAB><TAB> return <TAB> # somewhere outside of range proximity <TAB> l . append ( [ i , i ] ) <TAB> l . sort ( key = lambda x : x [ 0 ] )",elif i == _range [ 1 ] + 1 :,if i > _range [ 1 ] - 1 :,96.57123682025852,95.87,False
3955,"def process_dollar ( token , state , command_line ) : <TAB> if not state . is_range_start_line_parsed : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB><TAB> command_line . line_range . start . append ( token ) <TAB> else : <TAB><TAB> if command_line . line_range . end : <TAB><TAB><TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB><TAB> command_line . line_range . end . append ( token ) <TAB> return parse_line_ref , command_line",if command_line . line_range . start :,if command_line . line_range . start :,100.0,100.00,True
3956,"def _parse_description ( self , text : str ) : <TAB> result = dict ( links = [ ] , versions = [ ] ) <TAB> for line in text . splitlines ( ) : <TAB><TAB> clean = REX_TAG . sub ( "" "" , line . strip ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" severity "" ] = clean . split ( ) [ 1 ] <TAB><TAB><TAB> continue <TAB><TAB> if clean . startswith ( "" Affects: "" ) : <TAB><TAB><TAB> result [ "" name "" ] = clean . split ( ) [ 1 ] <TAB><TAB><TAB> continue <TAB><TAB> if ""  or higher "" in clean : <TAB><TAB><TAB> result [ "" versions "" ] = self . _get_versions ( clean ) <TAB><TAB> result [ "" links "" ] . extend ( REX_LINK . findall ( line ) ) <TAB> return result","if clean . startswith ( ""Severity:"" ) :","if clean . startswith ( ""Severity:"" ) :",100.0,100.00,True
3957,"def apply ( self , chart , grammar ) : <TAB> for prod in grammar . productions ( empty = True ) : <TAB><TAB> for index in compat . xrange ( chart . num_leaves ( ) + 1 ) : <TAB><TAB><TAB> new_edge = TreeEdge . from_production ( prod , index ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield new_edge","if chart . insert ( new_edge , ( ) ) :","if chart . insert ( new_edge , ( ) ) :",100.0,100.00,True
3958,"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB><TAB> self . clear ( ) <TAB><TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . current + = num <TAB><TAB> elif self . op == "" - "" : <TAB><TAB><TAB> self . current - = num <TAB><TAB> elif self . op == "" * "" : <TAB><TAB><TAB> self . current * = num <TAB><TAB> elif self . op == "" / "" : <TAB><TAB><TAB> self . current / = num <TAB><TAB> self . op = op <TAB> else : <TAB><TAB> self . op = op <TAB><TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB><TAB> self . clear ( ) <TAB> return res","if self . op == ""+"" :","if self . op == ""+"" :",100.0,100.00,True
3959,"def cascade ( self , event = None ) : <TAB> """"""Cascade all Leo windows."""""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB><TAB> w = frame and frame . top <TAB><TAB> if w : <TAB><TAB><TAB> r = w . geometry ( ) # a Qt.Rect <TAB><TAB><TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB><TAB><TAB> w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB><TAB><TAB> # Compute the new offsets. <TAB><TAB><TAB> x + = 30 <TAB><TAB><TAB> y + = 30 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> x = 10 + delta <TAB><TAB><TAB><TAB> y = 40 + delta <TAB><TAB><TAB><TAB> delta + = 10",if x > 200 :,if x < 10 and y < 40 :,97.9613373876254,97.08,False
3960,"def redirect ( self ) : <TAB> c = self . c <TAB> if c . config . getBool ( "" eval-redirect "" ) : <TAB><TAB> self . old_stderr = g . stdErrIsRedirected ( ) <TAB><TAB> self . old_stdout = g . stdOutIsRedirected ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> g . redirectStderr ( ) <TAB><TAB> if not self . old_stdout : <TAB><TAB><TAB> g . redirectStdout ( )",if not self . old_stderr :,if not self . old_stderr :,100.0,100.00,True
3961,"def on_event ( self , c , button , data ) : <TAB> if self . rvGestureGrab . get_reveal_child ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . use ( ) <TAB><TAB> elif button == "" Y "" and data [ 0 ] == 0 : <TAB><TAB><TAB> self . start_over ( )","if button == ""A"" and data [ 0 ] == 0 :","if button == ""X"" and data [ 0 ] == 1 :",70.84471406140958,95.07,False
3962,"def __init__ ( self , in_feats , out_feats , norm = "" both "" , bias = True , activation = None ) : <TAB> super ( DenseGraphConv , self ) . __init__ ( ) <TAB> self . _in_feats = in_feats <TAB> self . _out_feats = out_feats <TAB> self . _norm = norm <TAB> with self . name_scope ( ) : <TAB><TAB> self . weight = self . params . get ( <TAB><TAB><TAB> "" weight "" , <TAB><TAB><TAB> shape = ( in_feats , out_feats ) , <TAB><TAB><TAB> init = mx . init . Xavier ( magnitude = math . sqrt ( 2.0 ) ) , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . bias = self . params . get ( "" bias "" , shape = ( out_feats , ) , init = mx . init . Zero ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . bias = None <TAB><TAB> self . _activation = activation",if bias :,if bias :,100.0,100.00,True
3963,"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys . path : <TAB><TAB> if isinstance ( item , _StringType ) : <TAB><TAB><TAB> module = self . fs_imp . import_from_dir ( item , name ) <TAB><TAB> else : <TAB><TAB><TAB> module = item . import_top ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return module <TAB> return None",if module :,if module :,75.0,100.00,True
3964,"def resolver ( schemas , f ) : <TAB> if not callable ( f ) : <TAB><TAB> return <TAB> if not hasattr ( f , "" accepts "" ) : <TAB><TAB> return <TAB> new_params = [ ] <TAB> for p in f . accepts : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_params . append ( p . resolve ( schemas ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise ResolverError ( "" Invalid parameter definition  {0} "" . format ( p ) ) <TAB> # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB> f . accepts . clear ( ) <TAB> f . accepts . extend ( new_params )","if isinstance ( p , ( Patch , Ref , Attribute ) ) :","if isinstance ( p , Parameter ) :",93.62005536618292,95.39,False
3965,"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB><TAB> if not p : <TAB><TAB><TAB> continue <TAB><TAB> ( pth , fname ) = os . path . split ( p ) <TAB><TAB> if fname == "" output "" : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB><TAB><TAB> continue <TAB><TAB> if os . path . isdir ( p ) : <TAB><TAB><TAB> get_dir ( p ) <TAB><TAB> else : <TAB><TAB><TAB> res . append ( p ) <TAB> return res","if fname == ""PureMVC_Python_1_0"" :","if fname [ - 3 : ] == "".pyc"" :",95.66726795544703,95.57,False
3966,"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB><TAB> for rightname in kerning [ leftname ] : <TAB><TAB><TAB> if rightname [ 0 ] == "" @ "" : <TAB><TAB><TAB><TAB> for rightname2 in groups [ rightname ] : <TAB><TAB><TAB><TAB><TAB> rightnames . add ( rightname2 ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> # TODO: in this case, pick the one rightname that has the highest <TAB><TAB><TAB><TAB><TAB><TAB> # ranking in glyphorder <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> rightnames . add ( rightname )",if not includeAll :,if includeAll :,75.561403802549,98.86,False
3967,"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB><TAB><TAB> continue <TAB><TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB><TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB><TAB><TAB> if key not in old_obj . __table__ . columns : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB><TAB> self . session_new . add ( new_obj )",if not old_obj . summary :,if old_obj . __table__ . columns . _data . keys ( ) :,81.82067054196025,92.42,False
3968,"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB><TAB> envvar = match . groups ( ) [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> value = os . environ [ envvar ] <TAB><TAB><TAB> if six . PY2 : <TAB><TAB><TAB><TAB> value = value . decode ( "" utf8 "" ) <TAB><TAB><TAB> return value <TAB><TAB> else : <TAB><TAB><TAB> raise InvalidConfigException ( <TAB><TAB><TAB><TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise InvalidConfigException ( <TAB><TAB><TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB><TAB><TAB><TAB> msg , var , _ENV_VAR_PAT_STR <TAB><TAB><TAB> ) <TAB><TAB> )",if envvar in os . environ :,if envvar in os . environ :,100.0,100.00,True
3969,"def __next__ ( self ) : <TAB> self . _parse_reset ( ) <TAB> while True : <TAB><TAB> try : <TAB><TAB><TAB> line = next ( self . input_iter ) <TAB><TAB> except StopIteration : <TAB><TAB><TAB> # End of input OR exception <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Error ( "" newline inside string "" ) <TAB><TAB><TAB> raise <TAB><TAB> self . line_num + = 1 <TAB><TAB> if "" \0 "" in line : <TAB><TAB><TAB> raise Error ( "" line contains NULL byte "" ) <TAB><TAB> pos = 0 <TAB><TAB> while pos < len ( line ) : <TAB><TAB><TAB> pos = self . _parse_process_char ( line , pos ) <TAB><TAB> self . _parse_eol ( ) <TAB><TAB> if self . state == self . START_RECORD : <TAB><TAB><TAB> break <TAB> fields = self . fields <TAB> self . fields = [ ] <TAB> return fields",if len ( self . field ) > 0 :,if self . line_num >= self . input_len :,97.03611491314236,95.75,False
3970,"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB><TAB> pos = self . stream . searchBytes ( <TAB><TAB><TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB><TAB> ) # seek forward by at most 1MB <TAB><TAB> <MASK> <TAB><TAB><TAB> padsize = pos - self . current_size <TAB><TAB><TAB> if padsize : <TAB><TAB><TAB><TAB> yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB><TAB> chunk = Chunk ( self , "" chunk[] "" ) <TAB><TAB> try : <TAB><TAB><TAB> # force chunk to be processed, so that CustomFragments are complete <TAB><TAB><TAB> chunk [ "" content/data "" ] <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> yield chunk",if pos is not None :,if pos :,97.84041745111556,98.13,False
3971,"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB><TAB> if part . type == "" uid "" : <TAB><TAB><TAB> seenUID = True <TAB><TAB> <MASK> <TAB><TAB><TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB><TAB> else : <TAB><TAB><TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB><TAB><TAB> yield f ( id , msg , write , flush ) <TAB><TAB> if part is not query [ - 1 ] : <TAB><TAB><TAB> space ( ) <TAB> if uid and not seenUID : <TAB><TAB> space ( ) <TAB><TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( )","if part . type == ""body"" :",if part . body :,75.85628680247794,96.76,False
3972,"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB><TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB><TAB> # auto handle datetime <TAB><TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB><TAB><TAB> if config [ key ] [ "" inverse "" ] is True : <TAB><TAB><TAB><TAB> if ( datetime . now ( ) - limit ) > value : <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) - limit <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> value = datetime . now ( ) + limit <TAB><TAB> elif value > limit : <TAB><TAB><TAB> value = limit <TAB> return value",if ( datetime . now ( ) + limit ) < value :,if ( datetime . now ( ) + limit ) < value :,100.0,100.00,True
3973,"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB><TAB> if mod == "" input "" : <TAB><TAB><TAB> iter = op . inputs <TAB><TAB> else : <TAB><TAB><TAB> iter = op . outputs <TAB><TAB> for i in iter : <TAB><TAB><TAB> for name in names : <TAB><TAB><TAB><TAB> if i . raw_name == name and name not in map : <TAB><TAB><TAB><TAB><TAB> map [ i . raw_name ] = i . full_name <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> for name in names : <TAB><TAB> new_names . append ( map [ name ] ) <TAB> return new_names",if len ( map ) == len ( names ) :,"if mod == ""output"" :",86.42460073514104,95.37,False
3974,"def traverse ( tree ) : <TAB> """"""Generator dropping comment nodes"""""" <TAB> for entry in tree : <TAB><TAB> # key, values = entry <TAB><TAB> spaceless = [ e for e in entry if not nginxparser . spacey ( e ) ] <TAB><TAB> if spaceless : <TAB><TAB><TAB> key = spaceless [ 0 ] <TAB><TAB><TAB> values = spaceless [ 1 ] if len ( spaceless ) > 1 else None <TAB><TAB> else : <TAB><TAB><TAB> key = values = "" "" <TAB><TAB> if isinstance ( key , list ) : <TAB><TAB><TAB> new = copy . deepcopy ( entry ) <TAB><TAB><TAB> new [ 1 ] = filter_comments ( values ) <TAB><TAB><TAB> yield new <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield spaceless","if key != ""#"" and spaceless :",if len ( spaceless ) > 1 :,97.17225167187628,96.05,False
3975,"def mergeCombiners ( self , x , y ) : <TAB> for item in y : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . heap . push ( x , item ) <TAB><TAB> else : <TAB><TAB><TAB> self . heap . push_pop ( x , item ) <TAB> return x",if len ( x ) < self . heap_limit :,if self . heap :,62.15961398180034,88.32,False
3976,"def test_scatter ( self , harness : primitive_harness . Harness ) : <TAB> f_name = harness . params [ "" f_lax "" ] . __name__ <TAB> dtype = harness . params [ "" dtype "" ] <TAB> if jtu . device_under_test ( ) == "" tpu "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise unittest . SkipTest ( f "" TODO: complex  { f_name }  on TPU fails in JAX "" ) <TAB> self . ConvertAndCompare ( harness . dyn_fun , * harness . dyn_args_maker ( self . rng ( ) ) )","if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :","if not harness . dyn_fun . __name__ . endswith ( ""TPU",59.5548115287509,85.11,False
3977,"def TryMerge ( self , decoder ) : <TAB> while decoder . avail ( ) > 0 : <TAB><TAB> tag = decoder . getVarInt32 ( ) <TAB><TAB> if tag == TAG_BEGIN_ITEM_GROUP : <TAB><TAB><TAB> ( type_id , message ) = Item . Decode ( decoder ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . items [ type_id ] . MergeFrom ( Item ( message ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . items [ type_id ] = Item ( message ) <TAB><TAB><TAB> continue <TAB><TAB> if tag == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> decoder . skipData ( tag )",if type_id in self . items :,if type_id in self . items :,100.0,100.00,True
3978,"def process_continuations ( lines ) : <TAB> global continuation_pattern <TAB> olines = [ ] <TAB> while len ( lines ) != 0 : <TAB><TAB> line = no_comments ( lines [ 0 ] ) <TAB><TAB> line = line . strip ( ) <TAB><TAB> lines . pop ( 0 ) <TAB><TAB> if line == "" "" : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> # combine this line with the next line if the next line exists <TAB><TAB><TAB> line = continuation_pattern . sub ( "" "" , line ) <TAB><TAB><TAB> if len ( lines ) > = 1 : <TAB><TAB><TAB><TAB> combined_lines = [ line + lines [ 0 ] ] <TAB><TAB><TAB><TAB> lines . pop ( 0 ) <TAB><TAB><TAB><TAB> lines = combined_lines + lines <TAB><TAB><TAB><TAB> continue <TAB><TAB> olines . append ( line ) <TAB> del lines <TAB> return olines",if continuation_pattern . search ( line ) :,"if line . startswith ( ""#"" ) :",91.71578538747467,97.14,False
3979,"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB><TAB> if pkg in Scheduler . listOfPackagesCurrentlyBuilding : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB><TAB><TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" )",if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,if not Scheduler . listOfPackagesNextToBuild . has_key ( ( - Scheduler . _,62.025707798548964,88.14,False
3980,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB><TAB> # replace Mock function names <TAB><TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB> # add scope name to layer signatures: <TAB><TAB> if hasattr ( obj , "" use_scope "" ) : <TAB><TAB><TAB> if obj . use_scope : <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation",elif obj . use_scope is None :,elif obj . use_layer :,98.19229115173707,98.21,False
3981,"def find_distribution_modules ( name = __name__ , file = __file__ ) : <TAB> current_dist_depth = len ( name . split ( "" . "" ) ) - 1 <TAB> current_dist = os . path . join ( <TAB><TAB> os . path . dirname ( file ) , * ( [ os . pardir ] * current_dist_depth ) <TAB> ) <TAB> abs = os . path . abspath ( current_dist ) <TAB> dist_name = os . path . basename ( abs ) <TAB> for dirpath , dirnames , filenames in os . walk ( abs ) : <TAB><TAB> package = ( dist_name + dirpath [ len ( abs ) : ] ) . replace ( "" / "" , "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield package <TAB><TAB><TAB> for filename in filenames : <TAB><TAB><TAB><TAB> if filename . endswith ( "" .py "" ) and filename != "" __init__.py "" : <TAB><TAB><TAB><TAB><TAB> yield "" . "" . join ( [ package , filename ] ) [ : - 3 ]","if ""__init__.py"" in filenames :","if package . endswith ( ""__init__.py"" ) :",80.75956466313242,97.20,False
3982,"def transform_value ( i , v , * args ) : <TAB> if i not in converter_functions : <TAB><TAB> # no converter defined on this field, return value as-is <TAB><TAB> return v <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> return converter_functions [ i ] ( v , * args ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> if failonerror == "" inline "" : <TAB><TAB><TAB><TAB> return e <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise e <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return errorvalue",elif failonerror :,"elif failonerror == ""exception"" :",98.41969606406751,96.39,False
3983,"def _get_file ( self ) : <TAB> if self . _file is None : <TAB><TAB> self . _file = SpooledTemporaryFile ( <TAB><TAB><TAB> max_size = self . _storage . max_memory_size , <TAB><TAB><TAB> suffix = "" .S3Boto3StorageFile "" , <TAB><TAB><TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _is_dirty = False <TAB><TAB><TAB> self . obj . download_fileobj ( self . _file ) <TAB><TAB><TAB> self . _file . seek ( 0 ) <TAB><TAB> if self . _storage . gzip and self . obj . content_encoding == "" gzip "" : <TAB><TAB><TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file","if ""r"" in self . _mode :",if self . _storage . is_dirty :,74.53569110748161,96.72,False
3984,"def connect ( self , host , port , timeout ) : <TAB> fp = Telnet ( ) <TAB> for i in range ( 50 ) : <TAB><TAB> try : <TAB><TAB><TAB> fp . sock = socket . create_connection ( <TAB><TAB><TAB><TAB> ( host , int ( port ) ) , timeout = int ( timeout ) , source_address = ( "" "" , 1023 - i ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> break <TAB><TAB> except socket . error as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise e <TAB> self . need_handshake = True <TAB> return TCP_Connection ( fp )","if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",if i == 1023 :,62.402845515782566,88.30,False
3985,"def filtercomments ( source ) : <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB><TAB> if re . search ( r "" ^ \ s* \ / \ * "" , source ) : <TAB><TAB><TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB><TAB> else : <TAB><TAB><TAB> comment = None <TAB><TAB> if comment : <TAB><TAB><TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB><TAB><TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source","elif re . search ( r""^\s*\/\/"" , source ) :","elif re . search ( r""^\s*/"" , source ) :",99.22016533914974,98.26,False
3986,"def yview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB><TAB> value = float ( value ) <TAB> if mode is None : <TAB><TAB> return self . vsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB><TAB> frameHeight = self . innerframe . winfo_reqheight ( ) <TAB><TAB> self . _startY = value * float ( frameHeight ) <TAB> else : # mode == 'scroll' <TAB><TAB> clipperHeight = self . _clipper . winfo_height ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> jump = int ( clipperHeight * self . _jfraction ) <TAB><TAB> else : <TAB><TAB><TAB> jump = clipperHeight <TAB><TAB> self . _startY = self . _startY + value * jump <TAB> self . reposition ( )","if units == ""units"" :",if self . _jfraction :,98.37121521490587,96.53,False
3987,"def visit ( stmt ) : <TAB> """"""Collect information about VTCM buffers and their alignments."""""" <TAB> if isinstance ( stmt , tvm . tir . AttrStmt ) : <TAB><TAB> if stmt . attr_key == "" storage_scope "" and stmt . value == "" local.vtcm "" : <TAB><TAB><TAB> vtcm_buffers . append ( stmt . node ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if not stmt . node in alignments : <TAB><TAB><TAB><TAB> alignments [ stmt . node ] = [ ] <TAB><TAB><TAB> alignments [ stmt . node ] . append ( stmt . value )","elif stmt . attr_key == ""storage_alignment"" :","elif isinstance ( stmt , tvm . tir . AttrAttr ) :",94.11545004845672,92.23,False
3988,"def cost ( P ) : <TAB> # wda loss <TAB> loss_b = 0 <TAB> loss_w = 0 <TAB> for i , xi in enumerate ( xc ) : <TAB><TAB> xi = np . dot ( xi , P ) <TAB><TAB> for j , xj in enumerate ( xc [ i : ] ) : <TAB><TAB><TAB> xj = np . dot ( xj , P ) <TAB><TAB><TAB> M = dist ( xi , xj ) <TAB><TAB><TAB> G = sinkhorn ( wc [ i ] , wc [ j + i ] , M , reg , k ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> loss_w + = np . sum ( G * M ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> loss_b + = np . sum ( G * M ) <TAB> # loss inversed because minimization <TAB> return loss_w / loss_b",if j == 0 :,if reg == k :,73.4962765887734,97.99,False
3989,"def __init__ ( self , comm , in_channels , out_channels , ksize , pad = 1 ) : <TAB> super ( Block , self ) . __init__ ( ) <TAB> with self . init_scope ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . conv = ParallelConvolution2D ( <TAB><TAB><TAB><TAB> comm , in_channels , out_channels , ksize , pad = pad , nobias = True <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . conv = chainer . links . Convolution2D ( <TAB><TAB><TAB><TAB> in_channels , out_channels , ksize , pad = pad , nobias = True <TAB><TAB><TAB> ) <TAB><TAB> self . bn = L . BatchNormalization ( out_channels )",if comm . size <= in_channels :,if comm . shape [ 1 ] == 1 :,95.05637643072085,96.07,False
3990,"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB><TAB> wrong_found = 0 <TAB><TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB><TAB><TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> wrong_found + = 1 <TAB><TAB> if wrong_found == 1 : <TAB><TAB><TAB> return - 30 <TAB><TAB> return 0 <TAB> except : <TAB><TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0","if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",if nzb_name in wrong :,82.83229413987287,91.83,False
3991,"def should_include ( service ) : <TAB> for f in filt : <TAB><TAB> <MASK> <TAB><TAB><TAB> state = filt [ f ] <TAB><TAB><TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB><TAB><TAB> if not has_container_with_state ( containers , state ) : <TAB><TAB><TAB><TAB> return False <TAB><TAB> elif f == "" source "" : <TAB><TAB><TAB> source = filt [ f ] <TAB><TAB><TAB> if source == "" image "" or source == "" build "" : <TAB><TAB><TAB><TAB> if source not in service . options : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB><TAB> else : <TAB><TAB><TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True","if f == ""status"" :","if f == ""state"" :",99.05613830659769,99.07,False
3992,"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB><TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB><TAB><TAB> return "" TINYBLOB "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" BLOB "" <TAB><TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB><TAB><TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_BLOB :,if length <= self . LENGTH_LIMIT_BLOB :,100.0,100.00,True
3993,"def click_outside ( event ) : <TAB> if event not in d : <TAB><TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> y = 64 <TAB><TAB> y + = 3 <TAB><TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB><TAB> if event . num_clicks == 2 : <TAB><TAB><TAB> d . dismiss ( "" Goto "" )",if y == 0 :,if y < 64 :,92.67125364629688,96.35,False
3994,"def check_related_active_jobs ( self , obj ) : <TAB> active_jobs = obj . get_active_jobs ( ) <TAB> if len ( active_jobs ) > 0 : <TAB><TAB> raise ActiveJobConflict ( active_jobs ) <TAB> time_cutoff = now ( ) - dateutil . relativedelta . relativedelta ( minutes = 1 ) <TAB> recent_jobs = obj . _get_related_jobs ( ) . filter ( finished__gte = time_cutoff ) <TAB> for unified_job in recent_jobs . get_real_instances ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PermissionDenied ( <TAB><TAB><TAB><TAB> _ ( "" Related job  {}  is still processing events. "" ) . format ( <TAB><TAB><TAB><TAB><TAB> unified_job . log_format <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> )",if not unified_job . event_processing_finished :,if unified_job . is_processing_events :,72.20479060456775,96.70,False
3995,"def run ( self ) : <TAB> self . alive = True <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB><TAB> _log . debug ( "" started "" ) <TAB> while self . alive : <TAB><TAB> task = self . queue . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> function , args , kwargs = task <TAB><TAB><TAB> assert function <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> function ( * args , * * kwargs ) <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> _log . exception ( "" calling  %s "" , function ) <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB><TAB> _log . debug ( "" stopped "" )",if task :,if task :,100.0,100.00,True
3996,"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB><TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB><TAB> if v is None : <TAB><TAB><TAB> continue <TAB><TAB> v = str ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> contents [ k ] = v <TAB><TAB> updated_am + = 1 <TAB> if updated_am : <TAB><TAB> lines = [ <TAB><TAB><TAB> str ( contents ) , <TAB><TAB> ] <TAB><TAB> if not exists : <TAB><TAB><TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB><TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 )",if len ( v ) == 0 and not allow_empty :,"if allow_empty and v == """" :",93.28942915355674,95.86,False
3997,"def wrapper ( # type: ignore <TAB> self : RequestHandler , * args , * * kwargs ) - > Optional [ Awaitable [ None ] ] : <TAB> if self . request . path . endswith ( "" / "" ) : <TAB><TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB> uri = self . request . path . rstrip ( "" / "" ) <TAB><TAB><TAB> <MASK> # don't try to redirect '/' to '' <TAB><TAB><TAB><TAB> if self . request . query : <TAB><TAB><TAB><TAB><TAB> uri + = "" ? "" + self . request . query <TAB><TAB><TAB><TAB> self . redirect ( uri , permanent = True ) <TAB><TAB><TAB><TAB> return None <TAB><TAB> else : <TAB><TAB><TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )",if uri :,if uri :,75.0,100.00,True
3998,def output_handles_from_execution_plan ( execution_plan ) : <TAB> output_handles_for_current_run = set ( ) <TAB> for step_level in execution_plan . execution_step_levels ( ) : <TAB><TAB> for step in step_level : <TAB><TAB><TAB> for step_input in step . step_inputs : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> output_handles_for_current_run . update ( step_input . source_handles ) <TAB> return output_handles_for_current_run,if step_input . source_handles :,if step_input . is_current_run :,97.62692891654757,95.94,False
3999,"def _read_value ( self , item ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _store [ item ] <TAB><TAB><TAB> raise KeyError ( item ) <TAB><TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> elif item in self . _children : <TAB><TAB> return PathResult ( item , dir = True ) <TAB> else : <TAB><TAB> raise KeyError ( item )",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if self . _store [ item ] is None :,88.39961305608442,85.42,False
4000,"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB><TAB> if lidx > = len ( lines ) : <TAB><TAB><TAB> break <TAB><TAB> if stmt == lines [ lidx ] : <TAB><TAB><TAB> lidx + = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> start = stmt <TAB><TAB><TAB> end = stmt <TAB><TAB> elif start : <TAB><TAB><TAB> pairs . append ( ( start , end ) ) <TAB><TAB><TAB> start = None <TAB> if start : <TAB><TAB> pairs . append ( ( start , end ) ) <TAB> return pairs",if not start :,if start is None :,78.48366604261287,98.20,False
4001,"def _update_help_obj_params ( help_obj , data_params , params_equal , attr_key_tups ) : <TAB> loaded_params = [ ] <TAB> for param_obj in help_obj . parameters : <TAB><TAB> loaded_param = next ( <TAB><TAB><TAB> ( n for n in data_params if params_equal ( param_obj , n ) ) , None <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> BaseHelpLoader . _update_obj_from_data_dict ( <TAB><TAB><TAB><TAB> param_obj , loaded_param , attr_key_tups <TAB><TAB><TAB> ) <TAB><TAB> loaded_params . append ( param_obj ) <TAB> help_obj . parameters = loaded_params",if loaded_param :,if loaded_param is not None :,86.8573196769868,97.74,False
4002,"def __get_ratio ( self ) : <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB><TAB> w = free_layout . get_main_splitter ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> aList = w . sizes ( ) <TAB><TAB><TAB> if len ( aList ) == 2 : <TAB><TAB><TAB><TAB> n1 , n2 = aList <TAB><TAB><TAB><TAB> # 2017/06/07: guard against division by zero. <TAB><TAB><TAB><TAB> ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB><TAB><TAB><TAB> return ratio <TAB> return 0.5",if w :,if w :,100.0,100.00,True
4003,"def _check_required_env_variables ( vars ) : <TAB> for var in vars : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . tc . logger . error ( <TAB><TAB><TAB><TAB> "" %s  is not set. Did you forget to source your build environment setup script? "" <TAB><TAB><TAB><TAB> % var <TAB><TAB><TAB> ) <TAB><TAB><TAB> raise OEQAPreRun",if not os . environ . get ( var ) :,"if not var . startswith ( ""OEQAPreRun"" ) :",62.11744118974549,93.48,False
4004,"def clean_indexes ( ) : <TAB> for coll_name in mongo . collection_types . keys ( ) : <TAB><TAB> coll = mongo . get_collection ( coll_name ) <TAB><TAB> indexes = coll_indexes [ coll_name ] <TAB><TAB> try : <TAB><TAB><TAB> for index in coll . list_indexes ( ) : <TAB><TAB><TAB><TAB> name = index [ "" name "" ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> coll . drop_index ( name ) <TAB><TAB> except pymongo . errors . OperationFailure : <TAB><TAB><TAB> pass","if name == ""_id"" or name == ""_id_"" or name in indexes :",if name in indexes :,86.59546592486302,90.75,False
4005,"def _compare_dirs ( self , dir1 , dir2 ) : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [ ] <TAB> for root , dirs , files in os . walk ( dir1 ) : <TAB><TAB> for file_ in files : <TAB><TAB><TAB> path = os . path . join ( root , file_ ) <TAB><TAB><TAB> target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> diff . append ( file_ ) <TAB> return diff",if not os . path . exists ( target_path ) :,"if self . _compare_path ( target_path , dir1 ) :",70.93607973518996,93.81,False
4006,"def load_state_dict ( self , state_dict , strict = True ) : <TAB> """"""Customized load."""""" <TAB> self . language_model . load_state_dict ( <TAB><TAB> state_dict [ self . _language_model_key ] , strict = strict <TAB> ) <TAB> if mpu . is_pipeline_last_stage ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . multichoice_head . load_state_dict ( <TAB><TAB><TAB><TAB> state_dict [ self . _multichoice_head_key ] , strict = strict <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> print_rank_last ( <TAB><TAB><TAB><TAB> "" ***WARNING*** could not find  {}  in the checkpoint,  "" <TAB><TAB><TAB><TAB> "" initializing to random "" . format ( self . _multichoice_head_key ) <TAB><TAB><TAB> )",if self . _multichoice_head_key in state_dict :,if self . _multichoice_head_key in state_dict :,100.0,100.00,True
4007,"def _parse_timedelta ( self , value ) : <TAB> try : <TAB><TAB> sum = datetime . timedelta ( ) <TAB><TAB> start = 0 <TAB><TAB> while start < len ( value ) : <TAB><TAB><TAB> m = self . _TIMEDELTA_PATTERN . match ( value , start ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Exception ( ) <TAB><TAB><TAB> num = float ( m . group ( 1 ) ) <TAB><TAB><TAB> units = m . group ( 2 ) or "" seconds "" <TAB><TAB><TAB> units = self . _TIMEDELTA_ABBREV_DICT . get ( units , units ) <TAB><TAB><TAB> sum + = datetime . timedelta ( * * { units : num } ) <TAB><TAB><TAB> start = m . end ( ) <TAB><TAB> return sum <TAB> except : <TAB><TAB> raise",if not m :,if not m :,100.0,100.00,True
4008,"def SetChildMenuBar ( self , pChild ) : <TAB> if not pChild : <TAB><TAB> # No Child, set Our menu bar back. <TAB><TAB> if self . _pMyMenuBar : <TAB><TAB><TAB> self . SetMenuBar ( self . _pMyMenuBar ) <TAB><TAB> else : <TAB><TAB><TAB> self . SetMenuBar ( self . GetMenuBar ( ) ) <TAB><TAB> # Make sure we know our menu bar is in use <TAB><TAB> self . _pMyMenuBar = None <TAB> else : <TAB><TAB> if pChild . GetMenuBar ( ) is None : <TAB><TAB><TAB> return <TAB><TAB> # Do we need to save the current bar? <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _pMyMenuBar = self . GetMenuBar ( ) <TAB><TAB> self . SetMenuBar ( pChild . GetMenuBar ( ) )",if self . _pMyMenuBar is None :,if self . GetMenuBar ( ) != pChild . GetMenuBar ( ) :,96.79330467747252,94.68,False
4009,"def init_weights ( self ) : <TAB> """"""Initialize weights of the head."""""" <TAB> # retinanet_bias_init <TAB> bias_cls = bias_init_with_prob ( 0.01 ) <TAB> normal_init ( self . conv_reg , std = 0.01 ) <TAB> normal_init ( self . conv_centerness , std = 0.01 ) <TAB> normal_init ( self . conv_cls , std = 0.01 , bias = bias_cls ) <TAB> for branch in [ self . cls_convs , self . reg_convs ] : <TAB><TAB> for module in branch . modules ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> caffe2_xavier_init ( module . conv )","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",if module . conv :,91.95976729174305,90.80,False
4010,"def handle_exception ( self , e , result ) : <TAB> for k in sorted ( result . thrift_spec ) : <TAB><TAB> if result . thrift_spec [ k ] [ 1 ] == "" success "" : <TAB><TAB><TAB> continue <TAB><TAB> _ , exc_name , exc_cls , _ = result . thrift_spec [ k ] <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( result , exc_name , e ) <TAB><TAB><TAB> break <TAB> else : <TAB><TAB> raise","if isinstance ( e , exc_cls ) :","if exc_cls == ""TK_EXCEPTION"" :",66.33424571161505,93.05,False
4011,"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB><TAB> elif subdir : <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB><TAB> else : <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) )","if script . startswith ( ""http"" ) :","if script . startswith ( ""/"" ) :",99.00660551861131,98.81,False
4012,"def test_related_objects_local ( self ) : <TAB> result_key = "" get_all_related_objects_with_model_local "" <TAB> for model , expected in TEST_RESULTS [ result_key ] . items ( ) : <TAB><TAB> objects = [ <TAB><TAB><TAB> ( field , self . _model ( model , field ) ) <TAB><TAB><TAB> for field in model . _meta . get_fields ( include_parents = False ) <TAB><TAB><TAB> <MASK> <TAB><TAB> ] <TAB><TAB> self . assertEqual ( <TAB><TAB><TAB> sorted ( self . _map_related_query_names ( objects ) , key = self . key_name ) , <TAB><TAB><TAB> sorted ( expected , key = self . key_name ) , <TAB><TAB> )",if field . auto_created and not field . concrete,if not field . is_related and field . is_related and not field . is_,94.03266158549496,92.69,False
4013,"def setTestOutcome ( self , event ) : <TAB> """"""Update outcome, exc_info and reason based on configured mappings"""""" <TAB> if event . exc_info : <TAB><TAB> ec , ev , tb = event . exc_info <TAB><TAB> classname = ec . __name__ <TAB><TAB> if classname in self . treatAsFail : <TAB><TAB><TAB> short , long_ = self . labels ( classname ) <TAB><TAB><TAB> self . _setOutcome ( event , "" failed "" , short , long_ ) <TAB><TAB> <MASK> <TAB><TAB><TAB> short , long_ = self . labels ( classname , upper = False ) <TAB><TAB><TAB> self . _setOutcome ( event , "" skipped "" , short , "" %s :  ' %s ' "" % ( long_ , ev ) , str ( ev ) )",elif classname in self . treatAsSkip :,elif classname in self . treatAsSkip :,100.0,100.00,True
4014,"def small_count ( v ) : <TAB> if not v : <TAB><TAB> return 0 <TAB> z = [ <TAB><TAB> ( 1000000000 , _ ( "" b "" ) ) , <TAB><TAB> ( 1000000 , _ ( "" m "" ) ) , <TAB><TAB> ( 1000 , _ ( "" k "" ) ) , <TAB> ] <TAB> v = int ( v ) <TAB> for x , y in z : <TAB><TAB> o , p = divmod ( v , x ) <TAB><TAB> if o : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return "" %d %s "" % ( o , y ) <TAB><TAB><TAB> return "" %.1f %s "" % ( v / float ( x ) , y ) <TAB> return v",if len ( str ( o ) ) > 2 or not p :,if p :,92.55325148803995,93.87,False
4015,"def __read ( self , n ) : <TAB> if self . _read_watcher is None : <TAB><TAB> raise UnsupportedOperation ( "" read "" ) <TAB> while 1 : <TAB><TAB> try : <TAB><TAB><TAB> return _read ( self . _fileno , n ) <TAB><TAB> except ( IOError , OSError ) as ex : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB> wait_on_watcher ( self . _read_watcher , None , None , self . hub )",if ex . args [ 0 ] not in ignored_errors :,if ex . errno != errno . EINTR :,66.63893918348552,92.77,False
4016,"def locked ( self ) : <TAB> inputfiles = set ( self . all_inputfiles ( ) ) <TAB> outputfiles = set ( self . all_outputfiles ( ) ) <TAB> if os . path . exists ( self . _lockdir ) : <TAB><TAB> for lockfile in self . _locks ( "" input "" ) : <TAB><TAB><TAB> with open ( lockfile ) as lock : <TAB><TAB><TAB><TAB> for f in lock : <TAB><TAB><TAB><TAB><TAB> f = f . strip ( ) <TAB><TAB><TAB><TAB><TAB> if f in outputfiles : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB> for lockfile in self . _locks ( "" output "" ) : <TAB><TAB><TAB> with open ( lockfile ) as lock : <TAB><TAB><TAB><TAB> for f in lock : <TAB><TAB><TAB><TAB><TAB> f = f . strip ( ) <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if f in outputfiles or f in inputfiles :,if f in inputfiles :,92.52459619768707,98.53,False
4017,"def _flags_to_int ( flags ) : <TAB> # Note, that order does not matter, libev has its own predefined order <TAB> if not flags : <TAB><TAB> return 0 <TAB> if isinstance ( flags , integer_types ) : <TAB><TAB> return flags <TAB> result = 0 <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> flags = flags . split ( "" , "" ) <TAB><TAB> for value in flags : <TAB><TAB><TAB> value = value . strip ( ) . lower ( ) <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> result | = _flags_str2int [ value ] <TAB> except KeyError as ex : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" Invalid backend or flag:  %s \n Possible values:  %s "" <TAB><TAB><TAB> % ( ex , "" ,  "" . join ( sorted ( _flags_str2int . keys ( ) ) ) ) <TAB><TAB> ) <TAB> return result","if isinstance ( flags , basestring ) :","if "","" in flags :",72.53419475518457,97.29,False
4018,"def setFg ( self , colour , override = False ) : <TAB> if not self . ttkFlag : <TAB><TAB> self . containerStack [ - 1 ] [ "" fg "" ] = colour <TAB><TAB> gui . SET_WIDGET_FG ( self . _getContainerProperty ( "" container "" ) , colour , override ) <TAB><TAB> for child in self . _getContainerProperty ( "" container "" ) . winfo_children ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> gui . SET_WIDGET_FG ( child , colour , override ) <TAB> else : <TAB><TAB> gui . trace ( "" In ttk mode - trying to set FG to  %s "" , colour ) <TAB><TAB> self . ttkStyle . configure ( "" TLabel "" , foreground = colour ) <TAB><TAB> self . ttkStyle . configure ( "" TFrame "" , foreground = colour )",if not self . _isWidgetContainer ( child ) :,"if child . get ( ""fg"" ) == colour :",80.62808617818251,94.55,False
4019,"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB><TAB> v = f . features [ name ] <TAB><TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB><TAB><TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB><TAB><TAB><TAB> if name . startswith ( "" SCE_ "" ) : <TAB><TAB><TAB><TAB><TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","elif name . startswith ( ""SCLEX_"" ) :","elif name . startswith ( ""SCINTilla_"" ) :",98.93101970480124,98.76,False
4020,"def extract_error_message ( response : requests . Response ) : <TAB> if response . content : <TAB><TAB> try : <TAB><TAB><TAB> content = json . loads ( response . content ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return content [ "" message "" ] <TAB><TAB> except : <TAB><TAB><TAB> logging . debug ( f "" Failed to parse the response content:  { response . content } "" ) <TAB> return response . reason","if ""message"" in content :","if ""message"" in content :",100.0,100.00,True
4021,"def canvas_size ( self ) : <TAB> """"""Return the width and height for this sprite canvas"""""" <TAB> width = height = 0 <TAB> for image in self . images : <TAB><TAB> x = image . x + image . absolute_width <TAB><TAB> y = image . y + image . absolute_height <TAB><TAB> <MASK> <TAB><TAB><TAB> width = x <TAB><TAB> if height < y : <TAB><TAB><TAB> height = y <TAB> return round_up ( width ) , round_up ( height )",if width < x :,if width < x :,100.0,100.00,True
4022,"def _load_widgets ( self ) : <TAB> logger . info ( "" Loading plugins preferences widgets "" ) <TAB> # Collect the preferences widget for each active plugin <TAB> for plugin in self . plugin_manager . get_active_plugins ( ) : <TAB><TAB> plugin_name = plugin . metadata . get ( "" name "" ) <TAB><TAB> try : <TAB><TAB><TAB> preferences_widget = plugin . get_preferences_widget ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _tabs . addTab ( preferences_widget , plugin_name ) <TAB><TAB> except Exception as reason : <TAB><TAB><TAB> logger . error ( <TAB><TAB><TAB><TAB> "" Unable to add the preferences widget ( %s ):  %s "" , plugin_name , reason <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue",if preferences_widget :,if preferences_widget :,100.0,100.00,True
4023,"def clean_objects ( string , common_attributes ) : <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB><TAB> prefix_words_are_adj = True <TAB><TAB> for att in words [ : - 1 ] : <TAB><TAB><TAB> if att not in common_attributes : <TAB><TAB><TAB><TAB> prefix_words_are_adj = False <TAB><TAB> <MASK> <TAB><TAB><TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB><TAB> else : <TAB><TAB><TAB> return [ string ] , [ ] <TAB> else : <TAB><TAB> return [ string ] , [ ]",if prefix_words_are_adj :,if prefix_words_are_adj :,100.0,100.00,True
4024,"def _reader ( ) : <TAB> if shuffle : <TAB><TAB> random . shuffle ( file_list ) <TAB> while True : <TAB><TAB> for fn in file_list : <TAB><TAB><TAB> for line in open ( fn , "" r "" ) : <TAB><TAB><TAB><TAB> yield self . _process_line ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break",if not cycle :,if not file_list :,72.63480202930822,95.84,False
4025,"def load ( weights , model , K , fsz , dil ) : <TAB> index = 0 <TAB> layers = model . layers <TAB> for layer in layers . _layers : <TAB><TAB> <MASK> <TAB><TAB><TAB> if layer . W . shape == weights [ index ] . shape : <TAB><TAB><TAB><TAB> layer . W [ : ] = weights [ index ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> layer . W [ : ] = dilate ( weights [ index ] , K , fsz , dil ) <TAB><TAB><TAB> index + = 1","if hasattr ( layer , ""W"" ) :",if layer . W is not None :,93.71335487421935,94.24,False
4026,"def upgrade ( migrate_engine ) : <TAB> print ( __doc__ ) <TAB> metadata . bind = migrate_engine <TAB> liftoverjobs = dict ( ) <TAB> jobs = context . query ( DeferredJob ) . filter_by ( plugin = "" LiftOverTransferPlugin "" ) . all ( ) <TAB> for job in jobs : <TAB><TAB> <MASK> <TAB><TAB><TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] = [ ] <TAB><TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] . append ( job . id ) <TAB> for parent in liftoverjobs : <TAB><TAB> lifts = liftoverjobs [ parent ] <TAB><TAB> deferred = context . query ( DeferredJob ) . filter_by ( id = parent ) . first ( ) <TAB><TAB> deferred . params [ "" liftover "" ] = lifts <TAB> context . flush ( )","if job . params [ ""parentjob"" ] not in liftoverjobs :","if job . params [ ""parentjob"" ] not in liftoverjobs :",100.0,100.00,True
4027,"def get_refs ( self , recursive = False ) : <TAB> """""":see: AbstractExpression.get_refs()"""""" <TAB> if recursive : <TAB><TAB> conds_refs = self . refs + sum ( ( c . get_refs ( True ) for c in self . conds ) , [ ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> conds_refs . extend ( self . consequent . get_refs ( True ) ) <TAB><TAB> return conds_refs <TAB> else : <TAB><TAB> return self . refs",if self . consequent :,if self . consequent :,100.0,100.00,True
4028,"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . axis , int ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB><TAB> if "" momentum "" in self . args : <TAB><TAB><TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB><TAB><TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB><TAB><TAB><TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if ""axis"" in self . args :","if ""axis"" in self . args :",100.0,100.00,True
4029,"def CountMatches ( pat , predicate ) : <TAB> num_matches = 0 <TAB> for i in xrange ( 256 ) : <TAB><TAB> b = chr ( i ) <TAB><TAB> m = pat . match ( b ) <TAB><TAB> left = bool ( m ) <TAB><TAB> right = predicate ( i ) <TAB><TAB> if left != right : <TAB><TAB><TAB> self . fail ( "" i =  %d , b =  %r , match:  %s , predicate:  %s "" % ( i , b , left , right ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> num_matches + = 1 <TAB> return num_matches",if m :,if m :,100.0,100.00,True
4030,"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB><TAB> if len ( kwargs ) : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB><TAB><TAB><TAB><TAB> cls . __name__ <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB> if not args [ 0 ] : <TAB><TAB><TAB> return super ( ) . __new__ ( cls ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )","if isinstance ( args [ 0 ] , cls ) :",if not kwargs [ 0 ] :,66.89471272372668,95.85,False
4031,"def concatenateCharacterTokens ( tokens ) : <TAB> pendingCharacters = [ ] <TAB> for token in tokens : <TAB><TAB> type = token [ "" type "" ] <TAB><TAB> if type in ( "" Characters "" , "" SpaceCharacters "" ) : <TAB><TAB><TAB> pendingCharacters . append ( token [ "" data "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } <TAB><TAB><TAB><TAB> pendingCharacters = [ ] <TAB><TAB><TAB> yield token <TAB> <MASK> <TAB><TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) }",if pendingCharacters :,if pendingCharacters :,100.0,100.00,True
4032,"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB><TAB> if func . type in support_set : <TAB><TAB><TAB> pos_end = pos <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB><TAB><TAB> pos_start = pos + 1 <TAB> <MASK> <TAB><TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges",if pos_end >= pos_start :,"if func . type in ( ""linear"" , ""linear"" ) :",61.75719937329235,85.38,False
4033,"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB> import sys <TAB><TAB><TAB> sys . exit ( - 1 ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> else : <TAB><TAB> if fname not in self . _flags : <TAB><TAB><TAB> self . _flags [ fname ] = 1 <TAB><TAB> for output in func [ 3 ] : <TAB><TAB><TAB> for f in self . _orig : <TAB><TAB><TAB><TAB> for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB> if output == input : <TAB><TAB><TAB><TAB><TAB><TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if self . _flags [ fname ] == 1 :,if fname in self . _sorted :,95.8862643907256,96.45,False
4034,"def graph_merge_softmax_with_crossentropy_softmax ( node ) : <TAB> if node . op == softmax_with_bias : <TAB><TAB> x , b = node . inputs <TAB><TAB> for x_client in x . clients : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> big_client = x_client [ 0 ] <TAB><TAB><TAB><TAB> if big_client in [ b_client [ 0 ] for b_client in b . clients ] : <TAB><TAB><TAB><TAB><TAB> xx , bb , ll = big_client . inputs <TAB><TAB><TAB><TAB><TAB> mergeable_client = big_client . op ( x , b , ll ) <TAB><TAB><TAB><TAB><TAB> copy_stack_trace ( node . outputs [ 0 ] , mergeable_client [ 1 ] ) <TAB><TAB><TAB><TAB><TAB> return [ mergeable_client [ 1 ] ]",if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,if x_client in [ x_client [ 1 ] for x_client in b .,74.7189757640118,92.91,False
4035,"def confidence ( self ) : <TAB> if self . bbox : <TAB><TAB> # Units are measured in Kilometers <TAB><TAB> distance = Distance ( self . northeast , self . southwest , units = "" km "" ) <TAB><TAB> for score , maximum in [ <TAB><TAB><TAB> ( 10 , 0.25 ) , <TAB><TAB><TAB> ( 9 , 0.5 ) , <TAB><TAB><TAB> ( 8 , 1 ) , <TAB><TAB><TAB> ( 7 , 5 ) , <TAB><TAB><TAB> ( 6 , 7.5 ) , <TAB><TAB><TAB> ( 5 , 10 ) , <TAB><TAB><TAB> ( 4 , 15 ) , <TAB><TAB><TAB> ( 3 , 20 ) , <TAB><TAB><TAB> ( 2 , 25 ) , <TAB><TAB> ] : <TAB><TAB><TAB> if distance < maximum : <TAB><TAB><TAB><TAB> return score <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return 1 <TAB> # Cannot determine score <TAB> return 0",if distance >= 25 :,elif distance > maximum :,97.9457844021734,97.89,False
4036,"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB><TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB><TAB> for bp in bplist : <TAB><TAB><TAB> if id ( bp ) == item_id : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> text = None <TAB><TAB><TAB><TAB> bp . cond = text <TAB><TAB><TAB><TAB> break <TAB> self . RespondDebuggerData ( )","if text . strip ( ) . lower ( ) == ""none"" :",if bp . cond is None :,90.018192561356,92.16,False
4037,"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( text , CodeViewText ) : <TAB><TAB><TAB><TAB> text . autocompleter = Completer ( text ) <TAB><TAB><TAB> elif isinstance ( text , ShellText ) : <TAB><TAB><TAB><TAB> text . autocompleter = ShellCompleter ( text ) <TAB><TAB><TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",if text . autocompleter :,88.48141706205314,88.77,False
4038,"def visit_Macro ( self , node , frame ) : <TAB> macro_frame , macro_ref = self . macro_body ( node , frame ) <TAB> self . newline ( ) <TAB> if frame . toplevel : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . write ( "" context.exported_vars.add( %r ) "" % node . name ) <TAB><TAB> ref = frame . symbols . ref ( node . name ) <TAB><TAB> self . writeline ( "" context.vars[ %r ] =  "" % node . name ) <TAB> self . write ( "" %s  =  "" % frame . symbols . ref ( node . name ) ) <TAB> self . macro_def ( macro_ref , macro_frame )","if not node . name . startswith ( ""_"" ) :",if self . write_exported_vars :,78.07484806735283,93.37,False
4039,"def execute ( cls , ctx , op ) : <TAB> try : <TAB><TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return cls . _execute_map ( ctx , op ) <TAB><TAB> else : <TAB><TAB><TAB> return cls . _execute_combine ( ctx , op ) <TAB> finally : <TAB><TAB> pd . reset_option ( "" mode.use_inf_as_na "" )",if op . stage == OperandStage . map :,"if isinstance ( ctx , ( list , tuple ) ) :",65.67005879706682,92.03,False
4040,"def ranges ( self , start , end ) : <TAB> try : <TAB><TAB> iterators = [ i . ranges ( start , end ) for i in self . range_iterators ] <TAB><TAB> starts , ends , values = zip ( * [ next ( i ) for i in iterators ] ) <TAB><TAB> starts = list ( starts ) <TAB><TAB> ends = list ( ends ) <TAB><TAB> values = list ( values ) <TAB><TAB> while start < end : <TAB><TAB><TAB> min_end = min ( ends ) <TAB><TAB><TAB> yield start , min_end , values <TAB><TAB><TAB> start = min_end <TAB><TAB><TAB> for i , iterator in enumerate ( iterators ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> starts [ i ] , ends [ i ] , values [ i ] = next ( iterator ) <TAB> except StopIteration : <TAB><TAB> return",if ends [ i ] == min_end :,if i < len ( starts ) :,76.79223794216774,95.89,False
4041,"def get_explanation ( self , spec ) : <TAB> """"""Expand an explanation."""""" <TAB> if spec : <TAB><TAB> try : <TAB><TAB><TAB> a = self . dns_txt ( spec ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB><TAB> except PermError : <TAB><TAB><TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB><TAB><TAB> if self . strict > 1 : <TAB><TAB><TAB><TAB> raise # but report in harsh mode for record checking tools <TAB><TAB><TAB> pass <TAB> elif self . strict > 1 : <TAB><TAB> raise PermError ( "" Empty domain-spec on exp= "" ) <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if len ( a ) == 1 :,if len ( a ) == 1 :,100.0,100.00,True
4042,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB><TAB> if exclude_meta and field . meta : <TAB><TAB><TAB> continue <TAB><TAB> field_val = getattr ( node , field_name , _marker ) <TAB><TAB> if field_val is _marker : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> if callable ( field . default ) : <TAB><TAB><TAB><TAB> default = field . default ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> default = field . default <TAB><TAB><TAB> if field_val == default : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield field_name , field_val",if exclude_unset :,if field_val is not None and field_val is not exclude_unset :,96.41994417857327,94.63,False
4043,"def __setattr__ ( self , name , value ) : <TAB> try : <TAB><TAB> field = self . _meta . get_field ( name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = value [ : field . max_length ] <TAB> except models . fields . FieldDoesNotExist : <TAB><TAB> pass # This happens with foreign keys. <TAB> super . __setattr__ ( self , name , value )","if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",if field . max_length :,54.505151890052126,81.22,False
4044,"def create_child ( self , value = None , _id = None ) : <TAB> with atomic ( savepoint = False ) : <TAB><TAB> child_key = self . get_next_child_key ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = child_key <TAB><TAB> child = self . __class__ . objects . create ( id = _id , key = child_key , value = value ) <TAB><TAB> return child",if value is None :,if value is None :,100.0,100.00,True
4045,"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" HasMoreTags "" ] = True <TAB><TAB><TAB> break <TAB><TAB> if exclusive_start_tag_key and key < exclusive_start_tag_key : <TAB><TAB><TAB> continue <TAB><TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result",if limit and len ( tags ) >= limit :,"if limit and val [ ""Limit"" ] > limit :",85.82668130547975,96.00,False
4046,"def emit ( self , record ) : <TAB> try : <TAB><TAB> app = get_app ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = self . format ( record ) <TAB><TAB><TAB> debug_buffer = app . layout . get_buffer_by_name ( "" debug_buffer "" ) <TAB><TAB><TAB> current_document = debug_buffer . document . text <TAB><TAB><TAB> if current_document : <TAB><TAB><TAB><TAB> msg = "" \n "" . join ( [ current_document , msg ] ) <TAB><TAB><TAB> debug_buffer . set_document ( Document ( text = msg ) , bypass_readonly = True ) <TAB><TAB> else : <TAB><TAB><TAB> super ( ) . emit ( record ) <TAB> except : <TAB><TAB> self . handleError ( record )","if app . is_running and getattr ( app , ""debug"" , False ) :",if self . format :,66.36937980541164,92.42,False
4047,"def worker ( ) : <TAB> global error <TAB> while True : <TAB><TAB> ( num , q ) = pq . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pq . task_done ( ) <TAB><TAB><TAB> break <TAB><TAB> try : <TAB><TAB><TAB> process_one ( q ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> error = e <TAB><TAB> finally : <TAB><TAB><TAB> pq . task_done ( )",if q is None or error is not None :,if num == 0 :,62.671331151864194,93.36,False
4048,"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB><TAB> if data [ t ] == 0 : <TAB><TAB><TAB> continue <TAB><TAB> value = data [ t ] <TAB><TAB> for b in range ( 8 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if len ( TRANSCEIVER [ t ] ) < b + 1 : <TAB><TAB><TAB><TAB><TAB> out . append ( "" (unknown) "" ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB><TAB><TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) )",if value & 0x80 :,if value & 1 :,98.93309836958612,98.84,False
4049,"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB><TAB> tok = self . tokenizer . get_next_token ( ) <TAB><TAB> ttype = tok [ "" style "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB> tval = tok [ "" text "" ] <TAB><TAB><TAB> if self . opHash . has_key ( tval ) : <TAB><TAB><TAB><TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB> nestedCount + = 1 <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB> if nestedCount < = 0 : <TAB><TAB><TAB><TAB><TAB><TAB> break",if ttype == SCE_PL_UNUSED :,"if ttype == ""eof"" :",96.08583883855614,97.47,False
4050,"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB><TAB> if vector : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if item > self . max_separation + vector [ - 1 ] : <TAB><TAB><TAB><TAB> break <TAB><TAB> new_vector = vector + [ item ] <TAB><TAB> if level + 1 == len ( hits ) : <TAB><TAB><TAB> yield new_vector <TAB><TAB> elif level + 1 < len ( hits ) : <TAB><TAB><TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB><TAB><TAB><TAB> yield result",if item < vector [ - 1 ] :,if item < vector [ - 1 ] :,100.0,100.00,True
4051,"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> if value [ 0 ] != "" / "" : <TAB><TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB><TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB><TAB><TAB><TAB> ) <TAB> elif name == "" load_time "" : <TAB><TAB> if value and not isinstance ( value , int ) : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Page load time must be specified in integer milliseconds. "" <TAB><TAB><TAB> ) <TAB> object . __setattr__ ( self , name , value )","if value and value != """" :",if value :,70.74601146567484,96.43,False
4052,"def awaitTermination ( self , timeout = None ) : <TAB> if self . scheduler is None : <TAB><TAB> raise RuntimeError ( "" StreamimgContext not started "" ) <TAB> try : <TAB><TAB> deadline = time . time ( ) + timeout if timeout is not None else None <TAB><TAB> while True : <TAB><TAB><TAB> is_terminated = self . _runOnce ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if self . batchCallback : <TAB><TAB><TAB><TAB> self . batchCallback ( ) <TAB> except KeyboardInterrupt : <TAB><TAB> pass <TAB> finally : <TAB><TAB> self . sc . stop ( ) <TAB><TAB> logger . info ( "" StreamingContext stopped successfully "" )",if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,if is_terminated :,68.42385303269613,91.87,False
4053,"def stopbutton ( self ) : <TAB> if GPIOcontrol : <TAB><TAB> while mediastopbutton : <TAB><TAB><TAB> time . sleep ( 0.25 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> print ( "" Stopped "" ) <TAB><TAB><TAB><TAB> stop ( )",if not GPIO . input ( stoppushbutton ) :,if self . debug :,60.62463314831821,90.28,False
4054,"def test_create_connection_timeout ( self ) : <TAB> # Issue #9792: create_connection() should not recast timeout errors <TAB> # as generic socket errors. <TAB> with self . mocked_socket_module ( ) : <TAB><TAB> try : <TAB><TAB><TAB> socket . create_connection ( ( HOST , 1234 ) ) <TAB><TAB> except socket . timeout : <TAB><TAB><TAB> pass <TAB><TAB> except OSError as exc : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( "" socket.timeout not raised "" )",if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,if exc . errno != errno . EINTR :,70.29783160645216,94.39,False
4055,"def handle_exception_and_die ( e ) : <TAB> if hasattr ( e , "" kind "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> sys . stderr . write ( "" ABORT:  "" + e . msg + "" \n "" ) <TAB><TAB><TAB> sys . exit ( e . value ) <TAB><TAB> elif e . kind == "" exit "" : <TAB><TAB><TAB> sys . stderr . write ( "" EXITING \n "" ) <TAB><TAB><TAB> sys . exit ( e . value ) <TAB> else : <TAB><TAB> print ( str ( e ) ) <TAB><TAB> sys . exit ( 1 )","if e . kind == ""die"" :","if e . kind == ""abort"" :",73.7564242548323,98.52,False
4056,"def gets ( self , key ) : <TAB> with self . client_pool . get_and_release ( destroy_on_fail = True ) as client : <TAB><TAB> try : <TAB><TAB><TAB> return client . gets ( key ) <TAB><TAB> except Exception : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return ( None , None ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise",if self . ignore_exc :,if self . ignore_exc :,75.0,100.00,True
4057,"def _execute ( self , options , args ) : <TAB> if len ( args ) < 3 : <TAB><TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> tag = fsn2text ( args [ 0 ] ) <TAB> value = fsn2text ( args [ 1 ] ) <TAB> paths = args [ 2 : ] <TAB> songs = [ ] <TAB> for path in paths : <TAB><TAB> song = self . load_song ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CommandError ( _ ( "" Can not set  %r "" ) % tag ) <TAB><TAB> self . log ( "" Add  %r  to  %r "" % ( value , tag ) ) <TAB><TAB> song . add ( tag , value ) <TAB><TAB> songs . append ( song ) <TAB> self . save_songs ( songs )",if not song . can_change ( tag ) :,if not song :,83.42423329815489,95.87,False
4058,"def get_place_name ( self , place_handle ) : <TAB> """"""Obtain a place name"""""" <TAB> text = "" "" <TAB> if place_handle : <TAB><TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB><TAB> if place : <TAB><TAB><TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if len ( place_title ) > 25 : <TAB><TAB><TAB><TAB><TAB> text = place_title [ : 24 ] + "" ... "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> text = place_title <TAB> return text","if place_title != """" :",if place_title :,71.34006337241495,97.39,False
4059,"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> self . value = os . environ . get ( self . name , None ) <TAB> if self . value is None and black . configure . items . has_key ( "" buildType "" ) : <TAB><TAB> buildType = black . configure . items [ "" buildType "" ] . Get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . value = "" warn "" <TAB><TAB> else : <TAB><TAB><TAB> self . value = None <TAB> self . determined = 1","if buildType == ""debug"" :","if buildType == ""warn"" :",98.6837175755287,98.22,False
4060,"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB><TAB> nm = _u ( nm ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> itempath = os . path . join ( dirpath , nm ) <TAB><TAB> if os . path . isdir ( itempath ) : <TAB><TAB><TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB><TAB><TAB><TAB> self . bundle_package ( itempath ) <TAB><TAB> elif nm . endswith ( "" .py "" ) : <TAB><TAB><TAB> self . bundle_module ( itempath )","if nm . startswith ( ""."" ) :","if not os . path . isfile ( os . path . join ( dirpath , nm ) )",67.13917840603763,91.89,False
4061,"def header_fields ( self , fields ) : <TAB> headers = dict ( self . conn . response . getheaders ( ) ) <TAB> ret = { } <TAB> for field in fields : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" %s  was not found in response header "" % ( field [ 1 ] ) ) <TAB><TAB> try : <TAB><TAB><TAB> ret [ field [ 0 ] ] = int ( headers [ field [ 1 ] ] ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> ret [ field [ 0 ] ] = headers [ field [ 1 ] ] <TAB> return ret",if not headers . has_key ( field [ 1 ] ) :,if field [ 1 ] not in headers :,68.45068348611098,93.53,False
4062,"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB><TAB> n = ord ( char ) <TAB><TAB> <MASK> <TAB><TAB><TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB><TAB> if 96 < n < 123 : <TAB><TAB><TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB><TAB> result = result + chr ( n ) <TAB> return result",if 64 < n < 91 :,if 64 < n < 48 :,98.52245736880025,98.04,False
4063,"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB><TAB> # DataType doesn't have len function then convert it to string <TAB><TAB> if not hasattr ( val , "" __len__ "" ) : <TAB><TAB><TAB> val = str ( val ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> value = val <TAB><TAB> if Driver . needsQuoting ( val , True ) : <TAB><TAB><TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB><TAB><TAB> value = ' "" ' + value + ' "" ' <TAB><TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res",if len ( val ) == 0 :,"if not hasattr ( val , ""__len__"" ) :",72.81972549233132,94.64,False
4064,"def _parse_timezone ( <TAB> value : Optional [ str ] , error : Type [ Exception ] ) - > Union [ None , int , timezone ] : <TAB> if value == "" Z "" : <TAB><TAB> return timezone . utc <TAB> elif value is not None : <TAB><TAB> offset_mins = int ( value [ - 2 : ] ) if len ( value ) > 3 else 0 <TAB><TAB> offset = 60 * int ( value [ 1 : 3 ] ) + offset_mins <TAB><TAB> <MASK> <TAB><TAB><TAB> offset = - offset <TAB><TAB> try : <TAB><TAB><TAB> return timezone ( timedelta ( minutes = offset ) ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> raise error ( ) <TAB> else : <TAB><TAB> return None","if value [ 0 ] == ""-"" :",if offset < 0 :,70.23254428913029,94.98,False
4065,"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * ""    "" <TAB> if len ( elem ) : <TAB><TAB> if not elem . text or not elem . text . strip ( ) : <TAB><TAB><TAB> elem . text = i + ""    "" <TAB><TAB> <MASK> <TAB><TAB><TAB> elem . tail = i <TAB><TAB> for elem in elem : <TAB><TAB><TAB> indent ( elem , level + 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> elem . tail = i <TAB> else : <TAB><TAB> if level and ( not elem . tail or not elem . tail . strip ( ) ) : <TAB><TAB><TAB> elem . tail = i",if not elem . tail or not elem . tail . strip ( ) :,if not elem . tail or not elem . tail . strip ( ) :,100.0,100.00,True
4066,"def _make_slices ( <TAB> shape : tp . Tuple [ int , . . . ] , <TAB> axes : tp . Tuple [ int , . . . ] , <TAB> size : int , <TAB> rng : np . random . RandomState , ) - > tp . List [ slice ] : <TAB> slices = [ ] <TAB> for a , s in enumerate ( shape ) : <TAB><TAB> if a in axes : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValueError ( "" Cannot crossover on axis with size 1 "" ) <TAB><TAB><TAB> start = rng . randint ( s - size ) <TAB><TAB><TAB> slices . append ( slice ( start , start + size ) ) <TAB><TAB> else : <TAB><TAB><TAB> slices . append ( slice ( None ) ) <TAB> return slices",if s <= 1 :,if s < size :,95.78292699031388,98.31,False
4067,"def _loadTestsFromTestCase ( self , event , testCaseClass ) : <TAB> evt = events . LoadFromTestCaseEvent ( event . loader , testCaseClass ) <TAB> result = self . session . hooks . loadTestsFromTestCase ( evt ) <TAB> if evt . handled : <TAB><TAB> loaded_suite = result or event . loader . suiteClass ( ) <TAB> else : <TAB><TAB> names = self . _getTestCaseNames ( event , testCaseClass ) <TAB><TAB> <MASK> <TAB><TAB><TAB> names = [ "" runTest "" ] <TAB><TAB> # FIXME return failure test case if name not in testcase class <TAB><TAB> loaded_suite = event . loader . suiteClass ( map ( testCaseClass , names ) ) <TAB> if evt . extraTests : <TAB><TAB> loaded_suite . addTests ( evt . extraTests ) <TAB> return loaded_suite","if not names and hasattr ( testCaseClass , ""runTest"" ) :",if not names :,92.32436070120664,94.55,False
4068,"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB><TAB> if not settings . USE_TZ : <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB><TAB><TAB><TAB> "" False. "" % self . alias <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ImproperlyConfigured ( <TAB><TAB><TAB><TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB><TAB><TAB><TAB> "" handles time zones conversions natively. "" % self . alias <TAB><TAB><TAB> )",elif self . features . supports_timezones :,"if self . settings_dict [ ""TIME_ZONE"" ] is True :",93.63887680365306,92.48,False
4069,"def collect_conflicting_diffs ( path , decisions ) : <TAB> local_conflict_diffs = [ ] <TAB> remote_conflict_diffs = [ ] <TAB> for d in decisions : <TAB><TAB> <MASK> <TAB><TAB><TAB> ld = adjust_patch_level ( path , d . common_path , d . local_diff ) <TAB><TAB><TAB> rd = adjust_patch_level ( path , d . common_path , d . remote_diff ) <TAB><TAB><TAB> local_conflict_diffs . extend ( ld ) <TAB><TAB><TAB> remote_conflict_diffs . extend ( rd ) <TAB> return local_conflict_diffs , remote_conflict_diffs",if d . conflict :,if d . common_path :,97.74523362551773,97.32,False
4070,"def short_repr ( obj ) : <TAB> if isinstance ( <TAB><TAB> obj , <TAB><TAB> ( type , types . ModuleType , types . BuiltinMethodType , types . BuiltinFunctionType ) , <TAB> ) : <TAB><TAB> return obj . __name__ <TAB> if isinstance ( obj , types . MethodType ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return obj . im_func . __name__ + ""  (bound) "" <TAB><TAB> else : <TAB><TAB><TAB> return obj . im_func . __name__ <TAB> if isinstance ( obj , ( tuple , list , dict , set ) ) : <TAB><TAB> return "" %d  items "" % len ( obj ) <TAB> if isinstance ( obj , weakref . ref ) : <TAB><TAB> return "" all_weakrefs_are_one "" <TAB> return repr ( obj ) [ : 40 ]",if obj . im_self is not None :,"if obj . im_func . __name__ . startswith ( ""bound"" ) :",70.38555657353905,93.36,False
4071,"def _massage_uri ( uri ) : <TAB> if uri : <TAB><TAB> <MASK> <TAB><TAB><TAB> uri = uri . replace ( "" hdfs:// "" , get_defaultfs ( ) ) <TAB><TAB> elif uri . startswith ( "" / "" ) : <TAB><TAB><TAB> uri = get_defaultfs ( ) + uri <TAB> return uri","if uri . startswith ( ""hdfs:///"" ) :","if uri . startswith ( ""hdfs://"" ) :",97.70076290860976,98.76,False
4072,"def chsub ( self , msg , chatid ) : <TAB> ( cmd , evt , params ) = self . tokenize ( msg , 3 ) <TAB> if cmd == "" /sub "" : <TAB><TAB> sql = "" replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?) "" <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> sql = "" delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1) "" # does not look very elegant, but makes unsub'ing everythign possible <TAB><TAB> else : <TAB><TAB><TAB> sql = "" delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ? "" <TAB> with self . bot . database as conn : <TAB><TAB> conn . execute ( sql , [ chatid , evt , params ] ) <TAB><TAB> conn . commit ( ) <TAB> return","if evt == ""everything"" :","if evt == ""delete"" :",99.16057205967415,98.90,False
4073,"def undefined_symbols ( self ) : <TAB> result = [ ] <TAB> for p in self . Productions : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for s in p . prod : <TAB><TAB><TAB> if not s in self . Prodnames and not s in self . Terminals and s != "" error "" : <TAB><TAB><TAB><TAB> result . append ( ( s , p ) ) <TAB> return result",if not p :,if not p . is_constant :,69.02412943122023,95.34,False
4074,"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB><TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB><TAB> if m is not None : <TAB><TAB><TAB> sx , sy = m . groups ( ) <TAB><TAB><TAB> x = colname2num ( sx ) <TAB><TAB><TAB> y = int ( sy ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> part = cellname ( x + dx , y + dy ) <TAB><TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment )",if x1 <= x <= x2 and y1 <= y <= y2 :,if x < x2 and y < y2 :,74.74539746368197,94.14,False
4075,"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB><TAB> gate = column [ i ] <TAB><TAB> if gate is self : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> # The first parity control to modify the column must merge all <TAB><TAB><TAB> # of the other parity controls into itself. <TAB><TAB><TAB> column [ i ] = None <TAB><TAB><TAB> self . _basis_change + = gate . _basis_change <TAB><TAB><TAB> self . qubits + = gate . qubits <TAB><TAB> elif gate is not None : <TAB><TAB><TAB> column [ i ] = gate . controlled_by ( self . qubits [ 0 ] )","elif isinstance ( gate , ParityControlCell ) :","if isinstance ( gate , ParenthesisGate ) :",81.1771444614095,97.64,False
4076,"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB><TAB> if k == neighbors . ENABLED : <TAB><TAB><TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB><TAB> if k == neighbors . CONNECT_MODE : <TAB><TAB><TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . MULTI_EXIT_DISC :,if k == neighbors . MAGIC :,98.60694803356351,96.24,False
4077,"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB><TAB> val = self . nodeValue <TAB><TAB> if not isinstance ( val , str ) : <TAB><TAB><TAB> val = str ( self . nodeValue ) <TAB> else : <TAB><TAB> v = self . nodeValue <TAB><TAB> <MASK> <TAB><TAB><TAB> v = str ( v ) <TAB><TAB> if strip : <TAB><TAB><TAB> v = ""   "" . join ( v . split ( ) ) <TAB><TAB> val = escape ( v ) <TAB> w ( val )","if not isinstance ( v , str ) :","if not isinstance ( v , str ) :",100.0,100.00,True
4078,"def _condition ( ct ) : <TAB> for qobj in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> # normal kwargs are an AND anyway, so just use those for now <TAB><TAB><TAB> for child in qobj . children : <TAB><TAB><TAB><TAB> kwargs . update ( dict ( [ child ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( "" Unsupported Q object "" ) <TAB> for attr , val in kwargs . items ( ) : <TAB><TAB> if getattr ( ct , attr ) != val : <TAB><TAB><TAB> return False <TAB> return True","if qobj . connector == ""AND"" and not qobj . negated :","if isinstance ( qobj , QObject ) :",69.89521662015417,91.54,False
4079,"def results_iter ( self ) : <TAB> <MASK> <TAB><TAB> from django . db . models . fields import DateTimeField <TAB><TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB><TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB><TAB> for row in rows : <TAB><TAB><TAB> date = row [ offset ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB><TAB><TAB> elif needs_string_cast : <TAB><TAB><TAB><TAB> date = typecast_timestamp ( str ( date ) ) <TAB><TAB><TAB> yield date",if self . connection . ops . oracle :,if fields :,74.0716395879049,92.45,False
4080,"def get_job_type ( self ) : <TAB> if int ( self . job_runtime_conf . get ( "" dsl_version "" , 1 ) ) == 2 : <TAB><TAB> job_type = ( <TAB><TAB><TAB> self . job_runtime_conf [ "" job_parameters "" ] . get ( "" common "" , { } ) . get ( "" job_type "" ) <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> else : <TAB><TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> return job_type",if not job_type :,"if job_type == ""train"" :",74.6220502344638,96.04,False
4081,"def validate_assessment_criteria ( self ) : <TAB> if self . assessment_criteria : <TAB><TAB> total_weightage = 0 <TAB><TAB> for criteria in self . assessment_criteria : <TAB><TAB><TAB> total_weightage + = criteria . weightage or 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( _ ( "" Total Weightage of all Assessment Criteria must be 100 % "" ) )",if total_weightage != 100 :,if total_weightage > 100 :,97.86269711562517,96.70,False
4082,"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB><TAB> for x in notifications_list : <TAB><TAB><TAB> split_provider_id = x . split ( "" : "" ) # email:id <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> _id = split_provider_id [ 1 ] <TAB><TAB><TAB><TAB> cursor = self . get_by_id ( _id ) <TAB><TAB><TAB><TAB> if cursor : # Append if exists <TAB><TAB><TAB><TAB><TAB> result . append ( cursor ) <TAB> return result",if len ( split_provider_id ) == 2 :,"if split_provider_id [ 0 ] == ""email:id"" :",95.91095188392285,93.90,False
4083,"def dump_predictions_to_database ( relation , predictions ) : <TAB> judge = "" iepy-run on  {} "" . format ( datetime . now ( ) . strftime ( "" % Y- % m- %d   % H: % M "" ) ) <TAB> for evidence , relation_is_present in predictions . items ( ) : <TAB><TAB> label = ( <TAB><TAB><TAB> EvidenceLabel . YESRELATION <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else EvidenceLabel . NORELATION <TAB><TAB> ) <TAB><TAB> evidence . set_label ( relation , label , judge , labeled_by_machine = True )",if relation_is_present,if relation_is_present,100.0,100.00,True
4084,"def __init__ ( self , * * kwargs ) : <TAB> # We hard-code the `to` argument for ForeignKey.__init__ <TAB> dfl = get_model_label ( self . default_model_class ) <TAB> if "" to "" in kwargs . keys ( ) : # pragma: no cover <TAB><TAB> old_to = get_model_label ( kwargs . pop ( "" to "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> msg = "" %s  can only be a ForeignKey to  %s ;  %s  passed "" % ( <TAB><TAB><TAB><TAB> self . __class__ . __name__ , <TAB><TAB><TAB><TAB> dfl , <TAB><TAB><TAB><TAB> old_to , <TAB><TAB><TAB> ) <TAB><TAB><TAB> warnings . warn ( msg , SyntaxWarning ) <TAB> kwargs [ "" to "" ] = dfl <TAB> super ( ) . __init__ ( * * kwargs )",if old_to . lower ( ) != dfl . lower ( ) :,if old_to != dfl :,70.95024744713027,95.67,False
4085,"def reverse ( self ) : <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB><TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB><TAB> li + = 1 <TAB><TAB> if li > = BLOCKLEN : <TAB><TAB><TAB> lb = lb . rightlink <TAB><TAB><TAB> li = 0 <TAB><TAB> ri - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> rb = rb . leftlink <TAB><TAB><TAB> ri = BLOCKLEN - 1",if ri < 0 :,if ri == 0 :,98.94557084598661,98.23,False
4086,"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB><TAB> API_CACHE_LOCK . acquire ( ) <TAB><TAB> try : <TAB><TAB><TAB> if API_CACHE is None : <TAB><TAB><TAB><TAB> API_CACHE = { } <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB><TAB> finally : <TAB><TAB><TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api",if API_CACHE . get ( url ) is None :,if not API_CACHE . get ( url ) :,77.74494227712839,97.36,False
4087,"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB><TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB><TAB> start , stop = index . start , index . stop <TAB><TAB> new_start , new_stop = None , None <TAB><TAB> if start is not None : <TAB><TAB><TAB> new_stop = length - start <TAB><TAB> <MASK> <TAB><TAB><TAB> new_start = length - stop <TAB><TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB><TAB> new_index = [ ] <TAB><TAB> for ind in index : <TAB><TAB><TAB> new_index . append ( length - ind ) <TAB> return new_index",if stop is not None :,if stop is not None :,100.0,100.00,True
4088,"def infer_returned_object ( pyfunction , args ) : <TAB> """"""Infer the `PyObject` this `PyFunction` returns after calling"""""" <TAB> object_info = pyfunction . pycore . object_info <TAB> result = object_info . get_exact_returned ( pyfunction , args ) <TAB> if result is not None : <TAB><TAB> return result <TAB> result = _infer_returned ( pyfunction , args ) <TAB> if result is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> params = args . get_arguments ( pyfunction . get_param_names ( special_args = False ) ) <TAB><TAB><TAB> object_info . function_called ( pyfunction , params , result ) <TAB><TAB> return result <TAB> return object_info . get_returned ( pyfunction , args )",if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,if result is not None :,75.44563396037843,91.94,False
4089,"def _check_imports ( lib ) : <TAB> # Make sure no conflicting libraries have been imported. <TAB> libs = [ "" PyQt4 "" , "" PyQt5 "" , "" PySide "" ] <TAB> libs . remove ( lib ) <TAB> for lib2 in libs : <TAB><TAB> lib2 + = "" .QtCore "" <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> "" Refusing to import  %s  because  %s  is already  "" "" imported. "" % ( lib , lib2 ) <TAB><TAB><TAB> )",if lib2 in sys . modules :,if lib2 in libs :,72.38419392480178,96.72,False
4090,"def _poll ( fds , timeout ) : <TAB> if timeout is not None : <TAB><TAB> timeout = int ( timeout * 1000 ) # timeout is in milliseconds <TAB> fd_map = { } <TAB> pollster = select . poll ( ) <TAB> for fd in fds : <TAB><TAB> pollster . register ( fd , select . POLLIN ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fd_map [ fd . fileno ( ) ] = fd <TAB><TAB> else : <TAB><TAB><TAB> fd_map [ fd ] = fd <TAB> ls = [ ] <TAB> for fd , event in pollster . poll ( timeout ) : <TAB><TAB> if event & select . POLLNVAL : <TAB><TAB><TAB> raise ValueError ( "" invalid file descriptor  %i "" % fd ) <TAB><TAB> ls . append ( fd_map [ fd ] ) <TAB> return ls","if hasattr ( fd , ""fileno"" ) :",if fd . fileno ( ) :,97.8810473730313,96.46,False
4091,"def default ( cls , connection = None ) : <TAB> """"""show the default connection, or make CONNECTION the default"""""" <TAB> if connection is not None : <TAB><TAB> target = cls . _get_config_filename ( connection ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if os . path . exists ( cls . _default_symlink ) : <TAB><TAB><TAB><TAB> os . remove ( cls . _default_symlink ) <TAB><TAB><TAB> os . symlink ( target , cls . _default_symlink ) <TAB><TAB> else : <TAB><TAB><TAB> cls . _no_config_file_error ( target ) <TAB> if os . path . exists ( cls . _default_symlink ) : <TAB><TAB> print ( "" Default connection is  "" + cls . _default_connection ( ) ) <TAB> else : <TAB><TAB> print ( "" There is no default connection set "" )",if os . path . exists ( target ) :,if target :,75.12092363071675,96.01,False
4092,"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB><TAB> record = line . split ( "" / "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB> # Directory <TAB><TAB><TAB> if record [ 0 ] == "" D "" : <TAB><TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB><TAB><TAB><TAB> self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) )",if len ( record ) == 6 and record [ 1 ] :,"if record [ 0 ] == ""CVS"" :",90.44044175923945,94.26,False
4093,"def _GetCSVRow ( self , value ) : <TAB> row = [ ] <TAB> for type_info in value . __class__ . type_infos : <TAB><TAB> <MASK> <TAB><TAB><TAB> row . extend ( self . _GetCSVRow ( value . Get ( type_info . name ) ) ) <TAB><TAB> elif isinstance ( type_info , rdf_structs . ProtoBinary ) : <TAB><TAB><TAB> row . append ( text . Asciify ( value . Get ( type_info . name ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> row . append ( str ( value . Get ( type_info . name ) ) ) <TAB> return row","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :","if isinstance ( type_info , rdf_structs . ProtoStruct ) :",98.80701920898194,98.55,False
4094,"def get_history ( self , state , dict_ , passive = PASSIVE_OFF ) : <TAB> if self . key in dict_ : <TAB><TAB> return History . from_scalar_attribute ( self , state , dict_ [ self . key ] ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> passive ^ = INIT_OK <TAB><TAB> current = self . get ( state , dict_ , passive = passive ) <TAB><TAB> if current is PASSIVE_NO_RESULT : <TAB><TAB><TAB> return HISTORY_BLANK <TAB><TAB> else : <TAB><TAB><TAB> return History . from_scalar_attribute ( self , state , current )",if passive & INIT_OK :,if passive & INIT_OK :,100.0,100.00,True
4095,"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB><TAB> result + = ( current , ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> elif current . _parent is None : <TAB><TAB><TAB> raise sa_exc . InvalidRequestError ( <TAB><TAB><TAB><TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> current = current . _parent <TAB> return result",if current . _parent is upto :,if upto is None :,73.9730168842823,95.81,False
4096,"def get_by_uri ( self , uri : str ) - > bytes : <TAB> userId , bucket , key = self . _parse_uri ( uri ) <TAB> try : <TAB><TAB> with db . session_scope ( ) as dbsession : <TAB><TAB><TAB> result = db_archivedocument . get ( userId , bucket , key , session = dbsession ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return utils . ensure_bytes ( self . _decode ( result ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise ObjectKeyNotFoundError ( userId , bucket , key , caused_by = None ) <TAB> except Exception as err : <TAB><TAB> logger . debug ( "" cannot get data: exception -  "" + str ( err ) ) <TAB><TAB> raise err",if result :,if result :,100.0,100.00,True
4097,"def app ( scope , receive , send ) : <TAB> while True : <TAB><TAB> message = await receive ( ) <TAB><TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB><TAB><TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB><TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB><TAB><TAB> pass <TAB><TAB> <MASK> <TAB><TAB><TAB> break","elif message [ ""type"" ] == ""websocket.disconnect"" :","elif message [ ""type"" ] == ""websocket.disconnect"" :",100.0,100.00,True
4098,"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB><TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB><TAB> pr = p . recv_err <TAB> else : <TAB><TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB><TAB> r = pr ( ) <TAB><TAB> if r is None : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> y . append ( r ) <TAB><TAB> else : <TAB><TAB><TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y )",elif r :,if r :,79.25196755383422,98.86,False
4099,"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> p = event . local <TAB><TAB><TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB> self . scroll_up ( ) <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB><TAB><TAB><TAB> self . scroll_down ( ) <TAB><TAB><TAB><TAB> return <TAB> if event . button == 4 : <TAB><TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB><TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",if self . scrolling :,if self . scroll_up_rect ( ) . collidepoint ( event . local ),80.96624282651186,93.30,False
4100,"def copy_from ( self , other ) : <TAB> if self is other : <TAB><TAB> return # Myself! <TAB> self . strictness = other . strictness # sets behaviors in bulk <TAB> for name in self . all_behaviors : <TAB><TAB> self . set_behavior ( name , other . get_behavior ( name ) ) <TAB> for name in self . _plain_attrs : <TAB><TAB> val = getattr ( other , name ) <TAB><TAB> if isinstance ( val , set ) : <TAB><TAB><TAB> val = val . copy ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> val = val . copy ( ) <TAB><TAB> setattr ( self , name , val )","elif decimal and isinstance ( val , decimal . Decimal ) :","elif isinstance ( val , dict ) :",71.4407773405976,95.57,False
4101,"def __array_wrap__ ( self , out_arr , context = None ) : <TAB> if self . dim is None : <TAB><TAB> return out_arr <TAB> else : <TAB><TAB> this = self [ : ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return Quantity . __array_wrap__ ( self [ : ] , out_arr , context = context ) <TAB><TAB> else : <TAB><TAB><TAB> return out_arr","if isinstance ( this , Quantity ) :","if isinstance ( this , ( Quantity , list ) ) :",77.5980661217219,95.08,False
4102,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB><TAB> while token : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB> if token . ClosesScope ( ) : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if token . OpensScope ( ) : <TAB><TAB><TAB><TAB> token = token . matching_bracket <TAB><TAB><TAB> token = token . next_token <TAB> return False","if token . value == ""{"" :","if token . Name == ""arg"" :",97.90952421374823,97.62,False
4103,"def save_all_changed_extensions ( self ) : <TAB> """"""Save configuration changes to the user config file."""""" <TAB> has_changes = False <TAB> for ext_name in self . extensions : <TAB><TAB> options = self . extensions [ ext_name ] <TAB><TAB> for opt in options : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> has_changes = True <TAB> if has_changes : <TAB><TAB> self . ext_userCfg . Save ( )","if self . set_extension_value ( ext_name , opt ) :","if opt . Name != ""user_config"" :",87.00355070442508,89.46,False
4104,"def to_dict ( self ) : <TAB> out = { } <TAB> for key in ACTIVITY_KEYS : <TAB><TAB> attr = getattr ( self , key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> out [ key ] = str ( attr ) <TAB><TAB> else : <TAB><TAB><TAB> out [ key ] = attr <TAB> if self . streak : <TAB><TAB> out [ "" streak "" ] = self . streak <TAB> return out","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :","if isinstance ( attr , ( int , float ) ) :",84.21748928935004,93.60,False
4105,"def clean_publication_date ( cls , cleaned_input ) : <TAB> for add_channel in cleaned_input . get ( "" add_channels "" , [ ] ) : <TAB><TAB> is_published = add_channel . get ( "" is_published "" ) <TAB><TAB> publication_date = add_channel . get ( "" publication_date "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> add_channel [ "" publication_date "" ] = datetime . date . today ( )",if is_published and not publication_date :,if is_published and publication_date . isdigit ( ) :,68.32679663041552,94.43,False
4106,"def _random_blur ( self , batch , sigma_max ) : <TAB> for i in range ( len ( batch ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Random sigma <TAB><TAB><TAB> sigma = random . uniform ( 0.0 , sigma_max ) <TAB><TAB><TAB> batch [ i ] = scipy . ndimage . filters . gaussian_filter ( batch [ i ] , sigma ) <TAB> return batch",if bool ( random . getrandbits ( 1 ) ) :,if random . random ( ) < sigma_max :,78.73356955470709,91.80,False
4107,"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB><TAB> if dsn [ i ] . isspace ( ) : <TAB><TAB><TAB> i + = 1 <TAB><TAB><TAB> continue <TAB><TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB> if not param_match : <TAB><TAB><TAB> return <TAB><TAB> param = param_match . group ( 1 ) <TAB><TAB> i + = param_match . end ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB> if value is None : <TAB><TAB><TAB> return <TAB><TAB> i + = end <TAB><TAB> ret [ param ] = value <TAB> return ret",if i >= length :,"if param not in ( ""None"" , ""None"" ) :",69.67884662246641,94.63,False
4108,"def set_environment_vars ( env , source_env ) : <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env : <TAB><TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB><TAB> if is_forwarded_environment_variable ( name ) : <TAB><TAB><TAB> # Avoid creating circular dependencies from importing environment by <TAB><TAB><TAB> # using os.getenv. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = file_host . rebase_to_worker_root ( value ) <TAB><TAB><TAB> env [ name ] = value","if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :","if name == ""worker_root"" :",92.71389523035582,88.58,False
4109,"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i , entry in enumerate ( self . reprentries ) : <TAB><TAB> if entry . style == "" long "" : <TAB><TAB><TAB> tw . line ( "" "" ) <TAB><TAB> entry . toterminal ( tw ) <TAB><TAB> <MASK> <TAB><TAB><TAB> next_entry = self . reprentries [ i + 1 ] <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> entry . style == "" long "" <TAB><TAB><TAB><TAB> or entry . style == "" short "" <TAB><TAB><TAB><TAB> and next_entry . style == "" long "" <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> tw . sep ( self . entrysep ) <TAB> if self . extraline : <TAB><TAB> tw . line ( self . extraline )",if i < len ( self . reprentries ) - 1 :,"elif entry . style == ""short"" :",70.46025298080721,95.11,False
4110,"def __init__ ( self , loc , tabs = None ) : <TAB> if os . path . isdir ( loc ) : <TAB><TAB> for item in os . listdir ( loc ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> path = os . path . join ( loc , item ) <TAB><TAB><TAB> self . append ( CronTab ( user = False , tabfile = path ) ) <TAB> elif os . path . isfile ( loc ) : <TAB><TAB> self . append ( CronTab ( user = False , tabfile = loc ) )","if item [ 0 ] == ""."" :","if item . startswith ( ""_"" ) :",94.78189838137288,94.36,False
4111,"def import_data ( self , fname ) : <TAB> """"""Import data in current namespace"""""" <TAB> if self . count ( ) : <TAB><TAB> nsb = self . currentWidget ( ) <TAB><TAB> nsb . refresh_table ( ) <TAB><TAB> nsb . import_data ( fname ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . dockwidget . setVisible ( True ) <TAB><TAB><TAB> self . dockwidget . raise_ ( )",if self . dockwidget and not self . ismaximized :,if self . dockwidget :,65.56937253291473,94.65,False
4112,"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB><TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB><TAB><TAB><TAB> if tag == "" @menu "" : <TAB><TAB><TAB><TAB><TAB> aList . append ( ( "" %s   %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB><TAB><TAB><TAB><TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB><TAB><TAB><TAB> break <TAB> return aList",if child . h . startswith ( tag ) :,if child . h . startswith ( tag ) :,100.0,100.00,True
4113,"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB><TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB><TAB> if hasattr ( args [ 0 ] , "" iteritems "" ) : <TAB><TAB><TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> items = list ( args [ 0 ] . items ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> items = list ( args [ 0 ] ) <TAB><TAB> self . _items = items <TAB> else : <TAB><TAB> self . _items = [ ] <TAB> if kw : <TAB><TAB> self . _items . extend ( kw . items ( ) )","elif hasattr ( args [ 0 ] , ""items"" ) :","elif hasattr ( args [ 0 ] , ""items"" ) :",100.0,100.00,True
4114,"def open ( self ) - > "" KeyValueDb "" : <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os . path . exists ( self . _name ) : <TAB><TAB> if not os . path . isfile ( self . _name ) : <TAB><TAB><TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # ignore empty files <TAB><TAB><TAB> return self <TAB><TAB> with open ( self . _name , "" rb "" ) as _in : # binary mode <TAB><TAB><TAB> self . set_records ( pickle . load ( _in ) ) <TAB> else : <TAB><TAB> # make sure path exists <TAB><TAB> mkpath ( os . path . dirname ( self . _name ) ) <TAB><TAB> self . commit ( ) <TAB> return self",if os . path . getsize ( self . _name ) == 0 :,"if self . _name == """" :",93.95702336877036,94.81,False
4115,"def sortModules ( self ) : <TAB> super ( NeuronDecomposableNetwork , self ) . sortModules ( ) <TAB> self . _constructParameterInfo ( ) <TAB> # contains a list of lists of indices <TAB> self . decompositionIndices = { } <TAB> for neuron in self . _neuronIterator ( ) : <TAB><TAB> self . decompositionIndices [ neuron ] = [ ] <TAB> for w in range ( self . paramdim ) : <TAB><TAB> inneuron , outneuron = self . paramInfo [ w ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . decompositionIndices [ inneuron ] . append ( w ) <TAB><TAB> else : <TAB><TAB><TAB> self . decompositionIndices [ outneuron ] . append ( w )",if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,if inneuron in self . decompositionIndices :,94.96760650976105,92.94,False
4116,"def visit_Options ( self , node : qlast . Options ) - > None : <TAB> for i , opt in enumerate ( node . options . values ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . write ( ""   "" ) <TAB><TAB> self . write ( opt . name ) <TAB><TAB> if not isinstance ( opt , qlast . Flag ) : <TAB><TAB><TAB> self . write ( f ""   { opt . val } "" )",if i > 0 :,if i > 0 :,75.0,100.00,True
4117,"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB><TAB> return None <TAB> while True : <TAB><TAB> if possible_child_hash == item_hash : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB><TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash",if possible_child_hash not in self . items :,if self . items [ possible_child_hash ] . previous_hash != self . get,81.95882032647913,89.86,False
4118,"def __call__ ( self , text , * * kargs ) : <TAB> words = jieba . tokenize ( text , mode = "" search "" ) <TAB> token = Token ( ) <TAB> for ( w , start_pos , stop_pos ) in words : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> token . original = token . text = w <TAB><TAB> token . pos = start_pos <TAB><TAB> token . startchar = start_pos <TAB><TAB> token . endchar = stop_pos <TAB><TAB> yield token",if not accepted_chars . match ( w ) and len ( w ) <= 1 :,if w == 0 :,61.394167942944065,88.07,False
4119,"def test_analysis_jobs_cypher_syntax ( neo4j_session ) : <TAB> parameters = { <TAB><TAB> "" AWS_ID "" : None , <TAB><TAB> "" UPDATE_TAG "" : None , <TAB><TAB> "" OKTA_ORG_ID "" : None , <TAB> } <TAB> for job_name in contents ( "" cartography.data.jobs.analysis "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> cartography . util . run_analysis_job ( job_name , neo4j_session , parameters ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> pytest . fail ( <TAB><TAB><TAB><TAB> f "" run_analysis_job failed for analysis job  ' { job_name } '  with exception:  { e } "" <TAB><TAB><TAB> )","if not job_name . endswith ( "".json"" ) :","if not job_name . endswith ( "".json"" ) :",100.0,100.00,True
4120,"def _interleave_dataset_results_and_tensors ( dataset_results , flat_run_tensors ) : <TAB> flattened_results = [ ] <TAB> for idx in range ( len ( dataset_results ) + len ( flat_run_tensors ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> flattened_results . append ( dataset_results [ idx ] ) <TAB><TAB> else : <TAB><TAB><TAB> flattened_results . append ( flat_run_tensors . pop ( 0 ) ) <TAB> return flattened_results",if dataset_results . get ( idx ) :,if len ( dataset_results [ idx ] ) > 1 :,91.46624929782774,92.49,False
4121,"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB> seen = [ False , False ] <TAB> for i in sm . xrange ( 100 ) : <TAB><TAB> observed = aug . augment_image ( self . base_img ) <TAB><TAB> <MASK> <TAB><TAB><TAB> seen [ 0 ] + = True <TAB><TAB> elif np . array_equal ( observed , self . blur5x5 ) : <TAB><TAB><TAB> seen [ 1 ] + = True <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB><TAB> if all ( seen ) : <TAB><TAB><TAB> break <TAB> assert np . all ( seen )","if np . array_equal ( observed , self . blur3x3 ) :","if np . array_equal ( observed , self . blur3x3 ) :",75.0,100.00,True
4122,"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB><TAB> minDist = None <TAB><TAB> minGuide = None <TAB><TAB> for guide in self . guides [ color ] : <TAB><TAB><TAB> guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB> if minDist == None or guideDist < minDist : <TAB><TAB><TAB><TAB> minDist = guideDist <TAB><TAB><TAB><TAB> minGuide = guide <TAB><TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB> currentPos = minGuide <TAB><TAB> self . guides [ color ] . remove ( minGuide )",if minGuide == None :,if minGuide == None :,100.0,100.00,True
4123,"def UpdateRepository ( self ) : <TAB> if hasattr ( self , "" commit_update "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if not path . isdir ( "" .git/ "" ) : <TAB><TAB><TAB><TAB> self . gitZipRepo ( ) <TAB><TAB><TAB> call ( [ "" git "" , "" reset "" , "" --hard "" , "" origin/ {} "" . format ( self . getBranch ) ] ) <TAB><TAB><TAB> self . ProcessCall_ ( [ "" git "" , "" pull "" , "" origin "" , self . getBranch ] ) <TAB><TAB><TAB> self . ProcessCall_ ( [ "" pip "" , "" install "" , "" -r "" , "" requirements.txt "" ] )","if self . commit_update [ ""Updates"" ] != [ ] :",if self . getBranch in self . _git_refs :,69.01706402240761,92.84,False
4124,"def callback ( result = Cr . NS_OK , message = None , success = None ) : <TAB> if success is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> success = Ci . koIAsyncCallback . RESULT_SUCCESSFUL <TAB><TAB> else : <TAB><TAB><TAB> success = Ci . koIAsyncCallback . RESULT_ERROR <TAB> data = Namespace ( result = result , message = message , _com_interfaces_ = [ Ci . koIErrorInfo ] ) <TAB> self . _invoke_activate_callbacks ( success , data )",if Cr . NS_SUCCEEDED ( result ) :,if result == Cr . NS_OK :,92.52132918431019,94.75,False
4125,"def get_location ( device ) : <TAB> location = [ ] <TAB> node = device <TAB> while node : <TAB><TAB> position = node . get_position ( ) or "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> position = ""  [ %s ] "" % position <TAB><TAB> location . append ( node . name + position ) <TAB><TAB> node = node . parent <TAB> return ""  /  "" . join ( reversed ( location ) )",if position :,"if not position . startswith ( ""["" ) :",70.31735495167015,91.54,False
4126,"def load_checkpoint ( path , model , optimizer , reset_optimizer ) : <TAB> global global_step <TAB> global global_epoch <TAB> print ( "" Load checkpoint from:  {} "" . format ( path ) ) <TAB> checkpoint = _load ( path ) <TAB> model . load_state_dict ( checkpoint [ "" state_dict "" ] ) <TAB> if not reset_optimizer : <TAB><TAB> optimizer_state = checkpoint [ "" optimizer "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Load optimizer state from  {} "" . format ( path ) ) <TAB><TAB><TAB> optimizer . load_state_dict ( checkpoint [ "" optimizer "" ] ) <TAB> global_step = checkpoint [ "" global_step "" ] <TAB> global_epoch = checkpoint [ "" global_epoch "" ] <TAB> return model",if optimizer_state is not None :,if optimizer_state is not None :,100.0,100.00,True
4127,"def run_command ( self , command : str , data : Dict [ str , object ] ) - > Dict [ str , object ] : <TAB> """"""Run a specific command from the registry."""""" <TAB> key = "" cmd_ "" + command <TAB> method = getattr ( self . __class__ , key , None ) <TAB> if method is None : <TAB><TAB> return { "" error "" : "" Unrecognized command  ' %s ' "" % command } <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Only the above commands use some error formatting. <TAB><TAB><TAB> del data [ "" is_tty "" ] <TAB><TAB><TAB> del data [ "" terminal_width "" ] <TAB><TAB> return method ( self , * * data )","if command not in { ""check"" , ""recheck"" , ""run"" } :","if ""is_tty"" in data and ""terminal_width"" in data :",75.47029368542914,92.04,False
4128,"def call_init ( self , node , instance ) : <TAB> # Call __init__ on each binding. <TAB> for b in instance . bindings : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> self . _initialized_instances . add ( b . data ) <TAB><TAB> node = self . _call_init_on_binding ( node , b ) <TAB> return node",if b . data in self . _initialized_instances :,if b . data in self . _initialized_instances :,75.0,100.00,True
4129,"def get_request_headers ( ) - > Dict : <TAB> url = urlparse ( uri ) <TAB> candidates = [ <TAB><TAB> "" %s :// %s "" % ( url . scheme , url . netloc ) , <TAB><TAB> "" %s :// %s / "" % ( url . scheme , url . netloc ) , <TAB><TAB> uri , <TAB><TAB> "" * "" , <TAB> ] <TAB> for u in candidates : <TAB><TAB> <MASK> <TAB><TAB><TAB> headers = dict ( DEFAULT_REQUEST_HEADERS ) <TAB><TAB><TAB> headers . update ( self . config . linkcheck_request_headers [ u ] ) <TAB><TAB><TAB> return headers <TAB> return { }",if u in self . config . linkcheck_request_headers :,if u in self . config . linkcheck_request_headers :,100.0,100.00,True
4130,"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB><TAB> return <TAB> while True : <TAB><TAB> # We skip video packets which are not video frames <TAB><TAB> # This happens in mkv files for the first few frames. <TAB><TAB> video_packet = self . _get_video_packet ( ) <TAB><TAB> if video_packet . image == 0 : <TAB><TAB><TAB> self . _decode_video_packet ( video_packet ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> if _debug : <TAB><TAB> print ( "" Returning "" , video_packet ) <TAB> return video_packet . image",if video_packet . image is not None or not skip_empty_frame :,if skip_empty_frame :,94.68721759418727,94.14,False
4131,"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB><TAB> if code == Path . MOVETO : <TAB><TAB><TAB> ctx . move_to ( * points ) <TAB><TAB> elif code == Path . LINETO : <TAB><TAB><TAB> ctx . line_to ( * points ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ctx . curve_to ( <TAB><TAB><TAB><TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB> ) <TAB><TAB> elif code == Path . CURVE4 : <TAB><TAB><TAB> ctx . curve_to ( * points ) <TAB><TAB> elif code == Path . CLOSEPOLY : <TAB><TAB><TAB> ctx . close_path ( )",elif code == Path . CURVE3 :,elif code == Path . CURVE3 :,75.0,100.00,True
4132,"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """"""Constructor."""""" <TAB> self . layout = layout <TAB> if value is None : <TAB><TAB> if string is None : <TAB><TAB><TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB><TAB> else : <TAB><TAB><TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB><TAB> self . value = np . array ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB><TAB><TAB> )","if self . value . shape != ( self . layout . gaDims , ) :",if not self . value . shape :,93.80375966592811,94.30,False
4133,"def to_dict ( self ) : <TAB> contexts_ = { } <TAB> for k , data in self . contexts . items ( ) : <TAB><TAB> data_ = data . copy ( ) <TAB><TAB> if "" context "" in data_ : <TAB><TAB><TAB> del data_ [ "" context "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> del data_ [ "" loaded "" ] <TAB><TAB> contexts_ [ k ] = data_ <TAB> return dict ( contexts = contexts_ )","if ""loaded"" in data_ :","if ""loaded"" in data_ :",100.0,100.00,True
4134,"def include_module ( module ) : <TAB> if not include_these : <TAB><TAB> return True <TAB> result = False <TAB> for check in include_these : <TAB><TAB> if "" /* "" in check : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result = True <TAB><TAB> else : <TAB><TAB><TAB> if ( os . getcwd ( ) + "" / "" + check + "" .py "" ) == module : <TAB><TAB><TAB><TAB> result = True <TAB> if result : <TAB><TAB> print_status ( "" Including module:  "" + module ) <TAB> return result",if check [ : - 1 ] in module :,"if ( os . getcwd ( ) + ""/"" + check + "".py"" ) == module :",86.70199453649678,88.47,False
4135,"def extract_from ( msg_body , content_type = "" text/plain "" ) : <TAB> try : <TAB><TAB> if content_type == "" text/plain "" : <TAB><TAB><TAB> return extract_from_plain ( msg_body ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return extract_from_html ( msg_body ) <TAB> except Exception : <TAB><TAB> log . exception ( "" ERROR extracting message "" ) <TAB> return msg_body","elif content_type == ""text/html"" :","elif content_type == ""text/html"" :",100.0,100.00,True
4136,"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB><TAB> self . assertIn ( "" bbox "" , feature ) <TAB><TAB> fid = feature [ "" id "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB><TAB> elif fid == 2 : <TAB><TAB><TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB><TAB> else : <TAB><TAB><TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( )",if fid == 1 :,if fid == 1 :,100.0,100.00,True
4137,"def overrideCommand ( self , commandName , func ) : <TAB> # Override entries in c.k.masterBindingsDict <TAB> k = self <TAB> d = k . masterBindingsDict <TAB> for key in d : <TAB><TAB> d2 = d . get ( key ) <TAB><TAB> for key2 in d2 : <TAB><TAB><TAB> bi = d2 . get ( key2 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> bi . func = func <TAB><TAB><TAB><TAB> d2 [ key2 ] = bi",if bi . commandName == commandName :,if bi is not None :,71.42734782684069,95.23,False
4138,"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB><TAB> for spec in specs [ i ] . __sro__ : <TAB><TAB><TAB> comps = components . get ( spec ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB><TAB><TAB><TAB> if r is not None : <TAB><TAB><TAB><TAB><TAB> return r <TAB> else : <TAB><TAB> for iface in provided : <TAB><TAB><TAB> comps = components . get ( iface ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> r = comps . get ( name ) <TAB><TAB><TAB><TAB> if r is not None : <TAB><TAB><TAB><TAB><TAB> return r <TAB> return None",if comps :,if comps is not None :,69.65690125181085,96.38,False
4139,"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB><TAB> request <TAB><TAB> and is_deprecated ( request . version , self . min_version ) <TAB><TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB><TAB> social = value . copy ( ) <TAB><TAB> for key in old_social_string_fields : <TAB><TAB><TAB> if social . get ( key ) : <TAB><TAB><TAB><TAB> social [ key ] = value [ key ] [ 0 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> social [ key ] = "" "" <TAB><TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value )",elif social . get ( key ) == [ ] :,elif not social . get ( key ) :,94.50824224125691,97.21,False
4140,"def process_ref_attribute ( self , node , array_type = None ) : <TAB> ref = qname_attr ( node , "" ref "" ) <TAB> if ref : <TAB><TAB> ref = self . _create_qname ( ref ) <TAB><TAB> # Some wsdl's reference to xs:schema, we ignore that for now. It <TAB><TAB> # might be better in the future to process the actual schema file <TAB><TAB> # so that it is handled correctly <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> return xsd_elements . RefAttribute ( <TAB><TAB><TAB> node . tag , ref , self . schema , array_type = array_type <TAB><TAB> )","if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",if not self . schema :,96.97022746553756,88.68,False
4141,"def unescape ( text ) : <TAB> """"""Removes '\\' escaping from 'text'."""""" <TAB> rv = "" "" <TAB> i = 0 <TAB> while i < len ( text ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> rv + = text [ i + 1 ] <TAB><TAB><TAB> i + = 1 <TAB><TAB> else : <TAB><TAB><TAB> rv + = text [ i ] <TAB><TAB> i + = 1 <TAB> return rv","if i + 1 < len ( text ) and text [ i ] == ""\\"" :","if text [ i ] == ""\\"" :",83.70484615789499,92.54,False
4142,"def wait_child_process ( signum , frame ) : <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> child_pid , status = os . waitpid ( - 1 , os . WNOHANG ) <TAB><TAB><TAB> if child_pid == 0 : <TAB><TAB><TAB><TAB> stat_logger . info ( "" no child process was immediately available "" ) <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> exitcode = status >> 8 <TAB><TAB><TAB> stat_logger . info ( <TAB><TAB><TAB><TAB> "" child process  %s  exit with exitcode  %s "" , child_pid , exitcode <TAB><TAB><TAB> ) <TAB> except OSError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> stat_logger . warning ( <TAB><TAB><TAB><TAB> "" current process has no existing unwaited-for child processes. "" <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> raise",if e . errno == errno . ECHILD :,if e . errno == errno . ESRCH :,98.94401677692835,99.06,False
4143,"def translate_from_sortname ( name , sortname ) : <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name : <TAB><TAB> ctg = unicodedata . category ( c ) <TAB><TAB> if ctg [ 0 ] == "" L "" and unicodedata . name ( c ) . find ( "" LATIN "" ) == - 1 : <TAB><TAB><TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> parts = sortname . split ( separator ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> parts = [ sortname ] <TAB><TAB><TAB><TAB> separator = "" "" <TAB><TAB><TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name",if separator in sortname :,if sortname . find ( separator ) == - 1 :,96.08493914490055,95.77,False
4144,"def python_value ( self , value ) : <TAB> if value : <TAB><TAB> <MASK> <TAB><TAB><TAB> pp = lambda x : x . time ( ) <TAB><TAB><TAB> return format_date_time ( value , self . formats , pp ) <TAB><TAB> elif isinstance ( value , datetime . datetime ) : <TAB><TAB><TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB><TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value","if isinstance ( value , basestring ) :","if isinstance ( value , datetime . datetime ) :",87.73943830357919,96.94,False
4145,"def __init__ ( self , fileobj , info ) : <TAB> pages = [ ] <TAB> complete = False <TAB> while not complete : <TAB><TAB> page = OggPage ( fileobj ) <TAB><TAB> <MASK> <TAB><TAB><TAB> pages . append ( page ) <TAB><TAB><TAB> complete = page . complete or ( len ( page . packets ) > 1 ) <TAB> data = OggPage . to_packets ( pages ) [ 0 ] [ 7 : ] <TAB> super ( OggTheoraCommentDict , self ) . __init__ ( data , framing = False ) <TAB> self . _padding = len ( data ) - self . _size",if page . serial == info . serial :,if page . info == info :,69.65695584650122,96.22,False
4146,"def configure ( self ) : <TAB> # hack to configure 'from_' and 'to' and avoid exception <TAB> if "" from_ "" in self . wmeta . properties : <TAB><TAB> from_ = float ( self . wmeta . properties [ "" from_ "" ] ) <TAB><TAB> to = float ( self . wmeta . properties . get ( "" to "" , 0 ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> to = from_ + 1 <TAB><TAB><TAB> self . wmeta . properties [ "" to "" ] = str ( to ) <TAB> super ( TKSpinbox , self ) . configure ( )",if from_ > to :,if from_ < to :,73.78228096792873,98.28,False
4147,"def get_error_diagnostics ( self ) : <TAB> diagnostics = [ ] <TAB> if self . stdout is not None : <TAB><TAB> with open ( self . stdout . name ) as fds : <TAB><TAB><TAB> contents = fds . read ( ) . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> diagnostics . append ( "" ab STDOUT: \n "" + contents ) <TAB> if self . stderr is not None : <TAB><TAB> with open ( self . stderr . name ) as fds : <TAB><TAB><TAB> contents = fds . read ( ) . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> diagnostics . append ( "" ab STDERR: \n "" + contents ) <TAB> return diagnostics",if contents . strip ( ) :,if self . stdout is not None :,65.79338027087802,92.89,False
4148,"def set_environment_vars ( env , source_env ) : <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env : <TAB><TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Avoid creating circular dependencies from importing environment by <TAB><TAB><TAB> # using os.getenv. <TAB><TAB><TAB> if os . getenv ( "" TRUSTED_HOST "" ) and should_rebase_environment_value ( name ) : <TAB><TAB><TAB><TAB> value = file_host . rebase_to_worker_root ( value ) <TAB><TAB><TAB> env [ name ] = value",if is_forwarded_environment_variable ( name ) :,if name not in env :,84.97725770605197,94.09,False
4149,"def update_content ( self , more_content : StringList ) - > None : <TAB> if isinstance ( self . object , TypeVar ) : <TAB><TAB> attrs = [ repr ( self . object . __name__ ) ] <TAB><TAB> for constraint in self . object . __constraints__ : <TAB><TAB><TAB> attrs . append ( stringify_typehint ( constraint ) ) <TAB><TAB> if self . object . __covariant__ : <TAB><TAB><TAB> attrs . append ( "" covariant=True "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> attrs . append ( "" contravariant=True "" ) <TAB><TAB> more_content . append ( _ ( "" alias of TypeVar( %s ) "" ) % "" ,  "" . join ( attrs ) , "" "" ) <TAB><TAB> more_content . append ( "" "" , "" "" ) <TAB> super ( ) . update_content ( more_content )",if self . object . __contravariant__ :,if self . object . __contravariant__ :,100.0,100.00,True
4150,"def after ( self , event , state ) : <TAB> group = event . group <TAB> for plugin in self . get_plugins ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> metrics . incr ( "" notifications.sent "" , instance = plugin . slug ) <TAB><TAB> yield self . future ( plugin . rule_notify )","if not safe_execute ( plugin . should_notify , group = group , event = event ) :",if not self . future ( plugin . rule_notify ) :,58.89673282673095,84.50,False
4151,"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB><TAB> if isinstance ( n , Field ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> n = n . _name <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> if not isinstance ( n , _strtypes ) : <TAB><TAB><TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB> elif n not in fields : <TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )",if n . _child . isidentical ( expr ) :,if n . _name :,69.29306830842314,97.11,False
4152,"def build_filter ( arg ) : <TAB> filt = { } <TAB> if arg is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise UserError ( "" Arguments to --filter should be in form KEY=VAL "" ) <TAB><TAB> key , val = arg . split ( "" = "" , 1 ) <TAB><TAB> filt [ key ] = val <TAB> return filt","if ""="" not in arg :","if ""="" not in arg :",100.0,100.00,True
4153,"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB><TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB><TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB><TAB> line = f . readline ( ) <TAB><TAB> if not line : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> text = line [ len ( key ) + 1 : ] <TAB><TAB><TAB> while 1 : <TAB><TAB><TAB><TAB> line = f . readline ( ) <TAB><TAB><TAB><TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> text = text + line <TAB><TAB><TAB> return text . strip ( ) <TAB> return None",if prog . match ( line ) :,if prog . search ( line ) :,99.15114817495184,99.04,False
4154,"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB><TAB> <MASK> <TAB><TAB><TAB> category = "" preprint "" <TAB><TAB> elif node . is_registration : <TAB><TAB><TAB> category = "" registration "" <TAB><TAB> else : <TAB><TAB><TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB><TAB> index = index , <TAB><TAB> doc_type = category , <TAB><TAB> id = elastic_document_id , <TAB><TAB> refresh = True , <TAB><TAB> ignore = [ 404 ] , <TAB> )","if isinstance ( node , Preprint ) :",if node . is_preprint :,93.97339725137262,96.13,False
4155,"def update ( self , preds , labels ) : <TAB> if not _is_numpy_ ( labels ) : <TAB><TAB> raise ValueError ( "" The  ' labels '  must be a numpy ndarray. "" ) <TAB> if not _is_numpy_ ( preds ) : <TAB><TAB> raise ValueError ( "" The  ' predictions '  must be a numpy ndarray. "" ) <TAB> for i , lbl in enumerate ( labels ) : <TAB><TAB> value = preds [ i , 1 ] <TAB><TAB> bin_idx = int ( value * self . _num_thresholds ) <TAB><TAB> assert bin_idx < = self . _num_thresholds <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _stat_pos [ bin_idx ] + = 1.0 <TAB><TAB> else : <TAB><TAB><TAB> self . _stat_neg [ bin_idx ] + = 1.0",if lbl :,if lbl == 1 :,80.76476323147439,97.88,False
4156,"def checkStatusClient ( self ) : <TAB> if str ( self . comboxBoxIPAddress . currentText ( ) ) != "" "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . btnEnable . setEnabled ( False ) <TAB><TAB><TAB> self . btncancel . setEnabled ( True ) <TAB><TAB><TAB> return None <TAB><TAB> self . btnEnable . setEnabled ( True ) <TAB><TAB> self . btncancel . setEnabled ( False )","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :","if self . comboxBoxIPAddress . currentText ( ) == """" :",64.74045487484662,88.35,False
4157,"def colorizeDiffs ( sheet , col , row , cellval ) : <TAB> if not row or not col : <TAB><TAB> return None <TAB> vcolidx = sheet . visibleCols . index ( col ) <TAB> rowidx = sheet . rows . index ( row ) <TAB> if vcolidx < len ( othersheet . visibleCols ) and rowidx < len ( othersheet . rows ) : <TAB><TAB> otherval = othersheet . visibleCols [ vcolidx ] . getDisplayValue ( <TAB><TAB><TAB> othersheet . rows [ rowidx ] <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" color_diff "" <TAB> else : <TAB><TAB> return "" color_diff_add """,if cellval . display != otherval :,if otherval == cellval :,68.67485272036194,95.86,False
4158,"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB><TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB><TAB> return detected <TAB> for wafvendor in self . checklist : <TAB><TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB><TAB> <MASK> <TAB><TAB><TAB> detected . append ( wafvendor ) <TAB><TAB><TAB> if not findall : <TAB><TAB><TAB><TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected",if self . wafdetections [ wafvendor ] ( self ) :,if self . attackres == wafvendor :,90.66265002120116,94.85,False
4159,"def get_repository_metadata_by_repository_id_changeset_revision ( <TAB> app , id , changeset_revision , metadata_only = False ) : <TAB> """"""Get a specified metadata record for a specified repository in the tool shed."""""" <TAB> if metadata_only : <TAB><TAB> repository_metadata = get_repository_metadata_by_changeset_revision ( <TAB><TAB><TAB> app , id , changeset_revision <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return repository_metadata . metadata <TAB><TAB> return None <TAB> return get_repository_metadata_by_changeset_revision ( app , id , changeset_revision )",if repository_metadata and repository_metadata . metadata :,if repository_metadata :,73.00107283654647,96.08,False
4160,"def getmultiline ( self ) : <TAB> line = self . getline ( ) <TAB> if line [ 3 : 4 ] == "" - "" : <TAB><TAB> code = line [ : 3 ] <TAB><TAB> while 1 : <TAB><TAB><TAB> nextline = self . getline ( ) <TAB><TAB><TAB> line = line + ( "" \n "" + nextline ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB> return line","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :","if line . startswith ( "" "" ) or line . startswith ( "" "" ) :",59.24446393256388,84.79,False
4161,"def _validate_reports ( value , * args , * * kwargs ) : <TAB> from osf . models import OSFUser <TAB> for key , val in value . items ( ) : <TAB><TAB> if not OSFUser . load ( key ) : <TAB><TAB><TAB> raise ValidationValueError ( "" Keys must be user IDs "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationTypeError ( "" Values must be dictionaries "" ) <TAB><TAB> if ( <TAB><TAB><TAB> "" category "" not in val <TAB><TAB><TAB> or "" text "" not in val <TAB><TAB><TAB> or "" date "" not in val <TAB><TAB><TAB> or "" retracted "" not in val <TAB><TAB> ) : <TAB><TAB><TAB> raise ValidationValueError ( <TAB><TAB><TAB><TAB> ( "" Values must include `date`, `category`,  "" , "" `text`, `retracted` keys "" ) <TAB><TAB><TAB> )","if not isinstance ( val , dict ) :","if not isinstance ( val , dict ) :",100.0,100.00,True
4162,"def deselectItem ( self , item ) : <TAB> if self . isSelected ( item ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> listItem = self . _getListItem ( item ) <TAB><TAB><TAB> selections = self . getSelectedItems ( ) <TAB><TAB><TAB> selections . remove ( self . loadHandler . getSelection ( listItem ) ) <TAB><TAB><TAB> self . setSelections ( selections ) <TAB><TAB> else : <TAB><TAB><TAB> self . deselectAll ( )",if self . multiSelect :,if self . loadHandler . isShown ( item ) :,94.89251804193341,94.06,False
4163,"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB><TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB><TAB> if not key in self . options : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB><TAB><TAB> ) <TAB><TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name , ( description , default ) in self . options . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . option_values [ name ] = default",if not name in self . option_values :,if description is not None :,97.24737269720313,95.70,False
4164,"def setup_smart_indent ( self , view , lang ) : <TAB> # Configure a ""per-view"" instance <TAB> if type ( view ) == gedit . View : <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( view , "" smart_indent_instance "" , SmartIndent ( ) ) <TAB><TAB><TAB> handler_id = view . connect ( <TAB><TAB><TAB><TAB> "" key-press-event "" , view . smart_indent_instance . key_press_handler <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . handler_ids . append ( ( handler_id , view ) ) <TAB><TAB> view . smart_indent_instance . set_language ( lang , view )","if getattr ( view , ""smart_indent_instance"" , False ) == False :","if hasattr ( view , ""smart_indent_instance"" ) :",69.95902439059108,94.82,False
4165,"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB><TAB> <MASK> <TAB><TAB><TAB> letters + = char <TAB><TAB><TAB> count + = 1 <TAB><TAB> else : <TAB><TAB><TAB> if count > threshold : <TAB><TAB><TAB><TAB> strings . append ( letters ) <TAB><TAB><TAB> letters = "" "" <TAB><TAB><TAB> count = 0 <TAB> if count > threshold : <TAB><TAB> strings . append ( letters ) <TAB> return strings",if char in char_set :,if char in char_set :,100.0,100.00,True
4166,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
4167,def __create_table ( self ) : <TAB> for i in range ( 256 ) : <TAB><TAB> crcreg = i <TAB><TAB> for j in range ( 8 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> crcreg = self . __CRCPOLYNOMIAL ^ ( crcreg >> 1 ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> crcreg >> = 1 <TAB><TAB> self . __crctable [ i ] = crcreg,if ( crcreg & 1 ) != 0 :,if j == 0 :,64.49483342357105,94.27,False
4168,"def destroy ( self ) : <TAB> """"""Flush all entries and empty cache"""""" <TAB> # Note: this method is currently also used for dropping the cache <TAB> for i in range ( len ( self . cached_rows ) ) : <TAB><TAB> id_ = self . cached_rows [ i ] <TAB><TAB> self . cached_rows [ i ] = None <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> inode = self . attrs [ id_ ] <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> # We may have deleted that inode <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> del self . attrs [ id_ ] <TAB><TAB><TAB><TAB> self . setattr ( inode ) <TAB> assert len ( self . attrs ) == 0",if id_ is not None :,if id_ in self . attrs :,97.52845966519055,97.69,False
4169,"def set_config ( self ) : <TAB> """"""Set configuration options for QTextEdit."""""" <TAB> c = self . c <TAB> w = self . widget <TAB> w . setWordWrapMode ( QtGui . QTextOption . NoWrap ) <TAB> if 0 : # This only works when there is no style sheet. <TAB><TAB> n = c . config . getInt ( "" qt-rich-text-zoom-in "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> w . zoomIn ( n ) <TAB><TAB><TAB> w . updateMicroFocus ( ) <TAB> # tab stop in pixels - no config for this (yet) <TAB> w . setTabStopWidth ( 24 )","if n not in ( None , 0 ) :",if n :,95.44557492669442,94.47,False
4170,"def mouseDragEvent ( self , ev ) : <TAB> if self . movable and ev . button ( ) == QtCore . Qt . LeftButton : <TAB><TAB> if ev . isStart ( ) : <TAB><TAB><TAB> self . moving = True <TAB><TAB><TAB> self . cursorOffset = self . pos ( ) - self . mapToParent ( ev . buttonDownPos ( ) ) <TAB><TAB><TAB> self . startPosition = self . pos ( ) <TAB><TAB> ev . accept ( ) <TAB><TAB> if not self . moving : <TAB><TAB><TAB> return <TAB><TAB> self . setPos ( self . cursorOffset + self . mapToParent ( ev . pos ( ) ) ) <TAB><TAB> self . sigDragged . emit ( self ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . moving = False <TAB><TAB><TAB> self . sigPositionChangeFinished . emit ( self )",if ev . isFinish ( ) :,if ev . isEnd ( ) :,99.08911718208374,98.85,False
4171,"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB><TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB><TAB> if not newParent . _element . text : <TAB><TAB><TAB> newParent . _element . text = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent )",if self . _element . text is not None :,elif self . _element . text :,84.79051961310692,95.10,False
4172,"def _no_sp_or_bp ( self , bl ) : <TAB> for s in bl . vex . statements : <TAB><TAB> for e in chain ( [ s ] , s . expressions ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB><TAB><TAB><TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB><TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> elif e . tag == "" Ist_Put "" : <TAB><TAB><TAB><TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB><TAB><TAB><TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB><TAB><TAB><TAB><TAB> return False <TAB> return True","if e . tag == ""Iex_Get"" :","if e . tag == ""Ist_Get"" :",98.97405033059712,98.97,False
4173,"def _get_import_chain ( self , * , until = None ) : <TAB> stack = inspect . stack ( ) [ 2 : ] <TAB> try : <TAB><TAB> for frameinfo in stack : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> data = dedent ( "" "" . join ( frameinfo . code_context ) ) <TAB><TAB><TAB><TAB> if data . strip ( ) == until : <TAB><TAB><TAB><TAB><TAB> raise StopIteration <TAB><TAB><TAB><TAB> yield frameinfo . filename , frameinfo . lineno , data . strip ( ) <TAB><TAB><TAB><TAB> del data <TAB><TAB><TAB> finally : <TAB><TAB><TAB><TAB> del frameinfo <TAB> finally : <TAB><TAB> del stack",if not frameinfo . code_context :,if frameinfo . code_context is None :,91.81727222438795,97.89,False
4174,"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB><TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB><TAB><TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB><TAB> elif "" status "" in line : <TAB><TAB><TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB><TAB><TAB> raise DockerBuildError","elif ""error"" in line :","elif ""error"" in line :",100.0,100.00,True
4175,"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB><TAB> if dep == goal_node_index : <TAB><TAB><TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB><TAB> path = self . get_cycle_path ( <TAB><TAB><TAB> self . get_by_address ( dep ) , goal_node_index <TAB><TAB> ) # self.nodelist[dep], goal_node_index) <TAB><TAB> <MASK> <TAB><TAB><TAB> path . insert ( 0 , curr_node [ "" address "" ] ) <TAB><TAB><TAB> return path <TAB> return [ ]",if len ( path ) > 0 :,if path :,96.34169367147999,96.38,False
4176,"def prompt ( default = None ) : <TAB> editor = "" nano "" <TAB> with tempfile . NamedTemporaryFile ( mode = "" r+ "" ) as tmpfile : <TAB><TAB> <MASK> <TAB><TAB><TAB> tmpfile . write ( default ) <TAB><TAB><TAB> tmpfile . flush ( ) <TAB><TAB> child_pid = os . fork ( ) <TAB><TAB> is_child = child_pid == 0 <TAB><TAB> if is_child : <TAB><TAB><TAB> os . execvp ( editor , [ editor , tmpfile . name ] ) <TAB><TAB> else : <TAB><TAB><TAB> os . waitpid ( child_pid , 0 ) <TAB><TAB><TAB> tmpfile . seek ( 0 ) <TAB><TAB><TAB> return tmpfile . read ( ) . strip ( )",if default :,if default is not None :,97.39023226707657,97.74,False
4177,"def _get_annotated_template ( self , template ) : <TAB> changed = False <TAB> if template . get ( "" version "" , "" 0.12.0 "" ) > = "" 0.13.0 "" : <TAB><TAB> using_js = self . spider . _filter_js_urls ( template [ "" url "" ] ) <TAB><TAB> body = "" rendered_body "" if using_js else "" original_body "" <TAB><TAB> <MASK> <TAB><TAB><TAB> template [ "" body "" ] = body <TAB><TAB><TAB> changed = True <TAB> if changed or not template . get ( "" annotated "" ) : <TAB><TAB> _build_sample ( template ) <TAB> return template","if template . get ( ""body"" ) != body :",if body :,67.06266046061326,93.21,False
4178,"def collect ( self , paths ) : <TAB> for path in paths or ( ) : <TAB><TAB> relpath = os . path . relpath ( path , self . _artifact_root ) <TAB><TAB> dst = os . path . join ( self . _directory , relpath ) <TAB><TAB> safe_mkdir ( os . path . dirname ( dst ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> shutil . copytree ( path , dst ) <TAB><TAB> else : <TAB><TAB><TAB> shutil . copy ( path , dst ) <TAB><TAB> self . _relpaths . add ( relpath )",if os . path . isdir ( path ) :,if os . path . isdir ( dst ) :,73.73277764537532,98.36,False
4179,"def dependencies ( context = None ) : <TAB> """"""Return all dependencies detected by knowit."""""" <TAB> deps = OrderedDict ( [ ] ) <TAB> try : <TAB><TAB> initialize ( context ) <TAB><TAB> for name , provider_cls in _provider_map . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> deps [ name ] = available_providers [ name ] . version <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> deps [ name ] = { } <TAB> except Exception : <TAB><TAB> pass <TAB> return deps",if name in available_providers :,if provider_cls . version :,91.80928979712515,96.05,False
4180,"def _getaddrinfo ( self , host_bytes , port , family , socktype , proto , flags ) : <TAB> while True : <TAB><TAB> ares = self . cares <TAB><TAB> try : <TAB><TAB><TAB> return self . __getaddrinfo ( host_bytes , port , family , socktype , proto , flags ) <TAB><TAB> except gaierror : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise",if ares is self . cares :,if ares is None :,93.5836739817883,95.99,False
4181,"def write_entries ( cmd , basename , filename ) : <TAB> ep = cmd . distribution . entry_points <TAB> if isinstance ( ep , basestring ) or ep is None : <TAB><TAB> data = ep <TAB> elif ep is not None : <TAB><TAB> data = [ ] <TAB><TAB> for section , contents in ep . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> contents = EntryPoint . parse_group ( section , contents ) <TAB><TAB><TAB><TAB> contents = "" \n "" . join ( map ( str , contents . values ( ) ) ) <TAB><TAB><TAB> data . append ( "" [ %s ] \n %s \n \n "" % ( section , contents ) ) <TAB><TAB> data = "" "" . join ( data ) <TAB> cmd . write_or_delete_file ( "" entry points "" , filename , data , True )","if not isinstance ( contents , basestring ) :","if isinstance ( contents , dict ) :",74.64787077593493,97.81,False
4182,"def _highlight_do ( self ) : <TAB> new_hl_text = self . highlight_text . text ( ) <TAB> if new_hl_text != self . hl_text : <TAB><TAB> self . hl_text = new_hl_text <TAB><TAB> if self . hl is not None : <TAB><TAB><TAB> self . hl . setDocument ( None ) <TAB><TAB><TAB> self . hl = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . hl = Highlighter ( self . hl_text , parent = self . doc ) <TAB><TAB> self . clear_highlight_button . setEnabled ( bool ( self . hl ) )",if self . hl_text :,if self . hl_text :,100.0,100.00,True
4183,"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB><TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB><TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> node . functions = list ( functions ) <TAB><TAB><TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB><TAB> functions . append ( type ( node ) . __name__ ) <TAB><TAB> for f in node . next_functions : <TAB><TAB><TAB> if f [ 0 ] : <TAB><TAB><TAB><TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB><TAB><TAB><TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB><TAB> for t in node . saved_tensors : <TAB><TAB><TAB> traverse ( t )",if node :,if node :,100.0,100.00,True
4184,"def compress ( self , data_list ) : <TAB> if data_list : <TAB><TAB> page_id = data_list [ 1 ] <TAB><TAB> if page_id in EMPTY_VALUES : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB><TAB> return Page . objects . get ( pk = page_id ) <TAB> return None",if not self . required :,if not self . valid_pages :,98.0463728860268,96.51,False
4185,"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB><TAB> if self . _is_ast_node ( name , item ) : <TAB><TAB><TAB> if name == "" Index "" : <TAB><TAB><TAB><TAB> # Index(value) just returns value now. <TAB><TAB><TAB><TAB> # The argument is required. <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> x = item ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertEqual ( type ( x . _fields ) , tuple )","if isinstance ( x , ast . AST ) :","if hasattr ( x , ""_fields"" ) :",95.84876221122947,95.58,False
4186,"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB><TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB><TAB> for attr , value in attrs : <TAB><TAB><TAB> if self . scan_attr ( attr ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> value = strip_html5_whitespace ( value ) <TAB><TAB><TAB><TAB> url = self . process_attr ( value ) <TAB><TAB><TAB><TAB> link = Link ( url = url ) <TAB><TAB><TAB><TAB> self . links . append ( link ) <TAB><TAB><TAB><TAB> self . current_link = link",if self . strip :,if self . strip_html5_whitespace :,98.1659935679563,97.46,False
4187,"def _initialize_asset_map ( cls ) : <TAB> # Generating a list of acceptable asset files reduces the possibility of <TAB> # path attacks. <TAB> cls . _asset_name_to_path = { } <TAB> assets = os . listdir ( ASSETS_PATH ) <TAB> for asset in assets : <TAB><TAB> path = os . path . join ( ASSETS_PATH , asset ) <TAB><TAB> <MASK> <TAB><TAB><TAB> cls . _asset_name_to_path [ os . path . basename ( path ) ] = path",if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,75.0,100.00,True
4188,"def dataReceived ( self , data ) : <TAB> self . buf + = data <TAB> if self . _paused : <TAB><TAB> log . startLogging ( sys . stderr ) <TAB><TAB> log . msg ( "" dataReceived while transport paused! "" ) <TAB><TAB> self . transport . loseConnection ( ) <TAB> else : <TAB><TAB> self . transport . write ( data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . transport . loseConnection ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . pause ( )","if self . buf . endswith ( b""\n0\n"" ) :",if self . _keep_output :,68.12708265372227,90.81,False
4189,"def test_case_sensitive ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB><TAB> env . unset ( "" PYTHONCASEOK "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB><TAB> loader = self . find_module ( ) <TAB><TAB> self . assertIsNone ( loader )","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :","if ""PYTHONCASEOK"" not in env . get ( ""PYTHONCASEOK""",85.9848139535042,87.04,False
4190,"def manifest ( self ) : <TAB> """"""The current manifest dictionary."""""" <TAB> if self . reload : <TAB><TAB> if not self . exists ( self . manifest_path ) : <TAB><TAB><TAB> return { } <TAB><TAB> mtime = self . getmtime ( self . manifest_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _manifest = self . get_manifest ( ) <TAB><TAB><TAB> self . _mtime = mtime <TAB> return self . _manifest",if self . _mtime is None or mtime > self . _mtime :,if mtime is not None :,66.67951637086314,90.23,False
4191,"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB><TAB> elif name == "" mean_module.constant "" : <TAB><TAB><TAB> self . assertIsNone ( constraint ) <TAB><TAB> elif name == "" covar_module.raw_outputscale "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB><TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB><TAB><TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","if name == ""likelihood.noise_covar.raw_noise"" :","if name == ""mean_module.greater_than"" :",98.92285275819808,95.61,False
4192,"def process_plugin_result ( name , result ) : <TAB> if result : <TAB><TAB> try : <TAB><TAB><TAB> jsonify ( test = result ) <TAB><TAB> except Exception : <TAB><TAB><TAB> logger . exception ( <TAB><TAB><TAB><TAB> "" Error while jsonifying settings from plugin  {} , please contact the plugin author about this "" . format ( <TAB><TAB><TAB><TAB><TAB> name <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> del result [ "" __enabled "" ] <TAB><TAB><TAB> data [ name ] = result","if ""__enabled"" in result :","if ""__enabled"" in result :",100.0,100.00,True
4193,"def benchmarking ( net , ctx , num_iteration , datashape = 300 , batch_size = 64 ) : <TAB> input_shape = ( batch_size , 3 ) + ( datashape , datashape ) <TAB> data = mx . random . uniform ( - 1.0 , 1.0 , shape = input_shape , ctx = ctx , dtype = "" float32 "" ) <TAB> dryrun = 5 <TAB> for i in range ( dryrun + num_iteration ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tic = time . time ( ) <TAB><TAB> ids , scores , bboxes = net ( data ) <TAB><TAB> ids . asnumpy ( ) <TAB><TAB> scores . asnumpy ( ) <TAB><TAB> bboxes . asnumpy ( ) <TAB> toc = time . time ( ) - tic <TAB> return toc",if i == dryrun :,if i % 2 == 0 :,78.46171474563232,96.95,False
4194,"def merge_weekdays ( base_wd , icu_wd ) : <TAB> result = [ ] <TAB> for left , right in zip ( base_wd , icu_wd ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( left ) <TAB><TAB><TAB> continue <TAB><TAB> left = set ( left . split ( "" | "" ) ) <TAB><TAB> right = set ( right . split ( "" | "" ) ) <TAB><TAB> result . append ( "" | "" . join ( left | right ) ) <TAB> return result",if left == right :,"if left == ""*"" or right == ""*"" :",96.41418896533858,92.41,False
4195,"def create_key ( self , request ) : <TAB> if self . _ignored_parameters : <TAB><TAB> url , body = self . _remove_ignored_parameters ( request ) <TAB> else : <TAB><TAB> url , body = request . url , request . body <TAB> key = hashlib . sha256 ( ) <TAB> key . update ( _to_bytes ( request . method . upper ( ) ) ) <TAB> key . update ( _to_bytes ( url ) ) <TAB> if request . body : <TAB><TAB> key . update ( _to_bytes ( body ) ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> for name , value in sorted ( request . headers . items ( ) ) : <TAB><TAB><TAB><TAB> key . update ( _to_bytes ( name ) ) <TAB><TAB><TAB><TAB> key . update ( _to_bytes ( value ) ) <TAB> return key . hexdigest ( )",if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,if request . headers :,69.01399026468131,92.57,False
4196,"def test_invalid_mountinfo ( self ) : <TAB> line = ( <TAB><TAB> "" 20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root "" <TAB><TAB> "" rw,errors=remount-ro,data=ordered "" <TAB> ) <TAB> elements = line . split ( ) <TAB> for i in range ( len ( elements ) + 1 ) : <TAB><TAB> lines = [ ""   "" . join ( elements [ 0 : i ] ) ] <TAB><TAB> <MASK> <TAB><TAB><TAB> expected = None <TAB><TAB> else : <TAB><TAB><TAB> expected = ( "" /dev/mapper/vg0-root "" , "" ext4 "" , "" / "" ) <TAB><TAB> self . assertEqual ( expected , util . parse_mount_info ( "" / "" , lines ) )",if i < 10 :,if i == 0 :,78.7745705071445,97.76,False
4197,"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB><TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB><TAB> if k in keep_current : <TAB><TAB><TAB> if keep_nested is not None : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield k , v","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",100.0,100.00,True
4198,"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB><TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB><TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB><TAB> # reach leaf <TAB><TAB> if cur_node_idx == - 1 : <TAB><TAB><TAB> continue <TAB><TAB> rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB><TAB><TAB> tree , sample , cur_node_idx <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB><TAB> node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB> return node_pos",if reach_leaf :,if reach_leaf :,100.0,100.00,True
4199,"def _pop_waiting_trial_id ( self ) - > Optional [ int ] : <TAB> # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB> for trial in self . _storage . get_all_trials ( self . _study_id , deepcopy = False ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if not self . _storage . set_trial_state ( trial . _trial_id , TrialState . RUNNING ) : <TAB><TAB><TAB> continue <TAB><TAB> _logger . debug ( "" Trial  {}  popped from the trial queue. "" . format ( trial . number ) ) <TAB><TAB> return trial . _trial_id <TAB> return None",if trial . state != TrialState . WAITING :,if not trial . _trial_id :,71.30023610819698,95.12,False
4200,"def get_step_best ( self , step_models ) : <TAB> best_score = None <TAB> best_model = "" "" <TAB> for model in step_models : <TAB><TAB> model_info = self . models_trained [ model ] <TAB><TAB> score = model_info . get_score ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if best_score is None or score < best_score : <TAB><TAB><TAB> best_score = score <TAB><TAB><TAB> best_model = model <TAB> LOGGER . info ( f "" step  { self . n_step } , best model  { best_model } "" ) <TAB> return best_model",if score is None :,if score is None :,100.0,100.00,True
4201,"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB><TAB> f = queue . popleft ( ) <TAB><TAB> if f is not None and f . type in ( "" or "" , "" and "" , "" not "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> queue . appendleft ( None ) <TAB><TAB><TAB> for gf in f . filters : <TAB><TAB><TAB><TAB> queue . appendleft ( gf ) <TAB><TAB> yield f",if block_end :,if block_end :,100.0,100.00,True
4202,"def _buffer_decode ( self , input , errors , final ) : <TAB> if self . decoder is None : <TAB><TAB> ( output , consumed , byteorder ) = codecs . utf_16_ex_decode ( input , errors , 0 , final ) <TAB><TAB> if byteorder == - 1 : <TAB><TAB><TAB> self . decoder = codecs . utf_16_le_decode <TAB><TAB> <MASK> <TAB><TAB><TAB> self . decoder = codecs . utf_16_be_decode <TAB><TAB> elif consumed > = 2 : <TAB><TAB><TAB> raise UnicodeError ( "" UTF-16 stream does not start with BOM "" ) <TAB><TAB> return ( output , consumed ) <TAB> return self . decoder ( input , self . errors , final )",elif byteorder == 1 :,elif byteorder == 1 :,100.0,100.00,True
4203,"def _load_db ( self ) : <TAB> try : <TAB><TAB> with open ( self . db ) as db : <TAB><TAB><TAB> content = db . read ( 8 ) <TAB><TAB><TAB> db . seek ( 0 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = StringIO ( ) <TAB><TAB><TAB><TAB> if self . encryptor : <TAB><TAB><TAB><TAB><TAB> self . encryptor . decrypt ( db , data ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> raise EncryptionError ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> return json . loads ( data . getvalue ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return json . load ( db ) <TAB> except : <TAB><TAB> return { "" creds "" : [ ] }","if content == ( ""Salted__"" ) :",if content :,70.77437667827017,96.40,False
4204,"def _getbytes ( self , start , l = 1 ) : <TAB> out = [ ] <TAB> for ad in range ( l ) : <TAB><TAB> offset = ad + start + self . base_address <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IOError ( "" not enough bytes "" ) <TAB><TAB> out . append ( int_to_byte ( Byte ( offset ) ) ) <TAB> return b "" "" . join ( out )",if not is_mapped ( offset ) :,if len ( offset ) < 2 :,67.54575245265755,93.80,False
4205,"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d . keys ( ) : <TAB><TAB> if config . get ( "" environment "" ) == "" prod "" : <TAB><TAB><TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if config . get ( ""environment"" ) == ""aws"" :",96.21589923390243,92.69,False
4206,"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB><TAB> if row [ 0 ] == linenum : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> row [ refnum + 1 ] = line <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> # else keep looking <TAB><TAB> elif row [ 0 ] > linenum : <TAB><TAB><TAB> break <TAB> self . rows . insert ( i , self . newRow ( linenum , refnum , line ) )",if row [ refnum + 1 ] is None :,if i == refnum :,90.28854115049828,94.14,False
4207,"def __setattr__ ( self , name , val ) : <TAB> if self . __dict__ . get ( name , "" hamster_graphics_no_value_really "" ) == val : <TAB><TAB> return <TAB> Sprite . __setattr__ ( self , name , val ) <TAB> if name == "" image_data "" : <TAB><TAB> self . _surface = None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __dict__ [ "" width "" ] = self . image_data . get_width ( ) <TAB><TAB><TAB> self . __dict__ [ "" height "" ] = self . image_data . get_height ( )",if self . image_data :,if self . _surface is None :,73.09731215466142,96.96,False
4208,"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB><TAB> # replace Mock function names <TAB><TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB><TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB><TAB> # add scope name to layer signatures: <TAB><TAB> if hasattr ( obj , "" use_scope "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB><TAB><TAB> elif obj . use_scope is None : <TAB><TAB><TAB><TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation",if obj . use_scope :,"if obj . use_scope == ""layer"" :",99.14455283214878,97.46,False
4209,"def L_op ( self , inputs , outputs , gout ) : <TAB> ( x , ) = inputs <TAB> ( gz , ) = gout <TAB> if x . type in complex_types : <TAB><TAB> raise NotImplementedError ( ) <TAB> if outputs [ 0 ] . type in discrete_types : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ x . zeros_like ( dtype = theano . config . floatX ) ] <TAB><TAB> else : <TAB><TAB><TAB> return [ x . zeros_like ( ) ] <TAB> return ( gz * ( 1 - sqr ( tanh ( x ) ) ) , )",if x . type in discrete_types :,if x . type in discrete_types :,100.0,100.00,True
4210,"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB><TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB><TAB> if output . lower ( ) == "" n "" : <TAB><TAB><TAB> return False","if output . lower ( ) == ""y"" :","if output . lower ( ) == ""y"" :",100.0,100.00,True
4211,"def replace_documentation_for_matching_shape ( self , event_name , section , * * kwargs ) : <TAB> if self . _shape_name == section . context . get ( "" shape "" ) : <TAB><TAB> self . _replace_documentation ( event_name , section ) <TAB> for section_name in section . available_sections : <TAB><TAB> sub_section = section . get_section ( section_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _replace_documentation ( event_name , sub_section ) <TAB><TAB> else : <TAB><TAB><TAB> self . replace_documentation_for_matching_shape ( event_name , sub_section )","if self . _shape_name == sub_section . context . get ( ""shape"" ) :","if self . _shape_name == sub_section . context . get ( ""shape""",69.0071988903393,98.13,False
4212,"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB><TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB><TAB> if output . lower ( ) == "" y "" : <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return False","if output . lower ( ) == ""n"" :","elif output . lower ( ) == ""n"" :",72.66669307416457,97.74,False
4213,"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB><TAB> if isinstance ( index , int ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise IndexError ( index ) <TAB><TAB><TAB> if self . features [ index ] is None : <TAB><TAB><TAB><TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB><TAB><TAB><TAB> if feature : <TAB><TAB><TAB><TAB><TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB><TAB><TAB><TAB><TAB> self . features [ index ] = FEATURE [ feature ] <TAB><TAB><TAB> return self . features [ index ] <TAB><TAB> elif isinstance ( index , slice ) : <TAB><TAB><TAB> indices = index . indices ( len ( self . features ) ) <TAB><TAB><TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]",if index < 0 or index >= len ( self . features ) :,if index < 0 :,95.33614355307212,95.91,False
4214,"def _parse_locator ( self , locator ) : <TAB> prefix = None <TAB> criteria = locator <TAB> if not locator . startswith ( "" // "" ) : <TAB><TAB> locator_parts = locator . partition ( "" = "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> prefix = locator_parts [ 0 ] <TAB><TAB><TAB> criteria = locator_parts [ 2 ] . strip ( ) <TAB> return ( prefix , criteria )",if len ( locator_parts [ 1 ] ) > 0 :,if len ( locator_parts ) > 2 :,68.87718286943543,94.37,False
4215,"def trakt_episode_data_generate ( self , data ) : <TAB> # Find how many unique season we have <TAB> uniqueSeasons = [ ] <TAB> for season , episode in data : <TAB><TAB> <MASK> <TAB><TAB><TAB> uniqueSeasons . append ( season ) <TAB> # build the query <TAB> seasonsList = [ ] <TAB> for searchedSeason in uniqueSeasons : <TAB><TAB> episodesList = [ ] <TAB><TAB> for season , episode in data : <TAB><TAB><TAB> if season == searchedSeason : <TAB><TAB><TAB><TAB> episodesList . append ( { "" number "" : episode } ) <TAB><TAB> seasonsList . append ( { "" number "" : searchedSeason , "" episodes "" : episodesList } ) <TAB> post_data = { "" seasons "" : seasonsList } <TAB> return post_data",if season not in uniqueSeasons :,if season not in uniqueSeasons :,75.0,100.00,True
4216,"def __init__ ( self , data , n_bins ) : <TAB> bin_width = span / n_bins <TAB> bins = [ 0 ] * n_bins <TAB> for x in data : <TAB><TAB> b = int ( mpfloor ( ( x - minimum ) / bin_width ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> b = 0 <TAB><TAB> elif b > = n_bins : <TAB><TAB><TAB> b = n_bins - 1 <TAB><TAB> bins [ b ] + = 1 <TAB> self . bins = bins <TAB> self . bin_width = bin_width",if b < 0 :,if b < 0 :,100.0,100.00,True
4217,"def infer_context ( typ , context = "" http://schema.org "" ) : <TAB> parsed_context = urlparse ( typ ) <TAB> if parsed_context . netloc : <TAB><TAB> base = "" "" . join ( [ parsed_context . scheme , "" :// "" , parsed_context . netloc ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> context = urljoin ( base , parsed_context . path ) <TAB><TAB><TAB> typ = parsed_context . fragment . strip ( "" / "" ) <TAB><TAB> elif parsed_context . path : <TAB><TAB><TAB> context = base <TAB><TAB><TAB> typ = parsed_context . path . strip ( "" / "" ) <TAB> return context , typ",if parsed_context . path and parsed_context . fragment :,if parsed_context . fragment :,74.53012415402816,96.83,False
4218,"def parse ( self , items ) : <TAB> for index , item in enumerate ( items ) : <TAB><TAB> keys = self . build_key ( item ) <TAB><TAB> if keys is None : <TAB><TAB><TAB> continue <TAB><TAB> # Update `items` <TAB><TAB> self . items [ tuple ( keys ) ] = ( index , item ) <TAB><TAB> # Update `table` <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Unable to update table (keys:  %r ) "" , keys )","if not self . path_set ( self . table , keys , ( index , item ) ) :",if not self . update_table ( keys ) :,92.73562841656222,89.80,False
4219,"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB><TAB> if tag == "" layers "" : <TAB><TAB><TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB><TAB> elif isinstance ( val , MutableMapping ) : <TAB><TAB><TAB> child = dict_to_XML ( key , val ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> child = Element ( "" variable "" , name = key ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> child = Element ( key ) <TAB><TAB><TAB> child . text = str ( val ) <TAB><TAB> elem . append ( child ) <TAB> return elem","if tag == ""config"" :","if tag == ""variable"" :",99.06084860518331,98.98,False
4220,"def _get_config_value ( self , section , key ) : <TAB> if section : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . error ( "" Error: Config section  ' %s '  not found "" , section ) <TAB><TAB><TAB> return None <TAB><TAB> return self . config [ section ] . get ( key , self . config [ key ] ) <TAB> else : <TAB><TAB> return self . config [ key ]",if section not in self . config :,if section not in self . config :,75.0,100.00,True
4221,"def h_line_down ( self , input ) : <TAB> end_this_line = self . value . find ( "" \n "" , self . cursor_position ) <TAB> if end_this_line == - 1 : <TAB><TAB> if self . scroll_exit : <TAB><TAB><TAB> self . h_exit_down ( None ) <TAB><TAB> else : <TAB><TAB><TAB> self . cursor_position = len ( self . value ) <TAB> else : <TAB><TAB> self . cursor_position = end_this_line + 1 <TAB><TAB> for x in range ( self . cursorx ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> elif self . value [ self . cursor_position ] == "" \n "" : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . cursor_position + = 1",if self . cursor_position > len ( self . value ) - 1 :,"if self . value [ self . cursor_position ] == ""\r"" :",94.77291455830206,95.70,False
4222,"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB><TAB> while 1 : <TAB><TAB><TAB> data = fp . read ( bufsize ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> if isinstance ( data , str ) : <TAB><TAB><TAB><TAB> data = data . encode ( fp . encoding ) <TAB><TAB><TAB> m . update ( data ) <TAB> except IOError as msg : <TAB><TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB><TAB> return 1 <TAB> out . write ( "" %s   %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0",if not data :,if not data :,100.0,100.00,True
4223,"def main ( input ) : <TAB> logging . info ( "" Running Azure Cloud Custodian Policy  %s "" , input ) <TAB> context = { <TAB><TAB> "" config_file "" : join ( function_directory , "" config.json "" ) , <TAB><TAB> "" auth_file "" : join ( function_directory , "" auth.json "" ) , <TAB> } <TAB> event = None <TAB> subscription_id = None <TAB> if isinstance ( input , QueueMessage ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> event = input . get_json ( ) <TAB><TAB> subscription_id = ResourceIdParser . get_subscription_id ( event [ "" subject "" ] ) <TAB> handler . run ( event , context , subscription_id )",if input . dequeue_count > max_dequeue_count :,"if ""subject"" not in input . get_json ( ) :",71.47715737731976,93.53,False
4224,"def maybeExtractTarball ( self ) : <TAB> if self . tarball : <TAB><TAB> tar = self . computeTarballOptions ( ) + [ "" -xvf "" , self . tarball ] <TAB><TAB> res = yield self . _Cmd ( tar , abandonOnFailure = False ) <TAB><TAB> <MASK> # error with tarball.. erase repo dir and tarball <TAB><TAB><TAB> yield self . _Cmd ( [ "" rm "" , "" -f "" , self . tarball ] , abandonOnFailure = False ) <TAB><TAB><TAB> yield self . runRmdir ( self . repoDir ( ) , abandonOnFailure = False )",if res :,if not res :,71.99205422733861,98.12,False
4225,"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_action = 0 <TAB><TAB><TAB> for name , _val in val . items ( ) : <TAB><TAB><TAB><TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB><TAB><TAB><TAB> if action == 1 : <TAB><TAB><TAB><TAB><TAB> new_action = 1 <TAB><TAB> else : <TAB><TAB><TAB> new_action = watcher . set_opt ( key , val ) <TAB><TAB> if new_action == 1 : <TAB><TAB><TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher . do_action ( action )","if key == ""hooks"" :","if isinstance ( val , dict ) :",96.20945701617275,97.07,False
4226,"def _import_playlists ( self , fns , library ) : <TAB> added = 0 <TAB> for filename in fns : <TAB><TAB> name = _name_for ( filename ) <TAB><TAB> with open ( filename , "" rb "" ) as f : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> playlist = parse_m3u ( f , name , library = library ) <TAB><TAB><TAB> elif filename . endswith ( "" .pls "" ) : <TAB><TAB><TAB><TAB> playlist = parse_pls ( f , name , library = library ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> print_w ( "" Unsupported playlist type for  ' %s ' "" % filename ) <TAB><TAB><TAB><TAB> continue <TAB><TAB> self . changed ( playlist ) <TAB><TAB> library . add ( playlist ) <TAB><TAB> added + = 1 <TAB> return added","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :","if filename . endswith ( "".m3u"" ) :",92.70689459599967,95.88,False
4227,"def unwrap_term_buckets ( self , timestamp , term_buckets ) : <TAB> for term_data in term_buckets : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . unwrap_interval_buckets ( <TAB><TAB><TAB><TAB> timestamp , term_data [ "" key "" ] , term_data [ "" interval_aggs "" ] [ "" buckets "" ] <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> self . check_matches ( timestamp , term_data [ "" key "" ] , term_data )","if ""interval_aggs"" in term_data :","if ""interval_aggs"" in term_data :",75.0,100.00,True
4228,"def _get_exception ( flags , timeout_ms , payload_size ) : <TAB> if flags & FLAG_ERROR : <TAB><TAB> if flags & FLAG_TIMEOUT : <TAB><TAB><TAB> return SpicommTimeoutError ( timeout_ms / 1000.0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return SpicommOverflowError ( payload_size ) <TAB><TAB> return SpicommError ( ) <TAB> return None",if flags & FLAG_OVERFLOW :,if flags & FLAG_OVERFLOW :,75.0,100.00,True
4229,"def _get_pattern ( self , pattern_id ) : <TAB> """"""Get pattern item by id."""""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB><TAB> if key in self . tagged_blocks : <TAB><TAB><TAB> data = self . tagged_blocks . get_data ( key ) <TAB><TAB><TAB> for pattern in data : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return pattern <TAB> return None",if pattern . pattern_id == pattern_id :,if pattern . id == pattern_id :,98.21366407307775,97.57,False
4230,"def print_quiet ( self , context , * args , * * kwargs ) : <TAB> for index , ( key , value ) in enumerate ( <TAB><TAB> itertools . chain ( enumerate ( args ) , kwargs . items ( ) ) <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> self . format_quiet ( index , key , value , fields = context . get_input_fields ( ) ) <TAB><TAB><TAB> )","if self . filter ( index , key , value ) :",if index :,87.50809708699006,91.21,False
4231,"def complete ( self , block ) : <TAB> with self . _condition : <TAB><TAB> if not self . _final : <TAB><TAB><TAB> return False <TAB><TAB> if self . _complete ( ) : <TAB><TAB><TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _condition . wait_for ( self . _complete ) <TAB><TAB><TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB><TAB><TAB> return True <TAB><TAB> return False",if block :,if self . _final :,70.71164779538474,96.80,False
4232,"def compression_rotator ( source , dest ) : <TAB> with open ( source , "" rb "" ) as sf : <TAB><TAB> with gzip . open ( dest , "" wb "" ) as wf : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> data = sf . read ( CHUNK_SIZE ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> wf . write ( data ) <TAB> os . remove ( source )",if not data :,if not data :,100.0,100.00,True
4233,"def mockup ( self , records ) : <TAB> provider = TransipProvider ( "" "" , "" "" , "" "" ) <TAB> _dns_entries = [ ] <TAB> for record in records : <TAB><TAB> <MASK> <TAB><TAB><TAB> entries_for = getattr ( provider , "" _entries_for_ {} "" . format ( record . _type ) ) <TAB><TAB><TAB> # Root records have '@' as name <TAB><TAB><TAB> name = record . name <TAB><TAB><TAB> if name == "" "" : <TAB><TAB><TAB><TAB> name = provider . ROOT_RECORD <TAB><TAB><TAB> _dns_entries . extend ( entries_for ( name , record ) ) <TAB><TAB><TAB> # NS is not supported as a DNS Entry, <TAB><TAB><TAB> # so it should cover the if statement <TAB><TAB><TAB> _dns_entries . append ( DnsEntry ( "" @ "" , "" 3600 "" , "" NS "" , "" ns01.transip.nl. "" ) ) <TAB> self . mockupEntries = _dns_entries",if record . _type in provider . SUPPORTS :,"if hasattr ( record , ""_entries_for_{}"" . format ( record . _type )",67.46053525136274,93.00,False
4234,"def parse_known_args ( self , args = None , namespace = None ) : <TAB> entrypoint = self . prog . split ( ""   "" ) [ 0 ] <TAB> try : <TAB><TAB> defs = get_defaults_for_argparse ( entrypoint ) <TAB><TAB> ignore = defs . pop ( "" Ignore "" , None ) <TAB><TAB> self . set_defaults ( * * defs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> set_notebook_diff_ignores ( ignore ) <TAB> except ValueError : <TAB><TAB> pass <TAB> return super ( ConfigBackedParser , self ) . parse_known_args ( <TAB><TAB> args = args , namespace = namespace <TAB> )",if ignore :,if ignore is not None :,83.25813116674192,97.32,False
4235,"def _maybeRebuildAtlas ( self , threshold = 4 , minlen = 1000 ) : <TAB> n = len ( self . fragmentAtlas ) <TAB> if ( n > minlen ) and ( n > threshold * len ( self . data ) ) : <TAB><TAB> self . fragmentAtlas . rebuild ( <TAB><TAB><TAB> list ( zip ( * self . _style ( [ "" symbol "" , "" size "" , "" pen "" , "" brush "" ] ) ) ) <TAB><TAB> ) <TAB><TAB> self . data [ "" sourceRect "" ] = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _sourceQRect . clear ( ) <TAB><TAB> self . updateSpots ( )",if _USE_QRECT :,if self . _sourceQRect :,75.86387164940645,96.74,False
4236,"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB><TAB> # Ignore return events in generator except when stepping. <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . trace_dispatch <TAB><TAB> try : <TAB><TAB><TAB> self . frame_returning = frame <TAB><TAB><TAB> self . user_return ( frame , arg ) <TAB><TAB> finally : <TAB><TAB><TAB> self . frame_returning = None <TAB><TAB> if self . quitting : <TAB><TAB><TAB> raise BdbQuit <TAB><TAB> # The user issued a 'next' or 'until' command. <TAB><TAB> if self . stopframe is frame and self . stoplineno != - 1 : <TAB><TAB><TAB> self . _set_stopinfo ( None , None ) <TAB> return self . trace_dispatch",if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,if self . trace_dispatch :,95.899353989481,93.17,False
4237,"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB><TAB> try : <TAB><TAB><TAB> if self . hosted_service_name is not None : <TAB><TAB><TAB><TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB><TAB> try : <TAB><TAB><TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB><TAB> except : <TAB><TAB><TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( )",if self . storage_account_name is not None :,if self . storage_account_name is not None :,75.0,100.00,True
4238,"def make_log_msg ( self , msg , * other_messages ) : <TAB> MAX_MESSAGE_LENGTH = 1000 <TAB> if not other_messages : <TAB><TAB> # assume that msg is a single string <TAB><TAB> return msg [ - MAX_MESSAGE_LENGTH : ] <TAB> else : <TAB><TAB> if len ( msg ) : <TAB><TAB><TAB> msg + = "" \n ... \n "" <TAB><TAB><TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len ( msg ) <TAB><TAB> else : <TAB><TAB><TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <TAB><TAB> <MASK> <TAB><TAB><TAB> msg + = other_messages [ 0 ] [ - NEXT_MESSAGE_OFFSET : ] <TAB><TAB><TAB> return self . make_log_msg ( msg , * other_messages [ 1 : ] ) <TAB><TAB> else : <TAB><TAB><TAB> return self . make_log_msg ( msg )",if NEXT_MESSAGE_OFFSET > 0 :,if NEXT_MESSAGE_OFFSET < MAX_MESSAGE_LENGTH :,98.50805434135066,97.11,False
4239,"def wrapper ( # type: ignore <TAB> self : RequestHandler , * args , * * kwargs ) - > Optional [ Awaitable [ None ] ] : <TAB> if self . request . path . endswith ( "" / "" ) : <TAB><TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB><TAB><TAB> uri = self . request . path . rstrip ( "" / "" ) <TAB><TAB><TAB> if uri : # don't try to redirect '/' to '' <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> uri + = "" ? "" + self . request . query <TAB><TAB><TAB><TAB> self . redirect ( uri , permanent = True ) <TAB><TAB><TAB><TAB> return None <TAB><TAB> else : <TAB><TAB><TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )",if self . request . query :,if self . request . query :,75.0,100.00,True
4240,"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB><TAB> var = d . upper ( ) <TAB><TAB> if var == "" QTCORE "" : <TAB><TAB><TAB> continue <TAB><TAB> value = env [ "" LIBPATH_ "" + var ] <TAB><TAB> <MASK> <TAB><TAB><TAB> core = env [ coreval ] <TAB><TAB><TAB> accu = [ ] <TAB><TAB><TAB> for lib in value : <TAB><TAB><TAB><TAB> if lib in core : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> accu . append ( lib ) <TAB><TAB><TAB> env [ "" LIBPATH_ "" + var ] = accu",if value :,if coreval :,79.2582115848998,98.71,False
4241,"def _attach_children ( self , other , exclude_worldbody , dry_run = False ) : <TAB> for other_child in other . all_children ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self_child = self . get_children ( other_child . spec . name ) <TAB><TAB><TAB> self_child . _attach ( <TAB><TAB><TAB><TAB> other_child , exclude_worldbody , dry_run <TAB><TAB><TAB> ) # pylint: disable=protected-access",if not other_child . spec . repeated :,"if isinstance ( other_child , Leaf ) :",80.31661376731655,93.98,False
4242,"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB><TAB> if child . getchildren ( ) : <TAB><TAB><TAB> ## Complex-type child. Recurse <TAB><TAB><TAB> content = getDictFromTree ( child ) <TAB><TAB> else : <TAB><TAB><TAB> content = child . text <TAB><TAB> <MASK> <TAB><TAB><TAB> if not type ( ret_dict [ child . tag ] ) == list : <TAB><TAB><TAB><TAB> ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB><TAB><TAB> ret_dict [ child . tag ] . append ( content or "" "" ) <TAB><TAB> else : <TAB><TAB><TAB> ret_dict [ child . tag ] = content or "" "" <TAB> return ret_dict",if ret_dict . has_key ( child . tag ) :,if child . tag in ret_dict :,96.89399848696083,95.40,False
4243,"def nsUriMatch ( self , value , wanted , strict = 0 , tt = type ( ( ) ) ) : <TAB> """"""Return a true value if two namespace uri values match."""""" <TAB> if value == wanted or ( type ( wanted ) is tt ) and value in wanted : <TAB><TAB> return 1 <TAB> if not strict and value is not None : <TAB><TAB> wanted = type ( wanted ) is tt and wanted or ( wanted , ) <TAB><TAB> value = value [ - 1 : ] != "" / "" and value or value [ : - 1 ] <TAB><TAB> for item in wanted : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return 1 <TAB> return 0",if item == value or item [ : - 1 ] == value :,if item == value and item in value :,94.47324702917965,94.47,False
4244,"def update_repository ( self , ignore_issues = False , force = False ) : <TAB> """"""Update."""""" <TAB> if not await self . common_update ( ignore_issues , force ) : <TAB><TAB> return <TAB> # Get appdaemon objects. <TAB> if self . repository_manifest : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . content . path . remote = "" "" <TAB> if self . content . path . remote == "" apps "" : <TAB><TAB> self . data . domain = get_first_directory_in_directory ( <TAB><TAB><TAB> self . tree , self . content . path . remote <TAB><TAB> ) <TAB><TAB> self . content . path . remote = f "" apps/ { self . data . name } "" <TAB> # Set local path <TAB> self . content . path . local = self . localpath",if self . data . content_in_root :,"if self . content . path . remote == ""appdaemon"" :",97.71699387262987,95.18,False
4245,"def addOutput ( self , data , isAsync = None , * * kwargs ) : <TAB> isAsync = _get_async_param ( isAsync , * * kwargs ) <TAB> if isAsync : <TAB><TAB> self . terminal . eraseLine ( ) <TAB><TAB> self . terminal . cursorBackward ( len ( self . lineBuffer ) + len ( self . ps [ self . pn ] ) ) <TAB> self . terminal . write ( data ) <TAB> if isAsync : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . terminal . nextLine ( ) <TAB><TAB> self . terminal . write ( self . ps [ self . pn ] ) <TAB><TAB> if self . lineBuffer : <TAB><TAB><TAB> oldBuffer = self . lineBuffer <TAB><TAB><TAB> self . lineBuffer = [ ] <TAB><TAB><TAB> self . lineBufferIndex = 0 <TAB><TAB><TAB> self . _deliverBuffer ( oldBuffer )",if self . _needsNewline ( ) :,if self . lineBufferIndex == len ( self . ps [ self . pn ] ) :,96.02953650083188,93.81,False
4246,"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB><TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB><TAB> installed = True if dlc_version else False <TAB><TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB><TAB> <MASK> <TAB><TAB><TAB> status = self . legacy_get_dlc_status ( dlc_title ) <TAB><TAB><TAB> installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB><TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else : <TAB><TAB> if self . install_dir and os . path . exists ( self . install_dir ) : <TAB><TAB><TAB> installed = True <TAB> return installed",if not installed :,if self . legacy_get_dlc_version :,98.24109851853993,95.17,False
4247,"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB><TAB> sockname = None <TAB><TAB> try : <TAB><TAB><TAB> sockname = self . sock . getsockname ( ) <TAB><TAB> except ( socket . error , OSError ) : <TAB><TAB><TAB> pass <TAB><TAB> self . sock . close ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # it was a Unix domain socket, remove it from the filesystem <TAB><TAB><TAB> if os . path . exists ( sockname ) : <TAB><TAB><TAB><TAB> os . remove ( sockname ) <TAB> self . sock = None",if type ( sockname ) is str :,if sockname :,93.59743597278703,95.87,False
4248,"def post_file ( self , file_path , graph_type = "" edges "" , file_type = "" csv "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> base_path = self . server_base_path <TAB> with open ( file_path , "" rb "" ) as file : <TAB><TAB> out = requests . post ( <TAB><TAB><TAB> f "" { base_path } /api/v2/upload/datasets/ { dataset_id } / { graph_type } / { file_type } "" , <TAB><TAB><TAB> verify = self . certificate_validation , <TAB><TAB><TAB> headers = { "" Authorization "" : f "" Bearer  { tok } "" } , <TAB><TAB><TAB> data = file . read ( ) , <TAB><TAB> ) . json ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise Exception ( out ) <TAB><TAB> return out","if not out [ ""success"" ] :",if not out :,77.64771372872956,97.29,False
4249,"def _get_vqa_v2_image_raw_dataset ( directory , image_root_url , image_urls ) : <TAB> """"""Extract the VQA V2 image data set to directory unless it's there."""""" <TAB> for url in image_urls : <TAB><TAB> filename = os . path . basename ( url ) <TAB><TAB> download_url = os . path . join ( image_root_url , url ) <TAB><TAB> path = generator_utils . maybe_download ( directory , filename , download_url ) <TAB><TAB> unzip_dir = os . path . join ( directory , filename . strip ( "" .zip "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> zipfile . ZipFile ( path , "" r "" ) . extractall ( directory )",if not tf . gfile . Exists ( unzip_dir ) :,if os . path . exists ( unzip_dir ) :,66.33926144434903,96.36,False
4250,"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> request_uri = unquote ( environ [ key ] ) <TAB><TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB><TAB> if request_uri . startswith ( script_name ) : <TAB><TAB><TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB><TAB><TAB> break <TAB> return self . app ( environ , start_response )",if key not in environ :,if key not in environ :,100.0,100.00,True
4251,"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB><TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB><TAB> if isinstance ( value , tf . keras . layers . Layer ) : <TAB><TAB><TAB> new_layer = self . _instrument ( value ) <TAB><TAB><TAB> if new_layer is not value : <TAB><TAB><TAB><TAB> setattr ( model , key , new_layer ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for i , item in enumerate ( value ) : <TAB><TAB><TAB><TAB> if isinstance ( item , tf . keras . layers . Layer ) : <TAB><TAB><TAB><TAB><TAB> value [ i ] = self . _instrument ( item ) <TAB> return model","elif isinstance ( value , list ) :","elif isinstance ( value , list ) :",100.0,100.00,True
4252,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB><TAB> if i == "" . "" or i == "" .. "" : <TAB><TAB><TAB> continue <TAB><TAB> path = os . path . join ( dir , i ) <TAB><TAB> if os . path . isdir ( path ) : <TAB><TAB><TAB> dirlist . append ( i ) <TAB><TAB><TAB> continue <TAB><TAB> path = path . upper ( ) <TAB><TAB> value = i . upper ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB><TAB> self . dirs = dirlist",if pattern . match ( value ) is not None :,if pattern . match ( path ) :,71.82441913608622,97.64,False
4253,"def get_text ( self , nodelist ) : <TAB> """"""Return a string representation of the motif's properties listed on nodelist ."""""" <TAB> retlist = [ ] <TAB> for node in nodelist : <TAB><TAB> if node . nodeType == Node . TEXT_NODE : <TAB><TAB><TAB> retlist . append ( node . wholeText ) <TAB><TAB> <MASK> <TAB><TAB><TAB> retlist . append ( self . get_text ( node . childNodes ) ) <TAB> return re . sub ( r "" \ s+ "" , ""   "" , "" "" . join ( retlist ) )",elif node . hasChildNodes :,elif node . nodeType == Node . ELEMENT_NODE :,95.97563720051545,93.55,False
4254,"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB><TAB> if self . posts : <TAB><TAB><TAB> if self . latest : <TAB><TAB><TAB><TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . latest : <TAB><TAB><TAB><TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path )",if self . stories :,if self . stories :,100.0,100.00,True
4255,"def _get_python_wrapper_content ( self , job_class , args ) : <TAB> job = job_class ( [ "" -r "" , "" hadoop "" ] + list ( args ) ) <TAB> job . sandbox ( ) <TAB> with job . make_runner ( ) as runner : <TAB><TAB> runner . _create_setup_wrapper_scripts ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with open ( runner . _spark_python_wrapper_path ) as f : <TAB><TAB><TAB><TAB> return f . read ( ) <TAB><TAB> else : <TAB><TAB><TAB> return None",if runner . _spark_python_wrapper_path :,if runner . _spark_python_wrapper_path :,100.0,100.00,True
4256,"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB><TAB> <MASK> <TAB><TAB><TAB> w + = 1 <TAB><TAB> elif ch == "" \t "" : <TAB><TAB><TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return w","if ch == "" "" :","if ch == "" "" :",100.0,100.00,True
4257,def run ( self ) : <TAB> # if the i3status process dies we want to restart it. <TAB> # We give up restarting if we have died too often <TAB> for _ in range ( 10 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> self . spawn_i3status ( ) <TAB><TAB> # check if we never worked properly and if so quit now <TAB><TAB> if not self . ready : <TAB><TAB><TAB> break <TAB><TAB> # limit restart rate <TAB><TAB> self . lock . wait ( 5 ),if not self . py3_wrapper . running :,if self . _stopped :,71.1800751521046,94.20,False
4258,"def translate_len ( <TAB> builder : IRBuilder , expr : CallExpr , callee : RefExpr ) - > Optional [ Value ] : <TAB> # Special case builtins.len <TAB> if len ( expr . args ) == 1 and expr . arg_kinds == [ ARG_POS ] : <TAB><TAB> expr_rtype = builder . node_type ( expr . args [ 0 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # len() of fixed-length tuple can be trivially determined statically, <TAB><TAB><TAB> # though we still need to evaluate it. <TAB><TAB><TAB> builder . accept ( expr . args [ 0 ] ) <TAB><TAB><TAB> return Integer ( len ( expr_rtype . types ) ) <TAB><TAB> else : <TAB><TAB><TAB> obj = builder . accept ( expr . args [ 0 ] ) <TAB><TAB><TAB> return builder . builtin_len ( obj , - 1 ) <TAB> return None","if isinstance ( expr_rtype , RTuple ) :","if expr_rtype . kind == ""fixed"" :",97.49268590008997,95.82,False
4259,"def parse_auth ( val ) : <TAB> if val is not None : <TAB><TAB> authtype , params = val . split ( ""   "" , 1 ) <TAB><TAB> if authtype in known_auth_schemes : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> params = parse_auth_params ( params ) <TAB><TAB> return authtype , params <TAB> return val","if authtype == ""Basic"" and '""' not in params :",if params is None :,89.0486329354492,90.92,False
4260,"def toxml ( self ) : <TAB> text = self . value <TAB> self . parent . setBidi ( getBidiType ( text ) ) <TAB> if not text . startswith ( HTML_PLACEHOLDER_PREFIX ) : <TAB><TAB> if self . parent . nodeName == "" p "" : <TAB><TAB><TAB> text = text . replace ( "" \n "" , "" \n     "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> text = "" \n       "" + text . replace ( "" \n "" , "" \n       "" ) <TAB> text = self . doc . normalizeEntities ( text ) <TAB> return text","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :","elif self . parent . nodeName == ""a"" :",67.69963408336336,90.46,False
4261,"def get_all_related_many_to_many_objects ( self ) : <TAB> try : # Try the cache first. <TAB><TAB> return self . _all_related_many_to_many_objects <TAB> except AttributeError : <TAB><TAB> rel_objs = [ ] <TAB><TAB> for klass in get_models ( ) : <TAB><TAB><TAB> for f in klass . _meta . many_to_many : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> rel_objs . append ( RelatedObject ( f . rel . to , klass , f ) ) <TAB><TAB> self . _all_related_many_to_many_objects = rel_objs <TAB><TAB> return rel_objs",if f . rel and self == f . rel . to . _meta :,if f . rel and f . rel . to not in self . _all_related_,70.72519832030615,94.57,False
4262,"def state_highstate ( self , state , dirpath ) : <TAB> opts = copy . copy ( self . config ) <TAB> opts [ "" file_roots "" ] = dict ( base = [ dirpath ] ) <TAB> HIGHSTATE = HighState ( opts ) <TAB> HIGHSTATE . push_active ( ) <TAB> try : <TAB><TAB> high , errors = HIGHSTATE . render_highstate ( state ) <TAB><TAB> <MASK> <TAB><TAB><TAB> import pprint <TAB><TAB><TAB> pprint . pprint ( "" \n "" . join ( errors ) ) <TAB><TAB><TAB> pprint . pprint ( high ) <TAB><TAB> out = HIGHSTATE . state . call_high ( high ) <TAB><TAB> # pprint.pprint(out) <TAB> finally : <TAB><TAB> HIGHSTATE . pop_active ( )",if errors :,if errors :,100.0,100.00,True
4263,"def _update_target_host ( self , target , target_host ) : <TAB> """"""Update target host."""""" <TAB> target_host = None if target_host == "" "" else target_host <TAB> if not target_host : <TAB><TAB> for device_type , tgt in target . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> target_host = tgt <TAB><TAB><TAB><TAB> break <TAB> if not target_host : <TAB><TAB> target_host = "" llvm "" if tvm . runtime . enabled ( "" llvm "" ) else "" stackvm "" <TAB> if isinstance ( target_host , str ) : <TAB><TAB> target_host = tvm . target . Target ( target_host ) <TAB> return target_host",if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,"if isinstance ( tgt , tvm . target . Target ) :",87.630647977405,91.02,False
4264,"def __console_writer ( self ) : <TAB> while True : <TAB><TAB> self . __writer_event . wait ( ) <TAB><TAB> self . __writer_event . clear ( ) <TAB><TAB> if self . __console_view : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . log . debug ( "" Writing console view to STDOUT "" ) <TAB><TAB><TAB><TAB> sys . stdout . write ( self . console_markup . clear ) <TAB><TAB><TAB><TAB> sys . stdout . write ( self . __console_view ) <TAB><TAB><TAB><TAB> sys . stdout . write ( self . console_markup . TOTAL_RESET )",if not self . short_only :,if self . console_markup . clear :,69.56594917075472,95.98,False
4265,"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB><TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB><TAB> if p and p . isMarked ( ) : <TAB><TAB><TAB> break <TAB><TAB> elif p : <TAB><TAB><TAB> p . moveToThreadBack ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> wrapped = True <TAB><TAB><TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB><TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",elif wrapped :,elif wrapped :,100.0,100.00,True
4266,"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB><TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB><TAB><TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB><TAB><TAB><TAB> if vm_details == "" Absent "" : <TAB><TAB><TAB><TAB><TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB><TAB><TAB> if not query_map [ alias ] [ driver ] : <TAB><TAB><TAB><TAB> query_map [ alias ] . pop ( driver ) <TAB><TAB> <MASK> <TAB><TAB><TAB> query_map . pop ( alias ) <TAB> return query_map",if not query_map [ alias ] :,"if not query_map [ alias ] [ ""Depreciation"" ] :",97.74594582279474,97.61,False
4267,"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB><TAB> already_test = [ ] <TAB><TAB> for fname in lib_zip . namelist ( ) : <TAB><TAB><TAB> pname , fname = os . path . split ( fname ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if pname not in already_test and "" / "" not in pname : <TAB><TAB><TAB><TAB> already_test . append ( pname ) <TAB><TAB><TAB><TAB> if is_shadowing ( pname ) : <TAB><TAB><TAB><TAB><TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs",if fname or ( pname and fname ) :,"if not fname . endswith ( "".py"" ) :",65.50158479113772,95.37,False
4268,"def make_chains ( chains_info ) : <TAB> chains = [ [ ] for _ in chains_info [ 0 ] [ 1 ] ] <TAB> for i , num_ids in enumerate ( chains_info [ : - 1 ] ) : <TAB><TAB> num , ids = num_ids <TAB><TAB> for j , ident in enumerate ( ids ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> next_chain_info = chains_info [ i + 1 ] <TAB><TAB><TAB><TAB> previous = next_chain_info [ 1 ] [ j ] <TAB><TAB><TAB><TAB> block = SimpleBlock ( num , ident , previous ) <TAB><TAB><TAB><TAB> chains [ j ] . append ( block ) <TAB> chains = { i : make_generator ( chain ) for i , chain in enumerate ( chains ) } <TAB> return chains","if ident != """" :",if j < len ( ids ) - 1 :,95.13286086405232,95.73,False
4269,"def filter_input ( mindate , maxdate , files ) : <TAB> mindate = parse ( mindate ) if mindate is not None else datetime . datetime . min <TAB> maxdate = parse ( maxdate ) if maxdate is not None else datetime . datetime . max <TAB> for line in fileinput . input ( files ) : <TAB><TAB> tweet = json . loads ( line ) <TAB><TAB> created_at = parse ( tweet [ "" created_at "" ] ) <TAB><TAB> created_at = created_at . replace ( tzinfo = None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( json . dumps ( tweet ) )",if mindate < created_at and maxdate > created_at :,if mindate < created_at < mindate and maxdate < created_at :,68.17508928714686,96.33,False
4270,"def get ( self ) : <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self . _exception is not _NONE : <TAB><TAB> if self . _exception is None : <TAB><TAB><TAB> return self . value <TAB><TAB> getcurrent ( ) . throw ( * self . _exception ) # pylint:disable=undefined-variable <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ConcurrentObjectUseError ( <TAB><TAB><TAB><TAB> "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB><TAB><TAB> ) <TAB><TAB> self . greenlet = getcurrent ( ) # pylint:disable=undefined-variable <TAB><TAB> try : <TAB><TAB><TAB> return self . hub . switch ( ) <TAB><TAB> finally : <TAB><TAB><TAB> self . greenlet = None",if self . greenlet is not None :,if self . greenlet is not _NONE :,73.87677666774182,98.54,False
4271,"def default_loader ( href , parse , encoding = None ) : <TAB> with open ( href ) as file : <TAB><TAB> <MASK> <TAB><TAB><TAB> data = ElementTree . parse ( file ) . getroot ( ) <TAB><TAB> else : <TAB><TAB><TAB> data = file . read ( ) <TAB><TAB><TAB> if encoding : <TAB><TAB><TAB><TAB> data = data . decode ( encoding ) <TAB> return data","if parse == ""xml"" :",if parse :,93.7848060433092,94.51,False
4272,def is_all_qud ( world ) : <TAB> m = True <TAB> for obj in world : <TAB><TAB> <MASK> <TAB><TAB><TAB> if obj . nice : <TAB><TAB><TAB><TAB> m = m and True <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> m = m and False <TAB><TAB> else : <TAB><TAB><TAB> m = m and True <TAB> return m,if obj . blond :,"if isinstance ( obj , QuantizableObject ) :",93.52702810408238,94.06,False
4273,"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB><TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB><TAB> originalBuffer = self . view . substr ( region ) <TAB><TAB> prefixed = self . prefix ( originalBuffer ) <TAB><TAB> if prefixed : <TAB><TAB><TAB> self . view . replace ( edit , region , prefixed ) <TAB><TAB> return <TAB> for region in self . view . sel ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> originalBuffer = self . view . substr ( region ) <TAB><TAB> prefixed = self . prefix ( originalBuffer ) <TAB><TAB> if prefixed : <TAB><TAB><TAB> self . view . replace ( edit , region , prefixed )",if region . empty ( ) :,if region . size ( ) == 0 :,96.5042354509017,96.75,False
4274,"def add_fields ( self , params ) : <TAB> for ( key , val ) in params . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_params = { } <TAB><TAB><TAB> for k in val : <TAB><TAB><TAB><TAB> new_params [ "" %s __ %s "" % ( key , k ) ] = val [ k ] <TAB><TAB><TAB> self . add_fields ( new_params ) <TAB><TAB> else : <TAB><TAB><TAB> self . add_field ( key , val )","if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",100.0,100.00,True
4275,"def find_magic ( self , f , pos , magic ) : <TAB> f . seek ( pos ) <TAB> block = f . read ( 32 * 1024 ) <TAB> if len ( block ) < len ( magic ) : <TAB><TAB> return - 1 <TAB> p = block . find ( magic ) <TAB> while p < 0 : <TAB><TAB> pos + = len ( block ) - len ( magic ) + 1 <TAB><TAB> block = block [ 1 - len ( magic ) : ] + f . read ( 32 << 10 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return - 1 <TAB><TAB> p = block . find ( magic ) <TAB> return pos + p",if len ( block ) == len ( magic ) - 1 :,if len ( block ) < 32 :,77.98768642276488,94.61,False
4276,"def check_strings ( self ) : <TAB> """"""Check that all strings have been consumed."""""" <TAB> for i , aList in enumerate ( self . string_tokens ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> g . trace ( "" warning: line  %s . unused strings "" % i ) <TAB><TAB><TAB> for z in aList : <TAB><TAB><TAB><TAB> print ( self . dump_token ( z ) )",if aList :,if i > 0 :,70.03841832815205,96.05,False
4277,"def get_tokens_unprocessed ( self , text ) : <TAB> from pygments . lexers . _cocoa_builtins import ( <TAB><TAB> COCOA_INTERFACES , <TAB><TAB> COCOA_PROTOCOLS , <TAB><TAB> COCOA_PRIMITIVES , <TAB> ) <TAB> for index , token , value in RegexLexer . get_tokens_unprocessed ( self , text ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> value in COCOA_INTERFACES <TAB><TAB><TAB><TAB> or value in COCOA_PROTOCOLS <TAB><TAB><TAB><TAB> or value in COCOA_PRIMITIVES <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> token = Name . Builtin . Pseudo <TAB><TAB> yield index , token , value",if token is Name or token is Name . Class :,if token is Name . Builtin . Pseudo :,88.6828388953016,96.82,False
4278,"def key_from_key_value_dict ( key_info ) : <TAB> res = [ ] <TAB> if not "" key_value "" in key_info : <TAB><TAB> return res <TAB> for value in key_info [ "" key_value "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> e = base64_to_long ( value [ "" rsa_key_value "" ] [ "" exponent "" ] ) <TAB><TAB><TAB> m = base64_to_long ( value [ "" rsa_key_value "" ] [ "" modulus "" ] ) <TAB><TAB><TAB> key = RSA . construct ( ( m , e ) ) <TAB><TAB><TAB> res . append ( key ) <TAB> return res","if ""rsa_key_value"" in value :","if ""rsa_key_value"" in value :",100.0,100.00,True
4279,"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB><TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB><TAB> originalBuffer = self . view . substr ( region ) <TAB><TAB> prefixed = self . prefix ( originalBuffer ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . view . replace ( edit , region , prefixed ) <TAB><TAB> return <TAB> for region in self . view . sel ( ) : <TAB><TAB> if region . empty ( ) : <TAB><TAB><TAB> continue <TAB><TAB> originalBuffer = self . view . substr ( region ) <TAB><TAB> prefixed = self . prefix ( originalBuffer ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . view . replace ( edit , region , prefixed )",if prefixed :,if prefixed :,100.0,100.00,True
4280,def finalize ( self ) : <TAB> if self . ct < 1 : <TAB><TAB> return <TAB> elif self . ct == 1 : <TAB><TAB> return 0 <TAB> total = ct = 0 <TAB> dtp = None <TAB> while self . heap : <TAB><TAB> <MASK> <TAB><TAB><TAB> if dtp is None : <TAB><TAB><TAB><TAB> dtp = heapq . heappop ( self . heap ) <TAB><TAB><TAB><TAB> continue <TAB><TAB> dt = heapq . heappop ( self . heap ) <TAB><TAB> diff = dt - dtp <TAB><TAB> ct + = 1 <TAB><TAB> total + = total_seconds ( diff ) <TAB><TAB> dtp = dt <TAB> return float ( total ) / ct,if total == 0 :,if self . heap [ 0 ] == 0 :,96.46594684176625,96.24,False
4281,"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB><TAB> self . _log . debug ( "" testing configuration "" ) <TAB><TAB> verboseflag = "" -Q "" <TAB><TAB> <MASK> <TAB><TAB><TAB> verboseflag = "" -v "" <TAB><TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB><TAB> if p . wait ( ) != 0 : <TAB><TAB><TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB><TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB><TAB> os . remove ( config_path )",if self . _log . isEnabledFor ( logging . DEBUG ) :,if self . _verbose :,67.43439897378963,95.00,False
4282,"def exe ( self , ret ) : <TAB> if not ret : <TAB><TAB> self . assertEqual ( ret , "" "" ) <TAB> else : <TAB><TAB> assert os . path . isabs ( ret ) , ret <TAB><TAB> # Note: os.stat() may return False even if the file is there <TAB><TAB> # hence we skip the test, see: <TAB><TAB> # http://stackoverflow.com/questions/3112546/os-path-exists-lies <TAB><TAB> <MASK> <TAB><TAB><TAB> assert os . path . isfile ( ret ) , ret <TAB><TAB><TAB> if hasattr ( os , "" access "" ) and hasattr ( os , "" X_OK "" ) : <TAB><TAB><TAB><TAB> # XXX may fail on OSX <TAB><TAB><TAB><TAB> self . assertTrue ( os . access ( ret , os . X_OK ) )",if POSIX :,"if hasattr ( os , ""stat"" ) :",97.9795301706205,95.71,False
4283,"def _do_cleanup ( sg_name , device_id ) : <TAB> masking_view_list = self . rest . get_masking_views_from_storage_group ( array , sg_name ) <TAB> for masking_view in masking_view_list : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . rest . delete_masking_view ( array , masking_view ) <TAB><TAB><TAB> self . rest . remove_vol_from_sg ( array , sg_name , device_id , extra_specs ) <TAB><TAB><TAB> self . rest . delete_volume ( array , device_id ) <TAB><TAB><TAB> self . rest . delete_storage_group ( array , sg_name )","if ""STG-"" in masking_view :","if masking_view . get ( ""id"" ) == device_id :",93.28695610043263,92.33,False
4284,"def hide_tooltip_if_necessary ( self , key ) : <TAB> """"""Hide calltip when necessary"""""" <TAB> try : <TAB><TAB> calltip_char = self . get_character ( self . calltip_position ) <TAB><TAB> before = self . is_cursor_before ( self . calltip_position , char_offset = 1 ) <TAB><TAB> other = key in ( Qt . Key_ParenRight , Qt . Key_Period , Qt . Key_Tab ) <TAB><TAB> <MASK> <TAB><TAB><TAB> QToolTip . hideText ( ) <TAB> except ( IndexError , TypeError ) : <TAB><TAB> QToolTip . hideText ( )","if calltip_char not in ( ""?"" , ""("" ) or before or other :",if before and other :,62.25857771467433,88.98,False
4285,"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB><TAB> if limit and len ( tags ) > = limit : <TAB><TAB><TAB> result [ "" HasMoreTags "" ] = True <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result",if exclusive_start_tag_key and key < exclusive_start_tag_key :,if exclusive_start_tag_key and key in exclusive_start_tag_key :,99.02118080804655,98.78,False
4286,"def parametrize_function_name ( request , function_name ) : <TAB> suffixes = [ ] <TAB> if "" parametrize "" in request . keywords : <TAB><TAB> argnames = request . keywords [ "" parametrize "" ] . args [ : : 2 ] <TAB><TAB> argnames = [ x . strip ( ) for names in argnames for x in names . split ( "" , "" ) ] <TAB><TAB> for name in argnames : <TAB><TAB><TAB> value = request . getfuncargvalue ( name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value . __name__ <TAB><TAB><TAB> suffixes . append ( "" {} = {} "" . format ( name , value ) ) <TAB> return "" + "" . join ( [ function_name ] + suffixes )",if inspect . isclass ( value ) :,if value is not None :,76.13291060153628,96.31,False
4287,"def add_entities ( self , positions ) : <TAB> e1 = EntityFactory ( ) <TAB> for p in positions : <TAB><TAB> <MASK> <TAB><TAB><TAB> start , length = p <TAB><TAB> else : <TAB><TAB><TAB> start , length = p , 1 <TAB><TAB> EntityOccurrenceFactory ( <TAB><TAB><TAB> document = self . doc , <TAB><TAB><TAB> entity = e1 , <TAB><TAB><TAB> offset = start , <TAB><TAB><TAB> offset_end = start + length , <TAB><TAB><TAB> alias = "" AB "" , <TAB><TAB> )","if isinstance ( p , tuple ) :","if isinstance ( p , tuple ) :",100.0,100.00,True
4288,"def transform_value ( value ) : <TAB> if isinstance ( value , collections . MutableMapping ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return DBRef ( value [ "" _ns "" ] , transform_value ( value [ "" _id "" ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> return transform_dict ( SON ( value ) ) <TAB> elif isinstance ( value , list ) : <TAB><TAB> return [ transform_value ( v ) for v in value ] <TAB> return value","if ""_id"" in value and ""_ns"" in value :","if ""_ns"" in value and ""_id"" in value :",72.8190984385402,99.62,False
4289,"def remove ( self , items ) : <TAB> """"""Remove messages from lease management."""""" <TAB> with self . _add_remove_lock : <TAB><TAB> # Remove the ack ID from lease management, and decrement the <TAB><TAB> # byte counter. <TAB><TAB> for item in items : <TAB><TAB><TAB> if self . _leased_messages . pop ( item . ack_id , None ) is not None : <TAB><TAB><TAB><TAB> self . _bytes - = item . byte_size <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> _LOGGER . debug ( "" Item  %s  was not managed. "" , item . ack_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _LOGGER . debug ( "" Bytes was unexpectedly negative:  %d "" , self . _bytes ) <TAB><TAB><TAB> self . _bytes = 0",if self . _bytes < 0 :,if self . _bytes < 0 :,100.0,100.00,True
4290,"def parse_hgsub ( lines ) : <TAB> """"""Fills OrderedDict with hgsub file content passed as list of lines"""""" <TAB> rv = OrderedDict ( ) <TAB> for l in lines : <TAB><TAB> ls = l . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> name , value = l . split ( "" = "" , 1 ) <TAB><TAB> rv [ name . strip ( ) ] = value . strip ( ) <TAB> return rv","if not ls or ls [ 0 ] == ""#"" :","if ls . startswith ( ""#"" ) :",80.48475054282169,90.94,False
4291,"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB><TAB> if self . _keys [ hash_ ] is self . _empty : <TAB><TAB><TAB> # That key was never assigned <TAB><TAB><TAB> return None <TAB><TAB> elif self . _keys [ hash_ ] == key : <TAB><TAB><TAB> # key found, assign with deleted sentinel <TAB><TAB><TAB> self . _keys [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _values [ hash_ ] = self . _deleted <TAB><TAB><TAB> self . _len - = 1 <TAB><TAB><TAB> return <TAB><TAB> hash_ = self . _rehash ( hash_ ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # table is full and wrapped around <TAB><TAB><TAB> return None",if initial_hash == hash_ :,if hash_ == initial_hash :,98.42639568821625,97.70,False
4292,"def atom ( token , no_symbol = False ) : <TAB> try : <TAB><TAB> return int ( token ) <TAB> except ValueError : <TAB><TAB> try : <TAB><TAB><TAB> return float ( token ) <TAB><TAB> except ValueError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return token [ 1 : - 1 ] <TAB><TAB><TAB> elif no_symbol : <TAB><TAB><TAB><TAB> return token <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return Symbol ( token )","if token . startswith ( ""'"" ) or token . startswith ( '""' ) :","if token [ 0 ] == ""x"" :",87.49961739358734,89.77,False
4293,"def __Suffix_Noun_Step1b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step1b : <TAB><TAB> <MASK> <TAB><TAB><TAB> token = token [ : - 1 ] <TAB><TAB><TAB> self . suffixe_noun_step1b_success = True <TAB><TAB><TAB> break <TAB> return token",if token . endswith ( suffix ) and len ( token ) > 5 :,if token . endswith ( suffix ) :,83.94883851368581,91.47,False
4294,"def _guardAgainstUnicode ( self , data ) : <TAB> # Only accept byte strings or ascii unicode values, otherwise <TAB> # there is no way to correctly decode the data into bytes. <TAB> if _pythonMajorVersion < 3 : <TAB><TAB> <MASK> <TAB><TAB><TAB> data = data . encode ( "" utf8 "" ) <TAB> else : <TAB><TAB> if isinstance ( data , str ) : <TAB><TAB><TAB> # Only accept ascii unicode values. <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> return data . encode ( "" ascii "" ) <TAB><TAB><TAB> except UnicodeEncodeError : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> raise ValueError ( "" pyDes can only work with encoded strings, not Unicode. "" ) <TAB> return data","if isinstance ( data , unicode ) :","if isinstance ( data , unicode ) :",75.0,100.00,True
4295,"def populate_resource_parameters ( self , tool_source ) : <TAB> root = getattr ( tool_source , "" root "" , None ) <TAB> if ( <TAB><TAB> root is not None <TAB><TAB> and hasattr ( self . app , "" job_config "" ) <TAB><TAB> and hasattr ( self . app . job_config , "" get_tool_resource_xml "" ) <TAB> ) : <TAB><TAB> resource_xml = self . app . job_config . get_tool_resource_xml ( <TAB><TAB><TAB> root . get ( "" id "" ) , self . tool_type <TAB><TAB> ) <TAB><TAB> if resource_xml is not None : <TAB><TAB><TAB> inputs = root . find ( "" inputs "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> inputs = parse_xml_string ( "" <inputs/> "" ) <TAB><TAB><TAB><TAB> root . append ( inputs ) <TAB><TAB><TAB> inputs . append ( resource_xml )",if inputs is None :,if inputs is None :,100.0,100.00,True
4296,"def test_arguments_regex ( self ) : <TAB> argument_matches = ( <TAB><TAB> ( "" pip=1.1 "" , ( "" pip "" , "" 1.1 "" ) ) , <TAB><TAB> ( "" pip==1.1 "" , None ) , <TAB><TAB> ( "" pip=1.2=1 "" , ( "" pip "" , "" 1.2=1 "" ) ) , <TAB> ) <TAB> for argument , match in argument_matches : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsNone ( salt . utils . args . KWARG_REGEX . match ( argument ) ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( <TAB><TAB><TAB><TAB> salt . utils . args . KWARG_REGEX . match ( argument ) . groups ( ) , match <TAB><TAB><TAB> )",if match is None :,if match is None :,100.0,100.00,True
4297,"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB><TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB><TAB> if self . service_id : <TAB><TAB><TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected",if self . environment_id :,if self . environment_id :,100.0,100.00,True
4298,"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB><TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB><TAB> pass <TAB> else : <TAB><TAB> if ip . venture is not None : <TAB><TAB><TAB> result [ "" venture_id "" ] = ip . venture . id <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB> if ip . device . venture is not None : <TAB><TAB><TAB><TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . device is not None :,if ip . device is not None :,100.0,100.00,True
4299,"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> if family : <TAB><TAB><TAB> for event_ref in family . get_event_ref_list ( ) : <TAB><TAB><TAB><TAB> if event_ref : <TAB><TAB><TAB><TAB><TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB><TAB><TAB><TAB><TAB> if not event . get_place_handle ( ) : <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False",if not event . get_date_object ( ) :,if not event . get_place_handle ( ) :,97.43390084958297,98.18,False
4300,"def killIfDead ( ) : <TAB> if not self . _isalive : <TAB><TAB> self . log . debug ( <TAB><TAB><TAB> "" WampLongPoll: killing inactive WAMP session with transport  ' {0} ' "" . format ( <TAB><TAB><TAB><TAB> self . _transport_id <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> self . onClose ( False , 5000 , "" session inactive "" ) <TAB><TAB> self . _receive . _kill ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _parent . _transports [ self . _transport_id ] <TAB> else : <TAB><TAB> self . log . debug ( <TAB><TAB><TAB> "" WampLongPoll: transport  ' {0} '  is still alive "" . format ( self . _transport_id ) <TAB><TAB> ) <TAB><TAB> self . _isalive = False <TAB><TAB> self . reactor . callLater ( killAfter , killIfDead )",if self . _transport_id in self . _parent . _transports :,if self . _parent :,95.55723955624362,95.39,False
4301,"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> l . warning ( <TAB><TAB><TAB><TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB><TAB><TAB><TAB> "" element size. "" , <TAB><TAB><TAB><TAB> self . name , <TAB><TAB><TAB> ) <TAB><TAB><TAB> continue <TAB><TAB> if not self . _pack : <TAB><TAB><TAB> align = ty . alignment <TAB><TAB><TAB> if offset_so_far % align != 0 : <TAB><TAB><TAB><TAB> offset_so_far + = align - offset_so_far % align <TAB><TAB> offsets [ name ] = offset_so_far <TAB><TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets","if isinstance ( ty , SimTypeBottom ) :","if name == ""offset"" :",94.07545361027618,97.25,False
4302,"def get_override_css ( self ) : <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB><TAB> filename = self . view . file_name ( ) <TAB><TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for filetype in filetypes : <TAB><TAB><TAB><TAB> if filename . endswith ( filetype ) : <TAB><TAB><TAB><TAB><TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB><TAB><TAB><TAB><TAB> if os . path . isfile ( css_filename ) : <TAB><TAB><TAB><TAB><TAB><TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" """,if filename and filetypes :,if filetypes :,70.76077775420896,98.49,False
4303,"def setFullCSSSource ( self , fullsrc , inline = False ) : <TAB> self . fullsrc = fullsrc <TAB> if type ( self . fullsrc ) == six . binary_type : <TAB><TAB> self . fullsrc = six . text_type ( self . fullsrc , "" utf-8 "" ) <TAB> if inline : <TAB><TAB> self . inline = inline <TAB> if self . fullsrc : <TAB><TAB> self . srcFullIdx = self . fullsrc . find ( self . src ) <TAB><TAB> if self . srcFullIdx < 0 : <TAB><TAB><TAB> del self . srcFullIdx <TAB><TAB> self . ctxsrcFullIdx = self . fullsrc . find ( self . ctxsrc ) <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . ctxsrcFullIdx",if self . ctxsrcFullIdx < 0 :,if self . ctxsrcFullIdx < 0 :,100.0,100.00,True
4304,"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB><TAB> width = self . statwidth ( ) <TAB><TAB> return ( <TAB><TAB><TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( ""   "" , "" - "" ) + theme [ "" default "" ] <TAB><TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB><TAB> width = self . colwidth ( ) <TAB><TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( ""   "" , "" - "" ) <TAB><TAB> if i + 1 != len ( self . vars ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret = ret + char [ "" space "" ] <TAB> return ret",if op . color :,"if self . vars [ i ] . name == ""frame"" :",81.52527848147551,94.86,False
4305,"def _get_requested_databases ( self ) : <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB><TAB> for requested_namespace in self . _requested_namespaces : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return [ ] <TAB><TAB><TAB> elif requested_namespace [ 0 ] not in IGNORE_DBS : <TAB><TAB><TAB><TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases","if requested_namespace [ 0 ] is ""*"" :",if not requested_namespace :,91.30586738878598,94.26,False
4306,"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB><TAB> channel = add_channel [ "" channel "" ] <TAB><TAB> defaults = { "" currency "" : channel . currency_code } <TAB><TAB> <MASK> <TAB><TAB><TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB><TAB> if "" min_amount_spent "" in add_channel . keys ( ) : <TAB><TAB><TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB><TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB><TAB><TAB> voucher = voucher , <TAB><TAB><TAB> channel = channel , <TAB><TAB><TAB> defaults = defaults , <TAB><TAB> )","if ""discount_value"" in add_channel . keys ( ) :","if ""discount_value"" in add_channel . keys ( ) :",100.0,100.00,True
4307,"def read_xml ( path ) : <TAB> with tf . gfile . GFile ( path ) as f : <TAB><TAB> root = etree . fromstring ( f . read ( ) ) <TAB> annotations = { } <TAB> for node in root . getchildren ( ) : <TAB><TAB> key , val = node2dict ( node ) <TAB><TAB> # If `key` is object, it's actually a list. <TAB><TAB> <MASK> <TAB><TAB><TAB> annotations . setdefault ( key , [ ] ) . append ( val ) <TAB><TAB> else : <TAB><TAB><TAB> annotations [ key ] = val <TAB> return annotations","if key == ""object"" :","if isinstance ( key , dict ) :",97.15311376594843,95.36,False
4308,"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB><TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB><TAB> pass <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ "" venture_id "" ] = ip . venture . id <TAB><TAB> if ip . device is not None : <TAB><TAB><TAB> result [ "" device_id "" ] = ip . device . id <TAB><TAB><TAB> if ip . device . venture is not None : <TAB><TAB><TAB><TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . venture is not None :,if ip . venture is not None :,100.0,100.00,True
4309,"def test_large_headers ( self ) : <TAB> with ExpectLog ( gen_log , "" Unsatisfiable read "" , required = False ) : <TAB><TAB> try : <TAB><TAB><TAB> self . fetch ( "" / "" , headers = { "" X-Filler "" : "" a "" * 1000 } , raise_error = True ) <TAB><TAB><TAB> self . fail ( "" did not raise expected exception "" ) <TAB><TAB> except HTTPError as e : <TAB><TAB><TAB> # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB><TAB><TAB> # 6585. However, many implementations just close the <TAB><TAB><TAB> # connection in this case, resulting in a missing response. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertIn ( e . response . code , ( 431 , 599 ) )",if e . response is not None :,"if e . response . code in ( 431 , 599 ) :",96.98585618437932,95.65,False
4310,"def validate_reserved_serial_no_consumption ( self ) : <TAB> for item in self . items : <TAB><TAB> if item . s_warehouse and not item . t_warehouse and item . serial_no : <TAB><TAB><TAB> for sr in get_serial_nos ( item . serial_no ) : <TAB><TAB><TAB><TAB> sales_order = frappe . db . get_value ( "" Serial No "" , sr , "" sales_order "" ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> msg = _ ( <TAB><TAB><TAB><TAB><TAB><TAB> "" (Serial No:  {0} ) cannot be consumed as it ' s reserverd to fullfill Sales Order  {1} . "" <TAB><TAB><TAB><TAB><TAB> ) . format ( sr , sales_order ) <TAB><TAB><TAB><TAB><TAB> frappe . throw ( _ ( "" Item  {0}   {1} "" ) . format ( item . item_code , msg ) )",if sales_order :,if sales_order :,100.0,100.00,True
4311,"def force_decode ( string , encoding ) : <TAB> if isinstance ( string , str ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> string = string . decode ( encoding ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> # try decoding with utf-8, should only work for real UTF-8 <TAB><TAB><TAB><TAB> string = string . decode ( "" utf-8 "" ) <TAB><TAB><TAB> except UnicodeError : <TAB><TAB><TAB><TAB> # last resort -- can't fail <TAB><TAB><TAB><TAB> string = string . decode ( "" latin1 "" ) <TAB> return string",if encoding :,if encoding :,100.0,100.00,True
4312,"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB><TAB> new_parameter = copy . deepcopy ( hp ) <TAB><TAB> # Allow for an empty top-level parameter <TAB><TAB> if new_parameter . name == "" "" : <TAB><TAB><TAB> new_parameter . name = prefix <TAB><TAB> <MASK> <TAB><TAB><TAB> new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB><TAB> new_parameters . append ( new_parameter ) <TAB> for hp in new_parameters : <TAB><TAB> _add_hp ( master_cs , hp )","elif not prefix == """" :",elif new_parameter . name . startswith ( delimiter ) :,96.65507076290226,94.56,False
4313,"def __call__ ( self , * args , * * kwargs ) : <TAB> if self . log_file is not None : <TAB><TAB> kwargs [ "" file "" ] = self . log_file <TAB><TAB> print ( * args , * * kwargs ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # get immediate feedback <TAB><TAB><TAB> self . log_file . flush ( ) <TAB> elif self . log_func is not None : <TAB><TAB> self . log_func ( * args , * * kwargs )","if hasattr ( self . log_file , ""flush"" ) :",if self . log_file . flush :,91.03244688532932,93.20,False
4314,"def df_index_expr ( self , length_expr = None , as_range = False ) : <TAB> """"""Generate expression to get or create index of DF"""""" <TAB> if isinstance ( self . index , types . NoneType ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> length_expr = df_length_expr ( self ) <TAB><TAB> if as_range : <TAB><TAB><TAB> return f "" range( { length_expr } ) "" <TAB><TAB> else : <TAB><TAB><TAB> return f "" numpy.arange( { length_expr } ) "" <TAB> return "" self._index """,if length_expr is None :,if not length_expr :,82.06467701220419,96.87,False
4315,"def _setWeight ( self , value ) : <TAB> if value is None : <TAB><TAB> self . _fontWeight = None <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TextFormatException ( f "" Not a supported fontWeight:  { value } "" ) <TAB><TAB> self . _fontWeight = value . lower ( )","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :","if not value . lower ( ) in ( ""bold"" , ""boldbold"" ) :",64.8588795927116,91.74,False
4316,"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB><TAB> self . _log . debug ( "" testing configuration "" ) <TAB><TAB> verboseflag = "" -Q "" <TAB><TAB> if self . _log . isEnabledFor ( logging . DEBUG ) : <TAB><TAB><TAB> verboseflag = "" -v "" <TAB><TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB><TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB><TAB> os . remove ( config_path )",if p . wait ( ) != 0 :,if not p . returncode :,66.8937882313805,95.41,False
4317,"def filter_queryset ( self , request , queryset , view ) : <TAB> kwargs = { } <TAB> for field in view . filterset_fields : <TAB><TAB> value = request . GET . get ( field ) <TAB><TAB> if not value : <TAB><TAB><TAB> continue <TAB><TAB> if field == "" node_id "" : <TAB><TAB><TAB> value = get_object_or_none ( Node , pk = value ) <TAB><TAB><TAB> kwargs [ "" node "" ] = value <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> field = "" asset "" <TAB><TAB> kwargs [ field ] = value <TAB> if kwargs : <TAB><TAB> queryset = queryset . filter ( * * kwargs ) <TAB> logger . debug ( "" Filter  {} "" . format ( kwargs ) ) <TAB> return queryset","elif field == ""asset_id"" :","if field == ""asset_id"" :",78.46254956296175,98.87,False
4318,"def _find_closing_brace ( string , start_pos ) : <TAB> """"""Finds the corresponding closing brace after start_pos."""""" <TAB> bracks_open = 1 <TAB> for idx , char in enumerate ( string [ start_pos : ] ) : <TAB><TAB> if char == "" ( "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> bracks_open + = 1 <TAB><TAB> elif char == "" ) "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> bracks_open - = 1 <TAB><TAB><TAB> if not bracks_open : <TAB><TAB><TAB><TAB> return start_pos + idx + 1","if string [ idx + start_pos - 1 ] != ""\\"" :",if _is_brace ( string [ start_pos : idx + 1 ] ) :,86.03979740262828,86.92,False
4319,"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB><TAB> i = host . rfind ( "" : "" ) <TAB><TAB> j = host . rfind ( "" ] "" ) # ipv6 addresses have [...] <TAB><TAB> if i > j : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> port = int ( host [ i + 1 : ] ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB><TAB><TAB> host = host [ : i ] <TAB><TAB> else : <TAB><TAB><TAB> port = self . default_port <TAB><TAB> <MASK> <TAB><TAB><TAB> host = host [ 1 : - 1 ] <TAB> self . host = host <TAB> self . port = port","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :","if host [ - 1 ] == "":"" :",95.59812787726494,93.94,False
4320,"def __getstate__ ( self ) : <TAB> state = { } <TAB> for cls in type ( self ) . mro ( ) : <TAB><TAB> cls_slots = getattr ( cls , "" __slots__ "" , ( ) ) <TAB><TAB> for slot in cls_slots : <TAB><TAB><TAB> if slot != "" __weakref__ "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> state [ slot ] = getattr ( self , slot ) <TAB> state [ "" _cookiejar_cookies "" ] = list ( self . cookiejar ) <TAB> del state [ "" cookiejar "" ] <TAB> return state","if hasattr ( self , slot ) :","if hasattr ( self , slot ) :",100.0,100.00,True
4321,"def _evp_pkey_from_der_traditional_key ( self , bio_data , password ) : <TAB> key = self . _lib . d2i_PrivateKey_bio ( bio_data . bio , self . _ffi . NULL ) <TAB> if key != self . _ffi . NULL : <TAB><TAB> key = self . _ffi . gc ( key , self . _lib . EVP_PKEY_free ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( "" Password was given but private key is not encrypted. "" ) <TAB><TAB> return key <TAB> else : <TAB><TAB> self . _consume_errors ( ) <TAB><TAB> return None",if password is not None :,if not key :,65.5230167170177,96.80,False
4322,"def is_special ( s , i , directive ) : <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive [ 0 ] == "" @ "" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB> while i < len ( s ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return True , i <TAB><TAB> else : <TAB><TAB><TAB> i = skip_line ( s , i ) <TAB><TAB><TAB> if skip_flag : <TAB><TAB><TAB><TAB> i = skip_ws ( s , i ) <TAB> return False , - 1","if match_word ( s , i , directive ) :",if s [ i ] == directive [ 0 ] :,96.21011381795763,95.29,False
4323,"def _decorator ( coro_func ) : <TAB> fut = asyncio . ensure_future ( coro_func ( ) ) <TAB> self . _tests . append ( ( coro_func . __name__ , fut ) ) <TAB> if timeout_sec is not None : <TAB><TAB> timeout_at = self . _loop . time ( ) + timeout_sec <TAB><TAB> handle = self . MASTER_LOOP . call_at ( <TAB><TAB><TAB> timeout_at , self . _set_exception_if_not_done , fut , asyncio . TimeoutError ( ) <TAB><TAB> ) <TAB><TAB> fut . add_done_callback ( lambda * args : handle . cancel ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _global_timeout_at = timeout_at <TAB> return coro_func",if timeout_at > self . _global_timeout_at :,if timeout_at is not None :,82.57810903288397,95.01,False
4324,"def _load ( self , db , owner ) : <TAB> self . __init ( owner ) <TAB> db_result = db ( <TAB><TAB> "" SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ? "" , <TAB><TAB> self . owner . worldid , <TAB> ) <TAB> for ( <TAB><TAB> ship_id , <TAB><TAB> state_id , <TAB> ) in db_result : <TAB><TAB> ship = WorldObject . get_object_by_id ( ship_id ) <TAB><TAB> state = self . shipStates [ state_id ] <TAB><TAB> # add move callbacks corresponding to given state <TAB><TAB> <MASK> <TAB><TAB><TAB> ship . add_move_callback ( Callback ( BehaviorMoveCallback . _arrived , ship ) ) <TAB><TAB> self . add_new_unit ( ship , state )",if state == self . shipStates . moving :,"if state . get ( ""move_callback"" ) :",96.91012557448317,95.41,False
4325,"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB><TAB> elif self . dots : <TAB><TAB><TAB> self . stream . write ( "" s "" ) <TAB><TAB><TAB> self . stream . flush ( ) <TAB><TAB> return <TAB> _org_AddError ( self , test , err )",if self . showAll :,if self . verbose :,73.323570010837,97.91,False
4326,"def _construct ( self , node ) : <TAB> self . flatten_mapping ( node ) <TAB> ret = self . construct_pairs ( node ) <TAB> keys = [ d [ 0 ] for d in ret ] <TAB> keys_sorted = sorted ( keys , key = _natsort_key ) <TAB> for key in keys : <TAB><TAB> expected = keys_sorted . pop ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ConstructorError ( <TAB><TAB><TAB><TAB> None , <TAB><TAB><TAB><TAB> None , <TAB><TAB><TAB><TAB> "" keys out of order:  "" <TAB><TAB><TAB><TAB> "" expected  {}  got  {}  at  {} "" . format ( expected , key , node . start_mark ) , <TAB><TAB><TAB> ) <TAB> return dict ( ret )",if key != expected :,if expected != key :,73.32815898722214,98.00,False
4327,"def sample_pos_items_for_u ( u , num ) : <TAB> # sample num pos items for u-th user <TAB> pos_items = self . train_items [ u ] <TAB> n_pos_items = len ( pos_items ) <TAB> pos_batch = [ ] <TAB> while True : <TAB><TAB> if len ( pos_batch ) == num : <TAB><TAB><TAB> break <TAB><TAB> pos_id = np . random . randint ( low = 0 , high = n_pos_items , size = 1 ) [ 0 ] <TAB><TAB> pos_i_id = pos_items [ pos_id ] <TAB><TAB> <MASK> <TAB><TAB><TAB> pos_batch . append ( pos_i_id ) <TAB> return pos_batch",if pos_i_id not in pos_batch :,if pos_i_id not in self . _pos_ids :,73.27090802832487,96.64,False
4328,"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Expected id of type  %s  but found type  %s   %s "" , type , fields [ - 2 ] , id <TAB><TAB><TAB> ) <TAB><TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB><TAB> itype = fields [ - 2 ] <TAB><TAB> if type != itype : <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Expected id of type  %s  but found type  %s   %s "" , type , itype , id <TAB><TAB><TAB> ) <TAB><TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id",if type != fields [ - 2 ] :,if type != fields [ - 2 ] :,100.0,100.00,True
4329,"def uninstall_environments ( self , environments ) : <TAB> environments = [ <TAB><TAB> env <TAB><TAB> if not env . startswith ( self . conda_context . envs_path ) <TAB><TAB> else os . path . basename ( env ) <TAB><TAB> for env in environments <TAB> ] <TAB> return_codes = [ self . conda_context . exec_remove ( [ env ] ) for env in environments ] <TAB> final_return_code = 0 <TAB> for env , return_code in zip ( environments , return_codes ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . debug ( "" Conda environment  ' %s '  successfully removed. "" % env ) <TAB><TAB> else : <TAB><TAB><TAB> log . debug ( "" Conda environment  ' %s '  could not be removed. "" % env ) <TAB><TAB><TAB> final_return_code = return_code <TAB> return final_return_code",if return_code == 0 :,if return_code == 0 :,100.0,100.00,True
4330,"def _add_hit_offset ( self , context_list , string_name , original_offset , value ) : <TAB> for context in context_list : <TAB><TAB> hits_by_context_dict = self . hits_by_context . setdefault ( context , { } ) <TAB><TAB> <MASK> <TAB><TAB><TAB> hits_by_context_dict [ string_name ] = ( <TAB><TAB><TAB><TAB> original_offset , <TAB><TAB><TAB><TAB> value . encode ( "" base64 "" ) , <TAB><TAB><TAB> )",if string_name not in hits_by_context_dict :,if string_name not in hits_by_context_dict :,100.0,100.00,True
4331,"def detab ( self , text , length = None ) : <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> if length is None : <TAB><TAB> length = self . tab_length <TAB> newtext = [ ] <TAB> lines = text . split ( "" \n "" ) <TAB> for line in lines : <TAB><TAB> if line . startswith ( ""   "" * length ) : <TAB><TAB><TAB> newtext . append ( line [ length : ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> newtext . append ( "" "" ) <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return "" \n "" . join ( newtext ) , "" \n "" . join ( lines [ len ( newtext ) : ] )",elif not line . strip ( ) :,"elif line . startswith ( ""\n"" * length ) :",95.44555889304908,94.80,False
4332,"def dump ( self ) : <TAB> print ( self . package_name ) <TAB> for package , value in self . entries : <TAB><TAB> print ( str ( package . version ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( ""     [FILTERED] "" ) <TAB><TAB> elif isinstance ( value , list ) : <TAB><TAB><TAB> variants = value <TAB><TAB><TAB> for variant in variants : <TAB><TAB><TAB><TAB> print ( ""      %s "" % str ( variant ) ) <TAB><TAB> else : <TAB><TAB><TAB> print ( ""      %s "" % str ( package ) )",if value is None :,if value is None :,100.0,100.00,True
4333,"def __lexical_scope ( * args , * * kwargs ) : <TAB> try : <TAB><TAB> scope = Scope ( quasi ) <TAB><TAB> <MASK> <TAB><TAB><TAB> binding_name_set_stack [ - 1 ] . add_child ( scope ) <TAB><TAB> binding_name_set_stack . append ( scope ) <TAB><TAB> return func ( * args , * * kwargs ) <TAB> finally : <TAB><TAB> if binding_name_set_stack [ - 1 ] is scope : <TAB><TAB><TAB> binding_name_set_stack . pop ( )",if quasi :,if not scope . is_scope ( ) :,67.36856209290829,93.80,False
4334,"def getnotes ( self , origin = None ) : <TAB> if origin is None : <TAB><TAB> result = self . translator_comments <TAB><TAB> <MASK> <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> result + = "" \n "" + self . developer_comments <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> result = self . developer_comments <TAB><TAB> return result <TAB> elif origin == "" translator "" : <TAB><TAB> return self . translator_comments <TAB> elif origin in ( "" programmer "" , "" developer "" , "" source code "" ) : <TAB><TAB> return self . developer_comments <TAB> else : <TAB><TAB> raise ValueError ( "" Comment type not valid "" )",if self . developer_comments :,if self . developer_comments :,100.0,100.00,True
4335,"def fix_datetime_fields ( data : TableData , table : TableName ) - > None : <TAB> for item in data [ table ] : <TAB><TAB> for field_name in DATE_FIELDS [ table ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item [ field_name ] = datetime . datetime . fromtimestamp ( <TAB><TAB><TAB><TAB><TAB> item [ field_name ] , tz = datetime . timezone . utc <TAB><TAB><TAB><TAB> )",if item [ field_name ] is not None :,if field_name in item :,91.55317562953003,93.40,False
4336,"def _check_for_cart_error ( cart ) : <TAB> if cart . _safe_get_element ( "" Cart.Request.Errors "" ) is not None : <TAB><TAB> error = cart . _safe_get_element ( "" Cart.Request.Errors.Error.Code "" ) . text <TAB><TAB> <MASK> <TAB><TAB><TAB> raise CartInfoMismatchException ( <TAB><TAB><TAB><TAB> "" CartGet failed: AWS.ECommerceService.CartInfoMismatch  "" <TAB><TAB><TAB><TAB> "" make sure AssociateTag, CartId and HMAC are correct  "" <TAB><TAB><TAB><TAB> "" (dont use URLEncodedHMAC!!!) "" <TAB><TAB><TAB> ) <TAB><TAB> raise CartException ( "" CartGet failed:  "" + error )","if error == ""AWS.ECommerceService.CartInfoMismatch"" :","if error != ""InvalidRequestError"" :",97.77345430468279,95.41,False
4337,"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB><TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB> ) <TAB><TAB> if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB><TAB><TAB> )",if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,if geometry [ 0 ] < - 90 or geometry [ 0 ] < - 90 :,95.99590539431138,96.27,False
4338,"def _mapper_output_protocol ( self , step_num , step_map ) : <TAB> map_key = self . _step_key ( step_num , "" mapper "" ) <TAB> if map_key in step_map : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . output_protocol ( ) <TAB><TAB> else : <TAB><TAB><TAB> return self . internal_protocol ( ) <TAB> else : <TAB><TAB> # mapper is not a script substep, so protocols don't apply at all <TAB><TAB> return RawValueProtocol ( )",if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,"if self . _step_key ( step_num , ""output"" ) :",87.0929528859214,88.75,False
4339,"def asset ( * paths ) : <TAB> for path in paths : <TAB><TAB> fspath = www_root + "" /assets/ "" + path <TAB><TAB> etag = "" "" <TAB><TAB> try : <TAB><TAB><TAB> if env . cache_static : <TAB><TAB><TAB><TAB> etag = asset_etag ( fspath ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> os . stat ( fspath ) <TAB><TAB> except FileNotFoundError as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB><TAB><TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> continue <TAB><TAB> except Exception as e : <TAB><TAB><TAB> tell_sentry ( e , { } ) <TAB><TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )",if path == paths [ - 1 ] :,if env . ignore_file :,94.92407648190596,96.54,False
4340,"def ping ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB><TAB> <MASK> <TAB><TAB><TAB> payload = payload . decode ( "" utf-8 "" ) <TAB><TAB> self . logger . debug ( <TAB><TAB><TAB> "" Sending a ping data frame  "" <TAB><TAB><TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB><TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PING ) <TAB> with self . sock_send_lock : <TAB><TAB> self . sock . send ( data )","if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",100.0,100.00,True
4341,"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB><TAB> try : <TAB><TAB><TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> if f . read ( ) . strip ( ) != "" Mains "" : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB> except IOError : <TAB><TAB><TAB> continue <TAB> return False","if f . read ( 1 ) == ""1"" :","if f . read ( ) . strip ( ) == ""Connected"" :",69.57758153190512,96.31,False
4342,"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . validate_base_model ( model ) <TAB><TAB> if hasattr ( model , "" _feincms_content_models "" ) : <TAB><TAB><TAB> self . validate_content_type ( model )","if hasattr ( model , ""_create_content_base"" ) :","if hasattr ( model , ""_feincms_base_models"" ) :",98.46794334110184,96.22,False
4343,"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB><TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB> <MASK> <TAB><TAB><TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB><TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB> if module . padding_idx is not None : <TAB><TAB><TAB> module . weight . data [ module . padding_idx ] . zero_ ( )",if module . bias is not None :,if module . bias is not None :,75.0,100.00,True
4344,"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB><TAB> # multipart/* are just containers <TAB><TAB> if part . get_content_maintype ( ) == "" multipart "" : <TAB><TAB><TAB> continue <TAB><TAB> ctype = part . get_content_type ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ctype = OCTET_TYPE <TAB><TAB> filename = part . get_filename ( ) <TAB><TAB> if not filename : <TAB><TAB><TAB> filename = PART_FN_TPL % ( partnum ) <TAB><TAB> headers = dict ( part ) <TAB><TAB> LOG . debug ( headers ) <TAB><TAB> headers [ "" Content-Type "" ] = ctype <TAB><TAB> payload = util . fully_decoded_payload ( part ) <TAB><TAB> callback ( data , filename , payload , headers ) <TAB><TAB> partnum = partnum + 1",if ctype is None :,if not ctype :,98.09642956653603,98.24,False
4345,"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB><TAB> if dirs [ m , n ] == "" | "" : <TAB><TAB><TAB> m - = 1 <TAB><TAB><TAB> n - = 1 <TAB><TAB><TAB> mask [ m ] = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> m - = 1 <TAB><TAB> elif dirs [ m , n ] == "" < "" : <TAB><TAB><TAB> n - = 1 <TAB><TAB> else : <TAB><TAB><TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask","elif dirs [ m , n ] == ""^"" :","elif dirs [ m , n ] == "">"" :",98.74983180420261,98.62,False
4346,"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB><TAB> # strip line, skip over empty lines <TAB><TAB> line = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # skip over comments or empty lines <TAB><TAB> match = COMMENT . match ( line ) <TAB><TAB> if match : <TAB><TAB><TAB> continue <TAB><TAB> # skip over localparts with delimiters <TAB><TAB> if strip_delimiters : <TAB><TAB><TAB> if "" , "" in line or "" ; "" in line : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield line","if line == """" :",if not line :,97.83584276382261,96.78,False
4347,"def fetch ( self , * tileables , * * kw ) : <TAB> ret_list = False <TAB> if len ( tileables ) == 1 and isinstance ( tileables [ 0 ] , ( tuple , list ) ) : <TAB><TAB> ret_list = True <TAB><TAB> tileables = tileables [ 0 ] <TAB> elif len ( tileables ) > 1 : <TAB><TAB> ret_list = True <TAB> result = self . _sess . fetch ( * tileables , * * kw ) <TAB> ret = [ ] <TAB> for r , t in zip ( result , tileables ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( r . item ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> ret . append ( r ) <TAB> if ret_list : <TAB><TAB> return ret <TAB> return ret [ 0 ]","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :","if isinstance ( t , ( Tuple , list ) ) :",62.24579629736526,88.17,False
4348,"def _convert ( container ) : <TAB> if _value_marker in container : <TAB><TAB> force_list = False <TAB><TAB> values = container . pop ( _value_marker ) <TAB><TAB> if container . pop ( _list_marker , False ) : <TAB><TAB><TAB> force_list = True <TAB><TAB><TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> values = values [ 0 ] <TAB><TAB> if not container : <TAB><TAB><TAB> return values <TAB><TAB> return _convert ( container ) <TAB> elif container . pop ( _list_marker , False ) : <TAB><TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) )",if not force_list and len ( values ) == 1 :,if force_list :,68.58036568544668,95.14,False
4349,"def _transform_init_kwargs ( cls , kwargs ) : <TAB> transformed = [ ] <TAB> for field in list ( kwargs . keys ( ) ) : <TAB><TAB> prop = getattr ( cls , field , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> value = kwargs . pop ( field ) <TAB><TAB><TAB> _transform_single_init_kwarg ( prop , field , value , kwargs ) <TAB><TAB><TAB> transformed . append ( ( field , value ) ) <TAB> return transformed","if isinstance ( prop , MoneyProperty ) :",if prop is not None :,76.4091981471561,94.43,False
4350,"def haslayer ( self , cls ) : <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB><TAB> return 1 <TAB> for f in self . packetfields : <TAB><TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB><TAB> if fvalue_gen is None : <TAB><TAB><TAB> continue <TAB><TAB> if not f . islist : <TAB><TAB><TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB><TAB> for fvalue in fvalue_gen : <TAB><TAB><TAB> if isinstance ( fvalue , Packet ) : <TAB><TAB><TAB><TAB> ret = fvalue . haslayer ( cls ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return ret <TAB> return self . payload . haslayer ( cls )",if ret :,if ret is not None :,92.15981250964983,98.28,False
4351,def insert_broken_add_sometimes ( node ) : <TAB> if node . op == theano . tensor . add : <TAB><TAB> last_time_replaced [ 0 ] = not last_time_replaced [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ off_by_half ( * node . inputs ) ] <TAB> return False,if last_time_replaced [ 0 ] :,if last_time_replaced [ 0 ] :,100.0,100.00,True
4352,"def testReadChunk10 ( self ) : <TAB> # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB> self . createTempFile ( ) <TAB> with BZ2File ( self . filename ) as bz2f : <TAB><TAB> text = "" "" <TAB><TAB> while 1 : <TAB><TAB><TAB> str = bz2f . read ( 10 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> text + = str <TAB><TAB> self . assertEqual ( text , self . TEXT )",if not str :,if not str :,75.0,100.00,True
4353,"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [ ] <TAB> for i , face in enumerate ( dcel_mesh . faces ) : <TAB><TAB> if face . inners and face . outer : <TAB><TAB><TAB> "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB><TAB><TAB><TAB> i <TAB><TAB><TAB> ) <TAB><TAB> if not face . outer or del_flag in face . flags : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB> return sv_faces",if only_select and not face . select :,if only_select and face . inners and face . inners . loop_hedges,97.09992883956659,95.19,False
4354,"def __check_dict_contains ( dct , dict_name , keys , comment = "" "" , result = True ) : <TAB> for key in keys : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = False <TAB><TAB><TAB> comment = __append_comment ( <TAB><TAB><TAB><TAB> "" Missing  {0}  in  {1} "" . format ( key , dict_name ) , comment <TAB><TAB><TAB> ) <TAB> return result , comment",if key not in six . iterkeys ( dct ) :,if not key in dct :,84.42519377450503,92.59,False
4355,"def _dump_arg_defaults ( kwargs ) : <TAB> """"""Inject default arguments for dump functions."""""" <TAB> if current_app : <TAB><TAB> kwargs . setdefault ( "" cls "" , current_app . json_encoder ) <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs . setdefault ( "" ensure_ascii "" , False ) <TAB><TAB> kwargs . setdefault ( "" sort_keys "" , current_app . config [ "" JSON_SORT_KEYS "" ] ) <TAB> else : <TAB><TAB> kwargs . setdefault ( "" sort_keys "" , True ) <TAB><TAB> kwargs . setdefault ( "" cls "" , JSONEncoder )","if not current_app . config [ ""JSON_AS_ASCII"" ] :","if current_app . config [ ""JSON_AS_ASCII"" ] :",69.2042697546296,98.52,False
4356,"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB><TAB> if isinstance ( value , bool ) : <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB> if value != 1 : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> elif value is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> break <TAB> self . _reset_button . disabled = not changed",elif len ( value ) != 0 :,if value == 0 :,90.36688116552504,96.71,False
4357,"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> tab = p . split ( "" = "" , 1 ) <TAB><TAB><TAB> if tab [ 0 ] == "" socks "" : <TAB><TAB><TAB><TAB> tab [ 0 ] = "" SOCKS4 "" <TAB><TAB><TAB> proxies . append ( <TAB><TAB><TAB><TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB><TAB><TAB> ) # type, addr:port, username, password <TAB><TAB> else : <TAB><TAB><TAB> proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB> return proxies","if ""="" in p :","if ""="" in p :",100.0,100.00,True
4358,"def predict ( collect_dir , keys ) : <TAB> run_all = len ( keys ) == 0 <TAB> validate_keys ( keys ) <TAB> for exp_cfg in cfg : <TAB><TAB> <MASK> <TAB><TAB><TAB> key = exp_cfg [ "" key "" ] <TAB><TAB><TAB> _predict ( key , exp_cfg [ "" sample_img "" ] , collect_dir )","if run_all or exp_cfg [ ""key"" ] in keys :",if run_all :,84.48590464740388,88.42,False
4359,"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB><TAB> key = str ( k ) <TAB><TAB> <MASK> <TAB><TAB><TAB> key + = "" /tcp "" <TAB><TAB> if isinstance ( v , list ) : <TAB><TAB><TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB><TAB> else : <TAB><TAB><TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result","if ""/"" not in key :","if k . startswith ( ""tcp"" ) :",68.7645625482982,94.34,False
4360,"def assert_conll_writer_output ( <TAB> dataset : InternalBioNerDataset , <TAB> expected_output : List [ str ] , <TAB> sentence_splitter : SentenceSplitter = None , ) : <TAB> outfile_path = tempfile . mkstemp ( ) [ 1 ] <TAB> try : <TAB><TAB> sentence_splitter = ( <TAB><TAB><TAB> sentence_splitter <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> else NoSentenceSplitter ( tokenizer = SpaceTokenizer ( ) ) <TAB><TAB> ) <TAB><TAB> writer = CoNLLWriter ( sentence_splitter = sentence_splitter ) <TAB><TAB> writer . write_to_conll ( dataset , Path ( outfile_path ) ) <TAB><TAB> contents = [ l . strip ( ) for l in open ( outfile_path ) . readlines ( ) if l . strip ( ) ] <TAB> finally : <TAB><TAB> os . remove ( outfile_path ) <TAB> assert contents == expected_output",if sentence_splitter,if sentence_splitter,100.0,100.00,True
4361,"def post ( self , request , * args , * * kwargs ) : <TAB> self . comment_obj = get_object_or_404 ( Comment , id = request . POST . get ( "" commentid "" ) ) <TAB> if request . user == self . comment_obj . commented_by : <TAB><TAB> form = LeadCommentForm ( request . POST , instance = self . comment_obj ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . form_valid ( form ) <TAB><TAB> return self . form_invalid ( form ) <TAB> data = { "" error "" : "" You don ' t have permission to edit this comment. "" } <TAB> return JsonResponse ( data )",if form . is_valid ( ) :,if form . is_valid ( ) :,100.0,100.00,True
4362,"def trivia_list ( self , ctx : commands . Context ) : <TAB> """"""List available trivia categories."""""" <TAB> lists = set ( p . stem for p in self . _all_lists ( ) ) <TAB> if await ctx . embed_requested ( ) : <TAB><TAB> await ctx . send ( <TAB><TAB><TAB> embed = discord . Embed ( <TAB><TAB><TAB><TAB> title = _ ( "" Available trivia lists "" ) , <TAB><TAB><TAB><TAB> colour = await ctx . embed_colour ( ) , <TAB><TAB><TAB><TAB> description = "" ,  "" . join ( sorted ( lists ) ) , <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> else : <TAB><TAB> msg = box ( bold ( _ ( "" Available trivia lists "" ) ) + "" \n \n "" + "" ,  "" . join ( sorted ( lists ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> await ctx . author . send ( msg ) <TAB><TAB> else : <TAB><TAB><TAB> await ctx . send ( msg )",if len ( msg ) > 1000 :,if ctx . author :,82.600118965729,97.30,False
4363,"def validate ( self ) : <TAB> result = validators . SUCCESS <TAB> msgs = [ ] <TAB> for validator in self . _validators : <TAB><TAB> res , err = validator . validate ( ) <TAB><TAB> if res == validators . ERROR : <TAB><TAB><TAB> result = res <TAB><TAB> elif res == validators . WARNING and result != validators . ERROR : <TAB><TAB><TAB> result = res <TAB><TAB> <MASK> <TAB><TAB><TAB> msgs . append ( err ) <TAB> return result , "" \n "" . join ( msgs )",if len ( err ) > 0 :,if err :,66.30976282995252,95.08,False
4364,"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB><TAB> mod_type = self . etc [ 2 ] <TAB><TAB> if mod_type == imp . PY_SOURCE : <TAB><TAB><TAB> source = self . get_source ( fullname ) <TAB><TAB><TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _reopen ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . code = read_code ( self . file ) <TAB><TAB><TAB> finally : <TAB><TAB><TAB><TAB> self . file . close ( ) <TAB><TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB><TAB><TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",elif mod_type == imp . PY_COMPILED :,elif mod_type == imp . PY_REWRITE :,99.07638315339523,99.04,False
4365,"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> if self . compress : <TAB><TAB> f . compress = zlib . compressobj ( <TAB><TAB><TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB><TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB><TAB> if self . compress : <TAB><TAB><TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f . fileobj . close ( ) <TAB><TAB><TAB><TAB> f . fileobj = None <TAB><TAB> else : <TAB><TAB><TAB> f . close ( ) <TAB><TAB><TAB> self . files . pop ( key )",if open_files > self . MAX_OPEN_FILES :,if open_files == 0 :,92.37743766740923,96.02,False
4366,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
4367,"def init_author_file ( self ) : <TAB> self . author_map = { } <TAB> if self . ui . config ( "" git "" , "" authors "" ) : <TAB><TAB> f = open ( self . repo . wjoin ( self . ui . config ( "" git "" , "" authors "" ) ) ) <TAB><TAB> try : <TAB><TAB><TAB> for line in f : <TAB><TAB><TAB><TAB> line = line . strip ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> from_ , to = RE_AUTHOR_FILE . split ( line , 2 ) <TAB><TAB><TAB><TAB> self . author_map [ from_ ] = to <TAB><TAB> finally : <TAB><TAB><TAB> f . close ( )","if not line or line . startswith ( ""#"" ) :",if not line :,75.2888471935006,95.31,False
4368,"def decode_imsi ( self , imsi ) : <TAB> new_imsi = "" "" <TAB> for a in imsi : <TAB><TAB> c = hex ( a ) <TAB><TAB> <MASK> <TAB><TAB><TAB> new_imsi + = str ( c [ 3 ] ) + str ( c [ 2 ] ) <TAB><TAB> else : <TAB><TAB><TAB> new_imsi + = str ( c [ 2 ] ) + "" 0 "" <TAB> mcc = new_imsi [ 1 : 4 ] <TAB> mnc = new_imsi [ 4 : 6 ] <TAB> return new_imsi , mcc , mnc",if len ( c ) == 4 :,if c [ 3 ] :,70.75013184429973,94.54,False
4369,"def _get_infoset ( self , prefname ) : <TAB> """"""Return methods with the name starting with prefname."""""" <TAB> infoset = [ ] <TAB> excludes = ( "" %s infoset "" % prefname , ) <TAB> preflen = len ( prefname ) <TAB> for name in dir ( self . __class__ ) : <TAB><TAB> if name . startswith ( prefname ) and name not in excludes : <TAB><TAB><TAB> member = getattr ( self . __class__ , name ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> infoset . append ( name [ preflen : ] . replace ( "" _ "" , ""   "" ) ) <TAB> return infoset","if isinstance ( member , MethodType ) :","if isinstance ( member , types . MethodType ) :",69.00365192842344,97.98,False
4370,"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB><TAB> tok = self . tokenizer . get_next_token ( ) <TAB><TAB> ttype = tok [ "" style "" ] <TAB><TAB> if ttype == SCE_PL_UNUSED : <TAB><TAB><TAB> return <TAB><TAB> elif self . classifier . is_index_op ( tok ) : <TAB><TAB><TAB> tval = tok [ "" text "" ] <TAB><TAB><TAB> if self . opHash . has_key ( tval ) : <TAB><TAB><TAB><TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB><TAB><TAB><TAB><TAB> nestedCount + = 1 <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> nestedCount - = 1 <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> break",if nestedCount <= 0 :,if nestedCount == 0 :,98.82204644975407,99.03,False
4371,"def findMarkForUnitTestNodes ( self ) : <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB><TAB> <MASK> <TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB> else : <TAB><TAB><TAB> seen . append ( p . v ) <TAB><TAB><TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB><TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB><TAB> elif p . h . startswith ( "" @mark-for-unit-tests "" ) : <TAB><TAB><TAB><TAB> result . append ( p . copy ( ) ) <TAB><TAB><TAB><TAB> p . moveToNodeAfterTree ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> p . moveToThreadNext ( ) <TAB> return result",if p . v in seen :,if p . v in seen :,100.0,100.00,True
4372,"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB><TAB> earlier_part = earlier [ "" part "" ] <TAB><TAB> earlier_step = earlier [ "" step "" ] <TAB><TAB> found = False <TAB><TAB> for current in current_parts : <TAB><TAB><TAB> if earlier_part == current [ "" part "" ] and earlier_step == current [ "" step "" ] : <TAB><TAB><TAB><TAB> found = True <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB><TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint )",if not found :,if found :,95.29924205052016,99.00,False
4373,"def unmark_first_parents ( event = None ) : <TAB> """"""Mark the node and all its parents."""""" <TAB> c = event . get ( "" c "" ) <TAB> if not c : <TAB><TAB> return <TAB> changed = [ ] <TAB> for parent in c . p . self_and_parents ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> parent . v . clearMarked ( ) <TAB><TAB><TAB> parent . setAllAncestorAtFileNodesDirty ( ) <TAB><TAB><TAB> changed . append ( parent . copy ( ) ) <TAB> if changed : <TAB><TAB> # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB><TAB> c . setChanged ( ) <TAB><TAB> c . redraw ( ) <TAB> return changed",if parent . isMarked ( ) :,if parent . v :,96.48218491907112,97.83,False
4374,"def stop ( self ) : <TAB> self . _log ( "" Monitor stop "" ) <TAB> self . _stop_requested = True <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> fd = os . open ( self . fifo_path , os . O_WRONLY ) <TAB><TAB><TAB> os . write ( fd , b "" X "" ) <TAB><TAB><TAB> os . close ( fd ) <TAB> except Exception as e : <TAB><TAB> self . _log ( "" err while closing:  {0} "" . format ( str ( e ) ) ) <TAB> if self . _thread : <TAB><TAB> self . _thread . join ( ) <TAB><TAB> self . _thread = None",if os . path . exists ( self . fifo_path ) :,if self . fifo_path :,83.89456289073917,94.61,False
4375,"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB><TAB> f = True <TAB><TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f = False <TAB><TAB> if f : <TAB><TAB><TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB><TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB><TAB> cols2delete = [ x - 1 for x in cols2delete ]","if self . FindItemAtPosition ( ( r , c ) ) is not None :",if self . GetCols ( ) [ r ] == c :,81.33445462932094,93.23,False
4376,"def _load_objects ( self , obj_id_zset , limit , chunk_size = 1000 ) : <TAB> ct = i = 0 <TAB> while True : <TAB><TAB> id_chunk = obj_id_zset [ i : i + chunk_size ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> i + = chunk_size <TAB><TAB> for raw_data in self . _data [ id_chunk ] : <TAB><TAB><TAB> if not raw_data : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if self . _use_json : <TAB><TAB><TAB><TAB> yield json . loads ( decode ( raw_data ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield raw_data <TAB><TAB><TAB> ct + = 1 <TAB><TAB><TAB> if limit and ct == limit : <TAB><TAB><TAB><TAB> return",if not id_chunk :,if id_chunk not in self . _data :,70.7943048671557,96.61,False
4377,"def _convert_example ( example , use_bfloat16 ) : <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list ( example . keys ( ) ) : <TAB><TAB> val = example [ key ] <TAB><TAB> if tf . keras . backend . is_sparse ( val ) : <TAB><TAB><TAB> val = tf . sparse . to_dense ( val ) <TAB><TAB> <MASK> <TAB><TAB><TAB> val = tf . cast ( val , tf . int32 ) <TAB><TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB><TAB><TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB><TAB> example [ key ] = val",if val . dtype == tf . int64 :,if use_int32 and val . dtype == tf . int64 :,74.85675359666799,97.18,False
4378,"def print_callees ( self , * amount ) : <TAB> width , list = self . get_print_list ( amount ) <TAB> if list : <TAB><TAB> self . calc_callees ( ) <TAB><TAB> self . print_call_heading ( width , "" called... "" ) <TAB><TAB> for func in list : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . print_call_line ( width , func , self . all_callees [ func ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . print_call_line ( width , func , { } ) <TAB><TAB> print >> self . stream <TAB><TAB> print >> self . stream <TAB> return self",if func in self . all_callees :,if func in self . all_callees :,100.0,100.00,True
4379,"def on_task_input ( self , task , config ) : <TAB> if config is False : <TAB><TAB> return <TAB> for entry in task . entries : <TAB><TAB> <MASK> <TAB><TAB><TAB> log_once ( <TAB><TAB><TAB><TAB> "" Corrected ` %s ` url (replaced &amp; with &) "" % entry [ "" title "" ] , <TAB><TAB><TAB><TAB> logger = log , <TAB><TAB><TAB> ) <TAB><TAB><TAB> entry [ "" url "" ] = entry [ "" url "" ] . replace ( "" &amp; "" , "" & "" )","if ""&amp;"" in entry [ ""url"" ] :","if entry [ ""url"" ] :",94.37807006147077,96.58,False
4380,"def function ( self , inputs , outputs , ignore_empty = False ) : <TAB> f = function ( inputs , outputs , mode = self . mode ) <TAB> if self . mode is not None or theano . config . mode != "" FAST_COMPILE "" : <TAB><TAB> topo = f . maker . fgraph . toposort ( ) <TAB><TAB> topo_ = [ node for node in topo if not isinstance ( node . op , self . ignore_topo ) ] <TAB><TAB> if ignore_empty : <TAB><TAB><TAB> assert len ( topo_ ) < = 1 , topo_ <TAB><TAB> else : <TAB><TAB><TAB> assert len ( topo_ ) == 1 , topo_ <TAB><TAB> <MASK> <TAB><TAB><TAB> assert type ( topo_ [ 0 ] . op ) is self . op <TAB> return f",if len ( topo_ ) > 0 :,if len ( topo_ ) == 1 :,75.05106191532126,97.84,False
4381,"def _get_env_command ( self ) - > Sequence [ str ] : <TAB> """"""Get command sequence for `env` with configured flags."""""" <TAB> env_list = [ "" env "" ] <TAB> # Pass through configurable environment variables. <TAB> for key in [ "" http_proxy "" , "" https_proxy "" ] : <TAB><TAB> value = self . build_provider_flags . get ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # Ensure item is treated as string and append it. <TAB><TAB> value = str ( value ) <TAB><TAB> env_list . append ( f "" { key } = { value } "" ) <TAB> return env_list",if not value :,if value is None :,98.04229207046558,97.60,False
4382,"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB><TAB> compare_id , redo = self . in_queue . get ( <TAB><TAB><TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB><TAB> ) <TAB> except Empty : <TAB><TAB> pass <TAB> else : <TAB><TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB><TAB><TAB> if redo : <TAB><TAB><TAB><TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB><TAB><TAB> compares_done . add ( compare_id ) <TAB><TAB><TAB> self . _process_compare ( compare_id ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . callback ( )",if self . callback :,if self . callback :,100.0,100.00,True
4383,"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self . code : <TAB><TAB> self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB> if not self . site : <TAB><TAB> placeholders = StaticPlaceholder . objects . filter ( <TAB><TAB><TAB> code = self . code , site__isnull = True <TAB><TAB> ) <TAB><TAB> if self . pk : <TAB><TAB><TAB> placeholders = placeholders . exclude ( pk = self . pk ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB> _ ( "" A static placeholder with the same site and code already exists "" ) <TAB><TAB><TAB> )",if placeholders . exists ( ) :,if placeholders . exists ( ) :,75.0,100.00,True
4384,"def load_parser ( self ) : <TAB> result = OrderedDict ( ) <TAB> for name , flags in self . filenames : <TAB><TAB> filename = self . get_filename ( name ) <TAB><TAB> for match in sorted ( glob ( filename ) , key = self . file_key ) : <TAB><TAB><TAB> # Needed to allow overlapping globs, more specific first <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> result [ match ] = TextParser ( match , os . path . relpath ( match , self . base ) , flags ) <TAB> return result",if match in result :,if match in result :,100.0,100.00,True
4385,"def __init__ ( self , selectable , name = None ) : <TAB> baseselectable = selectable <TAB> while isinstance ( baseselectable , Alias ) : <TAB><TAB> baseselectable = baseselectable . element <TAB> self . original = baseselectable <TAB> self . supports_execution = baseselectable . supports_execution <TAB> if self . supports_execution : <TAB><TAB> self . _execution_options = baseselectable . _execution_options <TAB> self . element = selectable <TAB> if name is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> name = getattr ( self . original , "" name "" , None ) <TAB><TAB> name = _anonymous_label ( "" %% ( %d   %s )s "" % ( id ( self ) , name or "" anon "" ) ) <TAB> self . name = name",if self . original . named_with_column :,"if hasattr ( self . original , ""name"" ) :",73.24748655331038,94.90,False
4386,"def load_tour ( self , tour_id ) : <TAB> for tour_dir in self . tour_directories : <TAB><TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yaml "" ) <TAB><TAB> if not os . path . exists ( tour_path ) : <TAB><TAB><TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yml "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _load_tour_from_path ( tour_path )",if os . path . exists ( tour_path ) :,if os . path . exists ( tour_path ) :,100.0,100.00,True
4387,"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t . theme_style == "" Dark "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> c = t . primary_dark <TAB><TAB> elif self . md_bg_color == t . accent_color : <TAB><TAB><TAB> c = t . accent_dark <TAB> return c",if self . md_bg_color == t . primary_color :,if self . md_bg_color == t . primary_color :,100.0,100.00,True
4388,"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB><TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB><TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB><TAB> if shapes [ i ] is not None : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> for j in range ( len ( data [ i ] ) ) : <TAB><TAB><TAB><TAB><TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data )","if isinstance ( request , numbers . Integral ) :",if i == len ( data [ i ] ) :,84.66396555872096,95.87,False
4389,"def onClicked ( event ) : <TAB> if not self . path : <TAB><TAB> <MASK> <TAB><TAB><TAB> os . makedirs ( mh . getPath ( "" render "" ) ) <TAB><TAB> self . path = mh . getPath ( "" render "" ) <TAB> filename , ftype = mh . getSaveFileName ( <TAB><TAB> os . path . splitext ( self . path ) [ 0 ] , <TAB><TAB> "" PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*) "" , <TAB> ) <TAB> if filename : <TAB><TAB> if "" Thumbnail "" in ftype : <TAB><TAB><TAB> self . image . save ( filename , iformat = "" PNG "" ) <TAB><TAB> else : <TAB><TAB><TAB> self . image . save ( filename ) <TAB><TAB> self . path = os . path . dirname ( filename )","if not os . path . exists ( mh . getPath ( ""render"" ) ) :","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",100.0,100.00,True
4390,"def _build_dom ( cls , content , mode ) : <TAB> assert mode in ( "" html "" , "" xml "" ) <TAB> if mode == "" html "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> THREAD_STORAGE . html_parser = HTMLParser ( ) <TAB><TAB> dom = defusedxml . lxml . parse ( <TAB><TAB><TAB> StringIO ( content ) , parser = THREAD_STORAGE . html_parser <TAB><TAB> ) <TAB><TAB> return dom . getroot ( ) <TAB> else : <TAB><TAB> if not hasattr ( THREAD_STORAGE , "" xml_parser "" ) : <TAB><TAB><TAB> THREAD_STORAGE . xml_parser = XMLParser ( ) <TAB><TAB> dom = defusedxml . lxml . parse ( BytesIO ( content ) , parser = THREAD_STORAGE . xml_parser ) <TAB><TAB> return dom . getroot ( )","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :",100.0,100.00,True
4391,"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> ctx . move_to ( * points ) <TAB><TAB> elif code == Path . LINETO : <TAB><TAB><TAB> ctx . line_to ( * points ) <TAB><TAB> elif code == Path . CURVE3 : <TAB><TAB><TAB> ctx . curve_to ( <TAB><TAB><TAB><TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB><TAB><TAB> ) <TAB><TAB> elif code == Path . CURVE4 : <TAB><TAB><TAB> ctx . curve_to ( * points ) <TAB><TAB> elif code == Path . CLOSEPOLY : <TAB><TAB><TAB> ctx . close_path ( )",if code == Path . MOVETO :,if code == Path . MOVE :,74.00760634315193,98.91,False
4392,"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set ( ) <TAB> for condfield in self . conditions : <TAB><TAB> if condfield in sigmaparser . values : <TAB><TAB><TAB> rulefieldvalues = sigmaparser . values [ condfield ] <TAB><TAB><TAB> for condvalue in self . conditions [ condfield ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB> return targets",if condvalue in rulefieldvalues :,if condvalue in rulefieldvalues :,75.0,100.00,True
4393,"def create_image_upload ( ) : <TAB> if request . method == "" POST "" : <TAB><TAB> image = request . form [ "" image "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> image_file = uploaded_file ( file_content = image ) <TAB><TAB><TAB> image_url = upload_local ( <TAB><TAB><TAB><TAB> image_file , UPLOAD_PATHS [ "" temp "" ] [ "" image "" ] . format ( uuid = uuid4 ( ) ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> return jsonify ( { "" status "" : "" ok "" , "" image_url "" : image_url } ) <TAB><TAB> else : <TAB><TAB><TAB> return jsonify ( { "" status "" : "" no_image "" } )",if image :,if image :,100.0,100.00,True
4394,"def lookup_actions ( self , resp ) : <TAB> actions = { } <TAB> for action , conditions in self . actions . items ( ) : <TAB><TAB> for condition , opts in conditions : <TAB><TAB><TAB> for key , val in condition : <TAB><TAB><TAB><TAB> if key [ - 1 ] == "" ! "" : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> if not resp . match ( key , val ) : <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> actions [ action ] = opts <TAB> return actions","if resp . match ( key [ : - 1 ] , val ) :",if val is None :,83.83100286452583,93.64,False
4395,"def accept_quality ( accept , default = 1 ) : <TAB> """"""Separates out the quality score from the accepted content_type"""""" <TAB> quality = default <TAB> if accept and "" ; "" in accept : <TAB><TAB> accept , rest = accept . split ( "" ; "" , 1 ) <TAB><TAB> accept_quality = RE_ACCEPT_QUALITY . search ( rest ) <TAB><TAB> <MASK> <TAB><TAB><TAB> quality = float ( accept_quality . groupdict ( ) . get ( "" quality "" , quality ) . strip ( ) ) <TAB> return ( quality , accept . strip ( ) )",if accept_quality :,if accept_quality :,100.0,100.00,True
4396,"def save ( self , session = None , to = None , pickler = None ) : <TAB> if to and pickler : <TAB><TAB> self . _save_to = ( pickler , to ) <TAB> if self . _save_to and len ( self ) > 0 : <TAB><TAB> with self . _lock : <TAB><TAB><TAB> pickler , fn = self . _save_to <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> session . ui . mark ( _ ( "" Saving  %s  state to  %s "" ) % ( self , fn ) ) <TAB><TAB><TAB> pickler ( self , fn )",if session :,if session :,100.0,100.00,True
4397,"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB><TAB> if k . isupper ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> settings_dict [ k ] = "" ******************** "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict",if HIDDEN_SETTINGS . search ( k ) :,"if k . startswith ( ""*"" ) :",94.0848594295115,95.21,False
4398,def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB><TAB> part_l = i <TAB><TAB> part_h = 0 <TAB><TAB> for j in range ( 8 ) : <TAB><TAB><TAB> rflag = part_l & 1 <TAB><TAB><TAB> part_l >> = 1 <TAB><TAB><TAB> if part_h & 1 : <TAB><TAB><TAB><TAB> part_l | = 1 << 31 <TAB><TAB><TAB> part_h >> = 1 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> part_h ^ = 0xD8000000 <TAB><TAB> _table_h . append ( part_h ) <TAB> return _table_h,if rflag :,if rflag :,100.0,100.00,True
4399,"def dns_query ( server , timeout , protocol , qname , qtype , qclass ) : <TAB> request = dns . message . make_query ( qname , qtype , qclass ) <TAB> if protocol == "" tcp "" : <TAB><TAB> response = dns . query . tcp ( <TAB><TAB><TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB> ) <TAB> else : <TAB><TAB> response = dns . query . udp ( <TAB><TAB><TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> response = dns . query . tcp ( <TAB><TAB><TAB><TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB><TAB><TAB> ) <TAB> return response",if response . flags & dns . flags . TC :,"if protocol == ""udp"" :",79.48821796826341,95.30,False
4400,"def sum_and_divide ( self , losses ) : <TAB> if self . total_divisor != 0 : <TAB><TAB> output = torch . sum ( losses ) / self . total_divisor <TAB><TAB> <MASK> <TAB><TAB><TAB> # remove from autograd graph if necessary <TAB><TAB><TAB> self . total_divisor = self . total_divisor . item ( ) <TAB><TAB> return output <TAB> return torch . sum ( losses * 0 )",if torch . is_tensor ( self . total_divisor ) :,if self . autograd_graph :,84.82109675905448,89.75,False
4401,"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB><TAB> if chunk is not None : <TAB><TAB><TAB> self . wait_counter = 0 <TAB><TAB><TAB> yield chunk <TAB><TAB> <MASK> <TAB><TAB><TAB> self . wait_counter + = 1 <TAB><TAB> else : <TAB><TAB><TAB> logger . warning ( <TAB><TAB><TAB><TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB><TAB><TAB><TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> break <TAB><TAB> time . sleep ( self . poll_period )",elif self . wait_counter < self . wait_cntr_max :,elif self . wait_counter == self . wait_cntr_max :,98.72791286508651,98.37,False
4402,"def test_find_directive_from_block ( self ) : <TAB> blocks = self . config . parser_root . find_blocks ( "" virtualhost "" ) <TAB> found = False <TAB> for vh in blocks : <TAB><TAB> <MASK> <TAB><TAB><TAB> servername = vh . find_directives ( "" servername "" ) <TAB><TAB><TAB> self . assertEqual ( servername [ 0 ] . parameters [ 0 ] , "" certbot.demo "" ) <TAB><TAB><TAB> found = True <TAB> self . assertTrue ( found )","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :","if vh . name == ""virtualhost"" :",92.71761156267448,90.68,False
4403,"def assign_products ( request , discount_id ) : <TAB> """"""Assign products to given property group with given property_group_id."""""" <TAB> discount = lfs_get_object_or_404 ( Discount , pk = discount_id ) <TAB> for temp_id in request . POST . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> temp_id = temp_id . split ( "" - "" ) [ 1 ] <TAB><TAB><TAB> product = Product . objects . get ( pk = temp_id ) <TAB><TAB><TAB> discount . products . add ( product ) <TAB> html = [ [ "" #products-inline "" , products_inline ( request , discount_id , as_string = True ) ] ] <TAB> result = json . dumps ( <TAB><TAB> { "" html "" : html , "" message "" : _ ( u "" Products have been assigned. "" ) } , cls = LazyEncoder <TAB> ) <TAB> return HttpResponse ( result , content_type = "" application/json "" )","if temp_id . startswith ( ""product"" ) :","if ""-"" in temp_id :",59.20108364272817,96.19,False
4404,"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB><TAB> if combo . GetValue ( ) == 1 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> style = style | HTL . TR_VIRTUAL <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB><TAB> self . SetAGWWindowStyleFlag ( style )","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",if self . GetTransType ( ) == wx . TR_VIRTUAL :,92.72691539475504,95.54,False
4405,"def _set_autocomplete ( self , notebook ) : <TAB> if notebook : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> notebook = NotebookInfo ( notebook ) <TAB><TAB><TAB> obj , x = build_notebook ( notebook ) <TAB><TAB><TAB> self . form . widgets [ "" namespace "" ] . notebook = obj <TAB><TAB><TAB> self . form . widgets [ "" page "" ] . notebook = obj <TAB><TAB><TAB> logger . debug ( "" Notebook for autocomplete:  %s  ( %s ) "" , obj , notebook ) <TAB><TAB> except : <TAB><TAB><TAB> logger . exception ( "" Could not set notebook:  %s "" , notebook ) <TAB> else : <TAB><TAB> self . form . widgets [ "" namespace "" ] . notebook = None <TAB><TAB> self . form . widgets [ "" page "" ] . notebook = None <TAB><TAB> logger . debug ( "" Notebook for autocomplete unset "" )","if isinstance ( notebook , str ) :","if not isinstance ( notebook , str ) :",95.98480285410427,98.99,False
4406,"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB><TAB> if subDomain : <TAB><TAB><TAB> self . emitHostname ( subDomain , event )",if self . checkForStop ( ) :,"if not subDomainElem . get ( ""domain"" , """" ) :",89.24730763190796,88.80,False
4407,"def get_all_subnets ( self , subnet_ids = None , filters = None ) : <TAB> # Extract a list of all subnets <TAB> matches = itertools . chain ( * [ x . values ( ) for x in self . subnets . values ( ) ] ) <TAB> if subnet_ids : <TAB><TAB> matches = [ sn for sn in matches if sn . id in subnet_ids ] <TAB><TAB> <MASK> <TAB><TAB><TAB> unknown_ids = set ( subnet_ids ) - set ( matches ) <TAB><TAB><TAB> raise InvalidSubnetIdError ( unknown_ids ) <TAB> if filters : <TAB><TAB> matches = generic_filter ( filters , matches ) <TAB> return matches",if len ( subnet_ids ) > len ( matches ) :,if len ( matches ) != len ( subnet_ids ) :,98.44083404855,97.40,False
4408,"def _compat_map ( self , avs ) : <TAB> apps = { } <TAB> for av in avs : <TAB><TAB> av . version = self <TAB><TAB> app_id = av . application <TAB><TAB> <MASK> <TAB><TAB><TAB> apps [ amo . APP_IDS [ app_id ] ] = av <TAB> return apps",if app_id in amo . APP_IDS :,if app_id in amo . APP_IDS :,100.0,100.00,True
4409,"def generator ( self , data ) : <TAB> if self . _config . SILENT : <TAB><TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB><TAB> for var , val in task . environment_variables ( ) : <TAB><TAB><TAB> if self . _config . SILENT : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> int ( task . UniqueProcessId ) , <TAB><TAB><TAB><TAB><TAB> str ( task . ImageFileName ) , <TAB><TAB><TAB><TAB><TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB><TAB><TAB><TAB><TAB> str ( var ) , <TAB><TAB><TAB><TAB><TAB> str ( val ) , <TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB> )",if var in silent_vars :,if var in silent_vars :,100.0,100.00,True
4410,"def warn_if_repeatable_read ( self ) : <TAB> if "" mysql "" in self . current_engine ( ) . lower ( ) : <TAB><TAB> cursor = self . connection_for_read ( ) . cursor ( ) <TAB><TAB> if cursor . execute ( "" SELECT @@tx_isolation "" ) : <TAB><TAB><TAB> isolation = cursor . fetchone ( ) [ 0 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB><TAB> TxIsolationWarning ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Polling results with transaction isolation level  "" <TAB><TAB><TAB><TAB><TAB><TAB> "" repeatable-read within the same transaction  "" <TAB><TAB><TAB><TAB><TAB><TAB> "" may give outdated results. Be sure to commit the  "" <TAB><TAB><TAB><TAB><TAB><TAB> "" transaction for each poll iteration. "" <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> )","if isolation == ""REPEATABLE-READ"" :","if isolation != ""repeatable-read"" :",98.43016656732769,98.28,False
4411,"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB><TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB><TAB> lookup = "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> level = level_per_module [ "" "" ] <TAB><TAB> for n in name . split ( "" . "" ) : <TAB><TAB><TAB> lookup + = n <TAB><TAB><TAB> if lookup in level_per_module : <TAB><TAB><TAB><TAB> level = level_per_module [ lookup ] <TAB><TAB><TAB> lookup + = "" . "" <TAB> if level is False : <TAB><TAB> return False <TAB> return record [ "" level "" ] . no > = level","if """" in level_per_module :","if ""name"" in level_per_module :",67.70813899164615,98.92,False
4412,"def _readStream ( self , handle : str , path : str ) - > None : <TAB> eof = False <TAB> file = Path ( path ) <TAB> with file . open ( "" w "" ) as f : <TAB><TAB> while not eof : <TAB><TAB><TAB> response = await self . _client . send ( "" IO.read "" , { "" handle "" : handle } ) <TAB><TAB><TAB> eof = response . get ( "" eof "" , False ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f . write ( response . get ( "" data "" , "" "" ) ) <TAB> await self . _client . send ( "" IO.close "" , { "" handle "" : handle } )",if path :,"if response . get ( ""data"" , False ) :",71.14435594557901,93.76,False
4413,"def sendall ( self , data , flags = 0 ) : <TAB> if self . _sslobj : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" non-zero flags not allowed in calls to sendall() on  %s "" <TAB><TAB><TAB><TAB> % self . __class__ <TAB><TAB><TAB> ) <TAB><TAB> amount = len ( data ) <TAB><TAB> count = 0 <TAB><TAB> while count < amount : <TAB><TAB><TAB> v = self . send ( data [ count : ] ) <TAB><TAB><TAB> count + = v <TAB><TAB> return amount <TAB> else : <TAB><TAB> return socket . sendall ( self , data , flags )",if flags != 0 :,if flags != 0 :,100.0,100.00,True
4414,"def run ( self ) : <TAB> utils . assert_main_thread ( ) <TAB> # As a convenience, we'll set up the connection <TAB> # if there isn't one. So F5 (etc) can be hit <TAB> # to get started. <TAB> if not channel : <TAB><TAB> <MASK> <TAB><TAB><TAB> SwiDebugStartChromeCommand . run ( self ) <TAB><TAB> else : <TAB><TAB><TAB> self . window . run_command ( "" swi_debug_start "" ) <TAB> elif paused : <TAB><TAB> logger . info ( "" Resuming... "" ) <TAB><TAB> channel . send ( webkit . Debugger . resume ( ) ) <TAB> else : <TAB><TAB> logger . info ( "" Pausing... "" ) <TAB><TAB> channel . send ( webkit . Debugger . setSkipAllPauses ( False ) ) <TAB><TAB> channel . send ( webkit . Debugger . pause ( ) )",if not chrome_launched ( ) :,if self . window :,97.8668984604056,96.64,False
4415,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
4416,"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB><TAB> home = ( <TAB><TAB><TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB><TAB> ) <TAB><TAB> if x . startswith ( home ) : <TAB><TAB><TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> x = x . replace ( os . sep , os . altsep ) <TAB><TAB> return x <TAB> else : <TAB><TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB><TAB> if x . startswith ( home ) : <TAB><TAB><TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB><TAB> return x","if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",elif x . startswith ( os . sep ) :,71.31006111060142,91.35,False
4417,"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB><TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key , value in list ( semanticTags . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise TypeError ( "" At least one key is not a valid int position "" ) <TAB><TAB> if not isinstance ( value , list ) : <TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB> "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB> ) <TAB><TAB> for x in value : <TAB><TAB><TAB> if not isinstance ( x , str ) : <TAB><TAB><TAB><TAB> raise TypeError ( <TAB><TAB><TAB><TAB><TAB> "" At least one value of the provided dict is not a list of string "" <TAB><TAB><TAB><TAB> ) <TAB> self . __semanticTags = semanticTags","if not isinstance ( key , int ) :","if not isinstance ( key , int ) :",100.0,100.00,True
4418,"def _recv ( ) : <TAB> try : <TAB><TAB> return sock . recv ( bufsize ) <TAB> except SSLWantReadError : <TAB><TAB> pass <TAB> except socket . error as exc : <TAB><TAB> error_code = extract_error_code ( exc ) <TAB><TAB> if error_code is None : <TAB><TAB><TAB> raise <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB> r , w , e = select . select ( ( sock , ) , ( ) , ( ) , sock . gettimeout ( ) ) <TAB> if r : <TAB><TAB> return sock . recv ( bufsize )",if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,if error_code != errno . EINTR :,83.28551829450302,93.16,False
4419,"def _authenticate ( self ) : <TAB> oauth_token = self . options . get ( "" oauth_token "" ) <TAB> if oauth_token and not self . api . oauth_token : <TAB><TAB> self . logger . info ( "" Attempting to authenticate using OAuth token "" ) <TAB><TAB> self . api . oauth_token = oauth_token <TAB><TAB> user = self . api . user ( schema = _user_schema ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . logger . info ( "" Successfully logged in as  {0} "" , user ) <TAB><TAB> else : <TAB><TAB><TAB> self . logger . error ( <TAB><TAB><TAB><TAB> "" Failed to authenticate, the access token  "" "" is not valid "" <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> return JustinTVPluginBase . _authenticate ( self )",if user :,if user :,100.0,100.00,True
4420,"def reverse ( self , * args ) : <TAB> assert self . _path is not None , "" Cannot reverse url regex  "" + self . regex . pattern <TAB> assert len ( args ) == self . _group_count , "" required number of arguments  "" "" not found "" <TAB> if not len ( args ) : <TAB><TAB> return self . _path <TAB> converted_args = [ ] <TAB> for a in args : <TAB><TAB> <MASK> <TAB><TAB><TAB> a = str ( a ) <TAB><TAB> converted_args . append ( escape . url_escape ( utf8 ( a ) , plus = False ) ) <TAB> return self . _path % tuple ( converted_args )","if not isinstance ( a , ( unicode_type , bytes ) ) :","if not isinstance ( a , ( bytes , bytearray ) ) :",98.38432069718317,96.57,False
4421,"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB><TAB> <MASK> <TAB><TAB><TAB> hints + = str ( self . best_indent ) <TAB><TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = "" - "" <TAB><TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB><TAB><TAB> hints + = "" + "" <TAB> return hints","if text [ 0 ] in "" \n\x85\u2028\u2029"" :",if self . best_indent :,87.6256842386653,89.45,False
4422,"def find_package_modules ( package , mask ) : <TAB> import fnmatch <TAB> if hasattr ( package , "" __loader__ "" ) and hasattr ( package . __loader__ , "" _files "" ) : <TAB><TAB> path = package . __name__ . replace ( "" . "" , os . path . sep ) <TAB><TAB> mask = os . path . join ( path , mask ) <TAB><TAB> for fnm in package . __loader__ . _files . iterkeys ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield os . path . splitext ( fnm ) [ 0 ] . replace ( os . path . sep , "" . "" ) <TAB> else : <TAB><TAB> path = package . __path__ [ 0 ] <TAB><TAB> for fnm in os . listdir ( path ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield "" %s . %s "" % ( package . __name__ , os . path . splitext ( fnm ) [ 0 ] )","if fnmatch . fnmatchcase ( fnm , mask ) :","if fnmatch . fnmatch ( fnm , mask ) :",98.56651916483993,98.17,False
4423,"def _condition ( ct ) : <TAB> for qobj in args : <TAB><TAB> if qobj . connector == "" AND "" and not qobj . negated : <TAB><TAB><TAB> # normal kwargs are an AND anyway, so just use those for now <TAB><TAB><TAB> for child in qobj . children : <TAB><TAB><TAB><TAB> kwargs . update ( dict ( [ child ] ) ) <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError ( "" Unsupported Q object "" ) <TAB> for attr , val in kwargs . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return False <TAB> return True","if getattr ( ct , attr ) != val :","if not ct . _condition ( attr , val ) :",95.83087669925253,94.10,False
4424,"def process ( self , resources ) : <TAB> session = local_session ( self . manager . session_factory ) <TAB> client = session . client ( "" logs "" ) <TAB> state = self . data . get ( "" state "" , True ) <TAB> key = self . resolve_key ( self . data . get ( "" kms-key "" ) ) <TAB> for r in resources : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> client . associate_kms_key ( logGroupName = r [ "" logGroupName "" ] , kmsKeyId = key ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> client . disassociate_kms_key ( logGroupName = r [ "" logGroupName "" ] ) <TAB><TAB> except client . exceptions . ResourceNotFoundException : <TAB><TAB><TAB> continue",if state :,if state :,100.0,100.00,True
4425,"def get_xmm ( env , ii ) : <TAB> if is_gather ( ii ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return gen_reg_simd_unified ( env , "" xmm_evex "" , True ) <TAB><TAB> return gen_reg_simd_unified ( env , "" xmm "" , False ) <TAB> <MASK> <TAB><TAB> return gen_reg ( env , "" xmm_evex "" ) <TAB> return gen_reg ( env , "" xmm "" )","if ii . space == ""evex"" :","if ii . get_type ( ) == ""evex"" :",66.15655661000714,90.72,False
4426,"def parent ( self ) : <TAB> """"""Return the parent device."""""" <TAB> if self . _has_parent is None : <TAB><TAB> _parent = self . _ctx . backend . get_parent ( self . _ctx . dev ) <TAB><TAB> self . _has_parent = _parent is not None <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _parent = Device ( _parent , self . _ctx . backend ) <TAB><TAB> else : <TAB><TAB><TAB> self . _parent = None <TAB> return self . _parent",if self . _has_parent :,"if isinstance ( _parent , str ) :",70.51793291696556,94.76,False
4427,"def cascade ( self , event = None ) : <TAB> """"""Cascade all Leo windows."""""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB><TAB> w = frame and frame . top <TAB><TAB> <MASK> <TAB><TAB><TAB> r = w . geometry ( ) # a Qt.Rect <TAB><TAB><TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB><TAB><TAB> w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB><TAB><TAB> # Compute the new offsets. <TAB><TAB><TAB> x + = 30 <TAB><TAB><TAB> y + = 30 <TAB><TAB><TAB> if x > 200 : <TAB><TAB><TAB><TAB> x = 10 + delta <TAB><TAB><TAB><TAB> y = 40 + delta <TAB><TAB><TAB><TAB> delta + = 10",if w :,if w :,100.0,100.00,True
4428,"def _GetGoodDispatchAndUserName ( IDispatch , userName , clsctx ) : <TAB> # Get a dispatch object, and a 'user name' (ie, the name as <TAB> # displayed to the user in repr() etc. <TAB> if userName is None : <TAB><TAB> if isinstance ( IDispatch , str ) : <TAB><TAB><TAB> userName = IDispatch <TAB><TAB> <MASK> <TAB><TAB><TAB> # We always want the displayed name to be a real string <TAB><TAB><TAB> userName = IDispatch . encode ( "" ascii "" , "" replace "" ) <TAB> elif type ( userName ) == unicode : <TAB><TAB> # As above - always a string... <TAB><TAB> userName = userName . encode ( "" ascii "" , "" replace "" ) <TAB> else : <TAB><TAB> userName = str ( userName ) <TAB> return ( _GetGoodDispatch ( IDispatch , clsctx ) , userName )","elif isinstance ( IDispatch , unicode ) :","elif isinstance ( IDispatch , unicode ) :",75.0,100.00,True
4429,"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB><TAB> if arg is None : <TAB><TAB><TAB> continue <TAB><TAB> if isinstance ( arg , bytes ) : <TAB><TAB><TAB> if return_type is str : <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = bytes <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB><TAB><TAB> return_type = str <TAB> if return_type is None : <TAB><TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if return_type is bytes :,"if isinstance ( arg , bytes ) :",94.06138232627322,97.09,False
4430,"def test_ESPnetDataset_h5file_1 ( h5file_1 ) : <TAB> dataset = IterableESPnetDataset ( <TAB><TAB> path_name_type_list = [ ( h5file_1 , "" data4 "" , "" hdf5 "" ) ] , <TAB><TAB> preprocess = preprocess , <TAB> ) <TAB> for key , data in dataset : <TAB><TAB> if key == "" a "" : <TAB><TAB><TAB> assert data [ "" data4 "" ] . shape == ( <TAB><TAB><TAB><TAB> 100 , <TAB><TAB><TAB><TAB> 80 , <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert data [ "" data4 "" ] . shape == ( <TAB><TAB><TAB><TAB> 150 , <TAB><TAB><TAB><TAB> 80 , <TAB><TAB><TAB> )","if key == ""b"" :","if key == ""h5"" :",98.69454293562382,98.86,False
4431,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB><TAB> if exclude_meta and field . meta : <TAB><TAB><TAB> continue <TAB><TAB> field_val = getattr ( node , field_name , _marker ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if exclude_unset : <TAB><TAB><TAB> if callable ( field . default ) : <TAB><TAB><TAB><TAB> default = field . default ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> default = field . default <TAB><TAB><TAB> if field_val == default : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield field_name , field_val",if field_val is _marker :,if field_val is None :,80.4774580611491,98.54,False
4432,"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB><TAB> ret = [ ] <TAB><TAB> when_response = list ( when_response ) <TAB><TAB> for match in when_response : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if self . match_name : <TAB><TAB><TAB><TAB><TAB> match . name = self . match_name <TAB><TAB><TAB><TAB> matches . append ( match ) <TAB><TAB><TAB><TAB> ret . append ( match ) <TAB><TAB> return ret <TAB> if self . match_name : <TAB><TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB><TAB> matches . append ( when_response ) <TAB><TAB> return when_response",if match not in matches :,if match . name == self . match_name :,95.5021282074776,95.52,False
4433,"def _set_chat_ids ( self , chat_id : SLT [ int ] ) - > None : <TAB> with self . __lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB><TAB> f "" Can ' t set  { self . chat_id_name }  in conjunction with (already set)  "" <TAB><TAB><TAB><TAB> f "" { self . username_name } s. "" <TAB><TAB><TAB> ) <TAB><TAB> self . _chat_ids = self . _parse_chat_id ( chat_id )",if chat_id and self . _usernames :,if self . _chat_ids :,90.2224107698196,95.28,False
4434,"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if l [ 0 ] == "" Filename "" : <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> int ( l [ 2 ] ) <TAB><TAB><TAB> int ( l [ 3 ] ) <TAB><TAB> except : <TAB><TAB><TAB> continue <TAB><TAB> #           ret.append(improve(l[0])) <TAB><TAB> ret . append ( l [ 0 ] ) <TAB> ret . sort ( ) <TAB> for item in objlist : <TAB><TAB> ret . append ( item ) <TAB> return ret",if len ( l ) < 5 :,if len ( l ) < 4 :,98.82520154333652,98.76,False
4435,"def get_changed_module ( self ) : <TAB> source = self . resource . read ( ) <TAB> change_collector = codeanalyze . ChangeCollector ( source ) <TAB> if self . replacement is not None : <TAB><TAB> change_collector . add_change ( self . skip_start , self . skip_end , self . replacement ) <TAB> for occurrence in self . occurrence_finder . find_occurrences ( self . resource ) : <TAB><TAB> start , end = occurrence . get_primary_range ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . handle . occurred_inside_skip ( change_collector , occurrence ) <TAB><TAB> else : <TAB><TAB><TAB> self . handle . occurred_outside_skip ( change_collector , occurrence ) <TAB> result = change_collector . get_changed ( ) <TAB> if result is not None and result != source : <TAB><TAB> return result",if self . skip_start <= start < self . skip_end :,if start < self . skip_start and end < self . skip_end :,79.00784898870293,97.50,False
4436,"def hpat_pandas_series_var_impl ( <TAB> self , axis = None , skipna = None , level = None , ddof = 1 , numeric_only = None ) : <TAB> if skipna is None : <TAB><TAB> skipna = True <TAB> if skipna : <TAB><TAB> valuable_length = len ( self . _data ) - numpy . sum ( numpy . isnan ( self . _data ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return numpy . nan <TAB><TAB> return ( <TAB><TAB><TAB> numpy_like . nanvar ( self . _data ) * valuable_length / ( valuable_length - ddof ) <TAB><TAB> ) <TAB> if len ( self . _data ) < = ddof : <TAB><TAB> return numpy . nan <TAB> return self . _data . var ( ) * len ( self . _data ) / ( len ( self . _data ) - ddof )",if valuable_length <= ddof :,if valuable_length <= ddof :,100.0,100.00,True
4437,"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self # don't copy unless we need to <TAB> if condition is not Undefined : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass <TAB><TAB> elif "" field "" in condition and "" type "" not in condition : <TAB><TAB><TAB> kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB><TAB><TAB> copy = self . copy ( deep = [ "" condition "" ] ) <TAB><TAB><TAB> copy . condition . update ( kwds ) <TAB> return super ( ValueChannelMixin , copy ) . to_dict ( <TAB><TAB> validate = validate , ignore = ignore , context = context <TAB> )","if isinstance ( condition , core . SchemaBase ) :","if isinstance ( condition , ( list , tuple ) ) :",98.27488562661595,97.07,False
4438,"def get_field_result ( self , result , field_name ) : <TAB> if isinstance ( result . field , models . ImageField ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> img = getattr ( result . obj , field_name ) <TAB><TAB><TAB> result . text = mark_safe ( <TAB><TAB><TAB><TAB> ' <a href= "" %s ""  target= "" _blank ""  title= "" %s ""  data-gallery= "" gallery "" ><img src= "" %s ""  class= "" field_img "" /></a> ' <TAB><TAB><TAB><TAB> % ( img . url , result . label , img . url ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . include_image = True <TAB> return result",if result . value :,if result . obj :,98.14369809409955,98.72,False
4439,"def run ( self ) : <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> dp = self . queue_get_stoppable ( self . inq ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> # cannot ignore None here. will lead to unsynced send/recv <TAB><TAB><TAB> obj = self . func ( dp ) <TAB><TAB><TAB> self . queue_put_stoppable ( self . outq , obj ) <TAB> except Exception : <TAB><TAB> <MASK> <TAB><TAB><TAB> pass # skip duplicated error messages <TAB><TAB> else : <TAB><TAB><TAB> raise <TAB> finally : <TAB><TAB> self . stop ( )",if self . stopped ( ) :,if dp is None :,87.68112140114593,93.50,False
4440,"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB><TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB><TAB> with function . no_backprop_mode ( ) : <TAB><TAB><TAB> if isinstance ( in_arrays , tuple ) : <TAB><TAB><TAB><TAB> results = self . calc_local ( * in_arrays ) <TAB><TAB><TAB> elif isinstance ( in_arrays , dict ) : <TAB><TAB><TAB><TAB> results = self . calc_local ( * * in_arrays ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> results = self . calc_local ( in_arrays ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _progress_hook ( batch ) <TAB><TAB> yield results",if self . _progress_hook :,if self . _progress_hook :,100.0,100.00,True
4441,"def merge ( self , other ) : <TAB> d = self . _name2ft <TAB> for name , ( f , t ) in other . _name2ft . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Don't print here by default, since doing <TAB><TAB><TAB> #     so breaks some of the buildbots <TAB><TAB><TAB> # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB><TAB><TAB> #    "" testers; summing outcomes."" <TAB><TAB><TAB> f2 , t2 = d [ name ] <TAB><TAB><TAB> f = f + f2 <TAB><TAB><TAB> t = t + t2 <TAB><TAB> d [ name ] = f , t",if name in d :,if name in d :,100.0,100.00,True
4442,"def _addSettingsToPanels ( self , category , left , right ) : <TAB> count = len ( profile . getSubCategoriesFor ( category ) ) + len ( <TAB><TAB> profile . getSettingsForCategory ( category ) <TAB> ) <TAB> p = left <TAB> n = 0 <TAB> for title in profile . getSubCategoriesFor ( category ) : <TAB><TAB> n + = 1 + len ( profile . getSettingsForCategory ( category , title ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> p = right <TAB><TAB> configBase . TitleRow ( p , _ ( title ) ) <TAB><TAB> for s in profile . getSettingsForCategory ( category , title ) : <TAB><TAB><TAB> configBase . SettingRow ( p , s . getName ( ) )",if n > count / 2 :,if n > count :,69.71312959394852,97.97,False
4443,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> path = os . path . join ( dir , i ) <TAB><TAB> if os . path . isdir ( path ) : <TAB><TAB><TAB> dirlist . append ( i ) <TAB><TAB><TAB> continue <TAB><TAB> path = path . upper ( ) <TAB><TAB> value = i . upper ( ) <TAB><TAB> if pattern . match ( value ) is not None : <TAB><TAB><TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB><TAB> self . dirs = dirlist","if i == ""."" or i == "".."" :",if not i . startswith ( parent ) :,86.3842509589449,94.33,False
4444,def check_network_private ( test_network ) : <TAB> test_net = ipaddress . IPNetwork ( test_network ) <TAB> test_start = test_net . network <TAB> test_end = test_net . broadcast <TAB> for network in settings . vpn . safe_priv_subnets : <TAB><TAB> network = ipaddress . IPNetwork ( network ) <TAB><TAB> net_start = network . network <TAB><TAB> net_end = network . broadcast <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False,if test_start >= net_start and test_end <= net_end :,if test_start <= net_end and test_start <= net_end :,71.4304228327703,95.50,False
4445,"def _end_description ( self ) : <TAB> if self . _summaryKey == "" content "" : <TAB><TAB> self . _end_content ( ) <TAB> else : <TAB><TAB> value = self . popContent ( "" description "" ) <TAB><TAB> context = self . _getContext ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> context [ "" textinput "" ] [ "" description "" ] = value <TAB><TAB> elif self . inimage : <TAB><TAB><TAB> context [ "" image "" ] [ "" description "" ] = value <TAB> self . _summaryKey = None",if self . intextinput :,if self . intextinput :,100.0,100.00,True
4446,def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB><TAB> for p in self . grammar . Productions [ 1 : ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> nullable [ p . name ] = 1 <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> for t in p . prod : <TAB><TAB><TAB><TAB> if not t in nullable : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> nullable [ p . name ] = 1 <TAB><TAB> if len ( nullable ) == num_nullable : <TAB><TAB><TAB> break <TAB><TAB> num_nullable = len ( nullable ) <TAB> return nullable,if p . len == 0 :,if p . name in self . nullable_nonterminals :,94.30410427726595,96.28,False
4447,"def process_bind_param ( self , value , dialect ) : <TAB> if value is not None : <TAB><TAB> if MAX_METADATA_VALUE_SIZE is not None : <TAB><TAB><TAB> for k , v in list ( value . items ( ) ) : <TAB><TAB><TAB><TAB> sz = total_size ( v ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> del value [ k ] <TAB><TAB><TAB><TAB><TAB> log . warning ( <TAB><TAB><TAB><TAB><TAB><TAB> "" Refusing to bind metadata key  {}  due to size ( {} ) "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB><TAB> k , sz <TAB><TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB> value = json_encoder . encode ( value ) . encode ( ) <TAB> return value",if sz > MAX_METADATA_VALUE_SIZE :,if sz > MAX_METADATA_VALUE_SIZE :,100.0,100.00,True
4448,"def process_input_line ( self , line , store_history = True ) : <TAB> """"""process the input, capturing stdout"""""" <TAB> stdout = sys . stdout <TAB> splitter = self . IP . input_splitter <TAB> try : <TAB><TAB> sys . stdout = self . cout <TAB><TAB> splitter . push ( line ) <TAB><TAB> more = splitter . push_accepts_more ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> source_raw = splitter . source_raw_reset ( ) [ 1 ] <TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB> # recent ipython #4504 <TAB><TAB><TAB><TAB> source_raw = splitter . raw_reset ( ) <TAB><TAB><TAB> self . IP . run_cell ( source_raw , store_history = store_history ) <TAB> finally : <TAB><TAB> sys . stdout = stdout",if not more :,if not more :,100.0,100.00,True
4449,"def _dump_section ( self , name , values , f ) : <TAB> doc = "" __doc__ "" <TAB> <MASK> <TAB><TAB> print ( "" #  %s "" % values [ doc ] , file = f ) <TAB> print ( "" %s ( "" % name , file = f ) <TAB> for k , v in values . items ( ) : <TAB><TAB> if k . endswith ( "" __doc__ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> doc = k + "" __doc__ "" <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( ""     #  %s "" % values [ doc ] , file = f ) <TAB><TAB> print ( ""      %s  =  %s , "" % ( k , pprint . pformat ( v , indent = 8 ) ) , file = f ) <TAB> print ( "" ) \n "" , file = f )",if doc in values :,if doc in values :,100.0,100.00,True
4450,"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB><TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB><TAB> if stored_session : <TAB><TAB><TAB> expiration = stored_session . expiration <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB><TAB><TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB><TAB><TAB><TAB> return MongoEngineSession ( <TAB><TAB><TAB><TAB><TAB> initial = stored_session . data , sid = stored_session . sid <TAB><TAB><TAB><TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )",if not expiration . tzinfo :,if expiration :,82.22506184025315,97.67,False
4451,"def table_entry ( mode1 , bind_type1 , mode2 , bind_type2 ) : <TAB> with sock ( mode1 ) as sock1 : <TAB><TAB> bind ( sock1 , bind_type1 ) <TAB><TAB> try : <TAB><TAB><TAB> with sock ( mode2 ) as sock2 : <TAB><TAB><TAB><TAB> bind ( sock2 , bind_type2 ) <TAB><TAB> except OSError as exc : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return "" INUSE "" <TAB><TAB><TAB> elif exc . winerror == errno . WSAEACCES : <TAB><TAB><TAB><TAB> return "" ACCESS "" <TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> return "" Success """,if exc . winerror == errno . WSAEADDRINUSE :,if exc . winerror == errno . EINVAL :,73.64802024571213,98.74,False
4452,"def __init__ ( self , ruleset ) : <TAB> # Organize rules by path <TAB> self . ruleset = ruleset <TAB> self . rules = { } <TAB> for filename in self . ruleset . rules : <TAB><TAB> for rule in self . ruleset . rules [ filename ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> manage_dictionary ( self . rules , rule . path , [ ] ) <TAB><TAB><TAB> self . rules [ rule . path ] . append ( rule )",if not rule . enabled :,if rule . path in self . rules :,71.22570111241305,94.54,False
4453,"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB><TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB><TAB> i = self . readSentence ( ) <TAB><TAB> if len ( i ) == 0 : <TAB><TAB><TAB> continue <TAB><TAB> reply = i [ 0 ] <TAB><TAB> attrs = { } <TAB><TAB> for w in i [ 1 : ] : <TAB><TAB><TAB> j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> attrs [ w ] = "" "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB> r . append ( ( reply , attrs ) ) <TAB><TAB> if reply == "" !done "" : <TAB><TAB><TAB> return r",if j == - 1 :,if j == - 1 :,100.0,100.00,True
4454,"def _check_decorator_overload ( name : str , old : str , new : str ) - > int : <TAB> """"""Conditions for a decorator to overload an existing one."""""" <TAB> properties = _property_decorators ( name ) <TAB> if old == new : <TAB><TAB> return _MERGE <TAB> elif old in properties and new in properties : <TAB><TAB> p_old , p_new = properties [ old ] . precedence , properties [ new ] . precedence <TAB><TAB> <MASK> <TAB><TAB><TAB> return _DISCARD <TAB><TAB> elif p_old == p_new : <TAB><TAB><TAB> return _MERGE <TAB><TAB> else : <TAB><TAB><TAB> return _REPLACE <TAB> raise OverloadedDecoratorError ( name , "" "" )",if p_old > p_new :,if p_old == p_new :,98.81585925537323,98.22,False
4455,"def validate_pk ( self ) : <TAB> try : <TAB><TAB> self . _key = serialization . load_pem_private_key ( <TAB><TAB><TAB> self . key , password = None , backend = default_backend ( ) <TAB><TAB> ) <TAB><TAB> if self . _key . key_size > 2048 : <TAB><TAB><TAB> AWSValidationException ( <TAB><TAB><TAB><TAB> "" The private key length is not supported. Only 1024-bit and 2048-bit are allowed. "" <TAB><TAB><TAB> ) <TAB> except Exception as err : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> raise AWSValidationException ( <TAB><TAB><TAB> "" The private key is not PEM-encoded or is not valid. "" <TAB><TAB> )","if isinstance ( err , AWSValidationException ) :","if err . errno != ""pem-encoded"" :",92.49213745044042,95.54,False
4456,"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB><TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB><TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> custom_statements = [ custom_statements ] <TAB><TAB> statement = self . resource_policy [ "" Statement "" ] <TAB><TAB> if not isinstance ( statement , list ) : <TAB><TAB><TAB> statement = [ statement ] <TAB><TAB> for s in custom_statements : <TAB><TAB><TAB> if s not in statement : <TAB><TAB><TAB><TAB> statement . append ( s ) <TAB><TAB> self . resource_policy [ "" Statement "" ] = statement","if not isinstance ( custom_statements , list ) :","if not isinstance ( custom_statements , list ) :",100.0,100.00,True
4457,"def load ( self , repn ) : <TAB> for key in repn : <TAB><TAB> tmp = self . _convert ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . declare ( tmp ) <TAB><TAB> item = dict . __getitem__ ( self , tmp ) <TAB><TAB> item . _active = True <TAB><TAB> item . load ( repn [ key ] )",if tmp not in self :,if tmp :,87.16341683643564,95.63,False
4458,"def on_press_release ( x ) : <TAB> """"""Keyboard callback function."""""" <TAB> global is_recording , enable_trigger_record <TAB> press = keyboard . KeyboardEvent ( "" down "" , 28 , "" space "" ) <TAB> release = keyboard . KeyboardEvent ( "" up "" , 28 , "" space "" ) <TAB> if x . event_type == "" down "" and x . name == press . name : <TAB><TAB> if ( not is_recording ) and enable_trigger_record : <TAB><TAB><TAB> sys . stdout . write ( "" Start Recording ...  "" ) <TAB><TAB><TAB> sys . stdout . flush ( ) <TAB><TAB><TAB> is_recording = True <TAB> if x . event_type == "" up "" and x . name == release . name : <TAB><TAB> <MASK> <TAB><TAB><TAB> is_recording = False",if is_recording == True :,if ( not is_recording ) and enable_trigger_record :,76.24561403451308,94.71,False
4459,"def apply_mask ( self , mask , data_t , data_f ) : <TAB> ind_t , ind_f = 0 , 0 <TAB> out = [ ] <TAB> for m in cycle ( mask ) : <TAB><TAB> if m : <TAB><TAB><TAB> if ind_t == len ( data_t ) : <TAB><TAB><TAB><TAB> return out <TAB><TAB><TAB> out . append ( data_t [ ind_t ] ) <TAB><TAB><TAB> ind_t + = 1 <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return out <TAB><TAB><TAB> out . append ( data_f [ ind_f ] ) <TAB><TAB><TAB> ind_f + = 1 <TAB> return out",if ind_f == len ( data_f ) :,if ind_f == len ( data_f ) :,100.0,100.00,True
4460,"def oo_contains_rule ( source , apiGroups , resources , verbs ) : <TAB> """"""Return true if the specified rule is contained within the provided source"""""" <TAB> rules = source [ "" rules "" ] <TAB> if rules : <TAB><TAB> for rule in rules : <TAB><TAB><TAB> if set ( rule [ "" apiGroups "" ] ) == set ( apiGroups ) : <TAB><TAB><TAB><TAB> if set ( rule [ "" resources "" ] ) == set ( resources ) : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :","if len ( rule [ ""verbs"" ] ) == len ( verbs ) :",97.44977151990952,97.13,False
4461,"def _maybe_commit_artifact ( self , artifact_id ) : <TAB> artifact_status = self . _artifacts [ artifact_id ] <TAB> if artifact_status [ "" pending_count "" ] == 0 and artifact_status [ "" commit_requested "" ] : <TAB><TAB> for callback in artifact_status [ "" pre_commit_callbacks "" ] : <TAB><TAB><TAB> callback ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _api . commit_artifact ( artifact_id ) <TAB><TAB> for callback in artifact_status [ "" post_commit_callbacks "" ] : <TAB><TAB><TAB> callback ( )","if artifact_status [ ""finalize"" ] :","if artifact_status [ ""pending_count"" ] == 0 and artifact_status [ """,89.99403211059709,91.53,False
4462,"def shuffler ( iterator , pool_size = 10 * * 5 , refill_threshold = 0.9 ) : <TAB> yields_between_refills = round ( pool_size * ( 1 - refill_threshold ) ) <TAB> # initialize pool; this step may or may not exhaust the iterator. <TAB> pool = take_n ( pool_size , iterator ) <TAB> while True : <TAB><TAB> random . shuffle ( pool ) <TAB><TAB> for i in range ( yields_between_refills ) : <TAB><TAB><TAB> yield pool . pop ( ) <TAB><TAB> next_batch = take_n ( yields_between_refills , iterator ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> pool . extend ( next_batch ) <TAB> # finish consuming whatever's left - no need for further randomization. <TAB> yield from pool",if not next_batch :,if len ( next_batch ) == 0 :,97.66304940770245,95.69,False
4463,"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB><TAB> if isinstance ( key , ( int , long ) ) : <TAB><TAB><TAB> return self . _list [ key ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB><TAB> if k . lower ( ) == ikey : <TAB><TAB><TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB><TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key )","elif isinstance ( key , slice ) :","elif isinstance ( key , self . __class__ ) :",96.43168989302357,96.29,False
4464,"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB> if self . match_function ( path ) : <TAB><TAB><TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB><TAB> for content in os . listdir ( path ) : <TAB><TAB><TAB> file = os . path . join ( path , content ) <TAB><TAB><TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB><TAB><TAB><TAB> self . num_files = self . num_files + 1 <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . files . append ( file ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . find ( file )",if self . match_function ( file ) :,if self . match_function ( file ) :,100.0,100.00,True
4465,"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB><TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB><TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB><TAB> if not grade and not solution and not locked : <TAB><TAB><TAB> continue <TAB><TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB><TAB> if grade_id in ids : <TAB><TAB><TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB><TAB> ids . add ( grade_id )","if ""nbgrader"" not in cell . metadata :","if not cell . metadata [ ""nbgrader"" ] :",69.88123922665191,96.97,False
4466,"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB><TAB> self . _pos + = len ( chunk ) <TAB><TAB> if self . _pos < start : <TAB><TAB><TAB> continue <TAB><TAB> elif self . _pos == start : <TAB><TAB><TAB> return b "" "" <TAB><TAB> else : <TAB><TAB><TAB> chunk = chunk [ start - self . _pos : ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> chunk = chunk [ : stop - self . _pos ] <TAB><TAB><TAB><TAB> assert len ( chunk ) == stop - start <TAB><TAB><TAB> return chunk <TAB> else : <TAB><TAB> raise StopIteration ( )",if stop is not None and self . _pos > stop :,if self . _pos < stop :,79.5258264394867,95.97,False
4467,"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB><TAB> username = user [ 0 ] <TAB><TAB> settings = user [ 1 ] <TAB><TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB><TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB><TAB> if "" event "" in settings : <TAB><TAB><TAB> if "" joined "" in settings [ "" event "" ] : <TAB><TAB><TAB><TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _client . removeUser ( username ) <TAB><TAB> else : <TAB><TAB><TAB> self . _client . userlist . modUser ( username , room , file_ )","elif ""left"" in settings [ ""event"" ] :","elif ""removed"" in settings [ ""event"" ] :",99.12624956408497,98.91,False
4468,"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB><TAB> if case ( 0 ) : <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB><TAB> print ( "" zero "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" one or two "" ) <TAB><TAB> elif case ( 3 , 4 ) : <TAB><TAB><TAB> print ( "" three or four "" ) <TAB><TAB> else : <TAB><TAB><TAB> print ( "" default "" ) <TAB><TAB><TAB> print ( "" another "" )","elif case ( 1 , 2 ) :","elif case ( 1 , 3 ) :",73.71231510248136,98.57,False
4469,"def _populate ( ) : <TAB> for fname in glob . glob ( os . path . join ( os . path . dirname ( __file__ ) , "" data "" , "" *.json "" ) ) : <TAB><TAB> with open ( fname ) as inf : <TAB><TAB><TAB> data = json . load ( inf ) <TAB><TAB><TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB><TAB><TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB><TAB><TAB> for item in data : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> LOGGER . warning ( "" Repeated emoji  {} "" . format ( item [ "" key "" ] ) ) <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> TABLE [ item [ "" key "" ] ] = item [ "" value "" ]","if item [ ""key"" ] in TABLE :","if item [ ""type"" ] == ""emoji"" :",96.80817248030984,96.44,False
4470,"def slot_to_material ( bobject : bpy . types . Object , slot : bpy . types . MaterialSlot ) : <TAB> mat = slot . material <TAB> # Pick up backed material if present <TAB> if mat is not None : <TAB><TAB> baked_mat = mat . name + "" _ "" + bobject . name + "" _baked "" <TAB><TAB> <MASK> <TAB><TAB><TAB> mat = bpy . data . materials [ baked_mat ] <TAB> return mat",if baked_mat in bpy . data . materials :,if baked_mat in bpy . data . materials :,100.0,100.00,True
4471,"def __keyPress ( self , widget , event ) : <TAB> if event . key == "" G "" and event . modifiers & event . Modifiers . Control : <TAB><TAB> if not all ( hasattr ( p , "" isGanged "" ) for p in self . getPlugs ( ) ) : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __ungang ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . __gang ( ) <TAB><TAB> return True <TAB> return False",if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,"elif event . key == ""U"" :",62.80469120786084,87.70,False
4472,"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB><TAB> if isinstance ( result , str ) : <TAB><TAB><TAB> result = result . encode ( "" ascii "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB><TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB><TAB> if contains : <TAB><TAB><TAB> if eline not in rline : <TAB><TAB><TAB><TAB> return False <TAB><TAB> else : <TAB><TAB><TAB> if not rline . endswith ( eline ) : <TAB><TAB><TAB><TAB> return False <TAB> return True","if isinstance ( expected , str ) :","if isinstance ( expected , str ) :",100.0,100.00,True
4473,"def hosts_to_domains ( self , hosts , exclusions = [ ] ) : <TAB> domains = [ ] <TAB> for host in hosts : <TAB><TAB> elements = host . split ( "" . "" ) <TAB><TAB> # recursively walk through the elements <TAB><TAB> # extracting all possible (sub)domains <TAB><TAB> while len ( elements ) > = 2 : <TAB><TAB><TAB> # account for domains stored as hosts <TAB><TAB><TAB> if len ( elements ) == 2 : <TAB><TAB><TAB><TAB> domain = "" . "" . join ( elements ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> # drop the host element <TAB><TAB><TAB><TAB> domain = "" . "" . join ( elements [ 1 : ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> domains . append ( domain ) <TAB><TAB><TAB> del elements [ 0 ] <TAB> return domains",if domain not in domains + exclusions :,if domain not in exclusions :,98.71046362787537,98.61,False
4474,"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB><TAB> try : <TAB><TAB><TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB><TAB><TAB> request = self . send_queue . get ( True , 6.0 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> # Socket got closed and set to None in another thread... <TAB><TAB><TAB><TAB> self . socket . sendall ( request ) <TAB><TAB><TAB> if self . send_queue is not None : <TAB><TAB><TAB><TAB> self . send_queue . task_done ( ) <TAB><TAB> except queue . Empty : <TAB><TAB><TAB> pass <TAB><TAB> except OSError : <TAB><TAB><TAB> self . stop_event . set ( )",if self . socket is not None :,if request is not None :,98.04150324871065,98.05,False
4475,"def get_url_args ( self , item ) : <TAB> if self . url_args : <TAB><TAB> <MASK> <TAB><TAB><TAB> url_args = self . url_args ( item ) <TAB><TAB> else : <TAB><TAB><TAB> url_args = dict ( self . url_args ) <TAB><TAB> url_args [ "" id "" ] = item . id <TAB><TAB> return url_args <TAB> else : <TAB><TAB> return dict ( operation = self . label , id = item . id )","if hasattr ( self . url_args , ""__call__"" ) :",if callable ( self . url_args ) :,92.2948161435867,91.81,False
4476,"def list_projects ( self ) : <TAB> projects = [ ] <TAB> page = 1 <TAB> while True : <TAB><TAB> repos = self . _client . get ( <TAB><TAB><TAB> "" /user/repos "" , { "" sort "" : "" full_name "" , "" page "" : page , "" per_page "" : 100 } <TAB><TAB> ) <TAB><TAB> page + = 1 <TAB><TAB> for repo in repos : <TAB><TAB><TAB> projects . append ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" id "" : repo [ "" full_name "" ] , <TAB><TAB><TAB><TAB><TAB> "" name "" : repo [ "" full_name "" ] , <TAB><TAB><TAB><TAB><TAB> "" description "" : repo [ "" description "" ] , <TAB><TAB><TAB><TAB><TAB> "" is_private "" : repo [ "" private "" ] , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB> return projects",if len ( repos ) < 100 :,if page >= self . _max_pages :,95.55980328617888,96.50,False
4477,"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB><TAB> if script . startswith ( "" http "" ) : <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB><TAB> <MASK> <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB><TAB> else : <TAB><TAB><TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) )",elif subdir :,elif subdir :,100.0,100.00,True
4478,"def print_map ( node , l ) : <TAB> if node . title not in l : <TAB><TAB> l [ node . title ] = [ ] <TAB> for n in node . children : <TAB><TAB> <MASK> <TAB><TAB><TAB> w = { n . title : [ ] } <TAB><TAB><TAB> l [ node . title ] . append ( w ) <TAB><TAB><TAB> print_map ( n , w ) <TAB><TAB> else : <TAB><TAB><TAB> l [ node . title ] . append ( n . title )",if len ( n . children ) > 0 :,"if isinstance ( n , Tree ) :",90.38925945847355,94.18,False
4479,"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB><TAB> if isinstance ( results [ i ] , dict ) : <TAB><TAB><TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0","elif isinstance ( results [ i ] , list ) :","elif isinstance ( results [ i ] , list ) :",100.0,100.00,True
4480,"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if ( <TAB><TAB><TAB> v [ "" _class "" ] == "" Question "" <TAB><TAB><TAB> or v [ "" _class "" ] == "" Message "" <TAB><TAB><TAB> or v [ "" _class "" ] == "" Announcement "" <TAB><TAB> ) : <TAB><TAB><TAB> v [ "" admin "" ] = None <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",100.0,100.00,True
4481,"def qvec ( self ) : <TAB> #        if self.polrep != 'stokes': <TAB> #            raise Exception(""qvec is not defined unless self.polrep=='stokes'"") <TAB> qvec = np . array ( [ ] ) <TAB> if self . polrep == "" stokes "" : <TAB><TAB> qvec = self . _imdict [ "" Q "" ] <TAB> elif self . polrep == "" circ "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> qvec = np . real ( 0.5 * ( self . lrvec + self . rlvec ) ) <TAB> return qvec",if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,if self . lrvec and self . rlvec :,67.57534801396629,88.33,False
4482,"def display_value ( self , key , w ) : <TAB> if key == "" vdevices "" : <TAB><TAB> # Very special case <TAB><TAB> nids = [ n [ "" deviceID "" ] for n in self . get_value ( "" devices "" ) ] <TAB><TAB> for device in self . app . devices . values ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> b = Gtk . CheckButton ( device . get_title ( ) , False ) <TAB><TAB><TAB><TAB> b . set_tooltip_text ( device [ "" id "" ] ) <TAB><TAB><TAB><TAB> self [ "" vdevices "" ] . pack_start ( b , False , False , 0 ) <TAB><TAB><TAB><TAB> b . set_active ( device [ "" id "" ] in nids ) <TAB><TAB> self [ "" vdevices "" ] . show_all ( ) <TAB> else : <TAB><TAB> EditorDialog . display_value ( self , key , w )","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :","if device [ ""id"" ] :",96.42208607283929,93.65,False
4483,"def _set_xflux_setting ( self , * * kwargs ) : <TAB> for key , value in kwargs . items ( ) : <TAB><TAB> if key in self . _settings_map : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _set_xflux_screen_color ( value ) <TAB><TAB><TAB><TAB> self . _current_color = str ( value ) <TAB><TAB><TAB><TAB> # hackish - changing the current color unpauses xflux, <TAB><TAB><TAB><TAB> # must reflect that with state change <TAB><TAB><TAB><TAB> if self . state == self . states [ "" PAUSED "" ] : <TAB><TAB><TAB><TAB><TAB> self . state = self . states [ "" RUNNING "" ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _xflux . sendline ( self . _settings_map [ key ] + str ( value ) ) <TAB><TAB><TAB> self . _c ( )","if key == ""color"" :","if self . _settings_map [ key ] == ""screen_color"" :",95.41690183699654,94.96,False
4484,"def apply_acceleration ( self , veh_ids , acc ) : <TAB> """"""See parent class."""""" <TAB> # to hand the case of a single vehicle <TAB> if type ( veh_ids ) == str : <TAB><TAB> veh_ids = [ veh_ids ] <TAB><TAB> acc = [ acc ] <TAB> for i , vid in enumerate ( veh_ids ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> this_vel = self . get_speed ( vid ) <TAB><TAB><TAB> next_vel = max ( [ this_vel + acc [ i ] * self . sim_step , 0 ] ) <TAB><TAB><TAB> self . kernel_api . vehicle . slowDown ( vid , next_vel , 1e-3 )",if acc [ i ] is not None and vid in self . get_ids ( ) :,if acc [ i ] :,93.88399717600858,92.56,False
4485,"def largest_factor_relatively_prime ( a , b ) : <TAB> """"""Return the largest factor of a relatively prime to b."""""" <TAB> while 1 : <TAB><TAB> d = gcd ( a , b ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> b = d <TAB><TAB> while 1 : <TAB><TAB><TAB> q , r = divmod ( a , d ) <TAB><TAB><TAB> if r > 0 : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> a = q <TAB> return a",if d <= 1 :,if d < 0 :,75.94989891443589,97.75,False
4486,"def check_status ( self ) : <TAB> try : <TAB><TAB> du = psutil . disk_usage ( "" / "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ServiceWarning ( <TAB><TAB><TAB><TAB> "" {host}   {percent} % d isk usage exceeds  {disk_usage} % "" . format ( <TAB><TAB><TAB><TAB><TAB> host = host , percent = du . percent , disk_usage = DISK_USAGE_MAX <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> except ValueError as e : <TAB><TAB> self . add_error ( ServiceReturnedUnexpectedResult ( "" ValueError "" ) , e )",if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,if du . disk_usage > DISK_USAGE_MAX :,67.15099352511353,93.90,False
4487,"def build_reply ( self , msg , text = None , private = False , threaded = False ) : <TAB> response = self . build_message ( text ) <TAB> if msg . is_group : <TAB><TAB> <MASK> <TAB><TAB><TAB> response . frm = self . bot_identifier <TAB><TAB><TAB> response . to = IRCPerson ( str ( msg . frm ) ) <TAB><TAB> else : <TAB><TAB><TAB> response . frm = IRCRoomOccupant ( str ( self . bot_identifier ) , msg . frm . room ) <TAB><TAB><TAB> response . to = msg . frm . room <TAB> else : <TAB><TAB> response . frm = self . bot_identifier <TAB><TAB> response . to = msg . frm <TAB> return response",if private :,if private :,100.0,100.00,True
4488,"def _dict_refs ( obj , named ) : <TAB> """"""Return key and value objects of a dict/proxy."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> for k , v in _items ( obj ) : <TAB><TAB><TAB><TAB> s = str ( k ) <TAB><TAB><TAB><TAB> yield _NamedRef ( "" [K]  "" + s , k ) <TAB><TAB><TAB><TAB> yield _NamedRef ( "" [V]  "" + s + "" :  "" + _repr ( v ) , v ) <TAB><TAB> else : <TAB><TAB><TAB> for k , v in _items ( obj ) : <TAB><TAB><TAB><TAB> yield k <TAB><TAB><TAB><TAB> yield v <TAB> except ( KeyError , ReferenceError , TypeError ) as x : <TAB><TAB> warnings . warn ( "" Iterating  ' %s ' :  %r "" % ( _classof ( obj ) , x ) )",if named :,if named :,100.0,100.00,True
4489,"def fetch_images ( ) : <TAB> images = [ ] <TAB> marker = None <TAB> while True : <TAB><TAB> batch = image_service . detail ( <TAB><TAB><TAB> context , <TAB><TAB><TAB> filters = filters , <TAB><TAB><TAB> marker = marker , <TAB><TAB><TAB> sort_key = "" created_at "" , <TAB><TAB><TAB> sort_dir = "" desc "" , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> images + = batch <TAB><TAB> marker = batch [ - 1 ] [ "" id "" ] <TAB> return images",if not batch :,if not batch :,100.0,100.00,True
4490,"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB><TAB> if data_list [ 1 ] in forms . fields . EMPTY_VALUES : <TAB><TAB><TAB> error = self . error_messages [ "" invalid_year "" ] <TAB><TAB><TAB> raise forms . ValidationError ( error ) <TAB><TAB> <MASK> <TAB><TAB><TAB> error = self . error_messages [ "" invalid_month "" ] <TAB><TAB><TAB> raise forms . ValidationError ( error ) <TAB><TAB> year = int ( data_list [ 1 ] ) <TAB><TAB> month = int ( data_list [ 0 ] ) <TAB><TAB> # find last day of the month <TAB><TAB> day = monthrange ( year , month ) [ 1 ] <TAB><TAB> return date ( year , month , day ) <TAB> return None",if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,100.0,100.00,True
4491,"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB><TAB> if key not in new : <TAB><TAB><TAB> removed . append ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # modified is indicated by a remove and add <TAB><TAB><TAB> removed . append ( key ) <TAB><TAB><TAB> added . append ( key ) <TAB> for key , value in new . items ( ) : <TAB><TAB> if key not in old : <TAB><TAB><TAB> added . append ( key ) <TAB> if removed : <TAB><TAB> diff [ "" removed "" ] = sorted ( removed ) <TAB> if added : <TAB><TAB> diff [ "" added "" ] = sorted ( added ) <TAB> return diff",elif old [ key ] != new [ key ] :,if value is not None :,87.96615571549764,94.58,False
4492,"def add_filters ( self , function ) : <TAB> try : <TAB><TAB> subscription = self . exists ( function ) <TAB><TAB> <MASK> <TAB><TAB><TAB> response = self . _sns . call ( <TAB><TAB><TAB><TAB> "" set_subscription_attributes "" , <TAB><TAB><TAB><TAB> SubscriptionArn = subscription [ "" SubscriptionArn "" ] , <TAB><TAB><TAB><TAB> AttributeName = "" FilterPolicy "" , <TAB><TAB><TAB><TAB> AttributeValue = json . dumps ( self . filters ) , <TAB><TAB><TAB> ) <TAB><TAB><TAB> kappa . event_source . sns . LOG . debug ( response ) <TAB> except Exception : <TAB><TAB> kappa . event_source . sns . LOG . exception ( <TAB><TAB><TAB> "" Unable to add filters for SNS topic  %s "" , self . arn <TAB><TAB> )",if subscription :,if subscription :,100.0,100.00,True
4493,"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB><TAB> logger = logging . getLogger ( ) <TAB><TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB><TAB> for m in self . modules ( ) : <TAB><TAB><TAB> if isinstance ( m , nn . Conv2d ) : <TAB><TAB><TAB><TAB> kaiming_init ( m ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> constant_init ( m , 1 ) <TAB> else : <TAB><TAB> raise TypeError ( "" pretrained must be a str or None "" )","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :","elif isinstance ( m , nn . BatchNorm2d ) :",94.54816339312863,95.50,False
4494,def test_is_native_login ( self ) : <TAB> for campaign in self . campaign_lists : <TAB><TAB> native = campaigns . is_native_login ( campaign ) <TAB><TAB> <MASK> <TAB><TAB><TAB> assert_true ( native ) <TAB><TAB> else : <TAB><TAB><TAB> assert_false ( native ) <TAB> native = campaigns . is_proxy_login ( self . invalid_campaign ) <TAB> assert_true ( native is None ),"if campaign == ""prereg"" or campaign == ""erpc"" :",if campaigns . is_proxy_login ( self . invalid_campaign ) :,68.70687050288512,88.30,False
4495,"def _process_filter ( self , query , host_state ) : <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query : <TAB><TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB><TAB> if isinstance ( arg , list ) : <TAB><TAB><TAB> arg = self . _process_filter ( arg , host_state ) <TAB><TAB> <MASK> <TAB><TAB><TAB> arg = self . _parse_string ( arg , host_state ) <TAB><TAB> if arg is not None : <TAB><TAB><TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result","elif isinstance ( arg , basestring ) :","elif isinstance ( arg , str ) :",98.96329045495045,98.79,False
4496,"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if APP_CONFIG . nobuild_files . match ( f ) : <TAB><TAB><TAB> continue <TAB><TAB> files . append ( f ) <TAB><TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime","if not f . endswith ( "".go"" ) :","if f . startswith ( ""nt"" ) :",68.73468880148356,93.83,False
4497,"def ExcludePath ( self , path ) : <TAB> """"""Check to see if this is a service url and matches inbound_services."""""" <TAB> skip = False <TAB> for reserved_path in self . reserved_paths . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if ( <TAB><TAB><TAB><TAB> not self . inbound_services <TAB><TAB><TAB><TAB> or self . reserved_paths [ reserved_path ] not in self . inbound_services <TAB><TAB><TAB> ) : <TAB><TAB><TAB><TAB> return ( True , self . reserved_paths [ reserved_path ] ) <TAB> return ( False , None )",if path . startswith ( reserved_path ) :,if path . startswith ( reserved_path ) :,100.0,100.00,True
4498,"def param_cov ( self ) - > DataFrame : <TAB> """"""Parameter covariance"""""" <TAB> if self . _param_cov is not None : <TAB><TAB> param_cov = self . _param_cov <TAB> else : <TAB><TAB> params = np . asarray ( self . params ) <TAB><TAB> <MASK> <TAB><TAB><TAB> param_cov = self . model . compute_param_cov ( params ) <TAB><TAB> else : <TAB><TAB><TAB> param_cov = self . model . compute_param_cov ( params , robust = False ) <TAB> return DataFrame ( param_cov , columns = self . _names , index = self . _names )","if self . cov_type == ""robust"" :",if self . _robust :,78.30020139385472,94.83,False
4499,"def test_calculate_all_attentions ( module , atype ) : <TAB> m = importlib . import_module ( module ) <TAB> args = make_arg ( atype = atype ) <TAB> <MASK> <TAB><TAB> batch = prepare_inputs ( "" pytorch "" ) <TAB> else : <TAB><TAB> raise NotImplementedError <TAB> model = m . E2E ( 6 , 5 , args ) <TAB> with chainer . no_backprop_mode ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> att_ws = model . calculate_all_attentions ( * batch ) [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> raise NotImplementedError <TAB><TAB> print ( att_ws . shape )","if ""pytorch"" in module :","if isinstance ( module , ( list , tuple ) ) :",63.13325455346385,88.10,False
4500,"def __eq__ ( self , other ) : <TAB> try : <TAB><TAB> if self . type != other . type : <TAB><TAB><TAB> return False <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . askAnswer == other . askAnswer <TAB><TAB> elif self . type == "" SELECT "" : <TAB><TAB><TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB><TAB> else : <TAB><TAB><TAB> return self . graph == other . graph <TAB> except : <TAB><TAB> return False","if self . type == ""ASK"" :","if self . type == ""SELECT1"" :",73.53617082757967,98.42,False
4501,"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB><TAB> if v is None : # use NoneType to unset a value <TAB><TAB><TAB> continue <TAB><TAB> if not re . match ( PROCTYPE_MATCH , k ) : <TAB><TAB><TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise serializers . ValidationError ( <TAB><TAB><TAB><TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB> ) <TAB> return value","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :","if re . match ( LIMIT_MATCH , k ) :",70.0928063765036,94.11,False
4502,"def get_connections ( data_about ) : <TAB> data = data_about . find ( "" h3 "" , text = "" Connections "" ) . findNext ( ) <TAB> connections = { } <TAB> for row in data . find_all ( "" tr "" ) : <TAB><TAB> key = row . find_all ( "" td "" ) [ 0 ] . text <TAB><TAB> value = row . find_all ( "" td "" ) [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> connections [ key ] = get_all_links ( value ) <TAB><TAB> else : <TAB><TAB><TAB> connections [ key ] = value . text <TAB> return connections","if ""Teams"" in key :","if key == ""links"" :",80.17332173915536,95.95,False
4503,"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB><TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB><TAB> if second_byte == None : <TAB><TAB><TAB> return "" XED_ILD_MAP1 "" <TAB><TAB> if second_byte == 0x38 : <TAB><TAB><TAB> return "" XED_ILD_MAP2 "" <TAB><TAB> if second_byte == 0x3A : <TAB><TAB><TAB> return "" XED_ILD_MAP3 "" <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) )",if second_byte == 0x0F and self . amd_enabled :,if second_byte == 0x5E :,94.43650133564803,95.84,False
4504,"def compress ( self , data_list ) : <TAB> if data_list : <TAB><TAB> page_id = data_list [ 1 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if not self . required : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB><TAB> return Page . objects . get ( pk = page_id ) <TAB> return None",if page_id in EMPTY_VALUES :,if page_id not in Page . objects :,66.82903578558064,95.12,False
4505,"def find_module ( self , fullname , path = None ) : <TAB> path = path or self . path_entry <TAB> # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB> for _ext in [ "" js "" , "" pyj "" , "" py "" ] : <TAB><TAB> _filepath = os . path . join ( self . path_entry , "" %s . %s "" % ( fullname , _ext ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" module found at  %s : %s "" % ( _filepath , fullname ) ) <TAB><TAB><TAB> return VFSModuleLoader ( _filepath , fullname ) <TAB> print ( "" module  %s  not found "" % fullname ) <TAB> raise ImportError ( ) <TAB> return None",if _filepath in VFS :,if os . path . exists ( _filepath ) :,97.24626919264836,95.05,False
4506,"def __decToBin ( self , myDec ) : <TAB> n = 0 <TAB> binOfDec = "" "" <TAB> while myDec > 2 * * n : <TAB><TAB> n = n + 1 <TAB> if ( myDec < 2 * * n ) & ( myDec != 0 ) : <TAB><TAB> n = n - 1 <TAB> while n > = 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> myDec = myDec - 2 * * n <TAB><TAB><TAB> binOfDec = binOfDec + "" 1 "" <TAB><TAB> else : <TAB><TAB><TAB> binOfDec = binOfDec + "" 0 "" <TAB><TAB> n = n - 1 <TAB> return binOfDec",if myDec >= 2 ** n :,if myDec == 2 ** n :,98.81832888151484,98.54,False
4507,"def __str__ ( self ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> NVMLError . _errcode_to_string [ self . value ] = str ( nvmlErrorString ( self . value ) ) <TAB><TAB> return NVMLError . _errcode_to_string [ self . value ] <TAB> except NVMLError_Uninitialized : <TAB><TAB> return "" NVML Error with code  %d "" % self . value",if self . value not in NVMLError . _errcode_to_string :,if self . value not in NVMLError . _errcode_to_string :,100.0,100.00,True
4508,"def abspath ( pathdir : str ) - > str : <TAB> if Path is not None and isinstance ( pathdir , Path ) : <TAB><TAB> return pathdir . abspath ( ) <TAB> else : <TAB><TAB> pathdir = path . abspath ( pathdir ) <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> pathdir = pathdir . decode ( fs_encoding ) <TAB><TAB><TAB> except UnicodeDecodeError as exc : <TAB><TAB><TAB><TAB> raise UnicodeDecodeError ( <TAB><TAB><TAB><TAB><TAB> "" multibyte filename not supported on  "" <TAB><TAB><TAB><TAB><TAB> "" this filesystem encoding  "" <TAB><TAB><TAB><TAB><TAB> "" ( %r ) "" % fs_encoding <TAB><TAB><TAB><TAB> ) from exc <TAB><TAB> return pathdir","if isinstance ( pathdir , bytes ) :",if fs_encoding is not None :,73.01521697142238,96.63,False
4509,"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isfile ( self . object ) : <TAB><TAB><TAB><TAB> with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB> vtkjs = f . read ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB> vtkjs = data_url . read ( ) <TAB><TAB> elif hasattr ( self . object , "" read "" ) : <TAB><TAB><TAB> vtkjs = self . object . read ( ) <TAB><TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :","if hasattr ( self . object , ""read"" ) :",92.18413732936627,92.19,False
4510,"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB><TAB> if pwd is None : <TAB><TAB><TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB><TAB><TAB> val = None <TAB><TAB> <MASK> <TAB><TAB><TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val","elif isinstance ( val , text_or_bytes ) :",elif pwd . is_available ( val ) :,78.08277823375163,91.95,False
4511,"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB><TAB> if node_settings is None : <TAB><TAB><TAB> continue <TAB><TAB> if node_settings . external_account == external_account : <TAB><TAB><TAB> yield node",if node is None :,if not node . is_attached ( external_account ) :,76.51790296938323,91.68,False
4512,"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB><TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB><TAB> if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes : <TAB><TAB><TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> box_keys = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> mask_keys = [ ] <TAB><TAB> return cls ( box_keys , mask_keys )","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",100.0,100.00,True
4513,"def write ( self , * bits ) : <TAB> for bit in bits : <TAB><TAB> if not self . bytestream : <TAB><TAB><TAB> self . bytestream . append ( 0 ) <TAB><TAB> byte = self . bytestream [ self . bytenum ] <TAB><TAB> if self . bitnum == 8 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> byte = 0 <TAB><TAB><TAB><TAB> self . bytestream + = bytes ( [ byte ] ) <TAB><TAB><TAB> self . bytenum + = 1 <TAB><TAB><TAB> self . bitnum = 0 <TAB><TAB> mask = 2 * * self . bitnum <TAB><TAB> if bit : <TAB><TAB><TAB> byte | = mask <TAB><TAB> else : <TAB><TAB><TAB> byte & = ~ mask <TAB><TAB> self . bytestream [ self . bytenum ] = byte <TAB><TAB> self . bitnum + = 1",if self . bytenum == len ( self . bytestream ) - 1 :,if not byte :,66.47891069335947,94.16,False
4514,"def destroy ( self , wipe = False ) : <TAB> if self . state == self . UP : <TAB><TAB> image = self . image ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . confirm_destroy ( image , self . full_name , abort = False ) <TAB><TAB> else : <TAB><TAB><TAB> self . warn ( "" tried to destroy  {0}  which didn ' t exist "" . format ( self . full_name ) ) <TAB> return True",if image :,if image :,100.0,100.00,True
4515,"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB><TAB> try : <TAB><TAB><TAB> resp = requests . get ( <TAB><TAB><TAB><TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB><TAB><TAB> ) . json ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB><TAB><TAB><TAB> if match is not None and len ( match . groups ( ) ) == 1 : <TAB><TAB><TAB><TAB><TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta","if ""Version"" in resp :","if resp . get ( ""Status"" ) == 200 :",69.5242730534608,95.30,False
4516,"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB><TAB> <MASK> <TAB><TAB><TAB> parts . append ( "" file "" ) <TAB><TAB> elif stat . S_ISDIR ( st . st_mode ) : <TAB><TAB><TAB> parts . append ( "" dir "" ) <TAB><TAB> else : <TAB><TAB><TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB><TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB><TAB><TAB> parts . append ( "" link "" ) <TAB> return ""   "" . join ( parts )",if stat . S_ISREG ( st . st_mode ) :,if stat . S_ISFILE ( st . st_mode ) :,98.76093450335743,98.57,False
4517,"def changed ( self , action ) : <TAB> # Something was changed in the 'files' list <TAB> if len ( action . key ) > = 1 and action . key [ 0 ] . lower ( ) == "" files "" : <TAB><TAB> # Refresh project files model <TAB><TAB> <MASK> <TAB><TAB><TAB> # Don't clear the existing items if only inserting new things <TAB><TAB><TAB> self . update_model ( clear = False ) <TAB><TAB> else : <TAB><TAB><TAB> # Clear existing items <TAB><TAB><TAB> self . update_model ( clear = True )","if action . type == ""insert"" :",if self . _is_new_files ( ) :,71.74530516194186,92.75,False
4518,"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( "" es "" ) <TAB> for r in resources : <TAB><TAB> <MASK> <TAB><TAB><TAB> result = self . manager . retry ( <TAB><TAB><TAB><TAB> client . describe_elasticsearch_domain_config , <TAB><TAB><TAB><TAB> DomainName = r [ "" DomainName "" ] , <TAB><TAB><TAB><TAB> ignore_err_codes = ( "" ResourceNotFoundException "" , ) , <TAB><TAB><TAB> ) <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> r [ self . policy_attribute ] = json . loads ( <TAB><TAB><TAB><TAB><TAB> result . get ( "" DomainConfig "" ) . get ( "" AccessPolicies "" ) . get ( "" Options "" ) <TAB><TAB><TAB><TAB> ) <TAB> return super ( ) . process ( resources )",if self . policy_attribute not in r :,if self . policy_attribute not in r :,100.0,100.00,True
4519,"def line_items ( self ) : <TAB> line_items = [ ] <TAB> for line in self . lines_str : <TAB><TAB> line = line . split ( "" | "" ) <TAB><TAB> line = line [ 1 : - 1 ] # del first and last empty item (consequence of split) <TAB><TAB> items = [ ] <TAB><TAB> for item in line : <TAB><TAB><TAB> i = re . search ( r "" ( \ S+([  \ t]+ \ S+)*)+ "" , item ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> items . append ( i . group ( ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> items . append ( ""   "" ) <TAB><TAB> line_items . append ( items ) <TAB> return line_items",if i :,if i :,100.0,100.00,True
4520,"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB><TAB> return <TAB> if args . strings and not args . no_content : <TAB><TAB> if type ( res ) == tuple : <TAB><TAB><TAB> f , v = res <TAB><TAB><TAB> if type ( f ) == unicode : <TAB><TAB><TAB><TAB> f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB> if type ( v ) == unicode : <TAB><TAB><TAB><TAB> v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . success ( res ) <TAB> else : <TAB><TAB> self . success ( res )",elif not args . content_only :,elif args . strings :,95.85031909557571,96.97,False
4521,"def get_servers ( self , detail = True , search_opts = None ) : <TAB> rel_url = "" /servers/detail "" if detail else "" /servers "" <TAB> if search_opts is not None : <TAB><TAB> qparams = { } <TAB><TAB> for opt , val in search_opts . iteritems ( ) : <TAB><TAB><TAB> qparams [ opt ] = val <TAB><TAB> <MASK> <TAB><TAB><TAB> query_string = "" ? %s "" % urllib . urlencode ( qparams ) <TAB><TAB><TAB> rel_url + = query_string <TAB> return self . api_get ( rel_url ) [ "" servers "" ]",if qparams :,if qparams :,100.0,100.00,True
4522,"def run ( self ) : <TAB> while not self . __exit__ : <TAB><TAB> <MASK> <TAB><TAB><TAB> sleep ( 10 ) <TAB><TAB><TAB> continue <TAB><TAB> o = self . playlist [ 0 ] <TAB><TAB> self . playlist . remove ( o ) <TAB><TAB> obj = json . loads ( o ) <TAB><TAB> if not "" args "" in obj : <TAB><TAB><TAB> obj [ "" args "" ] = { "" ua "" : "" "" , "" header "" : "" "" , "" title "" : "" "" , "" referer "" : "" "" } <TAB><TAB> obj [ "" play "" ] = False <TAB><TAB> self . handle = launch_player ( obj [ "" urls "" ] , obj [ "" ext "" ] , * * obj [ "" args "" ] ) <TAB><TAB> self . handle . wait ( )",if len ( self . playlist ) == 0 :,if self . __exit__ :,94.2428589064653,95.61,False
4523,"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB><TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB><TAB> <MASK> <TAB><TAB><TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB><TAB><TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB><TAB><TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB><TAB><TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB><TAB><TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB><TAB><TAB> time . sleep ( 1 ) # spider rule <TAB><TAB><TAB> if not last_date : <TAB><TAB><TAB><TAB> break <TAB> return result",if r . ok :,if r . status_code == 200 :,77.13581920727714,97.32,False
4524,"def __saveWork ( self , work , results ) : <TAB> """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> __cached = self . __cache [ results [ 0 ] ] <TAB><TAB><TAB> __cached [ self . __TIME ] = time . time ( ) <TAB><TAB><TAB> __cached [ self . __LINE ] = results [ 1 ] <TAB><TAB><TAB> __cached [ self . __LLU ] = results [ 2 ] <TAB> except KeyError as e : <TAB><TAB> # Could happen while switching jobs with work in the queue <TAB><TAB> pass <TAB> except Exception as e : <TAB><TAB> list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) )",if results :,if results [ 0 ] in self . __cache :,98.16163384028465,95.44,False
4525,"def read_notes ( rec ) : <TAB> found = [ ] <TAB> for tag in range ( 500 , 595 ) : <TAB><TAB> if tag in ( 505 , 520 ) : <TAB><TAB><TAB> continue <TAB><TAB> fields = rec . get_fields ( str ( tag ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> for f in fields : <TAB><TAB><TAB> x = f . get_lower_subfields ( ) <TAB><TAB><TAB> if x : <TAB><TAB><TAB><TAB> found . append ( ""   "" . join ( x ) . strip ( ""   "" ) ) <TAB> if found : <TAB><TAB> return "" \n \n "" . join ( found )",if not fields :,if not fields :,100.0,100.00,True
4526,"def serialize_to ( self , stream , alternate_script = None ) : <TAB> stream . write ( self . txo_ref . tx_ref . hash ) <TAB> stream . write_uint32 ( self . txo_ref . position ) <TAB> if alternate_script is not None : <TAB><TAB> stream . write_string ( alternate_script ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> stream . write_string ( self . coinbase ) <TAB><TAB> else : <TAB><TAB><TAB> stream . write_string ( self . script . source ) <TAB> stream . write_uint32 ( self . sequence )",if self . is_coinbase :,if self . coinbase is not None :,96.0039295153184,96.81,False
4527,"def func_named ( self , arg ) : <TAB> result = None <TAB> target = "" do_ "" + arg <TAB> if target in dir ( self ) : <TAB><TAB> result = target <TAB> else : <TAB><TAB> <MASK> # accept shortened versions of commands <TAB><TAB><TAB> funcs = [ fname for fname in self . keywords if fname . startswith ( arg ) ] <TAB><TAB><TAB> if len ( funcs ) == 1 : <TAB><TAB><TAB><TAB> result = "" do_ "" + funcs [ 0 ] <TAB> return result",if self . abbrev :,if arg in self . keywords :,64.9949010340447,95.94,False
4528,"def static_login ( self , token , * , bot ) : <TAB> # Necessary to get aiohttp to stop complaining about session creation <TAB> self . __session = aiohttp . ClientSession ( <TAB><TAB> connector = self . connector , ws_response_class = DiscordClientWebSocketResponse <TAB> ) <TAB> old_token , old_bot = self . token , self . bot_token <TAB> self . _token ( token , bot = bot ) <TAB> try : <TAB><TAB> data = await self . request ( Route ( "" GET "" , "" /users/@me "" ) ) <TAB> except HTTPException as exc : <TAB><TAB> self . _token ( old_token , bot = old_bot ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise LoginFailure ( "" Improper token has been passed. "" ) from exc <TAB><TAB> raise <TAB> return data",if exc . response . status == 401 :,"if ""Authentication failed"" in str ( exc ) :",71.98617808104206,95.12,False
4529,"def render_buttons ( self ) : <TAB> for x , button in enumerate ( self . button_list ) : <TAB><TAB> gcolor = Gdk . color_parse ( self . color_list [ x ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fgcolor = Gdk . color_parse ( "" #FFFFFF "" ) <TAB><TAB> else : <TAB><TAB><TAB> fgcolor = Gdk . color_parse ( "" #000000 "" ) <TAB><TAB> button . set_label ( self . color_list [ x ] ) <TAB><TAB> button . set_sensitive ( True ) <TAB><TAB> button . modify_bg ( Gtk . StateType . NORMAL , gcolor ) <TAB><TAB> button . modify_fg ( Gtk . StateType . NORMAL , fgcolor )","if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",if x == 0 :,74.5917008488312,87.77,False
4530,"def _set_text ( self , data ) : <TAB> lines = [ ] <TAB> for key , value in data . items ( ) : <TAB><TAB> lines . append ( "" "" ) <TAB><TAB> txt = yaml . dump ( { key : value } , default_flow_style = False ) <TAB><TAB> title = self . titles . get ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> lines . append ( "" #  %s "" % title ) <TAB><TAB> lines . append ( txt . rstrip ( ) ) <TAB> txt = "" \n "" . join ( lines ) + "" \n "" <TAB> txt = txt . lstrip ( ) <TAB> self . edit . setPlainText ( txt )",if title :,if title :,100.0,100.00,True
4531,"def build_path ( self ) : <TAB> for variable in re_path_template . findall ( self . path ) : <TAB><TAB> name = variable . strip ( "" {} "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # No 'user' parameter provided, fetch it from Auth instead. <TAB><TAB><TAB> value = self . api . auth . get_username ( ) <TAB><TAB> else : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> value = quote ( self . session . params [ name ] ) <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> raise TweepError ( <TAB><TAB><TAB><TAB><TAB> "" No parameter value found for path variable:  %s "" % name <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> del self . session . params [ name ] <TAB><TAB> self . path = self . path . replace ( variable , value )","if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",if not name :,83.19384017007458,90.76,False
4532,"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> prop_vals = entity [ prop_name ] <TAB><TAB><TAB> if isinstance ( prop_vals , ( list ) ) : <TAB><TAB><TAB><TAB> num_prop_vals = len ( prop_vals ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> num_prop_vals = 1 <TAB><TAB><TAB> writes + = 2 * num_prop_vals <TAB> return writes",if not prop_name in entity . unindexed_properties ( ) :,"if not prop_name . startswith ( ""_"" ) :",69.73941614978496,95.57,False
4533,"def create_connection ( self , address , protocol_factory = None , * * kw ) : <TAB> """"""Helper method for creating a connection to an ``address``."""""" <TAB> protocol_factory = protocol_factory or self . create_protocol <TAB> if isinstance ( address , tuple ) : <TAB><TAB> host , port = address <TAB><TAB> <MASK> <TAB><TAB><TAB> self . logger . debug ( "" Create connection  %s : %s "" , host , port ) <TAB><TAB> _ , protocol = await self . _loop . create_connection ( <TAB><TAB><TAB> protocol_factory , host , port , * * kw <TAB><TAB> ) <TAB><TAB> await protocol . event ( "" connection_made "" ) <TAB> else : <TAB><TAB> raise NotImplementedError ( "" Could not connect to  %s "" % str ( address ) ) <TAB> return protocol",if self . debug :,if self . _loop . is_running ( ) :,72.59275208866464,95.75,False
4534,def _increment_bracket_num ( self ) : <TAB> self . _current_bracket - = 1 <TAB> if self . _current_bracket < 0 : <TAB><TAB> self . _current_bracket = self . _get_num_brackets ( ) - 1 <TAB><TAB> self . _current_iteration + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _current_bracket = 0,if self . _current_iteration > self . hyperband_iterations :,if self . _current_bracket > self . _get_num_brackets ( ),62.80314574248249,89.77,False
4535,"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB><TAB> path = self . get_cycle_path ( <TAB><TAB><TAB> self . get_by_address ( dep ) , goal_node_index <TAB><TAB> ) # self.nodelist[dep], goal_node_index) <TAB><TAB> if len ( path ) > 0 : <TAB><TAB><TAB> path . insert ( 0 , curr_node [ "" address "" ] ) <TAB><TAB><TAB> return path <TAB> return [ ]",if dep == goal_node_index :,"if dep == curr_node [ ""address"" ] :",95.15753007046823,95.71,False
4536,"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB><TAB> return None <TAB> for item in dirs : <TAB><TAB> if item . endswith ( "" / "" ) : <TAB><TAB><TAB> records = as_dict ( path + item , version , section ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ item [ : - 1 ] ] = records <TAB><TAB> elif is_dict . match ( item ) : <TAB><TAB><TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB><TAB><TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result [ name ] = records <TAB><TAB> else : <TAB><TAB><TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result",if records :,if records :,100.0,100.00,True
4537,"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB><TAB> with open ( output_filename , "" w "" ) as f2 : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> line = f1 . readline ( ) <TAB><TAB><TAB><TAB> if not line : <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB><TAB><TAB><TAB> if line != ""   "" and line != "" "" : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> line = line [ 1 : ] <TAB><TAB><TAB><TAB><TAB> f2 . writelines ( line + "" \n "" )","if line [ 0 ] == "" "" :","if line [ 0 ] == ""\n"" :",96.29313791600414,98.58,False
4538,"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB><TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> index = i <TAB><TAB><TAB><TAB> break <TAB><TAB> if index is not None : <TAB><TAB><TAB> del self . _subscribers [ index ] <TAB><TAB> if not self . _subscribers : <TAB><TAB><TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) )",if subscriber_web_sock == web_sock :,if web_sock == subscriber_web_sock :,97.6005023663768,98.23,False
4539,"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB><TAB> s = month_name [ themonth ] <TAB><TAB> if encoding is not None : <TAB><TAB><TAB> s = s . decode ( encoding ) <TAB><TAB> <MASK> <TAB><TAB><TAB> s = "" %s   %s "" % ( s , theyear ) <TAB><TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s",if withyear :,if withyear :,100.0,100.00,True
4540,"def generate_sitemaps ( filename ) : <TAB> rows = ( line . strip ( ) . split ( "" \t "" ) for line in open ( filename ) ) <TAB> for sortkey , chunk in itertools . groupby ( rows , lambda row : row [ 0 ] ) : <TAB><TAB> things = [ ] <TAB><TAB> _chunk = list ( chunk ) <TAB><TAB> for segment in _chunk : <TAB><TAB><TAB> sortkey = segment . pop ( 0 ) <TAB><TAB><TAB> last_modified = segment . pop ( - 1 ) <TAB><TAB><TAB> path = "" "" . join ( segment ) <TAB><TAB><TAB> things . append ( web . storage ( path = path , last_modified = last_modified ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> write ( "" sitemaps/sitemap_ %s .xml.gz "" % sortkey , sitemap ( things ) )",if things :,if things :,100.0,100.00,True
4541,"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _use_indexes . append ( t ) <TAB><TAB> elif isinstance ( t , str ) : <TAB><TAB><TAB> self . _use_indexes . append ( Index ( t ) )","if isinstance ( t , Index ) :","if isinstance ( t , Index ) :",100.0,100.00,True
4542,"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB><TAB> result = self . _get_node_text ( self . ast ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> return result <TAB> else : <TAB><TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB><TAB> last_end = - 1 <TAB><TAB> for match in self . matches : <TAB><TAB><TAB> start , end = match . get_region ( ) <TAB><TAB><TAB> if start < last_end : <TAB><TAB><TAB><TAB> if not self . _is_expression ( ) : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> last_end = end <TAB><TAB><TAB> replacement = self . _get_matched_text ( match ) <TAB><TAB><TAB> collector . add_change ( start , end , replacement ) <TAB><TAB> return collector . get_changed ( )",if result == self . source :,if result is None :,85.49735750665889,97.55,False
4543,"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB><TAB> if value . has_form ( "" List "" , None ) : <TAB><TAB><TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> return value <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> else : <TAB><TAB> value = extract_pyreal ( value ) <TAB><TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB><TAB><TAB> return None <TAB><TAB> return value",if any ( item is None for item in value ) :,if value is None or isinf ( value ) or isnan ( value ) :,84.34353020376024,95.13,False
4544,"def _reemit_nested_event ( self , event : Event ) : <TAB> source_index = self . index ( event . source ) <TAB> for attr in ( "" index "" , "" new_index "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> src_index = ensure_tuple_index ( event . index ) <TAB><TAB><TAB> setattr ( event , attr , ( source_index , ) + src_index ) <TAB> if not hasattr ( event , "" index "" ) : <TAB><TAB> setattr ( event , "" index "" , source_index ) <TAB> # reemit with this object's EventEmitter of the same type if present <TAB> # otherwise just emit with the EmitterGroup itself <TAB> getattr ( self . events , event . type , self . events ) ( event )","if hasattr ( event , attr ) :","if hasattr ( event , attr ) :",100.0,100.00,True
4545,"def check ( self ) : <TAB> """"""Perform required checks to conclude if it's safe to operate"""""" <TAB> if self . interpreter . manual is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . error = self . process . error <TAB><TAB><TAB> self . tip = self . process . tip <TAB><TAB><TAB> return False <TAB> start = time . time ( ) <TAB> while not self . _status ( ) : <TAB><TAB> if time . time ( ) - start > = 2 : # 2s <TAB><TAB><TAB> self . error = "" can ' t connect to the minserver on  {} : {} "" . format ( <TAB><TAB><TAB><TAB> self . interpreter . host , self . interpreter . port <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . tip = "" check your vagrant machine is running "" <TAB><TAB><TAB> return False <TAB><TAB> time . sleep ( 0.1 ) <TAB> return True",if not self . process . healthy :,if self . process . error :,83.32286273369547,98.01,False
4546,"def apply ( self ) : <TAB> new_block = self . block . copy ( ) <TAB> new_block . clear ( ) <TAB> for inst in self . block . body : <TAB><TAB> <MASK> <TAB><TAB><TAB> const_assign = self . _assign_const ( inst ) <TAB><TAB><TAB> new_block . append ( const_assign ) <TAB><TAB><TAB> inst = self . _assign_getitem ( inst , index = const_assign . target ) <TAB><TAB> new_block . append ( inst ) <TAB> return new_block","if isinstance ( inst , Assign ) and inst . value in self . getattrs :","if isinstance ( inst , ( Constant , ConstantList ) ) :",88.19362438181685,92.60,False
4547,"def _get_orientation ( self ) : <TAB> if self . state : <TAB><TAB> rotation = [ 0 ] * 9 <TAB><TAB> inclination = [ 0 ] * 9 <TAB><TAB> gravity = [ ] <TAB><TAB> geomagnetic = [ ] <TAB><TAB> gravity = self . listener_a . values <TAB><TAB> geomagnetic = self . listener_m . values <TAB><TAB> <MASK> <TAB><TAB><TAB> ff_state = SensorManager . getRotationMatrix ( <TAB><TAB><TAB><TAB> rotation , inclination , gravity , geomagnetic <TAB><TAB><TAB> ) <TAB><TAB><TAB> if ff_state : <TAB><TAB><TAB><TAB> values = [ 0 , 0 , 0 ] <TAB><TAB><TAB><TAB> values = SensorManager . getOrientation ( rotation , values ) <TAB><TAB><TAB> return values",if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,"if self . listener_a . state == ""F"" and self . listener_m .",63.884295813899385,91.25,False
4548,def getFirstSubGraph ( graph ) : <TAB> if len ( graph ) == 0 : <TAB><TAB> return None <TAB> subg = { } <TAB> todo = [ graph . keys ( ) [ 0 ] ] <TAB> while len ( todo ) > 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> subg [ todo [ 0 ] ] = graph [ todo [ 0 ] ] <TAB><TAB><TAB> todo . extend ( graph [ todo [ 0 ] ] ) <TAB><TAB><TAB> del graph [ todo [ 0 ] ] <TAB><TAB> del todo [ 0 ] <TAB> return subg,if todo [ 0 ] in graph . keys ( ) :,if graph [ todo [ 0 ] ] is not None :,93.19220559608033,94.27,False
4549,"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB><TAB> try : <TAB><TAB><TAB> result = date <TAB><TAB><TAB> if callable ( result ) : <TAB><TAB><TAB><TAB> result = result ( rv ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> from werkzeug . http import http_date <TAB><TAB><TAB><TAB> result = http_date ( result ) <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> rv . headers [ "" Last-Modified "" ] = result <TAB><TAB> except Exception : <TAB><TAB><TAB> logging . getLogger ( __name__ ) . exception ( <TAB><TAB><TAB><TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB><TAB><TAB><TAB><TAB> rv <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return rv","if not isinstance ( result , basestring ) :","elif isinstance ( result , datetime ) :",70.1148312439698,97.91,False
4550,"def set_invoice_details ( self , row ) : <TAB> invoice_details = self . invoice_details . get ( row . voucher_no , { } ) <TAB> if row . due_date : <TAB><TAB> invoice_details . pop ( "" due_date "" , None ) <TAB> row . update ( invoice_details ) <TAB> if row . voucher_type == "" Sales Invoice "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_delivery_notes ( row ) <TAB><TAB> if self . filters . show_sales_person and row . sales_team : <TAB><TAB><TAB> row . sales_person = "" ,  "" . join ( row . sales_team ) <TAB><TAB><TAB> del row [ "" sales_team "" ]",if self . filters . show_delivery_notes :,if row . delivery_notes :,95.85105951607036,96.28,False
4551,"def process ( output ) : <TAB> modules = { } <TAB> for line in output : <TAB><TAB> name , size , instances , depends , state , _ = line . split ( ""   "" , 5 ) <TAB><TAB> instances = int ( instances ) <TAB><TAB> module = { <TAB><TAB><TAB> "" size "" : size , <TAB><TAB><TAB> "" instances "" : instances , <TAB><TAB><TAB> "" state "" : state , <TAB><TAB> } <TAB><TAB> <MASK> <TAB><TAB><TAB> module [ "" depends "" ] = [ value for value in depends . split ( "" , "" ) if value ] <TAB><TAB> modules [ name ] = module <TAB> return modules","if depends != ""-"" :",if depends :,70.58468422836668,96.42,False
4552,"def _get_host_from_zc_service_info ( service_info : zeroconf . ServiceInfo ) : <TAB> """"""Get hostname or IP + port from zeroconf service_info."""""" <TAB> host = None <TAB> port = None <TAB> if ( <TAB><TAB> service_info <TAB><TAB> and service_info . port <TAB><TAB> and ( service_info . server or len ( service_info . addresses ) > 0 ) <TAB> ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> host = socket . inet_ntoa ( service_info . addresses [ 0 ] ) <TAB><TAB> else : <TAB><TAB><TAB> host = service_info . server . lower ( ) <TAB><TAB> port = service_info . port <TAB> return ( host , port )",if len ( service_info . addresses ) > 0 :,"if service_info . server . lower ( ) == ""localhost"" :",69.92052657100729,93.99,False
4553,"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB><TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB> if module . bias is not None : <TAB><TAB><TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB><TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB><TAB> <MASK> <TAB><TAB><TAB> module . weight . data [ module . padding_idx ] . zero_ ( )",if module . padding_idx is not None :,if module . padding_idx is not None :,75.0,100.00,True
4554,"def visitFromImport ( self , import_stmt , import_info ) : <TAB> new_pairs = [ ] <TAB> if not import_info . is_star_import ( ) : <TAB><TAB> for name , alias in import_info . names_and_aliases : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> pyname = self . pymodule [ alias or name ] <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> except exceptions . AttributeNotFoundError : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> new_pairs . append ( ( name , alias ) ) <TAB> return importinfo . FromImport ( import_info . module_name , import_info . level , new_pairs )","if occurrences . same_pyname ( self . pyname , pyname ) :",if pyname in self . _pymodule_aliases :,75.17181168954492,94.10,False
4555,"def _apply_patches ( self ) : <TAB> try : <TAB><TAB> s = Subprocess ( <TAB><TAB><TAB> log = self . logfile , cwd = self . build_dir , verbose = self . options . verbose <TAB><TAB> ) <TAB><TAB> for patch in self . patches : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for ed , source in patch . items ( ) : <TAB><TAB><TAB><TAB><TAB> s . shell ( "" ed -  %s  <  %s "" % ( source , ed ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> s . shell ( "" patch -p0 <  %s "" % patch ) <TAB> except : <TAB><TAB> logger . error ( "" Failed to patch ` %s `. \n %s "" % ( self . build_dir , sys . exc_info ( ) [ 1 ] ) ) <TAB><TAB> sys . exit ( 1 )",if type ( patch ) is dict :,"if isinstance ( patch , dict ) :",93.58100133355795,97.44,False
4556,"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB><TAB> if i == "" . "" or i == "" .. "" : <TAB><TAB><TAB> continue <TAB><TAB> path = os . path . join ( dir , i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> dirlist . append ( i ) <TAB><TAB><TAB> continue <TAB><TAB> path = path . upper ( ) <TAB><TAB> value = i . upper ( ) <TAB><TAB> if pattern . match ( value ) is not None : <TAB><TAB><TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB><TAB> self . dirs = dirlist",if os . path . isdir ( path ) :,if path . startswith ( parent ) :,71.99956462118823,97.17,False
4557,"def remove_invalid_dirs ( paths , bp_dir , module_name ) : <TAB> ret = [ ] <TAB> for path in paths : <TAB><TAB> <MASK> <TAB><TAB><TAB> ret . append ( path ) <TAB><TAB> else : <TAB><TAB><TAB> logging . warning ( ' Dir  "" %s ""  of module  "" %s ""  does not exist ' , path , module_name ) <TAB> return ret","if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",if os . path . exists ( path ) and not os . path . exists ( path ),57.788894163292085,88.89,False
4558,"def update_sockets ( self ) : <TAB> inputs = self . inputs <TAB> inputs_n = "" ABabcd "" <TAB> penta_sockets = pentagon_dict [ self . grid_type ] . input_sockets <TAB> for socket in inputs_n : <TAB><TAB> if socket in penta_sockets : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> inputs [ socket ] . hide_safe = False <TAB><TAB> else : <TAB><TAB><TAB> inputs [ socket ] . hide_safe = True",if inputs [ socket ] . hide_safe :,if not inputs [ socket ] . hide_safe :,93.45178353791736,98.17,False
4559,"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i , char in enumerate ( sentence ) : <TAB><TAB> pos = pos_list [ i ] <TAB><TAB> if pos == "" B "" : <TAB><TAB><TAB> begin = i <TAB><TAB> elif pos == "" E "" : <TAB><TAB><TAB> yield sentence [ begin : i + 1 ] <TAB><TAB><TAB> nexti = i + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> yield char <TAB><TAB><TAB> nexti = i + 1 <TAB> if nexti < len ( sentence ) : <TAB><TAB> yield sentence [ nexti : ]","elif pos == ""S"" :","elif pos == ""F"" :",99.00239803152061,98.88,False
4560,"def validate ( self ) : <TAB> if self . data . get ( "" encrypted "" , True ) : <TAB><TAB> key = self . data . get ( "" target_key "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise PolicyValidationError ( <TAB><TAB><TAB><TAB> "" Encrypted snapshot copy requires kms key on  %s "" % ( self . manager . data , ) <TAB><TAB><TAB> ) <TAB> return self",if not key :,if key is None :,67.96555546724639,96.17,False
4561,"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB><TAB> if isinstance ( filename_data , list ) : <TAB><TAB><TAB> filename , data = filename_data <TAB><TAB> else : <TAB><TAB><TAB> filename = filename_data <TAB><TAB><TAB> data = None <TAB><TAB> <MASK> <TAB><TAB><TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB><TAB> files . append ( filename ) <TAB><TAB> if data : <TAB><TAB><TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories",if not filename . startswith ( os . sep ) :,if FakeState . deploy_dir :,71.76047594975941,95.45,False
4562,"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB><TAB> value = body . get ( attribute ) <TAB><TAB> if value is not None : <TAB><TAB><TAB> if isinstance ( value , six . string_types ) : <TAB><TAB><TAB><TAB> body [ attribute ] = value . strip ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> utils . check_string_length ( <TAB><TAB><TAB><TAB><TAB><TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> except exception . InvalidInput as error : <TAB><TAB><TAB><TAB><TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg )",if check_length :,if check_length :,100.0,100.00,True
4563,"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB><TAB> if match ( s ) : <TAB><TAB><TAB> yield x <TAB><TAB> <MASK> <TAB><TAB><TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation )",elif not x . is_atom ( ) and not s . is_atom ( ) :,"elif isinstance ( s , Leaf ) :",60.047350814417854,82.63,False
4564,"def wait_or_kill ( self ) : <TAB> """"""Wait for the program to terminate, or kill it after 5s."""""" <TAB> if self . instance . poll ( ) is None : <TAB><TAB> # We try one more time to kill gracefully using Ctrl-C. <TAB><TAB> logger . info ( "" Interrupting  %s  and waiting... "" , self . coord ) <TAB><TAB> self . instance . send_signal ( signal . SIGINT ) <TAB><TAB> # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB><TAB> t = monotonic_time ( ) <TAB><TAB> while monotonic_time ( ) - t < 5 : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> logger . info ( "" Terminated  %s . "" , self . coord ) <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> time . sleep ( 0.1 ) <TAB><TAB> else : <TAB><TAB><TAB> self . kill ( )",if self . instance . poll ( ) is not None :,if self . instance . poll ( ) is None :,98.97552980172367,99.02,False
4565,"def sort_collection ( self , models , many ) : <TAB> ordering = self . ordering <TAB> if not many or not ordering : <TAB><TAB> return models <TAB> for key in reversed ( ordering ) : <TAB><TAB> reverse = key [ 0 ] == "" - "" <TAB><TAB> <MASK> <TAB><TAB><TAB> key = key [ 1 : ] <TAB><TAB> models = sorted ( models , key = partial ( deep_getattr , key = key ) , reverse = reverse ) <TAB> return models",if reverse :,if reverse :,100.0,100.00,True
4566,"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB><TAB> # return subset of palette <TAB><TAB> palette = [ ] <TAB><TAB> for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> palette . append ( self . PALETTE [ old_id ] ) <TAB><TAB> palette = type ( self . PALETTE ) ( palette ) <TAB> elif palette is None : <TAB><TAB> if self . PALETTE is None : <TAB><TAB><TAB> palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB><TAB> else : <TAB><TAB><TAB> palette = self . PALETTE <TAB> return palette",if new_id != - 1 :,if old_id in class_names :,98.07234521829807,96.69,False
4567,"def _find_tcl_dir ( ) : <TAB> lib_dirs = [ os . path . dirname ( _x ) for _x in sys . path if _x . lower ( ) . endswith ( "" lib "" ) ] <TAB> for lib_dir in lib_dirs : <TAB><TAB> base_dir = os . path . join ( lib_dir , TclLibrary . FOLDER ) <TAB><TAB> <MASK> <TAB><TAB><TAB> for root , _ , files in os . walk ( base_dir ) : <TAB><TAB><TAB><TAB> if TclLibrary . INIT_TCL in files : <TAB><TAB><TAB><TAB><TAB> return root",if os . path . exists ( base_dir ) :,if os . path . isdir ( base_dir ) :,98.6735711922678,98.47,False
4568,"def __next__ ( self ) : <TAB> """"""Special paging functionality"""""" <TAB> if self . iter is None : <TAB><TAB> self . iter = iter ( self . objs ) <TAB> try : <TAB><TAB> return next ( self . iter ) <TAB> except StopIteration : <TAB><TAB> self . iter = None <TAB><TAB> self . objs = [ ] <TAB><TAB> <MASK> <TAB><TAB><TAB> self . page + = 1 <TAB><TAB><TAB> self . _connection . get_response ( self . action , self . params , self . page , self ) <TAB><TAB><TAB> return next ( self ) <TAB><TAB> else : <TAB><TAB><TAB> raise",if int ( self . page ) < int ( self . total_pages ) :,if self . page < self . limit :,75.49080257396655,92.76,False
4569,"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB><TAB> if k == "" user "" : <TAB><TAB><TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB><TAB> else : <TAB><TAB><TAB> setattr ( lst , k , v ) <TAB> return lst","elif k == ""created_at"" :","elif k == ""date"" :",98.69454293562382,97.03,False
4570,"def real_type ( self ) : <TAB> # Find the real type representation by updating it as required <TAB> real_type = self . type <TAB> if self . flag_indicator : <TAB><TAB> real_type = "" # "" <TAB> if self . is_vector : <TAB><TAB> <MASK> <TAB><TAB><TAB> real_type = "" Vector< {} > "" . format ( real_type ) <TAB><TAB> else : <TAB><TAB><TAB> real_type = "" vector< {} > "" . format ( real_type ) <TAB> if self . is_generic : <TAB><TAB> real_type = "" ! {} "" . format ( real_type ) <TAB> if self . is_flag : <TAB><TAB> real_type = "" flags. {} ? {} "" . format ( self . flag_index , real_type ) <TAB> return real_type",if self . use_vector_id :,if self . flag_index == 0 :,73.56781107789661,96.74,False
4571,"def check_fs ( path ) : <TAB> with open ( path , "" rb "" ) as f : <TAB><TAB> code = python_bytes_to_unicode ( f . read ( ) , errors = "" replace "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> module = _load_module ( evaluator , path , code ) <TAB><TAB><TAB> module_name = sys_path . dotted_path_in_sys_path ( <TAB><TAB><TAB><TAB> evaluator . project . sys_path , path <TAB><TAB><TAB> ) <TAB><TAB><TAB> if module_name is not None : <TAB><TAB><TAB><TAB> add_module ( evaluator , module_name , module ) <TAB><TAB><TAB> return module",if name in code :,if code is not None :,68.96161115340693,97.28,False
4572,"def infoCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] , checkPrimary = True ) <TAB> i = 0 <TAB> count = len ( users ) <TAB> for user in users : <TAB><TAB> i + = 1 <TAB><TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB><TAB> if not cal : <TAB><TAB><TAB> continue <TAB><TAB> result = gapi . call ( <TAB><TAB><TAB> cal . calendarList ( ) , "" get "" , soft_errors = True , calendarId = calendarId <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( f "" User:  { user } , Calendar: { display . current_count ( i , count ) } "" ) <TAB><TAB><TAB> _showCalendar ( result , 1 , 1 )",if result :,if result :,100.0,100.00,True
4573,"def set_hidestate_input_sockets_to_cope_with_switchnum ( self ) : <TAB> tndict = get_indices_that_should_be_visible ( self . node_state ) <TAB> for key , value in tndict . items ( ) : <TAB><TAB> socket = self . inputs [ key ] <TAB><TAB> desired_hide_state = not ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> socket . hide_safe = desired_hide_state",if not socket . hide == desired_hide_state :,if socket . is_cope :,81.0379864342018,90.67,False
4574,"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB><TAB> if isinstance ( parent , pytest . Class ) : <TAB><TAB><TAB> class_name = parent . name <TAB><TAB> <MASK> <TAB><TAB><TAB> module_name = parent . module . __name__ <TAB><TAB><TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "" .tasks. "" not in module_name : <TAB><TAB> return "" {} . {} "" . format ( module_name , class_name ) <TAB> else : <TAB><TAB> return module_name","elif isinstance ( parent , pytest . Module ) :","elif isinstance ( parent , pytest . Module ) :",100.0,100.00,True
4575,"def run ( self ) : <TAB> versions = versioneer . get_versions ( ) <TAB> tempdir = tempfile . mkdtemp ( ) <TAB> generated = os . path . join ( tempdir , "" rundemo "" ) <TAB> with open ( generated , "" wb "" ) as f : <TAB><TAB> for line in open ( "" src/rundemo-template "" , "" rb "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f . write ( ( "" versions =  %r \n "" % ( versions , ) ) . encode ( "" ascii "" ) ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> f . write ( line ) <TAB> self . scripts = [ generated ] <TAB> rc = build_scripts . run ( self ) <TAB> os . unlink ( generated ) <TAB> os . rmdir ( tempdir ) <TAB> return rc","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",if versions :,74.65335020271996,91.14,False
4576,"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB><TAB> user = getattr ( request , "" user "" , None ) <TAB><TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB><TAB> <MASK> <TAB><TAB><TAB> result . update ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" email "" : user . email , <TAB><TAB><TAB><TAB><TAB> "" id "" : user . id , <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB><TAB><TAB> if user . name : <TAB><TAB><TAB><TAB> result [ "" name "" ] = user . name <TAB> else : <TAB><TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) )",if user and user . is_authenticated ( ) :,if user :,74.08206449306826,96.09,False
4577,"def tokens_to_spans ( ) - > Iterable [ Tuple [ str , Optional [ Style ] ] ] : <TAB> """"""Convert tokens to spans."""""" <TAB> tokens = iter ( line_tokenize ( ) ) <TAB> line_no = 0 <TAB> _line_start = line_start - 1 <TAB> # Skip over tokens until line start <TAB> while line_no < _line_start : <TAB><TAB> _token_type , token = next ( tokens ) <TAB><TAB> yield ( token , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line_no + = 1 <TAB> # Generate spans until line end <TAB> for token_type , token in tokens : <TAB><TAB> yield ( token , _get_theme_style ( token_type ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> line_no + = 1 <TAB><TAB><TAB> if line_no > = line_end : <TAB><TAB><TAB><TAB> break","if token . endswith ( ""\n"" ) :","if _token_type == ""end"" :",94.48600524442725,92.49,False
4578,"def encode ( self , encodeFun , value , defMode , maxChunkSize ) : <TAB> substrate , isConstructed = self . encodeValue ( encodeFun , value , defMode , maxChunkSize ) <TAB> tagSet = value . getTagSet ( ) <TAB> if tagSet : <TAB><TAB> <MASK> # primitive form implies definite mode <TAB><TAB><TAB> defMode = 1 <TAB><TAB> return ( <TAB><TAB><TAB> self . encodeTag ( tagSet [ - 1 ] , isConstructed ) <TAB><TAB><TAB> + self . encodeLength ( len ( substrate ) , defMode ) <TAB><TAB><TAB> + substrate <TAB><TAB><TAB> + self . _encodeEndOfOctets ( encodeFun , defMode ) <TAB><TAB> ) <TAB> else : <TAB><TAB> return substrate # untagged value",if not isConstructed :,"if tagSet [ - 2 ] == ""primitive"" :",70.8167859294163,93.83,False
4579,def _run ( self ) : <TAB> while True : <TAB><TAB> request = self . _requests . get ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . shutdown ( ) <TAB><TAB><TAB> break <TAB><TAB> self . process ( request ) <TAB><TAB> self . _requests . task_done ( ),if request is None :,if request is None :,100.0,100.00,True
4580,"def _decode_payload ( self , payload ) : <TAB> # we need to decrypt it <TAB> if payload [ "" enc "" ] == "" aes "" : <TAB><TAB> try : <TAB><TAB><TAB> payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB><TAB> except salt . crypt . AuthenticationError : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB> return payload",if not self . _update_aes ( ) :,"if payload [ ""enc"" ] != ""decrypt"" :",70.88084807269198,91.85,False
4581,"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> value = row [ idx ] <TAB><TAB> except IndexError : <TAB><TAB><TAB> value = "" "" <TAB><TAB> result = test ( value ) <TAB><TAB> if self . any_match : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return not self . inverse # True <TAB><TAB> else : <TAB><TAB><TAB> if not result : <TAB><TAB><TAB><TAB> return self . inverse # False <TAB> if self . any_match : <TAB><TAB> return self . inverse # False <TAB> else : <TAB><TAB> return not self . inverse # True",if result :,if result :,100.0,100.00,True
4582,"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB><TAB> if self . use_prop or self . get_prop_name ( ) : <TAB><TAB><TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB><TAB><TAB> print ( "" V "" , value ) <TAB><TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB><TAB> param_node . selected_mode = "" int "" <TAB><TAB><TAB><TAB> param_node . int_ = value <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> param_node . selected_mode = "" float "" <TAB><TAB><TAB><TAB> param_node . float_ = value","elif isinstance ( value , float ) :","elif isinstance ( value , float ) :",100.0,100.00,True
4583,"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB><TAB> clients = self . get_clients ( clients_filter ) <TAB><TAB> if not clients : <TAB><TAB><TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB><TAB> try : <TAB><TAB><TAB> module = self . get_module ( module_name ) <TAB><TAB> except PupyModuleDisabled : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> for client in clients : <TAB><TAB><TAB><TAB> if module . is_compatible_with ( client ) : <TAB><TAB><TAB><TAB><TAB> yield module <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> yield module",if clients is not None :,if clients :,72.84144334511457,98.24,False
4584,"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB><TAB> for pricing_rule in pricing_rules : <TAB><TAB><TAB> if pricing_rule . condition : <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB><TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",if doc . condition ( pricing_rule . condition ) :,82.94332889021365,92.87,False
4585,"def build_query_string ( kv_data , ignore_none = True ) : <TAB> # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB> query_string = "" "" <TAB> for k , v in kv_data . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if query_string != "" "" : <TAB><TAB><TAB> query_string + = "" & "" <TAB><TAB> else : <TAB><TAB><TAB> query_string = "" ? "" <TAB><TAB> query_string + = k + "" = "" + str ( v ) <TAB> return query_string",if ignore_none is True and kv_data [ k ] is None :,if ignore_none and k in ignore_none :,93.81255776281434,93.74,False
4586,"def sample ( self , * * config ) : <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB><TAB> if k in striped_keys : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB><TAB><TAB><TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> ret [ k ] = v <TAB> return ret","if isinstance ( v , NestedSpace ) :","if hasattr ( v , ""sample"" ) :",94.562540689559,96.84,False
4587,"def task_failed ( self , task_id , hostname , reason ) : <TAB> logger . debug ( "" task  %d  failed with message  %s "" , task_id , str ( reason ) ) <TAB> if hostname in self . host_dict : <TAB><TAB> host_status = self . host_dict [ hostname ] <TAB><TAB> host_status . task_failed ( task_id ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . task_host_failed_dict [ task_id ] = set ( ) <TAB><TAB> self . task_host_failed_dict [ task_id ] . add ( hostname )",if task_id not in self . task_host_failed_dict :,if task_id not in self . task_host_failed_dict :,100.0,100.00,True
4588,"def match ( path ) : <TAB> for pat , _type , _property , default_title in patterns : <TAB><TAB> m = web . re_compile ( "" ^ "" + pat ) . match ( path ) <TAB><TAB> <MASK> <TAB><TAB><TAB> prefix = m . group ( ) <TAB><TAB><TAB> extra = web . lstrips ( path , prefix ) <TAB><TAB><TAB> tokens = extra . split ( "" / "" , 2 ) <TAB><TAB><TAB> # `extra` starts with ""/"". So first token is always empty. <TAB><TAB><TAB> middle = web . listget ( tokens , 1 , "" "" ) <TAB><TAB><TAB> suffix = web . listget ( tokens , 2 , "" "" ) <TAB><TAB><TAB> if suffix : <TAB><TAB><TAB><TAB> suffix = "" / "" + suffix <TAB><TAB><TAB> return _type , _property , default_title , prefix , middle , suffix <TAB> return None , None , None , None , None , None",if m :,if m :,100.0,100.00,True
4589,"def _get_cached_resources ( self , ids ) : <TAB> key = self . get_cache_key ( None ) <TAB> if self . _cache . load ( ) : <TAB><TAB> resources = self . _cache . get ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . log . debug ( "" Using cached results for get_resources "" ) <TAB><TAB><TAB> m = self . get_model ( ) <TAB><TAB><TAB> id_set = set ( ids ) <TAB><TAB><TAB> return [ r for r in resources if r [ m . id ] in id_set ] <TAB> return None",if resources is not None :,if resources :,87.24201812804449,97.21,False
4590,"def has_api_behaviour ( self , protocol ) : <TAB> config = get_config ( ) <TAB> try : <TAB><TAB> r = self . session . get ( <TAB><TAB><TAB> f "" { protocol } :// { self . event . host } : { self . event . port } "" , <TAB><TAB><TAB> timeout = config . network_timeout , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> except requests . exceptions . SSLError : <TAB><TAB> logger . debug ( <TAB><TAB><TAB> f "" { [ protocol ] }  protocol not accepted on  { self . event . host } : { self . event . port } "" <TAB><TAB> ) <TAB> except Exception : <TAB><TAB> logger . debug ( <TAB><TAB><TAB> f "" Failed probing  { self . event . host } : { self . event . port } "" , exc_info = True <TAB><TAB> )","if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",if r . status_code == 200 and r . status_code == 401 :,66.4354491548398,90.45,False
4591,"def get_file_type ( self , context , parent_context = None ) : <TAB> file_type = context . get ( self . file_type_name , None ) <TAB> if file_type == "" "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> file_type = parent_context . get ( self . file_type_name , self . default_file_type ) <TAB><TAB> else : <TAB><TAB><TAB> file_type = self . default_file_type <TAB> return file_type",if parent_context :,if parent_context :,100.0,100.00,True
4592,"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB><TAB> if box == self . level . bounds : <TAB><TAB><TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB><TAB><TAB> return <TAB><TAB> selectedChunks = self . selectedChunks <TAB><TAB> boxedChunks = set ( box . chunkPositions ) <TAB><TAB> <MASK> <TAB><TAB><TAB> remove = True <TAB><TAB> if remove and not add : <TAB><TAB><TAB> selectedChunks . difference_update ( boxedChunks ) <TAB><TAB> else : <TAB><TAB><TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if boxedChunks . issubset ( selectedChunks ) :,if remove and add :,73.6533198067202,96.02,False
4593,"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split : <TAB><TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB><TAB> char = chars [ i ] <TAB><TAB> <MASK> <TAB><TAB><TAB> output . append ( [ char ] ) <TAB><TAB><TAB> start_new_word = True <TAB><TAB> else : <TAB><TAB><TAB> if start_new_word : <TAB><TAB><TAB><TAB> output . append ( [ ] ) <TAB><TAB><TAB> start_new_word = False <TAB><TAB><TAB> output [ - 1 ] . append ( char ) <TAB><TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ]",if _is_punctuation ( char ) :,if is_punctuation ( char ) :,99.12058981156915,99.08,False
4594,"def _save_images ( notebook ) : <TAB> if os . getenv ( "" NB_NO_IMAGES "" ) == "" 1 "" : <TAB><TAB> return <TAB> logged = False <TAB> for filename , img_bytes in _iter_notebook_images ( notebook ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> log . info ( "" Saving images "" ) <TAB><TAB><TAB> logged = True <TAB><TAB> with open ( filename , "" wb "" ) as f : <TAB><TAB><TAB> f . write ( img_bytes )",if not logged :,if not logged :,100.0,100.00,True
4595,"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB><TAB> minDist = None <TAB><TAB> minGuide = None <TAB><TAB> for guide in self . guides [ color ] : <TAB><TAB><TAB> guideDist = dist ( currentPos , guide ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> minDist = guideDist <TAB><TAB><TAB><TAB> minGuide = guide <TAB><TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB><TAB><TAB> return <TAB><TAB> if minGuide == None : <TAB><TAB><TAB> return <TAB><TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB><TAB> currentPos = minGuide <TAB><TAB> self . guides [ color ] . remove ( minGuide )",if minDist == None or guideDist < minDist :,if guideDist < minDist :,84.8054777205007,97.27,False
4596,"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB> elif tp == "" flush "" : <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> elif tp == "" write_flush "" : <TAB><TAB><TAB> out . write ( msg ) <TAB><TAB><TAB> out . flush ( ) <TAB><TAB> elif tp == "" print "" : <TAB><TAB><TAB> print ( msg , file = out ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB><TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB><TAB> pass","if tp == ""write"" :","if tp == ""write"" :",100.0,100.00,True
4597,"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB><TAB> for base in bases : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> include_trace = False <TAB><TAB><TAB> if hasattr ( base , "" garbage "" ) : <TAB><TAB><TAB><TAB> include_garbage = False <TAB> if include_profile : <TAB><TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB><TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB><TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs )","if hasattr ( base , ""trace"" ) :","if hasattr ( base , ""trace"" ) :",100.0,100.00,True
4598,"def generatePidEncryptionTable ( ) : <TAB> table = [ ] <TAB> for counter1 in range ( 0 , 0x100 ) : <TAB><TAB> value = counter1 <TAB><TAB> for counter2 in range ( 0 , 8 ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value >> 1 <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> value = value >> 1 <TAB><TAB><TAB><TAB> value = value ^ 0xEDB88320 <TAB><TAB> table . append ( value ) <TAB> return table",if value & 1 == 0 :,if counter1 == 0x10000 and counter2 == 0x10000 :,91.08097827563525,93.46,False
4599,"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB><TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB><TAB><TAB> if "" init "" not in item . keywords : <TAB><TAB><TAB><TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""stage"" not in item . keywords :","if ""stage"" not in item . keywords :",75.0,100.00,True
4600,"def python_value ( self , value ) : <TAB> if value : <TAB><TAB> if isinstance ( value , basestring ) : <TAB><TAB><TAB> pp = lambda x : x . time ( ) <TAB><TAB><TAB> return format_date_time ( value , self . formats , pp ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB><TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value","elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . datetime ) :",100.0,100.00,True
4601,"def list_interesting_hosts ( self ) : <TAB> hosts = [ ] <TAB> targets = self . target [ "" other "" ] <TAB> for target in targets : <TAB><TAB> <MASK> <TAB><TAB><TAB> hosts . append ( <TAB><TAB><TAB><TAB> { "" ip "" : target . ip , "" description "" : target . domain + ""  /  "" + target . name } <TAB><TAB><TAB> ) <TAB> return hosts",if self . is_interesting ( target ) and target . status and target . status != 400 :,if target . name in self . allowed_hosts :,86.00208944051859,85.15,False
4602,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 24 :,if tt == 16 :,98.98332928261893,98.86,False
4603,"def _wait_for_finish ( self ) - > PollExitResponse : <TAB> while True : <TAB><TAB> if self . _backend : <TAB><TAB><TAB> poll_exit_resp = self . _backend . interface . communicate_poll_exit ( ) <TAB><TAB> logger . info ( "" got exit ret:  %s "" , poll_exit_resp ) <TAB><TAB> if poll_exit_resp : <TAB><TAB><TAB> done = poll_exit_resp . done <TAB><TAB><TAB> pusher_stats = poll_exit_resp . pusher_stats <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _on_finish_progress ( pusher_stats , done ) <TAB><TAB><TAB> if done : <TAB><TAB><TAB><TAB> return poll_exit_resp <TAB><TAB> time . sleep ( 2 )",if pusher_stats :,if pusher_stats :,100.0,100.00,True
4604,"def listing_items ( method ) : <TAB> marker = None <TAB> once = True <TAB> items = [ ] <TAB> while once or items : <TAB><TAB> for i in items : <TAB><TAB><TAB> yield i <TAB><TAB> if once or marker : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> items = method ( parms = { "" marker "" : marker } ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> items = method ( ) <TAB><TAB><TAB> if len ( items ) == 10000 : <TAB><TAB><TAB><TAB> marker = items [ - 1 ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> marker = None <TAB><TAB><TAB> once = False <TAB><TAB> else : <TAB><TAB><TAB> items = [ ]",if marker :,if marker :,100.0,100.00,True
4605,"def call ( monad , * args ) : <TAB> for arg , name in izip ( args , ( "" hour "" , "" minute "" , "" second "" , "" microsecond "" ) ) : <TAB><TAB> if not isinstance ( arg , NumericMixin ) or arg . type is not int : <TAB><TAB><TAB> throw ( <TAB><TAB><TAB><TAB> TypeError , <TAB><TAB><TAB><TAB> "" ' %s '  argument of time(...) function must be of  ' int '  type. Got:  %r "" <TAB><TAB><TAB><TAB> % ( name , type2str ( arg . type ) ) , <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> throw ( NotImplementedError ) <TAB> return ConstMonad . new ( time ( * tuple ( arg . value for arg in args ) ) )","if not isinstance ( arg , ConstMonad ) :",if arg . type is not ConstMonad :,69.35341577902358,96.29,False
4606,"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB><TAB> ki = key ( i ) <TAB><TAB> if sign is None : <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> if ki != 0 : <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB> else : <TAB><TAB><TAB> subseq . append ( i ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sign = ki / abs ( ki ) <TAB><TAB><TAB><TAB> yield subseq <TAB><TAB><TAB><TAB> subseq = [ i ] <TAB> if subseq : <TAB><TAB> yield subseq",if sign * ki < - slop :,if sign < slop :,84.874092417097,97.65,False
4607,"def walk_links ( self ) : <TAB> link_info_list = [ ] <TAB> for item in self . content : <TAB><TAB> <MASK> <TAB><TAB><TAB> link_info = LinkInfo ( link = item , name = item . name , sections = ( ) ) <TAB><TAB><TAB> link_info_list . append ( link_info ) <TAB><TAB> else : <TAB><TAB><TAB> link_info_list . extend ( item . walk_links ( ) ) <TAB> return link_info_list","if isinstance ( item , Link ) :","if isinstance ( item , LinkInfo ) :",93.22811268552027,98.13,False
4608,"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB><TAB> test_path = k . get_path ( ) <TAB><TAB> if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB><TAB><TAB> sub = test_path [ len ( parent_path ) : ] <TAB><TAB><TAB> if sub . startswith ( "" \\ "" ) : <TAB><TAB><TAB><TAB> sub = sub [ 1 : ] <TAB><TAB><TAB> end_slash = sub . find ( "" \\ "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sub = sub [ : end_slash ] <TAB><TAB><TAB> if not sub : <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> subkeys . append ( sub ) <TAB> return subkeys",if end_slash >= 0 :,if end_slash > - 1 :,73.5762823026199,98.70,False
4609,"def load_dict ( dict_path , reverse = False ) : <TAB> word_dict = { } <TAB> with open ( dict_path , "" rb "" ) as fdict : <TAB><TAB> for idx , line in enumerate ( fdict ) : <TAB><TAB><TAB> line = cpt . to_text ( line ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> word_dict [ idx ] = line . strip ( "" \n "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> word_dict [ line . strip ( "" \n "" ) ] = idx <TAB> return word_dict",if reverse :,if reverse :,100.0,100.00,True
4610,"def test_network ( coords , feats , model , batch_sizes , forward_only = True ) : <TAB> for batch_size in batch_sizes : <TAB><TAB> bcoords = batched_coordinates ( [ coords for i in range ( batch_size ) ] ) <TAB><TAB> bfeats = torch . cat ( [ feats for i in range ( batch_size ) ] , 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> with torch . no_grad ( ) : <TAB><TAB><TAB><TAB> time , length = forward ( bcoords , bfeats , model ) <TAB><TAB> else : <TAB><TAB><TAB> time , length = train ( bcoords , bfeats , model ) <TAB><TAB> print ( f "" { net . __name__ } \t { voxel_size } \t { batch_size } \t { length } \t { time } "" ) <TAB><TAB> torch . cuda . empty_cache ( )",if forward_only :,if forward_only :,100.0,100.00,True
4611,"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB><TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB><TAB> self . utexc = True <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB><TAB> if self . utexc is not True : <TAB><TAB><TAB> self . utexc [ indices ] = True",if self . utexc is False :,if indices == 0 :,92.04072121209113,95.13,False
4612,"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB><TAB> module_directory = join ( directory , module ) <TAB><TAB> has_module_directory = isdir ( module_directory ) <TAB><TAB> <MASK> <TAB><TAB><TAB> has_module = has_module_directory or exists ( <TAB><TAB><TAB><TAB> module_directory <TAB><TAB><TAB> ) # could be a bare modulefile <TAB><TAB> else : <TAB><TAB><TAB> modulefile = join ( module_directory , version ) <TAB><TAB><TAB> has_modulefile = exists ( modulefile ) <TAB><TAB><TAB> has_module = has_module_directory and has_modulefile <TAB><TAB> if has_module : <TAB><TAB><TAB> break <TAB> return has_module",if not version :,if version is None :,95.31752478557338,98.06,False
4613,"def get_editops ( self ) : <TAB> if not self . _editops : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _editops = editops ( self . _opcodes , self . _str1 , self . _str2 ) <TAB><TAB> else : <TAB><TAB><TAB> self . _editops = editops ( self . _str1 , self . _str2 ) <TAB> return self . _editops",if self . _opcodes :,if self . _opcodes :,100.0,100.00,True
4614,"def to_representation ( self , data ) : <TAB> value = super ( CredentialTypeSerializer , self ) . to_representation ( data ) <TAB> # translate labels and help_text for credential fields ""managed by Tower"" <TAB> if value . get ( "" managed_by_tower "" ) : <TAB><TAB> value [ "" name "" ] = _ ( value [ "" name "" ] ) <TAB><TAB> for field in value . get ( "" inputs "" , { } ) . get ( "" fields "" , [ ] ) : <TAB><TAB><TAB> field [ "" label "" ] = _ ( field [ "" label "" ] ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> field [ "" help_text "" ] = _ ( field [ "" help_text "" ] ) <TAB> return value","if ""help_text"" in field :","if field . get ( ""help_text"" ) :",97.7582897637028,96.06,False
4615,"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB><TAB> if isinstance ( v , list ) : <TAB><TAB><TAB> for i in range ( 0 , len ( v ) ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB><TAB><TAB><TAB> d [ k ] = sorted ( v ) <TAB><TAB> if isinstance ( v , dict ) : <TAB><TAB><TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","if isinstance ( v [ i ] , dict ) :","if isinstance ( v [ i ] , dict ) :",100.0,100.00,True
4616,"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB><TAB> source = "" "" <TAB><TAB> if ss [ "" branch "" ] : <TAB><TAB><TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB><TAB> if ss [ "" revision "" ] : <TAB><TAB><TAB> source + = str ( ss [ "" revision "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> source + = "" HEAD "" <TAB><TAB> <MASK> <TAB><TAB><TAB> source + = ""  (plus patch) "" <TAB><TAB> discriminator = "" "" <TAB><TAB> if ss [ "" codebase "" ] : <TAB><TAB><TAB> discriminator = ""   ' %s ' "" % ss [ "" codebase "" ] <TAB><TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""patch"" ] is not None :","if ss [ ""patch"" ] :",72.05659367493689,98.19,False
4617,"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . median [ i ] . update ( xi ) <TAB><TAB> if self . with_scaling : <TAB><TAB><TAB> self . iqr [ i ] . update ( xi ) <TAB> return self",if self . with_centering :,if self . median [ i ] :,70.00942663367665,94.16,False
4618,"def start_response ( self , status , headers , exc_info = None ) : <TAB> if exc_info : <TAB><TAB> try : <TAB><TAB><TAB> if self . started : <TAB><TAB><TAB><TAB> six . reraise ( exc_info [ 0 ] , exc_info [ 1 ] , exc_info [ 2 ] ) <TAB><TAB> finally : <TAB><TAB><TAB> exc_info = None <TAB> self . request . status = int ( status [ : 3 ] ) <TAB> for key , val in headers : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . request . set_content_length ( int ( val ) ) <TAB><TAB> elif key . lower ( ) == "" content-type "" : <TAB><TAB><TAB> self . request . content_type = val <TAB><TAB> else : <TAB><TAB><TAB> self . request . headers_out . add ( key , val ) <TAB> return self . write","if key . lower ( ) == ""content-length"" :","if key . lower ( ) == ""content-length"" :",100.0,100.00,True
4619,"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB><TAB> y = self . _curve . b <TAB> else : <TAB><TAB> result = self . sqrtp ( <TAB><TAB><TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB><TAB> ) <TAB><TAB> if len ( result ) == 1 : <TAB><TAB><TAB> y = result [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> y1 , y2 = result <TAB><TAB><TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB><TAB> else : <TAB><TAB><TAB> return None <TAB> return ec . Point ( self . _curve , x , y )",elif len ( result ) == 2 :,elif len ( result ) == 2 :,100.0,100.00,True
4620,"def trace ( self , ee , rname ) : <TAB> print ( type ( self ) ) <TAB> self . traceIndent ( ) <TAB> guess = "" "" <TAB> if self . inputState . guessing > 0 : <TAB><TAB> guess = ""  [guessing] "" <TAB> print ( ( ee + rname + guess ) ) <TAB> for i in xrange ( 1 , self . k + 1 ) : <TAB><TAB> if i != 1 : <TAB><TAB><TAB> print ( "" ,  "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> v = self . LT ( i ) . getText ( ) <TAB><TAB> else : <TAB><TAB><TAB> v = "" null "" <TAB><TAB> print ( "" LA( %s ) ==  %s "" % ( i , v ) ) <TAB> print ( "" \n "" )",if self . LT ( i ) :,if self . inputState . guessing == 0 :,95.38701178170061,96.43,False
4621,"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = { } <TAB> for _ , name , data_type , not_null , _ , primary_key in rows : <TAB><TAB> parts = [ data_type ] <TAB><TAB> if primary_key : <TAB><TAB><TAB> parts . append ( "" PRIMARY KEY "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> parts . append ( "" NOT NULL "" ) <TAB><TAB> result [ name ] = ""   "" . join ( parts ) <TAB> return result",if not_null :,if not_null :,100.0,100.00,True
4622,"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB><TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB><TAB><TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB><TAB><TAB><TAB> if c . strip ( ) . startswith ( "" CSRF-Token- "" ) : <TAB><TAB><TAB><TAB><TAB> self . _CSRFtoken = c . strip ( ""   \r \n "" ) <TAB><TAB><TAB><TAB><TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break",if self . _CSRFtoken != None :,if not self . _CSRFtoken :,70.71527210717996,97.06,False
4623,"def _update_from_item ( self , row , download_item ) : <TAB> progress_stats = download_item . progress_stats <TAB> for key in self . columns : <TAB><TAB> column = self . columns [ key ] [ 0 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> # Not the best place but we build the playlist status here <TAB><TAB><TAB> status = "" {0}   {1} / {2} "" . format ( <TAB><TAB><TAB><TAB> progress_stats [ "" status "" ] , <TAB><TAB><TAB><TAB> progress_stats [ "" playlist_index "" ] , <TAB><TAB><TAB><TAB> progress_stats [ "" playlist_size "" ] , <TAB><TAB><TAB> ) <TAB><TAB><TAB> self . SetStringItem ( row , column , status ) <TAB><TAB> else : <TAB><TAB><TAB> self . SetStringItem ( row , column , progress_stats [ key ] )","if key == ""status"" and progress_stats [ ""playlist_index"" ] :","if column == ""status"" :",89.61019483651694,94.08,False
4624,"def unmarshal_package_repositories ( cls , data : Any ) - > List [ "" PackageRepository "" ] : <TAB> repositories = list ( ) <TAB> if data is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( f "" invalid package-repositories:  { data !r} "" ) <TAB><TAB> for repository in data : <TAB><TAB><TAB> package_repo = cls . unmarshal ( repository ) <TAB><TAB><TAB> repositories . append ( package_repo ) <TAB> return repositories","if not isinstance ( data , list ) :","if not isinstance ( data , ( list , tuple ) ) :",86.09001083704068,95.27,False
4625,"def remove_message ( e = None ) : <TAB> itop = scanbox . nearest ( 0 ) <TAB> sel = scanbox . curselection ( ) <TAB> if not sel : <TAB><TAB> dialog ( <TAB><TAB><TAB> root , <TAB><TAB><TAB> "" No Message To Remove "" , <TAB><TAB><TAB> "" Please select a message to remove "" , <TAB><TAB><TAB> "" "" , <TAB><TAB><TAB> 0 , <TAB><TAB><TAB> "" OK "" , <TAB><TAB> ) <TAB><TAB> return <TAB> todo = [ ] <TAB> for i in sel : <TAB><TAB> line = scanbox . get ( i ) <TAB><TAB> <MASK> <TAB><TAB><TAB> todo . append ( string . atoi ( scanparser . group ( 1 ) ) ) <TAB> mhf . removemessages ( todo ) <TAB> rescan ( ) <TAB> fixfocus ( min ( todo ) , itop )",if scanparser . match ( line ) >= 0 :,if line :,69.67254555343845,95.64,False
4626,"def test_patches ( ) : <TAB> print ( <TAB><TAB> "" Botocore version:  {}  aiohttp version:  {} "" . format ( <TAB><TAB><TAB> botocore . __version__ , aiohttp . __version__ <TAB><TAB> ) <TAB> ) <TAB> success = True <TAB> for obj , digests in chain ( _AIOHTTP_DIGESTS . items ( ) , _API_DIGESTS . items ( ) ) : <TAB><TAB> digest = hashlib . sha1 ( getsource ( obj ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" Digest of  {} : {}  not found in:  {} "" . format ( <TAB><TAB><TAB><TAB><TAB> obj . __qualname__ , digest , digests <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> success = False <TAB> assert success",if digest not in digests :,if digest not in digests :,100.0,100.00,True
4627,"def sample_admin_user ( ) : <TAB> """"""List of iris messages"""""" <TAB> with iris_ctl . db_from_config ( sample_db_config ) as ( conn , cursor ) : <TAB><TAB> cursor . execute ( <TAB><TAB><TAB> "" SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1 "" <TAB><TAB> ) <TAB><TAB> result = cursor . fetchone ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return result [ 0 ]",if result :,if result :,100.0,100.00,True
4628,"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB><TAB> for rightname in kerning [ leftname ] : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> for rightname2 in groups [ rightname ] : <TAB><TAB><TAB><TAB><TAB> rightnames . add ( rightname2 ) <TAB><TAB><TAB><TAB><TAB> if not includeAll : <TAB><TAB><TAB><TAB><TAB><TAB> # TODO: in this case, pick the one rightname that has the highest <TAB><TAB><TAB><TAB><TAB><TAB> # ranking in glyphorder <TAB><TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> rightnames . add ( rightname )","if rightname [ 0 ] == ""@"" :",if rightname not in rightnames :,93.2274894539164,95.68,False
4629,"def build ( self , input_shape ) : <TAB> if isinstance ( input_shape , list ) and len ( input_shape ) == 2 : <TAB><TAB> self . data_mode = "" disjoint "" <TAB><TAB> self . F = input_shape [ 0 ] [ - 1 ] <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . data_mode = "" single "" <TAB><TAB> else : <TAB><TAB><TAB> self . data_mode = "" batch "" <TAB><TAB> self . F = input_shape [ - 1 ]",if len ( input_shape ) == 2 :,if len ( input_shape ) == 1 :,97.59653144287432,98.32,False
4630,"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB><TAB> # most common case: extend a range <TAB><TAB> <MASK> <TAB><TAB><TAB> _range [ 0 ] = i <TAB><TAB><TAB> merge_ranges ( l ) <TAB><TAB><TAB> return <TAB><TAB> elif i == _range [ 1 ] + 1 : <TAB><TAB><TAB> _range [ 1 ] = i <TAB><TAB><TAB> merge_ranges ( l ) <TAB><TAB><TAB> return <TAB> # somewhere outside of range proximity <TAB> l . append ( [ i , i ] ) <TAB> l . sort ( key = lambda x : x [ 0 ] )",if i == _range [ 0 ] - 1 :,if i == _range [ 0 ] + 1 :,98.79683980563735,98.67,False
4631,"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB><TAB> ctype , line , col , char = cmd <TAB><TAB> <MASK> <TAB><TAB><TAB> if char != "" \n "" : <TAB><TAB><TAB><TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB><TAB><TAB><TAB> del buf [ line + 1 ] <TAB><TAB> elif ctype == "" I "" : <TAB><TAB><TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB><TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf )","if ctype == ""D"" :","if ctype == ""I"" :",99.24321260175164,99.03,False
4632,"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB><TAB> try : <TAB><TAB><TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB><TAB> except : <TAB><TAB><TAB> continue <TAB><TAB> uri , unused = uri_tuple <TAB><TAB> if os . path . exists ( uri ) == True : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB><TAB> return <TAB> open_dropped_files ( files )",if utils . is_media_file ( uri ) == True :,if not os . path . isfile ( uri ) :,66.8886641598075,93.71,False
4633,"def __walk_proceed_remote_dir_act ( self , r , args ) : <TAB> dirjs , filejs = args <TAB> j = r . json ( ) <TAB> if "" list "" not in j : <TAB><TAB> self . pd ( <TAB><TAB><TAB> "" Key  ' list '  not found in the response of directory listing request: \n {} "" . format ( <TAB><TAB><TAB><TAB> j <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB><TAB> return const . ERequestFailed <TAB> paths = j [ "" list "" ] <TAB> for path in paths : <TAB><TAB> <MASK> <TAB><TAB><TAB> dirjs . append ( path ) <TAB><TAB> else : <TAB><TAB><TAB> filejs . append ( path ) <TAB> return const . ENoError","if path [ ""isdir"" ] :","if path . startswith ( ""dir"" ) :",68.94432034441081,96.17,False
4634,"def TaskUpdatesVerbose ( task , progress ) : <TAB> if isinstance ( task . info . progress , int ) : <TAB><TAB> info = task . info <TAB><TAB> <MASK> <TAB><TAB><TAB> progress = "" %d %%  ( %s ) "" % ( info . progress , info . state ) <TAB><TAB> print ( <TAB><TAB><TAB> "" Task  %s  (key: %s , desc: %s ) -  %s "" <TAB><TAB><TAB> % ( info . name . info . name , info . key , info . description , progress ) <TAB><TAB> )","if not isinstance ( progress , str ) :",if info . progress :,87.31301184660177,94.50,False
4635,"def dump_constants ( header ) : <TAB> output = StringIO . StringIO ( ) <TAB> output . write ( header ) <TAB> for attribute in dir ( FSEvents ) : <TAB><TAB> value = getattr ( FSEvents , attribute ) <TAB><TAB> <MASK> <TAB><TAB><TAB> output . write ( ""      %s  =  %s \n "" % ( attribute , hex ( value ) ) ) <TAB> content = output . getvalue ( ) <TAB> output . close ( ) <TAB> return content","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",if value is not None :,65.44153803948684,87.08,False
4636,"def _ensure_data_is_loaded ( <TAB> self , <TAB> sql_object , <TAB> input_params , <TAB> stdin_file , <TAB> stdin_filename = "" - "" , <TAB> stop_after_analysis = False , ) : <TAB> data_loads = [ ] <TAB> # Get each ""table name"" which is actually the file name <TAB> for filename in sql_object . qtable_names : <TAB><TAB> data_load = self . _load_data ( <TAB><TAB><TAB> filename , <TAB><TAB><TAB> input_params , <TAB><TAB><TAB> stdin_file = stdin_file , <TAB><TAB><TAB> stdin_filename = stdin_filename , <TAB><TAB><TAB> stop_after_analysis = stop_after_analysis , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> data_loads . append ( data_load ) <TAB> return data_loads",if data_load is not None :,if data_load :,97.2424950308857,98.13,False
4637,"def _get_instantiation ( self ) : <TAB> if self . _data is None : <TAB><TAB> f , l , c , o = c_object_p ( ) , c_uint ( ) , c_uint ( ) , c_uint ( ) <TAB><TAB> SourceLocation_loc ( self , byref ( f ) , byref ( l ) , byref ( c ) , byref ( o ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> f = File ( f ) <TAB><TAB> else : <TAB><TAB><TAB> f = None <TAB><TAB> self . _data = ( f , int ( l . value ) , int ( c . value ) , int ( c . value ) ) <TAB> return self . _data",if f :,if os . path . exists ( f ) :,73.79691063151292,94.95,False
4638,"def _get_all_info_lines ( data ) : <TAB> infos = [ ] <TAB> for row in data : <TAB><TAB> splitrow = row . split ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if splitrow [ 0 ] == "" INFO: "" : <TAB><TAB><TAB><TAB> infos . append ( ""   "" . join ( splitrow [ 1 : ] ) ) <TAB> return infos",if len ( splitrow ) > 0 :,if len ( splitrow ) > 1 :,98.03188765925256,97.66,False
4639,"def _brush_modified_cb ( self , settings ) : <TAB> """"""Updates the brush's base setting adjustments on brush changes"""""" <TAB> for cname in settings : <TAB><TAB> adj = self . brush_adjustment . get ( cname , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> value = self . brush . get_base_value ( cname ) <TAB><TAB> adj . set_value ( value )",if adj is None :,if adj is None :,100.0,100.00,True
4640,"def migrate_node_facts ( facts ) : <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB><TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB><TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB><TAB> if role in facts : <TAB><TAB><TAB> for param in params [ role ] : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts",if param in facts [ role ] :,"if param in facts [ ""node"" ] :",98.86891609436688,97.61,False
4641,"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" When setting content_range to a list/tuple, it must  "" <TAB><TAB><TAB><TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB><TAB><TAB> ) <TAB><TAB> if len ( value ) == 2 : <TAB><TAB><TAB> begin , end = value <TAB><TAB><TAB> length = None <TAB><TAB> else : <TAB><TAB><TAB> begin , end , length = value <TAB><TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB><TAB> return None <TAB> return value","if len ( value ) not in ( 2 , 3 ) :",if len ( value ) != 3 :,94.75397164162725,96.43,False
4642,"def clean ( self ) : <TAB> data = super ( ) . clean ( ) <TAB> if data . get ( "" expires "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> data [ "" expires "" ] = make_aware ( <TAB><TAB><TAB><TAB> datetime . combine ( data [ "" expires "" ] , time ( hour = 23 , minute = 59 , second = 59 ) ) , <TAB><TAB><TAB><TAB> self . instance . event . timezone , <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> data [ "" expires "" ] = data [ "" expires "" ] . replace ( hour = 23 , minute = 59 , second = 59 ) <TAB><TAB> if data [ "" expires "" ] < now ( ) : <TAB><TAB><TAB> raise ValidationError ( _ ( "" The new expiry date needs to be in the future. "" ) ) <TAB> return data","if isinstance ( data [ ""expires"" ] , date ) :",if self . instance . event . timezone :,92.35062305874304,94.66,False
4643,"def _build ( self , obj , stream , context ) : <TAB> if self . include_name : <TAB><TAB> name , obj = obj <TAB><TAB> for sc in self . subcons : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sc . _build ( obj , stream , context ) <TAB><TAB><TAB><TAB> return <TAB> else : <TAB><TAB> for sc in self . subcons : <TAB><TAB><TAB> stream2 = BytesIO ( ) <TAB><TAB><TAB> context2 = context . __copy__ ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> sc . _build ( obj , stream2 , context2 ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> context . __update__ ( context2 ) <TAB><TAB><TAB><TAB> stream . write ( stream2 . getvalue ( ) ) <TAB><TAB><TAB><TAB> return <TAB> raise SelectError ( "" no subconstruct matched "" , obj )",if sc . name == name :,if sc . include_obj :,97.13738589499017,98.11,False
4644,"def records ( account_id ) : <TAB> """"""Fetch locks data"""""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB><TAB> if "" RevisionDate "" in r : <TAB><TAB><TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) )","if ""LockDate"" in r :","if ""LockDate"" in r :",100.0,100.00,True
4645,"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB><TAB> if isinstance ( test , ast . Const ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if not test . value : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB> self . visit ( test , scope ) <TAB><TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB><TAB> self . visit ( node . else_ , scope )",if type ( test . value ) in self . _const_types :,"if isinstance ( test , ast . Name ) :",66.05329121589662,91.02,False
4646,"def validate_max_discount ( self ) : <TAB> if self . rate_or_discount == "" Discount Percentage "" and self . get ( "" items "" ) : <TAB><TAB> for d in self . items : <TAB><TAB><TAB> max_discount = frappe . get_cached_value ( "" Item "" , d . item_code , "" max_discount "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> throw ( <TAB><TAB><TAB><TAB><TAB> _ ( "" Max discount allowed for item:  {0}  is  {1} % "" ) . format ( <TAB><TAB><TAB><TAB><TAB><TAB> self . item_code , max_discount <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> )",if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,if max_discount > self . rate_or_discount :,88.45872457867954,92.97,False
4647,"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB> rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB> if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB><TAB> for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB><TAB><TAB> if i_type [ 0 : 3 ] == "" cce "" : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB> return False","if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :","if i_value [ 0 : 3 ] == ""invalid"" :",88.06704589688512,87.04,False
4648,"def parse_calendar_eras ( data , calendar ) : <TAB> eras = data . setdefault ( "" eras "" , { } ) <TAB> for width in calendar . findall ( "" eras/* "" ) : <TAB><TAB> width_type = NAME_MAP [ width . tag ] <TAB><TAB> widths = eras . setdefault ( width_type , { } ) <TAB><TAB> for elem in width . getiterator ( ) : <TAB><TAB><TAB> if elem . tag == "" era "" : <TAB><TAB><TAB><TAB> _import_type_text ( widths , elem , type = int ( elem . attrib . get ( "" type "" ) ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> eras [ width_type ] = Alias ( <TAB><TAB><TAB><TAB><TAB> _translate_alias ( [ "" eras "" , width_type ] , elem . attrib [ "" path "" ] ) <TAB><TAB><TAB><TAB> )","elif elem . tag == ""alias"" :","elif elem . tag == ""path"" :",99.07987431509754,98.98,False
4649,"def validate_grammar ( ) - > None : <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE : <TAB><TAB> fn_productions = get_productions ( fn ) <TAB><TAB> if all ( p . name == fn_productions [ 0 ] . name for p in fn_productions ) : <TAB><TAB><TAB> # all the production names are the same, ensure that the `convert_` function <TAB><TAB><TAB> # is named correctly <TAB><TAB><TAB> production_name = fn_productions [ 0 ] . name <TAB><TAB><TAB> expected_name = f "" convert_ { production_name } "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB><TAB> f "" The conversion function for  ' { production_name } '   "" <TAB><TAB><TAB><TAB><TAB> + f "" must be called  ' { expected_name } ' , not  ' { fn . __name__ } ' . "" <TAB><TAB><TAB><TAB> )",if fn . __name__ != expected_name :,if not _is_function_defined ( expected_name ) :,97.59146920151878,95.87,False
4650,"def split_ratio ( row ) : <TAB> if float ( row [ "" Numerator "" ] ) > 0 : <TAB><TAB> <MASK> <TAB><TAB><TAB> n , m = row [ "" Splitratio "" ] . split ( "" : "" ) <TAB><TAB><TAB> return float ( m ) / float ( n ) <TAB><TAB> else : <TAB><TAB><TAB> return eval ( row [ "" Splitratio "" ] ) <TAB> else : <TAB><TAB> return 1","if "":"" in row [ ""Splitratio"" ] :","if "":"" in row [ ""Splitratio"" ] :",100.0,100.00,True
4651,"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef . error : <TAB><TAB> if testdef . exception : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise testdef . exception <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise Exception ( testdef . exception ) <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( "" Test parse failure "" )","if isinstance ( testdef . exception , Exception ) :","if isinstance ( testdef . exception , Exception ) :",75.0,100.00,True
4652,"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB><TAB> if count < = 0 : <TAB><TAB><TAB> quotas_ok [ quota ] = 0 <TAB><TAB><TAB> break <TAB><TAB> avail = qa . results [ quota ] <TAB><TAB> <MASK> <TAB><TAB><TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok",if avail [ 1 ] is not None and avail [ 1 ] < count :,if avail [ 0 ] :,67.23655969899079,94.10,False
4653,"def reverse ( self ) : <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB><TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB><TAB> li + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> lb = lb . rightlink <TAB><TAB><TAB> li = 0 <TAB><TAB> ri - = 1 <TAB><TAB> if ri < 0 : <TAB><TAB><TAB> rb = rb . leftlink <TAB><TAB><TAB> ri = BLOCKLEN - 1",if li >= BLOCKLEN :,if li > BLOCKLEN :,98.93658702112498,98.73,False
4654,"def __manipulate_item ( self , item ) : <TAB> if self . _Cursor__manipulate : <TAB><TAB> db = self . _Cursor__collection . database <TAB><TAB> son = db . _fix_outgoing ( item , self . _Cursor__collection ) <TAB> else : <TAB><TAB> son = item <TAB> if self . __wrap is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> return getattr ( self . _Cursor__collection , son [ self . __wrap . type_field ] ) ( son ) <TAB><TAB> return self . __wrap ( son , collection = self . _Cursor__collection ) <TAB> else : <TAB><TAB> return son",if self . __wrap . type_field in son :,if self . __wrap . type_field in son :,100.0,100.00,True
4655,"def apply_transforms ( self ) : <TAB> """"""Apply all of the stored transforms, in priority order."""""" <TAB> self . document . reporter . attach_observer ( self . document . note_transform_message ) <TAB> while self . transforms : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Unsorted initially, and whenever a transform is added. <TAB><TAB><TAB> self . transforms . sort ( ) <TAB><TAB><TAB> self . transforms . reverse ( ) <TAB><TAB><TAB> self . sorted = 1 <TAB><TAB> priority , transform_class , pending , kwargs = self . transforms . pop ( ) <TAB><TAB> transform = transform_class ( self . document , startnode = pending ) <TAB><TAB> transform . apply ( * * kwargs ) <TAB><TAB> self . applied . append ( ( priority , transform_class , pending , kwargs ) )",if not self . sorted :,if self . sorted :,75.96537961575619,98.84,False
4656,"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB><TAB> # convert sql with named parameters to sql with unnamed parameters <TAB><TAB> conv = _FormatConverter ( params ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sql = sql_to_string ( sql ) <TAB><TAB><TAB> sql = sql % conv <TAB><TAB><TAB> params = conv . params <TAB><TAB> else : <TAB><TAB><TAB> params = ( ) <TAB> for param in params or ( ) : <TAB><TAB> if param is None : <TAB><TAB><TAB> rv . append ( "" NULL "" ) <TAB><TAB> param = safe_repr ( param ) <TAB><TAB> rv . append ( param ) <TAB> return sql , rv",if params :,if conv . params :,98.90460988585183,98.31,False
4657,"def on_execution_item ( self , cpath , execution ) : <TAB> if not isinstance ( execution , dict ) : <TAB><TAB> return <TAB> if "" executor "" in execution and execution . get ( "" executor "" ) != "" jmeter "" : <TAB><TAB> return <TAB> scenario = execution . get ( "" scenario "" , None ) <TAB> <MASK> <TAB><TAB> return <TAB> if isinstance ( scenario , str ) : <TAB><TAB> scenario_name = scenario <TAB><TAB> scenario = self . get_named_scenario ( scenario_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> scenario = None <TAB><TAB> scenario_path = Path ( "" scenarios "" , scenario_name ) <TAB> else : <TAB><TAB> scenario_path = cpath . copy ( ) <TAB><TAB> scenario_path . add_component ( "" scenario "" ) <TAB> if scenario is not None : <TAB><TAB> self . check_jmeter_scenario ( scenario_path , scenario )",if not scenario :,if not scenario :,100.0,100.00,True
4658,"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB><TAB> if self . _ipc_requests . empty ( ) : <TAB><TAB><TAB> return <TAB><TAB> while not self . _ipc_requests . empty ( ) : <TAB><TAB><TAB> args = self . _ipc_requests . get ( ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> for filename in args : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB><TAB><TAB> except Exception as e : <TAB><TAB><TAB><TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB><TAB> self . become_active_window ( ) <TAB> finally : <TAB><TAB> self . after ( 50 , self . _poll_ipc_requests )",if os . path . isfile ( filename ) :,"if filename . endswith ( "".py"" ) :",95.28472603140249,96.69,False
4659,"def get_scroll_distance_to_element ( driver , element ) : <TAB> try : <TAB><TAB> scroll_position = driver . execute_script ( "" return window.scrollY; "" ) <TAB><TAB> element_location = None <TAB><TAB> element_location = element . location [ "" y "" ] <TAB><TAB> element_location = element_location - 130 <TAB><TAB> <MASK> <TAB><TAB><TAB> element_location = 0 <TAB><TAB> distance = element_location - scroll_position <TAB><TAB> return distance <TAB> except Exception : <TAB><TAB> return 0",if element_location < 0 :,if element_location < 130 :,81.8019416966131,98.34,False
4660,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 16 :,if tt == 16 :,100.0,100.00,True
4661,"def _validate_and_define ( params , key , value ) : <TAB> ( key , force_generic ) = _validate_key ( _unescape ( key ) ) <TAB> if key in params : <TAB><TAB> raise SyntaxError ( f ' duplicate key  "" { key } "" ' ) <TAB> cls = _class_for_key . get ( key , GenericParam ) <TAB> emptiness = cls . emptiness ( ) <TAB> if value is None : <TAB><TAB> if emptiness == Emptiness . NEVER : <TAB><TAB><TAB> raise SyntaxError ( "" value cannot be empty "" ) <TAB><TAB> value = cls . from_value ( value ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> value = cls . from_wire_parser ( dns . wire . Parser ( _unescape ( value ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> value = cls . from_value ( value ) <TAB> params [ key ] = value",if force_generic :,if force_generic :,100.0,100.00,True
4662,"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> field_val = getattr ( node , field_name , _marker ) <TAB><TAB> if field_val is _marker : <TAB><TAB><TAB> continue <TAB><TAB> if exclude_unset : <TAB><TAB><TAB> if callable ( field . default ) : <TAB><TAB><TAB><TAB> default = field . default ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> default = field . default <TAB><TAB><TAB> if field_val == default : <TAB><TAB><TAB><TAB> continue <TAB><TAB> yield field_name , field_val",if exclude_meta and field . meta :,if include_meta and field . default is None :,81.91564210967488,97.09,False
4663,"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB><TAB> if self . server : <TAB><TAB><TAB> self . server . stop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB><TAB><TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB><TAB> BaseTest . tearDown ( self )",if self . sl_hdlr :,if self . sl_hdlr :,75.0,100.00,True
4664,"def _wait_for_async_copy ( self , share_name , file_path ) : <TAB> count = 0 <TAB> share_client = self . fsc . get_share_client ( share_name ) <TAB> file_client = share_client . get_file_client ( file_path ) <TAB> properties = file_client . get_file_properties ( ) <TAB> while properties . copy . status != "" success "" : <TAB><TAB> count = count + 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . fail ( "" Timed out waiting for async copy to complete. "" ) <TAB><TAB> self . sleep ( 6 ) <TAB><TAB> properties = file_client . get_file_properties ( ) <TAB> self . assertEqual ( properties . copy . status , "" success "" )",if count > 10 :,if count > 100 :,98.8691352232095,98.70,False
4665,"def __new__ ( <TAB> cls , <TAB> message_type : OrderBookMessageType , <TAB> content : Dict [ str , any ] , <TAB> timestamp : Optional [ float ] = None , <TAB> * args , <TAB> * * kwargs , ) : <TAB> if timestamp is None : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> "" timestamp must not be None when initializing snapshot messages. "" <TAB><TAB><TAB> ) <TAB><TAB> timestamp = int ( time . time ( ) ) <TAB> return super ( KucoinOrderBookMessage , cls ) . __new__ ( <TAB><TAB> cls , message_type , content , timestamp = timestamp , * args , * * kwargs <TAB> )",if message_type is OrderBookMessageType . SNAPSHOT :,if message_type is OrderBookMessageType . SNAPSHOT :,100.0,100.00,True
4666,"def _drop_unique_features ( <TAB> X : DataFrame , feature_metadata : FeatureMetadata , max_unique_ratio ) - > list : <TAB> features_to_drop = [ ] <TAB> X_len = len ( X ) <TAB> max_unique_value_count = X_len * max_unique_ratio <TAB> for column in X : <TAB><TAB> unique_value_count = len ( X [ column ] . unique ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> features_to_drop . append ( column ) <TAB><TAB> elif feature_metadata . get_feature_type_raw ( column ) in [ <TAB><TAB><TAB> R_CATEGORY , <TAB><TAB><TAB> R_OBJECT , <TAB><TAB> ] and ( unique_value_count > max_unique_value_count ) : <TAB><TAB><TAB> features_to_drop . append ( column ) <TAB> return features_to_drop",if unique_value_count == 1 :,if feature_metadata . get_feature_type_raw ( column ) in [ R_,65.99932194120734,92.32,False
4667,"def get_src_findex_by_pad ( s , S , padding_mode , align_corners ) : <TAB> if padding_mode == "" zero "" : <TAB><TAB> return get_src_findex_with_zero_pad ( s , S ) <TAB> elif padding_mode == "" reflect "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> return get_src_findex_with_reflect_pad ( s , S , True ) <TAB><TAB> else : <TAB><TAB><TAB> sf = get_src_findex_with_reflect_pad ( s , S , False ) <TAB><TAB><TAB> return get_src_findex_with_repeat_pad ( sf , S ) <TAB> elif padding_mode == "" repeat "" : <TAB><TAB> return get_src_findex_with_repeat_pad ( s , S )",if align_corners :,if align_corners :,100.0,100.00,True
4668,"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB><TAB> result + = ( current , ) <TAB><TAB> if current . _parent is upto : <TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> raise sa_exc . InvalidRequestError ( <TAB><TAB><TAB><TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> current = current . _parent <TAB> return result",elif current . _parent is None :,elif current . _parent is upto :,84.94093656481432,98.50,False
4669,"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> old_val = self [ name ] <TAB><TAB><TAB> if old_val == val : <TAB><TAB><TAB><TAB> return <TAB><TAB><TAB> raise KeyError ( <TAB><TAB><TAB><TAB> "" Computed attributed  ' {} '  already exists  "" <TAB><TAB><TAB><TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB><TAB><TAB> ) <TAB><TAB> self [ name ] = val <TAB> else : <TAB><TAB> super ( ) . __setattr__ ( name , val )",if name in self :,if name in self :,100.0,100.00,True
4670,"def get_fnlist ( bbhandler , pkg_pn , preferred ) : <TAB> """"""Get all recipe file names"""""" <TAB> <MASK> <TAB><TAB> ( latest_versions , preferred_versions ) = bb . providers . findProviders ( <TAB><TAB><TAB> bbhandler . config_data , bbhandler . cooker . recipecaches [ "" "" ] , pkg_pn <TAB><TAB> ) <TAB> fn_list = [ ] <TAB> for pn in sorted ( pkg_pn ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> fn_list . append ( preferred_versions [ pn ] [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> fn_list . extend ( pkg_pn [ pn ] ) <TAB> return fn_list",if preferred :,if pn in preferred_versions :,92.3666236624511,93.42,False
4671,"def links_extracted ( self , _ , links ) : <TAB> links_deduped = { } <TAB> for link in links : <TAB><TAB> link_fingerprint = link . meta [ FIELD_FINGERPRINT ] <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> links_deduped [ link_fingerprint ] = link <TAB> [ <TAB><TAB> self . _redis_pipeline . hmset ( fingerprint , self . _create_link_extracted ( link ) ) <TAB><TAB> for ( fingerprint , link ) in links_deduped . items ( ) <TAB> ] <TAB> self . _redis_pipeline . execute ( )",if link_fingerprint in links_deduped :,if link_fingerprint in self . _redis_pipeline . hlist ( link_fingerprint ),80.18069534419138,91.38,False
4672,"def __call__ ( self , name , rawtext , text , lineno , inliner , options = None , content = None ) : <TAB> options = options or { } <TAB> content = content or [ ] <TAB> issue_nos = [ each . strip ( ) for each in utils . unescape ( text ) . split ( "" , "" ) ] <TAB> config = inliner . document . settings . env . app . config <TAB> ret = [ ] <TAB> for i , issue_no in enumerate ( issue_nos ) : <TAB><TAB> node = self . make_node ( name , issue_no , config , options = options ) <TAB><TAB> ret . append ( node ) <TAB><TAB> <MASK> <TAB><TAB><TAB> sep = nodes . raw ( text = "" ,  "" , format = "" html "" ) <TAB><TAB><TAB> ret . append ( sep ) <TAB> return ret , [ ]",if i != len ( issue_nos ) - 1 :,if i == len ( issue_nos ) - 1 :,99.22076565636996,98.87,False
4673,"def init_messengers ( messengers ) : <TAB> for messenger in messengers : <TAB><TAB> <MASK> <TAB><TAB><TAB> module_path = messenger [ "" type "" ] <TAB><TAB><TAB> messenger [ "" type "" ] = messenger [ "" type "" ] . split ( "" . "" ) [ - 1 ] <TAB><TAB> else : <TAB><TAB><TAB> module_path = "" oncall.messengers. "" + messenger [ "" type "" ] <TAB><TAB> instance = getattr ( importlib . import_module ( module_path ) , messenger [ "" type "" ] ) ( <TAB><TAB><TAB> messenger <TAB><TAB> ) <TAB><TAB> for transport in instance . supports : <TAB><TAB><TAB> _active_messengers [ transport ] . append ( instance )","if ""."" in messenger [ ""type"" ] :","if ""."" in messenger [ ""type"" ] :",100.0,100.00,True
4674,"def _process_enum_definition ( self , tok ) : <TAB> fields = [ ] <TAB> for field in tok . fields : <TAB><TAB> <MASK> <TAB><TAB><TAB> expression = self . expression_parser . parse ( field . expression ) <TAB><TAB> else : <TAB><TAB><TAB> expression = None <TAB><TAB> fields . append ( c_ast . CEnumField ( name = field . name . first , value = expression ) ) <TAB> name = tok . enum_name <TAB> if name : <TAB><TAB> name = "" enum  %s "" % tok . enum_name . first <TAB> else : <TAB><TAB> name = self . _make_anonymous_type ( "" enum "" ) <TAB> return c_ast . CTypeDefinition ( <TAB><TAB> name = name , <TAB><TAB> type_definition = c_ast . CEnum ( <TAB><TAB><TAB> attributes = tok . attributes , fields = fields , name = name <TAB><TAB> ) , <TAB> )",if field . expression :,if field . expression :,100.0,100.00,True
4675,def result_iterator ( ) : <TAB> try : <TAB><TAB> # reverse to keep finishing order <TAB><TAB> fs . reverse ( ) <TAB><TAB> while fs : <TAB><TAB><TAB> # Careful not to keep a reference to the popped future <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> yield fs . pop ( ) . result ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> yield fs . pop ( ) . result ( end_time - time . time ( ) ) <TAB> finally : <TAB><TAB> for future in fs : <TAB><TAB><TAB> future . cancel ( ),if timeout is None :,if end_time is None :,98.59996198434256,97.38,False
4676,"def has_encrypted_ssh_key_data ( self ) : <TAB> try : <TAB><TAB> ssh_key_data = self . get_input ( "" ssh_key_data "" ) <TAB> except AttributeError : <TAB><TAB> return False <TAB> try : <TAB><TAB> pem_objects = validate_ssh_private_key ( ssh_key_data ) <TAB><TAB> for pem_object in pem_objects : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB> except ValidationError : <TAB><TAB> pass <TAB> return False","if pem_object . get ( ""key_enc"" , False ) :",if self . verify_pem_object ( pem_object ) :,91.580469248477,92.24,False
4677,"def test_seq_object_transcription_method ( self ) : <TAB> for nucleotide_seq in test_seqs : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( <TAB><TAB><TAB><TAB> repr ( Seq . transcribe ( nucleotide_seq ) ) , <TAB><TAB><TAB><TAB> repr ( nucleotide_seq . transcribe ( ) ) , <TAB><TAB><TAB> )","if isinstance ( nucleotide_seq , Seq . Seq ) :","if isinstance ( nucleotide_seq , Seq . Seq ) :",100.0,100.00,True
4678,"def max_elevation ( self ) : <TAB> max_el = None <TAB> for y in xrange ( self . height ) : <TAB><TAB> for x in xrange ( self . width ) : <TAB><TAB><TAB> el = self . elevation [ "" data "" ] [ y ] [ x ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> max_el = el <TAB> return max_el",if max_el is None or el > max_el :,if el > max_el :,85.21194364335163,93.37,False
4679,"def stress ( mapping , index ) : <TAB> for count in range ( OPERATIONS ) : <TAB><TAB> function = random . choice ( functions ) <TAB><TAB> function ( mapping , index ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" \r "" , len ( mapping ) , ""   "" * 7 , end = "" "" ) <TAB> print ( )",if count % 1000 == 0 :,if count % 10000 == 0 :,98.08582335768273,97.33,False
4680,"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB><TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB><TAB> if "" terminology "" not in source . all_flags : <TAB><TAB><TAB> continue <TAB><TAB> try : <TAB><TAB><TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB><TAB> except UnitNotFound : <TAB><TAB><TAB> add = True <TAB><TAB> # Unit is already present <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> missing . append ( ( source . context , source . source , "" "" ) ) <TAB> if missing : <TAB><TAB> self . add_units ( None , missing )",if not add :,if add :,98.84849850087174,98.85,False
4681,"def get_generators ( self ) : <TAB> """"""Get a dict with all registered generators, indexed by name"""""" <TAB> generators = { } <TAB> for core in self . db . find ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> _generators = core . get_generators ( { } ) <TAB><TAB><TAB> if _generators : <TAB><TAB><TAB><TAB> generators [ str ( core . name ) ] = _generators <TAB> return generators","if hasattr ( core , ""get_generators"" ) :","if hasattr ( core , ""get_generators"" ) :",100.0,100.00,True
4682,"def act ( self , state ) : <TAB> if self . body . env . clock . frame < self . training_start_step : <TAB><TAB> return policy_util . random ( state , self , self . body ) . cpu ( ) . squeeze ( ) . numpy ( ) <TAB> else : <TAB><TAB> action = self . action_policy ( state , self , self . body ) <TAB><TAB> <MASK> <TAB><TAB><TAB> action = self . scale_action ( torch . tanh ( action ) ) # continuous action bound <TAB><TAB> return action . cpu ( ) . squeeze ( ) . numpy ( )",if not self . body . is_discrete :,if self . body . env . clock . frame < self . training_start_step :,70.32898016416573,90.22,False
4683,"def try_open_completions_event ( self , event = None ) : <TAB> "" (./) Open completion list after pause with no movement. "" <TAB> lastchar = self . text . get ( "" insert-1c "" ) <TAB> if lastchar in TRIGGERS : <TAB><TAB> args = TRY_A if lastchar == "" . "" else TRY_F <TAB><TAB> self . _delayed_completion_index = self . text . index ( "" insert "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . text . after_cancel ( self . _delayed_completion_id ) <TAB><TAB> self . _delayed_completion_id = self . text . after ( <TAB><TAB><TAB> self . popupwait , self . _delayed_open_completions , args <TAB><TAB> )",if self . _delayed_completion_id is not None :,if self . _delayed_completion_index == self . _delayed_completion_,93.75669689234286,94.34,False
4684,"def token_is_available ( self ) : <TAB> if self . token : <TAB><TAB> try : <TAB><TAB><TAB> resp = requests . get ( <TAB><TAB><TAB><TAB> "" https://api.shodan.io/account/profile?key= {0} "" . format ( self . token ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return True <TAB><TAB> except Exception as ex : <TAB><TAB><TAB> logger . error ( str ( ex ) ) <TAB> return False","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :","if resp and resp . status_code == 200 and ""available"" in resp . text :",90.55747686918643,95.83,False
4685,"def next_bar_ ( self , event ) : <TAB> bars = event . bar_dict <TAB> self . _current_minute = self . _minutes_since_midnight ( <TAB><TAB> self . ucontext . now . hour , self . ucontext . now . minute <TAB> ) <TAB> for day_rule , time_rule , func in self . _registry : <TAB><TAB> <MASK> <TAB><TAB><TAB> with ExecutionContext ( EXECUTION_PHASE . SCHEDULED ) : <TAB><TAB><TAB><TAB> with ModifyExceptionFromType ( EXC_TYPE . USER_EXC ) : <TAB><TAB><TAB><TAB><TAB> func ( self . ucontext , bars ) <TAB> self . _last_minute = self . _current_minute",if day_rule ( ) and time_rule ( ) :,"if day_rule ( self . ucontext , bars , time_rule ) :",93.27293381972152,95.16,False
4686,"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB><TAB> if c == "" & "" and not decode : <TAB><TAB><TAB> decode . append ( "" & "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if len ( decode ) == 1 : <TAB><TAB><TAB><TAB> r . append ( "" & "" ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB><TAB><TAB> decode = [ ] <TAB><TAB> elif decode : <TAB><TAB><TAB> decode . append ( c ) <TAB><TAB> else : <TAB><TAB><TAB> r . append ( c ) <TAB> if decode : <TAB><TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )","elif c == ""-"" and decode :","elif c == ""&"" :",97.50964051149411,98.12,False
4687,"def admin_audit_get ( admin_id ) : <TAB> if settings . app . demo_mode : <TAB><TAB> resp = utils . demo_get_cache ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return utils . jsonify ( resp ) <TAB> if not flask . g . administrator . super_user : <TAB><TAB> return utils . jsonify ( <TAB><TAB><TAB> { <TAB><TAB><TAB><TAB> "" error "" : REQUIRES_SUPER_USER , <TAB><TAB><TAB><TAB> "" error_msg "" : REQUIRES_SUPER_USER_MSG , <TAB><TAB><TAB> } , <TAB><TAB><TAB> 400 , <TAB><TAB> ) <TAB> admin = auth . get_by_id ( admin_id ) <TAB> resp = admin . get_audit_events ( ) <TAB> if settings . app . demo_mode : <TAB><TAB> utils . demo_set_cache ( resp ) <TAB> return utils . jsonify ( resp )",if resp :,if resp :,100.0,100.00,True
4688,"def vjp ( self , argnum , outgrad , ans , vs , gvs , args , kwargs ) : <TAB> try : <TAB><TAB> return self . vjps [ argnum ] ( outgrad , ans , vs , gvs , * args , * * kwargs ) <TAB> except KeyError : <TAB><TAB> <MASK> <TAB><TAB><TAB> errstr = "" Gradient of  {0}  not yet implemented. "" <TAB><TAB> else : <TAB><TAB><TAB> errstr = "" Gradient of  {0}  w.r.t. arg number  {1}  not yet implemented. "" <TAB><TAB> raise NotImplementedError ( errstr . format ( self . fun . __name__ , argnum ) )",if self . vjps == { } :,if self . fun is None :,94.87750674077209,96.00,False
4689,"def update ( self , * args , * * kwargs ) : <TAB> assert not self . readonly <TAB> longest_key = 0 <TAB> _dict = self . _dict <TAB> reverse = self . reverse <TAB> casereverse = self . casereverse <TAB> for iterable in args + ( kwargs , ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> iterable = iterable . items ( ) <TAB><TAB> for key , value in iterable : <TAB><TAB><TAB> longest_key = max ( longest_key , len ( key ) ) <TAB><TAB><TAB> _dict [ key ] = value <TAB><TAB><TAB> reverse [ value ] . append ( key ) <TAB><TAB><TAB> casereverse [ value . lower ( ) ] [ value ] + = 1 <TAB> self . _longest_key = max ( self . _longest_key , longest_key )","if isinstance ( iterable , ( dict , StenoDictionary ) ) :","if isinstance ( iterable , dict ) :",72.61699829211148,97.12,False
4690,"def update_ui ( self , window ) : <TAB> view = window . get_active_view ( ) <TAB> self . set_status ( view ) <TAB> lang = "" plain_text "" <TAB> if view : <TAB><TAB> buf = view . get_buffer ( ) <TAB><TAB> language = buf . get_language ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> lang = language . get_id ( ) <TAB><TAB> self . setup_smart_indent ( view , lang )",if language :,if language :,100.0,100.00,True
4691,"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB><TAB> if name not in skip : <TAB><TAB><TAB> name = "" __ %s __ "" % name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> res = eval ( expr , dict ) <TAB><TAB><TAB><TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB><TAB> if name not in skip : <TAB><TAB><TAB> name = "" __ %s __ "" % name <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> res = eval ( expr , dict ) <TAB><TAB><TAB><TAB> self . unop_test ( a , res , expr , name )","if hasattr ( a , name ) :","if name == ""a"" :",76.31507086387994,94.59,False
4692,"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB><TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB><TAB> # Set radio button layout <TAB><TAB> <MASK> <TAB><TAB><TAB> return 0.03 + ctrl . labelHeight * 3 <TAB><TAB> elif item [ "" layout "" ] == "" vert "" : <TAB><TAB><TAB> # for vertical take into account the nOptions <TAB><TAB><TAB> return ctrl . labelHeight * len ( item [ "" options "" ] )","if item [ ""layout"" ] == ""horiz"" :","if item [ ""layout"" ] == ""radio"" :",98.96076013483109,98.64,False
4693,"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB><TAB> if key in ( "" disabled "" , "" is_up "" ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> value = value == "" true "" <TAB><TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json )",if value is not None :,"if key == ""is_test"" :",95.16606033696908,95.58,False
4694,"def _read_json_content ( self , body_is_optional = False ) : <TAB> if "" content-length "" not in self . headers : <TAB><TAB> return self . send_error ( 411 ) if not body_is_optional else { } <TAB> try : <TAB><TAB> content_length = int ( self . headers . get ( "" content-length "" ) ) <TAB><TAB> if content_length == 0 and body_is_optional : <TAB><TAB><TAB> return { } <TAB><TAB> request = json . loads ( self . rfile . read ( content_length ) . decode ( "" utf-8 "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return request <TAB> except Exception : <TAB><TAB> logger . exception ( "" Bad request "" ) <TAB> self . send_error ( 400 )","if isinstance ( request , dict ) and ( request or body_is_optional ) :","if request . get ( ""status"" ) == 200 :",69.18580271799402,92.10,False
4695,"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> code , tags , used , refname = entry <TAB><TAB> for fullname in list ( used ) : <TAB><TAB><TAB> if used [ fullname ] == docname : <TAB><TAB><TAB><TAB> used . pop ( fullname ) <TAB><TAB> if len ( used ) == 0 : <TAB><TAB><TAB> modules . pop ( modname )",if entry is False :,"if modname == ""viewcode"" :",89.77702922158161,95.74,False
4696,"def frames ( self ) : <TAB> """"""an array of all the frames (including iframes) in the current window"""""" <TAB> from thug . DOM . W3C . HTML . HTMLCollection import HTMLCollection <TAB> frames = set ( ) <TAB> for frame in self . _findAll ( [ "" frame "" , "" iframe "" ] ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB><TAB><TAB> DOMImplementation . createHTMLElement ( self . window . doc , frame ) <TAB><TAB> frames . add ( frame . _node ) <TAB> return HTMLCollection ( self . doc , list ( frames ) )","if not getattr ( frame , ""_node"" , None ) :",if frame . _node is not None :,93.34824004853127,92.66,False
4697,"def check ( self , * * kw ) : <TAB> if not kw : <TAB><TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB><TAB> <MASK> <TAB><TAB><TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB><TAB> if "" file "" in kw : <TAB><TAB><TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw )","if ""dir"" in kw :","if ""dir"" in kw :",75.0,100.00,True
4698,"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB><TAB> duplicates = [ ] <TAB><TAB> for other_folder , other_path in folders . items ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> if other_path == path : <TAB><TAB><TAB><TAB> duplicates . append ( other_folder ) <TAB><TAB> if len ( duplicates ) : <TAB><TAB><TAB> self . duplicates [ folder ] = duplicates",if other_folder == folder :,if other_folder == folder :,100.0,100.00,True
4699,"def next ( self , buf , pos ) : <TAB> if pos > = len ( buf ) : <TAB><TAB> return EOF , "" "" , pos <TAB> mo = self . tokens_re . match ( buf , pos ) <TAB> if mo : <TAB><TAB> text = mo . group ( ) <TAB><TAB> type , regexp , test_lit = self . tokens [ mo . lastindex - 1 ] <TAB><TAB> pos = mo . end ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> type = self . literals . get ( text , type ) <TAB><TAB> return type , text , pos <TAB> else : <TAB><TAB> c = buf [ pos ] <TAB><TAB> return self . symbols . get ( c , None ) , c , pos + 1",if test_lit :,if regexp == test_lit :,91.14290457837495,97.67,False
4700,"def step ( self , action ) : <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB><TAB> obs , reward , done , info = self . env . step ( action ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _obs_buffer [ 0 ] = obs <TAB><TAB> if i == self . _skip - 1 : <TAB><TAB><TAB> self . _obs_buffer [ 1 ] = obs <TAB><TAB> total_reward + = reward <TAB><TAB> if done : <TAB><TAB><TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB> return max_frame , total_reward , done , info",if i == self . _skip - 2 :,if i == self . _skip - 2 :,100.0,100.00,True
4701,"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB><TAB> arg = arg [ 1 : ] <TAB> try : <TAB><TAB> value = int ( arg , base = 16 ) <TAB><TAB> if not ( 0 < = value < = 0xFFFFFF ) : <TAB><TAB><TAB> raise BadColourArgument ( arg ) <TAB><TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB><TAB> arg = arg . replace ( ""   "" , "" _ "" ) <TAB><TAB> method = getattr ( discord . Colour , arg , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise BadColourArgument ( arg ) <TAB><TAB> return method ( )","if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",if not method :,62.88114719537642,89.65,False
4702,"def run ( self , * * inputs ) : <TAB> if self . inputs . copy_inputs : <TAB><TAB> self . inputs . subjects_dir = os . getcwd ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> inputs [ "" subjects_dir "" ] = self . inputs . subjects_dir <TAB><TAB> for originalfile in [ self . inputs . in_file , self . inputs . in_norm ] : <TAB><TAB><TAB> copy2subjdir ( self , originalfile , folder = "" mri "" ) <TAB> return super ( SegmentCC , self ) . run ( * * inputs )","if ""subjects_dir"" in inputs :",if self . inputs . subjects_dir :,68.86572680204203,95.30,False
4703,"def get_queryset ( self ) : <TAB> if not hasattr ( self , "" _queryset "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> qs = self . queryset <TAB><TAB> else : <TAB><TAB><TAB> qs = self . model . _default_manager . get_queryset ( ) <TAB><TAB> # If the queryset isn't already ordered we need to add an <TAB><TAB> # artificial ordering here to make sure that all formsets <TAB><TAB> # constructed from this queryset have the same form order. <TAB><TAB> if not qs . ordered : <TAB><TAB><TAB> qs = qs . order_by ( self . model . _meta . pk . name ) <TAB><TAB> # Removed queryset limiting here. As per discussion re: #13023 <TAB><TAB> # on django-dev, max_num should not prevent existing <TAB><TAB> # related objects/inlines from being displayed. <TAB><TAB> self . _queryset = qs <TAB> return self . _queryset",if self . queryset is not None :,if self . queryset :,95.38408813647332,98.16,False
4704,"def visit_simple_stmt ( self , node : Node ) - > Iterator [ Line ] : <TAB> """"""Visit a statement without nested statements."""""" <TAB> is_suite_like = node . parent and node . parent . type in STATEMENT <TAB> if is_suite_like : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield from self . visit_default ( node ) <TAB><TAB> else : <TAB><TAB><TAB> yield from self . line ( + 1 ) <TAB><TAB><TAB> yield from self . visit_default ( node ) <TAB><TAB><TAB> yield from self . line ( - 1 ) <TAB> else : <TAB><TAB> if not self . is_pyi or not node . parent or not is_stub_suite ( node . parent ) : <TAB><TAB><TAB> yield from self . line ( ) <TAB><TAB> yield from self . visit_default ( node )",if self . is_pyi and is_stub_body ( node ) :,if self . is_pyi :,95.91752445067343,95.51,False
4705,"def rawDataReceived ( self , data ) : <TAB> if self . timeout > 0 : <TAB><TAB> self . resetTimeout ( ) <TAB> self . _pendingSize - = len ( data ) <TAB> if self . _pendingSize > 0 : <TAB><TAB> self . _pendingBuffer . write ( data ) <TAB> else : <TAB><TAB> passon = b "" "" <TAB><TAB> <MASK> <TAB><TAB><TAB> data , passon = data [ : self . _pendingSize ] , data [ self . _pendingSize : ] <TAB><TAB> self . _pendingBuffer . write ( data ) <TAB><TAB> rest = self . _pendingBuffer <TAB><TAB> self . _pendingBuffer = None <TAB><TAB> self . _pendingSize = None <TAB><TAB> rest . seek ( 0 , 0 ) <TAB><TAB> self . _parts . append ( rest . read ( ) ) <TAB><TAB> self . setLineMode ( passon . lstrip ( b "" \r \n "" ) )",if self . _pendingSize < 0 :,if self . _pendingSize > 0 :,99.16597132368267,98.93,False
4706,"def handle ( self , * args , * * options ) : <TAB> app_name = options . get ( "" app_name "" ) <TAB> job_name = options . get ( "" job_name "" ) <TAB> # hack since we are using job_name nargs='?' for -l to work <TAB> if app_name and not job_name : <TAB><TAB> job_name = app_name <TAB><TAB> app_name = None <TAB> if options . get ( "" list_jobs "" ) : <TAB><TAB> print_jobs ( only_scheduled = False , show_when = True , show_appname = True ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( "" Run a single maintenance job. Please specify the name of the job. "" ) <TAB><TAB><TAB> return <TAB><TAB> self . runjob ( app_name , job_name , options )",if not job_name :,"if options . get ( ""show_maintenance"" ) :",97.75989932327887,95.05,False
4707,"def _exportReceived ( self , content , error = False , server = None , context = { } , * * kwargs ) : <TAB> if error : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . error . emit ( content [ "" message "" ] , True ) <TAB><TAB> else : <TAB><TAB><TAB> self . error . emit ( "" Can ' t export the project from the server "" , True ) <TAB><TAB> self . finished . emit ( ) <TAB><TAB> return <TAB> self . finished . emit ( )",if content :,"if content [ ""message"" ] :",96.39204032925886,95.19,False
4708,"def __iter__ ( self ) : <TAB> n = self . n <TAB> k = self . k <TAB> j = int ( np . ceil ( n / k ) ) <TAB> for i in range ( k ) : <TAB><TAB> test_index = np . zeros ( n , dtype = bool ) <TAB><TAB> <MASK> <TAB><TAB><TAB> test_index [ i * j : ( i + 1 ) * j ] = True <TAB><TAB> else : <TAB><TAB><TAB> test_index [ i * j : ] = True <TAB><TAB> train_index = np . logical_not ( test_index ) <TAB><TAB> yield train_index , test_index",if i < k - 1 :,if i + 1 < k :,83.53053791141454,97.39,False
4709,"def addType ( self , graphene_type ) : <TAB> meta = get_meta ( graphene_type ) <TAB> if meta : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _typeMap [ meta . name ] = graphene_type <TAB><TAB> else : <TAB><TAB><TAB> raise Exception ( <TAB><TAB><TAB><TAB> "" Type  {typeName}  already exists in the registry. "" . format ( <TAB><TAB><TAB><TAB><TAB> typeName = meta . name <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> else : <TAB><TAB> raise Exception ( "" Cannot add unnamed type or a non-type to registry. "" )",if not graphene_type in self . _typeMap :,if meta . name in self . _typeMap :,69.47176109148879,97.00,False
4710,"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB><TAB> if size == 0 : <TAB><TAB><TAB> bsize = 0 <TAB><TAB> elif size < = 3 : <TAB><TAB><TAB> bsize = 4 <TAB><TAB> <MASK> <TAB><TAB><TAB> bsize = 8 <TAB><TAB> elif size < = 9 : <TAB><TAB><TAB> bsize = 12 <TAB><TAB> elif size < = 12 : <TAB><TAB><TAB> bsize = 16 <TAB><TAB> else : <TAB><TAB><TAB> bsize = 20 <TAB><TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 6 :,elif size <= 6 :,100.0,100.00,True
4711,"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB><TAB> <MASK> <TAB><TAB><TAB> out . append ( sep ) <TAB><TAB> if isinstance ( item , ParseResults ) : <TAB><TAB><TAB> out + = item . _asStringList ( ) <TAB><TAB> else : <TAB><TAB><TAB> out . append ( str ( item ) ) <TAB> return out",if out and sep :,if sep :,95.19699207816723,97.01,False
4712,"def open_file_input ( cli_parsed ) : <TAB> files = glob . glob ( os . path . join ( cli_parsed . d , "" *report.html "" ) ) <TAB> if len ( files ) > 0 : <TAB><TAB> print ( "" \n [*] Done! Report written in the  "" + cli_parsed . d + ""  folder! "" ) <TAB><TAB> print ( "" Would you like to open the report now? [Y/n] "" ) <TAB><TAB> while True : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> response = input ( ) . lower ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> return strtobool ( response ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> print ( "" Please respond with y or n "" ) <TAB> else : <TAB><TAB> print ( "" [*] No report files found to open, perhaps no hosts were successful "" ) <TAB><TAB> return False","if response == """" :","if response == ""y"" :",99.15540750078014,99.15,False
4713,"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB><TAB><TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB><TAB> else : <TAB><TAB><TAB> config [ valname ] = value <TAB> for name in config : <TAB><TAB> if name in self . values : <TAB><TAB><TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config","if ""."" in valname :","if ""."" in valname :",100.0,100.00,True
4714,"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB><TAB> try : <TAB><TAB><TAB> result_list . append ( f . get_result ( ) ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> exc_info = sys . exc_info ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> if not isinstance ( e , self . quiet_exceptions ) : <TAB><TAB><TAB><TAB><TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB><TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB><TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB><TAB> return list ( result_list )",if exc_info is None :,if exc_info is None :,100.0,100.00,True
4715,"def test01e_json ( self ) : <TAB> "" Testing GeoJSON input/output. "" <TAB> if not GEOJSON : <TAB><TAB> return <TAB> for g in self . geometries . json_geoms : <TAB><TAB> geom = OGRGeometry ( g . wkt ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( g . json , geom . json ) <TAB><TAB><TAB> self . assertEqual ( g . json , geom . geojson ) <TAB><TAB> self . assertEqual ( OGRGeometry ( g . wkt ) , OGRGeometry ( geom . json ) )","if not hasattr ( g , ""not_equal"" ) :","if hasattr ( g , ""geojson"" ) :",92.98615037100475,95.13,False
4716,"def __init__ ( self , hub = None ) : # pylint: disable=unused-argument <TAB> if resolver . _resolver is None : <TAB><TAB> _resolver = resolver . _resolver = _DualResolver ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB><TAB> if config . resolver_timeout : <TAB><TAB><TAB> _resolver . network_resolver . lifetime = config . resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance ( resolver . _resolver , _DualResolver ) <TAB> self . _resolver = resolver . _resolver",if config . resolver_nameservers :,if config . resolver_nameservers :,100.0,100.00,True
4717,"def __iadd__ ( self , term ) : <TAB> if isinstance ( term , ( int , long ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> _gmp . mpz_add_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( term ) ) <TAB><TAB><TAB> return self <TAB><TAB> if - 65535 < term < 0 : <TAB><TAB><TAB> _gmp . mpz_sub_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( - term ) ) <TAB><TAB><TAB> return self <TAB><TAB> term = Integer ( term ) <TAB> _gmp . mpz_add ( self . _mpz_p , self . _mpz_p , term . _mpz_p ) <TAB> return self",if 0 <= term < 65536 :,if 0 <= term < 65536 :,100.0,100.00,True
4718,"def copy ( dst , src ) : <TAB> for ( k , v ) in src . iteritems ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> d = { } <TAB><TAB><TAB> dst [ k ] = d <TAB><TAB><TAB> copy ( d , v ) <TAB><TAB> else : <TAB><TAB><TAB> dst [ k ] = v","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",100.0,100.00,True
4719,"def generator ( self , data ) : <TAB> self . procs = OrderedDict ( ) <TAB> for task in data : <TAB><TAB> self . recurse_task ( task , 0 , 0 , self . procs ) <TAB> for offset , name , level , pid , ppid , uid , euid , gid in self . procs . values ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( <TAB><TAB><TAB><TAB> 0 , <TAB><TAB><TAB><TAB> [ <TAB><TAB><TAB><TAB><TAB> Address ( offset ) , <TAB><TAB><TAB><TAB><TAB> str ( name ) , <TAB><TAB><TAB><TAB><TAB> str ( level ) , <TAB><TAB><TAB><TAB><TAB> int ( pid ) , <TAB><TAB><TAB><TAB><TAB> int ( ppid ) , <TAB><TAB><TAB><TAB><TAB> int ( uid ) , <TAB><TAB><TAB><TAB><TAB> int ( gid ) , <TAB><TAB><TAB><TAB><TAB> int ( euid ) , <TAB><TAB><TAB><TAB> ] , <TAB><TAB><TAB> )",if offset :,if offset :,100.0,100.00,True
4720,"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB><TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB><TAB> family = db . get_family_from_handle ( family_handle ) <TAB><TAB> <MASK> <TAB><TAB><TAB> father_handle = family . get_father_handle ( ) <TAB><TAB><TAB> mother_handle = family . get_mother_handle ( ) <TAB><TAB><TAB> if not father_handle : <TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB> if not mother_handle : <TAB><TAB><TAB><TAB> return True <TAB> return False",if family :,if family :,100.0,100.00,True
4721,"def _arctic_task_exec ( request ) : <TAB> request . start_time = time . time ( ) <TAB> logging . debug ( <TAB><TAB> "" Executing asynchronous request for  {} / {} "" . format ( <TAB><TAB><TAB> request . library , request . symbol <TAB><TAB> ) <TAB> ) <TAB> result = None <TAB> try : <TAB><TAB> request . is_running = True <TAB><TAB> <MASK> <TAB><TAB><TAB> result = mongo_retry ( request . fun ) ( * request . args , * * request . kwargs ) <TAB><TAB> else : <TAB><TAB><TAB> result = request . fun ( * request . args , * * request . kwargs ) <TAB> except Exception as e : <TAB><TAB> request . exception = e <TAB> finally : <TAB><TAB> request . data = result <TAB><TAB> request . end_time = time . time ( ) <TAB><TAB> request . is_running = False <TAB> return result",if request . mongo_retry :,if request . retry :,75.20302245417159,98.60,False
4722,"def _setup_styles ( self ) : <TAB> for ttype , ndef in self . style : <TAB><TAB> escape = EscapeSequence ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> escape . fg = self . _color_index ( ndef [ "" color "" ] ) <TAB><TAB> if ndef [ "" bgcolor "" ] : <TAB><TAB><TAB> escape . bg = self . _color_index ( ndef [ "" bgcolor "" ] ) <TAB><TAB> if self . usebold and ndef [ "" bold "" ] : <TAB><TAB><TAB> escape . bold = True <TAB><TAB> if self . useunderline and ndef [ "" underline "" ] : <TAB><TAB><TAB> escape . underline = True <TAB><TAB> self . style_string [ str ( ttype ) ] = ( escape . color_string ( ) , escape . reset_string ( ) )","if ndef [ ""color"" ] :","if ndef [ ""color"" ] :",100.0,100.00,True
4723,"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB><TAB> if char != self . int_to_char [ self . blank_index ] : <TAB><TAB><TAB> # if this char is a repetition and remove_repetitions=true, <TAB><TAB><TAB> # skip. <TAB><TAB><TAB> if remove_repetitions and i != 0 and char == sequence [ i - 1 ] : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> string + = ""   "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> string = string + char <TAB> return string",elif char == self . labels [ self . space_index ] :,elif i == 0 :,94.54229461908588,93.33,False
4724,"def arith_expr ( self , nodelist ) : <TAB> node = self . com_node ( nodelist [ 0 ] ) <TAB> for i in range ( 2 , len ( nodelist ) , 2 ) : <TAB><TAB> right = self . com_node ( nodelist [ i ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> node = Add ( node , right , lineno = nodelist [ 1 ] . context ) <TAB><TAB> elif nodelist [ i - 1 ] . type == token . MINUS : <TAB><TAB><TAB> node = Sub ( node , right , lineno = nodelist [ 1 ] . context ) <TAB><TAB> else : <TAB><TAB><TAB> raise ValueError ( "" unexpected token:  %s "" % nodelist [ i - 1 ] [ 0 ] ) <TAB> return node",if nodelist [ i - 1 ] . type == token . PLUS :,if nodelist [ i - 1 ] . type == token . MINUS :,74.10064471052289,98.74,False
4725,"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB><TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB><TAB> start , stop = index . start , index . stop <TAB><TAB> new_start , new_stop = None , None <TAB><TAB> <MASK> <TAB><TAB><TAB> new_stop = length - start <TAB><TAB> if stop is not None : <TAB><TAB><TAB> new_start = length - stop <TAB><TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB><TAB> new_index = [ ] <TAB><TAB> for ind in index : <TAB><TAB><TAB> new_index . append ( length - ind ) <TAB> return new_index",if start is not None :,if start is not None :,100.0,100.00,True
4726,"def getRoots ( job ) : <TAB> if job not in visited : <TAB><TAB> visited . add ( job ) <TAB><TAB> <MASK> <TAB><TAB><TAB> list ( map ( lambda p : getRoots ( p ) , job . _directPredecessors ) ) <TAB><TAB> else : <TAB><TAB><TAB> roots . add ( job ) <TAB><TAB> # The following call ensures we explore all successor edges. <TAB><TAB> list ( map ( lambda c : getRoots ( c ) , job . _children + job . _followOns ) )",if len ( job . _directPredecessors ) > 0 :,if job . _directPredecessors :,92.04411462944556,94.17,False
4727,"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB><TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB><TAB> <MASK> <TAB><TAB><TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB><TAB><TAB> if current is not None : <TAB><TAB><TAB><TAB> collected . append ( current ) <TAB> return collected","if self . _is_true ( self . visit ( comparator_node , element ) ) :","if element [ ""type"" ] == comparator_node :",88.33210327613259,89.82,False
4728,"def func ( x , y ) : <TAB> try : <TAB><TAB> if x > y : <TAB><TAB><TAB> z = x + 2 * math . sin ( y ) <TAB><TAB><TAB> return z * * 2 <TAB><TAB> <MASK> <TAB><TAB><TAB> return 4 <TAB><TAB> else : <TAB><TAB><TAB> return 2 * * 3 <TAB> except ValueError : <TAB><TAB> foo = 0 <TAB><TAB> for i in range ( 4 ) : <TAB><TAB><TAB> foo + = i <TAB><TAB> return foo <TAB> except TypeError : <TAB><TAB> return 42 <TAB> else : <TAB><TAB> return 33 <TAB> finally : <TAB><TAB> print ( "" finished "" )",elif x == y :,elif x == y :,100.0,100.00,True
4729,"def set_filter ( self , dataset_opt ) : <TAB> """"""This function create and set the pre_filter to the obj as attributes"""""" <TAB> self . pre_filter = None <TAB> for key_name in dataset_opt . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> new_name = key_name . replace ( "" filters "" , "" filter "" ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> filt = instantiate_filters ( getattr ( dataset_opt , key_name ) ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> log . exception ( <TAB><TAB><TAB><TAB><TAB> "" Error trying to create  {} ,  {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB> new_name , getattr ( dataset_opt , key_name ) <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> setattr ( self , new_name , filt )","if ""filter"" in key_name :","if hasattr ( dataset_opt , key_name ) :",96.09915899892488,96.60,False
4730,"def _add_states_to_lookup ( <TAB> self , trackers_as_states , trackers_as_actions , domain , online = False ) : <TAB> """"""Add states to lookup dict"""""" <TAB> for states in trackers_as_states : <TAB><TAB> active_form = self . _get_active_form_name ( states [ - 1 ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # modify the states <TAB><TAB><TAB> states = self . _modified_states ( states ) <TAB><TAB><TAB> feature_key = self . _create_feature_key ( states ) <TAB><TAB><TAB> # even if there are two identical feature keys <TAB><TAB><TAB> # their form will be the same <TAB><TAB><TAB> # because of `active_form_...` feature <TAB><TAB><TAB> self . lookup [ feature_key ] = active_form",if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,if active_form is not None :,87.9864290110812,91.23,False
4731,"def list_loaded_payloads ( self ) : <TAB> print ( helpers . color ( "" \n  [*] Available Payloads: \n "" ) ) <TAB> lastBase = None <TAB> x = 1 <TAB> for name in sorted ( self . active_payloads . keys ( ) ) : <TAB><TAB> parts = name . split ( "" / "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( ) <TAB><TAB> lastBase = parts [ 0 ] <TAB><TAB> print ( "" \t %s ) \t %s "" % ( x , "" {0: <24} "" . format ( name ) ) ) <TAB><TAB> x + = 1 <TAB> print ( "" \n "" ) <TAB> return",if lastBase and parts [ 0 ] != lastBase :,if lastBase is None or parts [ 0 ] != lastBase :,84.9387247358392,97.54,False
4732,"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB><TAB> if - 1024 < item < 1024 : <TAB><TAB><TAB> return str ( item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return vw . reprPointer ( item ) <TAB><TAB> else : <TAB><TAB><TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB><TAB> return reprComplex ( vw , item ) # recurse <TAB> elif ptype is dict : <TAB><TAB> return "" { %s } "" % "" , "" . join ( <TAB><TAB><TAB> [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB><TAB> ) <TAB> else : <TAB><TAB> return repr ( item )",elif vw . isValidPointer ( item ) :,elif - 1024 < item < 1024 :,66.1071239358925,96.78,False
4733,"def ConfigSectionMap ( section ) : <TAB> config = ConfigParser . RawConfigParser ( ) <TAB> configurations = config_manager ( ) # Class from mkchromecast.config <TAB> configf = configurations . configf <TAB> config . read ( configf ) <TAB> dict1 = { } <TAB> options = config . options ( section ) <TAB> for option in options : <TAB><TAB> try : <TAB><TAB><TAB> dict1 [ option ] = config . get ( section , option ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> DebugPrint ( "" skip:  %s "" % option ) <TAB><TAB> except : <TAB><TAB><TAB> print ( "" Exception on  %s ! "" % option ) <TAB><TAB><TAB> dict1 [ option ] = None <TAB> return dict1",if dict1 [ option ] == - 1 :,"if option in [ ""skip"" , ""skip_in"" ] :",96.72979242818671,93.09,False
4734,"def on_success ( result ) : <TAB> subtasks = { } <TAB> if result : <TAB><TAB> subtasks = { <TAB><TAB><TAB> self . nodes_keys . inverse [ s [ "" node_id "" ] ] : s . get ( "" subtask_id "" ) <TAB><TAB><TAB> for s in result <TAB><TAB><TAB> <MASK> <TAB><TAB> } <TAB> if subtasks : <TAB><TAB> print ( "" subtask finished "" ) <TAB><TAB> self . next ( ) <TAB> else : <TAB><TAB> print ( "" waiting for a subtask to finish "" ) <TAB><TAB> time . sleep ( 10 )","if s . get ( ""status"" ) == ""Failure""","if s [ ""subtask_id"" ] not in self . nodes_keys . inverse",65.15974273606307,90.49,False
4735,"def redirect_aware_commmunicate ( p , sys = _sys ) : <TAB> """"""Variant of process.communicate that works with in process I/O redirection."""""" <TAB> assert sys is not None <TAB> out , err = p . communicate ( ) <TAB> if redirecting_io ( sys = sys ) : <TAB><TAB> if out : <TAB><TAB><TAB> # We don't unicodify in Python2 because sys.stdout may be a <TAB><TAB><TAB> # cStringIO.StringIO object, which does not accept Unicode strings <TAB><TAB><TAB> out = unicodify ( out ) <TAB><TAB><TAB> sys . stdout . write ( out ) <TAB><TAB><TAB> out = None <TAB><TAB> <MASK> <TAB><TAB><TAB> err = unicodify ( err ) <TAB><TAB><TAB> sys . stderr . write ( err ) <TAB><TAB><TAB> err = None <TAB> return out , err",if err :,if err :,100.0,100.00,True
4736,"def __exit__ ( self , * args , * * kwargs ) : <TAB> self . _samples_cache = { } <TAB> if is_validation_enabled ( ) and isinstance ( self . prior , dict ) : <TAB><TAB> extra = set ( self . prior ) - self . _param_hits <TAB><TAB> <MASK> <TAB><TAB><TAB> warnings . warn ( <TAB><TAB><TAB><TAB> "" pyro.module prior did not find params [ ' {} ' ].  "" <TAB><TAB><TAB><TAB> "" Did you instead mean one of [ ' {} ' ]? "" . format ( <TAB><TAB><TAB><TAB><TAB> "" ' ,  ' "" . join ( extra ) , "" ' ,  ' "" . join ( self . _param_misses ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> ) <TAB> return super ( ) . __exit__ ( * args , * * kwargs )",if extra :,if extra :,100.0,100.00,True
4737,def __download_thread ( self ) : <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . __current_download = self . __queue . get ( ) <TAB><TAB><TAB> self . __download_file ( self . __current_download ) <TAB><TAB> time . sleep ( 0.1 ),if not self . __queue . empty ( ) :,if self . __current_download is None :,82.4008539735156,90.52,False
4738,"def plot_timer_command ( args ) : <TAB> import nnabla . monitor as M <TAB> format_unit = dict ( <TAB><TAB> s = "" seconds "" , <TAB><TAB> m = "" minutes "" , <TAB><TAB> h = "" hours "" , <TAB><TAB> d = "" days "" , <TAB> ) <TAB> if not args . ylabel : <TAB><TAB> <MASK> <TAB><TAB><TAB> args . ylabel = "" Total elapsed time [ {} ] "" . format ( format_unit [ args . time_unit ] ) <TAB><TAB> else : <TAB><TAB><TAB> args . ylabel = "" Elapsed time [ {} /iter] "" . format ( format_unit [ args . time_unit ] ) <TAB> plot_any_command ( <TAB><TAB> args , M . plot_time_elapsed , dict ( elapsed = args . elapsed , unit = args . time_unit ) <TAB> ) <TAB> return True",if args . elapsed :,if args . elapsed :,100.0,100.00,True
4739,"def resolve_page ( root : ChannelContext [ models . MenuItem ] , info , * * kwargs ) : <TAB> if root . node . page_id : <TAB><TAB> requestor = get_user_or_app_from_context ( info . context ) <TAB><TAB> requestor_has_access_to_all = requestor . is_active and requestor . has_perm ( <TAB><TAB><TAB> PagePermissions . MANAGE_PAGES <TAB><TAB> ) <TAB><TAB> return ( <TAB><TAB><TAB> PageByIdLoader ( info . context ) <TAB><TAB><TAB> . load ( root . node . page_id ) <TAB><TAB><TAB> . then ( <TAB><TAB><TAB><TAB> lambda page : page <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> else None <TAB><TAB><TAB> ) <TAB><TAB> ) <TAB> return None",if requestor_has_access_to_all or page . is_visible,if requestor_has_access_to_all,68.63016147122642,96.85,False
4740,"def find ( self , pattern ) : <TAB> """"""Find pages in database."""""" <TAB> results = self . _search_keyword ( pattern ) <TAB> pat = re . compile ( "" (.*?)( %s )(.*?)(  \ (.* \ ))?$ "" % re . escape ( pattern ) , re . I ) <TAB> if results : <TAB><TAB> for name , keyword , url in results : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> keyword = pat . sub ( <TAB><TAB><TAB><TAB><TAB> r "" \ 1 \ 033[1;31m \ 2 \ 033[0m \ 3 \ 033[1;33m \ 4 \ 033[0m "" , keyword <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> print ( "" %s  -  %s "" % ( keyword , name ) ) <TAB> else : <TAB><TAB> raise RuntimeError ( "" %s : nothing appropriate. "" % pattern )",if os . isatty ( sys . stdout . fileno ( ) ) :,if url :,85.34264132193358,94.62,False
4741,"def _certonly_new_request_common ( self , mock_client , args = None ) : <TAB> with mock . patch ( <TAB><TAB> "" certbot._internal.main._find_lineage_for_domains_and_certname "" <TAB> ) as mock_renewal : <TAB><TAB> mock_renewal . return_value = ( "" newcert "" , None ) <TAB><TAB> with mock . patch ( "" certbot._internal.main._init_le_client "" ) as mock_init : <TAB><TAB><TAB> mock_init . return_value = mock_client <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> args = [ ] <TAB><TAB><TAB> args + = "" -d foo.bar -a standalone certonly "" . split ( ) <TAB><TAB><TAB> self . _call ( args )",if args is None :,if args is None :,100.0,100.00,True
4742,"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB><TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB><TAB> <MASK> <TAB><TAB><TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB><TAB> elif hasattr ( args [ 0 ] , "" items "" ) : <TAB><TAB><TAB> items = list ( args [ 0 ] . items ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> items = list ( args [ 0 ] ) <TAB><TAB> self . _items = items <TAB> else : <TAB><TAB> self . _items = [ ] <TAB> if kw : <TAB><TAB> self . _items . extend ( kw . items ( ) )","if hasattr ( args [ 0 ] , ""iteritems"" ) :","if hasattr ( args [ 0 ] , ""iteritems"" ) :",100.0,100.00,True
4743,"def test08_ExceptionTypes ( self ) : <TAB> self . assertTrue ( issubclass ( db . DBError , Exception ) ) <TAB> for i , j in db . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertTrue ( issubclass ( j , db . DBError ) , msg = i ) <TAB><TAB><TAB> if i not in ( "" DBKeyEmptyError "" , "" DBNotFoundError "" ) : <TAB><TAB><TAB><TAB> self . assertFalse ( issubclass ( j , KeyError ) , msg = i ) <TAB> # This two exceptions have two bases <TAB> self . assertTrue ( issubclass ( db . DBKeyEmptyError , KeyError ) ) <TAB> self . assertTrue ( issubclass ( db . DBNotFoundError , KeyError ) )","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :","if i not in ( ""DBError"" , ""DBNotFoundError"" ) :",91.82111021121784,92.28,False
4744,"def _delegate_to_sinks ( self , value : Any ) - > None : <TAB> for sink in self . _sinks : <TAB><TAB> if isinstance ( sink , AgentT ) : <TAB><TAB><TAB> await sink . send ( value = value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> await cast ( TopicT , sink ) . send ( value = value ) <TAB><TAB> else : <TAB><TAB><TAB> await maybe_async ( cast ( Callable , sink ) ( value ) )","elif isinstance ( sink , ChannelT ) :","elif isinstance ( sink , TopicT ) :",73.43699879082564,98.04,False
4745,"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB><TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB><TAB> if str_in [ pos ] == start_tag : <TAB><TAB><TAB> depth + = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> depth - = 1 <TAB><TAB> if depth == 0 : <TAB><TAB><TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",elif str_in [ pos ] == end_tag :,elif str_in [ pos ] == end_tag :,100.0,100.00,True
4746,"def confirm ( request ) : <TAB> details = request . session . get ( "" reauthenticate "" ) <TAB> if not details : <TAB><TAB> return redirect ( "" home "" ) <TAB> # Monkey patch request <TAB> request . user = User . objects . get ( pk = details [ "" user_pk "" ] ) <TAB> if request . method == "" POST "" : <TAB><TAB> confirm_form = PasswordConfirmForm ( request , request . POST ) <TAB><TAB> <MASK> <TAB><TAB><TAB> request . session . pop ( "" reauthenticate "" ) <TAB><TAB><TAB> request . session [ "" reauthenticate_done "" ] = True <TAB><TAB><TAB> return redirect ( "" social:complete "" , backend = details [ "" backend "" ] ) <TAB> else : <TAB><TAB> confirm_form = PasswordConfirmForm ( request ) <TAB> context = { "" confirm_form "" : confirm_form } <TAB> context . update ( details ) <TAB> return render ( request , "" accounts/confirm.html "" , context )",if confirm_form . is_valid ( ) :,if not confirm_form . is_valid ( ) :,99.38336579179979,98.99,False
4747,"def verify_credentials ( self ) : <TAB> if self . enabled : <TAB><TAB> response = requests . get ( <TAB><TAB><TAB> "" https://api.exotel.com/v1/Accounts/ {sid} "" . format ( sid = self . account_sid ) , <TAB><TAB><TAB> auth = ( self . api_key , self . api_token ) , <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> frappe . throw ( _ ( "" Invalid credentials "" ) )",if response . status_code != 200 :,if response . status_code != 200 :,100.0,100.00,True
4748,"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB><TAB> icon = "" class "" <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> icon = "" method_priv "" <TAB><TAB> elif tok . visibility == "" protected "" : <TAB><TAB><TAB> icon = "" method_prot "" <TAB><TAB> else : <TAB><TAB><TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] )","if tok . visibility == ""private"" :","if tok . visibility == ""private"" :",100.0,100.00,True
4749,"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB><TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB><TAB> omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB><TAB> start = event == "" start "" <TAB><TAB> if omit and start : <TAB><TAB><TAB> omitted_kws + = 1 <TAB><TAB> if not omitted_kws : <TAB><TAB><TAB> yield event , elem <TAB><TAB> <MASK> <TAB><TAB><TAB> elem . clear ( ) <TAB><TAB> if omit and not start : <TAB><TAB><TAB> omitted_kws - = 1",elif not start :,"elif event == ""end"" :",97.97463635749418,96.14,False
4750,"def on_double_click ( self , event ) : <TAB> # TODO: don't act when the click happens below last item <TAB> path = self . get_selected_path ( ) <TAB> kind = self . get_selected_kind ( ) <TAB> name = self . get_selected_name ( ) <TAB> if kind == "" file "" : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . open_file ( path ) <TAB><TAB> else : <TAB><TAB><TAB> self . open_path_with_system_app ( path ) <TAB> elif kind == "" dir "" : <TAB><TAB> self . request_focus_into ( path ) <TAB> return "" break """,if self . should_open_name_in_thonny ( name ) :,if os . path . isfile ( path ) :,71.43462059367985,92.29,False
4751,"def search_cve ( db : DatabaseInterface , product : Product ) - > dict : <TAB> result = { } <TAB> for query_result in db . fetch_multiple ( QUERIES [ "" cve_lookup "" ] ) : <TAB><TAB> cve_entry = CveDbEntry ( * query_result ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result [ cve_entry . cve_id ] = { <TAB><TAB><TAB><TAB> "" score2 "" : cve_entry . cvss_v2_score , <TAB><TAB><TAB><TAB> "" score3 "" : cve_entry . cvss_v3_score , <TAB><TAB><TAB><TAB> "" cpe_version "" : build_version_string ( cve_entry ) , <TAB><TAB><TAB> } <TAB> return result","if _product_matches_cve ( product , cve_entry ) :",if cve_entry . cve_id == product . id :,93.98340812840141,93.90,False
4752,"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB><TAB> if not f . endswith ( "" .go "" ) : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> files . append ( f ) <TAB><TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime",if APP_CONFIG . nobuild_files . match ( f ) :,if not os . path . exists ( f ) :,65.54716848358206,92.31,False
4753,"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> old_mtime , result = cache . pop ( filename ) <TAB><TAB><TAB> if old_mtime == mtime : <TAB><TAB><TAB><TAB> # Move to the end <TAB><TAB><TAB><TAB> cache [ filename ] = old_mtime , result <TAB><TAB><TAB><TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB><TAB> cache [ filename ] = mtime , result # at the end <TAB><TAB> if len ( cache ) > max_size : <TAB><TAB><TAB> cache . popitem ( last = False ) <TAB> return result",if filename in cache :,if len ( cache ) > max_size :,94.4272031787381,95.31,False
4754,"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB><TAB> # The type checker can't know the true type of item! <TAB><TAB> item = cast ( TupleStr4 , item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> typ = "" number "" <TAB><TAB><TAB> val = item [ 0 ] <TAB><TAB> elif item [ 1 ] : <TAB><TAB><TAB> typ = "" name "" <TAB><TAB><TAB> val = item [ 1 ] <TAB><TAB> elif item [ 2 ] : <TAB><TAB><TAB> typ = item [ 2 ] <TAB><TAB><TAB> val = item [ 2 ] <TAB><TAB> elif item [ 3 ] : <TAB><TAB><TAB> typ = item [ 3 ] <TAB><TAB><TAB> val = item [ 3 ] <TAB><TAB> yield Token ( typ , val )",if item [ 0 ] :,if item [ 0 ] :,75.0,100.00,True
4755,"def _show_encoders ( self , * args , * * kwargs ) : <TAB> if issubclass ( self . current_module . __class__ , BasePayload ) : <TAB><TAB> encoders = self . current_module . get_encoders ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> headers = ( "" Encoder "" , "" Name "" , "" Description "" ) <TAB><TAB><TAB> print_table ( headers , * encoders , max_column_length = 100 ) <TAB><TAB><TAB> return <TAB> print_error ( "" No encoders available "" )",if encoders :,if encoders :,100.0,100.00,True
4756,"def __init__ ( self ) : <TAB> Builder . __init__ ( self , commandName = "" VCExpress.exe "" , formatName = "" msvcProject "" ) <TAB> for key in [ "" VS90COMNTOOLS "" , "" VC80COMNTOOLS "" , "" VC71COMNTOOLS "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . programDir = os . path . join ( os . environ [ key ] , "" .. "" , "" IDE "" ) <TAB> if self . programDir is None : <TAB><TAB> for version in [ "" 9.0 "" , "" 8 "" , "" .NET 2003 "" ] : <TAB><TAB><TAB> msvcDir = ( <TAB><TAB><TAB><TAB> "" C: \\ Program Files \\ Microsoft Visual Studio  %s \\ Common7 \\ IDE "" % version <TAB><TAB><TAB> ) <TAB><TAB><TAB> if os . path . exists ( msvcDir ) : <TAB><TAB><TAB><TAB> self . programDir = msvcDir",if os . environ . has_key ( key ) :,if os . path . exists ( os . environ [ key ] ) :,75.23829179309648,95.81,False
4757,"def _inner ( * args , * * kwargs ) : <TAB> component_manager = args [ 0 ] . component_manager <TAB> for condition_name in condition_names : <TAB><TAB> condition_result , err_msg = component_manager . evaluate_condition ( condition_name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ComponentStartConditionNotMetError ( err_msg ) <TAB> if not component_manager . all_components_running ( * components ) : <TAB><TAB> raise ComponentsNotStartedError ( <TAB><TAB><TAB> f "" the following required components have not yet started:  { json . dumps ( components ) } "" <TAB><TAB> ) <TAB> return method ( * args , * * kwargs )",if not condition_result :,if not condition_result :,100.0,100.00,True
4758,"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB><TAB> try : <TAB><TAB><TAB> svalue = str ( value ) <TAB><TAB><TAB> if not svalue : <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . tk . getdouble ( svalue ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> return self . tk . getint ( svalue ) <TAB><TAB> except ( ValueError , TclError ) : <TAB><TAB><TAB> pass <TAB> return value","elif ""."" in svalue :","elif isinstance ( svalue , float ) :",67.67048946330333,95.86,False
4759,"def check_songs ( ) : <TAB> desc = numeric_phrase ( "" %d  song "" , "" %d  songs "" , len ( songs ) ) <TAB> with Task ( _ ( "" Rescan songs "" ) , desc ) as task : <TAB><TAB> task . copool ( check_songs ) <TAB><TAB> for i , song in enumerate ( songs ) : <TAB><TAB><TAB> song = song . _song <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> app . library . reload ( song ) <TAB><TAB><TAB> task . update ( ( float ( i ) + 1 ) / len ( songs ) ) <TAB><TAB><TAB> yield",if song in app . library :,if song :,78.42661352211438,96.72,False
4760,"def initialize ( self ) : <TAB> nn . init . xavier_uniform_ ( self . linear . weight . data ) <TAB> if self . linear . bias is not None : <TAB><TAB> self . linear . bias . data . uniform_ ( - 1.0 , 1.0 ) <TAB> if self . self_layer : <TAB><TAB> nn . init . xavier_uniform_ ( self . linear_self . weight . data ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . linear_self . bias . data . uniform_ ( - 1.0 , 1.0 )",if self . linear_self . bias is not None :,if self . linear_self . bias is not None :,75.0,100.00,True
4761,"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> value = row [ idx ] <TAB><TAB> except IndexError : <TAB><TAB><TAB> value = "" "" <TAB><TAB> result = test ( value ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if result : <TAB><TAB><TAB><TAB> return not self . inverse # True <TAB><TAB> else : <TAB><TAB><TAB> if not result : <TAB><TAB><TAB><TAB> return self . inverse # False <TAB> <MASK> <TAB><TAB> return self . inverse # False <TAB> else : <TAB><TAB> return not self . inverse # True",if self . any_match :,"elif value == """" :",64.7165714153935,92.65,False
4762,"def toterminal ( self , tw ) : <TAB> for element in self . chain : <TAB><TAB> element [ 0 ] . toterminal ( tw ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tw . line ( "" "" ) <TAB><TAB><TAB> tw . line ( element [ 2 ] , yellow = True ) <TAB> super ( ExceptionChainRepr , self ) . toterminal ( tw )",if element [ 2 ] is not None :,if element [ 1 ] :,67.00202916903946,93.62,False
4763,"def runMainLoop ( self ) : <TAB> """"""The curses gui main loop."""""" <TAB> # pylint: disable=no-member <TAB> # <TAB> # Do NOT change g.app! <TAB> self . curses_app = LeoApp ( ) <TAB> stdscr = curses . initscr ( ) <TAB> if 1 : # Must follow initscr. <TAB><TAB> self . dump_keys ( ) <TAB> try : <TAB><TAB> self . curses_app . run ( ) <TAB><TAB> # run calls CApp.main(), which calls CGui.run(). <TAB> finally : <TAB><TAB> curses . nocbreak ( ) <TAB><TAB> stdscr . keypad ( 0 ) <TAB><TAB> curses . echo ( ) <TAB><TAB> curses . endwin ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> g . pr ( "" Exiting Leo... "" )","if ""shutdown"" in g . app . debug :",if g . isEnabledForDebug ( ) :,96.61643869604704,95.57,False
4764,"def test_chunkcoding ( self ) : <TAB> for native , utf8 in zip ( * [ StringIO ( f ) . readlines ( ) for f in self . tstring ] ) : <TAB><TAB> u = self . decode ( native ) [ 0 ] <TAB><TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] )",if self . roundtriptest :,"if self . tstring . startswith ( ""utf-8"" ) :",68.53002864050605,91.83,False
4765,"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB><TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB><TAB><TAB> for line in f . readlines ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB><TAB> if explicit : <TAB><TAB><TAB> log . warning ( <TAB><TAB><TAB><TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB><TAB><TAB><TAB> self . sanitize_allowlist_file , <TAB><TAB><TAB> )","if not line . startswith ( ""#"" ) :","if line . startswith ( ""Allow list:"" ) :",94.97239252665265,97.18,False
4766,"def get_all_extensions ( subtree = None ) : <TAB> if subtree is None : <TAB><TAB> subtree = full_extension_tree ( ) <TAB> result = [ ] <TAB> if isinstance ( subtree , dict ) : <TAB><TAB> for value in subtree . values ( ) : <TAB><TAB><TAB> if isinstance ( value , dict ) : <TAB><TAB><TAB><TAB> result + = get_all_extensions ( value ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> result + = value . extensions <TAB><TAB><TAB> elif isinstance ( value , ( list , tuple ) ) : <TAB><TAB><TAB><TAB> result + = value <TAB> elif isinstance ( subtree , ( ContentTypeMapping , ContentTypeDetector ) ) : <TAB><TAB> result = subtree . extensions <TAB> elif isinstance ( subtree , ( list , tuple ) ) : <TAB><TAB> result = subtree <TAB> return result","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :","elif isinstance ( value , ContentTypeMapping ) :",81.1792918814249,97.36,False
4767,"def _configuration_dict_to_commandlist ( name , config_dict ) : <TAB> command_list = [ "" config: %s "" % name ] <TAB> for key , value in config_dict . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> b = "" true "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> b = "" false "" <TAB><TAB><TAB> command_list . append ( "" %s : %s "" % ( key , b ) ) <TAB><TAB> else : <TAB><TAB><TAB> command_list . append ( "" %s : %s "" % ( key , value ) ) <TAB> return command_list",if type ( value ) is bool :,"if key in [ ""name"" , ""name"" ] :",93.49189860918553,93.67,False
4768,"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB><TAB><TAB> continue <TAB><TAB> if info_strings is not None : <TAB><TAB><TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB><TAB> if line . startswith ( "" vermagic "" ) : <TAB><TAB><TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB><TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo",if not line :,"if line . startswith ( ""vermagic"" ) :",82.69764989135678,96.26,False
4769,"def zip_random_open_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile . ZipFile ( f , "" r "" , compression ) as zipfp : <TAB><TAB> zipdata1 = [ ] <TAB><TAB> with zipfp . open ( TESTFN ) as zipopen1 : <TAB><TAB><TAB> while True : <TAB><TAB><TAB><TAB> read_data = zipopen1 . read ( randint ( 1 , 1024 ) ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> break <TAB><TAB><TAB><TAB> zipdata1 . append ( read_data ) <TAB><TAB> testdata = "" "" . join ( zipdata1 ) <TAB><TAB> self . assertEqual ( len ( testdata ) , len ( self . data ) ) <TAB><TAB> self . assertEqual ( testdata , self . data )",if not read_data :,if not read_data :,100.0,100.00,True
4770,"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB><TAB> value , last_update = self . cache [ args ] <TAB><TAB> age = now - last_update <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _call_count = 0 <TAB><TAB><TAB> raise AttributeError <TAB><TAB> if self . ctl : <TAB><TAB><TAB> self . _call_count + = 1 <TAB><TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB><TAB> value = func ( * args ) <TAB><TAB> if value : <TAB><TAB><TAB> self . cache [ args ] = ( value , now ) <TAB><TAB> return value <TAB> except TypeError : <TAB><TAB> return func ( * args )",if self . _call_count > self . ctl or age > self . ttl :,if age <= 0 :,65.99922849899221,92.06,False
4771,"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB><TAB> return <TAB> if args . strings and not args . no_content : <TAB><TAB> if type ( res ) == tuple : <TAB><TAB><TAB> f , v = res <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> f = f . encode ( "" utf-8 "" ) <TAB><TAB><TAB> if type ( v ) == unicode : <TAB><TAB><TAB><TAB> v = v . encode ( "" utf-8 "" ) <TAB><TAB><TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB><TAB> elif not args . content_only : <TAB><TAB><TAB> self . success ( res ) <TAB> else : <TAB><TAB> self . success ( res )",if type ( f ) == unicode :,if type ( f ) == unicode :,100.0,100.00,True
4772,"def _finalize_setup_keywords ( self ) : <TAB> for ep in pkg_resources . iter_entry_points ( "" distutils.setup_keywords "" ) : <TAB><TAB> value = getattr ( self , ep . name , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> ep . require ( installer = self . fetch_build_egg ) <TAB><TAB><TAB> ep . load ( ) ( self , ep . name , value )",if value is not None :,if value is not None :,100.0,100.00,True
4773,"def test_attributes_types ( self ) : <TAB> if not self . connection . strategy . pooled : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . connection . refresh_server_info ( ) <TAB><TAB> self . assertEqual ( <TAB><TAB><TAB> type ( self . connection . server . schema . attribute_types [ "" cn "" ] ) , AttributeTypeInfo <TAB><TAB> )",if not self . connection . server . info :,if self . connection . server . schema . attribute_types is None :,84.61799647791165,90.82,False
4774,"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB><TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB><TAB> k = literal_or_identifier [ "" value "" ] <TAB><TAB> if isinstance ( k , float ) : <TAB><TAB><TAB> return unicode ( float_repr ( k ) ) <TAB><TAB> elif "" regex "" in literal_or_identifier : <TAB><TAB><TAB> return compose_regex ( k ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" true "" if k else "" false "" <TAB><TAB> elif k is None : <TAB><TAB><TAB> return "" null "" <TAB><TAB> else : <TAB><TAB><TAB> return unicode ( k )","elif isinstance ( k , bool ) :","elif isinstance ( k , bool ) :",100.0,100.00,True
4775,"def list2rec ( x , test = False ) : <TAB> if test : <TAB><TAB> vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 0 ] , int ( x [ 1 ] ) , int ( x [ 2 ] ) ) <TAB><TAB> label = - 1 # label unknown <TAB><TAB> return vid , label <TAB> else : <TAB><TAB> vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 1 ] , int ( x [ 2 ] ) , int ( x [ 3 ] ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> vid = "" {} / {} "" . format ( convert_label ( x [ 0 ] ) , vid ) <TAB><TAB> else : <TAB><TAB><TAB> assert level == 1 <TAB><TAB> label = class_mapping [ convert_label ( x [ 0 ] ) ] <TAB><TAB> return vid , label",if level == 2 :,if level == 2 :,100.0,100.00,True
4776,"def _expand_env ( self , snapcraft_yaml ) : <TAB> environment_keys = [ "" name "" , "" version "" ] <TAB> for key in snapcraft_yaml : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> replacements = environment_to_replacements ( <TAB><TAB><TAB> get_snapcraft_global_environment ( self . project ) <TAB><TAB> ) <TAB><TAB> snapcraft_yaml [ key ] = replace_attr ( snapcraft_yaml [ key ] , replacements ) <TAB> return snapcraft_yaml",if any ( ( key == env_key for env_key in environment_keys ) ) :,if key not in environment_keys :,84.25328110582075,87.81,False
4777,"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self . storySettingsData : <TAB><TAB> name = data [ "" name "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> if "" requires "" in data : <TAB><TAB><TAB><TAB> set = self . getSetting ( data [ "" requires "" ] ) <TAB><TAB><TAB><TAB> for i in self . ctrls [ name ] : <TAB><TAB><TAB><TAB><TAB> i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] )",if name in self . ctrls :,if name in self . ctrls :,75.0,100.00,True
4778,"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ChallengePhaseCreateSerializer , self ) . __init__ ( * args , * * kwargs ) <TAB> context = kwargs . get ( "" context "" ) <TAB> if context : <TAB><TAB> challenge = context . get ( "" challenge "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> kwargs [ "" data "" ] [ "" challenge "" ] = challenge . pk <TAB><TAB> test_annotation = context . get ( "" test_annotation "" ) <TAB><TAB> if test_annotation : <TAB><TAB><TAB> kwargs [ "" data "" ] [ "" test_annotation "" ] = test_annotation",if challenge :,if challenge :,100.0,100.00,True
4779,def set_inactive ( self ) : <TAB> for title in self . gramplet_map : <TAB><TAB> if self . gramplet_map [ title ] . pui : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . gramplet_map [ title ] . pui . active = False,"if self . gramplet_map [ title ] . gstate != ""detached"" :",if self . gramplet_map [ title ] . pui . active :,91.95119053131339,91.50,False
4780,"def authenticate ( username , password ) : <TAB> try : <TAB><TAB> u = User . objects . get ( username = username ) <TAB><TAB> <MASK> <TAB><TAB><TAB> userLogger . info ( "" User logged in :  %s "" , username ) <TAB><TAB><TAB> return u <TAB><TAB> else : <TAB><TAB><TAB> userLogger . warn ( "" Attempt to log in to :  %s "" , username ) <TAB><TAB><TAB> return False <TAB> except DoesNotExist : <TAB><TAB> return False","if check_password_hash ( u . password , password ) :",if u . verify ( password ) :,66.50675863819671,92.61,False
4781,def _check_date ( self ) : <TAB> if not self . value : <TAB><TAB> return None <TAB> if not self . allow_date_in_past : <TAB><TAB> if self . value < self . date_or_datetime ( ) . today ( ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . value = self . date_or_datetime ( ) . today ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . value = self . date_or_datetime ( ) . today ( ) + datetime . timedelta ( 1 ),if self . allow_todays_date :,if self . value > self . date_or_datetime ( ) . today ( ) +,91.09653064314004,90.04,False
4782,"def update ( self , E = None , * * F ) : <TAB> if E : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Update with `E` dictionary <TAB><TAB><TAB> for k in E : <TAB><TAB><TAB><TAB> self [ k ] = E [ k ] <TAB><TAB> else : <TAB><TAB><TAB> # Update with `E` items <TAB><TAB><TAB> for ( k , v ) in E : <TAB><TAB><TAB><TAB> self [ k ] = v <TAB> # Update with `F` dictionary <TAB> for k in F : <TAB><TAB> self [ k ] = F [ k ]","if hasattr ( E , ""keys"" ) :","if isinstance ( E , dict ) :",91.14835572424931,96.07,False
4783,"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> quotas_ok [ quota ] = 0 <TAB><TAB><TAB> break <TAB><TAB> avail = qa . results [ quota ] <TAB><TAB> if avail [ 1 ] is not None and avail [ 1 ] < count : <TAB><TAB><TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB><TAB> else : <TAB><TAB><TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok",if count <= 0 :,if quota == self . _quota_size :,95.69450444412143,95.59,False
4784,"def gen_env_vars ( ) : <TAB> for fd_id , fd in zip ( STDIO_DESCRIPTORS , ( stdin , stdout , stderr ) ) : <TAB><TAB> is_atty = fd . isatty ( ) <TAB><TAB> yield ( cls . TTY_ENV_TMPL . format ( fd_id ) , cls . encode_env_var_value ( int ( is_atty ) ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield ( cls . TTY_PATH_ENV . format ( fd_id ) , os . ttyname ( fd . fileno ( ) ) or b "" "" )",if is_atty :,if fd . is_dir ( ) :,68.88943721531017,94.62,False
4785,"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB><TAB> if isinstance ( v , bytes ) : <TAB><TAB><TAB> v = str ( v , "" utf-8 "" ) <TAB><TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB><TAB><TAB> v = self . _convertList ( v ) <TAB><TAB> elif isinstance ( v , dict ) : <TAB><TAB><TAB> v = self . _convertDict ( v ) <TAB><TAB> <MASK> <TAB><TAB><TAB> k = str ( k , "" utf-8 "" ) <TAB><TAB> r [ k ] = v <TAB> return r","if isinstance ( k , bytes ) :","elif isinstance ( k , bytes ) :",85.18358842428782,98.62,False
4786,"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB><TAB> self . logger . debug ( "" get attr val:  %s   %s "" , nodeid , attr ) <TAB><TAB> if nodeid not in self . _nodes : <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB> return dv <TAB><TAB> node = self . _nodes [ nodeid ] <TAB><TAB> <MASK> <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB> return dv <TAB><TAB> attval = node . attributes [ attr ] <TAB><TAB> if attval . value_callback : <TAB><TAB><TAB> return attval . value_callback ( ) <TAB><TAB> return attval . value",if attr not in node . attributes :,if attr not in node . attributes :,100.0,100.00,True
4787,"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB><TAB> <MASK> <TAB><TAB><TAB> i + = 1 <TAB><TAB><TAB> continue <TAB><TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB><TAB> if not param_match : <TAB><TAB><TAB> return <TAB><TAB> param = param_match . group ( 1 ) <TAB><TAB> i + = param_match . end ( ) <TAB><TAB> if i > = length : <TAB><TAB><TAB> return <TAB><TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB><TAB> if value is None : <TAB><TAB><TAB> return <TAB><TAB> i + = end <TAB><TAB> ret [ param ] = value <TAB> return ret",if dsn [ i ] . isspace ( ) :,if not dsn [ i : ] :,69.29020215282918,96.81,False
4788,"def connect ( self , buttons ) : <TAB> for button in buttons : <TAB><TAB> assert button is not None <TAB><TAB> handled = False <TAB><TAB> for handler_idx in range ( 0 , len ( self . __signal_handlers ) ) : <TAB><TAB><TAB> ( obj_class , signal , handler , handler_id ) = self . __signal_handlers [ <TAB><TAB><TAB><TAB> handler_idx <TAB><TAB><TAB> ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> handler_id = button . connect ( signal , handler ) <TAB><TAB><TAB><TAB> handled = True <TAB><TAB><TAB> self . __signal_handlers [ handler_idx ] = ( <TAB><TAB><TAB><TAB> obj_class , <TAB><TAB><TAB><TAB> signal , <TAB><TAB><TAB><TAB> handler , <TAB><TAB><TAB><TAB> handler_id , <TAB><TAB><TAB> ) <TAB><TAB> assert handled","if isinstance ( button , obj_class ) :",if handler_id is None :,88.26464878858825,96.65,False
4789,"def _parse_display ( display ) : <TAB> """"""Parse an X11 display value"""""" <TAB> try : <TAB><TAB> host , dpynum = display . rsplit ( "" : "" , 1 ) <TAB><TAB> if host . startswith ( "" [ "" ) and host . endswith ( "" ] "" ) : <TAB><TAB><TAB> host = host [ 1 : - 1 ] <TAB><TAB> idx = dpynum . find ( "" . "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> screen = int ( dpynum [ idx + 1 : ] ) <TAB><TAB><TAB> dpynum = dpynum [ : idx ] <TAB><TAB> else : <TAB><TAB><TAB> screen = 0 <TAB> except ( ValueError , UnicodeEncodeError ) : <TAB><TAB> raise ValueError ( "" Invalid X11 display "" ) from None <TAB> return host , dpynum , screen",if idx >= 0 :,if idx >= 0 :,100.0,100.00,True
4790,"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB><TAB> fn_full = os . path . join ( path , fn ) <TAB><TAB> if os . path . isdir ( fn ) : <TAB><TAB><TAB> delete_all ( fn_full ) <TAB><TAB> <MASK> <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> elif fn . endswith ( "" .md "" ) : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB><TAB> elif DELETE_ALL_OLD : <TAB><TAB><TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )","elif fn . endswith ( "".png"" ) :","elif fn . endswith ( "".md"" ) :",98.96540516768711,98.80,False
4791,"def _sync_get ( self , identifier , * args , * * kw ) : <TAB> self . _mutex . acquire ( ) <TAB> try : <TAB><TAB> try : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . _values [ identifier ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB><TAB><TAB><TAB> return value <TAB><TAB> except KeyError : <TAB><TAB><TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB><TAB><TAB> return value <TAB> finally : <TAB><TAB> self . _mutex . release ( )",if identifier in self . _values :,if identifier in self . _values :,100.0,100.00,True
4792,"def _query_fd ( self ) : <TAB> if self . stream is None : <TAB><TAB> self . _last_stat = None , None <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> st = os . stat ( self . _filename ) <TAB><TAB> except OSError : <TAB><TAB><TAB> e = sys . exc_info ( ) [ 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise <TAB><TAB><TAB> self . _last_stat = None , None <TAB><TAB> else : <TAB><TAB><TAB> self . _last_stat = st [ stat . ST_DEV ] , st [ stat . ST_INO ]",if e . errno != errno . ENOENT :,if e . errno != errno . ENOENT :,100.0,100.00,True
4793,"def get_place_name ( self , place_handle ) : <TAB> """"""Obtain a place name"""""" <TAB> text = "" "" <TAB> if place_handle : <TAB><TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB><TAB> <MASK> <TAB><TAB><TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB><TAB><TAB> if place_title != "" "" : <TAB><TAB><TAB><TAB> if len ( place_title ) > 25 : <TAB><TAB><TAB><TAB><TAB> text = place_title [ : 24 ] + "" ... "" <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> text = place_title <TAB> return text",if place :,if place :,100.0,100.00,True
4794,"def test_decoder_state ( self ) : <TAB> # Check that getstate() and setstate() handle the state properly <TAB> u = "" abc123 "" <TAB> for encoding in all_unicode_encodings : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . check_state_handling_decode ( encoding , u , u . encode ( encoding ) ) <TAB><TAB><TAB> self . check_state_handling_encode ( encoding , u , u . encode ( encoding ) )",if encoding not in broken_unicode_with_stateful :,"if encoding in ( ""utf-8"" , ""utf-8"" ) :",70.55934502386188,90.94,False
4795,"def cleanup ( self ) : <TAB> if os . path . exists ( self . meta_gui_dir ) : <TAB><TAB> for f in os . listdir ( self . meta_gui_dir ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> os . remove ( os . path . join ( self . meta_gui_dir , f ) )","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :","if f . endswith ( "".py"" ) :",60.76925966457982,84.23,False
4796,"def _have_applied_incense ( self ) : <TAB> for applied_item in inventory . applied_items ( ) . all ( ) : <TAB><TAB> self . logger . info ( applied_item ) <TAB><TAB> <MASK> <TAB><TAB><TAB> mins = format_time ( applied_item . expire_ms * 1000 ) <TAB><TAB><TAB> self . logger . info ( <TAB><TAB><TAB><TAB> "" Not applying incense, currently active:  %s ,  %s  minutes remaining "" , <TAB><TAB><TAB><TAB> applied_item . item . name , <TAB><TAB><TAB><TAB> mins , <TAB><TAB><TAB> ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> self . logger . info ( "" "" ) <TAB><TAB><TAB> return False <TAB> return False",if applied_item . expire_ms > 0 :,if applied_item . active :,87.9137094090217,97.15,False
4797,"def get_closest_point ( self , point ) : <TAB> point = to_point ( point ) <TAB> cp , cd = None , None <TAB> for p0 , p1 in iter_pairs ( self . pts , self . connected ) : <TAB><TAB> diff = p1 - p0 <TAB><TAB> l = diff . length <TAB><TAB> d = diff / l <TAB><TAB> pp = p0 + d * max ( 0 , min ( l , ( point - p0 ) . dot ( d ) ) ) <TAB><TAB> dist = ( point - pp ) . length <TAB><TAB> <MASK> <TAB><TAB><TAB> cp , cd = pp , dist <TAB> return cp",if not cp or dist < cd :,if cd is None or dist < cp :,72.95634311617275,96.11,False
4798,"def process_return ( lines ) : <TAB> for line in lines : <TAB><TAB> m = re . fullmatch ( r "" (?P<param> \ w+) \ s+: \ s+(?P<type>[ \ w.]+) "" , line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Once this is in scanpydoc, we can use the fancy hover stuff <TAB><TAB><TAB> yield f ' ** { m [ "" param "" ] } ** : :class:`~ { m [ "" type "" ] } ` ' <TAB><TAB> else : <TAB><TAB><TAB> yield line",if m :,if m :,100.0,100.00,True
4799,"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB><TAB> for node in level : <TAB><TAB><TAB> if node . binary == BINARY_MISSING : <TAB><TAB><TAB><TAB> missing . append ( node ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> invalid . append ( node ) <TAB><TAB><TAB> elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) : <TAB><TAB><TAB><TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads",elif node . binary == BINARY_INVALID :,"elif node . binary in ( BINARY_INVALID , BINARY_INVALID ) :",96.73617660684403,94.41,False
4800,"def safe_parse_date ( date_hdr ) : <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB><TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB><TAB> if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) : <TAB><TAB><TAB> return None <TAB><TAB> else : <TAB><TAB><TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB><TAB> return None","if "";"" in date_hdr :","if "";"" in date_hdr :",100.0,100.00,True
4801,"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB><TAB> if isinstance ( value , bool ) : <TAB><TAB><TAB> if value : <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> if isinstance ( value , int ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> changed = True <TAB><TAB><TAB><TAB> break <TAB><TAB> elif value is None : <TAB><TAB><TAB> continue <TAB><TAB> elif len ( value ) != 0 : <TAB><TAB><TAB> changed = True <TAB><TAB><TAB> break <TAB> self . _reset_button . disabled = not changed",if value != 1 :,if value != 0 :,97.38412669368901,98.86,False
4802,"def _rewrite_prepend_append ( self , string , prepend , append = None ) : <TAB> if append is None : <TAB><TAB> append = prepend <TAB> if not isinstance ( string , StringElem ) : <TAB><TAB> string = StringElem ( string ) <TAB> string . sub . insert ( 0 , prepend ) <TAB> if unicode ( string ) . endswith ( u "" \n "" ) : <TAB><TAB> # Try and remove the last character from the tree <TAB><TAB> try : <TAB><TAB><TAB> lastnode = string . flatten ( ) [ - 1 ] <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> lastnode . sub [ - 1 ] = lastnode . sub [ - 1 ] . rstrip ( u "" \n "" ) <TAB><TAB> except IndexError : <TAB><TAB><TAB> pass <TAB><TAB> string . sub . append ( append + u "" \n "" ) <TAB> else : <TAB><TAB> string . sub . append ( append ) <TAB> return string","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :","if lastnode . sub [ - 1 ] . startswith ( u""\n"" ) :",97.97914345103624,95.85,False
4803,"def parse_indentless_sequence_entry ( self ) : <TAB> if self . check_token ( BlockEntryToken ) : <TAB><TAB> token = self . get_token ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . states . append ( self . parse_indentless_sequence_entry ) <TAB><TAB><TAB> return self . parse_block_node ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . state = self . parse_indentless_sequence_entry <TAB><TAB><TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> token = self . peek_token ( ) <TAB> event = SequenceEndEvent ( token . start_mark , token . start_mark ) <TAB> self . state = self . states . pop ( ) <TAB> return event","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",if token . end_mark == self . token_end_mark :,67.20677987055565,92.71,False
4804,"def walk_directory ( directory , verbose = False ) : <TAB> """"""Iterates a directory's text files and their contents."""""" <TAB> for dir_path , _ , filenames in os . walk ( directory ) : <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> file_path = os . path . join ( dir_path , filename ) <TAB><TAB><TAB> if os . path . isfile ( file_path ) and not filename . startswith ( "" . "" ) : <TAB><TAB><TAB><TAB> with io . open ( file_path , "" r "" , encoding = "" utf-8 "" ) as file : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> print ( "" Reading  {} "" . format ( filename ) ) <TAB><TAB><TAB><TAB><TAB> doc_text = file . read ( ) <TAB><TAB><TAB><TAB><TAB> yield filename , doc_text",if verbose :,if verbose :,100.0,100.00,True
4805,"def set_bounds ( self , x , y , width , height ) : <TAB> if self . native : <TAB><TAB> # Root level widgets may require vertical adjustment to <TAB><TAB> # account for toolbars, etc. <TAB><TAB> <MASK> <TAB><TAB><TAB> vertical_shift = self . frame . vertical_shift <TAB><TAB> else : <TAB><TAB><TAB> vertical_shift = 0 <TAB><TAB> self . native . Size = Size ( width , height ) <TAB><TAB> self . native . Location = Point ( x , y + vertical_shift )",if self . interface . parent is None :,if self . frame :,95.92162335849625,95.58,False
4806,"def _check_x11 ( self , command = None , * , exc = None , exit_status = None , * * kwargs ) : <TAB> """"""Check requesting X11 forwarding"""""" <TAB> with ( yield from self . connect ( ) ) as conn : <TAB><TAB> <MASK> <TAB><TAB><TAB> with self . assertRaises ( exc ) : <TAB><TAB><TAB><TAB> yield from _create_x11_process ( conn , command , * * kwargs ) <TAB><TAB> else : <TAB><TAB><TAB> proc = yield from _create_x11_process ( conn , command , * * kwargs ) <TAB><TAB><TAB> yield from proc . wait ( ) <TAB><TAB><TAB> self . assertEqual ( proc . exit_status , exit_status ) <TAB> yield from conn . wait_closed ( )",if exc :,if exc is not None :,97.40305062086045,97.76,False
4807,"def repr ( self ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> from infogami . infobase . utils import prepr <TAB><TAB><TAB> return prepr ( self . obj ) <TAB><TAB> else : <TAB><TAB><TAB> return repr ( self . obj ) <TAB> except : <TAB><TAB> return "" failed "" <TAB> return render_template ( "" admin/memory/object "" , self . obj )","if isinstance ( self . obj , ( dict , web . threadeddict ) ) :","if hasattr ( self . obj , ""prepr"" ) :",89.53506562004074,91.04,False
4808,"def add ( self , tag , values ) : <TAB> if tag not in self . different : <TAB><TAB> if tag not in self : <TAB><TAB><TAB> self [ tag ] = values <TAB><TAB> <MASK> <TAB><TAB><TAB> self . different . add ( tag ) <TAB><TAB><TAB> self [ tag ] = [ "" "" ] <TAB> self . counts [ tag ] + = 1",elif self [ tag ] != values :,elif self . counts [ tag ] == 0 :,76.5119798891242,92.93,False
4809,"def _on_geturl ( self , event ) : <TAB> selected = self . _status_list . get_selected ( ) <TAB> if selected != - 1 : <TAB><TAB> object_id = self . _status_list . GetItemData ( selected ) <TAB><TAB> download_item = self . _download_list . get_item ( object_id ) <TAB><TAB> url = download_item . url <TAB><TAB> <MASK> <TAB><TAB><TAB> clipdata = wx . TextDataObject ( ) <TAB><TAB><TAB> clipdata . SetText ( url ) <TAB><TAB><TAB> wx . TheClipboard . Open ( ) <TAB><TAB><TAB> wx . TheClipboard . SetData ( clipdata ) <TAB><TAB><TAB> wx . TheClipboard . Close ( )",if not wx . TheClipboard . IsOpened ( ) :,if url :,75.40032497686356,95.00,False
4810,"def escape2null ( text ) : <TAB> """"""Return a string with escape-backslashes converted to nulls."""""" <TAB> parts = [ ] <TAB> start = 0 <TAB> while True : <TAB><TAB> found = text . find ( "" \\ "" , start ) <TAB><TAB> <MASK> <TAB><TAB><TAB> parts . append ( text [ start : ] ) <TAB><TAB><TAB> return "" "" . join ( parts ) <TAB><TAB> parts . append ( text [ start : found ] ) <TAB><TAB> parts . append ( "" \x00 "" + text [ found + 1 : found + 2 ] ) <TAB><TAB> start = found + 2 # skip character after escape",if found == - 1 :,if found == - 1 :,100.0,100.00,True
4811,def _process_inner_views ( self ) : <TAB> for view in self . baseviews : <TAB><TAB> for inner_class in view . get_uninit_inner_views ( ) : <TAB><TAB><TAB> for v in self . baseviews : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> view . get_init_inner_views ( ) . append ( v ),"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",if v . get_class ( ) == inner_class :,58.682196279656864,83.43,False
4812,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 26 : <TAB><TAB><TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 34 : <TAB><TAB><TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 18 :,if tt == 18 :,100.0,100.00,True
4813,"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB><TAB> if _file . suffix == "" .py "" and _file . name not in skip_files : <TAB><TAB><TAB> with _file . open ( ) as f : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB><TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB><TAB> for error in errors : <TAB><TAB><TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB><TAB> print ( line [ : - 1 ] ) <TAB><TAB> assert False",if comment not in f . read ( ) :,if comment not in f . read ( ) :,100.0,100.00,True
4814,"def _get_planner ( name , path , source ) : <TAB> for klass in _planners : <TAB><TAB> <MASK> <TAB><TAB><TAB> LOG . debug ( "" %r  accepted  %r  (filename  %r ) "" , klass , name , path ) <TAB><TAB><TAB> return klass <TAB><TAB> LOG . debug ( "" %r  rejected  %r "" , klass , name ) <TAB> raise ansible . errors . AnsibleError ( NO_METHOD_MSG + repr ( invocation ) )","if klass . detect ( path , source ) :","if klass . accept ( name , path , source ) :",68.91978362443074,95.76,False
4815,"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB><TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB><TAB> hasConst = not ( <TAB><TAB><TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> idx - = 1 <TAB><TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB><TAB> _lt = _l . __class__ <TAB><TAB> if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) : <TAB><TAB><TAB> ostream . write ( ""  -  "" ) <TAB><TAB> else : <TAB><TAB><TAB> ostream . write ( ""  +  "" )",if hasConst :,if hasConst :,100.0,100.00,True
4816,"def cluster_info_query ( self ) : <TAB> if self . _major_version > = 90600 : <TAB><TAB> extra = ( <TAB><TAB><TAB> "" , CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END, "" <TAB><TAB><TAB> ""  slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver() "" <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> extra = "" timeline_id "" + extra + "" , pg_catalog.pg_control_checkpoint() "" <TAB><TAB> else : <TAB><TAB><TAB> extra = "" 0 "" + extra <TAB> else : <TAB><TAB> extra = "" 0, NULL, NULL, NULL "" <TAB> return ( "" SELECT  "" + self . TL_LSN + "" ,  {2} "" ) . format ( <TAB><TAB> self . wal_name , self . lsn_name , extra <TAB> )","if self . role == ""standby_leader"" :",if self . _major_version >= 90600 :,94.13967840839494,96.31,False
4817,"def __init__ ( self , * args , * * kwargs ) : <TAB> self . country = kwargs . pop ( "" country "" ) <TAB> self . fields_needed = kwargs . pop ( "" fields_needed "" , [ ] ) <TAB> super ( DynamicManagedAccountForm , self ) . __init__ ( * args , * * kwargs ) <TAB> # build our form using the country specific fields and falling <TAB> # back to our default set <TAB> for f in self . fields_needed : <TAB><TAB> <MASK> # pragma: no branch <TAB><TAB><TAB> field_name , field = FIELDS_BY_COUNTRY [ self . country ] [ f ] <TAB><TAB><TAB> self . fields [ field_name ] = field","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",if f not in FIELDS_BY_COUNTRY [ self . country ] :,95.60937304372527,93.83,False
4818,"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB><TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB><TAB><TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB><TAB><TAB> if not query_map [ alias ] [ driver ] : <TAB><TAB><TAB><TAB> query_map [ alias ] . pop ( driver ) <TAB><TAB> if not query_map [ alias ] : <TAB><TAB><TAB> query_map . pop ( alias ) <TAB> return query_map","if vm_details == ""Absent"" :",if vm_name in query_map [ alias ] [ driver ] :,95.52425968316152,94.80,False
4819,"def on_strokes_edited ( self ) : <TAB> strokes = self . _strokes ( ) <TAB> if strokes : <TAB><TAB> translation = self . _engine . raw_lookup ( strokes ) <TAB><TAB> <MASK> <TAB><TAB><TAB> fmt = _ ( "" {strokes}  maps to  {translation} "" ) <TAB><TAB> else : <TAB><TAB><TAB> fmt = _ ( "" {strokes}  is not in the dictionary "" ) <TAB><TAB> info = self . _format_label ( fmt , ( strokes , ) , translation ) <TAB> else : <TAB><TAB> info = "" "" <TAB> self . strokes_info . setText ( info )",if translation is not None :,if translation :,72.04675668594925,97.26,False
4820,"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB><TAB> if self . owner != tid : <TAB><TAB><TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB><TAB> assert self . count > 0 <TAB><TAB> self . count - = 1 <TAB><TAB> <MASK> <TAB><TAB><TAB> self . owner = None <TAB><TAB><TAB> if self . waiters : <TAB><TAB><TAB><TAB> self . waiters - = 1 <TAB><TAB><TAB><TAB> self . wakeup . release ( )",if self . count == 0 :,if self . count == 0 :,100.0,100.00,True
4821,"def _cat_blob ( self , gcs_uri ) : <TAB> """""":py:meth:`cat_file`, minus decompression."""""" <TAB> blob = self . _get_blob ( gcs_uri ) <TAB> if not blob : <TAB><TAB> return # don't cat nonexistent files <TAB> start = 0 <TAB> while True : <TAB><TAB> end = start + _CAT_CHUNK_SIZE <TAB><TAB> try : <TAB><TAB><TAB> chunk = blob . download_as_string ( start = start , end = end ) <TAB><TAB> except google . api_core . exceptions . RequestRangeNotSatisfiable : <TAB><TAB><TAB> return <TAB><TAB> yield chunk <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> start = end",if len ( chunk ) < _CAT_CHUNK_SIZE :,if not chunk :,96.20715255568555,93.97,False
4822,"def device_iter ( * * kwargs ) : <TAB> for dev in backend . enumerate_devices ( ) : <TAB><TAB> d = Device ( dev , backend ) <TAB><TAB> tests = ( val == _try_getattr ( d , key ) for key , val in kwargs . items ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> yield d",if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,if tests :,53.346484910031975,76.29,False
4823,"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB><TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB><TAB><TAB> if isfile ( self . object ) : <TAB><TAB><TAB><TAB> with open ( self . object , "" rb "" ) as f : <TAB><TAB><TAB><TAB><TAB> vtkjs = f . read ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> data_url = urlopen ( self . object ) <TAB><TAB><TAB><TAB> vtkjs = data_url . read ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> vtkjs = self . object . read ( ) <TAB><TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs","elif hasattr ( self . object , ""read"" ) :","elif isinstance ( self . object , binary_type ) :",96.04316577883625,96.95,False
4824,"def _execute_with_error ( command , error , message ) : <TAB> try : <TAB><TAB> cli . invocation = cli . invocation_cls ( <TAB><TAB><TAB> cli_ctx = cli , <TAB><TAB><TAB> parser_cls = cli . parser_cls , <TAB><TAB><TAB> commands_loader_cls = cli . commands_loader_cls , <TAB><TAB><TAB> help_cls = cli . help_cls , <TAB><TAB> ) <TAB><TAB> cli . invocation . execute ( command . split ( ) ) <TAB> except CLIError as ex : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise AssertionError ( <TAB><TAB><TAB><TAB> "" {} \n Expected:  {} \n Actual:  {} "" . format ( message , error , ex ) <TAB><TAB><TAB> ) <TAB><TAB> return <TAB> except Exception as ex : <TAB><TAB> raise ex <TAB> raise AssertionError ( "" exception not raised for  ' {0} ' "" . format ( message ) )",if error not in str ( ex ) :,if error != ex . args [ 0 ] :,75.07089595399282,96.51,False
4825,"def ray_intersection ( self , p , line ) : <TAB> p = Vector ( center ( line . sites ) ) <TAB> min_r = BIG_FLOAT <TAB> nearest = None <TAB> for v_i , v_j in self . edges : <TAB><TAB> bound = LineEquation2D . from_two_points ( v_i , v_j ) <TAB><TAB> intersection = bound . intersect_with_line ( line ) <TAB><TAB> if intersection is not None : <TAB><TAB><TAB> r = ( p - intersection ) . length <TAB><TAB><TAB> # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> nearest = intersection <TAB><TAB><TAB><TAB> min_r = r <TAB> return nearest",if r < min_r :,if r < min_r :,100.0,100.00,True
4826,"def CalculateChecksum ( data ) : <TAB> # The checksum is just a sum of all the bytes. I swear. <TAB> if isinstance ( data , bytearray ) : <TAB><TAB> total = sum ( data ) <TAB> elif isinstance ( data , bytes ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Python 2 bytes (str) index as single-character strings. <TAB><TAB><TAB> total = sum ( map ( ord , data ) ) <TAB><TAB> else : <TAB><TAB><TAB> # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB><TAB><TAB> total = sum ( data ) <TAB> else : <TAB><TAB> # Unicode strings (should never see?) <TAB><TAB> total = sum ( map ( ord , data ) ) <TAB> return total & 0xFFFFFFFF","if data and isinstance ( data [ 0 ] , bytes ) :",if PY2 :,70.17845707725492,93.98,False
4827,"def __mul__ ( self , other : Union [ "" Tensor "" , float ] ) - > "" Tensor "" : <TAB> if isinstance ( other , Tensor ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> errstr = ( <TAB><TAB><TAB><TAB> f "" Given backens are inconsistent. Found  ' { self . backend . name } ' "" <TAB><TAB><TAB><TAB> f "" and  ' { other . backend . name } ' "" <TAB><TAB><TAB> ) <TAB><TAB><TAB> raise ValueError ( errstr ) <TAB><TAB> other = other . array <TAB> array = self . backend . multiply ( self . array , other ) <TAB> return Tensor ( array , backend = self . backend )",if self . backend . name != other . backend . name :,if self . backend . name != other . backend . name :,100.0,100.00,True
4828,"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB><TAB> start = self . items . index ( self . _selected ) <TAB><TAB> i = start + direction <TAB> except : <TAB><TAB> pass <TAB> while True : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Cannot find valid menu item <TAB><TAB><TAB> self . select ( start ) <TAB><TAB><TAB> break <TAB><TAB> if i > = len ( self . items ) : <TAB><TAB><TAB> i = 0 <TAB><TAB><TAB> continue <TAB><TAB> if i < 0 : <TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> continue <TAB><TAB> if self . select ( i ) : <TAB><TAB><TAB> break <TAB><TAB> i + = direction <TAB><TAB> if start < 0 : <TAB><TAB><TAB> start = 0",if i == start :,if self . _selected == i :,94.96209643939419,97.35,False
4829,"def resolve_none ( self , data ) : <TAB> # replace None to '_' <TAB> for tok_idx in range ( len ( data ) ) : <TAB><TAB> for feat_idx in range ( len ( data [ tok_idx ] ) ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data [ tok_idx ] [ feat_idx ] = "" _ "" <TAB> return data",if data [ tok_idx ] [ feat_idx ] is None :,if data [ tok_idx ] [ feat_idx ] is None :,75.0,100.00,True
4830,"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB><TAB> if isinstance ( n , Field ) : <TAB><TAB><TAB> if n . _child . isidentical ( expr ) : <TAB><TAB><TAB><TAB> n = n . _name <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> if not isinstance ( n , _strtypes ) : <TAB><TAB><TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB><TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )",elif n not in fields :,if not fields . issubset ( n ) :,68.85533360013518,96.67,False
4831,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 24 : <TAB><TAB><TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 0 : <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,100.0,100.00,True
4832,"def func_std_string ( func_name ) : # match what old profile produced <TAB> if func_name [ : 2 ] == ( "" ~ "" , 0 ) : <TAB><TAB> # special case for built-in functions <TAB><TAB> name = func_name [ 2 ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" { %s } "" % name [ 1 : - 1 ] <TAB><TAB> else : <TAB><TAB><TAB> return name <TAB> else : <TAB><TAB> return "" %s : %d ( %s ) "" % func_name","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :","if name [ : 1 ] == ( ""~"" , 0 ) :",68.37333921712589,90.20,False
4833,"def f ( ) : <TAB> try : <TAB><TAB> # Intra-buffer read then buffer-flushing read <TAB><TAB> for n in cycle ( [ 1 , 19 ] ) : <TAB><TAB><TAB> s = bufio . read ( n ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> # list.append() is atomic <TAB><TAB><TAB> results . append ( s ) <TAB> except Exception as e : <TAB><TAB> errors . append ( e ) <TAB><TAB> raise",if not s :,if s is None :,97.11448988104856,96.98,False
4834,"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try : <TAB><TAB> self . rpcserver . stop ( ) <TAB><TAB> if self . backend_rpcserver : <TAB><TAB><TAB> self . backend_rpcserver . stop ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . cluster_rpcserver . stop ( ) <TAB> except Exception : <TAB><TAB> pass <TAB> if self . coordination : <TAB><TAB> try : <TAB><TAB><TAB> coordination . COORDINATOR . stop ( ) <TAB><TAB> except Exception : <TAB><TAB><TAB> pass <TAB> super ( Service , self ) . stop ( graceful = True )",if self . cluster_rpcserver :,if self . cluster_rpcserver :,75.0,100.00,True
4835,"def download ( cls , architecture , path = "" ./ "" ) : <TAB> if cls . sanity_check ( architecture ) : <TAB><TAB> architecture_file = download_file ( <TAB><TAB><TAB> cls . architecture_map [ architecture ] , directory = path <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return None <TAB><TAB> print ( "" Coreml model  {}  is saved in [ {} ] "" . format ( architecture , path ) ) <TAB><TAB> return architecture_file <TAB> else : <TAB><TAB> return None",if not architecture_file :,if not architecture_file :,100.0,100.00,True
4836,"def opps_output_converter ( kpt_list ) : <TAB> kpts = [ ] <TAB> mpii_keys = to_opps_converter . keys ( ) <TAB> for mpii_idx in range ( 0 , 16 ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> model_idx = to_opps_converter [ mpii_idx ] <TAB><TAB><TAB> x , y = kpt_list [ model_idx ] <TAB><TAB><TAB> if x < 0 or y < 0 : <TAB><TAB><TAB><TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> kpts + = [ x , y , 1.0 ] <TAB><TAB> else : <TAB><TAB><TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB> return kpts",if mpii_idx in mpii_keys :,if mpii_idx in mpii_keys :,100.0,100.00,True
4837,"def _get_headers ( self , headers = None ) : <TAB> request_headers = headers or { } <TAB> # Auth headers if access_token is present <TAB> if self . _client . client . config : <TAB><TAB> config = self . _client . client . config <TAB><TAB> if "" Authorization "" not in request_headers and config . token : <TAB><TAB><TAB> request_headers . update ( <TAB><TAB><TAB><TAB> { <TAB><TAB><TAB><TAB><TAB> "" Authorization "" : "" {}   {} "" . format ( <TAB><TAB><TAB><TAB><TAB><TAB> config . authentication_type , config . token <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> } <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> request_headers . update ( { config . header : config . header_service } ) <TAB> return request_headers",if config . header and config . header_service :,if config . header_service :,98.10356365701814,98.44,False
4838,"def get_last_traded_prices ( cls , trading_pairs : List [ str ] ) - > Dict [ str , float ] : <TAB> results = dict ( ) <TAB> async with aiohttp . ClientSession ( ) as client : <TAB><TAB> resp = await client . get ( f "" { constants . REST_URL } /tickers "" ) <TAB><TAB> resp_json = await resp . json ( ) <TAB><TAB> for trading_pair in trading_pairs : <TAB><TAB><TAB> resp_record = [ <TAB><TAB><TAB><TAB> o <TAB><TAB><TAB><TAB> for o in resp_json <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> ] [ 0 ] <TAB><TAB><TAB> results [ trading_pair ] = float ( resp_record [ "" price "" ] ) <TAB> return results","if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )","if o [ ""type"" ] == ""last_traded_prices""",84.4528169861062,92.37,False
4839,"def reset_two_factor_hotp ( ) : <TAB> uid = request . form [ "" uid "" ] <TAB> otp_secret = request . form . get ( "" otp_secret "" , None ) <TAB> if otp_secret : <TAB><TAB> user = Journalist . query . get ( uid ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) <TAB><TAB> db . session . commit ( ) <TAB><TAB> return redirect ( url_for ( "" admin.new_user_two_factor "" , uid = uid ) ) <TAB> else : <TAB><TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid )","if not validate_hotp_secret ( user , otp_secret ) :",if user . secret == otp_secret :,66.64503943840047,93.51,False
4840,"def ctx_for_video ( self , vurl ) : <TAB> "" Get a context dict for a given video URL "" <TAB> ctx = self . get_context_dict ( ) <TAB> for portal , match , context_fn in self . PORTALS : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> ctx . update ( context_fn ( vurl ) ) <TAB><TAB><TAB><TAB> ctx [ "" portal "" ] = portal <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> continue <TAB> return ctx",if match . search ( vurl ) :,if match and match . group ( 1 ) == vurl . group ( 1 ) :,92.69642515116804,91.72,False
4841,"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB><TAB> opts = dict ( ) <TAB><TAB> opts [ "" type "" ] = "" episode "" <TAB><TAB> result = guessit ( name , options = opts ) <TAB><TAB> res = dict ( ) <TAB><TAB> if "" episode "" in result : <TAB><TAB><TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB><TAB> else : <TAB><TAB><TAB> res [ "" episode "" ] = 0 <TAB><TAB> if "" season "" in result : <TAB><TAB><TAB> res [ "" season "" ] = result [ "" season "" ] <TAB><TAB> else : <TAB><TAB><TAB> res [ "" season "" ] = 0 <TAB><TAB> <MASK> <TAB><TAB><TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB><TAB> return jsonify ( data = res ) <TAB> else : <TAB><TAB> return "" "" , 400","if ""subtitle_language"" in result :","if ""subtitle_language"" in result :",100.0,100.00,True
4842,"def package_files ( package_path , directory_name ) : <TAB> paths = [ ] <TAB> directory_path = os . path . join ( package_path , directory_name ) <TAB> for ( path , directories , filenames ) in os . walk ( directory_path ) : <TAB><TAB> relative_path = os . path . relpath ( path , package_path ) <TAB><TAB> for filename in filenames : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> paths . append ( os . path . join ( relative_path , filename ) ) <TAB> return paths","if filename [ 0 ] == ""."" :","if filename . endswith ( "".py"" ) :",91.65690915243046,94.62,False
4843,"def parse_simple ( d , data ) : <TAB> units = { } <TAB> for v in data [ d ] : <TAB><TAB> key = v [ "" name "" ] <TAB><TAB> if not key : <TAB><TAB><TAB> continue <TAB><TAB> key_to_insert = make_key ( key ) <TAB><TAB> <MASK> <TAB><TAB><TAB> index = 2 <TAB><TAB><TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB><TAB><TAB> while tmp in units : <TAB><TAB><TAB><TAB> index + = 1 <TAB><TAB><TAB><TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB><TAB><TAB> key_to_insert = tmp <TAB><TAB> units [ key_to_insert ] = v [ "" id "" ] <TAB> return units",if key_to_insert in units :,if key_to_insert not in units :,99.08393445024639,98.92,False
4844,"def parse_clademodelc ( branch_type_no , line_floats , site_classes ) : <TAB> """"""Parse results specific to the clade model C."""""" <TAB> if not site_classes or len ( line_floats ) == 0 : <TAB><TAB> return <TAB> for n in range ( len ( line_floats ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> site_classes [ n ] [ "" branch types "" ] = { } <TAB><TAB> site_classes [ n ] [ "" branch types "" ] [ branch_type_no ] = line_floats [ n ] <TAB> return site_classes","if site_classes [ n ] . get ( ""branch types"" ) is None :","if not site_classes [ n ] [ ""branch types"" ] :",86.5223784113382,93.62,False
4845,"def track_modules ( self , * modules ) : <TAB> """"""Add module names to the tracked list."""""" <TAB> already_tracked = self . session . GetParameter ( "" autodetect_build_local_tracked "" ) or [ ] <TAB> needed = set ( modules ) <TAB> if not needed . issubset ( already_tracked ) : <TAB><TAB> needed . update ( already_tracked ) <TAB><TAB> with self . session as session : <TAB><TAB><TAB> session . SetParameter ( "" autodetect_build_local_tracked "" , needed ) <TAB><TAB><TAB> for module_name in modules : <TAB><TAB><TAB><TAB> module_obj = self . GetModuleByName ( module_name ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> # Clear the module's profile. This will force it to <TAB><TAB><TAB><TAB><TAB> # reload a new profile. <TAB><TAB><TAB><TAB><TAB> module_obj . profile = None",if module_obj :,if module_obj :,100.0,100.00,True
4846,"def set_job_on_hold ( self , value , blocking = True ) : <TAB> trigger = False <TAB> # don't run any locking code beyond this... <TAB> if not self . _job_on_hold . acquire ( blocking = blocking ) : <TAB><TAB> return False <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _job_on_hold . set ( ) <TAB><TAB> else : <TAB><TAB><TAB> self . _job_on_hold . clear ( ) <TAB><TAB><TAB> if self . _job_on_hold . counter == 0 : <TAB><TAB><TAB><TAB> trigger = True <TAB> finally : <TAB><TAB> self . _job_on_hold . release ( ) <TAB> # locking code is now safe to run again <TAB> if trigger : <TAB><TAB> self . _continue_sending ( ) <TAB> return True",if value :,if value :,100.0,100.00,True
4847,"def moveToThreadNext ( self ) : <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p . v : <TAB><TAB> <MASK> <TAB><TAB><TAB> p . moveToFirstChild ( ) <TAB><TAB> elif p . hasNext ( ) : <TAB><TAB><TAB> p . moveToNext ( ) <TAB><TAB> else : <TAB><TAB><TAB> p . moveToParent ( ) <TAB><TAB><TAB> while p : <TAB><TAB><TAB><TAB> if p . hasNext ( ) : <TAB><TAB><TAB><TAB><TAB> p . moveToNext ( ) <TAB><TAB><TAB><TAB><TAB> break # found <TAB><TAB><TAB><TAB> p . moveToParent ( ) <TAB><TAB><TAB> # not found. <TAB> return p",if p . v . children :,if p . isChild ( ) :,96.015840615384,97.90,False
4848,"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images [ 0 ] <TAB> for img in images : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Exact match always used <TAB><TAB><TAB> return img <TAB><TAB> elif img . width > = width and img . width * img . height > image . width * image . height : <TAB><TAB><TAB> # At least wide enough, and largest area <TAB><TAB><TAB> image = img <TAB> return image",if img . width == width and img . height == height :,if img . width == width and img . height == height :,75.0,100.00,True
4849,"def _check_input_types ( self ) : <TAB> if len ( self . base_features ) == 0 : <TAB><TAB> return True <TAB> input_types = self . primitive . input_types <TAB> if input_types is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> input_types = [ input_types ] <TAB><TAB> for t in input_types : <TAB><TAB><TAB> zipped = list ( zip ( t , self . base_features ) ) <TAB><TAB><TAB> if all ( [ issubclass ( f . variable_type , v ) for v , f in zipped ] ) : <TAB><TAB><TAB><TAB> return True <TAB> else : <TAB><TAB> return True <TAB> return False",if type ( input_types [ 0 ] ) != list :,"if not isinstance ( input_types , list ) :",63.69595143056379,94.66,False
4850,"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB><TAB> try : <TAB><TAB><TAB> result_list . append ( f . get_result ( ) ) <TAB><TAB> except Exception as e : <TAB><TAB><TAB> if exc_info is None : <TAB><TAB><TAB><TAB> exc_info = sys . exc_info ( ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB><TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB><TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB><TAB> return list ( result_list )","if not isinstance ( e , self . quiet_exceptions ) :",if len ( result_list ) > 1 :,85.82609808774501,95.50,False
4851,"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB><TAB> if step_num < hparams . lrn_step : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn <TAB><TAB> <MASK> <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 10 <TAB><TAB> elif step_num < 35000 : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 100 <TAB><TAB> else : <TAB><TAB><TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB><TAB> fd [ model . lrn_rate ] = lrn_rate",elif step_num < 30000 :,elif step_num < 10000 :,98.78228096792873,98.82,False
4852,"def topic_exists ( self , arn ) : <TAB> response = self . _conn . get_all_topics ( ) <TAB> topics = response [ "" ListTopicsResponse "" ] [ "" ListTopicsResult "" ] [ "" Topics "" ] <TAB> current_topics = [ ] <TAB> if len ( topics ) > 0 : <TAB><TAB> for topic in topics : <TAB><TAB><TAB> topic_arn = topic [ "" TopicArn "" ] <TAB><TAB><TAB> current_topics . append ( topic_arn ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False",if arn in current_topics :,if arn in current_topics :,100.0,100.00,True
4853,"def assertStartsWith ( self , expectedPrefix , text , msg = None ) : <TAB> if not text . startswith ( expectedPrefix ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> text = text [ : len ( expectedPrefix ) + 5 ] + "" ... "" <TAB><TAB> standardMsg = "" {}  not found at the start of  {} "" . format ( <TAB><TAB><TAB> repr ( expectedPrefix ) , repr ( text ) <TAB><TAB> ) <TAB><TAB> self . fail ( self . _formatMessage ( msg , standardMsg ) )",if len ( expectedPrefix ) + 5 < len ( text ) :,if len ( text ) + 5 < len ( expectedPrefix ) :,98.9213625901529,98.53,False
4854,"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB><TAB> <MASK> # use NoneType to unset a value <TAB><TAB><TAB> continue <TAB><TAB> if not re . match ( PROCTYPE_MATCH , k ) : <TAB><TAB><TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB><TAB> if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB><TAB><TAB> raise serializers . ValidationError ( <TAB><TAB><TAB><TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB><TAB><TAB> ) <TAB> return value",if v is None :,if v is None :,75.0,100.00,True
4855,"def open ( self ) - > "" KeyValueJsonDb "" : <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os . path . exists ( self . _name ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB><TAB> try : <TAB><TAB><TAB> with open ( self . _name , "" r "" ) as _in : <TAB><TAB><TAB><TAB> self . set_records ( json . load ( _in ) ) <TAB><TAB> except json . JSONDecodeError : <TAB><TAB><TAB> # file corrupted, reset it. <TAB><TAB><TAB> self . commit ( ) <TAB> else : <TAB><TAB> # make sure path exists <TAB><TAB> mkpath ( os . path . dirname ( self . _name ) ) <TAB><TAB> self . commit ( ) <TAB> return self",if not os . path . isfile ( self . _name ) :,if not os . path . isfile ( self . _name ) :,100.0,100.00,True
4856,"def _calculate ( self ) : <TAB> before = self . before . data <TAB> after = self . after . data <TAB> self . deleted = { } <TAB> self . updated = { } <TAB> self . created = after . copy ( ) <TAB> for path , f in before . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . deleted [ path ] = f <TAB><TAB><TAB> continue <TAB><TAB> del self . created [ path ] <TAB><TAB> if f . mtime < after [ path ] . mtime : <TAB><TAB><TAB> self . updated [ path ] = after [ path ]",if path not in after :,"if f . name == ""delete"" :",77.13400963622182,94.18,False
4857,"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB><TAB> else : <TAB><TAB><TAB> if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) : <TAB><TAB><TAB><TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True","if config . get ( ""environment"" ) == ""prod"" :","if account_id in config . get ( ""celery.test_account_ids""",96.96973777153359,94.26,False
4858,"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB><TAB> if error_on_path : <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> return <TAB> if config is not None or defaults is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> config = self . _config <TAB><TAB> if defaults is None : <TAB><TAB><TAB> defaults = dict ( self . _map . parents ) <TAB><TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB><TAB> chain = self . _map <TAB> try : <TAB><TAB> chain . del_by_path ( path ) <TAB><TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB><TAB> if error_on_path : <TAB><TAB><TAB> raise NoSuchSettingsPath ( ) <TAB><TAB> pass",if config is None :,if config is None :,100.0,100.00,True
4859,"def PopulateProjectId ( project_id = None ) : <TAB> """"""Fills in a project_id from the boto config file if one is not provided."""""" <TAB> if not project_id : <TAB><TAB> default_id = boto . config . get_value ( "" GSUtil "" , "" default_project_id "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProjectIdException ( "" MissingProjectId "" ) <TAB><TAB> return default_id <TAB> return project_id",if not default_id :,if default_id is None :,67.92519734288159,95.78,False
4860,"def set ( self , name , value ) : <TAB> with self . _object_cache_lock : <TAB><TAB> old_value = self . _object_cache . get ( name ) <TAB><TAB> ret = not old_value or int ( old_value . metadata . resource_version ) < int ( <TAB><TAB><TAB> value . metadata . resource_version <TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _object_cache [ name ] = value <TAB> return ret , old_value",if ret :,if ret :,100.0,100.00,True
4861,"def remove ( self , url ) : <TAB> try : <TAB><TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB><TAB> pass <TAB> else : <TAB><TAB> was_selected = i in self . selectedindices ( ) <TAB><TAB> self . list . delete ( i ) <TAB><TAB> del self . items [ i ] <TAB><TAB> if not self . items : <TAB><TAB><TAB> self . mp . hidepanel ( self . name ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if i > = len ( self . items ) : <TAB><TAB><TAB><TAB> i = len ( self . items ) - 1 <TAB><TAB><TAB> self . list . select_set ( i )",elif was_selected :,if was_selected :,78.58470270150688,98.72,False
4862,"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB><TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB><TAB> path = join ( dir_path , p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # call recursively for each dir <TAB><TAB><TAB> paths = add_directory_csv_files ( path , paths ) <TAB><TAB> elif isfile ( path ) and path . endswith ( "" .csv "" ) : <TAB><TAB><TAB> # add every file to the list <TAB><TAB><TAB> paths . append ( path ) <TAB> return paths",if isdir ( path ) :,if isdir ( path ) :,100.0,100.00,True
4863,"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> if isinstance ( value , dict ) : <TAB><TAB><TAB><TAB> return GeneralPrivateEndpointClient ( <TAB><TAB><TAB><TAB><TAB> key , <TAB><TAB><TAB><TAB><TAB> value [ "" api_version "" ] , <TAB><TAB><TAB><TAB><TAB> value [ "" support_list_or_not "" ] , <TAB><TAB><TAB><TAB><TAB> value [ "" resource_get_api_version "" ] , <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB> return value ( ) <TAB> raise CLIError ( <TAB><TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> )",if str . lower ( key ) == str . lower ( resource_provider ) :,if resource_provider == key :,91.08307217446256,93.99,False
4864,"def compute_rule_hash ( self , rule ) : <TAB> buf = "" %d - %d - %s - "" % ( <TAB><TAB> rule . get ( "" FromPort "" , 0 ) or 0 , <TAB><TAB> rule . get ( "" ToPort "" , 0 ) or 0 , <TAB><TAB> rule . get ( "" IpProtocol "" , "" -1 "" ) or "" -1 "" , <TAB> ) <TAB> for a , ke in self . RULE_ATTRS : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> ev = [ e [ ke ] for e in rule [ a ] ] <TAB><TAB> ev . sort ( ) <TAB><TAB> for e in ev : <TAB><TAB><TAB> buf + = "" %s - "" % e <TAB> # mask to generate the same numeric value across all Python versions <TAB> return zlib . crc32 ( buf . encode ( "" ascii "" ) ) & 0xFFFFFFFF",if a not in rule :,if a not in rule :,100.0,100.00,True
4865,"def analysis_sucess_metrics ( analysis_time : float , allow_exception = False ) : <TAB> try : <TAB><TAB> anchore_engine . subsys . metrics . counter_inc ( name = "" anchore_analysis_success "" ) <TAB><TAB> anchore_engine . subsys . metrics . histogram_observe ( <TAB><TAB><TAB> "" anchore_analysis_time_seconds "" , <TAB><TAB><TAB> analysis_time , <TAB><TAB><TAB> buckets = ANALYSIS_TIME_SECONDS_BUCKETS , <TAB><TAB><TAB> status = "" success "" , <TAB><TAB> ) <TAB> except : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> else : <TAB><TAB><TAB> logger . exception ( <TAB><TAB><TAB><TAB> "" Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing "" <TAB><TAB><TAB> )",if allow_exception :,if allow_exception :,100.0,100.00,True
4866,"def decide_file_icon ( file ) : <TAB> if file . state == File . ERROR : <TAB><TAB> return FileItem . icon_error <TAB> elif isinstance ( file . parent , Track ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return FileItem . icon_saved <TAB><TAB> elif file . state == File . PENDING : <TAB><TAB><TAB> return FileItem . match_pending_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB><TAB> else : <TAB><TAB><TAB> return FileItem . match_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB> elif file . state == File . PENDING : <TAB><TAB> return FileItem . icon_file_pending <TAB> else : <TAB><TAB> return FileItem . icon_file",if file . state == File . NORMAL :,if file . state == File . SENTINEL :,73.92750377866864,98.75,False
4867,"def deleteMenu ( self , menuName ) : <TAB> try : <TAB><TAB> menu = self . getMenu ( menuName ) <TAB><TAB> <MASK> <TAB><TAB><TAB> self . destroy ( menu ) <TAB><TAB><TAB> self . destroyMenu ( menuName ) <TAB><TAB> else : <TAB><TAB><TAB> g . es ( "" can ' t delete menu: "" , menuName ) <TAB> except Exception : <TAB><TAB> g . es ( "" exception deleting "" , menuName , "" menu "" ) <TAB><TAB> g . es_exception ( )",if menu :,if menu :,100.0,100.00,True
4868,"def parser ( cls , buf ) : <TAB> ( type_ , code , csum ) = struct . unpack_from ( cls . _PACK_STR , buf ) <TAB> msg = cls ( type_ , code , csum ) <TAB> offset = cls . _MIN_LEN <TAB> if len ( buf ) > offset : <TAB><TAB> cls_ = cls . _ICMPV6_TYPES . get ( type_ , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> msg . data = cls_ . parser ( buf , offset ) <TAB><TAB> else : <TAB><TAB><TAB> msg . data = buf [ offset : ] <TAB> return msg , None , None",if cls_ :,if cls_ :,100.0,100.00,True
4869,"def _load_dataset_area ( self , dsid , file_handlers , coords ) : <TAB> """"""Get the area for *dsid*."""""" <TAB> try : <TAB><TAB> return self . _load_area_def ( dsid , file_handlers ) <TAB> except NotImplementedError : <TAB><TAB> if any ( x is None for x in coords ) : <TAB><TAB><TAB> logger . warning ( "" Failed to load coordinates for  ' {} ' "" . format ( dsid ) ) <TAB><TAB><TAB> return None <TAB><TAB> area = self . _make_area_from_coords ( coords ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( "" No coordinates found for  %s "" , str ( dsid ) ) <TAB><TAB> return area",if area is None :,if not area :,69.82335647038434,97.80,False
4870,"def __getattr__ ( self , name ) : <TAB> if Popen . verbose : <TAB><TAB> sys . stdout . write ( "" Getattr:  %s ... "" % name ) <TAB> if name in Popen . __slots__ : <TAB><TAB> return object . __getattribute__ ( self , name ) <TAB> else : <TAB><TAB> if self . popen is not None : <TAB><TAB><TAB> if Popen . verbose : <TAB><TAB><TAB><TAB> print ( "" from Popen "" ) <TAB><TAB><TAB> return getattr ( self . popen , name ) <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return self . emu_wait <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> raise Exception ( "" subprocess emulation: not implemented:  %s "" % name )","if name == ""wait"" :",if self . emu_wait is not None :,71.04445057836092,95.96,False
4871,"def update ( self , time_delta ) : <TAB> super ( ) . update ( time_delta ) <TAB> n = self . menu . selected_option <TAB> if n == self . last : <TAB><TAB> return <TAB> self . last = n <TAB> s = "" "" <TAB> for i in range ( len ( self . files ) ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> for l in open ( self . files [ i ] [ 1 ] ) : <TAB><TAB><TAB><TAB> x = l . strip ( ) <TAB><TAB><TAB><TAB> if len ( x ) > 1 and x [ 0 ] == "" # "" : <TAB><TAB><TAB><TAB><TAB> x = "" <b><u> "" + x [ 1 : ] + ""  </u></b> "" <TAB><TAB><TAB><TAB> s + = x + "" <br> "" <TAB> self . set_text ( s )",if self . files [ i ] [ 0 ] == n :,"if self . files [ i ] [ 0 ] == ""file"" :",97.98866521462574,98.22,False
4872,"def wrapper ( * args , * * kwargs ) : <TAB> list_args , empty = _apply_defaults ( func , args , kwargs ) <TAB> if len ( dimensions ) > len ( list_args ) : <TAB><TAB> raise TypeError ( <TAB><TAB><TAB> "" %s  takes  %i  parameters, but  %i  dimensions were passed "" <TAB><TAB><TAB> % ( func . __name__ , len ( list_args ) , len ( dimensions ) ) <TAB><TAB> ) <TAB> for dim , value in zip ( dimensions , list_args ) : <TAB><TAB> if dim is None : <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> val_dim = ureg . get_dimensionality ( value ) <TAB><TAB><TAB> raise DimensionalityError ( value , "" a quantity of "" , val_dim , dim ) <TAB> return func ( * args , * * kwargs )",if not ureg . Quantity ( value ) . check ( dim ) :,if not empty and dim not in ureg . get_quantity ( value ) :,94.11915032423093,95.23,False
4873,"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB><TAB> for width in VALUES : <TAB><TAB><TAB> strlen = abs ( width * height ) <TAB><TAB><TAB> if size : <TAB><TAB><TAB><TAB> strlen * = size <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> data = "" A "" * strlen <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> data = AAAAA <TAB><TAB><TAB> if size : <TAB><TAB><TAB><TAB> arguments = ( data , size , width , height ) + extra <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> arguments = ( data , width , height ) + extra <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> func ( * arguments ) <TAB><TAB><TAB> except ( ValueError , imageop . error ) : <TAB><TAB><TAB><TAB> pass",if strlen < MAX_LEN :,if strlen > 0 :,96.99938961187,98.04,False
4874,"def wait_send_all_might_not_block ( self ) - > None : <TAB> with self . _send_conflict_detector : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise trio . ClosedResourceError ( "" file was already closed "" ) <TAB><TAB> try : <TAB><TAB><TAB> await trio . lowlevel . wait_writable ( self . _fd_holder . fd ) <TAB><TAB> except BrokenPipeError as e : <TAB><TAB><TAB> # kqueue: raises EPIPE on wait_writable instead <TAB><TAB><TAB> # of sending, which is annoying <TAB><TAB><TAB> raise trio . BrokenResourceError from e",if self . _fd_holder . closed :,if self . _fd_holder . fd is None :,82.266734627958,97.27,False
4875,"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB><TAB> if "" = "" in p : <TAB><TAB><TAB> tab = p . split ( "" = "" , 1 ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tab [ 0 ] = "" SOCKS4 "" <TAB><TAB><TAB> proxies . append ( <TAB><TAB><TAB><TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB><TAB><TAB> ) # type, addr:port, username, password <TAB><TAB> else : <TAB><TAB><TAB> proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB> return proxies","if tab [ 0 ] == ""socks"" :",if len ( tab ) == 2 :,76.67341172721524,95.39,False
4876,"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB><TAB> return passed_class <TAB> else : <TAB><TAB> # pyclass = passed_self.get_type() <TAB><TAB> pyclass = passed_class <TAB><TAB> if isinstance ( pyclass , pyobjects . AbstractClass ) : <TAB><TAB><TAB> supers = pyclass . get_superclasses ( ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return pyobjects . PyObject ( supers [ 0 ] ) <TAB><TAB> return passed_self",if supers :,if supers :,100.0,100.00,True
4877,"def update_output_mintime ( job ) : <TAB> try : <TAB><TAB> return output_mintime [ job ] <TAB> except KeyError : <TAB><TAB> for job_ in chain ( [ job ] , self . depending [ job ] ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> t = output_mintime [ job_ ] <TAB><TAB><TAB> except KeyError : <TAB><TAB><TAB><TAB> t = job_ . output_mintime <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> output_mintime [ job ] = t <TAB><TAB><TAB><TAB> return <TAB><TAB> output_mintime [ job ] = None",if t is not None :,if t is not None :,100.0,100.00,True
4878,"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB><TAB> for x in notifications_list : <TAB><TAB><TAB> split_provider_id = x . split ( "" : "" ) # email:id <TAB><TAB><TAB> if len ( split_provider_id ) == 2 : <TAB><TAB><TAB><TAB> _id = split_provider_id [ 1 ] <TAB><TAB><TAB><TAB> cursor = self . get_by_id ( _id ) <TAB><TAB><TAB><TAB> <MASK> # Append if exists <TAB><TAB><TAB><TAB><TAB> result . append ( cursor ) <TAB> return result",if cursor :,if cursor :,100.0,100.00,True
4879,"def stop ( self ) : <TAB> with self . lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return <TAB><TAB> self . task_queue . put ( None ) <TAB><TAB> self . result_queue . put ( None ) <TAB><TAB> process = self . process <TAB><TAB> self . process = None <TAB><TAB> self . task_queue = None <TAB><TAB> self . result_queue = None <TAB> process . join ( timeout = 0.1 ) <TAB> if process . exitcode is None : <TAB><TAB> os . kill ( process . pid , signal . SIGKILL ) <TAB><TAB> process . join ( )",if not self . process :,if self . process is None :,90.75692698050996,96.96,False
4880,"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB><TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB><TAB><TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB><TAB> choice = data [ "" choice "" ] <TAB><TAB> if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) : <TAB><TAB><TAB> return flask . abort ( <TAB><TAB><TAB><TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB><TAB><TAB> ) <TAB><TAB> self . _answer_prompt ( choice )",if self . _prompt is None :,"if not data [ ""choice"" ] :",76.32513636447415,96.11,False
4881,"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames : <TAB><TAB> logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB><TAB> <MASK> <TAB><TAB><TAB> if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES : <TAB><TAB><TAB><TAB> sabnzbd . add_nzbfile ( filename , keep = True )",if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,75.0,100.00,True
4882,"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self . CloseFailureIO ( ) <TAB> with support . catch_unraisable_exception ( ) as cm : <TAB><TAB> with self . assertRaises ( AttributeError ) : <TAB><TAB><TAB> self . tp ( rawio ) . xyzzy <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertIsNone ( cm . unraisable ) <TAB><TAB> elif cm . unraisable is not None : <TAB><TAB><TAB> self . assertEqual ( cm . unraisable . exc_type , OSError )",if not IOBASE_EMITS_UNRAISABLE :,"if hasattr ( cm , ""unraisable"" ) :",72.0668171272002,94.22,False
4883,"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> f = urllib . urlopen ( url , postdata ) <TAB><TAB> else : <TAB><TAB><TAB> f = urllib . urlopen ( url ) <TAB><TAB> response = f . read ( ) <TAB> except : <TAB><TAB> import traceback <TAB><TAB> import logging , sys <TAB><TAB> cla , exc , tb = sys . exc_info ( ) <TAB><TAB> logging . error ( url ) <TAB><TAB> if postdata : <TAB><TAB><TAB> logging . error ( "" with post data "" ) <TAB><TAB> else : <TAB><TAB><TAB> logging . error ( "" without post data "" ) <TAB><TAB> logging . error ( exc . args ) <TAB><TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB><TAB> response = "" "" <TAB> return response",if postdata != { } :,if postdata :,97.18682207915101,97.75,False
4884,"def check_single_file ( fn , fetchuri ) : <TAB> """"""Determine if a single downloaded file is something we can't handle"""""" <TAB> with open ( fn , "" r "" , errors = "" surrogateescape "" ) as f : <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . error ( <TAB><TAB><TAB><TAB> ' Fetching  "" %s ""  returned a single HTML page - check the URL is correct and functional ' <TAB><TAB><TAB><TAB> % fetchuri <TAB><TAB><TAB> ) <TAB><TAB><TAB> sys . exit ( 1 )","if ""<html"" in f . read ( 100 ) . lower ( ) :",if fetchuri in f . read ( ) :,67.15899912063128,92.81,False
4885,"def update_properties ( self , update_dict ) : <TAB> signed_attribute_changed = False <TAB> for k , value in update_dict . items ( ) : <TAB><TAB> if getattr ( self , k ) != value : <TAB><TAB><TAB> setattr ( self , k , value ) <TAB><TAB><TAB> signed_attribute_changed = signed_attribute_changed or ( <TAB><TAB><TAB><TAB> k in self . payload_arguments <TAB><TAB><TAB> ) <TAB> if signed_attribute_changed : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . status = UPDATED <TAB><TAB> self . timestamp = clock . tick ( ) <TAB><TAB> self . sign ( ) <TAB> return self",if self . status != NEW :,if self . status == NOT_UPDATED :,98.15515651041477,96.75,False
4886,"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB><TAB> if event != item . event : <TAB><TAB><TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB><TAB> if item . has_variations : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> raise ValidationError ( <TAB><TAB><TAB><TAB><TAB> _ ( <TAB><TAB><TAB><TAB><TAB><TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB><TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> )",if not any ( var . item == item for var in variations ) :,if variations and variations not in item . variations :,67.9936994411023,92.70,False
4887,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> if tt == 18 : <TAB><TAB><TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
4888,"def connections ( self ) : <TAB> # Connections look something like this: <TAB> # socket:[102422] <TAB> fds = self . open_files <TAB> socket = "" socket:[ "" <TAB> result = [ ] <TAB> functions = [ pwndbg . net . tcp , pwndbg . net . unix , pwndbg . net . netlink ] <TAB> for fd , path in fds . items ( ) : <TAB><TAB> if socket not in path : <TAB><TAB><TAB> continue <TAB><TAB> inode = path [ len ( socket ) : - 1 ] <TAB><TAB> inode = int ( inode ) <TAB><TAB> for func in functions : <TAB><TAB><TAB> for x in func ( ) : <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> x . fd = fd <TAB><TAB><TAB><TAB><TAB> result . append ( x ) <TAB> return tuple ( result )",if x . inode == inode :,if x . inode == inode :,75.0,100.00,True
4889,"def _movement_finished ( self ) : <TAB> if self . in_ship_map : <TAB><TAB> # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <TAB><TAB> <MASK> <TAB><TAB><TAB> ship = self . session . world . ship_map . get ( self . _next_target . to_tuple ( ) ) <TAB><TAB><TAB> if ship is not None and ship ( ) is self : <TAB><TAB><TAB><TAB> del self . session . world . ship_map [ self . _next_target . to_tuple ( ) ] <TAB> super ( ) . _movement_finished ( )",if self . _next_target is not None :,if self . _next_target . to_tuple ( ) is not None :,98.25066163703035,95.72,False
4890,"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 : # at least one complete IP address <TAB><TAB> while 1 : <TAB><TAB><TAB> if p + 1 == self . get_ptr ( ) : <TAB><TAB><TAB><TAB> tmp_str + = "" # "" <TAB><TAB><TAB> tmp_str + = self . get_ip_address ( p ) <TAB><TAB><TAB> p + = 4 <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> tmp_str + = "" ,  "" <TAB> tmp_str + = "" ]  "" <TAB> if self . get_ptr ( ) % 4 : # ptr field should be a multiple of 4 <TAB><TAB> tmp_str + = "" nonsense ptr field:  %d   "" % self . get_ptr ( ) <TAB> return tmp_str",if p >= self . get_len ( ) :,if self . get_ptr ( ) == self . get_ptr ( ) :,97.24810391536546,95.59,False
4891,"def source_shapes ( self ) : <TAB> """"""Prints debug information about the sources in this provider."""""" <TAB> if logger . isEnabledFor ( logging . DEBUG ) : <TAB><TAB> for i , source in enumerate ( self . sources ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> name = "" anonymous "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> name = self . keys [ i ] <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> shape = source . shape ( ) <TAB><TAB><TAB> except NotImplementedError : <TAB><TAB><TAB><TAB> shape = "" N/A "" <TAB><TAB><TAB> logger . debug ( <TAB><TAB><TAB><TAB> ' Data source  "" %s "" : entries= %s , shape= %s ' , name , len ( source ) , shape <TAB><TAB><TAB> )",if self . keys is None :,if i == 0 :,95.51769431736035,97.33,False
4892,def swap_actions ( actions ) : <TAB> for mutexgroup in mutex_groups : <TAB><TAB> mutex_actions = mutexgroup . _group_actions <TAB><TAB> <MASK> <TAB><TAB><TAB> # make a best guess as to where we should store the group <TAB><TAB><TAB> targetindex = actions . index ( mutexgroup . _group_actions [ 0 ] ) <TAB><TAB><TAB> # insert the _ArgumentGroup container <TAB><TAB><TAB> actions [ targetindex ] = mutexgroup <TAB><TAB><TAB> # remove the duplicated individual actions <TAB><TAB><TAB> actions = [ action for action in actions if action not in mutex_actions ] <TAB> return actions,"if contains_actions ( mutex_actions , actions ) :",if mutexgroup . _group_actions :,76.0149942558811,93.89,False
4893,"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB><TAB> dep_cnts = services . get ( dep ) <TAB><TAB> if not dep_cnts : <TAB><TAB><TAB> continue <TAB><TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB><TAB> if dep_cnt : <TAB><TAB><TAB> # TODO: avoid creating loops, A->B->A <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB><TAB><TAB> deps . update ( new_deps ) <TAB> return deps","if init_service and init_service in dep_cnt [ ""_deps"" ] :",if dep_cnt == 0 :,95.3556349212712,92.63,False
4894,"def make_dump_list_by_name_list ( name_list ) : <TAB> info_list = [ ] <TAB> for info_name in name_list : <TAB><TAB> info = next ( ( x for x in DUMP_LIST if x . info_name == info_name ) , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RuntimeError ( ' Unknown info name:  "" {} "" ' . format ( info_name ) ) <TAB><TAB> info_list . append ( info ) <TAB> return info_list",if not info :,if not info :,100.0,100.00,True
4895,"def create ( self , private = False ) : <TAB> try : <TAB><TAB> if private : <TAB><TAB><TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB><TAB><TAB> self . _bot . api_call ( <TAB><TAB><TAB><TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB><TAB><TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB><TAB> else : <TAB><TAB><TAB> raise RoomError ( e )","if e . error == ""user_is_bot"" :",if e . error_code == USER_IS_BOT_HELPTEXT :,97.11790669426277,95.67,False
4896,"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB><TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB><TAB> i = self . readSentence ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> reply = i [ 0 ] <TAB><TAB> attrs = { } <TAB><TAB> for w in i [ 1 : ] : <TAB><TAB><TAB> j = w . find ( "" = "" , 1 ) <TAB><TAB><TAB> if j == - 1 : <TAB><TAB><TAB><TAB> attrs [ w ] = "" "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB><TAB> r . append ( ( reply , attrs ) ) <TAB><TAB> if reply == "" !done "" : <TAB><TAB><TAB> return r",if len ( i ) == 0 :,if not i :,69.61643249394812,96.72,False
4897,"def _load_logfile ( self , lfn ) : <TAB> enc_key = self . decryption_key_func ( ) <TAB> with open ( os . path . join ( self . logdir , lfn ) ) as fd : <TAB><TAB> <MASK> <TAB><TAB><TAB> with DecryptingStreamer ( <TAB><TAB><TAB><TAB> fd , mep_key = enc_key , name = "" EventLog/DS( %s ) "" % lfn <TAB><TAB><TAB> ) as streamer : <TAB><TAB><TAB><TAB> lines = streamer . read ( ) <TAB><TAB><TAB><TAB> streamer . verify ( _raise = IOError ) <TAB><TAB> else : <TAB><TAB><TAB> lines = fd . read ( ) <TAB><TAB> if lines : <TAB><TAB><TAB> for line in lines . splitlines ( ) : <TAB><TAB><TAB><TAB> event = Event . Parse ( line . strip ( ) ) <TAB><TAB><TAB><TAB> self . _events [ event . event_id ] = event",if enc_key :,if enc_key :,100.0,100.00,True
4898,"def set_ok_port ( self , cookie , request ) : <TAB> if cookie . port_specified : <TAB><TAB> req_port = request_port ( request ) <TAB><TAB> if req_port is None : <TAB><TAB><TAB> req_port = "" 80 "" <TAB><TAB> else : <TAB><TAB><TAB> req_port = str ( req_port ) <TAB><TAB> for p in cookie . port . split ( "" , "" ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> int ( p ) <TAB><TAB><TAB> except ValueError : <TAB><TAB><TAB><TAB> debug ( ""    bad port  %s  (not numeric) "" , p ) <TAB><TAB><TAB><TAB> return False <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> else : <TAB><TAB><TAB> debug ( ""    request port ( %s ) not found in  %s "" , req_port , cookie . port ) <TAB><TAB><TAB> return False <TAB> return True",if p == req_port :,if p == req_port :,100.0,100.00,True
4899,"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB><TAB> self . logger . debug ( "" get attr val:  %s   %s "" , nodeid , attr ) <TAB><TAB> <MASK> <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB><TAB><TAB> return dv <TAB><TAB> node = self . _nodes [ nodeid ] <TAB><TAB> if attr not in node . attributes : <TAB><TAB><TAB> dv = ua . DataValue ( ) <TAB><TAB><TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB><TAB><TAB> return dv <TAB><TAB> attval = node . attributes [ attr ] <TAB><TAB> if attval . value_callback : <TAB><TAB><TAB> return attval . value_callback ( ) <TAB><TAB> return attval . value",if nodeid not in self . _nodes :,if nodeid not in self . _nodes :,100.0,100.00,True
4900,"def data_logging_status ( self , trail_name , trail_details , api_client ) : <TAB> for es in api_client . get_event_selectors ( TrailName = trail_name ) [ "" EventSelectors "" ] : <TAB><TAB> has_wildcard = { <TAB><TAB><TAB> u "" Values "" : [ u "" arn:aws:s3::: "" ] , <TAB><TAB><TAB> u "" Type "" : u "" AWS::S3::Object "" , <TAB><TAB> } in es [ "" DataResources "" ] <TAB><TAB> is_logging = trail_details [ "" IsLogging "" ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False",if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,if has_wildcard and is_logging :,78.9410147156232,93.17,False
4901,"def pytest_deselected ( items ) : <TAB> if sb_config . dashboard : <TAB><TAB> sb_config . item_count - = len ( items ) <TAB><TAB> for item in items : <TAB><TAB><TAB> test_id , display_id = _get_test_ids_ ( item ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> sb_config . _results . pop ( test_id )",if test_id in sb_config . _results . keys ( ) :,if test_id in sb_config . _results :,64.47633917811706,95.52,False
4902,"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB><TAB> if self . _flags [ fname ] == 1 : <TAB><TAB><TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB><TAB><TAB> import sys <TAB><TAB><TAB> sys . exit ( - 1 ) <TAB><TAB> else : <TAB><TAB><TAB> return <TAB> else : <TAB><TAB> if fname not in self . _flags : <TAB><TAB><TAB> self . _flags [ fname ] = 1 <TAB><TAB> for output in func [ 3 ] : <TAB><TAB><TAB> for f in self . _orig : <TAB><TAB><TAB><TAB> for input in f [ 2 ] : <TAB><TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB><TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if output == input :,if input == output :,98.67168870173366,98.45,False
4903,"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB><TAB> <MASK> <TAB><TAB><TAB> if firstHeading : <TAB><TAB><TAB><TAB> output ( "" |} "" ) <TAB><TAB><TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB><TAB><TAB> firstHeading = True <TAB><TAB> else : <TAB><TAB><TAB> output ( "" |- "" ) <TAB><TAB><TAB> output ( <TAB><TAB><TAB><TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB><TAB><TAB><TAB> + m [ 0 ] <TAB><TAB><TAB><TAB> + "" </tt></span> || ||  "" <TAB><TAB><TAB><TAB> + m [ 1 ] <TAB><TAB><TAB> ) <TAB> output ( "" |} "" )","if m [ 0 ] == """" :","if m [ 0 ] == ""heading"" :",98.7731393588137,98.98,False
4904,"def test_getitem ( self ) : <TAB> n = 200 <TAB> d = deque ( range ( n ) ) <TAB> l = list ( range ( n ) ) <TAB> for i in range ( n ) : <TAB><TAB> d . popleft ( ) <TAB><TAB> l . pop ( 0 ) <TAB><TAB> <MASK> <TAB><TAB><TAB> d . append ( i ) <TAB><TAB><TAB> l . append ( i ) <TAB><TAB> for j in range ( 1 - len ( l ) , len ( l ) ) : <TAB><TAB><TAB> assert d [ j ] == l [ j ] <TAB> d = deque ( "" superman "" ) <TAB> self . assertEqual ( d [ 0 ] , "" s "" ) <TAB> self . assertEqual ( d [ - 1 ] , "" n "" ) <TAB> d = deque ( ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , 0 ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , - 1 )",if random . random ( ) < 0.5 :,if len ( d ) == 1 :,75.71353516632334,96.80,False
4905,"def get_num ( line , char_ptr , num_chars ) : <TAB> char_ptr = char_ptr + 1 <TAB> numstr = "" "" <TAB> good = "" -.0123456789 "" <TAB> while char_ptr < num_chars : <TAB><TAB> digit = line [ char_ptr ] <TAB><TAB> <MASK> <TAB><TAB><TAB> numstr = numstr + digit <TAB><TAB><TAB> char_ptr = char_ptr + 1 <TAB><TAB> else : <TAB><TAB><TAB> break <TAB> return numstr",if good . find ( digit ) != - 1 :,if digit in good :,61.26746393959927,92.19,False
4906,"def read_digits ( source , start , first_code ) : <TAB> body = source . body <TAB> position = start <TAB> code = first_code <TAB> if code is not None and 48 < = code < = 57 : # 0 - 9 <TAB><TAB> while True : <TAB><TAB><TAB> position + = 1 <TAB><TAB><TAB> code = char_code_at ( body , position ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> return position <TAB> raise GraphQLSyntaxError ( <TAB><TAB> source , <TAB><TAB> position , <TAB><TAB> u "" Invalid number, expected digit but got:  {} . "" . format ( print_char_code ( code ) ) , <TAB> )",if not ( code is not None and 48 <= code <= 57 ) :,if code is not None and code != code :,95.23285775343429,93.97,False
4907,"def get_aws_metadata ( headers , provider = None ) : <TAB> if not provider : <TAB><TAB> provider = boto . provider . get_default ( ) <TAB> metadata_prefix = provider . metadata_prefix <TAB> metadata = { } <TAB> for hkey in headers . keys ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> val = urllib . unquote_plus ( headers [ hkey ] ) <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = unicode ( val , "" utf-8 "" ) <TAB><TAB><TAB> except UnicodeDecodeError : <TAB><TAB><TAB><TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = val <TAB><TAB><TAB> del headers [ hkey ] <TAB> return metadata",if hkey . lower ( ) . startswith ( metadata_prefix ) :,if hkey . startswith ( metadata_prefix ) :,95.86312418269128,97.76,False
4908,"def _process_rtdest ( self ) : <TAB> LOG . debug ( "" Processing RT NLRI destination... "" ) <TAB> if self . _rtdest_queue . is_empty ( ) : <TAB><TAB> return <TAB> else : <TAB><TAB> processed_any = False <TAB><TAB> while not self . _rtdest_queue . is_empty ( ) : <TAB><TAB><TAB> # We process the first destination in the queue. <TAB><TAB><TAB> next_dest = self . _rtdest_queue . pop_first ( ) <TAB><TAB><TAB> if next_dest : <TAB><TAB><TAB><TAB> next_dest . process ( ) <TAB><TAB><TAB><TAB> processed_any = True <TAB><TAB> <MASK> <TAB><TAB><TAB> # Since RT destination were updated we update RT filters <TAB><TAB><TAB> self . _core_service . update_rtfilters ( )",if processed_any :,if processed_any :,100.0,100.00,True
4909,"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB><TAB> if header_name in headers : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB><TAB><TAB> return headers . get ( header_name )",if self . revs_enabled :,if self . revs_enabled :,100.0,100.00,True
4910,"def add_external_deps ( self , deps ) : <TAB> for dep in deps : <TAB><TAB> if hasattr ( dep , "" el "" ) : <TAB><TAB><TAB> dep = dep . el <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidArguments ( "" Argument is not an external dependency "" ) <TAB><TAB> self . external_deps . append ( dep ) <TAB><TAB> if isinstance ( dep , dependencies . Dependency ) : <TAB><TAB><TAB> self . process_sourcelist ( dep . get_sources ( ) )","if not isinstance ( dep , dependencies . Dependency ) :","if not isinstance ( dep , ( Sourcelist , Sourcelist ) ) :",69.86330603803603,95.46,False
4911,"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB><TAB> while True : <TAB><TAB><TAB> r = await ws . recv ( ) <TAB><TAB><TAB> if isinstance ( r , bytes ) : <TAB><TAB><TAB><TAB> r = r . decode ( "" utf-8 "" ) <TAB><TAB><TAB> msg = json . loads ( r ) <TAB><TAB><TAB> stream = msg . get ( "" stream "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB><TAB> logging . warn ( wse ) <TAB><TAB> await self . close ( ) <TAB><TAB> asyncio . ensure_future ( self . _ensure_ws ( ) )",if stream is not None :,if stream :,72.20706805376892,97.90,False
4912,"def generate_and_check_random ( ) : <TAB> random_size = 256 <TAB> while True : <TAB><TAB> random = os . urandom ( random_size ) <TAB><TAB> a = int . from_bytes ( random , "" big "" ) <TAB><TAB> A = pow ( g , a , p ) <TAB><TAB> <MASK> <TAB><TAB><TAB> a_for_hash = big_num_for_hash ( A ) <TAB><TAB><TAB> u = int . from_bytes ( sha256 ( a_for_hash , b_for_hash ) , "" big "" ) <TAB><TAB><TAB> if u > 0 : <TAB><TAB><TAB><TAB> return ( a , a_for_hash , u )","if is_good_mod_exp_first ( A , p ) :",if A > 0 :,67.24155958143616,92.12,False
4913,"def write ( self , datagram , address ) : <TAB> """"""Write a datagram."""""" <TAB> try : <TAB><TAB> return self . socket . sendto ( datagram , address ) <TAB> except OSError as se : <TAB><TAB> no = se . args [ 0 ] <TAB><TAB> if no == EINTR : <TAB><TAB><TAB> return self . write ( datagram , address ) <TAB><TAB> elif no == EMSGSIZE : <TAB><TAB><TAB> raise error . MessageLengthError ( "" message too long "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # oh, well, drop the data. The only difference from UDP <TAB><TAB><TAB> # is that UDP won't ever notice. <TAB><TAB><TAB> # TODO: add TCP-like buffering <TAB><TAB><TAB> pass <TAB><TAB> else : <TAB><TAB><TAB> raise",elif no == EAGAIN :,elif no == EWOULDBLOCK :,98.92830758459522,98.87,False
4914,"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if child . tagName == "" Directory "" : <TAB><TAB><TAB> doDir ( child ) <TAB><TAB> elif child . tagName == "" Component "" : <TAB><TAB><TAB> for grandchild in child . childNodes : <TAB><TAB><TAB><TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> if grandchild . tagName != "" File "" : <TAB><TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB><TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if not isinstance ( child , minidom . Element ) :","if not isinstance ( child , minidom . Element ) :",75.0,100.00,True
4915,"def add_reversed_tensor ( i , X , reversed_X ) : <TAB> # Do not keep tensors that should stop the mapping. <TAB> if X in stop_mapping_at_tensors : <TAB><TAB> return <TAB> if X not in reversed_tensors : <TAB><TAB> reversed_tensors [ X ] = { "" id "" : ( nid , i ) , "" tensor "" : reversed_X } <TAB> else : <TAB><TAB> tmp = reversed_tensors [ X ] <TAB><TAB> if "" tensor "" in tmp and "" tensors "" in tmp : <TAB><TAB><TAB> raise Exception ( "" Wrong order, tensors already aggregated! "" ) <TAB><TAB> <MASK> <TAB><TAB><TAB> tmp [ "" tensors "" ] = [ tmp [ "" tensor "" ] , reversed_X ] <TAB><TAB><TAB> del tmp [ "" tensor "" ] <TAB><TAB> else : <TAB><TAB><TAB> tmp [ "" tensors "" ] . append ( reversed_X )","if ""tensor"" in tmp :","if ""tensors"" not in tmp :",73.94653246475073,98.23,False
4916,"def walk ( source , path , default , delimiter = "" . "" ) : <TAB> """"""Walk the sourch hash given the path and return the value or default if not found"""""" <TAB> if not isinstance ( source , dict ) : <TAB><TAB> raise RuntimeError ( <TAB><TAB><TAB> "" The source is not a walkable dict:  {}  path:  {} "" . format ( source , path ) <TAB><TAB> ) <TAB> keys = path . split ( delimiter ) <TAB> max_depth = len ( keys ) <TAB> cur_depth = 0 <TAB> while cur_depth < max_depth : <TAB><TAB> <MASK> <TAB><TAB><TAB> source = source [ keys [ cur_depth ] ] <TAB><TAB><TAB> cur_depth = cur_depth + 1 <TAB><TAB> else : <TAB><TAB><TAB> return default <TAB> return source",if keys [ cur_depth ] in source :,if source [ keys [ cur_depth ] ] :,96.11015412748382,97.38,False
4917,"def _from_txt_get_vulns ( self ) : <TAB> file_vulns = [ ] <TAB> vuln_regex = ( <TAB><TAB> ' SQL injection in a .*? was found at:  "" (.*?) "" ' <TAB><TAB> ' , using HTTP method (.*?). The sent .*?data was:  "" (.*?) "" ' <TAB> ) <TAB> vuln_re = re . compile ( vuln_regex ) <TAB> for line in file ( self . OUTPUT_FILE ) : <TAB><TAB> mo = vuln_re . search ( line ) <TAB><TAB> <MASK> <TAB><TAB><TAB> v = MockVuln ( "" TestCase "" , None , "" High "" , 1 , "" plugin "" ) <TAB><TAB><TAB> v . set_url ( URL ( mo . group ( 1 ) ) ) <TAB><TAB><TAB> v . set_method ( mo . group ( 2 ) ) <TAB><TAB><TAB> file_vulns . append ( v ) <TAB> return file_vulns",if mo :,if mo :,100.0,100.00,True
4918,"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB><TAB> if self . att_name not in instance . _obj_cache : <TAB><TAB><TAB> rel_obj = self . get_obj ( instance ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB><TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self",if rel_obj :,if rel_obj :,100.0,100.00,True
4919,"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> pos_end = pos <TAB><TAB> else : <TAB><TAB><TAB> if pos_end > = pos_start : <TAB><TAB><TAB><TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB><TAB><TAB> pos_start = pos + 1 <TAB> if pos_end > = pos_start : <TAB><TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges",if func . type in support_set :,if func . name in support_set :,98.62554929352855,98.67,False
4920,"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB><TAB> # None is a placeholder for any plugin not having a defined order <TAB><TAB> if name is None : <TAB><TAB><TAB> all_plugins + = [ <TAB><TAB><TAB><TAB> plugin <TAB><TAB><TAB><TAB> for name , plugin in self . plugins . items ( ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB> ] <TAB><TAB> else : <TAB><TAB><TAB> plugin = self . plugins [ name ] <TAB><TAB><TAB> if plugin . is_activated : <TAB><TAB><TAB><TAB> all_plugins . append ( plugin ) <TAB> return all_plugins",if name not in self . plugins_callback_order and plugin . is_activated,"if isinstance ( plugin , BotPlugin )",95.14383916398165,93.11,False
4921,"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB><TAB> <MASK> <TAB><TAB><TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB><TAB> elif token . token_type == TOKEN_VAR : <TAB><TAB><TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB><TAB><TAB> vars . append ( token . contents ) <TAB> msg = "" "" . join ( result ) <TAB> if self . trimmed : <TAB><TAB> msg = translation . trim_whitespace ( msg ) <TAB> return msg , vars",if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_VAR_PREFIX :,98.90161650567319,97.58,False
4922,"def test_build_root_config_overwrite ( self ) : <TAB> cfg = build_root_config ( "" tests.files.settings_overwrite "" ) <TAB> for key , val in DEFAULT_SPIDER_GLOBAL_CONFIG . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , [ "" zzz "" ] ) <TAB><TAB> else : <TAB><TAB><TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , val )","if key == ""spider_modules"" :","if key == ""paths"" :",98.2796073235745,96.57,False
4923,"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB><TAB> try : <TAB><TAB><TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB><TAB><TAB> if limit < 0 : <TAB><TAB><TAB><TAB> raise ValueError ( ) <TAB><TAB><TAB> # Enforce maximum page size, if defined <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> if limit == 0 : <TAB><TAB><TAB><TAB><TAB> return settings . MAX_PAGE_SIZE <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> return min ( limit , settings . MAX_PAGE_SIZE ) <TAB><TAB><TAB> return limit <TAB><TAB> except ( KeyError , ValueError ) : <TAB><TAB><TAB> pass <TAB> return self . default_limit",if settings . MAX_PAGE_SIZE :,if settings . MAX_PAGE_SIZE > settings . MAX_PAGE_SIZE :,99.00484940231617,96.87,False
4924,"def track_handler ( handler ) : <TAB> tid = handler . request . tid <TAB> for event in events_monitored : <TAB><TAB> <MASK> <TAB><TAB><TAB> e = Event ( event , handler . request . execution_time ) <TAB><TAB><TAB> State . tenant_state [ tid ] . RecentEventQ . append ( e ) <TAB><TAB><TAB> State . tenant_state [ tid ] . EventQ . append ( e ) <TAB><TAB><TAB> break","if event [ ""handler_check"" ] ( handler ) :",if event not in State . tenant_state [ tid ] . RecentEventQ :,89.18353875132968,90.04,False
4925,"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB><TAB> tt = d . getVarInt32 ( ) <TAB><TAB> if tt == 10 : <TAB><TAB><TAB> length = d . getVarInt32 ( ) <TAB><TAB><TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB><TAB><TAB> d . skip ( length ) <TAB><TAB><TAB> self . add_subscription ( ) . TryMerge ( tmp ) <TAB><TAB><TAB> continue <TAB><TAB> <MASK> <TAB><TAB><TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB><TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,100.0,100.00,True
4926,"def GetCreateInstanceBinder ( self , info ) : <TAB> with self . _lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> return self . _createInstanceBinders [ info ] <TAB><TAB> b = runtime . SymplCreateInstanceBinder ( info ) <TAB><TAB> self . _createInstanceBinders [ info ] = b <TAB> return b",if self . _createInstanceBinders . ContainsKey ( info ) :,if self . _createInstanceBinders . ContainsKey ( info ) :,100.0,100.00,True
4927,"def process_task ( self , body , message ) : <TAB> if "" control "" in body : <TAB><TAB> try : <TAB><TAB><TAB> return self . control ( body , message ) <TAB><TAB> except Exception : <TAB><TAB><TAB> logger . exception ( "" Exception handling control message: "" ) <TAB><TAB><TAB> return <TAB> if len ( self . pool ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> queue = UUID ( body [ "" uuid "" ] ) . int % len ( self . pool ) <TAB><TAB><TAB> except Exception : <TAB><TAB><TAB><TAB> queue = self . total_messages % len ( self . pool ) <TAB><TAB> else : <TAB><TAB><TAB> queue = self . total_messages % len ( self . pool ) <TAB> else : <TAB><TAB> queue = 0 <TAB> self . pool . write ( queue , body ) <TAB> self . total_messages + = 1 <TAB> message . ack ( )","if ""uuid"" in body and body [ ""uuid"" ] :","if ""uuid"" in body :",95.68566845097806,96.89,False
4928,"def is_defined_in_base_class ( self , var : Var ) - > bool : <TAB> if var . info : <TAB><TAB> for base in var . info . mro [ 1 : ] : <TAB><TAB><TAB> if base . get ( var . name ) is not None : <TAB><TAB><TAB><TAB> return True <TAB><TAB> <MASK> <TAB><TAB><TAB> return True <TAB> return False",if var . info . fallback_to_any :,if base . get ( var . name ) is not None :,66.80319435670646,90.17,False
4929,"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB><TAB> tmp + = "" m  "" <TAB><TAB> for col in row : <TAB><TAB><TAB> if col == LAND : <TAB><TAB><TAB><TAB> tmp + = "" . "" <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> tmp + = "" % "" <TAB><TAB><TAB> elif col == FOOD : <TAB><TAB><TAB><TAB> tmp + = "" * "" <TAB><TAB><TAB> elif col == UNSEEN : <TAB><TAB><TAB><TAB> tmp + = "" ? "" <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> players [ col ] = True <TAB><TAB><TAB><TAB> tmp + = chr ( col + 97 ) <TAB><TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == BARRIER :,elif col == LEAST :,99.19101256226242,99.16,False
4930,"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB><TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB><TAB> prompt = "" (R/F)>  "" <TAB><TAB> answer = "" "" <TAB><TAB> try : <TAB><TAB><TAB> answer = raw_input ( prompt ) <TAB><TAB> except NameError : <TAB><TAB><TAB> answer = input ( prompt ) <TAB><TAB> <MASK> <TAB><TAB><TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB><TAB> elif answer . upper ( ) == "" R "" : <TAB><TAB><TAB> logger . debug ( "" Resuming previous scan "" ) <TAB><TAB><TAB> config . resume = True <TAB> return config . resume","if answer . upper ( ) == ""F"" :","if answer . upper ( ) == ""F"" :",100.0,100.00,True
4931,"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB><TAB> <MASK> <TAB><TAB><TAB> if view . line ( s . b ) . size ( ) > 0 : <TAB><TAB><TAB><TAB> eol = view . line ( s . b ) . b <TAB><TAB><TAB><TAB> return R ( s . b , eol ) <TAB><TAB><TAB> return s <TAB> return s",if count == 1 :,if s . b :,94.43865294113735,95.31,False
4932,"def flush ( self ) : <TAB> if not self . cuts : <TAB><TAB> return <TAB> for move , ( x , y , z ) , cent in douglas ( self . cuts , self . tolerance , self . plane ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . write ( "" %s  X %.4f  Y %.4f  Z %.4f   %s "" % ( move , x , y , z , cent ) ) <TAB><TAB><TAB> self . lastgcode = None <TAB><TAB><TAB> self . lastx = x <TAB><TAB><TAB> self . lasty = y <TAB><TAB><TAB> self . lastz = z <TAB><TAB> else : <TAB><TAB><TAB> self . move_common ( x , y , z , gcode = "" G1 "" ) <TAB> self . cuts = [ ]",if cent :,if self . verbose :,97.3255301457785,97.82,False
4933,"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( ) # create a new group <TAB> new_i . id = self . id # with the same id <TAB> cls . id = old_id # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls . properties : <TAB><TAB> <MASK> <TAB><TAB><TAB> if self . has ( prop ) : <TAB><TAB><TAB><TAB> val = getattr ( self , prop ) <TAB><TAB><TAB><TAB> setattr ( new_i , prop , val ) <TAB> # but no members <TAB> new_i . members = [ ] <TAB> return new_i","if prop is not ""members"" :","if hasattr ( self , prop ) :",96.9717244432341,96.19,False
4934,"def find_region_by_value ( key , value ) : <TAB> for region in cognitoidp_backends : <TAB><TAB> backend = cognitoidp_backends [ region ] <TAB><TAB> for user_pool in backend . user_pools . values ( ) : <TAB><TAB><TAB> if key == "" client_id "" and value in user_pool . clients : <TAB><TAB><TAB><TAB> return region <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return region <TAB> # If we can't find the `client_id` or `access_token`, we just pass <TAB> # back a default backend region, which will raise the appropriate <TAB> # error message (e.g. NotAuthorized or NotFound). <TAB> return list ( cognitoidp_backends ) [ 0 ]","if key == ""access_token"" and value in user_pool . access_tokens :","if key == ""access_token"" and value in user_pool . access_tokens :",100.0,100.00,True
4935,"def __init__ ( <TAB> self , fixed : MQTTFixedHeader = None , variable_header : PacketIdVariableHeader = None ) : <TAB> if fixed is None : <TAB><TAB> header = MQTTFixedHeader ( PUBREL , 0x02 ) # [MQTT-3.6.1-1] <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise HBMQTTException ( <TAB><TAB><TAB><TAB> "" Invalid fixed packet type  %s  for PubrelPacket init "" % fixed . packet_type <TAB><TAB><TAB> ) <TAB><TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = variable_header <TAB> self . payload = None",if fixed . packet_type is not PUBREL :,if fixed . packet_type is not PUBREL :,100.0,100.00,True
4936,"def _on_event_MetadataStatisticsUpdated ( self , event , data ) : <TAB> with self . _selectedFileMutex : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . _setJobData ( <TAB><TAB><TAB><TAB> self . _selectedFile [ "" filename "" ] , <TAB><TAB><TAB><TAB> self . _selectedFile [ "" filesize "" ] , <TAB><TAB><TAB><TAB> self . _selectedFile [ "" sd "" ] , <TAB><TAB><TAB><TAB> self . _selectedFile [ "" user "" ] , <TAB><TAB><TAB> )",if self . _selectedFile :,"if self . _selectedFile [ ""filename"" ] :",96.16084808330389,95.70,False
4937,"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB><TAB> parameter_range_key , <TAB><TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> # Categorical ranges <TAB><TAB> if isinstance ( parameter_range_value , list ) : <TAB><TAB><TAB> for categorical_value in parameter_range_value : <TAB><TAB><TAB><TAB> value_hp . validate ( categorical_value ) <TAB><TAB> # Continuous, Integer ranges <TAB><TAB> else : <TAB><TAB><TAB> value_hp . validate ( parameter_range_value )","if parameter_range_key == ""scaling_type"" :","if parameter_range_key == ""ranges"" :",98.45472973741919,97.91,False
4938,"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB><TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB><TAB> if self . _is_true ( self . visit ( comparator_node , element ) ) : <TAB><TAB><TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> collected . append ( current ) <TAB> return collected",if current is not None :,if current is not None :,100.0,100.00,True
4939,"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set ( ) <TAB> end = va + size <TAB> for offs in range ( va , end , 1 ) : <TAB><TAB> loc = self . getLocation ( offs , range = True ) <TAB><TAB> <MASK> <TAB><TAB><TAB> subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB><TAB><TAB> if loc [ L_TINFO ] : <TAB><TAB><TAB><TAB> subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB> return list ( subs )",if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,if loc [ L_VA ] and loc [ L_SIZE ] :,70.22162193812052,92.12,False
4940,"def run ( self ) : <TAB> while not self . _stopped : <TAB><TAB> try : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> test_name = next ( self . pending ) <TAB><TAB><TAB> except StopIteration : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> mp_result = self . _runtest ( test_name ) <TAB><TAB><TAB> self . output . put ( ( False , mp_result ) ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> break <TAB><TAB> except ExitThread : <TAB><TAB><TAB> break <TAB><TAB> except BaseException : <TAB><TAB><TAB> self . output . put ( ( True , traceback . format_exc ( ) ) ) <TAB><TAB><TAB> break","if must_stop ( mp_result . result , self . ns ) :",if mp_result :,66.05377226006891,93.78,False
4941,"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB><TAB> for k , v in data . items ( ) : <TAB><TAB><TAB> if k == key : <TAB><TAB><TAB><TAB> return v <TAB><TAB><TAB> elif isinstance ( v , ( list , tuple , dict ) ) : <TAB><TAB><TAB><TAB> out = get_in_inputs ( key , v ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB><TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB><TAB> out = [ x for x in out if x ] <TAB><TAB> <MASK> <TAB><TAB><TAB> return out [ 0 ]",if out :,if len ( out ) == 1 :,68.0467057084438,93.04,False
4942,"def act_mapping ( self , items , actions , mapping ) : <TAB> """"""Executes all the actions on the list of pods."""""" <TAB> success = True <TAB> for action in actions : <TAB><TAB> for key , method in mapping . items ( ) : <TAB><TAB><TAB> if key in action : <TAB><TAB><TAB><TAB> params = action . get ( key ) <TAB><TAB><TAB><TAB> ret = method ( items , params ) <TAB><TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB><TAB> success = False <TAB> return success",if not ret :,if ret is False :,82.49874913329813,97.27,False
4943,"def _apply ( self , plan ) : <TAB> desired = plan . desired <TAB> changes = plan . changes <TAB> self . log . debug ( "" _apply: zone= %s , len(changes)= %d "" , desired . name , len ( changes ) ) <TAB> domain_name = desired . name [ : - 1 ] <TAB> try : <TAB><TAB> nsone_zone = self . _client . loadZone ( domain_name ) <TAB> except ResourceException as e : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise <TAB><TAB> self . log . debug ( "" _apply:   no matching zone, creating "" ) <TAB><TAB> nsone_zone = self . _client . createZone ( domain_name ) <TAB> for change in changes : <TAB><TAB> class_name = change . __class__ . __name__ <TAB><TAB> getattr ( self , "" _apply_ {} "" . format ( class_name ) ) ( nsone_zone , change )",if e . message != self . ZONE_NOT_FOUND_MESSAGE :,if e . code != 404 :,83.33476473997007,94.81,False
4944,"def split_artists ( self , json ) : <TAB> if len ( json ) == 0 : <TAB><TAB> ( [ ] , [ ] ) <TAB> elif len ( json ) == 1 : <TAB><TAB> artist = Artist . query . filter_by ( name = json [ 0 ] [ "" name "" ] ) . first ( ) <TAB><TAB> return ( [ artist ] , [ ] ) <TAB> my_artists = [ ] <TAB> other_artists = [ ] <TAB> for artist_dict in json : <TAB><TAB> artist = Artist . query . filter_by ( name = artist_dict [ "" name "" ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> my_artists . append ( artist . first ( ) ) <TAB><TAB> else : <TAB><TAB><TAB> del artist_dict [ "" thumb_url "" ] <TAB><TAB><TAB> other_artists . append ( artist_dict ) <TAB> return ( my_artists , other_artists )",if artist . count ( ) :,if artist :,70.86615942058754,97.72,False
4945,"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB><TAB> if attrname . startswith ( "" __ "" ) : <TAB><TAB><TAB> continue <TAB><TAB> attrvalue = getattr ( self , attrname , None ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> if attrname == "" salt_version "" : <TAB><TAB><TAB> attrname = "" version "" <TAB><TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB><TAB><TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB><TAB> elif hasattr ( self . metadata , attrname ) : <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB><TAB><TAB> except AttributeError : <TAB><TAB><TAB><TAB> pass",if attrvalue == 0 :,if not attrvalue :,70.88006833410697,97.85,False
4946,"def close ( self , code = errno . ECONNRESET ) : <TAB> with self . shutdown_lock : <TAB><TAB> <MASK> <TAB><TAB><TAB> super ( RemoteIPRoute , self ) . close ( code = code ) <TAB><TAB><TAB> self . closed = True <TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB> self . _mitogen_call . get ( ) <TAB><TAB><TAB> except mitogen . core . ChannelError : <TAB><TAB><TAB><TAB> pass <TAB><TAB><TAB> if self . _mitogen_broker is not None : <TAB><TAB><TAB><TAB> self . _mitogen_broker . shutdown ( ) <TAB><TAB><TAB><TAB> self . _mitogen_broker . join ( )",if not self . closed :,if self . closed :,88.59370341817538,98.71,False
4947,"def untokenize ( self , iterable ) : <TAB> for t in iterable : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . compat ( t , iterable ) <TAB><TAB><TAB> break <TAB><TAB> tok_type , token , start , end , line = t <TAB><TAB> self . add_whitespace ( start ) <TAB><TAB> self . tokens . append ( token ) <TAB><TAB> self . prev_row , self . prev_col = end <TAB><TAB> if tok_type in ( NEWLINE , NL ) : <TAB><TAB><TAB> self . prev_row + = 1 <TAB><TAB><TAB> self . prev_col = 0 <TAB> return "" "" . join ( self . tokens )",if len ( t ) == 2 :,if self . compat :,93.17906007510494,95.41,False
4948,"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB><TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB><TAB> spk = uttid <TAB> if not self . reverse : <TAB><TAB> if self . norm_means : <TAB><TAB><TAB> x = np . add ( x , self . bias [ spk ] ) <TAB><TAB> <MASK> <TAB><TAB><TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB><TAB> if self . norm_means : <TAB><TAB><TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x",if self . norm_vars :,if self . scale [ spk ] :,73.87372601282074,95.05,False
4949,"def get_party_total ( self , args ) : <TAB> self . party_total = frappe . _dict ( ) <TAB> for d in self . receivables : <TAB><TAB> self . init_party_total ( d ) <TAB><TAB> # Add all amount columns <TAB><TAB> for k in list ( self . party_total [ d . party ] ) : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . party_total [ d . party ] [ k ] + = d . get ( k , 0.0 ) <TAB><TAB> # set territory, customer_group, sales person etc <TAB><TAB> self . set_party_details ( d )","if k not in [ ""currency"" , ""sales_person"" ] :","if k not in [ ""amount"" , ""total_amount"" ] :",97.92048839416148,96.20,False
4950,"def get_databases ( request ) : <TAB> dbs = { } <TAB> global_env = globals ( ) <TAB> for ( key , value ) in global_env . items ( ) : <TAB><TAB> try : <TAB><TAB><TAB> cond = isinstance ( value , GQLDB ) <TAB><TAB> except : <TAB><TAB><TAB> cond = isinstance ( value , SQLDB ) <TAB><TAB> <MASK> <TAB><TAB><TAB> dbs [ key ] = value <TAB> return dbs",if cond :,if cond :,100.0,100.00,True
4951,"def check_twobit_file ( dbkey , GALAXY_DATA_INDEX_DIR ) : <TAB> twobit_file = "" %s /twobit.loc "" % GALAXY_DATA_INDEX_DIR <TAB> twobit_path = "" "" <TAB> twobits = { } <TAB> for i , line in enumerate ( open ( twobit_file ) ) : <TAB><TAB> line = line . rstrip ( "" \r \n "" ) <TAB><TAB> if line and not line . startswith ( "" # "" ) : <TAB><TAB><TAB> fields = line . split ( "" \t "" ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> continue <TAB><TAB><TAB> twobits [ ( fields [ 0 ] ) ] = fields [ 1 ] <TAB> if dbkey in twobits : <TAB><TAB> twobit_path = twobits [ ( dbkey ) ] <TAB> return twobit_path",if len ( fields ) < 2 :,if len ( fields ) != 2 :,98.96936433032708,98.38,False
4952,"def action ( scheduler , _ ) : <TAB> nonlocal state <TAB> nonlocal has_result <TAB> nonlocal result <TAB> nonlocal first <TAB> nonlocal time <TAB> <MASK> <TAB><TAB> observer . on_next ( result ) <TAB> try : <TAB><TAB> if first : <TAB><TAB><TAB> first = False <TAB><TAB> else : <TAB><TAB><TAB> state = iterate ( state ) <TAB><TAB> has_result = condition ( state ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = state <TAB><TAB><TAB> time = time_mapper ( state ) <TAB> except Exception as e : # pylint: disable=broad-except <TAB><TAB> observer . on_error ( e ) <TAB><TAB> return <TAB> <MASK> <TAB><TAB> mad . disposable = scheduler . schedule_relative ( time , action ) <TAB> else : <TAB><TAB> observer . on_completed ( )",if has_result :,if has_result :,100.0,100.00,True
4953,def orthogonalEnd ( self ) : <TAB> if self . type == Segment . LINE : <TAB><TAB> O = self . AB . orthogonal ( ) <TAB><TAB> O . norm ( ) <TAB><TAB> return O <TAB> else : <TAB><TAB> O = self . B - self . C <TAB><TAB> O . norm ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return - O <TAB><TAB> else : <TAB><TAB><TAB> return O,if self . type == Segment . CCW :,if self . type == Segment . NOR :,98.28186285750704,98.06,False
4954,"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB><TAB> values = [ values ] <TAB> for v in values : <TAB><TAB> v = str ( v ) <TAB><TAB> if isinstance ( self . _definition , dict ) : <TAB><TAB><TAB> self . _definition . pop ( v , None ) <TAB><TAB> elif self . _definition == "" ANY "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . _definition = [ ] <TAB><TAB> elif v in self . _definition : <TAB><TAB><TAB> self . _definition . remove ( v ) <TAB> if ( <TAB><TAB> self . _value is not None <TAB><TAB> and self . _value not in self . _definition <TAB><TAB> and self . _not_any ( ) <TAB> ) : <TAB><TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )","if v == ""ANY"" :",if not self . _definition :,94.07005784643556,97.16,False
4955,"def __enter__ ( self ) - > None : <TAB> try : <TAB><TAB> <MASK> <TAB><TAB><TAB> signal . signal ( signal . SIGALRM , self . handle_timeout ) <TAB><TAB><TAB> signal . alarm ( self . seconds ) <TAB> except ValueError as ex : <TAB><TAB> logger . warning ( "" timeout can ' t be used in the current context "" ) <TAB><TAB> logger . exception ( ex )",if threading . current_thread ( ) == threading . main_thread ( ) :,if self . seconds is not None :,62.746816924437276,85.79,False
4956,"def __init__ ( self , fixed : MQTTFixedHeader = None ) : <TAB> if fixed is None : <TAB><TAB> header = MQTTFixedHeader ( PINGRESP , 0x00 ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise HBMQTTException ( <TAB><TAB><TAB><TAB> "" Invalid fixed packet type  %s  for PingRespPacket init "" <TAB><TAB><TAB><TAB> % fixed . packet_type <TAB><TAB><TAB> ) <TAB><TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = None <TAB> self . payload = None",if fixed . packet_type is not PINGRESP :,if fixed . packet_type is not PINGRESP :,100.0,100.00,True
4957,"def _put_nowait ( self , data , * , sender ) : <TAB> if not self . _running : <TAB><TAB> logger . warning ( "" Pub/Sub listener message after stop:  %r ,  %r "" , sender , data ) <TAB><TAB> return <TAB> self . _queue . put_nowait ( ( sender , data ) ) <TAB> if self . _waiter is not None : <TAB><TAB> fut , self . _waiter = self . _waiter , None <TAB><TAB> <MASK> <TAB><TAB><TAB> assert fut . cancelled ( ) , ( "" Waiting future is in wrong state "" , self , fut ) <TAB><TAB><TAB> return <TAB><TAB> fut . set_result ( None )",if fut . done ( ) :,if fut . done ( ) :,100.0,100.00,True
4958,"def OnAssignBuiltin ( self , cmd_val ) : <TAB> # type: (cmd_value__Assign) -> None <TAB> buf = self . _ShTraceBegin ( ) <TAB> if not buf : <TAB><TAB> return <TAB> for i , arg in enumerate ( cmd_val . argv ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> buf . write ( ""   "" ) <TAB><TAB> buf . write ( arg ) <TAB> for pair in cmd_val . pairs : <TAB><TAB> buf . write ( ""   "" ) <TAB><TAB> buf . write ( pair . var_name ) <TAB><TAB> buf . write ( "" = "" ) <TAB><TAB> if pair . rval : <TAB><TAB><TAB> _PrintShValue ( pair . rval , buf ) <TAB> buf . write ( "" \n "" ) <TAB> self . f . write ( buf . getvalue ( ) )",if i != 0 :,if i :,73.69785508080551,97.94,False
4959,"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB><TAB> del obj [ k ] <TAB><TAB> if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) : <TAB><TAB><TAB> k = dumps ( k ) <TAB><TAB><TAB> # Keep track of which keys need to be decoded when loading. <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> obj [ Types . KEYS ] = [ ] <TAB><TAB><TAB> obj [ Types . KEYS ] . append ( k ) <TAB><TAB> obj [ k ] = convertObjects ( v ) <TAB> return obj",if Types . KEYS not in obj :,if not obj [ Types . KEYS ] :,97.1762131612322,96.33,False
4960,"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB><TAB> while token : <TAB><TAB><TAB> if token . value == "" { "" : <TAB><TAB><TAB><TAB> length = token . matching_bracket . total_length - token . total_length <TAB><TAB><TAB><TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB><TAB><TAB> if token . ClosesScope ( ) : <TAB><TAB><TAB><TAB> break <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> token = token . matching_bracket <TAB><TAB><TAB> token = token . next_token <TAB> return False",if token . OpensScope ( ) :,"if token . value == ""}"" :",96.64629776157805,96.50,False
4961,"def get_editable_dict ( self ) : <TAB> ret = { } <TAB> for ref , ws_package in self . _workspace_packages . items ( ) : <TAB><TAB> path = ws_package . root_folder <TAB><TAB> <MASK> <TAB><TAB><TAB> path = os . path . join ( path , CONANFILE ) <TAB><TAB> ret [ ref ] = { "" path "" : path , "" layout "" : ws_package . layout } <TAB> return ret",if os . path . isdir ( path ) :,if not path . startswith ( CONANFILE ) :,75.69732726419943,93.80,False
4962,"def serialize ( self , name = None ) : <TAB> data = super ( WebLink , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> if self . width : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise InvalidWidthException ( self . width ) <TAB><TAB> data [ "" inputOptions "" ] = { } <TAB><TAB> data [ "" width "" ] = self . width <TAB> data . update ( { "" content "" : { "" url "" : self . linkUrl , "" text "" : self . linkText } } ) <TAB> return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",if not self . width . is_valid ( ) :,68.85567941278151,90.83,False
4963,"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB><TAB> context . next_indent = len ( text ) <TAB><TAB> <MASK> <TAB><TAB><TAB> while context . next_indent < context . indent : <TAB><TAB><TAB><TAB> context . indent = context . indent_stack . pop ( ) <TAB><TAB><TAB> if context . next_indent > context . indent : <TAB><TAB><TAB><TAB> extra = text [ context . indent : ] <TAB><TAB><TAB><TAB> text = text [ : context . indent ] <TAB> else : <TAB><TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB><TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB><TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( )",if context . next_indent < context . indent :,if context . next_indent < context . indent :,100.0,100.00,True
4964,"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB><TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB><TAB><TAB> if subscriber_web_sock == web_sock : <TAB><TAB><TAB><TAB> index = i <TAB><TAB><TAB><TAB> break <TAB><TAB> <MASK> <TAB><TAB><TAB> del self . _subscribers [ index ] <TAB><TAB> if not self . _subscribers : <TAB><TAB><TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) )",if index is not None :,if index :,87.26682080558264,97.37,False
4965,"def test_missing_dict_param ( ) : <TAB> expected_err = "" params dictionary did not contain value for placeholder "" <TAB> try : <TAB><TAB> substitute_params ( <TAB><TAB><TAB> "" SELECT * FROM cust WHERE salesrep =  %(name)s "" , { "" foobar "" : "" John Doe "" } <TAB><TAB> ) <TAB><TAB> assert False , "" expected exception b/c dict did not contain replacement value "" <TAB> except ValueError as exc : <TAB><TAB> <MASK> <TAB><TAB><TAB> raise",if expected_err not in str ( exc ) :,if expected_err not in str ( exc ) :,100.0,100.00,True
4966,"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> n + = 1 <TAB><TAB> elif op_gprv ( op ) : <TAB><TAB><TAB> r + = 1 <TAB><TAB> else : <TAB><TAB><TAB> return False <TAB> return n == 1 and r == 1","if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",if op_mem ( op ) :,75.80373875672298,85.30,False
4967,"def on_enter ( self ) : <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB><TAB> if hasattr ( self , "" theme_cls "" ) and not self . focus_color : <TAB><TAB><TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> self . md_bg_color = self . focus_color",if not self . focus_color :,"if hasattr ( App , ""get_running_app"" ) and not self . focus_",70.31506882412518,92.31,False
4968,"def __init__ ( self , * args , * * kwargs ) : <TAB> BaseCellExporter . __init__ ( self , * args , * * kwargs ) <TAB> self . comment = "" # "" <TAB> for key in [ "" cell_marker "" ] : <TAB><TAB> <MASK> <TAB><TAB><TAB> self . metadata [ key ] = self . unfiltered_metadata [ key ] <TAB> if self . fmt . get ( "" rst2md "" ) : <TAB><TAB> raise ValueError ( <TAB><TAB><TAB> "" The  ' rst2md '  option is a read only option. The reverse conversion is not  "" <TAB><TAB><TAB> "" implemented. Please either deactivate the option, or save to another format. "" <TAB><TAB> ) # pragma: no cover",if key in self . unfiltered_metadata :,if key in self . unfiltered_metadata :,100.0,100.00,True
4969,"def sendQueryQueueByAfterNate ( self ) : <TAB> for i in range ( 10 ) : <TAB><TAB> queryQueueByAfterNateRsp = self . session . httpClint . send ( urls . get ( "" queryQueue "" ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> print ( <TAB><TAB><TAB><TAB> "" "" . join ( queryQueueByAfterNateRsp . get ( "" messages "" ) ) <TAB><TAB><TAB><TAB> or queryQueueByAfterNateRsp . get ( "" validateMessages "" ) <TAB><TAB><TAB> ) <TAB><TAB><TAB> time . sleep ( 1 ) <TAB><TAB> else : <TAB><TAB><TAB> sendEmail ( ticket . WAIT_ORDER_SUCCESS ) <TAB><TAB><TAB> sendServerChan ( ticket . WAIT_ORDER_SUCCESS ) <TAB><TAB><TAB> raise ticketIsExitsException ( ticket . WAIT_AFTER_NATE_SUCCESS )","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",if queryQueueByAfterNateRsp :,67.91071214594176,95.03,False
4970,"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB><TAB> line = line . strip ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> continue <TAB><TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB><TAB> if fn is not None : <TAB><TAB><TAB> _path = os . path . split ( fn ) <TAB><TAB><TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB><TAB><TAB><TAB> continue <TAB><TAB> real_errors . append ( line ) <TAB> return real_errors",if not line :,if not line :,100.0,100.00,True
4971,"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB><TAB> r = repr ( n ) <TAB><TAB> if not comment : # then it can be inside a comment! <TAB><TAB><TAB> r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB><TAB> return r <TAB> if not isinstance ( n , six . integer_types ) : <TAB><TAB> return n <TAB> if isinstance ( n , constants . Constant ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB><TAB> else : <TAB><TAB><TAB> return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB> elif abs ( n ) < 10 : <TAB><TAB> return str ( n ) <TAB> else : <TAB><TAB> return hex ( n )",if comment :,"if n . startswith ( ""/*"" ) :",98.57238745467048,96.01,False
4972,"def get_pricings ( self , subscription_id : str ) : <TAB> try : <TAB><TAB> client = self . get_client ( subscription_id ) <TAB><TAB> pricings_list = await run_concurrently ( lambda : client . pricings . list ( ) ) <TAB><TAB> <MASK> <TAB><TAB><TAB> return pricings_list . value <TAB><TAB> else : <TAB><TAB><TAB> return [ ] <TAB> except Exception as e : <TAB><TAB> print_exception ( f "" Failed to retrieve pricings:  { e } "" ) <TAB><TAB> return [ ]","if hasattr ( pricings_list , ""value"" ) :",if pricings_list . value :,65.39140214246808,93.56,False
4973,"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB><TAB> # if it is a variable name add it to the doc <TAB><TAB> name = target . id <TAB><TAB> if name not in variables : <TAB><TAB><TAB> doc = find_doc_for ( target , body_lines ) <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> variables [ name ] = doc <TAB> elif isinstance ( target , ast . Tuple ) : <TAB><TAB> # if it is a tuple then iterate the elements <TAB><TAB> # this can happen like this: <TAB><TAB> # a, b = 1, 2 <TAB><TAB> for e in target . elts : <TAB><TAB><TAB> add_doc ( e , variables , body_lines )",if doc is not None :,if doc is not None :,100.0,100.00,True
4974,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB><TAB> if left == 0 : <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB> left - = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> done = False <TAB> while not done : <TAB><TAB> <MASK> <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB><TAB><TAB> right + = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> return left , right",if right == len ( text ) :,if right in allowed_chars :,78.55555518601214,96.60,False
4975,"def pxrun_nodes ( self , * args , * * kwargs ) : <TAB> cell = self . _px_cell <TAB> if re . search ( r "" ^ \ s* %a utopx \ b "" , cell ) : <TAB><TAB> self . _disable_autopx ( ) <TAB><TAB> return False <TAB> else : <TAB><TAB> try : <TAB><TAB><TAB> result = self . view . execute ( cell , silent = False , block = False ) <TAB><TAB> except : <TAB><TAB><TAB> self . shell . showtraceback ( ) <TAB><TAB><TAB> return True <TAB><TAB> else : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> try : <TAB><TAB><TAB><TAB><TAB> result . get ( ) <TAB><TAB><TAB><TAB> except : <TAB><TAB><TAB><TAB><TAB> self . shell . showtraceback ( ) <TAB><TAB><TAB><TAB><TAB> return True <TAB><TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB><TAB> result . display_outputs ( ) <TAB><TAB><TAB> return False",if self . view . block :,"if isinstance ( result , _YieldableResult ) :",96.45908885631755,97.22,False
4976,"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB><TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB><TAB> if matchSelf : <TAB><TAB><TAB> yield s <TAB><TAB> if recurseInAnon : <TAB><TAB><TAB> yield from s . children_recurse_anon <TAB><TAB> else : <TAB><TAB><TAB> yield from s . _children <TAB><TAB> <MASK> <TAB><TAB><TAB> break <TAB><TAB> s = s . siblingAbove <TAB><TAB> if Symbol . debug_lookup : <TAB><TAB><TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB><TAB><TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",if s . siblingAbove is None :,if s . siblingAbove is None :,100.0,100.00,True
4977,"def decTaskGen ( ) : <TAB> cnt = intbv ( 0 , min = - n , max = n ) <TAB> while 1 : <TAB><TAB> yield clock . posedge , reset . negedge <TAB><TAB> <MASK> <TAB><TAB><TAB> cnt [ : ] = 0 <TAB><TAB><TAB> count . next = 0 <TAB><TAB> else : <TAB><TAB><TAB> # print count <TAB><TAB><TAB> decTaskFunc ( cnt , enable , reset , n ) <TAB><TAB><TAB> count . next = cnt",if reset == ACTIVE_LOW :,if enable :,92.05503316521485,94.51,False
4978,"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB><TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB><TAB> <MASK> <TAB><TAB><TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB><TAB><TAB> if layer in layer_names : <TAB><TAB><TAB><TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB><TAB><TAB><TAB> print ( layer_names [ layer ] ) <TAB><TAB><TAB><TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> #     out=[out] <TAB> return out","if ""self"" in stack [ 0 ] . f_locals :","if stack [ 0 ] . f_locals [ ""self"" ] :",96.33374709666515,97.09,False
4979,"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB><TAB> if isinstance ( self . header , RenderedContent ) : <TAB><TAB><TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB><TAB> else : <TAB><TAB><TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB><TAB> <MASK> <TAB><TAB><TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB><TAB> else : <TAB><TAB><TAB> d [ "" subheader "" ] = self . subheader <TAB> return d","if isinstance ( self . subheader , RenderedContent ) :","if isinstance ( self . subheader , RenderedContent ) :",100.0,100.00,True
4980,"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB><TAB> form = BookMarkForm ( request . POST ) <TAB><TAB> <MASK> <TAB><TAB><TAB> form_type = form . save ( ) <TAB><TAB><TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB><TAB> else : <TAB><TAB><TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB><TAB> if form_type == "" server "" : <TAB><TAB><TAB> url = reverse ( "" servers "" ) <TAB><TAB> else : <TAB><TAB><TAB> url = reverse ( "" metrics "" ) <TAB><TAB> return redirect ( url ) <TAB> else : <TAB><TAB> return redirect ( reverse ( "" servers "" ) )",if form . is_valid ( ) :,if form . is_valid ( ) :,100.0,100.00,True
4981,"def fee_amount_in_quote ( self , trading_pair : str , price : Decimal , order_amount : Decimal ) : <TAB> fee_amount = Decimal ( "" 0 "" ) <TAB> if self . percent > 0 : <TAB><TAB> fee_amount = ( price * order_amount ) * self . percent <TAB> base , quote = trading_pair . split ( "" - "" ) <TAB> for flat_fee in self . flat_fees : <TAB><TAB> if interchangeable ( flat_fee [ 0 ] , base ) : <TAB><TAB><TAB> fee_amount + = flat_fee [ 1 ] * price <TAB><TAB> <MASK> <TAB><TAB><TAB> fee_amount + = flat_fee [ 1 ] <TAB> return fee_amount","elif interchangeable ( flat_fee [ 0 ] , quote ) :","elif interchangeable ( flat_fee [ 0 ] , quote ) :",100.0,100.00,True
4982,"def load_batch ( fpath ) : <TAB> with open ( fpath , "" rb "" ) as f : <TAB><TAB> <MASK> <TAB><TAB><TAB> # Python3 <TAB><TAB><TAB> d = pickle . load ( f , encoding = "" latin1 "" ) <TAB><TAB> else : <TAB><TAB><TAB> # Python2 <TAB><TAB><TAB> d = pickle . load ( f ) <TAB> data = d [ "" data "" ] <TAB> labels = d [ "" labels "" ] <TAB> return data , labels","if sys . version_info > ( 3 , 0 ) :","if sys . version_info >= ( 3 , 0 ) :",98.53977450535136,98.21,False
4983,"def clear_entries ( options ) : <TAB> """"""Clear pending entries"""""" <TAB> with Session ( ) as session : <TAB><TAB> query = session . query ( db . PendingEntry ) . filter ( db . PendingEntry . approved == False ) <TAB><TAB> <MASK> <TAB><TAB><TAB> query = query . filter ( db . PendingEntry . task_name == options . task_name ) <TAB><TAB> deleted = query . delete ( ) <TAB><TAB> console ( "" Successfully deleted  %i  pending entries "" % deleted )",if options . task_name :,if options . task_name :,100.0,100.00,True
4984,"def attribute_table ( self , attribute ) : <TAB> """"""Return a tuple (schema, table) for attribute."""""" <TAB> dimension = attribute . dimension <TAB> if dimension : <TAB><TAB> schema = self . naming . dimension_schema or self . naming . schema <TAB><TAB> <MASK> <TAB><TAB><TAB> table = self . fact_name <TAB><TAB> else : <TAB><TAB><TAB> table = self . naming . dimension_table_name ( dimension ) <TAB> else : <TAB><TAB> table = self . fact_name <TAB><TAB> schema = self . naming . schema <TAB> return ( schema , table )",if dimension . is_flat and not dimension . has_details :,"if dimension == ""fact"" :",69.04473360137838,92.63,False
4985,"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB><TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB><TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB><TAB> if dialog . run ( ) != Gtk . ResponseType . YES : <TAB><TAB><TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB><TAB> <MASK> <TAB><TAB><TAB> del song [ "" ~#rating "" ] <TAB><TAB><TAB> reset . append ( song ) <TAB> librarian . changed ( reset )","if ""~#rating"" in song :","if not song . get ( ""~#rating"" ) :",68.66366941348673,95.55,False
4986,"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB><TAB> if left == 0 : <TAB><TAB><TAB> done = True <TAB><TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB><TAB><TAB> left - = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> done = False <TAB> while not done : <TAB><TAB> if right == len ( text ) : <TAB><TAB><TAB> done = True <TAB><TAB> <MASK> <TAB><TAB><TAB> right + = 1 <TAB><TAB> else : <TAB><TAB><TAB> done = True <TAB> return left , right",elif not self . word_boundary_char ( text [ right ] ) :,elif self . word_boundary_char ( text [ right ] ) in allowed_chars,70.3029591299076,96.84,False
4987,"def handle_read ( self ) : <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try : <TAB><TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB><TAB> pass <TAB> except socket . error : <TAB><TAB> self . handle_error ( ) <TAB> else : <TAB><TAB> self . tot_bytes_received + = len ( chunk ) <TAB><TAB> if not chunk : <TAB><TAB><TAB> self . transfer_finished = True <TAB><TAB><TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB><TAB><TAB> return <TAB><TAB> <MASK> <TAB><TAB><TAB> chunk = self . _data_wrapper ( chunk ) <TAB><TAB> try : <TAB><TAB><TAB> self . file_obj . write ( chunk ) <TAB><TAB> except OSError as err : <TAB><TAB><TAB> raise _FileReadWriteError ( err )",if self . _data_wrapper is not None :,if self . _data_wrapper :,97.85307441644004,98.30,False
4988,"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB><TAB> if self . save == self . split : <TAB><TAB><TAB> self . save = 100 <TAB><TAB> if self . split > 20 : <TAB><TAB><TAB> self . save = self . split <TAB><TAB><TAB> self . split = 1 <TAB><TAB> else : <TAB><TAB><TAB> self . split = self . save <TAB> else : <TAB><TAB> if self . save == self . split : <TAB><TAB><TAB> self . save = 0.3 <TAB><TAB> if self . split < = self . min or self . split > = self . max : <TAB><TAB><TAB> self . split = self . save <TAB><TAB> <MASK> <TAB><TAB><TAB> self . split = self . min <TAB><TAB> else : <TAB><TAB><TAB> self . split = self . max <TAB> self . placeChilds ( )",elif self . split < 0.5 :,elif self . min <= self . max :,73.6799698353388,97.14,False
4989,"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB><TAB> rlen = size - len ( ret ) <TAB><TAB> x = self . fd . read ( rlen ) <TAB><TAB> if x == b "" "" : <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> return None <TAB><TAB><TAB> return ret <TAB><TAB> ret + = x <TAB> return ret",if not shortok :,if shortok :,71.53160992950413,98.22,False
4990,"def webfinger ( environ , start_response , _ ) : <TAB> query = parse_qs ( environ [ "" QUERY_STRING "" ] ) <TAB> try : <TAB><TAB> rel = query [ "" rel "" ] <TAB><TAB> resource = query [ "" resource "" ] [ 0 ] <TAB> except KeyError : <TAB><TAB> resp = BadRequest ( "" Missing parameter in request "" ) <TAB> else : <TAB><TAB> <MASK> <TAB><TAB><TAB> resp = BadRequest ( "" Bad issuer in request "" ) <TAB><TAB> else : <TAB><TAB><TAB> wf = WebFinger ( ) <TAB><TAB><TAB> resp = Response ( wf . response ( subject = resource , base = OAS . baseurl ) ) <TAB> return resp ( environ , start_response )",if rel != [ OIC_ISSUER ] :,"if rel != ""issuer"" :",94.50357397247453,96.59,False
4991,"def _tokenize ( self , text ) : <TAB> if format_text ( text ) == EMPTY_TEXT : <TAB><TAB> return [ self . additional_special_tokens [ 0 ] ] <TAB> split_tokens = [ ] <TAB> if self . do_basic_tokenize : <TAB><TAB> for token in self . basic_tokenizer . tokenize ( <TAB><TAB><TAB> text , never_split = self . all_special_tokens <TAB><TAB> ) : <TAB><TAB><TAB> # If the token is part of the never_split set <TAB><TAB><TAB> <MASK> <TAB><TAB><TAB><TAB> split_tokens . append ( token ) <TAB><TAB><TAB> else : <TAB><TAB><TAB><TAB> split_tokens + = self . wordpiece_tokenizer . tokenize ( token ) <TAB> else : <TAB><TAB> split_tokens = self . wordpiece_tokenizer . tokenize ( text ) <TAB> return split_tokens",if token in self . basic_tokenizer . never_split :,"if token . startswith ( ""never_split"" ) :",96.83285446693321,95.99,False
4992,"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB><TAB> self . connect ( ) <TAB> try : <TAB><TAB> if isinstance ( command , str ) : <TAB><TAB><TAB> command = [ command ] <TAB><TAB> for item in command : <TAB><TAB><TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB><TAB> self . disconnect ( ) <TAB><TAB> <MASK> <TAB><TAB><TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB><TAB> else : <TAB><TAB><TAB> _errno , errmsg = e . args <TAB><TAB> raise ConnectionError ( <TAB><TAB><TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB><TAB> ) <TAB> except Exception : <TAB><TAB> self . disconnect ( ) <TAB><TAB> raise",if len ( e . args ) == 1 :,if check_health :,88.65743942383867,95.87,False
4993,"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> #      taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = { } <TAB> for key , val in value . items ( ) : <TAB><TAB> if key in [ "" attachments "" , "" custom_attributes "" , "" description_diff "" ] : <TAB><TAB><TAB> ret [ key ] = val <TAB><TAB> <MASK> <TAB><TAB><TAB> ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB><TAB> else : <TAB><TAB><TAB> ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB> return ret","elif key == ""points"" :","elif isinstance ( val , dict ) :",72.86311570213107,96.42,False
4994,"def to_child ( cls , key = None , process = None ) : <TAB> if process is not None : <TAB><TAB> if type ( process ) is not dict : <TAB><TAB><TAB> raise ValueError ( <TAB><TAB><TAB><TAB> ' Invalid value provided for  "" process ""  parameter, expected a dictionary ' <TAB><TAB><TAB> ) <TAB><TAB> <MASK> <TAB><TAB><TAB> # Merge class `__process__` parameters with provided parameters <TAB><TAB><TAB> result = { } <TAB><TAB><TAB> result . update ( deepcopy ( cls . __process__ ) ) <TAB><TAB><TAB> result . update ( process ) <TAB><TAB><TAB> process = result <TAB> class Child ( cls ) : <TAB><TAB> __key__ = key <TAB><TAB> __process__ = process <TAB><TAB> __root__ = False <TAB> Child . __name__ = cls . __name__ <TAB> return Child",if cls . __process__ :,if key is not None and cls . __process__ is not None :,95.43443024261522,95.88,False
4995,"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB><TAB> return passed_class <TAB> else : <TAB><TAB> # pyclass = passed_self.get_type() <TAB><TAB> pyclass = passed_class <TAB><TAB> <MASK> <TAB><TAB><TAB> supers = pyclass . get_superclasses ( ) <TAB><TAB><TAB> if supers : <TAB><TAB><TAB><TAB> return pyobjects . PyObject ( supers [ 0 ] ) <TAB><TAB> return passed_self","if isinstance ( pyclass , pyobjects . AbstractClass ) :",if pyclass . is_subclass ( ) :,95.29660537349304,95.33,False
4996,"def get_data ( row ) : <TAB> data = [ ] <TAB> for field_name , field_xpath in fields : <TAB><TAB> result = row . xpath ( field_xpath ) <TAB><TAB> <MASK> <TAB><TAB><TAB> result = ""   "" . join ( <TAB><TAB><TAB><TAB> text <TAB><TAB><TAB><TAB> for text in map ( <TAB><TAB><TAB><TAB><TAB> six . text_type . strip , map ( six . text_type , map ( unescape , result ) ) <TAB><TAB><TAB><TAB> ) <TAB><TAB><TAB><TAB> if text <TAB><TAB><TAB> ) <TAB><TAB> else : <TAB><TAB><TAB> result = None <TAB><TAB> data . append ( result ) <TAB> return data",if result :,if result :,100.0,100.00,True
4997,"def say ( jarvis , s ) : <TAB> """"""Reads what is typed."""""" <TAB> if not s : <TAB><TAB> jarvis . say ( "" What should I say? "" ) <TAB> else : <TAB><TAB> voice_state = jarvis . is_voice_enabled ( ) <TAB><TAB> jarvis . enable_voice ( ) <TAB><TAB> jarvis . say ( s ) <TAB><TAB> <MASK> <TAB><TAB><TAB> jarvis . disable_voice ( )",if not voice_state :,if voice_state :,68.40032299137906,97.95,False
4998,"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB><TAB> <MASK> <TAB><TAB><TAB> fromlist = list ( fromlist ) <TAB><TAB><TAB> fromlist . remove ( "" * "" ) <TAB><TAB><TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB><TAB> for x in fromlist : <TAB><TAB><TAB> if isinstance ( getattr ( module , x , None ) , types . ModuleType ) : <TAB><TAB><TAB><TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB><TAB><TAB><TAB> if from_name in modules : <TAB><TAB><TAB><TAB><TAB> importlib . import_module ( from_name ) <TAB> return module","if ""*"" in fromlist :","if ""*"" in fromlist :",100.0,100.00,True
4999,"def _read_pricing_file ( self , region = None , pricing_file = None ) : <TAB> if not self . __pricing_file_cache : <TAB><TAB> <MASK> <TAB><TAB><TAB> logging . info ( "" Reading pricing file... "" ) <TAB><TAB><TAB> with open ( pricing_file ) as data_file : <TAB><TAB><TAB><TAB> self . __pricing_file_cache = json . load ( data_file ) <TAB><TAB> else : <TAB><TAB><TAB> self . __pricing_file_cache = self . _download_pricing_file ( region ) <TAB> return self . __pricing_file_cache",if pricing_file :,if pricing_file :,100.0,100.00,True
